  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 09:26:40,224 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:05:11,  1.32it/s][INFO|trainer.py:4226] 2025-01-21 09:26:44,394 >>
{'loss': 3.6579, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.5810112953186035, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.9603, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.876985788345337, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.9675, 'grad_norm': 125.88013458251953, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.8986222743988037, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.4891, 'grad_norm': inf, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.4166135787963867, 'loss_2': 0.07244873046875, 'loss_3': -14.02206039428711, 'loss_4': 8.943965911865234, 'epoch': 0.02}
{'loss': 3.8514, 'grad_norm': 127.84427642822266, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.7701499462127686, 'loss_2': 0.08123779296875, 'loss_3': -13.695306777954102, 'loss_4': 9.941965103149414, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:26:44,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:44,394 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:05:11,  1.32it/s][INFO|trainer.py:3910] 2025-01-21 09:26:48,172 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 09:26:48,174 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5/config.json                                                                                
{'eval_loss': 1.8909966945648193, 'eval_runtime': 3.7764, 'eval_samples_per_second': 271.155, 'eval_steps_per_second': 4.237, 'eval_loss_1': 1.8358533382415771, 'eval_loss_2': 0.05514335632324219, 'eval_loss_3': -17.712106704711914, 'eval_loss_4': 8.473479270935059, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 09:26:48,668 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:26:48,669 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:26:48,670 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:33:08,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 09:26:52,954 >>
{'loss': 3.4944, 'grad_norm': inf, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.4396183490753174, 'loss_2': 0.0548095703125, 'loss_3': -13.945830345153809, 'loss_4': 9.065216064453125, 'epoch': 0.03}
{'loss': 3.1655, 'grad_norm': 123.5893783569336, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.110966205596924, 'loss_2': 0.054534912109375, 'loss_3': -14.0938081741333, 'loss_4': 8.566936492919922, 'epoch': 0.04}
{'loss': 3.2716, 'grad_norm': 149.4989013671875, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.2252869606018066, 'loss_2': 0.046356201171875, 'loss_3': -14.19311809539795, 'loss_4': 7.97108268737793, 'epoch': 0.05}
{'loss': 2.6737, 'grad_norm': 130.50723266601562, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.6406733989715576, 'loss_2': 0.033050537109375, 'loss_3': -14.605631828308105, 'loss_4': 7.521351337432861, 'epoch': 0.05}
{'loss': 2.4915, 'grad_norm': 121.0882568359375, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.4534223079681396, 'loss_2': 0.038116455078125, 'loss_3': -14.938735961914062, 'loss_4': 7.908272743225098, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:26:52,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:52,955 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:33:08,  1.09s/it][INFO|trainer.py:3910] 2025-01-21 09:26:56,730 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 09:26:56,732 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10/config.json                                                                               
{'eval_loss': 1.0282227993011475, 'eval_runtime': 3.7743, 'eval_samples_per_second': 271.307, 'eval_steps_per_second': 4.239, 'eval_loss_1': 0.9971216917037964, 'eval_loss_2': 0.031101226806640625, 'eval_loss_3': -17.78649139404297, 'eval_loss_4': 7.895226955413818, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 09:26:57,147 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:26:57,148 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:26:57,148 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:26:57,874 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:36:55,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:27:01,494 >>
{'loss': 2.0408, 'grad_norm': 122.07339477539062, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.00317120552063, 'loss_2': 0.03759765625, 'loss_3': -15.017995834350586, 'loss_4': 8.630205154418945, 'epoch': 0.06}
{'loss': 2.2082, 'grad_norm': 107.23700714111328, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.171379804611206, 'loss_2': 0.036773681640625, 'loss_3': -14.866450309753418, 'loss_4': 8.451050758361816, 'epoch': 0.07}
{'loss': 1.8605, 'grad_norm': 119.580078125, 'learning_rate': 2.994767441860465e-05, 'loss_1': 1.8225297927856445, 'loss_2': 0.0379638671875, 'loss_3': -15.104247093200684, 'loss_4': 9.655344009399414, 'epoch': 0.08}
{'loss': 1.6892, 'grad_norm': 105.56027221679688, 'learning_rate': 2.994186046511628e-05, 'loss_1': 1.6571158170700073, 'loss_2': 0.03204345703125, 'loss_3': -15.457223892211914, 'loss_4': 9.944604873657227, 'epoch': 0.08}
{'loss': 1.3948, 'grad_norm': 106.99066162109375, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.3674983978271484, 'loss_2': 0.027252197265625, 'loss_3': -15.546866416931152, 'loss_4': 10.6244535446167, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:01,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:01,494 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:36:55,  1.13s/it][INFO|trainer.py:3910] 2025-01-21 09:27:05,276 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 09:27:05,278 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15/config.json                                                                               
{'eval_loss': 0.43714311718940735, 'eval_runtime': 3.7812, 'eval_samples_per_second': 270.813, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.41092759370803833, 'eval_loss_2': 0.026215553283691406, 'eval_loss_3': -18.04656982421875, 'eval_loss_4': 9.576783180236816, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:05,734 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:05,736 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:05,736 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:06,514 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:29<1:38:06,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:27:10,128 >>
{'loss': 1.4207, 'grad_norm': 110.1649169921875, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.3813968896865845, 'loss_2': 0.039337158203125, 'loss_3': -15.419747352600098, 'loss_4': 10.119650840759277, 'epoch': 0.09}
{'loss': 1.4068, 'grad_norm': 110.7396011352539, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.3802837133407593, 'loss_2': 0.0264892578125, 'loss_3': -15.491020202636719, 'loss_4': 10.543203353881836, 'epoch': 0.1}
{'loss': 0.9423, 'grad_norm': 84.4699935913086, 'learning_rate': 2.991860465116279e-05, 'loss_1': 0.9058671593666077, 'loss_2': 0.03643798828125, 'loss_3': -15.575904846191406, 'loss_4': 10.234014511108398, 'epoch': 0.1}
{'loss': 0.9545, 'grad_norm': 95.85490417480469, 'learning_rate': 2.991279069767442e-05, 'loss_1': 0.9248482584953308, 'loss_2': 0.029632568359375, 'loss_3': -15.435991287231445, 'loss_4': 9.34444808959961, 'epoch': 0.11}
{'loss': 0.5945, 'grad_norm': 76.3032455444336, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 0.5739353895187378, 'loss_2': 0.0205230712890625, 'loss_3': -15.613492012023926, 'loss_4': 8.15157413482666, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:10,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:10,128 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:33<1:38:06,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:27:13,903 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 09:27:13,904 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20/config.json                                                                               
{'eval_loss': 0.1645200103521347, 'eval_runtime': 3.7738, 'eval_samples_per_second': 271.343, 'eval_steps_per_second': 4.24, 'eval_loss_1': 0.1468360424041748, 'eval_loss_2': 0.017683982849121094, 'eval_loss_3': -17.939382553100586, 'eval_loss_4': 8.691186904907227, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:14,325 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:14,326 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:14,326 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:15,102 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:38<1:38:07,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:27:18,738 >>
{'loss': 0.564, 'grad_norm': 78.13436889648438, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 0.5524051785469055, 'loss_2': 0.0116119384765625, 'loss_3': -15.364936828613281, 'loss_4': 8.378150939941406, 'epoch': 0.12}
{'loss': 0.5025, 'grad_norm': 63.16977310180664, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 0.47702738642692566, 'loss_2': 0.0254364013671875, 'loss_3': -15.182913780212402, 'loss_4': 8.723577499389648, 'epoch': 0.13}
{'loss': 0.3158, 'grad_norm': 44.114654541015625, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.2939337193965912, 'loss_2': 0.021820068359375, 'loss_3': -15.2791748046875, 'loss_4': 8.14197063446045, 'epoch': 0.13}
{'loss': 0.4485, 'grad_norm': 66.73417663574219, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.4351210296154022, 'loss_2': 0.01342010498046875, 'loss_3': -15.107660293579102, 'loss_4': 8.369503021240234, 'epoch': 0.14}
{'loss': 0.3482, 'grad_norm': 57.93960189819336, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.34110304713249207, 'loss_2': 0.007122039794921875, 'loss_3': -15.251219749450684, 'loss_4': 8.132133483886719, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:18,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:18,738 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:42<1:38:07,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:27:22,509 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 09:27:22,510 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25/config.json                                                                               
{'eval_loss': 0.09351523965597153, 'eval_runtime': 3.7697, 'eval_samples_per_second': 271.64, 'eval_steps_per_second': 4.244, 'eval_loss_1': 0.08921714127063751, 'eval_loss_2': 0.004298098385334015, 'eval_loss_3': -17.896297454833984, 'eval_loss_4': 8.312599182128906, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:22,970 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:22,972 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:22,972 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:23,745 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:37:58,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:27:27,364 >>
{'loss': 0.2951, 'grad_norm': 50.03315353393555, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.29384440183639526, 'loss_2': 0.0012235641479492188, 'loss_3': -15.054060935974121, 'loss_4': 8.064824104309082, 'epoch': 0.15}
{'loss': 0.3244, 'grad_norm': 55.21188735961914, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.3207753896713257, 'loss_2': 0.00365447998046875, 'loss_3': -15.277796745300293, 'loss_4': 8.36309814453125, 'epoch': 0.16}
{'loss': 0.2261, 'grad_norm': 37.91388702392578, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.21560785174369812, 'loss_2': 0.01047515869140625, 'loss_3': -15.207000732421875, 'loss_4': 7.838901996612549, 'epoch': 0.16}
{'loss': 0.3292, 'grad_norm': 52.79810333251953, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.31819483637809753, 'loss_2': 0.01097869873046875, 'loss_3': -14.994237899780273, 'loss_4': 7.767727851867676, 'epoch': 0.17}
{'loss': 0.3025, 'grad_norm': 45.37627029418945, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.28375351428985596, 'loss_2': 0.01873779296875, 'loss_3': -15.01625919342041, 'loss_4': 9.2781982421875, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:27,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:27,364 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:50<1:37:58,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:27:31,136 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 09:27:31,138 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30/config.json                                                                               
{'eval_loss': 0.08362584561109543, 'eval_runtime': 3.7708, 'eval_samples_per_second': 271.559, 'eval_steps_per_second': 4.243, 'eval_loss_1': 0.0634189173579216, 'eval_loss_2': 0.020206928253173828, 'eval_loss_3': -18.001623153686523, 'eval_loss_4': 8.899908065795898, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:31,609 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:31,610 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:31,611 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:32,385 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:55<1:37:46,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:27:35,984 >>
{'loss': 0.3219, 'grad_norm': 51.60956573486328, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.30377691984176636, 'loss_2': 0.0181121826171875, 'loss_3': -14.962587356567383, 'loss_4': 9.521142959594727, 'epoch': 0.18}
{'loss': 0.2859, 'grad_norm': 47.11468505859375, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.2729295492172241, 'loss_2': 0.012939453125, 'loss_3': -14.949129104614258, 'loss_4': 8.482760429382324, 'epoch': 0.19}
{'loss': 0.2603, 'grad_norm': 49.13786697387695, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.2568061053752899, 'loss_2': 0.00351715087890625, 'loss_3': -15.047626495361328, 'loss_4': 8.947227478027344, 'epoch': 0.19}
{'loss': 0.1656, 'grad_norm': 31.23419189453125, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.1539667397737503, 'loss_2': 0.01158905029296875, 'loss_3': -14.865213394165039, 'loss_4': 7.692080974578857, 'epoch': 0.2}
{'loss': 0.2554, 'grad_norm': 49.84555435180664, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.2527191638946533, 'loss_2': 0.00263214111328125, 'loss_3': -14.830759048461914, 'loss_4': 8.447007179260254, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:35,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:35,984 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:59<1:37:46,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:27:39,764 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 09:27:39,765 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35/config.json                                                                               
{'eval_loss': 0.05741972476243973, 'eval_runtime': 3.7778, 'eval_samples_per_second': 271.055, 'eval_steps_per_second': 4.235, 'eval_loss_1': 0.05395076423883438, 'eval_loss_2': 0.0034689605236053467, 'eval_loss_3': -17.999528884887695, 'eval_loss_4': 7.456076622009277, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:40,215 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:40,217 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:40,217 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:40,980 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:04<1:37:32,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:27:44,582 >>
{'loss': 0.2669, 'grad_norm': 42.17357635498047, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.25772207975387573, 'loss_2': 0.0091705322265625, 'loss_3': -14.626744270324707, 'loss_4': 7.7275800704956055, 'epoch': 0.21}
{'loss': 0.1535, 'grad_norm': 32.56307601928711, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.13983789086341858, 'loss_2': 0.01364898681640625, 'loss_3': -14.792182922363281, 'loss_4': 7.261894226074219, 'epoch': 0.22}
{'loss': 0.2208, 'grad_norm': 44.56473159790039, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.20618709921836853, 'loss_2': 0.01464080810546875, 'loss_3': -14.758840560913086, 'loss_4': 7.3797149658203125, 'epoch': 0.22}
{'loss': 0.1808, 'grad_norm': 49.261436462402344, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.17004604637622833, 'loss_2': 0.01071929931640625, 'loss_3': -15.015928268432617, 'loss_4': 6.443207740783691, 'epoch': 0.23}
{'loss': 0.208, 'grad_norm': 42.49253845214844, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.17951972782611847, 'loss_2': 0.0285186767578125, 'loss_3': -15.078582763671875, 'loss_4': 6.847944736480713, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:44,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:44,582 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:11<1:29:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:27:51,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06399522721767426, 'eval_runtime': 3.7677, 'eval_samples_per_second': 271.787, 'eval_steps_per_second': 4.247, 'eval_loss_1': 0.05001949518918991, 'eval_loss_2': 0.013975739479064941, 'eval_loss_3': -17.9952392578125, 'eval_loss_4': 6.941859722137451, 'epoch': 0.23}
{'loss': 0.1633, 'grad_norm': 37.51400375366211, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.1587853580713272, 'loss_2': 0.00452423095703125, 'loss_3': -14.79600715637207, 'loss_4': 6.689373016357422, 'epoch': 0.24}
{'loss': 0.1631, 'grad_norm': 30.916507720947266, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.14593861997127533, 'loss_2': 0.0171661376953125, 'loss_3': -14.885140419006348, 'loss_4': 5.652347087860107, 'epoch': 0.24}
{'loss': 0.1503, 'grad_norm': 32.999755859375, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.1386570781469345, 'loss_2': 0.01165771484375, 'loss_3': -14.860118865966797, 'loss_4': 6.4247026443481445, 'epoch': 0.25}
{'loss': 0.3133, 'grad_norm': 38.83892822265625, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.30375486612319946, 'loss_2': 0.0095367431640625, 'loss_3': -14.981239318847656, 'loss_4': 7.480134963989258, 'epoch': 0.26}
{'loss': 0.1642, 'grad_norm': 32.57637023925781, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.1574963927268982, 'loss_2': 0.006702423095703125, 'loss_3': -14.833444595336914, 'loss_4': 7.170624732971191, 'epoch': 0.26}
[INFO|trainer.py:4228] 2025-01-21 09:27:51,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:51,879 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:15<1:29:32,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 09:27:55,668 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 09:27:55,669 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45/config.json                                                                               
{'eval_loss': 0.047343723475933075, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.358, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.04408552870154381, 'eval_loss_2': 0.0032581984996795654, 'eval_loss_3': -18.067340850830078, 'eval_loss_4': 7.799276351928711, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:56,117 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:56,119 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:56,119 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:56,882 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-35] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:20<1:36:16,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:28:00,499 >>
{'loss': 0.1552, 'grad_norm': 29.970876693725586, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.15167684853076935, 'loss_2': 0.00350189208984375, 'loss_3': -14.872995376586914, 'loss_4': 7.3103718757629395, 'epoch': 0.27}
{'loss': 0.1587, 'grad_norm': 37.15517807006836, 'learning_rate': 2.975e-05, 'loss_1': 0.1576157957315445, 'loss_2': 0.0010423660278320312, 'loss_3': -14.899002075195312, 'loss_4': 7.108436584472656, 'epoch': 0.27}
{'loss': 0.2242, 'grad_norm': 41.38906478881836, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.21208502352237701, 'loss_2': 0.012115478515625, 'loss_3': -14.80572509765625, 'loss_4': 7.730032920837402, 'epoch': 0.28}
{'loss': 0.2335, 'grad_norm': 41.95801544189453, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.2281259000301361, 'loss_2': 0.00537872314453125, 'loss_3': -15.080680847167969, 'loss_4': 8.234822273254395, 'epoch': 0.28}
{'loss': 0.1454, 'grad_norm': 35.497581481933594, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.14329370856285095, 'loss_2': 0.00213623046875, 'loss_3': -14.839561462402344, 'loss_4': 6.796487808227539, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:00,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:00,499 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:27<1:29:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:28:07,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.052358873188495636, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.911, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.041999585926532745, 'eval_loss_2': 0.01035928726196289, 'eval_loss_3': -18.08285140991211, 'eval_loss_4': 7.47473669052124, 'epoch': 0.29}
{'loss': 0.215, 'grad_norm': 40.86775588989258, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.2039046734571457, 'loss_2': 0.011077880859375, 'loss_3': -15.203705787658691, 'loss_4': 7.059717655181885, 'epoch': 0.3}
{'loss': 0.1415, 'grad_norm': 26.179706573486328, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.12089448422193527, 'loss_2': 0.0206146240234375, 'loss_3': -15.061731338500977, 'loss_4': 7.519052505493164, 'epoch': 0.3}
{'loss': 0.1468, 'grad_norm': 56.47769546508789, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.1459476798772812, 'loss_2': 0.0008521080017089844, 'loss_3': -15.095170974731445, 'loss_4': 7.662613868713379, 'epoch': 0.31}
{'loss': 0.1117, 'grad_norm': 23.01738929748535, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.10782483965158463, 'loss_2': 0.003856658935546875, 'loss_3': -15.118325233459473, 'loss_4': 7.429903984069824, 'epoch': 0.31}
{'loss': 0.1928, 'grad_norm': 33.946189880371094, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.18155662715435028, 'loss_2': 0.01129150390625, 'loss_3': -15.157894134521484, 'loss_4': 6.662703037261963, 'epoch': 0.32}
[INFO|trainer.py:4228] 2025-01-21 09:28:07,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:07,831 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:31<1:29:29,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 09:28:11,641 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55
[INFO|configuration_utils.py:420] 2025-01-21 09:28:11,643 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55/config.json                                                                               
{'eval_loss': 0.045336395502090454, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.040170468389987946, 'eval_loss_2': 0.0051659345626831055, 'eval_loss_3': -18.097070693969727, 'eval_loss_4': 7.299750804901123, 'epoch': 0.32}
[INFO|modeling_utils.py:2988] 2025-01-21 09:28:12,093 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:28:12,095 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:28:12,095 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:28:12,859 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-45] due to args.save_total_limit
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:36<1:36:18,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:28:16,474 >>
{'loss': 0.1917, 'grad_norm': 39.53584289550781, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.18830566108226776, 'loss_2': 0.0034027099609375, 'loss_3': -15.3356351852417, 'loss_4': 6.964481353759766, 'epoch': 0.33}
{'loss': 0.1856, 'grad_norm': 38.74430847167969, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.18160274624824524, 'loss_2': 0.00397491455078125, 'loss_3': -15.31186580657959, 'loss_4': 6.970645427703857, 'epoch': 0.33}
{'loss': 0.1484, 'grad_norm': 29.152692794799805, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.13844384253025055, 'loss_2': 0.00994873046875, 'loss_3': -15.219797134399414, 'loss_4': 7.37721061706543, 'epoch': 0.34}
{'loss': 0.241, 'grad_norm': 41.48086166381836, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.23508144915103912, 'loss_2': 0.005931854248046875, 'loss_3': -14.909116744995117, 'loss_4': 6.637941360473633, 'epoch': 0.34}
{'loss': 0.1828, 'grad_norm': 36.36146926879883, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.1720876693725586, 'loss_2': 0.0107269287109375, 'loss_3': -15.162332534790039, 'loss_4': 6.691692352294922, 'epoch': 0.35}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:16,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:16,474 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:40<1:36:18,  1.13s/it][INFO|trainer.py:3910] 2025-01-21 09:28:20,268 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 09:28:20,270 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60/config.json                                                                               
{'eval_loss': 0.04242679104208946, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.962, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.038594022393226624, 'eval_loss_2': 0.0038327649235725403, 'eval_loss_3': -18.097942352294922, 'eval_loss_4': 6.690057754516602, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 09:28:20,733 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:28:20,735 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:28:20,735 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:28:21,541 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-55] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:44<1:37:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:28:25,166 >>
{'loss': 0.229, 'grad_norm': 44.78507995605469, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.22814875841140747, 'loss_2': 0.0008516311645507812, 'loss_3': -15.071174621582031, 'loss_4': 6.534000396728516, 'epoch': 0.35}
{'loss': 0.1327, 'grad_norm': 25.3177433013916, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.12382657825946808, 'loss_2': 0.00890350341796875, 'loss_3': -15.09320068359375, 'loss_4': 6.217458248138428, 'epoch': 0.36}
{'loss': 0.1503, 'grad_norm': 25.41200828552246, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.14966189861297607, 'loss_2': 0.0005984306335449219, 'loss_3': -15.125123977661133, 'loss_4': 6.19774055480957, 'epoch': 0.37}
{'loss': 0.1776, 'grad_norm': 31.395471572875977, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.17681322991847992, 'loss_2': 0.0007433891296386719, 'loss_3': -15.054475784301758, 'loss_4': 6.826338768005371, 'epoch': 0.37}
{'loss': 0.1988, 'grad_norm': 45.43635177612305, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.19842270016670227, 'loss_2': 0.00035762786865234375, 'loss_3': -15.046072959899902, 'loss_4': 6.70893669128418, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:25,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:25,166 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:52<1:29:34,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:28:32,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0455293245613575, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.981, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.03907259553670883, 'eval_loss_2': 0.006456732749938965, 'eval_loss_3': -18.128541946411133, 'eval_loss_4': 6.467522621154785, 'epoch': 0.38}
{'loss': 0.1112, 'grad_norm': 22.530807495117188, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.11039214581251144, 'loss_2': 0.0007891654968261719, 'loss_3': -15.338887214660645, 'loss_4': 6.652061462402344, 'epoch': 0.38}
{'loss': 0.1646, 'grad_norm': 31.012287139892578, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.15771761536598206, 'loss_2': 0.00689697265625, 'loss_3': -15.313729286193848, 'loss_4': 6.976202011108398, 'epoch': 0.39}
{'loss': 0.1771, 'grad_norm': 33.68552780151367, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.17197097837924957, 'loss_2': 0.005096435546875, 'loss_3': -15.347038269042969, 'loss_4': 6.921311378479004, 'epoch': 0.4}
{'loss': 0.1605, 'grad_norm': 40.13026809692383, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.1598038375377655, 'loss_2': 0.0007009506225585938, 'loss_3': -15.182372093200684, 'loss_4': 7.763912677764893, 'epoch': 0.4}
{'loss': 0.1687, 'grad_norm': 31.053756713867188, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.16627392172813416, 'loss_2': 0.00238800048828125, 'loss_3': -15.185857772827148, 'loss_4': 6.919294357299805, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 09:28:32,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:32,499 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:56<1:29:34,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 09:28:36,293 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70
[INFO|configuration_utils.py:420] 2025-01-21 09:28:36,295 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70/config.json                                                                               
{'eval_loss': 0.04043198376893997, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.974, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.032060157507658005, 'eval_loss_2': 0.008371829986572266, 'eval_loss_3': -18.15451431274414, 'eval_loss_4': 6.762738227844238, 'epoch': 0.41}
[INFO|modeling_utils.py:2988] 2025-01-21 09:28:36,750 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:28:36,752 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:28:36,752 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:28:37,517 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-60] due to args.save_total_limit
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:00<1:36:10,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:28:41,156 >>
{'loss': 0.1402, 'grad_norm': 31.22652816772461, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.13102863729000092, 'loss_2': 0.00920867919921875, 'loss_3': -15.101105690002441, 'loss_4': 6.919747352600098, 'epoch': 0.41}
{'loss': 0.1732, 'grad_norm': 38.09263229370117, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.1619647741317749, 'loss_2': 0.0112762451171875, 'loss_3': -15.06750202178955, 'loss_4': 6.2637529373168945, 'epoch': 0.42}
{'loss': 0.1272, 'grad_norm': 31.718868255615234, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.11157679557800293, 'loss_2': 0.0156402587890625, 'loss_3': -15.212739944458008, 'loss_4': 7.043824195861816, 'epoch': 0.42}
{'loss': 0.1054, 'grad_norm': 17.77132797241211, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.07977832108736038, 'loss_2': 0.025665283203125, 'loss_3': -15.126667976379395, 'loss_4': 5.542919635772705, 'epoch': 0.43}
{'loss': 0.1057, 'grad_norm': 21.743144989013672, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.09588354825973511, 'loss_2': 0.00982666015625, 'loss_3': -15.27696418762207, 'loss_4': 6.293516635894775, 'epoch': 0.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:41,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:41,156 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:04<1:36:10,  1.13s/it][INFO|trainer.py:3910] 2025-01-21 09:28:44,963 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75
[INFO|configuration_utils.py:420] 2025-01-21 09:28:44,964 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75/config.json                                                                               
{'eval_loss': 0.028797950595617294, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.021778099238872528, 'eval_loss_2': 0.007019847631454468, 'eval_loss_3': -18.146133422851562, 'eval_loss_4': 6.2293171882629395, 'epoch': 0.44}
[INFO|modeling_utils.py:2988] 2025-01-21 09:28:45,436 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:28:45,438 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:28:45,438 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:28:46,228 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-70] due to args.save_total_limit
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:37:38,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:28:49,870 >>
{'loss': 0.1131, 'grad_norm': 27.567262649536133, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.09870848804712296, 'loss_2': 0.0143890380859375, 'loss_3': -15.059521675109863, 'loss_4': 7.420283317565918, 'epoch': 0.44}
{'loss': 0.0618, 'grad_norm': 14.096135139465332, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.055806756019592285, 'loss_2': 0.0060272216796875, 'loss_3': -15.192947387695312, 'loss_4': 5.100903511047363, 'epoch': 0.45}
{'loss': 0.1215, 'grad_norm': 29.461925506591797, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.11672011017799377, 'loss_2': 0.00473785400390625, 'loss_3': -15.34051513671875, 'loss_4': 6.065617561340332, 'epoch': 0.45}
{'loss': 0.1282, 'grad_norm': 32.58259201049805, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.12357242405414581, 'loss_2': 0.00458526611328125, 'loss_3': -15.274881362915039, 'loss_4': 6.453858375549316, 'epoch': 0.46}
{'loss': 0.1354, 'grad_norm': 29.52924156188965, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.1352115273475647, 'loss_2': 0.0001900196075439453, 'loss_3': -14.899036407470703, 'loss_4': 5.124781608581543, 'epoch': 0.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:49,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:49,871 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:17<1:29:30,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:28:57,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03319390118122101, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.672, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.023361042141914368, 'eval_loss_2': 0.00983285903930664, 'eval_loss_3': -18.09394645690918, 'eval_loss_4': 5.226226806640625, 'epoch': 0.47}
{'loss': 0.1217, 'grad_norm': 26.110065460205078, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.1133274957537651, 'loss_2': 0.008331298828125, 'loss_3': -15.194931983947754, 'loss_4': 5.660953044891357, 'epoch': 0.47}
{'loss': 0.0985, 'grad_norm': 24.81597328186035, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.09760615229606628, 'loss_2': 0.0008449554443359375, 'loss_3': -15.099010467529297, 'loss_4': 4.527024745941162, 'epoch': 0.48}
{'loss': 0.1185, 'grad_norm': 29.58355712890625, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.10639651119709015, 'loss_2': 0.0120697021484375, 'loss_3': -15.217517852783203, 'loss_4': 4.689320087432861, 'epoch': 0.48}
{'loss': 0.1372, 'grad_norm': 29.33235740661621, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.12919959425926208, 'loss_2': 0.00795745849609375, 'loss_3': -15.124187469482422, 'loss_4': 4.444214344024658, 'epoch': 0.49}
{'loss': 0.0989, 'grad_norm': 23.40970802307129, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.09715700149536133, 'loss_2': 0.0017242431640625, 'loss_3': -15.296911239624023, 'loss_4': 4.875430583953857, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 09:28:57,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:57,221 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:27:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:04,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032365016639232635, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.027379341423511505, 'eval_loss_2': 0.00498567521572113, 'eval_loss_3': -18.091909408569336, 'eval_loss_4': 4.428802490234375, 'epoch': 0.49}
{'loss': 0.1159, 'grad_norm': 30.5445556640625, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.11241234093904495, 'loss_2': 0.003459930419921875, 'loss_3': -15.063498497009277, 'loss_4': 5.047042369842529, 'epoch': 0.5}
{'loss': 0.1031, 'grad_norm': 24.18433380126953, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.10108962655067444, 'loss_2': 0.0020465850830078125, 'loss_3': -15.218149185180664, 'loss_4': 4.522830963134766, 'epoch': 0.51}
{'loss': 0.1405, 'grad_norm': 34.333038330078125, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.13962328433990479, 'loss_2': 0.0008730888366699219, 'loss_3': -15.062957763671875, 'loss_4': 4.266483783721924, 'epoch': 0.51}
{'loss': 0.1652, 'grad_norm': 34.96121597290039, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.1460951715707779, 'loss_2': 0.0190887451171875, 'loss_3': -15.292119979858398, 'loss_4': 4.5146307945251465, 'epoch': 0.52}
{'loss': 0.0615, 'grad_norm': 15.408394813537598, 'learning_rate': 2.95e-05, 'loss_1': 0.057527799159288406, 'loss_2': 0.0040130615234375, 'loss_3': -15.119935989379883, 'loss_4': 4.20408821105957, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 09:29:04,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:04,556 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:31<1:27:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:11,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03529072552919388, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.305, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.02895249053835869, 'eval_loss_2': 0.006338238716125488, 'eval_loss_3': -18.121368408203125, 'eval_loss_4': 4.289239406585693, 'epoch': 0.52}
{'loss': 0.1279, 'grad_norm': 37.537689208984375, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.12685102224349976, 'loss_2': 0.0010585784912109375, 'loss_3': -15.2745361328125, 'loss_4': 4.7527666091918945, 'epoch': 0.53}
{'loss': 0.1067, 'grad_norm': 27.02149772644043, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.1005316898226738, 'loss_2': 0.006145477294921875, 'loss_3': -15.279274940490723, 'loss_4': 4.081748008728027, 'epoch': 0.53}
{'loss': 0.1322, 'grad_norm': 30.915014266967773, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.12807397544384003, 'loss_2': 0.004161834716796875, 'loss_3': -15.093330383300781, 'loss_4': 3.714360237121582, 'epoch': 0.54}
{'loss': 0.1195, 'grad_norm': 26.794410705566406, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.11686092615127563, 'loss_2': 0.002590179443359375, 'loss_3': -15.248924255371094, 'loss_4': 3.3009424209594727, 'epoch': 0.55}
{'loss': 0.1613, 'grad_norm': 41.62403106689453, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.1551143229007721, 'loss_2': 0.00616455078125, 'loss_3': -15.068327903747559, 'loss_4': 3.2426223754882812, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 09:29:11,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:11,895 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:39<1:27:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:19,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0345061793923378, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.77, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.030403269454836845, 'eval_loss_2': 0.0041029080748558044, 'eval_loss_3': -18.12258529663086, 'eval_loss_4': 3.811063528060913, 'epoch': 0.55}
{'loss': 0.1252, 'grad_norm': 26.34929847717285, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.11581826210021973, 'loss_2': 0.00940704345703125, 'loss_3': -15.074146270751953, 'loss_4': 3.407723903656006, 'epoch': 0.56}
{'loss': 0.1298, 'grad_norm': 26.553604125976562, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.12489127367734909, 'loss_2': 0.0048828125, 'loss_3': -15.050540924072266, 'loss_4': 2.920348644256592, 'epoch': 0.56}
{'loss': 0.1441, 'grad_norm': 25.725460052490234, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.14147114753723145, 'loss_2': 0.002666473388671875, 'loss_3': -15.110221862792969, 'loss_4': 3.4832680225372314, 'epoch': 0.57}
{'loss': 0.0966, 'grad_norm': 28.40882110595703, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.09632907062768936, 'loss_2': 0.00029778480529785156, 'loss_3': -15.057655334472656, 'loss_4': 4.248453140258789, 'epoch': 0.58}
{'loss': 0.1417, 'grad_norm': 34.67918395996094, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.13972990214824677, 'loss_2': 0.001979827880859375, 'loss_3': -14.799392700195312, 'loss_4': 4.393540859222412, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 09:29:19,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:19,233 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:46<1:27:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:26,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03727062791585922, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.641, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02657332457602024, 'eval_loss_2': 0.01069730520248413, 'eval_loss_3': -18.1174373626709, 'eval_loss_4': 4.080729961395264, 'epoch': 0.58}
{'loss': 0.0873, 'grad_norm': 24.445480346679688, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.08414395898580551, 'loss_2': 0.003147125244140625, 'loss_3': -15.142396926879883, 'loss_4': 3.963191509246826, 'epoch': 0.59}
{'loss': 0.188, 'grad_norm': 47.02629089355469, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.17971587181091309, 'loss_2': 0.00830078125, 'loss_3': -15.044052124023438, 'loss_4': 3.997880458831787, 'epoch': 0.59}
{'loss': 0.0975, 'grad_norm': 23.056867599487305, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.0944824069738388, 'loss_2': 0.0030117034912109375, 'loss_3': -15.013673782348633, 'loss_4': 5.106176376342773, 'epoch': 0.6}
{'loss': 0.0865, 'grad_norm': 18.1049861907959, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.0809045359492302, 'loss_2': 0.005634307861328125, 'loss_3': -15.341540336608887, 'loss_4': 5.241759300231934, 'epoch': 0.6}
{'loss': 0.0637, 'grad_norm': 16.361896514892578, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.0626417025923729, 'loss_2': 0.001010894775390625, 'loss_3': -15.223225593566895, 'loss_4': 4.737083435058594, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 09:29:26,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:26,587 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:53<1:27:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:33,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02895504981279373, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.517, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.024407515302300453, 'eval_loss_2': 0.004547536373138428, 'eval_loss_3': -18.094520568847656, 'eval_loss_4': 4.355900287628174, 'epoch': 0.61}
{'loss': 0.0772, 'grad_norm': 21.181058883666992, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.07287577539682388, 'loss_2': 0.00431060791015625, 'loss_3': -15.056051254272461, 'loss_4': 4.389399528503418, 'epoch': 0.62}
{'loss': 0.1418, 'grad_norm': 31.648183822631836, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.13337571918964386, 'loss_2': 0.0084075927734375, 'loss_3': -14.903928756713867, 'loss_4': 4.505724906921387, 'epoch': 0.62}
{'loss': 0.0853, 'grad_norm': 21.79975128173828, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.07931538671255112, 'loss_2': 0.006000518798828125, 'loss_3': -15.043865203857422, 'loss_4': 4.921655654907227, 'epoch': 0.63}
{'loss': 0.1276, 'grad_norm': 43.346561431884766, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.11453936249017715, 'loss_2': 0.0131072998046875, 'loss_3': -14.99976921081543, 'loss_4': 4.388754844665527, 'epoch': 0.63}
{'loss': 0.0935, 'grad_norm': 19.543962478637695, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.08248251676559448, 'loss_2': 0.0110321044921875, 'loss_3': -15.09793472290039, 'loss_4': 5.92595100402832, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 09:29:33,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:33,949 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:57<1:27:31,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:29:37,743 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110
[INFO|configuration_utils.py:420] 2025-01-21 09:29:37,745 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110/config.json                                                                              
{'eval_loss': 0.022817760705947876, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.989, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.018517479300498962, 'eval_loss_2': 0.004300281405448914, 'eval_loss_3': -18.167613983154297, 'eval_loss_4': 6.112908363342285, 'epoch': 0.64}
[INFO|modeling_utils.py:2988] 2025-01-21 09:29:38,204 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:29:38,205 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:29:38,206 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:29:38,980 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-75] due to args.save_total_limit
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:02<1:35:18,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:29:42,611 >>
{'loss': 0.1718, 'grad_norm': 38.9422492980957, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.1708851158618927, 'loss_2': 0.0009469985961914062, 'loss_3': -15.122249603271484, 'loss_4': 6.425362586975098, 'epoch': 0.65}
{'loss': 0.156, 'grad_norm': 34.17266082763672, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.15222865343093872, 'loss_2': 0.00372314453125, 'loss_3': -14.886588096618652, 'loss_4': 7.152824401855469, 'epoch': 0.65}
{'loss': 0.0818, 'grad_norm': 17.767940521240234, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.07577434927225113, 'loss_2': 0.0059967041015625, 'loss_3': -15.19178581237793, 'loss_4': 6.6356987953186035, 'epoch': 0.66}
{'loss': 0.0732, 'grad_norm': 17.682449340820312, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.06903626024723053, 'loss_2': 0.004119873046875, 'loss_3': -15.237756729125977, 'loss_4': 7.41992712020874, 'epoch': 0.66}
{'loss': 0.0988, 'grad_norm': 25.495847702026367, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.09249261021614075, 'loss_2': 0.006351470947265625, 'loss_3': -15.112028121948242, 'loss_4': 7.233148574829102, 'epoch': 0.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:29:42,611 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:42,611 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:09<1:28:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:29:49,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023081012070178986, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.512, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.019451508298516273, 'eval_loss_2': 0.0036295056343078613, 'eval_loss_3': -18.203819274902344, 'eval_loss_4': 7.399426460266113, 'epoch': 0.67}
{'loss': 0.1773, 'grad_norm': 38.864410400390625, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.16530859470367432, 'loss_2': 0.0120086669921875, 'loss_3': -15.001073837280273, 'loss_4': 8.316160202026367, 'epoch': 0.67}
{'loss': 0.1345, 'grad_norm': 27.929224014282227, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.1324707567691803, 'loss_2': 0.00205230712890625, 'loss_3': -15.20543098449707, 'loss_4': 6.859288215637207, 'epoch': 0.68}
{'loss': 0.0829, 'grad_norm': 23.486831665039062, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.07672291249036789, 'loss_2': 0.006175994873046875, 'loss_3': -15.380831718444824, 'loss_4': 7.9206671714782715, 'epoch': 0.69}
{'loss': 0.1446, 'grad_norm': 35.17437744140625, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.1430695354938507, 'loss_2': 0.001544952392578125, 'loss_3': -15.071372032165527, 'loss_4': 7.732147216796875, 'epoch': 0.69}
{'loss': 0.0936, 'grad_norm': 128.2933349609375, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.08675552159547806, 'loss_2': 0.00679779052734375, 'loss_3': -15.009817123413086, 'loss_4': 6.471688270568848, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 09:29:49,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:49,958 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:17<1:27:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:57,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025598332285881042, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.696, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.018899312242865562, 'eval_loss_2': 0.006699018180370331, 'eval_loss_3': -18.190738677978516, 'eval_loss_4': 6.214714050292969, 'epoch': 0.7}
{'loss': 0.0929, 'grad_norm': 26.644956588745117, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.08241771161556244, 'loss_2': 0.01049041748046875, 'loss_3': -15.115235328674316, 'loss_4': 5.803884029388428, 'epoch': 0.7}
{'loss': 0.1182, 'grad_norm': 26.8122615814209, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.11401288211345673, 'loss_2': 0.0042266845703125, 'loss_3': -15.051904678344727, 'loss_4': 5.808931827545166, 'epoch': 0.71}
{'loss': 0.1056, 'grad_norm': 26.16199493408203, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.10236556828022003, 'loss_2': 0.0032196044921875, 'loss_3': -15.304784774780273, 'loss_4': 5.733532905578613, 'epoch': 0.72}
{'loss': 0.0818, 'grad_norm': 21.41938591003418, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.0744539126753807, 'loss_2': 0.007335662841796875, 'loss_3': -15.253326416015625, 'loss_4': 4.3903093338012695, 'epoch': 0.72}
{'loss': 0.0968, 'grad_norm': 22.778825759887695, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.08803404867649078, 'loss_2': 0.0087890625, 'loss_3': -15.24570083618164, 'loss_4': 5.459067344665527, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 09:29:57,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:57,317 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:24<1:27:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:04,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02591731585562229, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.021791992709040642, 'eval_loss_2': 0.00412532314658165, 'eval_loss_3': -18.137720108032227, 'eval_loss_4': 5.14997673034668, 'epoch': 0.73}
{'loss': 0.0921, 'grad_norm': 17.8371639251709, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.08000720292329788, 'loss_2': 0.012115478515625, 'loss_3': -15.368637084960938, 'loss_4': 4.881769180297852, 'epoch': 0.73}
{'loss': 0.0865, 'grad_norm': 25.798988342285156, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.08603905886411667, 'loss_2': 0.00047588348388671875, 'loss_3': -15.041400909423828, 'loss_4': 4.649504661560059, 'epoch': 0.74}
{'loss': 0.1365, 'grad_norm': 25.085586547851562, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.13257695734500885, 'loss_2': 0.003955841064453125, 'loss_3': -15.265048027038574, 'loss_4': 4.581669807434082, 'epoch': 0.74}
{'loss': 0.1035, 'grad_norm': 23.021284103393555, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.09510623663663864, 'loss_2': 0.0084228515625, 'loss_3': -15.210189819335938, 'loss_4': 4.266206741333008, 'epoch': 0.75}
{'loss': 0.1039, 'grad_norm': 21.576147079467773, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.09140595048666, 'loss_2': 0.012542724609375, 'loss_3': -15.310218811035156, 'loss_4': 4.161345481872559, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 09:30:04,657 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:04,657 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:31<1:27:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:12,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03645658120512962, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.681, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.02842998318374157, 'eval_loss_2': 0.008026599884033203, 'eval_loss_3': -18.06970977783203, 'eval_loss_4': 3.9940645694732666, 'epoch': 0.76}
{'loss': 0.0937, 'grad_norm': 21.977767944335938, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.08860888332128525, 'loss_2': 0.0050506591796875, 'loss_3': -15.109941482543945, 'loss_4': 3.847874164581299, 'epoch': 0.76}
{'loss': 0.0722, 'grad_norm': 16.650144577026367, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.06478122621774673, 'loss_2': 0.00738525390625, 'loss_3': -15.006086349487305, 'loss_4': 3.7350871562957764, 'epoch': 0.77}
{'loss': 0.1542, 'grad_norm': 30.767261505126953, 'learning_rate': 2.925e-05, 'loss_1': 0.14435267448425293, 'loss_2': 0.0098114013671875, 'loss_3': -14.895862579345703, 'loss_4': 3.173490524291992, 'epoch': 0.77}
{'loss': 0.0766, 'grad_norm': 17.507497787475586, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.0729898139834404, 'loss_2': 0.00360107421875, 'loss_3': -15.152023315429688, 'loss_4': 3.2490673065185547, 'epoch': 0.78}
{'loss': 0.0897, 'grad_norm': 21.87812042236328, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.07942155748605728, 'loss_2': 0.0102386474609375, 'loss_3': -15.153050422668457, 'loss_4': 3.5888938903808594, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 09:30:12,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:12,016 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:39<1:26:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:19,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034824199974536896, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.615, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.03005613014101982, 'eval_loss_2': 0.004768073558807373, 'eval_loss_3': -18.074350357055664, 'eval_loss_4': 3.568673610687256, 'epoch': 0.78}
{'loss': 0.0793, 'grad_norm': 15.65685749053955, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.07124760001897812, 'loss_2': 0.0080108642578125, 'loss_3': -15.281660079956055, 'loss_4': 3.6788549423217773, 'epoch': 0.79}
{'loss': 0.1044, 'grad_norm': 20.64463233947754, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.09847220033407211, 'loss_2': 0.0059051513671875, 'loss_3': -15.049287796020508, 'loss_4': 3.276561737060547, 'epoch': 0.8}
{'loss': 0.1294, 'grad_norm': 28.273052215576172, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.12271839380264282, 'loss_2': 0.00664520263671875, 'loss_3': -15.042499542236328, 'loss_4': 3.18679141998291, 'epoch': 0.8}
{'loss': 0.0761, 'grad_norm': 14.879231452941895, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.06566530466079712, 'loss_2': 0.0104827880859375, 'loss_3': -15.134174346923828, 'loss_4': 2.8540802001953125, 'epoch': 0.81}
{'loss': 0.0589, 'grad_norm': 15.275975227355957, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.05181567743420601, 'loss_2': 0.0071258544921875, 'loss_3': -14.926687240600586, 'loss_4': 3.384274482727051, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 09:30:19,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:19,361 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:46<1:26:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:26,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03670017421245575, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.030249137431383133, 'eval_loss_2': 0.006451040506362915, 'eval_loss_3': -18.042633056640625, 'eval_loss_4': 3.3821864128112793, 'epoch': 0.81}
{'loss': 0.067, 'grad_norm': 22.221338272094727, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.06440331786870956, 'loss_2': 0.00260162353515625, 'loss_3': -15.020881652832031, 'loss_4': 2.449129104614258, 'epoch': 0.82}
{'loss': 0.0679, 'grad_norm': 19.7454891204834, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.06529580056667328, 'loss_2': 0.0026302337646484375, 'loss_3': -15.175291061401367, 'loss_4': 3.7604377269744873, 'epoch': 0.83}
{'loss': 0.0987, 'grad_norm': 29.303176879882812, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.09704338014125824, 'loss_2': 0.001628875732421875, 'loss_3': -15.001920700073242, 'loss_4': 3.219249725341797, 'epoch': 0.83}
{'loss': 0.0648, 'grad_norm': 17.336881637573242, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.06362839043140411, 'loss_2': 0.0012140274047851562, 'loss_3': -15.136096000671387, 'loss_4': 3.1875884532928467, 'epoch': 0.84}
{'loss': 0.091, 'grad_norm': 30.411922454833984, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.08782125264406204, 'loss_2': 0.0031681060791015625, 'loss_3': -14.933454513549805, 'loss_4': 4.0096540451049805, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 09:30:26,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:26,709 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:53<1:26:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:34,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029698744416236877, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.718, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.023359138518571854, 'eval_loss_2': 0.006339605897665024, 'eval_loss_3': -18.05858039855957, 'eval_loss_4': 3.7969229221343994, 'epoch': 0.84}
{'loss': 0.0775, 'grad_norm': 20.731327056884766, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.07534532994031906, 'loss_2': 0.00218963623046875, 'loss_3': -15.253438949584961, 'loss_4': 3.8304638862609863, 'epoch': 0.85}
{'loss': 0.0895, 'grad_norm': 22.140228271484375, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.08168793469667435, 'loss_2': 0.0077667236328125, 'loss_3': -14.949564933776855, 'loss_4': 4.658280372619629, 'epoch': 0.85}
{'loss': 0.0721, 'grad_norm': 17.48407745361328, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.06895247846841812, 'loss_2': 0.0031890869140625, 'loss_3': -15.355718612670898, 'loss_4': 4.247226238250732, 'epoch': 0.86}
{'loss': 0.0612, 'grad_norm': 18.046321868896484, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.055621951818466187, 'loss_2': 0.005615234375, 'loss_3': -15.095877647399902, 'loss_4': 4.423741340637207, 'epoch': 0.87}
{'loss': 0.0781, 'grad_norm': 22.22342300415039, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.07504184544086456, 'loss_2': 0.0030384063720703125, 'loss_3': -14.980624198913574, 'loss_4': 4.628841400146484, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 09:30:34,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:34,057 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:01<1:26:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:41,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024636130779981613, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.608, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019908566027879715, 'eval_loss_2': 0.004727564752101898, 'eval_loss_3': -18.07100486755371, 'eval_loss_4': 4.275057315826416, 'epoch': 0.87}
{'loss': 0.0552, 'grad_norm': 13.866228103637695, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.046710822731256485, 'loss_2': 0.00850677490234375, 'loss_3': -15.140987396240234, 'loss_4': 4.3193464279174805, 'epoch': 0.88}
{'loss': 0.0825, 'grad_norm': 19.494834899902344, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.0796704888343811, 'loss_2': 0.0028057098388671875, 'loss_3': -15.142586708068848, 'loss_4': 4.17573356628418, 'epoch': 0.88}
{'loss': 0.132, 'grad_norm': 28.272357940673828, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.13102629780769348, 'loss_2': 0.000934600830078125, 'loss_3': -15.02406120300293, 'loss_4': 3.571105480194092, 'epoch': 0.89}
{'loss': 0.1532, 'grad_norm': 44.689579010009766, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.14217783510684967, 'loss_2': 0.01102447509765625, 'loss_3': -14.96847152709961, 'loss_4': 4.983269691467285, 'epoch': 0.9}
{'loss': 0.0843, 'grad_norm': 18.710893630981445, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.07620912045240402, 'loss_2': 0.0081024169921875, 'loss_3': -15.254079818725586, 'loss_4': 5.452739715576172, 'epoch': 0.9}
[INFO|trainer.py:4228] 2025-01-21 09:30:41,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:41,398 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:08<1:26:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:48,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02326202020049095, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.737, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.017367955297231674, 'eval_loss_2': 0.005894064903259277, 'eval_loss_3': -18.173091888427734, 'eval_loss_4': 4.85157585144043, 'epoch': 0.9}
{'loss': 0.0974, 'grad_norm': 23.86676597595215, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.0970858633518219, 'loss_2': 0.0003020763397216797, 'loss_3': -15.145011901855469, 'loss_4': 4.209583282470703, 'epoch': 0.91}
{'loss': 0.0935, 'grad_norm': 25.158058166503906, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.08294831216335297, 'loss_2': 0.01055908203125, 'loss_3': -15.383846282958984, 'loss_4': 6.283042907714844, 'epoch': 0.91}
{'loss': 0.0868, 'grad_norm': 21.246402740478516, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.08369340747594833, 'loss_2': 0.003101348876953125, 'loss_3': -15.233579635620117, 'loss_4': 5.858758926391602, 'epoch': 0.92}
{'loss': 0.101, 'grad_norm': 22.124380111694336, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.09437505900859833, 'loss_2': 0.006622314453125, 'loss_3': -15.225133895874023, 'loss_4': 5.9915971755981445, 'epoch': 0.92}
{'loss': 0.0823, 'grad_norm': 21.3452205657959, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.07845284789800644, 'loss_2': 0.00383758544921875, 'loss_3': -15.47340202331543, 'loss_4': 5.017626762390137, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 09:30:48,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:48,760 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:15<1:26:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:56,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024641670286655426, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.136, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0170864537358284, 'eval_loss_2': 0.007555216550827026, 'eval_loss_3': -18.206497192382812, 'eval_loss_4': 4.913171768188477, 'epoch': 0.93}
{'loss': 0.1096, 'grad_norm': 23.155757904052734, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.10925142467021942, 'loss_2': 0.0003819465637207031, 'loss_3': -15.339788436889648, 'loss_4': 4.990881443023682, 'epoch': 0.94}
{'loss': 0.0447, 'grad_norm': 10.772934913635254, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.04420233890414238, 'loss_2': 0.00047397613525390625, 'loss_3': -15.232183456420898, 'loss_4': 5.7383012771606445, 'epoch': 0.94}
{'loss': 0.1314, 'grad_norm': 27.479347229003906, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.11716999858617783, 'loss_2': 0.01422882080078125, 'loss_3': -15.124140739440918, 'loss_4': 5.689719200134277, 'epoch': 0.95}
{'loss': 0.0637, 'grad_norm': 12.562825202941895, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.060375623404979706, 'loss_2': 0.0033550262451171875, 'loss_3': -15.337176322937012, 'loss_4': 5.050876617431641, 'epoch': 0.95}
{'loss': 0.1182, 'grad_norm': 26.277048110961914, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.10883258283138275, 'loss_2': 0.00934600830078125, 'loss_3': -15.248549461364746, 'loss_4': 4.486574649810791, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 09:30:56,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:56,099 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:23<1:26:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:03,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03178448975086212, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01814977452158928, 'eval_loss_2': 0.013634711503982544, 'eval_loss_3': -18.202030181884766, 'eval_loss_4': 3.955268144607544, 'epoch': 0.96}
{'loss': 0.1008, 'grad_norm': 26.284465789794922, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.08893754333257675, 'loss_2': 0.01187896728515625, 'loss_3': -15.195481300354004, 'loss_4': 4.8999199867248535, 'epoch': 0.97}
{'loss': 0.119, 'grad_norm': 25.951759338378906, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.1127796396613121, 'loss_2': 0.006175994873046875, 'loss_3': -15.252245903015137, 'loss_4': 4.364010810852051, 'epoch': 0.97}
{'loss': 0.0941, 'grad_norm': 21.818578720092773, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.09245674312114716, 'loss_2': 0.001621246337890625, 'loss_3': -15.147597312927246, 'loss_4': 4.171587944030762, 'epoch': 0.98}
{'loss': 0.1957, 'grad_norm': 43.915523529052734, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.1838579922914505, 'loss_2': 0.01181793212890625, 'loss_3': -15.10187816619873, 'loss_4': 3.5432968139648438, 'epoch': 0.98}
{'loss': 0.1251, 'grad_norm': 28.944189071655273, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.11585742235183716, 'loss_2': 0.00923919677734375, 'loss_3': -15.266084671020508, 'loss_4': 4.765920162200928, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 09:31:03,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:03,437 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:30<1:23:45,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 09:31:10,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028695670887827873, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.271, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.022072285413742065, 'eval_loss_2': 0.006623387336730957, 'eval_loss_3': -18.183494567871094, 'eval_loss_4': 3.2032060623168945, 'epoch': 0.99}
{'loss': 0.0367, 'grad_norm': 9.399328231811523, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.034996792674064636, 'loss_2': 0.0016603469848632812, 'loss_3': -15.409937858581543, 'loss_4': 2.7902681827545166, 'epoch': 0.99}
{'loss': 0.029, 'grad_norm': 11.501252174377441, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.02039336785674095, 'loss_2': 0.00860595703125, 'loss_3': -15.2686767578125, 'loss_4': 4.334005832672119, 'epoch': 1.0}
{'loss': 0.0781, 'grad_norm': 17.395652770996094, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.0742485299706459, 'loss_2': 0.003803253173828125, 'loss_3': -15.148130416870117, 'loss_4': 3.363171100616455, 'epoch': 1.01}
{'loss': 0.0544, 'grad_norm': 18.637178421020508, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.05353376269340515, 'loss_2': 0.0008869171142578125, 'loss_3': -15.125999450683594, 'loss_4': 3.47392201423645, 'epoch': 1.01}
{'loss': 0.082, 'grad_norm': 22.15634536743164, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.07732285559177399, 'loss_2': 0.004680633544921875, 'loss_3': -15.187576293945312, 'loss_4': 3.4329328536987305, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 09:31:10,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:10,465 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:37<1:25:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:31:17,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03173648193478584, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.027225151658058167, 'eval_loss_2': 0.004511326551437378, 'eval_loss_3': -18.116025924682617, 'eval_loss_4': 3.2758431434631348, 'epoch': 1.02}
{'loss': 0.1401, 'grad_norm': 26.424680709838867, 'learning_rate': 2.9e-05, 'loss_1': 0.13235247135162354, 'loss_2': 0.007770538330078125, 'loss_3': -15.211357116699219, 'loss_4': 3.874478816986084, 'epoch': 1.02}
{'loss': 0.0475, 'grad_norm': 13.168557167053223, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.04311687499284744, 'loss_2': 0.0043487548828125, 'loss_3': -15.242344856262207, 'loss_4': 3.0294113159179688, 'epoch': 1.03}
{'loss': 0.1012, 'grad_norm': 23.06589698791504, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.093656986951828, 'loss_2': 0.00749969482421875, 'loss_3': -14.93822193145752, 'loss_4': 3.2440543174743652, 'epoch': 1.03}
{'loss': 0.0725, 'grad_norm': 20.016592025756836, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.06760047376155853, 'loss_2': 0.0048980712890625, 'loss_3': -15.043212890625, 'loss_4': 2.9917261600494385, 'epoch': 1.04}
{'loss': 0.1083, 'grad_norm': 25.304994583129883, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.09890082478523254, 'loss_2': 0.00939178466796875, 'loss_3': -15.118033409118652, 'loss_4': 3.270565986633301, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 09:31:17,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:17,819 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:44<1:26:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:25,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.049477964639663696, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.04370102286338806, 'eval_loss_2': 0.005776941776275635, 'eval_loss_3': -18.027599334716797, 'eval_loss_4': 3.703942060470581, 'epoch': 1.05}
{'loss': 0.0768, 'grad_norm': 16.9520320892334, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.06933316588401794, 'loss_2': 0.00746917724609375, 'loss_3': -15.077569961547852, 'loss_4': 3.621058464050293, 'epoch': 1.05}
{'loss': 0.1336, 'grad_norm': 31.388877868652344, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.12521235644817352, 'loss_2': 0.00838470458984375, 'loss_3': -14.885316848754883, 'loss_4': 4.141490459442139, 'epoch': 1.06}
{'loss': 0.1154, 'grad_norm': 26.50324058532715, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.11457027494907379, 'loss_2': 0.0008473396301269531, 'loss_3': -15.038164138793945, 'loss_4': 4.326756477355957, 'epoch': 1.06}
{'loss': 0.0862, 'grad_norm': 19.542192459106445, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.07878037542104721, 'loss_2': 0.0074005126953125, 'loss_3': -14.961565971374512, 'loss_4': 4.338644981384277, 'epoch': 1.07}
{'loss': 0.0393, 'grad_norm': 12.235259056091309, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.037772972136735916, 'loss_2': 0.00152587890625, 'loss_3': -15.285711288452148, 'loss_4': 4.683148384094238, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 09:31:25,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:25,166 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:52<1:26:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:32,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03244418278336525, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.928, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.02417105808854103, 'eval_loss_2': 0.008273124694824219, 'eval_loss_3': -18.19183921813965, 'eval_loss_4': 4.769948482513428, 'epoch': 1.08}
{'loss': 0.1036, 'grad_norm': 27.43377685546875, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.10248241573572159, 'loss_2': 0.0011425018310546875, 'loss_3': -15.144402503967285, 'loss_4': 4.750620365142822, 'epoch': 1.08}
{'loss': 0.0758, 'grad_norm': 14.430914878845215, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.0650976225733757, 'loss_2': 0.01065826416015625, 'loss_3': -15.175434112548828, 'loss_4': 4.977545738220215, 'epoch': 1.09}
{'loss': 0.1096, 'grad_norm': 24.10756492614746, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.09689358621835709, 'loss_2': 0.01275634765625, 'loss_3': -15.09033489227295, 'loss_4': 6.029885768890381, 'epoch': 1.09}
{'loss': 0.1162, 'grad_norm': 23.383304595947266, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.10550596565008163, 'loss_2': 0.010650634765625, 'loss_3': -15.065414428710938, 'loss_4': 6.375302314758301, 'epoch': 1.1}
{'loss': 0.1263, 'grad_norm': 31.400354385375977, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.11951115727424622, 'loss_2': 0.0067596435546875, 'loss_3': -15.284102439880371, 'loss_4': 6.825515270233154, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 09:31:32,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:32,524 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [04:59<1:25:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:39,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030018160119652748, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.97, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.024205457419157028, 'eval_loss_2': 0.005812704563140869, 'eval_loss_3': -18.271156311035156, 'eval_loss_4': 6.31296968460083, 'epoch': 1.1}
{'loss': 0.1163, 'grad_norm': 23.79306411743164, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.11230646073818207, 'loss_2': 0.00396728515625, 'loss_3': -15.327421188354492, 'loss_4': 7.20720911026001, 'epoch': 1.11}
{'loss': 0.1498, 'grad_norm': 29.53619956970215, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.14321967959403992, 'loss_2': 0.00653839111328125, 'loss_3': -15.352670669555664, 'loss_4': 7.5048017501831055, 'epoch': 1.12}
{'loss': 0.1639, 'grad_norm': 34.56442642211914, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.159706711769104, 'loss_2': 0.00417327880859375, 'loss_3': -15.393864631652832, 'loss_4': 7.566741466522217, 'epoch': 1.12}
{'loss': 0.1309, 'grad_norm': 33.58338165283203, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.12413472682237625, 'loss_2': 0.0067291259765625, 'loss_3': -15.445911407470703, 'loss_4': 6.2773661613464355, 'epoch': 1.13}
{'loss': 0.1168, 'grad_norm': 25.920961380004883, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.09911486506462097, 'loss_2': 0.0177154541015625, 'loss_3': -15.385560989379883, 'loss_4': 6.394157409667969, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 09:31:39,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:39,871 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:07<1:25:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:47,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029041869565844536, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.256, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.022709950804710388, 'eval_loss_2': 0.006331920623779297, 'eval_loss_3': -18.265832901000977, 'eval_loss_4': 5.324841499328613, 'epoch': 1.13}
{'loss': 0.1157, 'grad_norm': 24.946889877319336, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.11127017438411713, 'loss_2': 0.004425048828125, 'loss_3': -15.273889541625977, 'loss_4': 5.273266315460205, 'epoch': 1.14}
{'loss': 0.093, 'grad_norm': 23.261293411254883, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.09180538356304169, 'loss_2': 0.001186370849609375, 'loss_3': -15.324645042419434, 'loss_4': 5.948423385620117, 'epoch': 1.15}
{'loss': 0.1249, 'grad_norm': 25.883955001831055, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.11134061217308044, 'loss_2': 0.01358795166015625, 'loss_3': -15.379888534545898, 'loss_4': 5.44300651550293, 'epoch': 1.15}
{'loss': 0.1053, 'grad_norm': 19.04755973815918, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.09193765372037888, 'loss_2': 0.0133514404296875, 'loss_3': -15.289710998535156, 'loss_4': 4.785493850708008, 'epoch': 1.16}
{'loss': 0.1184, 'grad_norm': 28.58203887939453, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.1095675453543663, 'loss_2': 0.0087890625, 'loss_3': -15.450671195983887, 'loss_4': 5.1729278564453125, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 09:31:47,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:47,199 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:14<1:25:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:54,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02387375570833683, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.019301678985357285, 'eval_loss_2': 0.004572078585624695, 'eval_loss_3': -18.24721336364746, 'eval_loss_4': 3.9829442501068115, 'epoch': 1.16}
{'loss': 0.043, 'grad_norm': 11.00241756439209, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.04041425138711929, 'loss_2': 0.0026092529296875, 'loss_3': -15.32656478881836, 'loss_4': 4.512331962585449, 'epoch': 1.17}
{'loss': 0.1022, 'grad_norm': 28.449989318847656, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.09702103585004807, 'loss_2': 0.00516510009765625, 'loss_3': -15.368063926696777, 'loss_4': 4.134270668029785, 'epoch': 1.17}
{'loss': 0.0578, 'grad_norm': 14.344893455505371, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.05720692127943039, 'loss_2': 0.0006160736083984375, 'loss_3': -15.41543197631836, 'loss_4': 4.707098007202148, 'epoch': 1.18}
{'loss': 0.1189, 'grad_norm': 33.53350067138672, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.11648780107498169, 'loss_2': 0.00240325927734375, 'loss_3': -15.35140609741211, 'loss_4': 4.250741958618164, 'epoch': 1.19}
{'loss': 0.0903, 'grad_norm': 35.67006301879883, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.08744440972805023, 'loss_2': 0.0028076171875, 'loss_3': -15.30698299407959, 'loss_4': 3.4705147743225098, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 09:31:54,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:54,538 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:21<1:25:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:01,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023368358612060547, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.628, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018380552530288696, 'eval_loss_2': 0.004987806081771851, 'eval_loss_3': -18.266489028930664, 'eval_loss_4': 3.026054620742798, 'epoch': 1.19}
{'loss': 0.0783, 'grad_norm': 16.197704315185547, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.07386863231658936, 'loss_2': 0.00443267822265625, 'loss_3': -15.547159194946289, 'loss_4': 3.6699540615081787, 'epoch': 1.2}
{'loss': 0.0924, 'grad_norm': 37.4437141418457, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.09069289267063141, 'loss_2': 0.001682281494140625, 'loss_3': -15.276203155517578, 'loss_4': 3.609328031539917, 'epoch': 1.2}
{'loss': 0.1086, 'grad_norm': 22.46830177307129, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.10136792808771133, 'loss_2': 0.0071868896484375, 'loss_3': -15.608198165893555, 'loss_4': 3.332022190093994, 'epoch': 1.21}
{'loss': 0.1309, 'grad_norm': 34.549842834472656, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.12056509405374527, 'loss_2': 0.0103607177734375, 'loss_3': -15.403986930847168, 'loss_4': 2.7706291675567627, 'epoch': 1.22}
{'loss': 0.128, 'grad_norm': 20.295799255371094, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.12179931253194809, 'loss_2': 0.0061798095703125, 'loss_3': -15.347920417785645, 'loss_4': 3.139988422393799, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 09:32:01,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:01,881 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:29<1:25:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:09,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027525851503014565, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.021965306252241135, 'eval_loss_2': 0.005560547113418579, 'eval_loss_3': -18.284542083740234, 'eval_loss_4': 2.0902609825134277, 'epoch': 1.22}
{'loss': 0.1048, 'grad_norm': 25.71639060974121, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.10131009668111801, 'loss_2': 0.00348663330078125, 'loss_3': -15.584030151367188, 'loss_4': 2.058976173400879, 'epoch': 1.23}
{'loss': 0.0904, 'grad_norm': 26.168346405029297, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.07826930284500122, 'loss_2': 0.01213836669921875, 'loss_3': -15.430957794189453, 'loss_4': 2.628251552581787, 'epoch': 1.23}
{'loss': 0.0818, 'grad_norm': 20.634357452392578, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.0796528235077858, 'loss_2': 0.0021209716796875, 'loss_3': -15.556930541992188, 'loss_4': 1.6895732879638672, 'epoch': 1.24}
{'loss': 0.0945, 'grad_norm': 23.93016242980957, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.094290591776371, 'loss_2': 0.0001919269561767578, 'loss_3': -15.631346702575684, 'loss_4': 1.8505725860595703, 'epoch': 1.24}
{'loss': 0.0556, 'grad_norm': 12.779876708984375, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.047086991369724274, 'loss_2': 0.0085296630859375, 'loss_3': -15.399559020996094, 'loss_4': 2.048128843307495, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 09:32:09,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:09,242 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:36<1:25:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:16,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0453893318772316, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.516, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03301754593849182, 'eval_loss_2': 0.01237177848815918, 'eval_loss_3': -18.239683151245117, 'eval_loss_4': 1.8624522686004639, 'epoch': 1.25}
{'loss': 0.0969, 'grad_norm': 18.63372230529785, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.08329541236162186, 'loss_2': 0.0135650634765625, 'loss_3': -15.628741264343262, 'loss_4': 1.5181169509887695, 'epoch': 1.26}
{'loss': 0.082, 'grad_norm': 16.090824127197266, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.06245872378349304, 'loss_2': 0.019500732421875, 'loss_3': -15.525857925415039, 'loss_4': 2.229759454727173, 'epoch': 1.26}
{'loss': 0.1059, 'grad_norm': 20.2122745513916, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.09057553112506866, 'loss_2': 0.01537322998046875, 'loss_3': -15.307449340820312, 'loss_4': 1.576812982559204, 'epoch': 1.27}
{'loss': 0.0825, 'grad_norm': 16.92023468017578, 'learning_rate': 2.875e-05, 'loss_1': 0.06164650619029999, 'loss_2': 0.020843505859375, 'loss_3': -15.451201438903809, 'loss_4': 2.2734313011169434, 'epoch': 1.27}
{'loss': 0.0568, 'grad_norm': 17.37830924987793, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.05125997215509415, 'loss_2': 0.0054931640625, 'loss_3': -15.364425659179688, 'loss_4': 1.8494312763214111, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 09:32:16,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:16,585 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:43<1:25:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:23,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04819071292877197, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.026, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.043026506900787354, 'eval_loss_2': 0.005164206027984619, 'eval_loss_3': -18.159334182739258, 'eval_loss_4': 1.9210550785064697, 'epoch': 1.28}
{'loss': 0.0775, 'grad_norm': 19.293981552124023, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.07634220272302628, 'loss_2': 0.00113677978515625, 'loss_3': -15.39169692993164, 'loss_4': 1.3551181554794312, 'epoch': 1.28}
{'loss': 0.0539, 'grad_norm': 16.361236572265625, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.050543516874313354, 'loss_2': 0.003387451171875, 'loss_3': -15.357316017150879, 'loss_4': 2.285334825515747, 'epoch': 1.29}
{'loss': 0.0539, 'grad_norm': 9.68073558807373, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.045072246342897415, 'loss_2': 0.00878143310546875, 'loss_3': -15.563837051391602, 'loss_4': 1.917322039604187, 'epoch': 1.3}
{'loss': 0.0566, 'grad_norm': 13.4812593460083, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.051614005118608475, 'loss_2': 0.005031585693359375, 'loss_3': -15.507970809936523, 'loss_4': 1.7105700969696045, 'epoch': 1.3}
{'loss': 0.088, 'grad_norm': 23.75871467590332, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.08727292716503143, 'loss_2': 0.0007505416870117188, 'loss_3': -15.544037818908691, 'loss_4': 2.185105800628662, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 09:32:23,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:23,922 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [05:51<1:25:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:31,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030370494350790977, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.023093782365322113, 'eval_loss_2': 0.007276713848114014, 'eval_loss_3': -18.2440128326416, 'eval_loss_4': 1.9864943027496338, 'epoch': 1.31}
{'loss': 0.0414, 'grad_norm': 14.64765739440918, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.03998696804046631, 'loss_2': 0.0014286041259765625, 'loss_3': -15.631025314331055, 'loss_4': 1.8148725032806396, 'epoch': 1.31}
{'loss': 0.0945, 'grad_norm': 22.226463317871094, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.08643697947263718, 'loss_2': 0.00803375244140625, 'loss_3': -15.368457794189453, 'loss_4': 2.511305332183838, 'epoch': 1.32}
{'loss': 0.0424, 'grad_norm': 9.737506866455078, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.03291616961359978, 'loss_2': 0.00948333740234375, 'loss_3': -15.541557312011719, 'loss_4': 2.170199155807495, 'epoch': 1.33}
{'loss': 0.0607, 'grad_norm': 14.544269561767578, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.054165471345186234, 'loss_2': 0.00650787353515625, 'loss_3': -15.541265487670898, 'loss_4': 3.274439573287964, 'epoch': 1.33}
{'loss': 0.0735, 'grad_norm': 16.214120864868164, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.0618799552321434, 'loss_2': 0.01157379150390625, 'loss_3': -15.46435832977295, 'loss_4': 2.598395347595215, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 09:32:31,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:31,270 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [05:58<1:25:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:38,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0231438260525465, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.965, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016512393951416016, 'eval_loss_2': 0.006631433963775635, 'eval_loss_3': -18.305259704589844, 'eval_loss_4': 2.638223171234131, 'epoch': 1.34}
{'loss': 0.0683, 'grad_norm': 19.16206169128418, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.06705911457538605, 'loss_2': 0.00128173828125, 'loss_3': -15.503719329833984, 'loss_4': 3.36946439743042, 'epoch': 1.34}
{'loss': 0.0984, 'grad_norm': 21.850419998168945, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.09002325683832169, 'loss_2': 0.00835418701171875, 'loss_3': -15.328234672546387, 'loss_4': 2.7248711585998535, 'epoch': 1.35}
{'loss': 0.0857, 'grad_norm': 29.30958366394043, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.08245229721069336, 'loss_2': 0.00321197509765625, 'loss_3': -15.255083084106445, 'loss_4': 3.279374599456787, 'epoch': 1.35}
{'loss': 0.061, 'grad_norm': 16.60384750366211, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.05540115758776665, 'loss_2': 0.00563812255859375, 'loss_3': -15.49787712097168, 'loss_4': 3.2455899715423584, 'epoch': 1.36}
{'loss': 0.0803, 'grad_norm': 17.895627975463867, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.0638548955321312, 'loss_2': 0.0164031982421875, 'loss_3': -15.74144458770752, 'loss_4': 4.03971004486084, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 09:32:38,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:38,607 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:05<1:25:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:45,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026720209047198296, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.016934139654040337, 'eval_loss_2': 0.009786069393157959, 'eval_loss_3': -18.27713966369629, 'eval_loss_4': 2.8303728103637695, 'epoch': 1.37}
{'loss': 0.0867, 'grad_norm': 18.603195190429688, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.08436606079339981, 'loss_2': 0.00235748291015625, 'loss_3': -15.213720321655273, 'loss_4': 3.240044593811035, 'epoch': 1.37}
{'loss': 0.0967, 'grad_norm': 24.487524032592773, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.08230678737163544, 'loss_2': 0.014434814453125, 'loss_3': -15.394388198852539, 'loss_4': 3.2625536918640137, 'epoch': 1.38}
{'loss': 0.0663, 'grad_norm': 16.95756721496582, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.061779435724020004, 'loss_2': 0.0045166015625, 'loss_3': -15.605541229248047, 'loss_4': 3.6205461025238037, 'epoch': 1.38}
{'loss': 0.075, 'grad_norm': 20.351564407348633, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.07436159998178482, 'loss_2': 0.00066375732421875, 'loss_3': -15.352911949157715, 'loss_4': 3.8260581493377686, 'epoch': 1.39}
{'loss': 0.0476, 'grad_norm': 9.980364799499512, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.036892544478178024, 'loss_2': 0.0107421875, 'loss_3': -15.328373908996582, 'loss_4': 3.2936387062072754, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 09:32:45,948 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:45,948 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:13<1:25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:53,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02395911142230034, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018126722425222397, 'eval_loss_2': 0.005832388997077942, 'eval_loss_3': -18.206661224365234, 'eval_loss_4': 2.971423387527466, 'epoch': 1.4}
{'loss': 0.1158, 'grad_norm': 28.189199447631836, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.0995645821094513, 'loss_2': 0.016204833984375, 'loss_3': -15.48056697845459, 'loss_4': 3.6141977310180664, 'epoch': 1.4}
{'loss': 0.0498, 'grad_norm': 11.84532642364502, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.0482904352247715, 'loss_2': 0.001506805419921875, 'loss_3': -15.495662689208984, 'loss_4': 3.148191452026367, 'epoch': 1.41}
{'loss': 0.1004, 'grad_norm': 22.11683464050293, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.08835172653198242, 'loss_2': 0.01202392578125, 'loss_3': -15.14966106414795, 'loss_4': 3.7949609756469727, 'epoch': 1.41}
{'loss': 0.0461, 'grad_norm': 12.108572006225586, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.036212947219610214, 'loss_2': 0.0099029541015625, 'loss_3': -15.537271499633789, 'loss_4': 3.096580982208252, 'epoch': 1.42}
{'loss': 0.051, 'grad_norm': 15.027032852172852, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.04459008947014809, 'loss_2': 0.00640869140625, 'loss_3': -15.401893615722656, 'loss_4': 2.326807737350464, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 09:32:53,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:53,295 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:16<1:25:02,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:32:57,089 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245
[INFO|configuration_utils.py:420] 2025-01-21 09:32:57,091 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245/config.json                                                                              
{'eval_loss': 0.021369095891714096, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.035, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.015014614909887314, 'eval_loss_2': 0.006354480981826782, 'eval_loss_3': -18.16288185119629, 'eval_loss_4': 2.573242425918579, 'epoch': 1.42}
[INFO|modeling_utils.py:2988] 2025-01-21 09:32:57,556 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:32:57,557 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:32:57,557 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:32:58,341 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-110] due to args.save_total_limit
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:21<1:32:36,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 09:33:01,958 >>
{'loss': 0.0811, 'grad_norm': 29.94353675842285, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.0730135589838028, 'loss_2': 0.0081329345703125, 'loss_3': -15.505626678466797, 'loss_4': 3.4215149879455566, 'epoch': 1.43}
{'loss': 0.0939, 'grad_norm': 52.450687408447266, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.08073229342699051, 'loss_2': 0.0131683349609375, 'loss_3': -15.324740409851074, 'loss_4': 2.8073720932006836, 'epoch': 1.44}
{'loss': 0.0935, 'grad_norm': 27.202878952026367, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.08961568772792816, 'loss_2': 0.00389862060546875, 'loss_3': -15.097367286682129, 'loss_4': 2.3223166465759277, 'epoch': 1.44}
{'loss': 0.0684, 'grad_norm': 15.215956687927246, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.06432324647903442, 'loss_2': 0.004070281982421875, 'loss_3': -15.300106048583984, 'loss_4': 2.2039241790771484, 'epoch': 1.45}
{'loss': 0.053, 'grad_norm': 14.727718353271484, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.05247041955590248, 'loss_2': 0.000522613525390625, 'loss_3': -15.537339210510254, 'loss_4': 2.1476216316223145, 'epoch': 1.45}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:33:01,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:01,958 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:25<1:32:36,  1.13s/it][INFO|trainer.py:3910] 2025-01-21 09:33:05,750 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250
[INFO|configuration_utils.py:420] 2025-01-21 09:33:05,752 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250/config.json                                                                              
{'eval_loss': 0.020974809303879738, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.116, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01475339662283659, 'eval_loss_2': 0.006221413612365723, 'eval_loss_3': -18.157926559448242, 'eval_loss_4': 1.8797991275787354, 'epoch': 1.45}
[INFO|modeling_utils.py:2988] 2025-01-21 09:33:06,197 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:33:06,199 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:33:06,199 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:33:06,965 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-245] due to args.save_total_limit
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:30<1:33:42,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:33:10,596 >>
{'loss': 0.0686, 'grad_norm': 17.557493209838867, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.06856408715248108, 'loss_2': 7.903575897216797e-05, 'loss_3': -15.39791202545166, 'loss_4': 3.0699779987335205, 'epoch': 1.46}
{'loss': 0.0464, 'grad_norm': 13.1414155960083, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.04138685017824173, 'loss_2': 0.005031585693359375, 'loss_3': -15.517545700073242, 'loss_4': 1.9140547513961792, 'epoch': 1.47}
{'loss': 0.0382, 'grad_norm': 22.27056312561035, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.03666047379374504, 'loss_2': 0.0015811920166015625, 'loss_3': -15.45688247680664, 'loss_4': 1.491452932357788, 'epoch': 1.47}
{'loss': 0.0717, 'grad_norm': 27.813661575317383, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.07133881747722626, 'loss_2': 0.00034618377685546875, 'loss_3': -15.274460792541504, 'loss_4': 2.5965962409973145, 'epoch': 1.48}
{'loss': 0.034, 'grad_norm': 10.403876304626465, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.02565760537981987, 'loss_2': 0.0083160400390625, 'loss_3': -15.500657081604004, 'loss_4': 1.7146131992340088, 'epoch': 1.48}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:33:10,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:10,597 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:37<1:26:14,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:33:17,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027290785685181618, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.811, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021344982087612152, 'eval_loss_2': 0.005945801734924316, 'eval_loss_3': -18.070507049560547, 'eval_loss_4': 1.759054183959961, 'epoch': 1.48}
{'loss': 0.0502, 'grad_norm': 14.88735294342041, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.04540694132447243, 'loss_2': 0.00481414794921875, 'loss_3': -15.51740837097168, 'loss_4': 2.0343050956726074, 'epoch': 1.49}
{'loss': 0.0458, 'grad_norm': 14.694188117980957, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.043999042361974716, 'loss_2': 0.0017976760864257812, 'loss_3': -15.555471420288086, 'loss_4': 2.2157678604125977, 'epoch': 1.49}
{'loss': 0.055, 'grad_norm': 27.358882904052734, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.04834125190973282, 'loss_2': 0.006626129150390625, 'loss_3': -15.084335327148438, 'loss_4': 1.2852057218551636, 'epoch': 1.5}
{'loss': 0.0884, 'grad_norm': 24.205032348632812, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.08680455386638641, 'loss_2': 0.001598358154296875, 'loss_3': -15.176013946533203, 'loss_4': 2.078616142272949, 'epoch': 1.51}
{'loss': 0.0711, 'grad_norm': 23.317272186279297, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.06899400055408478, 'loss_2': 0.0021038055419921875, 'loss_3': -15.186137199401855, 'loss_4': 2.3034796714782715, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 09:33:17,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:17,942 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:45<1:24:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:25,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022777575999498367, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.018681885674595833, 'eval_loss_2': 0.004095688462257385, 'eval_loss_3': -18.07082748413086, 'eval_loss_4': 1.8646339178085327, 'epoch': 1.51}
{'loss': 0.0938, 'grad_norm': 24.093050003051758, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.09078454971313477, 'loss_2': 0.00299835205078125, 'loss_3': -15.371125221252441, 'loss_4': 2.579293966293335, 'epoch': 1.52}
{'loss': 0.0583, 'grad_norm': 21.507183074951172, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.04766791686415672, 'loss_2': 0.01067352294921875, 'loss_3': -15.474706649780273, 'loss_4': 2.013490915298462, 'epoch': 1.52}
{'loss': 0.0419, 'grad_norm': 12.352399826049805, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.03628332540392876, 'loss_2': 0.005611419677734375, 'loss_3': -15.325262069702148, 'loss_4': 2.168260097503662, 'epoch': 1.53}
{'loss': 0.0453, 'grad_norm': 15.009638786315918, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.036717940121889114, 'loss_2': 0.0086212158203125, 'loss_3': -15.20697021484375, 'loss_4': 1.2024314403533936, 'epoch': 1.53}
{'loss': 0.0292, 'grad_norm': 9.667283058166504, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.028162354603409767, 'loss_2': 0.0010166168212890625, 'loss_3': -15.264032363891602, 'loss_4': 1.6164518594741821, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 09:33:25,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:25,275 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [06:52<1:24:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:32,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022104749456048012, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015146822668612003, 'eval_loss_2': 0.006957925856113434, 'eval_loss_3': -18.123470306396484, 'eval_loss_4': 2.1545677185058594, 'epoch': 1.54}
{'loss': 0.0618, 'grad_norm': 13.96528148651123, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.05101810395717621, 'loss_2': 0.0108184814453125, 'loss_3': -15.285497665405273, 'loss_4': 2.253763198852539, 'epoch': 1.55}
{'loss': 0.122, 'grad_norm': 38.25029754638672, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.10977979749441147, 'loss_2': 0.0121917724609375, 'loss_3': -15.03509521484375, 'loss_4': 2.2909369468688965, 'epoch': 1.55}
{'loss': 0.0981, 'grad_norm': 28.071426391601562, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.07416841387748718, 'loss_2': 0.023956298828125, 'loss_3': -15.155455589294434, 'loss_4': 2.403979539871216, 'epoch': 1.56}
{'loss': 0.0618, 'grad_norm': 18.80349349975586, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.05626816302537918, 'loss_2': 0.00555419921875, 'loss_3': -15.439302444458008, 'loss_4': 2.837207078933716, 'epoch': 1.56}
{'loss': 0.1025, 'grad_norm': 25.28577423095703, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.08844511955976486, 'loss_2': 0.0140228271484375, 'loss_3': -15.334944725036621, 'loss_4': 3.128878116607666, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 09:33:32,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:32,618 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [06:59<1:24:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:39,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02328193373978138, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.224, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015577406622469425, 'eval_loss_2': 0.00770452618598938, 'eval_loss_3': -18.149688720703125, 'eval_loss_4': 3.1571671962738037, 'epoch': 1.57}
{'loss': 0.0467, 'grad_norm': 11.747340202331543, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.03927527368068695, 'loss_2': 0.00746917724609375, 'loss_3': -15.369457244873047, 'loss_4': 3.0514416694641113, 'epoch': 1.58}
{'loss': 0.0896, 'grad_norm': 21.26433563232422, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.07875241339206696, 'loss_2': 0.0108489990234375, 'loss_3': -15.27186393737793, 'loss_4': 4.096895217895508, 'epoch': 1.58}
{'loss': 0.0965, 'grad_norm': 21.285871505737305, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.09066403657197952, 'loss_2': 0.005786895751953125, 'loss_3': -15.452903747558594, 'loss_4': 3.8389840126037598, 'epoch': 1.59}
{'loss': 0.0902, 'grad_norm': 22.35442543029785, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.08356746286153793, 'loss_2': 0.006622314453125, 'loss_3': -15.650367736816406, 'loss_4': 4.898385047912598, 'epoch': 1.59}
{'loss': 0.0528, 'grad_norm': 14.417919158935547, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.04716618359088898, 'loss_2': 0.00566864013671875, 'loss_3': -15.363815307617188, 'loss_4': 4.08726167678833, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 09:33:39,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:39,952 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:07<1:24:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:47,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026610562577843666, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.873, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01564319059252739, 'eval_loss_2': 0.010967373847961426, 'eval_loss_3': -18.234567642211914, 'eval_loss_4': 4.321779727935791, 'epoch': 1.6}
{'loss': 0.0809, 'grad_norm': 15.941648483276367, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.07701122760772705, 'loss_2': 0.003864288330078125, 'loss_3': -15.425947189331055, 'loss_4': 4.652214050292969, 'epoch': 1.6}
{'loss': 0.0486, 'grad_norm': 11.170008659362793, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.040044236928224564, 'loss_2': 0.008544921875, 'loss_3': -15.46743392944336, 'loss_4': 5.248864650726318, 'epoch': 1.61}
{'loss': 0.0517, 'grad_norm': 9.254593849182129, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.0355217419564724, 'loss_2': 0.01617431640625, 'loss_3': -15.454622268676758, 'loss_4': 4.586343765258789, 'epoch': 1.62}
{'loss': 0.0723, 'grad_norm': 26.728153228759766, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.07139996439218521, 'loss_2': 0.0008883476257324219, 'loss_3': -15.370417594909668, 'loss_4': 5.418566703796387, 'epoch': 1.62}
{'loss': 0.0824, 'grad_norm': 21.79958152770996, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.07404521107673645, 'loss_2': 0.0083465576171875, 'loss_3': -15.510066032409668, 'loss_4': 4.973998069763184, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 09:33:47,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:47,296 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:14<1:24:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:54,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02296062931418419, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.82, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01845608279109001, 'eval_loss_2': 0.004504546523094177, 'eval_loss_3': -18.26034927368164, 'eval_loss_4': 4.609772205352783, 'epoch': 1.63}
{'loss': 0.058, 'grad_norm': 10.20899772644043, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.045291390269994736, 'loss_2': 0.01267242431640625, 'loss_3': -15.36433219909668, 'loss_4': 4.567454814910889, 'epoch': 1.63}
{'loss': 0.0422, 'grad_norm': 9.582859992980957, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.028842920437455177, 'loss_2': 0.0133209228515625, 'loss_3': -15.517242431640625, 'loss_4': 4.829800128936768, 'epoch': 1.64}
{'loss': 0.0747, 'grad_norm': 20.63875389099121, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.07156109809875488, 'loss_2': 0.0030956268310546875, 'loss_3': -15.568094253540039, 'loss_4': 4.321784973144531, 'epoch': 1.65}
{'loss': 0.0777, 'grad_norm': 23.22157859802246, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.07309258729219437, 'loss_2': 0.00457000732421875, 'loss_3': -15.386577606201172, 'loss_4': 5.789546012878418, 'epoch': 1.65}
{'loss': 0.0758, 'grad_norm': 19.58154296875, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.0741388276219368, 'loss_2': 0.0016565322875976562, 'loss_3': -15.342493057250977, 'loss_4': 4.810410499572754, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 09:33:54,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:54,637 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:21<1:24:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:01,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023580193519592285, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.58, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018297165632247925, 'eval_loss_2': 0.00528302788734436, 'eval_loss_3': -18.247879028320312, 'eval_loss_4': 4.605568885803223, 'epoch': 1.66}
{'loss': 0.0609, 'grad_norm': 23.639888763427734, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.05545370280742645, 'loss_2': 0.005458831787109375, 'loss_3': -15.623111724853516, 'loss_4': 5.600506782531738, 'epoch': 1.66}
{'loss': 0.0671, 'grad_norm': 15.80101490020752, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.06464506685733795, 'loss_2': 0.00247955322265625, 'loss_3': -15.350204467773438, 'loss_4': 5.118068218231201, 'epoch': 1.67}
{'loss': 0.0597, 'grad_norm': 16.630462646484375, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.053407225757837296, 'loss_2': 0.006290435791015625, 'loss_3': -15.553465843200684, 'loss_4': 4.860828399658203, 'epoch': 1.67}
{'loss': 0.0563, 'grad_norm': 16.18459129333496, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.05053019896149635, 'loss_2': 0.005756378173828125, 'loss_3': -15.611398696899414, 'loss_4': 5.608957290649414, 'epoch': 1.68}
{'loss': 0.0441, 'grad_norm': 13.400735855102539, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.040365494787693024, 'loss_2': 0.003749847412109375, 'loss_3': -15.538107872009277, 'loss_4': 4.642581462860107, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 09:34:01,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:01,975 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:29<1:24:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:09,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02560366317629814, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017527323216199875, 'eval_loss_2': 0.008076339960098267, 'eval_loss_3': -18.255754470825195, 'eval_loss_4': 4.155623912811279, 'epoch': 1.69}
{'loss': 0.075, 'grad_norm': 20.262981414794922, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.06771040707826614, 'loss_2': 0.007305145263671875, 'loss_3': -15.476446151733398, 'loss_4': 4.913166046142578, 'epoch': 1.69}
{'loss': 0.0346, 'grad_norm': 9.403646469116211, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.02991613559424877, 'loss_2': 0.004638671875, 'loss_3': -15.549331665039062, 'loss_4': 4.686668395996094, 'epoch': 1.7}
{'loss': 0.072, 'grad_norm': 18.630531311035156, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.06741590052843094, 'loss_2': 0.00460052490234375, 'loss_3': -15.51877212524414, 'loss_4': 4.048868179321289, 'epoch': 1.7}
{'loss': 0.0509, 'grad_norm': 14.186294555664062, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.04190460965037346, 'loss_2': 0.0089569091796875, 'loss_3': -15.604252815246582, 'loss_4': 3.8719115257263184, 'epoch': 1.71}
{'loss': 0.0645, 'grad_norm': 20.065528869628906, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.06133656203746796, 'loss_2': 0.003170013427734375, 'loss_3': -15.455866813659668, 'loss_4': 3.1708106994628906, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 09:34:09,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:09,319 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:36<1:24:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:16,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02364332228899002, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.037, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01724989153444767, 'eval_loss_2': 0.0063934326171875, 'eval_loss_3': -18.236021041870117, 'eval_loss_4': 3.507613182067871, 'epoch': 1.72}
{'loss': 0.0673, 'grad_norm': 24.422985076904297, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.06405170261859894, 'loss_2': 0.00325775146484375, 'loss_3': -15.319910049438477, 'loss_4': 3.463444709777832, 'epoch': 1.72}
{'loss': 0.067, 'grad_norm': 18.545085906982422, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.06315436959266663, 'loss_2': 0.00386810302734375, 'loss_3': -15.329959869384766, 'loss_4': 3.3157222270965576, 'epoch': 1.73}
{'loss': 0.0595, 'grad_norm': 17.921911239624023, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.04784533753991127, 'loss_2': 0.01165771484375, 'loss_3': -15.69207763671875, 'loss_4': 4.118814945220947, 'epoch': 1.73}
{'loss': 0.0775, 'grad_norm': 20.602752685546875, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.07459846884012222, 'loss_2': 0.002899169921875, 'loss_3': -15.579879760742188, 'loss_4': 4.015033721923828, 'epoch': 1.74}
{'loss': 0.0512, 'grad_norm': 10.226688385009766, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.03712017834186554, 'loss_2': 0.01409912109375, 'loss_3': -15.43603515625, 'loss_4': 3.5102219581604004, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 09:34:16,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:16,660 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:43<1:24:59,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:34:24,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02429760992527008, 'eval_runtime': 3.9912, 'eval_samples_per_second': 256.565, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.017392858862876892, 'eval_loss_2': 0.0069047510623931885, 'eval_loss_3': -18.240005493164062, 'eval_loss_4': 3.379817008972168, 'epoch': 1.74}
{'loss': 0.0569, 'grad_norm': 18.663625717163086, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.05149460956454277, 'loss_2': 0.0053863525390625, 'loss_3': -15.491058349609375, 'loss_4': 3.8287692070007324, 'epoch': 1.75}
{'loss': 0.0369, 'grad_norm': 9.967004776000977, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.03611154109239578, 'loss_2': 0.0007877349853515625, 'loss_3': -15.557283401489258, 'loss_4': 3.0989153385162354, 'epoch': 1.76}
{'loss': 0.0249, 'grad_norm': 6.7991180419921875, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.02338217757642269, 'loss_2': 0.0014829635620117188, 'loss_3': -15.554055213928223, 'loss_4': 3.654555082321167, 'epoch': 1.76}
{'loss': 0.0496, 'grad_norm': 11.537496566772461, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.04117458313703537, 'loss_2': 0.0083770751953125, 'loss_3': -15.350106239318848, 'loss_4': 3.29705810546875, 'epoch': 1.77}
{'loss': 0.0483, 'grad_norm': 12.229077339172363, 'learning_rate': 2.825e-05, 'loss_1': 0.041177455335855484, 'loss_2': 0.0071563720703125, 'loss_3': -15.440935134887695, 'loss_4': 3.6988463401794434, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 09:34:24,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:24,189 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [07:51<1:24:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:31,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03022185154259205, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.268, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.015191705897450447, 'eval_loss_2': 0.015030145645141602, 'eval_loss_3': -18.21965980529785, 'eval_loss_4': 3.5273985862731934, 'epoch': 1.77}
{'loss': 0.0665, 'grad_norm': 20.913061141967773, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.06201614812016487, 'loss_2': 0.00447845458984375, 'loss_3': -15.51724910736084, 'loss_4': 3.8013954162597656, 'epoch': 1.78}
{'loss': 0.065, 'grad_norm': 16.812728881835938, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.05782268941402435, 'loss_2': 0.0071563720703125, 'loss_3': -15.627297401428223, 'loss_4': 3.8180298805236816, 'epoch': 1.78}
{'loss': 0.059, 'grad_norm': 14.118945121765137, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.04382553696632385, 'loss_2': 0.015167236328125, 'loss_3': -15.57402515411377, 'loss_4': 3.1539125442504883, 'epoch': 1.79}
{'loss': 0.0592, 'grad_norm': 18.588214874267578, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.047031205147504807, 'loss_2': 0.012176513671875, 'loss_3': -15.460197448730469, 'loss_4': 3.234335422515869, 'epoch': 1.8}
{'loss': 0.0418, 'grad_norm': 9.317370414733887, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.029656067490577698, 'loss_2': 0.0121917724609375, 'loss_3': -15.444561004638672, 'loss_4': 3.3415215015411377, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 09:34:31,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:31,527 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [07:58<1:23:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:38,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024299202486872673, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.015846310183405876, 'eval_loss_2': 0.008452892303466797, 'eval_loss_3': -18.202533721923828, 'eval_loss_4': 3.6034035682678223, 'epoch': 1.8}
{'loss': 0.0284, 'grad_norm': 8.681548118591309, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.025292472913861275, 'loss_2': 0.00305938720703125, 'loss_3': -15.511869430541992, 'loss_4': 3.526900291442871, 'epoch': 1.81}
{'loss': 0.0325, 'grad_norm': 10.0498046875, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.02491045743227005, 'loss_2': 0.0075531005859375, 'loss_3': -15.589755058288574, 'loss_4': 3.6868929862976074, 'epoch': 1.81}
{'loss': 0.0358, 'grad_norm': 16.150876998901367, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.03337710350751877, 'loss_2': 0.0024013519287109375, 'loss_3': -15.428607940673828, 'loss_4': 3.2319202423095703, 'epoch': 1.82}
{'loss': 0.047, 'grad_norm': 13.140952110290527, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.03128763288259506, 'loss_2': 0.0156707763671875, 'loss_3': -15.351424217224121, 'loss_4': 3.209934949874878, 'epoch': 1.83}
{'loss': 0.0594, 'grad_norm': 18.479455947875977, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.04936257377266884, 'loss_2': 0.0099945068359375, 'loss_3': -15.580840110778809, 'loss_4': 3.6838648319244385, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 09:34:38,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:38,878 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:02<1:23:57,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:34:42,681 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315
[INFO|configuration_utils.py:420] 2025-01-21 09:34:42,682 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315/config.json                                                                              
{'eval_loss': 0.02069051004946232, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016355331987142563, 'eval_loss_2': 0.004335179924964905, 'eval_loss_3': -18.209144592285156, 'eval_loss_4': 3.1901087760925293, 'epoch': 1.83}
[INFO|modeling_utils.py:2988] 2025-01-21 09:34:43,187 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:34:43,188 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:34:43,188 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:34:43,998 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-250] due to args.save_total_limit
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:07<1:31:50,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:34:47,616 >>
{'loss': 0.0645, 'grad_norm': 16.75674057006836, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.05404592677950859, 'loss_2': 0.010498046875, 'loss_3': -15.379573822021484, 'loss_4': 3.242750883102417, 'epoch': 1.84}
{'loss': 0.0879, 'grad_norm': 27.31751251220703, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.0781184732913971, 'loss_2': 0.0098114013671875, 'loss_3': -15.543012619018555, 'loss_4': 3.2649450302124023, 'epoch': 1.84}
{'loss': 0.0508, 'grad_norm': 13.236305236816406, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.04348016530275345, 'loss_2': 0.00731658935546875, 'loss_3': -15.363370895385742, 'loss_4': 3.4414117336273193, 'epoch': 1.85}
{'loss': 0.0385, 'grad_norm': 9.212312698364258, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.024322770535945892, 'loss_2': 0.0141754150390625, 'loss_3': -15.63311767578125, 'loss_4': 2.838771343231201, 'epoch': 1.85}
{'loss': 0.0771, 'grad_norm': 22.305334091186523, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.07509902864694595, 'loss_2': 0.0020160675048828125, 'loss_3': -15.354303359985352, 'loss_4': 2.9856438636779785, 'epoch': 1.86}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:34:47,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:47,617 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:14<1:24:54,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:34:54,957 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025819577276706696, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018465273082256317, 'eval_loss_2': 0.007354304194450378, 'eval_loss_3': -18.224498748779297, 'eval_loss_4': 2.6369895935058594, 'epoch': 1.86}
{'loss': 0.0398, 'grad_norm': 10.489608764648438, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.03305672109127045, 'loss_2': 0.006740570068359375, 'loss_3': -15.392173767089844, 'loss_4': 2.2421507835388184, 'epoch': 1.87}
{'loss': 0.0462, 'grad_norm': 10.420629501342773, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.027743646875023842, 'loss_2': 0.0184173583984375, 'loss_3': -15.324136734008789, 'loss_4': 2.0739939212799072, 'epoch': 1.87}
{'loss': 0.0445, 'grad_norm': 12.02685260772705, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.04148918390274048, 'loss_2': 0.0029754638671875, 'loss_3': -15.448921203613281, 'loss_4': 2.636402130126953, 'epoch': 1.88}
{'loss': 0.1406, 'grad_norm': 39.15578079223633, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.14026634395122528, 'loss_2': 0.00037741661071777344, 'loss_3': -15.504302978515625, 'loss_4': 2.6327385902404785, 'epoch': 1.88}
{'loss': 0.0444, 'grad_norm': 16.627527236938477, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.040778983384370804, 'loss_2': 0.003597259521484375, 'loss_3': -15.409204483032227, 'loss_4': 2.5013678073883057, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 09:34:54,957 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:54,957 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:22<1:23:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:02,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02262912504374981, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017872018739581108, 'eval_loss_2': 0.004757106304168701, 'eval_loss_3': -18.230546951293945, 'eval_loss_4': 2.6621828079223633, 'epoch': 1.89}
{'loss': 0.0292, 'grad_norm': 9.091537475585938, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.025972880423069, 'loss_2': 0.00322723388671875, 'loss_3': -15.472152709960938, 'loss_4': 2.7232518196105957, 'epoch': 1.9}
{'loss': 0.0332, 'grad_norm': 9.8406982421875, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.0300945732742548, 'loss_2': 0.003143310546875, 'loss_3': -15.559181213378906, 'loss_4': 2.8658409118652344, 'epoch': 1.9}
{'loss': 0.0589, 'grad_norm': 21.204605102539062, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.055650126188993454, 'loss_2': 0.00324249267578125, 'loss_3': -15.556747436523438, 'loss_4': 2.9535739421844482, 'epoch': 1.91}
{'loss': 0.0233, 'grad_norm': 7.598732948303223, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.02154521830379963, 'loss_2': 0.0017175674438476562, 'loss_3': -15.561237335205078, 'loss_4': 2.1473002433776855, 'epoch': 1.91}
{'loss': 0.0311, 'grad_norm': 11.665129661560059, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.028007689863443375, 'loss_2': 0.003139495849609375, 'loss_3': -15.714956283569336, 'loss_4': 2.9189562797546387, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 09:35:02,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:02,300 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:25<1:23:42,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:35:06,096 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330
[INFO|configuration_utils.py:420] 2025-01-21 09:35:06,097 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330/config.json                                                                              
{'eval_loss': 0.018132077530026436, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.891, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014492259360849857, 'eval_loss_2': 0.003639817237854004, 'eval_loss_3': -18.25969123840332, 'eval_loss_4': 2.9517929553985596, 'epoch': 1.92}
[INFO|modeling_utils.py:2988] 2025-01-21 09:35:06,560 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:35:06,562 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:35:06,562 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:35:07,347 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-315] due to args.save_total_limit
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:30<1:31:19,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:35:10,993 >>
{'loss': 0.0354, 'grad_norm': 8.63535213470459, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.03132025897502899, 'loss_2': 0.00411224365234375, 'loss_3': -15.485040664672852, 'loss_4': 3.0377535820007324, 'epoch': 1.92}
{'loss': 0.065, 'grad_norm': 14.747103691101074, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.062152519822120667, 'loss_2': 0.002834320068359375, 'loss_3': -15.630048751831055, 'loss_4': 3.217482805252075, 'epoch': 1.93}
{'loss': 0.0615, 'grad_norm': 15.324304580688477, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.05559692904353142, 'loss_2': 0.005950927734375, 'loss_3': -15.497028350830078, 'loss_4': 2.8317646980285645, 'epoch': 1.94}
{'loss': 0.0307, 'grad_norm': 6.355533599853516, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.014403704553842545, 'loss_2': 0.0163421630859375, 'loss_3': -15.53738021850586, 'loss_4': 3.0798768997192383, 'epoch': 1.94}
{'loss': 0.0534, 'grad_norm': 13.182890892028809, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.04569955915212631, 'loss_2': 0.00766754150390625, 'loss_3': -15.814970016479492, 'loss_4': 3.085289478302002, 'epoch': 1.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:35:10,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:10,993 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:38<1:24:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:35:18,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01983528956770897, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.795, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012136218138039112, 'eval_loss_2': 0.007699072360992432, 'eval_loss_3': -18.217504501342773, 'eval_loss_4': 2.806056261062622, 'epoch': 1.95}
{'loss': 0.0421, 'grad_norm': 11.052775382995605, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.03999793529510498, 'loss_2': 0.002056121826171875, 'loss_3': -15.618743896484375, 'loss_4': 2.691314697265625, 'epoch': 1.95}
{'loss': 0.0704, 'grad_norm': 15.43333625793457, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.06778955459594727, 'loss_2': 0.0026302337646484375, 'loss_3': -15.509532928466797, 'loss_4': 2.8650059700012207, 'epoch': 1.96}
{'loss': 0.0882, 'grad_norm': 22.699493408203125, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.07715325057506561, 'loss_2': 0.01105499267578125, 'loss_3': -15.444334983825684, 'loss_4': 2.9720005989074707, 'epoch': 1.97}
{'loss': 0.0437, 'grad_norm': 12.244532585144043, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.04006102308630943, 'loss_2': 0.003681182861328125, 'loss_3': -15.640623092651367, 'loss_4': 2.881014347076416, 'epoch': 1.97}
{'loss': 0.0211, 'grad_norm': 7.356019973754883, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.017568549141287804, 'loss_2': 0.00350189208984375, 'loss_3': -15.59591293334961, 'loss_4': 2.9764819145202637, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 09:35:18,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:18,337 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:45<1:18:39,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:35:25,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02249467931687832, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.57, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01511497050523758, 'eval_loss_2': 0.007379710674285889, 'eval_loss_3': -18.18914031982422, 'eval_loss_4': 2.5743186473846436, 'epoch': 1.98}
{'loss': 0.0417, 'grad_norm': 13.84260082244873, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.036216914653778076, 'loss_2': 0.005435943603515625, 'loss_3': -15.45743179321289, 'loss_4': 2.5292413234710693, 'epoch': 1.98}
{'loss': 0.0401, 'grad_norm': 10.746353149414062, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.035819072276353836, 'loss_2': 0.004306793212890625, 'loss_3': -15.415260314941406, 'loss_4': 2.2437922954559326, 'epoch': 1.99}
{'loss': 0.0527, 'grad_norm': 13.683581352233887, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.04003116115927696, 'loss_2': 0.0126190185546875, 'loss_3': -15.375072479248047, 'loss_4': 2.322760581970215, 'epoch': 1.99}
{'loss': 0.0575, 'grad_norm': 20.487852096557617, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.05183236673474312, 'loss_2': 0.005680084228515625, 'loss_3': -15.816415786743164, 'loss_4': 3.233224391937256, 'epoch': 2.0}
{'loss': 0.0626, 'grad_norm': 16.27937126159668, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.05267011374235153, 'loss_2': 0.0098876953125, 'loss_3': -15.513197898864746, 'loss_4': 2.150125741958618, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 09:35:25,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:25,373 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [08:52<1:22:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:35:32,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029860906302928925, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.238, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018692128360271454, 'eval_loss_2': 0.01116877794265747, 'eval_loss_3': -18.190160751342773, 'eval_loss_4': 2.263547420501709, 'epoch': 2.01}
{'loss': 0.0456, 'grad_norm': 13.583734512329102, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.040732771158218384, 'loss_2': 0.00482177734375, 'loss_3': -15.555180549621582, 'loss_4': 2.528615951538086, 'epoch': 2.01}
{'loss': 0.0519, 'grad_norm': 11.939985275268555, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.03777024522423744, 'loss_2': 0.01409912109375, 'loss_3': -15.505651473999023, 'loss_4': 2.133530855178833, 'epoch': 2.02}
{'loss': 0.0417, 'grad_norm': 11.265130996704102, 'learning_rate': 2.8e-05, 'loss_1': 0.0325310118496418, 'loss_2': 0.0092010498046875, 'loss_3': -15.339354515075684, 'loss_4': 1.5127009153366089, 'epoch': 2.02}
{'loss': 0.0279, 'grad_norm': 8.605359077453613, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.026412688195705414, 'loss_2': 0.00150299072265625, 'loss_3': -15.500103950500488, 'loss_4': 1.181688666343689, 'epoch': 2.03}
{'loss': 0.0545, 'grad_norm': 11.746187210083008, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.041739653795957565, 'loss_2': 0.0128021240234375, 'loss_3': -15.775643348693848, 'loss_4': 1.9328315258026123, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 09:35:32,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:32,717 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [08:59<1:22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:40,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0341823473572731, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017026221379637718, 'eval_loss_2': 0.017156124114990234, 'eval_loss_3': -18.242828369140625, 'eval_loss_4': 2.013298273086548, 'epoch': 2.03}
{'loss': 0.0673, 'grad_norm': 14.190019607543945, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.04329502955079079, 'loss_2': 0.023956298828125, 'loss_3': -15.463712692260742, 'loss_4': 2.573115348815918, 'epoch': 2.04}
{'loss': 0.1482, 'grad_norm': 21.214387893676758, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.1285741627216339, 'loss_2': 0.019622802734375, 'loss_3': -15.255306243896484, 'loss_4': 2.491960287094116, 'epoch': 2.05}
{'loss': 0.0771, 'grad_norm': 15.378494262695312, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.05014090985059738, 'loss_2': 0.0269927978515625, 'loss_3': -15.392491340637207, 'loss_4': 1.836878776550293, 'epoch': 2.05}
{'loss': 0.0729, 'grad_norm': 12.909289360046387, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.04574999958276749, 'loss_2': 0.027191162109375, 'loss_3': -15.416523933410645, 'loss_4': 2.27614164352417, 'epoch': 2.06}
{'loss': 0.0839, 'grad_norm': 17.746917724609375, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.06338990479707718, 'loss_2': 0.020477294921875, 'loss_3': -15.602075576782227, 'loss_4': 2.6539957523345947, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 09:35:40,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:40,055 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:07<1:22:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:47,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04322342574596405, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018047377467155457, 'eval_loss_2': 0.025176048278808594, 'eval_loss_3': -18.310937881469727, 'eval_loss_4': 2.373782157897949, 'epoch': 2.06}
{'loss': 0.094, 'grad_norm': 23.763343811035156, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.08247195929288864, 'loss_2': 0.01149749755859375, 'loss_3': -15.477483749389648, 'loss_4': 2.462631940841675, 'epoch': 2.07}
{'loss': 0.0812, 'grad_norm': 16.169126510620117, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.061380624771118164, 'loss_2': 0.019866943359375, 'loss_3': -15.521587371826172, 'loss_4': 2.5446300506591797, 'epoch': 2.08}
{'loss': 0.0522, 'grad_norm': 11.579521179199219, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.03761390596628189, 'loss_2': 0.0145416259765625, 'loss_3': -15.747323036193848, 'loss_4': 3.335771083831787, 'epoch': 2.08}
{'loss': 0.0631, 'grad_norm': 14.866436004638672, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.05206146463751793, 'loss_2': 0.0110626220703125, 'loss_3': -15.389366149902344, 'loss_4': 3.122025489807129, 'epoch': 2.09}
{'loss': 0.0559, 'grad_norm': 14.971652030944824, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.047282714396715164, 'loss_2': 0.0086669921875, 'loss_3': -15.595757484436035, 'loss_4': 2.8055548667907715, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 09:35:47,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:47,396 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:14<1:22:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:54,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020363736897706985, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016688544303178787, 'eval_loss_2': 0.0036751925945281982, 'eval_loss_3': -18.297178268432617, 'eval_loss_4': 2.4111571311950684, 'epoch': 2.09}
{'loss': 0.0449, 'grad_norm': 12.085823059082031, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.04432259127497673, 'loss_2': 0.0006036758422851562, 'loss_3': -15.75660228729248, 'loss_4': 2.824451446533203, 'epoch': 2.1}
{'loss': 0.0275, 'grad_norm': 8.096112251281738, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.022766517475247383, 'loss_2': 0.0047607421875, 'loss_3': -15.666998863220215, 'loss_4': 2.76605486869812, 'epoch': 2.1}
{'loss': 0.0277, 'grad_norm': 8.154640197753906, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.02124452218413353, 'loss_2': 0.006481170654296875, 'loss_3': -15.493050575256348, 'loss_4': 2.3876030445098877, 'epoch': 2.11}
{'loss': 0.0332, 'grad_norm': 10.64581298828125, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.03268469497561455, 'loss_2': 0.0005102157592773438, 'loss_3': -15.63363265991211, 'loss_4': 2.9356281757354736, 'epoch': 2.12}
{'loss': 0.0616, 'grad_norm': 15.029539108276367, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.060876861214637756, 'loss_2': 0.0007729530334472656, 'loss_3': -15.42917251586914, 'loss_4': 2.477694034576416, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 09:35:54,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:54,739 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:21<1:22:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:02,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023153487592935562, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018296483904123306, 'eval_loss_2': 0.004857003688812256, 'eval_loss_3': -18.226238250732422, 'eval_loss_4': 2.6462831497192383, 'epoch': 2.12}
{'loss': 0.0559, 'grad_norm': 12.535778045654297, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.05011025071144104, 'loss_2': 0.00574493408203125, 'loss_3': -15.400893211364746, 'loss_4': 2.590604543685913, 'epoch': 2.13}
{'loss': 0.073, 'grad_norm': 20.733558654785156, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.07118835300207138, 'loss_2': 0.0017719268798828125, 'loss_3': -15.383357048034668, 'loss_4': 2.870173215866089, 'epoch': 2.13}
{'loss': 0.0438, 'grad_norm': 14.075432777404785, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.03739460930228233, 'loss_2': 0.006404876708984375, 'loss_3': -15.58465576171875, 'loss_4': 3.093904495239258, 'epoch': 2.14}
{'loss': 0.0384, 'grad_norm': 9.778131484985352, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.03284398466348648, 'loss_2': 0.00557708740234375, 'loss_3': -15.398324966430664, 'loss_4': 3.1138763427734375, 'epoch': 2.15}
{'loss': 0.0428, 'grad_norm': 14.019088745117188, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.04071426764130592, 'loss_2': 0.002063751220703125, 'loss_3': -15.391910552978516, 'loss_4': 2.9720187187194824, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 09:36:02,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:02,077 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:29<1:22:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:09,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022230757400393486, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017070887610316277, 'eval_loss_2': 0.0051598697900772095, 'eval_loss_3': -18.20680046081543, 'eval_loss_4': 2.7454211711883545, 'epoch': 2.15}
{'loss': 0.0305, 'grad_norm': 9.93675708770752, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.029248857870697975, 'loss_2': 0.0012645721435546875, 'loss_3': -15.597883224487305, 'loss_4': 2.5152716636657715, 'epoch': 2.16}
{'loss': 0.1604, 'grad_norm': 18.109500885009766, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.15164758265018463, 'loss_2': 0.008758544921875, 'loss_3': -15.322717666625977, 'loss_4': 2.1842806339263916, 'epoch': 2.16}
{'loss': 0.0562, 'grad_norm': 16.321489334106445, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.048310454934835434, 'loss_2': 0.00787353515625, 'loss_3': -15.559575080871582, 'loss_4': 3.1650195121765137, 'epoch': 2.17}
{'loss': 0.0299, 'grad_norm': 6.8835015296936035, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.017018398270010948, 'loss_2': 0.012847900390625, 'loss_3': -15.547497749328613, 'loss_4': 3.3919262886047363, 'epoch': 2.17}
{'loss': 0.0464, 'grad_norm': 12.221386909484863, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.04161376878619194, 'loss_2': 0.00482177734375, 'loss_3': -15.277254104614258, 'loss_4': 3.199784517288208, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 09:36:09,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:09,425 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:36<1:22:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:16,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026064634323120117, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.815, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018463734537363052, 'eval_loss_2': 0.007600903511047363, 'eval_loss_3': -18.177730560302734, 'eval_loss_4': 3.149203062057495, 'epoch': 2.18}
{'loss': 0.0254, 'grad_norm': 6.63377046585083, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.015762589871883392, 'loss_2': 0.0096435546875, 'loss_3': -15.38747787475586, 'loss_4': 3.1844711303710938, 'epoch': 2.19}
{'loss': 0.0445, 'grad_norm': 11.172452926635742, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.03820665925741196, 'loss_2': 0.006256103515625, 'loss_3': -15.193607330322266, 'loss_4': 3.3722238540649414, 'epoch': 2.19}
{'loss': 0.0373, 'grad_norm': 13.519810676574707, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.03571922704577446, 'loss_2': 0.0016050338745117188, 'loss_3': -15.443073272705078, 'loss_4': 3.495178461074829, 'epoch': 2.2}
{'loss': 0.0682, 'grad_norm': 18.41362190246582, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.05233384296298027, 'loss_2': 0.015869140625, 'loss_3': -15.343046188354492, 'loss_4': 3.1724281311035156, 'epoch': 2.2}
{'loss': 0.049, 'grad_norm': 13.785476684570312, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.04147696495056152, 'loss_2': 0.00751495361328125, 'loss_3': -15.371145248413086, 'loss_4': 3.5445518493652344, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 09:36:16,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:16,769 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:43<1:22:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:24,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032076120376586914, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.775, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01921933703124523, 'eval_loss_2': 0.012856781482696533, 'eval_loss_3': -18.149131774902344, 'eval_loss_4': 3.53214430809021, 'epoch': 2.21}
{'loss': 0.0555, 'grad_norm': 24.27287483215332, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.04923715069890022, 'loss_2': 0.006256103515625, 'loss_3': -15.468587875366211, 'loss_4': 3.7985422611236572, 'epoch': 2.22}
{'loss': 0.056, 'grad_norm': 12.844765663146973, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.038366954773664474, 'loss_2': 0.017669677734375, 'loss_3': -15.177362442016602, 'loss_4': 3.0576884746551514, 'epoch': 2.22}
{'loss': 0.081, 'grad_norm': 20.13609504699707, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.06775692105293274, 'loss_2': 0.0132904052734375, 'loss_3': -15.480367660522461, 'loss_4': 3.1648383140563965, 'epoch': 2.23}
{'loss': 0.0507, 'grad_norm': 12.229162216186523, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.03593740612268448, 'loss_2': 0.01479339599609375, 'loss_3': -15.52467155456543, 'loss_4': 3.547584056854248, 'epoch': 2.23}
{'loss': 0.0444, 'grad_norm': 12.220077514648438, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.03621283546090126, 'loss_2': 0.0082244873046875, 'loss_3': -15.420072555541992, 'loss_4': 3.578341484069824, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 09:36:24,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:24,112 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:51<1:22:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:31,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03160320222377777, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.607, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.023816270753741264, 'eval_loss_2': 0.007786929607391357, 'eval_loss_3': -18.151124954223633, 'eval_loss_4': 3.690495491027832, 'epoch': 2.24}
{'loss': 0.0333, 'grad_norm': 8.84195327758789, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.029288295656442642, 'loss_2': 0.0039825439453125, 'loss_3': -15.291906356811523, 'loss_4': 3.2763519287109375, 'epoch': 2.24}
{'loss': 0.0647, 'grad_norm': 20.31063461303711, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.06215697526931763, 'loss_2': 0.00252532958984375, 'loss_3': -15.32238483428955, 'loss_4': 3.8369994163513184, 'epoch': 2.25}
{'loss': 0.0635, 'grad_norm': 26.767549514770508, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.05957569554448128, 'loss_2': 0.0039215087890625, 'loss_3': -15.56328010559082, 'loss_4': 4.109314441680908, 'epoch': 2.26}
{'loss': 0.0594, 'grad_norm': 20.285404205322266, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.05845263972878456, 'loss_2': 0.0009136199951171875, 'loss_3': -15.49519157409668, 'loss_4': 3.8610727787017822, 'epoch': 2.26}
{'loss': 0.0382, 'grad_norm': 10.010774612426758, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.03307155892252922, 'loss_2': 0.0050811767578125, 'loss_3': -15.413347244262695, 'loss_4': 3.520063877105713, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 09:36:31,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:31,468 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [09:58<1:22:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:38,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.040330298244953156, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.033094100654125214, 'eval_loss_2': 0.007236197590827942, 'eval_loss_3': -18.140708923339844, 'eval_loss_4': 3.712977409362793, 'epoch': 2.27}
{'loss': 0.0468, 'grad_norm': 11.170313835144043, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.04439529404044151, 'loss_2': 0.002391815185546875, 'loss_3': -15.477910041809082, 'loss_4': 3.567953109741211, 'epoch': 2.27}
{'loss': 0.0448, 'grad_norm': 10.397871971130371, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.0385747104883194, 'loss_2': 0.0062255859375, 'loss_3': -15.583684921264648, 'loss_4': 3.768218755722046, 'epoch': 2.28}
{'loss': 0.0521, 'grad_norm': 17.65665626525879, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.0454101599752903, 'loss_2': 0.00667572021484375, 'loss_3': -15.483449935913086, 'loss_4': 3.5467443466186523, 'epoch': 2.28}
{'loss': 0.1369, 'grad_norm': 21.007122039794922, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.1254388391971588, 'loss_2': 0.01149749755859375, 'loss_3': -15.330768585205078, 'loss_4': 3.8833117485046387, 'epoch': 2.29}
{'loss': 0.059, 'grad_norm': 12.37443733215332, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.047269225120544434, 'loss_2': 0.011749267578125, 'loss_3': -15.368574142456055, 'loss_4': 3.316614866256714, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 09:36:38,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:38,816 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:05<1:22:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:46,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03290857374668121, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.026091618463397026, 'eval_loss_2': 0.006816953420639038, 'eval_loss_3': -18.19635009765625, 'eval_loss_4': 3.4372410774230957, 'epoch': 2.3}
{'loss': 0.0457, 'grad_norm': 13.693681716918945, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.03942105919122696, 'loss_2': 0.006290435791015625, 'loss_3': -15.582172393798828, 'loss_4': 3.320328712463379, 'epoch': 2.3}
{'loss': 0.0302, 'grad_norm': 9.506644248962402, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.027891306206583977, 'loss_2': 0.002323150634765625, 'loss_3': -15.277351379394531, 'loss_4': 3.588599681854248, 'epoch': 2.31}
{'loss': 0.0454, 'grad_norm': 13.0006742477417, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.04181439429521561, 'loss_2': 0.003631591796875, 'loss_3': -15.593137741088867, 'loss_4': 3.979752779006958, 'epoch': 2.31}
{'loss': 0.0991, 'grad_norm': 29.597883224487305, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.09464015811681747, 'loss_2': 0.00446319580078125, 'loss_3': -15.2421236038208, 'loss_4': 3.672194480895996, 'epoch': 2.32}
{'loss': 0.0419, 'grad_norm': 11.518207550048828, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.03773956000804901, 'loss_2': 0.00412750244140625, 'loss_3': -15.342998504638672, 'loss_4': 4.033874034881592, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 09:36:46,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:46,170 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:13<1:22:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:53,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02035774663090706, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01581450179219246, 'eval_loss_2': 0.0045432448387146, 'eval_loss_3': -18.278133392333984, 'eval_loss_4': 3.4699490070343018, 'epoch': 2.33}
{'loss': 0.0689, 'grad_norm': 18.046335220336914, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.06338436901569366, 'loss_2': 0.005489349365234375, 'loss_3': -15.689091682434082, 'loss_4': 3.982078790664673, 'epoch': 2.33}
{'loss': 0.0273, 'grad_norm': 7.289690017700195, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.024539288133382797, 'loss_2': 0.0027561187744140625, 'loss_3': -15.399420738220215, 'loss_4': 3.276512384414673, 'epoch': 2.34}
{'loss': 0.0248, 'grad_norm': 7.47984504699707, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.02220452018082142, 'loss_2': 0.0026187896728515625, 'loss_3': -15.495847702026367, 'loss_4': 3.1234047412872314, 'epoch': 2.34}
{'loss': 0.0866, 'grad_norm': 17.958127975463867, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.05978396534919739, 'loss_2': 0.026824951171875, 'loss_3': -15.403963088989258, 'loss_4': 3.6576480865478516, 'epoch': 2.35}
{'loss': 0.0432, 'grad_norm': 7.123754501342773, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.02829979732632637, 'loss_2': 0.014862060546875, 'loss_3': -15.3938570022583, 'loss_4': 3.779147148132324, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 09:36:53,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:53,525 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:20<1:22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:00,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03488462418317795, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017285991460084915, 'eval_loss_2': 0.017598628997802734, 'eval_loss_3': -18.276607513427734, 'eval_loss_4': 3.2938475608825684, 'epoch': 2.35}
{'loss': 0.0694, 'grad_norm': 15.504806518554688, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.05866921693086624, 'loss_2': 0.010711669921875, 'loss_3': -15.441705703735352, 'loss_4': 4.460508346557617, 'epoch': 2.36}
{'loss': 0.0807, 'grad_norm': 15.037020683288574, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.06009279191493988, 'loss_2': 0.020599365234375, 'loss_3': -15.562899589538574, 'loss_4': 3.1116795539855957, 'epoch': 2.37}
{'loss': 0.0519, 'grad_norm': 21.452239990234375, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.04380948841571808, 'loss_2': 0.0081024169921875, 'loss_3': -15.573488235473633, 'loss_4': 3.2541322708129883, 'epoch': 2.37}
{'loss': 0.0466, 'grad_norm': 9.385394096374512, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.033511437475681305, 'loss_2': 0.0131072998046875, 'loss_3': -15.523797035217285, 'loss_4': 3.1965579986572266, 'epoch': 2.38}
{'loss': 0.0624, 'grad_norm': 17.687728881835938, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.05108993873000145, 'loss_2': 0.0113067626953125, 'loss_3': -15.493857383728027, 'loss_4': 3.9449172019958496, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 09:37:00,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:00,862 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:28<1:22:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:08,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026679299771785736, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.098, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.01642443798482418, 'eval_loss_2': 0.010254859924316406, 'eval_loss_3': -18.277042388916016, 'eval_loss_4': 3.011194944381714, 'epoch': 2.38}
{'loss': 0.0437, 'grad_norm': 9.229891777038574, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.030946407467126846, 'loss_2': 0.01279449462890625, 'loss_3': -15.387377738952637, 'loss_4': 4.054606914520264, 'epoch': 2.39}
{'loss': 0.0804, 'grad_norm': 23.072826385498047, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.07401289790868759, 'loss_2': 0.006412506103515625, 'loss_3': -15.412240028381348, 'loss_4': 3.380542755126953, 'epoch': 2.4}
{'loss': 0.0333, 'grad_norm': 10.21925163269043, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.029503686353564262, 'loss_2': 0.0038318634033203125, 'loss_3': -15.633784294128418, 'loss_4': 3.0400142669677734, 'epoch': 2.4}
{'loss': 0.0248, 'grad_norm': 8.935144424438477, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.02304641716182232, 'loss_2': 0.0017118453979492188, 'loss_3': -15.667418479919434, 'loss_4': 2.641042709350586, 'epoch': 2.41}
{'loss': 0.0575, 'grad_norm': 19.49017333984375, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.05419387295842171, 'loss_2': 0.0033111572265625, 'loss_3': -15.524813652038574, 'loss_4': 2.865703582763672, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 09:37:08,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:08,223 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:35<1:22:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:15,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02133062295615673, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.088, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01593184471130371, 'eval_loss_2': 0.005398780107498169, 'eval_loss_3': -18.22684097290039, 'eval_loss_4': 2.633434534072876, 'epoch': 2.41}
{'loss': 0.0332, 'grad_norm': 13.152024269104004, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.024873407557606697, 'loss_2': 0.00836181640625, 'loss_3': -15.669529914855957, 'loss_4': 2.9762516021728516, 'epoch': 2.42}
{'loss': 0.0335, 'grad_norm': 10.394144058227539, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.028136394917964935, 'loss_2': 0.005344390869140625, 'loss_3': -15.509511947631836, 'loss_4': 2.9140195846557617, 'epoch': 2.42}
{'loss': 0.0317, 'grad_norm': 12.919170379638672, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.024472439661622047, 'loss_2': 0.007205963134765625, 'loss_3': -15.608753204345703, 'loss_4': 2.991278648376465, 'epoch': 2.43}
{'loss': 0.0371, 'grad_norm': 12.134346961975098, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.03146113082766533, 'loss_2': 0.00560760498046875, 'loss_3': -15.550912857055664, 'loss_4': 2.867295742034912, 'epoch': 2.44}
{'loss': 0.0533, 'grad_norm': 16.00139045715332, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.043813545256853104, 'loss_2': 0.009521484375, 'loss_3': -15.613231658935547, 'loss_4': 2.2407350540161133, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 09:37:15,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:15,574 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:42<1:21:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:22,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02549411542713642, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017588334158062935, 'eval_loss_2': 0.007905781269073486, 'eval_loss_3': -18.2191219329834, 'eval_loss_4': 2.1735522747039795, 'epoch': 2.44}
{'loss': 0.04, 'grad_norm': 10.384773254394531, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.023832805454730988, 'loss_2': 0.01617431640625, 'loss_3': -15.559934616088867, 'loss_4': 2.384744167327881, 'epoch': 2.45}
{'loss': 0.0342, 'grad_norm': 7.620822429656982, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.026201114058494568, 'loss_2': 0.0079803466796875, 'loss_3': -15.64736557006836, 'loss_4': 1.9661887884140015, 'epoch': 2.45}
{'loss': 0.028, 'grad_norm': 11.665472984313965, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.02793821506202221, 'loss_2': 3.88026237487793e-05, 'loss_3': -15.585956573486328, 'loss_4': 2.1813626289367676, 'epoch': 2.46}
{'loss': 0.0808, 'grad_norm': 22.91290855407715, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.07757136225700378, 'loss_2': 0.00322723388671875, 'loss_3': -15.39428997039795, 'loss_4': 3.0020580291748047, 'epoch': 2.47}
{'loss': 0.0347, 'grad_norm': 12.527449607849121, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.024887632578611374, 'loss_2': 0.00977325439453125, 'loss_3': -15.437638282775879, 'loss_4': 2.4334661960601807, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 09:37:22,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:22,917 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:50<1:21:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:30,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02408602647483349, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.462, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019627777859568596, 'eval_loss_2': 0.004458248615264893, 'eval_loss_3': -18.175296783447266, 'eval_loss_4': 1.8880393505096436, 'epoch': 2.47}
{'loss': 0.0243, 'grad_norm': 6.3228254318237305, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.01945401541888714, 'loss_2': 0.004894256591796875, 'loss_3': -15.483210563659668, 'loss_4': 2.010814905166626, 'epoch': 2.48}
{'loss': 0.0364, 'grad_norm': 15.89857292175293, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.030184803530573845, 'loss_2': 0.006252288818359375, 'loss_3': -15.383865356445312, 'loss_4': 2.10032057762146, 'epoch': 2.48}
{'loss': 0.0473, 'grad_norm': 8.810577392578125, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.03570985794067383, 'loss_2': 0.01155853271484375, 'loss_3': -15.50538444519043, 'loss_4': 1.238809585571289, 'epoch': 2.49}
{'loss': 0.0356, 'grad_norm': 9.022947311401367, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.027655648067593575, 'loss_2': 0.007904052734375, 'loss_3': -15.490143775939941, 'loss_4': 1.3511931896209717, 'epoch': 2.49}
{'loss': 0.1144, 'grad_norm': 29.879117965698242, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.10009676218032837, 'loss_2': 0.0142669677734375, 'loss_3': -15.720312118530273, 'loss_4': 2.3058431148529053, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 09:37:30,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:30,256 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [10:57<1:21:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:37,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022673754021525383, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.018150143325328827, 'eval_loss_2': 0.004523612558841705, 'eval_loss_3': -18.231107711791992, 'eval_loss_4': 1.9025028944015503, 'epoch': 2.5}
{'loss': 0.0462, 'grad_norm': 12.794620513916016, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.04202356934547424, 'loss_2': 0.0041961669921875, 'loss_3': -15.644390106201172, 'loss_4': 2.895030975341797, 'epoch': 2.51}
{'loss': 0.0462, 'grad_norm': 13.431363105773926, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.04075454920530319, 'loss_2': 0.0054779052734375, 'loss_3': -15.62829303741455, 'loss_4': 2.366201639175415, 'epoch': 2.51}
{'loss': 0.0655, 'grad_norm': 14.089694023132324, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.05982980504631996, 'loss_2': 0.005645751953125, 'loss_3': -15.425375938415527, 'loss_4': 1.8204832077026367, 'epoch': 2.52}
{'loss': 0.0917, 'grad_norm': 26.092121124267578, 'learning_rate': 2.75e-05, 'loss_1': 0.08974552154541016, 'loss_2': 0.00197601318359375, 'loss_3': -15.504968643188477, 'loss_4': 2.5490188598632812, 'epoch': 2.52}
{'loss': 0.0659, 'grad_norm': 11.027058601379395, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.058033376932144165, 'loss_2': 0.00787353515625, 'loss_3': -15.598405838012695, 'loss_4': 1.0432747602462769, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 09:37:37,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:37,595 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:04<1:21:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:44,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027834003791213036, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019302552565932274, 'eval_loss_2': 0.008531451225280762, 'eval_loss_3': -18.286128997802734, 'eval_loss_4': 1.9674867391586304, 'epoch': 2.53}
{'loss': 0.0617, 'grad_norm': 13.296947479248047, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.04766005650162697, 'loss_2': 0.0140838623046875, 'loss_3': -15.695877075195312, 'loss_4': 2.399502754211426, 'epoch': 2.53}
{'loss': 0.0414, 'grad_norm': 8.119207382202148, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.030729161575436592, 'loss_2': 0.0106658935546875, 'loss_3': -15.604562759399414, 'loss_4': 3.0815796852111816, 'epoch': 2.54}
{'loss': 0.0759, 'grad_norm': 19.986860275268555, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.06698541343212128, 'loss_2': 0.008880615234375, 'loss_3': -15.744342803955078, 'loss_4': 3.08585786819458, 'epoch': 2.55}
{'loss': 0.0505, 'grad_norm': 16.862993240356445, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.0494101345539093, 'loss_2': 0.0010728836059570312, 'loss_3': -15.624757766723633, 'loss_4': 2.2124791145324707, 'epoch': 2.55}
{'loss': 0.0392, 'grad_norm': 13.562759399414062, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.03679909557104111, 'loss_2': 0.0023860931396484375, 'loss_3': -15.693397521972656, 'loss_4': 1.9348357915878296, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 09:37:44,948 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:44,948 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:12<1:21:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:52,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024431243538856506, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019920572638511658, 'eval_loss_2': 0.004510670900344849, 'eval_loss_3': -18.294654846191406, 'eval_loss_4': 1.7118533849716187, 'epoch': 2.56}
{'loss': 0.0629, 'grad_norm': 15.249871253967285, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.05458902195096016, 'loss_2': 0.00829315185546875, 'loss_3': -15.611063003540039, 'loss_4': 2.1257457733154297, 'epoch': 2.56}
{'loss': 0.049, 'grad_norm': 14.976341247558594, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.04608498513698578, 'loss_2': 0.00289154052734375, 'loss_3': -15.738155364990234, 'loss_4': 1.8693935871124268, 'epoch': 2.57}
{'loss': 0.0729, 'grad_norm': 19.9072322845459, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.0718260407447815, 'loss_2': 0.0011138916015625, 'loss_3': -15.623902320861816, 'loss_4': 1.4768633842468262, 'epoch': 2.58}
{'loss': 0.0918, 'grad_norm': 20.764572143554688, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.07967433333396912, 'loss_2': 0.01214599609375, 'loss_3': -15.830760955810547, 'loss_4': 2.3316237926483154, 'epoch': 2.58}
{'loss': 0.1475, 'grad_norm': 27.498981475830078, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.14742246270179749, 'loss_2': 6.657838821411133e-05, 'loss_3': -15.602407455444336, 'loss_4': 1.2449074983596802, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 09:37:52,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:52,298 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:19<1:21:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:59,641 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02460389956831932, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.944, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018477821722626686, 'eval_loss_2': 0.006126075983047485, 'eval_loss_3': -18.307334899902344, 'eval_loss_4': 1.1287250518798828, 'epoch': 2.59}
{'loss': 0.0408, 'grad_norm': 8.96621036529541, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.03236065059900284, 'loss_2': 0.008453369140625, 'loss_3': -15.770916938781738, 'loss_4': 1.6125414371490479, 'epoch': 2.59}
{'loss': 0.0562, 'grad_norm': 11.47811508178711, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.04874696582555771, 'loss_2': 0.007404327392578125, 'loss_3': -15.760716438293457, 'loss_4': 1.0520448684692383, 'epoch': 2.6}
{'loss': 0.0504, 'grad_norm': 12.557029724121094, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.04464122653007507, 'loss_2': 0.0057220458984375, 'loss_3': -15.691699028015137, 'loss_4': 1.7319672107696533, 'epoch': 2.6}
{'loss': 0.0357, 'grad_norm': 8.923201560974121, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.026404784992337227, 'loss_2': 0.00933074951171875, 'loss_3': -15.785470008850098, 'loss_4': 0.7656048536300659, 'epoch': 2.61}
{'loss': 0.0734, 'grad_norm': 16.428964614868164, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.07069914788007736, 'loss_2': 0.0027103424072265625, 'loss_3': -15.771310806274414, 'loss_4': 1.4124548435211182, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 09:37:59,641 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:59,642 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:26<1:21:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:06,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027852555736899376, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.841, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.023531736806035042, 'eval_loss_2': 0.004320822656154633, 'eval_loss_3': -18.22026252746582, 'eval_loss_4': 1.0193411111831665, 'epoch': 2.62}
{'loss': 0.0414, 'grad_norm': 9.36512279510498, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.030538151040673256, 'loss_2': 0.010833740234375, 'loss_3': -15.41961669921875, 'loss_4': 1.2157015800476074, 'epoch': 2.62}
{'loss': 0.0401, 'grad_norm': 11.468143463134766, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.03795507550239563, 'loss_2': 0.002117156982421875, 'loss_3': -15.757926940917969, 'loss_4': 1.448720932006836, 'epoch': 2.63}
{'loss': 0.0259, 'grad_norm': 6.426538944244385, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.02006826177239418, 'loss_2': 0.00583648681640625, 'loss_3': -15.770727157592773, 'loss_4': 1.2376048564910889, 'epoch': 2.63}
{'loss': 0.0339, 'grad_norm': 11.796191215515137, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.032145388424396515, 'loss_2': 0.0017156600952148438, 'loss_3': -15.707845687866211, 'loss_4': 1.6627814769744873, 'epoch': 2.64}
{'loss': 0.0293, 'grad_norm': 11.08711051940918, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.027077287435531616, 'loss_2': 0.002269744873046875, 'loss_3': -15.635814666748047, 'loss_4': 1.1483474969863892, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 09:38:06,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:06,982 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:34<1:21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:14,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034240782260894775, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.025933919474482536, 'eval_loss_2': 0.00830686092376709, 'eval_loss_3': -18.189830780029297, 'eval_loss_4': 1.6110913753509521, 'epoch': 2.65}
{'loss': 0.0345, 'grad_norm': 8.323700904846191, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.02303890325129032, 'loss_2': 0.01141357421875, 'loss_3': -15.874139785766602, 'loss_4': 1.4480116367340088, 'epoch': 2.65}
{'loss': 0.0423, 'grad_norm': 13.2682523727417, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.03831849247217178, 'loss_2': 0.00402069091796875, 'loss_3': -15.542573928833008, 'loss_4': 1.9877707958221436, 'epoch': 2.66}
{'loss': 0.0353, 'grad_norm': 12.594491958618164, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.030598480254411697, 'loss_2': 0.0046844482421875, 'loss_3': -15.852195739746094, 'loss_4': 2.3157308101654053, 'epoch': 2.66}
{'loss': 0.0656, 'grad_norm': 10.860047340393066, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.05096249654889107, 'loss_2': 0.0146331787109375, 'loss_3': -15.780889511108398, 'loss_4': 2.287297010421753, 'epoch': 2.67}
{'loss': 0.0621, 'grad_norm': 11.212383270263672, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.04057258740067482, 'loss_2': 0.021575927734375, 'loss_3': -15.947798728942871, 'loss_4': 2.7512106895446777, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 09:38:14,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:14,339 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:41<1:21:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:21,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022364601492881775, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.286, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.017679018899798393, 'eval_loss_2': 0.004685580730438232, 'eval_loss_3': -18.232175827026367, 'eval_loss_4': 2.494480848312378, 'epoch': 2.67}
{'loss': 0.0263, 'grad_norm': 6.403220176696777, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.025336267426609993, 'loss_2': 0.000965118408203125, 'loss_3': -15.826841354370117, 'loss_4': 2.736654281616211, 'epoch': 2.68}
{'loss': 0.035, 'grad_norm': 7.664055824279785, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.02413647435605526, 'loss_2': 0.01085662841796875, 'loss_3': -15.845453262329102, 'loss_4': 3.290262222290039, 'epoch': 2.69}
{'loss': 0.0371, 'grad_norm': 8.0563383102417, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.024382682517170906, 'loss_2': 0.01271820068359375, 'loss_3': -15.949411392211914, 'loss_4': 2.7399749755859375, 'epoch': 2.69}
{'loss': 0.0693, 'grad_norm': 14.167967796325684, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.04963250085711479, 'loss_2': 0.019683837890625, 'loss_3': -15.837047576904297, 'loss_4': 2.9501891136169434, 'epoch': 2.7}
{'loss': 0.0799, 'grad_norm': 21.877859115600586, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.06984058767557144, 'loss_2': 0.0100860595703125, 'loss_3': -15.965713500976562, 'loss_4': 2.6989831924438477, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 09:38:21,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:21,688 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:48<1:21:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:29,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029633067548274994, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01711847633123398, 'eval_loss_2': 0.012514591217041016, 'eval_loss_3': -18.234529495239258, 'eval_loss_4': 3.1789655685424805, 'epoch': 2.7}
{'loss': 0.059, 'grad_norm': 15.854700088500977, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.0471976064145565, 'loss_2': 0.0118408203125, 'loss_3': -15.868695259094238, 'loss_4': 3.159980058670044, 'epoch': 2.71}
{'loss': 0.0464, 'grad_norm': 12.45571231842041, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.04163177311420441, 'loss_2': 0.004791259765625, 'loss_3': -15.815978050231934, 'loss_4': 3.356508255004883, 'epoch': 2.72}
{'loss': 0.0556, 'grad_norm': 17.270050048828125, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.047293927520513535, 'loss_2': 0.0083465576171875, 'loss_3': -15.879833221435547, 'loss_4': 2.8828251361846924, 'epoch': 2.72}
{'loss': 0.0487, 'grad_norm': 10.439491271972656, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.041516438126564026, 'loss_2': 0.0072021484375, 'loss_3': -15.99854564666748, 'loss_4': 3.4399313926696777, 'epoch': 2.73}
{'loss': 0.04, 'grad_norm': 8.960906982421875, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.031071269884705544, 'loss_2': 0.0088958740234375, 'loss_3': -15.937873840332031, 'loss_4': 3.505333185195923, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 09:38:29,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:29,036 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [11:56<1:21:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:36,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020298665389418602, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01469600573182106, 'eval_loss_2': 0.005602657794952393, 'eval_loss_3': -18.24323272705078, 'eval_loss_4': 3.6447248458862305, 'epoch': 2.73}
{'loss': 0.15, 'grad_norm': 16.882125854492188, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.1408260017633438, 'loss_2': 0.0091705322265625, 'loss_3': -15.7749662399292, 'loss_4': 4.297632217407227, 'epoch': 2.74}
{'loss': 0.0336, 'grad_norm': 8.054254531860352, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.027321869507431984, 'loss_2': 0.00627899169921875, 'loss_3': -15.82750129699707, 'loss_4': 3.757202625274658, 'epoch': 2.74}
{'loss': 0.0582, 'grad_norm': 12.685132026672363, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.051393575966358185, 'loss_2': 0.00678253173828125, 'loss_3': -15.77856159210205, 'loss_4': 4.16926908493042, 'epoch': 2.75}
{'loss': 0.0561, 'grad_norm': 18.328685760498047, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.05406995490193367, 'loss_2': 0.00202178955078125, 'loss_3': -15.735406875610352, 'loss_4': 3.25913143157959, 'epoch': 2.76}
{'loss': 0.0508, 'grad_norm': 14.724376678466797, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.04988294467329979, 'loss_2': 0.000965118408203125, 'loss_3': -15.770764350891113, 'loss_4': 3.660076141357422, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 09:38:36,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:36,385 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:03<1:21:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:43,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02698163501918316, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.876, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.02165072225034237, 'eval_loss_2': 0.00533091276884079, 'eval_loss_3': -18.218685150146484, 'eval_loss_4': 3.7077088356018066, 'epoch': 2.76}
{'loss': 0.1447, 'grad_norm': 30.892148971557617, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.14276203513145447, 'loss_2': 0.0019292831420898438, 'loss_3': -15.724332809448242, 'loss_4': 3.7156026363372803, 'epoch': 2.77}
{'loss': 0.0771, 'grad_norm': 18.294628143310547, 'learning_rate': 2.725e-05, 'loss_1': 0.07176843285560608, 'loss_2': 0.0053558349609375, 'loss_3': -15.759916305541992, 'loss_4': 4.069158554077148, 'epoch': 2.77}
{'loss': 0.0699, 'grad_norm': 13.017502784729004, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.056147027760744095, 'loss_2': 0.01373291015625, 'loss_3': -15.895366668701172, 'loss_4': 4.565958499908447, 'epoch': 2.78}
{'loss': 0.0707, 'grad_norm': 28.058032989501953, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.06656429916620255, 'loss_2': 0.00417327880859375, 'loss_3': -15.582913398742676, 'loss_4': 3.6084601879119873, 'epoch': 2.78}
{'loss': 0.0441, 'grad_norm': 15.739156723022461, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.036540452390909195, 'loss_2': 0.007598876953125, 'loss_3': -15.982964515686035, 'loss_4': 3.7612929344177246, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 09:38:43,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:43,737 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:10<1:21:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:51,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024306537583470345, 'eval_runtime': 3.8209, 'eval_samples_per_second': 268.0, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.01942390203475952, 'eval_loss_2': 0.004882633686065674, 'eval_loss_3': -18.264087677001953, 'eval_loss_4': 3.726585865020752, 'epoch': 2.79}
{'loss': 0.0366, 'grad_norm': 9.913552284240723, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.03162073343992233, 'loss_2': 0.004978179931640625, 'loss_3': -15.750887870788574, 'loss_4': 3.48337984085083, 'epoch': 2.8}
{'loss': 0.0315, 'grad_norm': 8.517788887023926, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.028240526095032692, 'loss_2': 0.0033054351806640625, 'loss_3': -15.80272388458252, 'loss_4': 4.206482887268066, 'epoch': 2.8}
{'loss': 0.0521, 'grad_norm': 13.899530410766602, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.042590122669935226, 'loss_2': 0.009552001953125, 'loss_3': -15.82541561126709, 'loss_4': 3.9316225051879883, 'epoch': 2.81}
{'loss': 0.0777, 'grad_norm': 21.691621780395508, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.06517884135246277, 'loss_2': 0.012542724609375, 'loss_3': -15.723337173461914, 'loss_4': 4.464929580688477, 'epoch': 2.81}
{'loss': 0.057, 'grad_norm': 19.61822509765625, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.05171599239110947, 'loss_2': 0.00531005859375, 'loss_3': -15.896535873413086, 'loss_4': 4.049394130706787, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 09:38:51,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:51,112 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:18<1:20:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:58,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020025059580802917, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01606033556163311, 'eval_loss_2': 0.003964725881814957, 'eval_loss_3': -18.266796112060547, 'eval_loss_4': 4.244131088256836, 'epoch': 2.82}
{'loss': 0.0465, 'grad_norm': 15.977927207946777, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.044814277440309525, 'loss_2': 0.0016536712646484375, 'loss_3': -15.788609504699707, 'loss_4': 4.765860557556152, 'epoch': 2.83}
{'loss': 0.0476, 'grad_norm': 11.024677276611328, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.03813209757208824, 'loss_2': 0.00946044921875, 'loss_3': -15.758056640625, 'loss_4': 4.030231952667236, 'epoch': 2.83}
{'loss': 0.0286, 'grad_norm': 7.695225715637207, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.026440586894750595, 'loss_2': 0.002155303955078125, 'loss_3': -15.924054145812988, 'loss_4': 4.767586708068848, 'epoch': 2.84}
{'loss': 0.0584, 'grad_norm': 14.13675308227539, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.05650912970304489, 'loss_2': 0.0018978118896484375, 'loss_3': -15.701069831848145, 'loss_4': 4.03090763092041, 'epoch': 2.84}
{'loss': 0.0322, 'grad_norm': 11.634499549865723, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.03207575902342796, 'loss_2': 0.00011426210403442383, 'loss_3': -15.797266006469727, 'loss_4': 4.616191387176514, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 09:38:58,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:58,457 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:25<1:20:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:05,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020738855004310608, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014995618723332882, 'eval_loss_2': 0.005743235349655151, 'eval_loss_3': -18.29426383972168, 'eval_loss_4': 4.756296157836914, 'epoch': 2.85}
{'loss': 0.0824, 'grad_norm': 20.420705795288086, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.07480562478303909, 'loss_2': 0.007633209228515625, 'loss_3': -15.638989448547363, 'loss_4': 4.203948020935059, 'epoch': 2.85}
{'loss': 0.0428, 'grad_norm': 9.17817211151123, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.03372002765536308, 'loss_2': 0.009124755859375, 'loss_3': -15.813825607299805, 'loss_4': 5.055513381958008, 'epoch': 2.86}
{'loss': 0.0739, 'grad_norm': 35.406517028808594, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.07011453807353973, 'loss_2': 0.00379180908203125, 'loss_3': -15.845857620239258, 'loss_4': 5.3129987716674805, 'epoch': 2.87}
{'loss': 0.0465, 'grad_norm': 10.525629997253418, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.034598175436258316, 'loss_2': 0.0118560791015625, 'loss_3': -15.752532005310059, 'loss_4': 4.769493103027344, 'epoch': 2.87}
{'loss': 0.0361, 'grad_norm': 9.48108959197998, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.033208686858415604, 'loss_2': 0.002887725830078125, 'loss_3': -15.68380355834961, 'loss_4': 5.221368312835693, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 09:39:05,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:05,808 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:32<1:20:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:13,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022560331970453262, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.299, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0163252092897892, 'eval_loss_2': 0.0062351226806640625, 'eval_loss_3': -18.292556762695312, 'eval_loss_4': 5.283219337463379, 'epoch': 2.88}
{'loss': 0.0393, 'grad_norm': 12.432282447814941, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.03740528225898743, 'loss_2': 0.0018663406372070312, 'loss_3': -15.768097877502441, 'loss_4': 5.2645745277404785, 'epoch': 2.88}
{'loss': 0.0334, 'grad_norm': 8.483602523803711, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.026528501883149147, 'loss_2': 0.00689697265625, 'loss_3': -15.75857925415039, 'loss_4': 5.805360317230225, 'epoch': 2.89}
{'loss': 0.0387, 'grad_norm': 11.981912612915039, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.030391911044716835, 'loss_2': 0.008270263671875, 'loss_3': -15.64913558959961, 'loss_4': 5.131444454193115, 'epoch': 2.9}
{'loss': 0.0602, 'grad_norm': 19.294361114501953, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.055683866143226624, 'loss_2': 0.00450897216796875, 'loss_3': -15.785043716430664, 'loss_4': 5.259160995483398, 'epoch': 2.9}
{'loss': 0.0307, 'grad_norm': 9.440961837768555, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.028674207627773285, 'loss_2': 0.001979827880859375, 'loss_3': -15.6678466796875, 'loss_4': 5.626520156860352, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 09:39:13,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:13,168 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:40<1:20:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:20,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01819758117198944, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.442, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.013482659123837948, 'eval_loss_2': 0.0047149211168289185, 'eval_loss_3': -18.269569396972656, 'eval_loss_4': 4.602057456970215, 'epoch': 2.91}
{'loss': 0.0487, 'grad_norm': 14.950238227844238, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.04159624129533768, 'loss_2': 0.007076263427734375, 'loss_3': -15.701051712036133, 'loss_4': 4.484610557556152, 'epoch': 2.91}
{'loss': 0.0337, 'grad_norm': 8.855770111083984, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.0293634831905365, 'loss_2': 0.00434112548828125, 'loss_3': -15.773032188415527, 'loss_4': 4.524328231811523, 'epoch': 2.92}
{'loss': 0.0432, 'grad_norm': 10.669289588928223, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.04168917238712311, 'loss_2': 0.0014781951904296875, 'loss_3': -15.861385345458984, 'loss_4': 3.5714094638824463, 'epoch': 2.92}
{'loss': 0.0545, 'grad_norm': 17.871841430664062, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.041968509554862976, 'loss_2': 0.01251220703125, 'loss_3': -15.754076957702637, 'loss_4': 3.7681963443756104, 'epoch': 2.93}
{'loss': 0.0278, 'grad_norm': 9.279779434204102, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.026397764682769775, 'loss_2': 0.0013904571533203125, 'loss_3': -15.664775848388672, 'loss_4': 3.876950740814209, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 09:39:20,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:20,528 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [12:47<1:20:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:27,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018518982455134392, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.545, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01335807703435421, 'eval_loss_2': 0.005160905420780182, 'eval_loss_3': -18.23699188232422, 'eval_loss_4': 3.0826072692871094, 'epoch': 2.94}
{'loss': 0.0456, 'grad_norm': 12.71887493133545, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.04074528068304062, 'loss_2': 0.00489044189453125, 'loss_3': -15.686796188354492, 'loss_4': 3.0147042274475098, 'epoch': 2.94}
{'loss': 0.0284, 'grad_norm': 10.574508666992188, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.02470618300139904, 'loss_2': 0.00370025634765625, 'loss_3': -15.745555877685547, 'loss_4': 3.0425734519958496, 'epoch': 2.95}
{'loss': 0.0536, 'grad_norm': 25.734683990478516, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.04856857284903526, 'loss_2': 0.0050048828125, 'loss_3': -15.627979278564453, 'loss_4': 2.986294984817505, 'epoch': 2.95}
{'loss': 0.052, 'grad_norm': 17.17156982421875, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.047228023409843445, 'loss_2': 0.00482177734375, 'loss_3': -15.484875679016113, 'loss_4': 1.6959682703018188, 'epoch': 2.96}
{'loss': 0.0646, 'grad_norm': 25.19301414489746, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.05596417188644409, 'loss_2': 0.00865936279296875, 'loss_3': -15.49921989440918, 'loss_4': 2.9213790893554688, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 09:39:27,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:27,870 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [12:54<1:19:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:39:35,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022188227623701096, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.632, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012665966525673866, 'eval_loss_2': 0.00952225923538208, 'eval_loss_3': -18.177223205566406, 'eval_loss_4': 2.0129034519195557, 'epoch': 2.97}
{'loss': 0.0327, 'grad_norm': 8.132355690002441, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.024545781314373016, 'loss_2': 0.0081787109375, 'loss_3': -15.686301231384277, 'loss_4': 2.623889923095703, 'epoch': 2.97}
{'loss': 0.0337, 'grad_norm': 7.302563190460205, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.02104075439274311, 'loss_2': 0.012664794921875, 'loss_3': -15.749611854553223, 'loss_4': 2.378559112548828, 'epoch': 2.98}
{'loss': 0.032, 'grad_norm': 10.96617317199707, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.023561684414744377, 'loss_2': 0.0084686279296875, 'loss_3': -15.69884967803955, 'loss_4': 2.6075332164764404, 'epoch': 2.98}
{'loss': 0.0715, 'grad_norm': 18.765275955200195, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.06551604717969894, 'loss_2': 0.00601959228515625, 'loss_3': -15.790853500366211, 'loss_4': 1.4613392353057861, 'epoch': 2.99}
{'loss': 0.0306, 'grad_norm': 9.692509651184082, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.02724687196314335, 'loss_2': 0.00339508056640625, 'loss_3': -15.837472915649414, 'loss_4': 1.8891663551330566, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 09:39:35,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:35,190 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [12:58<1:19:49,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 09:39:38,991 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515
[INFO|configuration_utils.py:420] 2025-01-21 09:39:38,993 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515/config.json                                                                              
{'eval_loss': 0.016675958409905434, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012661376968026161, 'eval_loss_2': 0.0040145814418792725, 'eval_loss_3': -18.20001220703125, 'eval_loss_4': 1.6393376588821411, 'epoch': 2.99}
[INFO|modeling_utils.py:2988] 2025-01-21 09:39:39,472 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:39:39,473 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:39:39,473 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:39:40,282 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-330] due to args.save_total_limit
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:03<1:26:11,  1.11s/it][INFO|trainer.py:4226] 2025-01-21 09:39:43,614 >>
{'loss': 0.0097, 'grad_norm': 7.058624267578125, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.007428065873682499, 'loss_2': 0.0022296905517578125, 'loss_3': -15.649643898010254, 'loss_4': 1.8076578378677368, 'epoch': 3.0}
{'loss': 0.0225, 'grad_norm': 10.14653205871582, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.022309377789497375, 'loss_2': 0.00015246868133544922, 'loss_3': -15.778200149536133, 'loss_4': 1.535719394683838, 'epoch': 3.01}
{'loss': 0.033, 'grad_norm': 10.203495025634766, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.02879248932003975, 'loss_2': 0.0042266845703125, 'loss_3': -15.619565963745117, 'loss_4': 1.8312695026397705, 'epoch': 3.01}
{'loss': 0.0334, 'grad_norm': 7.88515567779541, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.023653889074921608, 'loss_2': 0.009735107421875, 'loss_3': -15.813363075256348, 'loss_4': 0.7336224317550659, 'epoch': 3.02}
{'loss': 0.1031, 'grad_norm': 32.299537658691406, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.1013791412115097, 'loss_2': 0.001750946044921875, 'loss_3': -15.58980941772461, 'loss_4': 1.4319136142730713, 'epoch': 3.02}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:39:43,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:43,615 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:10<1:21:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:39:50,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017677128314971924, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013246940448880196, 'eval_loss_2': 0.0044301897287368774, 'eval_loss_3': -18.16518783569336, 'eval_loss_4': 1.0789365768432617, 'epoch': 3.02}
{'loss': 0.0384, 'grad_norm': 13.647902488708496, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.03492440655827522, 'loss_2': 0.0034465789794921875, 'loss_3': -15.571830749511719, 'loss_4': 1.2692265510559082, 'epoch': 3.03}
{'loss': 0.0573, 'grad_norm': 16.85251235961914, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.05131938308477402, 'loss_2': 0.0059814453125, 'loss_3': -15.71117877960205, 'loss_4': 0.8628778457641602, 'epoch': 3.03}
{'loss': 0.0354, 'grad_norm': 10.618263244628906, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.030034493654966354, 'loss_2': 0.00537109375, 'loss_3': -15.656166076660156, 'loss_4': 1.5538688898086548, 'epoch': 3.04}
{'loss': 0.0287, 'grad_norm': 14.474019050598145, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.024004587903618813, 'loss_2': 0.004669189453125, 'loss_3': -15.788705825805664, 'loss_4': 1.250069260597229, 'epoch': 3.05}
{'loss': 0.042, 'grad_norm': 12.746994972229004, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.039083946496248245, 'loss_2': 0.002956390380859375, 'loss_3': -15.49822998046875, 'loss_4': 0.9971861839294434, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 09:39:50,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:50,956 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:18<1:20:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:58,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02291399985551834, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01616538129746914, 'eval_loss_2': 0.006748616695404053, 'eval_loss_3': -18.140729904174805, 'eval_loss_4': 0.5701791644096375, 'epoch': 3.05}
{'loss': 0.0468, 'grad_norm': 18.403175354003906, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.04251003637909889, 'loss_2': 0.004241943359375, 'loss_3': -15.742208480834961, 'loss_4': 1.1231586933135986, 'epoch': 3.06}
{'loss': 0.0245, 'grad_norm': 10.471171379089355, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.021939920261502266, 'loss_2': 0.0025615692138671875, 'loss_3': -15.475017547607422, 'loss_4': 0.35935938358306885, 'epoch': 3.06}
{'loss': 0.0737, 'grad_norm': 16.776365280151367, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.07141635566949844, 'loss_2': 0.002254486083984375, 'loss_3': -15.726469039916992, 'loss_4': 0.9419030547142029, 'epoch': 3.07}
{'loss': 0.0192, 'grad_norm': 6.782956600189209, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.015046331100165844, 'loss_2': 0.0041046142578125, 'loss_3': -15.863615036010742, 'loss_4': 0.31280580163002014, 'epoch': 3.08}
{'loss': 0.0333, 'grad_norm': 8.289003372192383, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.02410813421010971, 'loss_2': 0.0092010498046875, 'loss_3': -15.646068572998047, 'loss_4': 0.9510362148284912, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 09:39:58,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:58,308 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:25<1:19:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:05,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02716616354882717, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.082, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.023112526163458824, 'eval_loss_2': 0.004053637385368347, 'eval_loss_3': -18.087112426757812, 'eval_loss_4': 0.7728974223136902, 'epoch': 3.08}
{'loss': 0.0449, 'grad_norm': 15.294761657714844, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.043027665466070175, 'loss_2': 0.001888275146484375, 'loss_3': -15.755048751831055, 'loss_4': 1.0465028285980225, 'epoch': 3.09}
{'loss': 0.0239, 'grad_norm': 10.95964241027832, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.020382581278681755, 'loss_2': 0.00347900390625, 'loss_3': -15.68840217590332, 'loss_4': 0.565414309501648, 'epoch': 3.09}
{'loss': 0.0618, 'grad_norm': 19.575754165649414, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.060929350554943085, 'loss_2': 0.0008449554443359375, 'loss_3': -15.622583389282227, 'loss_4': 0.8813915848731995, 'epoch': 3.1}
{'loss': 0.0229, 'grad_norm': 10.190706253051758, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.02232496626675129, 'loss_2': 0.0005950927734375, 'loss_3': -15.719522476196289, 'loss_4': 1.5521316528320312, 'epoch': 3.1}
{'loss': 0.0231, 'grad_norm': 10.882509231567383, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.0217274222522974, 'loss_2': 0.0013570785522460938, 'loss_3': -15.83681583404541, 'loss_4': 0.906452476978302, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 09:40:05,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:05,638 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:32<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:12,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026607852429151535, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.961, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02113684080541134, 'eval_loss_2': 0.0054710134863853455, 'eval_loss_3': -18.09903907775879, 'eval_loss_4': 1.2793395519256592, 'epoch': 3.11}
{'loss': 0.0584, 'grad_norm': 22.015968322753906, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.040582768619060516, 'loss_2': 0.0178070068359375, 'loss_3': -15.689382553100586, 'loss_4': 2.185157299041748, 'epoch': 3.12}
{'loss': 0.0215, 'grad_norm': 7.448241233825684, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.016965247690677643, 'loss_2': 0.00457763671875, 'loss_3': -15.676170349121094, 'loss_4': 0.9180704355239868, 'epoch': 3.12}
{'loss': 0.0463, 'grad_norm': 12.068646430969238, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.03053436614573002, 'loss_2': 0.0157470703125, 'loss_3': -15.869399070739746, 'loss_4': 2.1287193298339844, 'epoch': 3.13}
{'loss': 0.0365, 'grad_norm': 6.862986087799072, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.019362224265933037, 'loss_2': 0.0171051025390625, 'loss_3': -15.87134838104248, 'loss_4': 2.375450611114502, 'epoch': 3.13}
{'loss': 0.0207, 'grad_norm': 6.654489994049072, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.015407342463731766, 'loss_2': 0.00531768798828125, 'loss_3': -15.832315444946289, 'loss_4': 2.3965563774108887, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 09:40:12,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:12,980 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:40<1:19:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:20,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020735569298267365, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.854, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01474738959223032, 'eval_loss_2': 0.005988180637359619, 'eval_loss_3': -18.15098762512207, 'eval_loss_4': 2.3756520748138428, 'epoch': 3.14}
{'loss': 0.0295, 'grad_norm': 8.703489303588867, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.01599626988172531, 'loss_2': 0.0134735107421875, 'loss_3': -15.703208923339844, 'loss_4': 2.4900665283203125, 'epoch': 3.15}
{'loss': 0.0222, 'grad_norm': 6.9323906898498535, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.01555553637444973, 'loss_2': 0.006622314453125, 'loss_3': -15.885939598083496, 'loss_4': 2.952517509460449, 'epoch': 3.15}
{'loss': 0.0268, 'grad_norm': 8.134331703186035, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.02625950425863266, 'loss_2': 0.0005054473876953125, 'loss_3': -15.761865615844727, 'loss_4': 3.356822967529297, 'epoch': 3.16}
{'loss': 0.0378, 'grad_norm': 10.294875144958496, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.02398230880498886, 'loss_2': 0.013824462890625, 'loss_3': -15.73049545288086, 'loss_4': 3.2477807998657227, 'epoch': 3.16}
{'loss': 0.0494, 'grad_norm': 9.624844551086426, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.028075149282813072, 'loss_2': 0.0213623046875, 'loss_3': -15.770111083984375, 'loss_4': 2.8926608562469482, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 09:40:20,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:20,319 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:47<1:19:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:27,672 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035660140216350555, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.615, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011795391328632832, 'eval_loss_2': 0.02386474609375, 'eval_loss_3': -18.191181182861328, 'eval_loss_4': 3.0338170528411865, 'epoch': 3.17}
{'loss': 0.0511, 'grad_norm': 10.524409294128418, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.032008297741413116, 'loss_2': 0.0190582275390625, 'loss_3': -15.892641067504883, 'loss_4': 2.8964762687683105, 'epoch': 3.17}
{'loss': 0.0667, 'grad_norm': 21.068790435791016, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.0459066778421402, 'loss_2': 0.020782470703125, 'loss_3': -15.746715545654297, 'loss_4': 3.6017911434173584, 'epoch': 3.18}
{'loss': 0.0405, 'grad_norm': 7.199054718017578, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.02063213288784027, 'loss_2': 0.0198974609375, 'loss_3': -15.649480819702148, 'loss_4': 3.3918399810791016, 'epoch': 3.19}
{'loss': 0.0328, 'grad_norm': 9.550126075744629, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.02177821472287178, 'loss_2': 0.0110626220703125, 'loss_3': -15.872101783752441, 'loss_4': 3.9984421730041504, 'epoch': 3.19}
{'loss': 0.0381, 'grad_norm': 6.574538230895996, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.021989326924085617, 'loss_2': 0.016143798828125, 'loss_3': -15.712557792663574, 'loss_4': 4.031106472015381, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 09:40:27,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:27,672 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [13:54<1:19:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:35,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01917397230863571, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011569253169000149, 'eval_loss_2': 0.007604718208312988, 'eval_loss_3': -18.188859939575195, 'eval_loss_4': 3.5949978828430176, 'epoch': 3.2}
{'loss': 0.0206, 'grad_norm': 7.4109206199646, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.01962493732571602, 'loss_2': 0.0009713172912597656, 'loss_3': -15.79788589477539, 'loss_4': 4.836136817932129, 'epoch': 3.2}
{'loss': 0.0227, 'grad_norm': 6.501256465911865, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.014007915742695332, 'loss_2': 0.0087127685546875, 'loss_3': -15.673951148986816, 'loss_4': 4.13068962097168, 'epoch': 3.21}
{'loss': 0.051, 'grad_norm': 11.41254711151123, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.046606339514255524, 'loss_2': 0.0044403076171875, 'loss_3': -15.78598690032959, 'loss_4': 3.9554991722106934, 'epoch': 3.22}
{'loss': 0.0223, 'grad_norm': 8.943330764770508, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.020859068259596825, 'loss_2': 0.001461029052734375, 'loss_3': -15.976902961730957, 'loss_4': 3.903164863586426, 'epoch': 3.22}
{'loss': 0.0458, 'grad_norm': 17.63457679748535, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.03506391867995262, 'loss_2': 0.01068878173828125, 'loss_3': -15.806894302368164, 'loss_4': 3.3335297107696533, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 09:40:35,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:35,030 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:02<1:19:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:42,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02374800480902195, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01394578255712986, 'eval_loss_2': 0.00980222225189209, 'eval_loss_3': -18.151344299316406, 'eval_loss_4': 3.366428852081299, 'epoch': 3.23}
{'loss': 0.0386, 'grad_norm': 10.718798637390137, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.030961355194449425, 'loss_2': 0.00766754150390625, 'loss_3': -15.46631145477295, 'loss_4': 3.872131824493408, 'epoch': 3.23}
{'loss': 0.022, 'grad_norm': 6.360532760620117, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.016458936035633087, 'loss_2': 0.00557708740234375, 'loss_3': -15.678266525268555, 'loss_4': 3.107907772064209, 'epoch': 3.24}
{'loss': 0.0358, 'grad_norm': 7.599057674407959, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.023624474182724953, 'loss_2': 0.01215362548828125, 'loss_3': -15.755266189575195, 'loss_4': 3.719496250152588, 'epoch': 3.24}
{'loss': 0.1132, 'grad_norm': 21.494930267333984, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.11275690048933029, 'loss_2': 0.00039386749267578125, 'loss_3': -15.392202377319336, 'loss_4': 3.332048177719116, 'epoch': 3.25}
{'loss': 0.0268, 'grad_norm': 12.69361686706543, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.023832006379961967, 'loss_2': 0.00296783447265625, 'loss_3': -15.68252182006836, 'loss_4': 3.55532169342041, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 09:40:42,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:42,385 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:09<1:19:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:49,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019634079188108444, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014434349723160267, 'eval_loss_2': 0.005199730396270752, 'eval_loss_3': -18.11914825439453, 'eval_loss_4': 3.0255956649780273, 'epoch': 3.26}
{'loss': 0.0255, 'grad_norm': 7.6886138916015625, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.019028712064027786, 'loss_2': 0.00649261474609375, 'loss_3': -15.604432106018066, 'loss_4': 3.4986608028411865, 'epoch': 3.26}
{'loss': 0.0155, 'grad_norm': 7.280444622039795, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.013503559865057468, 'loss_2': 0.001995086669921875, 'loss_3': -15.603677749633789, 'loss_4': 2.954582929611206, 'epoch': 3.27}
{'loss': 0.0516, 'grad_norm': 11.50178050994873, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.04302671179175377, 'loss_2': 0.008544921875, 'loss_3': -15.529090881347656, 'loss_4': 2.9827771186828613, 'epoch': 3.27}
{'loss': 0.0291, 'grad_norm': 12.579380989074707, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.027925752103328705, 'loss_2': 0.0011501312255859375, 'loss_3': -15.718377113342285, 'loss_4': 3.51157283782959, 'epoch': 3.28}
{'loss': 0.0505, 'grad_norm': 15.484617233276367, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.04996960610151291, 'loss_2': 0.0005283355712890625, 'loss_3': -15.234457015991211, 'loss_4': 2.5818588733673096, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 09:40:49,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:49,730 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:16<1:19:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:57,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020454201847314835, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.017, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014150177128612995, 'eval_loss_2': 0.006304025650024414, 'eval_loss_3': -18.114757537841797, 'eval_loss_4': 2.550718307495117, 'epoch': 3.28}
{'loss': 0.0506, 'grad_norm': 17.960540771484375, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.04880187660455704, 'loss_2': 0.0017566680908203125, 'loss_3': -15.505843162536621, 'loss_4': 2.976114273071289, 'epoch': 3.29}
{'loss': 0.0632, 'grad_norm': 16.5694580078125, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.06286339461803436, 'loss_2': 0.0003418922424316406, 'loss_3': -15.62387752532959, 'loss_4': 2.1369807720184326, 'epoch': 3.3}
{'loss': 0.0287, 'grad_norm': 5.797613143920898, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.014879152178764343, 'loss_2': 0.0138092041015625, 'loss_3': -15.652559280395508, 'loss_4': 3.3165664672851562, 'epoch': 3.3}
{'loss': 0.027, 'grad_norm': 9.344483375549316, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.024188697338104248, 'loss_2': 0.00278472900390625, 'loss_3': -15.62009048461914, 'loss_4': 2.156805992126465, 'epoch': 3.31}
{'loss': 0.0379, 'grad_norm': 12.032806396484375, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.03390800952911377, 'loss_2': 0.00399017333984375, 'loss_3': -15.54946517944336, 'loss_4': 2.821523666381836, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 09:40:57,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:57,068 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:24<1:19:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:04,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016823744401335716, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013785664923489094, 'eval_loss_2': 0.003038078546524048, 'eval_loss_3': -18.107526779174805, 'eval_loss_4': 2.5548369884490967, 'epoch': 3.31}
{'loss': 0.054, 'grad_norm': 15.225180625915527, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.05369396507740021, 'loss_2': 0.00028896331787109375, 'loss_3': -15.431629180908203, 'loss_4': 3.407076597213745, 'epoch': 3.32}
{'loss': 0.019, 'grad_norm': 7.262367248535156, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.01868816651403904, 'loss_2': 0.0003402233123779297, 'loss_3': -15.527852058410645, 'loss_4': 2.62781023979187, 'epoch': 3.33}
{'loss': 0.0328, 'grad_norm': 10.316502571105957, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.02303403802216053, 'loss_2': 0.009735107421875, 'loss_3': -15.546525001525879, 'loss_4': 2.9634053707122803, 'epoch': 3.33}
{'loss': 0.0713, 'grad_norm': 30.26957130432129, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.06139674410223961, 'loss_2': 0.00989532470703125, 'loss_3': -15.509547233581543, 'loss_4': 2.9394302368164062, 'epoch': 3.34}
{'loss': 0.0419, 'grad_norm': 10.992225646972656, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.02794225513935089, 'loss_2': 0.0139312744140625, 'loss_3': -15.839441299438477, 'loss_4': 3.153036594390869, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 09:41:04,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:04,417 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:31<1:19:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:11,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022547319531440735, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.755, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013296201825141907, 'eval_loss_2': 0.009251117706298828, 'eval_loss_3': -18.07131576538086, 'eval_loss_4': 2.798330068588257, 'epoch': 3.34}
{'loss': 0.057, 'grad_norm': 15.294780731201172, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.04357166960835457, 'loss_2': 0.013458251953125, 'loss_3': -15.42095947265625, 'loss_4': 3.4233598709106445, 'epoch': 3.35}
{'loss': 0.0477, 'grad_norm': 9.021491050720215, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.029726769775152206, 'loss_2': 0.0179443359375, 'loss_3': -15.274149894714355, 'loss_4': 3.155179977416992, 'epoch': 3.35}
{'loss': 0.0415, 'grad_norm': 27.619211196899414, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.03870949521660805, 'loss_2': 0.0028362274169921875, 'loss_3': -15.518834114074707, 'loss_4': 2.7136435508728027, 'epoch': 3.36}
{'loss': 0.0455, 'grad_norm': 13.98878288269043, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.044951431453228, 'loss_2': 0.0005102157592773438, 'loss_3': -15.466033935546875, 'loss_4': 3.1205685138702393, 'epoch': 3.37}
{'loss': 0.0549, 'grad_norm': 16.305355072021484, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.046696845442056656, 'loss_2': 0.00824737548828125, 'loss_3': -15.596023559570312, 'loss_4': 3.5774168968200684, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 09:41:11,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:11,779 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:38<1:19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:19,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017475701868534088, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.223, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.012371590360999107, 'eval_loss_2': 0.0051041096448898315, 'eval_loss_3': -18.14842414855957, 'eval_loss_4': 3.053194284439087, 'epoch': 3.37}
{'loss': 0.0588, 'grad_norm': 15.117864608764648, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.049556367099285126, 'loss_2': 0.00925445556640625, 'loss_3': -15.397281646728516, 'loss_4': 3.4561691284179688, 'epoch': 3.38}
{'loss': 0.098, 'grad_norm': 23.810287475585938, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.08983100205659866, 'loss_2': 0.00818634033203125, 'loss_3': -15.522834777832031, 'loss_4': 3.3084428310394287, 'epoch': 3.38}
{'loss': 0.0416, 'grad_norm': 10.255244255065918, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.03681432455778122, 'loss_2': 0.0047454833984375, 'loss_3': -15.627342224121094, 'loss_4': 3.50014591217041, 'epoch': 3.39}
{'loss': 0.0276, 'grad_norm': 8.194225311279297, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.024603070691227913, 'loss_2': 0.003025054931640625, 'loss_3': -15.638503074645996, 'loss_4': 3.343996047973633, 'epoch': 3.4}
{'loss': 0.035, 'grad_norm': 11.162405967712402, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.033927541226148605, 'loss_2': 0.0010662078857421875, 'loss_3': -15.6094331741333, 'loss_4': 3.781479835510254, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 09:41:19,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:19,140 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:42<1:19:14,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:41:22,939 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585
[INFO|configuration_utils.py:420] 2025-01-21 09:41:22,940 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585/config.json                                                                              
{'eval_loss': 0.01543731614947319, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012442576698958874, 'eval_loss_2': 0.002994738519191742, 'eval_loss_3': -18.190956115722656, 'eval_loss_4': 3.1736667156219482, 'epoch': 3.4}
[INFO|modeling_utils.py:2988] 2025-01-21 09:41:23,440 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:41:23,441 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:41:23,441 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:41:24,261 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-515] due to args.save_total_limit
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:47<1:26:45,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:41:27,896 >>
{'loss': 0.0444, 'grad_norm': 9.442447662353516, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.03392908722162247, 'loss_2': 0.0104522705078125, 'loss_3': -15.797225952148438, 'loss_4': 3.60158634185791, 'epoch': 3.41}
{'loss': 0.0474, 'grad_norm': 14.464054107666016, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.036821383982896805, 'loss_2': 0.01056671142578125, 'loss_3': -15.821884155273438, 'loss_4': 3.9269959926605225, 'epoch': 3.41}
{'loss': 0.0492, 'grad_norm': 11.976190567016602, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.03569246828556061, 'loss_2': 0.01348876953125, 'loss_3': -15.477432250976562, 'loss_4': 3.0052502155303955, 'epoch': 3.42}
{'loss': 0.0585, 'grad_norm': 19.688596725463867, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.050174180418252945, 'loss_2': 0.00836181640625, 'loss_3': -15.666196823120117, 'loss_4': 3.6897387504577637, 'epoch': 3.42}
{'loss': 0.0428, 'grad_norm': 9.515568733215332, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.027284594252705574, 'loss_2': 0.0155029296875, 'loss_3': -15.49886703491211, 'loss_4': 2.726390838623047, 'epoch': 3.43}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:41:27,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:27,896 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [14:55<1:20:14,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:41:35,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020755454897880554, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01109806913882494, 'eval_loss_2': 0.00965738296508789, 'eval_loss_3': -18.183059692382812, 'eval_loss_4': 2.600778818130493, 'epoch': 3.43}
{'loss': 0.05, 'grad_norm': 18.66634178161621, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.0418623611330986, 'loss_2': 0.0081329345703125, 'loss_3': -15.737189292907715, 'loss_4': 2.791228771209717, 'epoch': 3.44}
{'loss': 0.0185, 'grad_norm': 6.577267169952393, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.015050302259624004, 'loss_2': 0.0034656524658203125, 'loss_3': -15.786211967468262, 'loss_4': 2.6536190509796143, 'epoch': 3.44}
{'loss': 0.0285, 'grad_norm': 9.985249519348145, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.026477543637156487, 'loss_2': 0.002063751220703125, 'loss_3': -15.716222763061523, 'loss_4': 2.5219597816467285, 'epoch': 3.45}
{'loss': 0.0387, 'grad_norm': 18.187088012695312, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.037287596613168716, 'loss_2': 0.0013904571533203125, 'loss_3': -15.54198932647705, 'loss_4': 2.7043795585632324, 'epoch': 3.45}
{'loss': 0.0188, 'grad_norm': 7.143504619598389, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.017302172258496284, 'loss_2': 0.001476287841796875, 'loss_3': -15.76404094696045, 'loss_4': 2.9032070636749268, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 09:41:35,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:35,246 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:02<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:42,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016102056950330734, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.909, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010527709499001503, 'eval_loss_2': 0.005574345588684082, 'eval_loss_3': -18.21741485595703, 'eval_loss_4': 2.3159518241882324, 'epoch': 3.46}
{'loss': 0.0223, 'grad_norm': 8.398913383483887, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.01915750652551651, 'loss_2': 0.00318145751953125, 'loss_3': -15.679461479187012, 'loss_4': 1.7325551509857178, 'epoch': 3.47}
{'loss': 0.0398, 'grad_norm': 13.20006275177002, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.025701193138957024, 'loss_2': 0.014068603515625, 'loss_3': -15.602497100830078, 'loss_4': 2.8956642150878906, 'epoch': 3.47}
{'loss': 0.0665, 'grad_norm': 27.40895652770996, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.054538823664188385, 'loss_2': 0.011962890625, 'loss_3': -15.614267349243164, 'loss_4': 3.179417610168457, 'epoch': 3.48}
{'loss': 0.0907, 'grad_norm': 22.347003936767578, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.081025131046772, 'loss_2': 0.0096282958984375, 'loss_3': -15.535536766052246, 'loss_4': 2.6271119117736816, 'epoch': 3.48}
{'loss': 0.0343, 'grad_norm': 7.403045654296875, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.017851492390036583, 'loss_2': 0.0164794921875, 'loss_3': -15.715152740478516, 'loss_4': 2.8859457969665527, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 09:41:42,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:42,579 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:09<1:18:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:49,919 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019265322014689445, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010620741173624992, 'eval_loss_2': 0.008644580841064453, 'eval_loss_3': -18.246889114379883, 'eval_loss_4': 2.5863070487976074, 'epoch': 3.49}
{'loss': 0.0274, 'grad_norm': 6.730865955352783, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.015366729348897934, 'loss_2': 0.0120086669921875, 'loss_3': -15.94261360168457, 'loss_4': 2.7248942852020264, 'epoch': 3.49}
{'loss': 0.0395, 'grad_norm': 12.20290470123291, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.038223542273044586, 'loss_2': 0.0012969970703125, 'loss_3': -15.564191818237305, 'loss_4': 3.409759044647217, 'epoch': 3.5}
{'loss': 0.0446, 'grad_norm': 15.112763404846191, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.039678461849689484, 'loss_2': 0.004913330078125, 'loss_3': -15.737553596496582, 'loss_4': 2.637680768966675, 'epoch': 3.51}
{'loss': 0.0131, 'grad_norm': 6.146099090576172, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.010913209058344364, 'loss_2': 0.00222015380859375, 'loss_3': -15.752680778503418, 'loss_4': 2.782698631286621, 'epoch': 3.51}
{'loss': 0.0194, 'grad_norm': 6.188568592071533, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.01917506754398346, 'loss_2': 0.00022459030151367188, 'loss_3': -15.690582275390625, 'loss_4': 3.3378968238830566, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 09:41:49,919 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:49,919 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:17<1:18:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:57,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01971544697880745, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.028, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010503428988158703, 'eval_loss_2': 0.009212017059326172, 'eval_loss_3': -18.265058517456055, 'eval_loss_4': 2.4436850547790527, 'epoch': 3.52}
{'loss': 0.0427, 'grad_norm': 20.83052635192871, 'learning_rate': 2.65e-05, 'loss_1': 0.03204173222184181, 'loss_2': 0.0106353759765625, 'loss_3': -15.637802124023438, 'loss_4': 2.5721545219421387, 'epoch': 3.52}
{'loss': 0.0524, 'grad_norm': 16.784284591674805, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.035061802715063095, 'loss_2': 0.017364501953125, 'loss_3': -15.61913776397705, 'loss_4': 2.729407548904419, 'epoch': 3.53}
{'loss': 0.0576, 'grad_norm': 17.91715431213379, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.03689069300889969, 'loss_2': 0.020751953125, 'loss_3': -15.762520790100098, 'loss_4': 2.8917646408081055, 'epoch': 3.53}
{'loss': 0.0462, 'grad_norm': 15.937833786010742, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.0327579602599144, 'loss_2': 0.013458251953125, 'loss_3': -15.796675682067871, 'loss_4': 3.296268939971924, 'epoch': 3.54}
{'loss': 0.143, 'grad_norm': 19.383146286010742, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.1379261314868927, 'loss_2': 0.00506591796875, 'loss_3': -15.557802200317383, 'loss_4': 1.7960280179977417, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 09:41:57,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:57,272 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:24<1:18:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:04,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025645188987255096, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012604167684912682, 'eval_loss_2': 0.013041019439697266, 'eval_loss_3': -18.23186683654785, 'eval_loss_4': 2.0505142211914062, 'epoch': 3.55}
{'loss': 0.0212, 'grad_norm': 6.284053802490234, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.011329800821840763, 'loss_2': 0.00982666015625, 'loss_3': -15.627853393554688, 'loss_4': 2.53733229637146, 'epoch': 3.55}
{'loss': 0.041, 'grad_norm': 9.786663055419922, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.025214530527591705, 'loss_2': 0.0157928466796875, 'loss_3': -15.866482734680176, 'loss_4': 3.1251628398895264, 'epoch': 3.56}
{'loss': 0.0286, 'grad_norm': 7.486537933349609, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.020209744572639465, 'loss_2': 0.00836181640625, 'loss_3': -15.850740432739258, 'loss_4': 2.274056911468506, 'epoch': 3.56}
{'loss': 0.0607, 'grad_norm': 23.443592071533203, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.058152541518211365, 'loss_2': 0.0025386810302734375, 'loss_3': -15.482198715209961, 'loss_4': 2.4596688747406006, 'epoch': 3.57}
{'loss': 0.0235, 'grad_norm': 7.431331157684326, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.017038065940141678, 'loss_2': 0.00643157958984375, 'loss_3': -15.787179946899414, 'loss_4': 2.2720885276794434, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 09:42:04,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:04,607 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:31<1:18:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:11,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02338206022977829, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.806, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012393347918987274, 'eval_loss_2': 0.010988712310791016, 'eval_loss_3': -18.27186393737793, 'eval_loss_4': 1.7881256341934204, 'epoch': 3.58}
{'loss': 0.0393, 'grad_norm': 11.079705238342285, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.03484387695789337, 'loss_2': 0.0044403076171875, 'loss_3': -15.94747257232666, 'loss_4': 1.8551691770553589, 'epoch': 3.58}
{'loss': 0.0183, 'grad_norm': 6.741344928741455, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.015619901940226555, 'loss_2': 0.002712249755859375, 'loss_3': -15.899291038513184, 'loss_4': 1.667468786239624, 'epoch': 3.59}
{'loss': 0.0397, 'grad_norm': 13.010785102844238, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.03588473051786423, 'loss_2': 0.00384521484375, 'loss_3': -15.705009460449219, 'loss_4': 2.533693313598633, 'epoch': 3.59}
{'loss': 0.0518, 'grad_norm': 12.169332504272461, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.04887538030743599, 'loss_2': 0.0029449462890625, 'loss_3': -15.816509246826172, 'loss_4': 2.605379104614258, 'epoch': 3.6}
{'loss': 0.0136, 'grad_norm': 6.804129123687744, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.013498080894351006, 'loss_2': 0.00015032291412353516, 'loss_3': -15.821906089782715, 'loss_4': 1.693869709968567, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 09:42:11,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:11,945 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:39<1:18:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:19,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017992794513702393, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.847, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013867601752281189, 'eval_loss_2': 0.004125192761421204, 'eval_loss_3': -18.295888900756836, 'eval_loss_4': 2.0182549953460693, 'epoch': 3.6}
{'loss': 0.0242, 'grad_norm': 8.53542423248291, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.02389959618449211, 'loss_2': 0.000286102294921875, 'loss_3': -15.922255516052246, 'loss_4': 2.253096103668213, 'epoch': 3.61}
{'loss': 0.0433, 'grad_norm': 18.316089630126953, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.043053317815065384, 'loss_2': 0.00020241737365722656, 'loss_3': -15.946235656738281, 'loss_4': 2.168010711669922, 'epoch': 3.62}
{'loss': 0.0199, 'grad_norm': 9.610679626464844, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.01869768649339676, 'loss_2': 0.0011930465698242188, 'loss_3': -15.602164268493652, 'loss_4': 2.602604866027832, 'epoch': 3.62}
{'loss': 0.086, 'grad_norm': 19.675500869750977, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.07058534026145935, 'loss_2': 0.0154266357421875, 'loss_3': -15.77918815612793, 'loss_4': 1.4647138118743896, 'epoch': 3.63}
{'loss': 0.0698, 'grad_norm': 26.727218627929688, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.06556492298841476, 'loss_2': 0.0041961669921875, 'loss_3': -15.776054382324219, 'loss_4': 2.5017123222351074, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 09:42:19,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:19,285 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:46<1:18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:26,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02454722672700882, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.402, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01304972916841507, 'eval_loss_2': 0.01149749755859375, 'eval_loss_3': -18.277507781982422, 'eval_loss_4': 2.208984136581421, 'epoch': 3.63}
{'loss': 0.0693, 'grad_norm': 19.126371383666992, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.05171491205692291, 'loss_2': 0.017578125, 'loss_3': -15.635917663574219, 'loss_4': 2.161742687225342, 'epoch': 3.64}
{'loss': 0.0578, 'grad_norm': 17.100830078125, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.04457412660121918, 'loss_2': 0.0131988525390625, 'loss_3': -15.773089408874512, 'loss_4': 2.1101865768432617, 'epoch': 3.65}
{'loss': 0.0521, 'grad_norm': 14.003314971923828, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.03634975850582123, 'loss_2': 0.015777587890625, 'loss_3': -15.604232788085938, 'loss_4': 1.9119232892990112, 'epoch': 3.65}
{'loss': 0.047, 'grad_norm': 10.059144020080566, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.03002578765153885, 'loss_2': 0.0169525146484375, 'loss_3': -15.791658401489258, 'loss_4': 2.6999802589416504, 'epoch': 3.66}
{'loss': 0.0382, 'grad_norm': 7.37142276763916, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.018141480162739754, 'loss_2': 0.02008056640625, 'loss_3': -15.647811889648438, 'loss_4': 2.009542465209961, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 09:42:26,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:26,633 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [15:53<1:19:31,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:42:34,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021907620131969452, 'eval_runtime': 3.9865, 'eval_samples_per_second': 256.868, 'eval_steps_per_second': 4.014, 'eval_loss_1': 0.014146975241601467, 'eval_loss_2': 0.00776064395904541, 'eval_loss_3': -18.26494598388672, 'eval_loss_4': 2.332501173019409, 'epoch': 3.66}
{'loss': 0.0383, 'grad_norm': 7.500099182128906, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.025806117802858353, 'loss_2': 0.0125274658203125, 'loss_3': -15.77285385131836, 'loss_4': 3.1400909423828125, 'epoch': 3.67}
{'loss': 0.0293, 'grad_norm': 8.636302947998047, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.027103738859295845, 'loss_2': 0.00222015380859375, 'loss_3': -15.809344291687012, 'loss_4': 2.130075216293335, 'epoch': 3.67}
{'loss': 0.04, 'grad_norm': 9.989352226257324, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.03730956092476845, 'loss_2': 0.0027313232421875, 'loss_3': -15.456993103027344, 'loss_4': 3.0160281658172607, 'epoch': 3.68}
{'loss': 0.0513, 'grad_norm': 17.828594207763672, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.04714652895927429, 'loss_2': 0.0041351318359375, 'loss_3': -15.893998146057129, 'loss_4': 2.580721855163574, 'epoch': 3.69}
{'loss': 0.0386, 'grad_norm': 7.743632793426514, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.02301250398159027, 'loss_2': 0.0155487060546875, 'loss_3': -15.757978439331055, 'loss_4': 3.165987491607666, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 09:42:34,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:34,185 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:01<1:18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:41,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029132086783647537, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014209468849003315, 'eval_loss_2': 0.014922618865966797, 'eval_loss_3': -18.26032829284668, 'eval_loss_4': 2.460411310195923, 'epoch': 3.69}
{'loss': 0.0217, 'grad_norm': 8.316327095031738, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.017561867833137512, 'loss_2': 0.004138946533203125, 'loss_3': -15.556609153747559, 'loss_4': 2.6921067237854004, 'epoch': 3.7}
{'loss': 0.046, 'grad_norm': 11.904397010803223, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.036917321383953094, 'loss_2': 0.00911712646484375, 'loss_3': -15.75613784790039, 'loss_4': 3.706953287124634, 'epoch': 3.7}
{'loss': 0.1483, 'grad_norm': 20.015583038330078, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.13899299502372742, 'loss_2': 0.00928497314453125, 'loss_3': -15.459322929382324, 'loss_4': 3.056245803833008, 'epoch': 3.71}
{'loss': 0.0375, 'grad_norm': 7.84454870223999, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.021398305892944336, 'loss_2': 0.01605224609375, 'loss_3': -15.983076095581055, 'loss_4': 1.9907336235046387, 'epoch': 3.72}
{'loss': 0.0343, 'grad_norm': 15.192355155944824, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.030264172703027725, 'loss_2': 0.00403594970703125, 'loss_3': -15.541851997375488, 'loss_4': 2.7859275341033936, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 09:42:41,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:41,526 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:08<1:18:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:48,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02213750034570694, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015442587435245514, 'eval_loss_2': 0.006694912910461426, 'eval_loss_3': -18.201509475708008, 'eval_loss_4': 2.6409850120544434, 'epoch': 3.72}
{'loss': 0.0601, 'grad_norm': 21.539560317993164, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.05877164751291275, 'loss_2': 0.00131988525390625, 'loss_3': -15.534677505493164, 'loss_4': 2.707855463027954, 'epoch': 3.73}
{'loss': 0.0185, 'grad_norm': 6.627448558807373, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.01520831324160099, 'loss_2': 0.0033130645751953125, 'loss_3': -15.741582870483398, 'loss_4': 2.7287702560424805, 'epoch': 3.73}
{'loss': 0.0329, 'grad_norm': 9.204056739807129, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.027310622856020927, 'loss_2': 0.00562286376953125, 'loss_3': -15.688891410827637, 'loss_4': 3.2510995864868164, 'epoch': 3.74}
{'loss': 0.0482, 'grad_norm': 17.008895874023438, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.04586189612746239, 'loss_2': 0.00231170654296875, 'loss_3': -15.576886177062988, 'loss_4': 2.6120452880859375, 'epoch': 3.74}
{'loss': 0.0355, 'grad_norm': 8.138293266296387, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.021458301693201065, 'loss_2': 0.0140380859375, 'loss_3': -15.70147705078125, 'loss_4': 2.7988569736480713, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 09:42:48,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:48,873 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:16<1:18:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:56,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021450014784932137, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.845, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014043065719306469, 'eval_loss_2': 0.007406949996948242, 'eval_loss_3': -18.214923858642578, 'eval_loss_4': 3.226039171218872, 'epoch': 3.75}
{'loss': 0.0313, 'grad_norm': 6.783822059631348, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.018708359450101852, 'loss_2': 0.012603759765625, 'loss_3': -15.485761642456055, 'loss_4': 3.229935646057129, 'epoch': 3.76}
{'loss': 0.0296, 'grad_norm': 10.559147834777832, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.024602727964520454, 'loss_2': 0.0049896240234375, 'loss_3': -15.789015769958496, 'loss_4': 3.436922788619995, 'epoch': 3.76}
{'loss': 0.0266, 'grad_norm': 8.381051063537598, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.02060845121741295, 'loss_2': 0.00603485107421875, 'loss_3': -15.667243957519531, 'loss_4': 2.9540419578552246, 'epoch': 3.77}
{'loss': 0.0316, 'grad_norm': 11.850866317749023, 'learning_rate': 2.625e-05, 'loss_1': 0.028137745335698128, 'loss_2': 0.003448486328125, 'loss_3': -15.603935241699219, 'loss_4': 3.758444309234619, 'epoch': 3.77}
{'loss': 0.0477, 'grad_norm': 12.471083641052246, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.035685691982507706, 'loss_2': 0.012054443359375, 'loss_3': -15.682147979736328, 'loss_4': 3.885932207107544, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 09:42:56,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:56,215 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:23<1:17:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:03,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016741028055548668, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013388624414801598, 'eval_loss_2': 0.0033524036407470703, 'eval_loss_3': -18.225061416625977, 'eval_loss_4': 3.4833788871765137, 'epoch': 3.78}
{'loss': 0.0366, 'grad_norm': 21.227222442626953, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.03595981001853943, 'loss_2': 0.0006656646728515625, 'loss_3': -15.628503799438477, 'loss_4': 3.674109935760498, 'epoch': 3.78}
{'loss': 0.0281, 'grad_norm': 8.710762023925781, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.025380153208971024, 'loss_2': 0.002712249755859375, 'loss_3': -15.536290168762207, 'loss_4': 3.2493066787719727, 'epoch': 3.79}
{'loss': 0.0258, 'grad_norm': 7.340084552764893, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.01625867560505867, 'loss_2': 0.00949859619140625, 'loss_3': -15.60574722290039, 'loss_4': 3.9642555713653564, 'epoch': 3.8}
{'loss': 0.0257, 'grad_norm': 8.166910171508789, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.022703872993588448, 'loss_2': 0.002971649169921875, 'loss_3': -15.880837440490723, 'loss_4': 4.206557273864746, 'epoch': 3.8}
{'loss': 0.0241, 'grad_norm': 6.408620834350586, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.018467718735337257, 'loss_2': 0.005680084228515625, 'loss_3': -15.76167106628418, 'loss_4': 3.774188280105591, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 09:43:03,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:03,567 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:30<1:17:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:10,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023007240146398544, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.629, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012144174426794052, 'eval_loss_2': 0.010863065719604492, 'eval_loss_3': -18.264713287353516, 'eval_loss_4': 3.570671558380127, 'epoch': 3.81}
{'loss': 0.0329, 'grad_norm': 7.5527729988098145, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.02002580650150776, 'loss_2': 0.01287841796875, 'loss_3': -15.716743469238281, 'loss_4': 3.594184398651123, 'epoch': 3.81}
{'loss': 0.0299, 'grad_norm': 7.207221031188965, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.02176154963672161, 'loss_2': 0.008148193359375, 'loss_3': -15.691394805908203, 'loss_4': 3.7353568077087402, 'epoch': 3.82}
{'loss': 0.048, 'grad_norm': 16.36284637451172, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.03873871639370918, 'loss_2': 0.00921630859375, 'loss_3': -15.585306167602539, 'loss_4': 3.0132522583007812, 'epoch': 3.83}
{'loss': 0.0256, 'grad_norm': 6.233800888061523, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.01711811125278473, 'loss_2': 0.00846099853515625, 'loss_3': -15.713214874267578, 'loss_4': 3.538506269454956, 'epoch': 3.83}
{'loss': 0.0398, 'grad_norm': 15.750508308410645, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.03480156511068344, 'loss_2': 0.00495147705078125, 'loss_3': -15.770076751708984, 'loss_4': 3.8102874755859375, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 09:43:10,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:10,914 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:38<1:18:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:18,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015513809397816658, 'eval_runtime': 3.8244, 'eval_samples_per_second': 267.752, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.012258411385118961, 'eval_loss_2': 0.003255397081375122, 'eval_loss_3': -18.286571502685547, 'eval_loss_4': 3.2521395683288574, 'epoch': 3.84}
{'loss': 0.0225, 'grad_norm': 7.419992446899414, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.01737581565976143, 'loss_2': 0.0051422119140625, 'loss_3': -15.938543319702148, 'loss_4': 3.4389915466308594, 'epoch': 3.84}
{'loss': 0.0338, 'grad_norm': 10.864737510681152, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.03176065534353256, 'loss_2': 0.002025604248046875, 'loss_3': -15.702411651611328, 'loss_4': 3.3211615085601807, 'epoch': 3.85}
{'loss': 0.0332, 'grad_norm': 8.054780960083008, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.015797903761267662, 'loss_2': 0.0174407958984375, 'loss_3': -15.99105453491211, 'loss_4': 3.6173722743988037, 'epoch': 3.85}
{'loss': 0.0316, 'grad_norm': 11.55587100982666, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.029069235548377037, 'loss_2': 0.002552032470703125, 'loss_3': -15.693549156188965, 'loss_4': 2.431464195251465, 'epoch': 3.86}
{'loss': 0.0308, 'grad_norm': 10.081512451171875, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.029319334775209427, 'loss_2': 0.0014591217041015625, 'loss_3': -15.761579513549805, 'loss_4': 2.7403812408447266, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 09:43:18,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:18,294 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:41<1:18:01,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:43:22,099 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665
[INFO|configuration_utils.py:420] 2025-01-21 09:43:22,101 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665/config.json                                                                              
{'eval_loss': 0.01527339220046997, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011421442031860352, 'eval_loss_2': 0.003851950168609619, 'eval_loss_3': -18.30811309814453, 'eval_loss_4': 2.33454966545105, 'epoch': 3.87}
[INFO|modeling_utils.py:2988] 2025-01-21 09:43:22,568 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:43:22,569 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:43:22,570 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:43:23,371 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-585] due to args.save_total_limit
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:46<1:24:59,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:43:27,005 >>
{'loss': 0.022, 'grad_norm': 6.481098651885986, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.01480844710022211, 'loss_2': 0.0071868896484375, 'loss_3': -15.694345474243164, 'loss_4': 2.8365750312805176, 'epoch': 3.87}
{'loss': 0.0269, 'grad_norm': 7.211398124694824, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.01861531473696232, 'loss_2': 0.008331298828125, 'loss_3': -15.996435165405273, 'loss_4': 2.518343448638916, 'epoch': 3.88}
{'loss': 0.0347, 'grad_norm': 11.280779838562012, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.03073292225599289, 'loss_2': 0.003948211669921875, 'loss_3': -15.855842590332031, 'loss_4': 2.811093330383301, 'epoch': 3.88}
{'loss': 0.0445, 'grad_norm': 9.772729873657227, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.03151284158229828, 'loss_2': 0.01300048828125, 'loss_3': -15.918190956115723, 'loss_4': 2.3396549224853516, 'epoch': 3.89}
{'loss': 0.0299, 'grad_norm': 7.454882621765137, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.026316789910197258, 'loss_2': 0.003551483154296875, 'loss_3': -15.951553344726562, 'loss_4': 2.713906764984131, 'epoch': 3.9}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:43:27,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:27,005 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [16:54<1:18:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:43:34,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020021436735987663, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01325303129851818, 'eval_loss_2': 0.006768405437469482, 'eval_loss_3': -18.335485458374023, 'eval_loss_4': 1.9313220977783203, 'epoch': 3.9}
{'loss': 0.0352, 'grad_norm': 8.909791946411133, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.03111753985285759, 'loss_2': 0.004123687744140625, 'loss_3': -15.949552536010742, 'loss_4': 2.7127108573913574, 'epoch': 3.9}
{'loss': 0.0545, 'grad_norm': 18.87557601928711, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.05164484307169914, 'loss_2': 0.002864837646484375, 'loss_3': -15.813396453857422, 'loss_4': 2.422091007232666, 'epoch': 3.91}
{'loss': 0.0381, 'grad_norm': 10.443742752075195, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.033128973096609116, 'loss_2': 0.00498199462890625, 'loss_3': -16.03154754638672, 'loss_4': 2.321638822555542, 'epoch': 3.91}
{'loss': 0.0301, 'grad_norm': 11.412468910217285, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.026188554242253304, 'loss_2': 0.003910064697265625, 'loss_3': -15.769882202148438, 'loss_4': 2.582098960876465, 'epoch': 3.92}
{'loss': 0.0442, 'grad_norm': 13.410985946655273, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.03992502763867378, 'loss_2': 0.00423431396484375, 'loss_3': -15.789892196655273, 'loss_4': 2.0213937759399414, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 09:43:34,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:34,340 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:01<1:17:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:41,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017324600368738174, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012498918920755386, 'eval_loss_2': 0.004825681447982788, 'eval_loss_3': -18.340974807739258, 'eval_loss_4': 1.7930735349655151, 'epoch': 3.92}
{'loss': 0.024, 'grad_norm': 9.20930004119873, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.023793410509824753, 'loss_2': 0.00022649765014648438, 'loss_3': -16.021106719970703, 'loss_4': 2.759976863861084, 'epoch': 3.93}
{'loss': 0.067, 'grad_norm': 17.416641235351562, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.050039567053318024, 'loss_2': 0.016937255859375, 'loss_3': -15.668395042419434, 'loss_4': 1.6520321369171143, 'epoch': 3.94}
{'loss': 0.0442, 'grad_norm': 12.073273658752441, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.03606671467423439, 'loss_2': 0.0081329345703125, 'loss_3': -16.07589340209961, 'loss_4': 2.161017894744873, 'epoch': 3.94}
{'loss': 0.0399, 'grad_norm': 11.97347354888916, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.037708383053541183, 'loss_2': 0.002216339111328125, 'loss_3': -15.900991439819336, 'loss_4': 2.301426410675049, 'epoch': 3.95}
{'loss': 0.0224, 'grad_norm': 8.27538013458252, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.022231101989746094, 'loss_2': 0.00013303756713867188, 'loss_3': -15.902257919311523, 'loss_4': 3.1598429679870605, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 09:43:41,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:41,674 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:08<1:17:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:49,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01977463811635971, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012039625085890293, 'eval_loss_2': 0.007735013961791992, 'eval_loss_3': -18.344087600708008, 'eval_loss_4': 1.7643136978149414, 'epoch': 3.95}
{'loss': 0.0395, 'grad_norm': 9.073250770568848, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.03646986186504364, 'loss_2': 0.003009796142578125, 'loss_3': -16.074275970458984, 'loss_4': 2.043712615966797, 'epoch': 3.96}
{'loss': 0.0452, 'grad_norm': 14.646896362304688, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.03825874254107475, 'loss_2': 0.006988525390625, 'loss_3': -15.981465339660645, 'loss_4': 2.2575337886810303, 'epoch': 3.97}
{'loss': 0.0298, 'grad_norm': 11.82638931274414, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.023601483553647995, 'loss_2': 0.0062408447265625, 'loss_3': -15.99650764465332, 'loss_4': 2.1723411083221436, 'epoch': 3.97}
{'loss': 0.0363, 'grad_norm': 7.823531150817871, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.023070869967341423, 'loss_2': 0.0132598876953125, 'loss_3': -15.808243751525879, 'loss_4': 1.838454246520996, 'epoch': 3.98}
{'loss': 0.0312, 'grad_norm': 7.359764575958252, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.025294991210103035, 'loss_2': 0.005889892578125, 'loss_3': -15.919525146484375, 'loss_4': 2.392731189727783, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 09:43:49,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:49,018 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:15<1:14:04,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 09:43:56,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020884763449430466, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.079, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011723053641617298, 'eval_loss_2': 0.009161710739135742, 'eval_loss_3': -18.31212615966797, 'eval_loss_4': 1.5074248313903809, 'epoch': 3.98}
{'loss': 0.0438, 'grad_norm': 10.822628021240234, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.03744553029537201, 'loss_2': 0.006366729736328125, 'loss_3': -15.924633026123047, 'loss_4': 1.76607346534729, 'epoch': 3.99}
{'loss': 0.0336, 'grad_norm': 12.440999984741211, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.032633792608976364, 'loss_2': 0.00092315673828125, 'loss_3': -15.850065231323242, 'loss_4': 2.555299997329712, 'epoch': 3.99}
{'loss': 0.0239, 'grad_norm': 17.734529495239258, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.02223989926278591, 'loss_2': 0.0017080307006835938, 'loss_3': -15.811773300170898, 'loss_4': 2.4529995918273926, 'epoch': 4.0}
{'loss': 0.0409, 'grad_norm': 11.209521293640137, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.040845032781362534, 'loss_2': 1.4543533325195312e-05, 'loss_3': -15.937479019165039, 'loss_4': 1.8663028478622437, 'epoch': 4.01}
{'loss': 0.0734, 'grad_norm': 20.28742027282715, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.07338215410709381, 'loss_2': 7.867813110351562e-06, 'loss_3': -16.032207489013672, 'loss_4': 1.7254791259765625, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 09:43:56,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:56,038 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:23<1:16:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:44:03,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01709464192390442, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.182, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014004947617650032, 'eval_loss_2': 0.003089696168899536, 'eval_loss_3': -18.240371704101562, 'eval_loss_4': 1.630844235420227, 'epoch': 4.01}
{'loss': 0.0579, 'grad_norm': 21.290252685546875, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.050612278282642365, 'loss_2': 0.007266998291015625, 'loss_3': -15.976106643676758, 'loss_4': 1.9590696096420288, 'epoch': 4.02}
{'loss': 0.0373, 'grad_norm': 17.45665168762207, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.03555751219391823, 'loss_2': 0.001789093017578125, 'loss_3': -15.947450637817383, 'loss_4': 1.8131130933761597, 'epoch': 4.02}
{'loss': 0.0576, 'grad_norm': 14.759657859802246, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.05127312242984772, 'loss_2': 0.006336212158203125, 'loss_3': -15.847589492797852, 'loss_4': 1.6234865188598633, 'epoch': 4.03}
{'loss': 0.0565, 'grad_norm': 16.796274185180664, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.0485946349799633, 'loss_2': 0.007904052734375, 'loss_3': -15.91218090057373, 'loss_4': 1.896514892578125, 'epoch': 4.03}
{'loss': 0.0329, 'grad_norm': 9.185593605041504, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.03280595317482948, 'loss_2': 4.8160552978515625e-05, 'loss_3': -15.890146255493164, 'loss_4': 2.4301352500915527, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 09:44:03,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:03,389 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:30<1:17:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:10,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019087817519903183, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.742, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012663032859563828, 'eval_loss_2': 0.0064247846603393555, 'eval_loss_3': -18.220321655273438, 'eval_loss_4': 1.8734159469604492, 'epoch': 4.04}
{'loss': 0.0443, 'grad_norm': 15.846257209777832, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.04350471869111061, 'loss_2': 0.0008397102355957031, 'loss_3': -15.627653121948242, 'loss_4': 2.828307628631592, 'epoch': 4.05}
{'loss': 0.0354, 'grad_norm': 9.428145408630371, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.029618287459015846, 'loss_2': 0.005817413330078125, 'loss_3': -15.844785690307617, 'loss_4': 2.427830934524536, 'epoch': 4.05}
{'loss': 0.031, 'grad_norm': 8.018178939819336, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.02894233725965023, 'loss_2': 0.0020904541015625, 'loss_3': -15.806177139282227, 'loss_4': 1.8816899061203003, 'epoch': 4.06}
{'loss': 0.044, 'grad_norm': 17.68271255493164, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.036203667521476746, 'loss_2': 0.00782012939453125, 'loss_3': -15.789107322692871, 'loss_4': 2.748342990875244, 'epoch': 4.06}
{'loss': 0.0347, 'grad_norm': 13.27492618560791, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.02769586257636547, 'loss_2': 0.0070037841796875, 'loss_3': -15.841973304748535, 'loss_4': 1.7913843393325806, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 09:44:10,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:10,729 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:34<1:17:01,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:44:14,527 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700
[INFO|configuration_utils.py:420] 2025-01-21 09:44:14,529 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700/config.json                                                                              
{'eval_loss': 0.013630727306008339, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.669, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011270265094935894, 'eval_loss_2': 0.0023604631423950195, 'eval_loss_3': -18.23443603515625, 'eval_loss_4': 1.8797695636749268, 'epoch': 4.07}
[INFO|modeling_utils.py:2988] 2025-01-21 09:44:15,013 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:44:15,014 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:44:15,015 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:44:15,823 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-665] due to args.save_total_limit
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:39<1:24:24,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:44:19,458 >>
{'loss': 0.0208, 'grad_norm': 6.553946495056152, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.017568714916706085, 'loss_2': 0.003276824951171875, 'loss_3': -15.783387184143066, 'loss_4': 2.5720009803771973, 'epoch': 4.08}
{'loss': 0.025, 'grad_norm': 6.638638973236084, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.01610524021089077, 'loss_2': 0.00885772705078125, 'loss_3': -15.882184982299805, 'loss_4': 2.682347297668457, 'epoch': 4.08}
{'loss': 0.0557, 'grad_norm': 12.615775108337402, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.029375432059168816, 'loss_2': 0.0263671875, 'loss_3': -15.790185928344727, 'loss_4': 2.5103940963745117, 'epoch': 4.09}
{'loss': 0.0316, 'grad_norm': 8.24233627319336, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.02294520102441311, 'loss_2': 0.008636474609375, 'loss_3': -15.817545890808105, 'loss_4': 2.4451684951782227, 'epoch': 4.09}
{'loss': 0.0202, 'grad_norm': 6.632874965667725, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.01264114584773779, 'loss_2': 0.007534027099609375, 'loss_3': -15.944962501525879, 'loss_4': 1.9411017894744873, 'epoch': 4.1}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:44:19,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:19,458 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:46<1:18:03,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:44:26,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018101368099451065, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.024, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.012143556028604507, 'eval_loss_2': 0.005957812070846558, 'eval_loss_3': -18.210607528686523, 'eval_loss_4': 1.7548717260360718, 'epoch': 4.1}
{'loss': 0.0305, 'grad_norm': 7.740830898284912, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.02207733877003193, 'loss_2': 0.00838470458984375, 'loss_3': -15.812911987304688, 'loss_4': 1.9730606079101562, 'epoch': 4.1}
{'loss': 0.0307, 'grad_norm': 6.528530120849609, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.017090503126382828, 'loss_2': 0.01361083984375, 'loss_3': -15.780040740966797, 'loss_4': 2.2227954864501953, 'epoch': 4.11}
{'loss': 0.0224, 'grad_norm': 10.32553768157959, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.02201809547841549, 'loss_2': 0.00041484832763671875, 'loss_3': -15.719762802124023, 'loss_4': 2.64725923538208, 'epoch': 4.12}
{'loss': 0.0289, 'grad_norm': 8.257378578186035, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.026226969435811043, 'loss_2': 0.002643585205078125, 'loss_3': -15.894062995910645, 'loss_4': 1.3674161434173584, 'epoch': 4.12}
{'loss': 0.0268, 'grad_norm': 10.59459114074707, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.020562419667840004, 'loss_2': 0.00623321533203125, 'loss_3': -15.69499397277832, 'loss_4': 2.081669807434082, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 09:44:26,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:26,789 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [17:53<1:17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:34,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022211946547031403, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.324, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011371769942343235, 'eval_loss_2': 0.010840177536010742, 'eval_loss_3': -18.227584838867188, 'eval_loss_4': 1.3298625946044922, 'epoch': 4.13}
{'loss': 0.0688, 'grad_norm': 17.3360652923584, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.054957110434770584, 'loss_2': 0.01386260986328125, 'loss_3': -15.805209159851074, 'loss_4': 1.4194488525390625, 'epoch': 4.13}
{'loss': 0.1047, 'grad_norm': 28.828304290771484, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.0784771591424942, 'loss_2': 0.0262603759765625, 'loss_3': -15.663351058959961, 'loss_4': 1.7176408767700195, 'epoch': 4.14}
{'loss': 0.0282, 'grad_norm': 8.75045394897461, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.018909210339188576, 'loss_2': 0.0093231201171875, 'loss_3': -15.787150382995605, 'loss_4': 1.4310669898986816, 'epoch': 4.15}
{'loss': 0.0404, 'grad_norm': 10.355378150939941, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.027336379513144493, 'loss_2': 0.01306915283203125, 'loss_3': -15.748486518859863, 'loss_4': 2.342339515686035, 'epoch': 4.15}
{'loss': 0.05, 'grad_norm': 23.860607147216797, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.040642328560352325, 'loss_2': 0.0093841552734375, 'loss_3': -15.755209922790527, 'loss_4': 1.3290427923202515, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 09:44:34,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:34,122 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:01<1:16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:41,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02486884966492653, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011280421167612076, 'eval_loss_2': 0.013588428497314453, 'eval_loss_3': -18.2049560546875, 'eval_loss_4': 1.4417237043380737, 'epoch': 4.16}
{'loss': 0.0364, 'grad_norm': 10.181964874267578, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.021060701459646225, 'loss_2': 0.015380859375, 'loss_3': -15.905582427978516, 'loss_4': 2.239694833755493, 'epoch': 4.16}
{'loss': 0.0299, 'grad_norm': 7.873602390289307, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.018000369891524315, 'loss_2': 0.011932373046875, 'loss_3': -15.767578125, 'loss_4': 1.646933913230896, 'epoch': 4.17}
{'loss': 0.0196, 'grad_norm': 7.156596660614014, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.013902397826313972, 'loss_2': 0.005649566650390625, 'loss_3': -15.84720230102539, 'loss_4': 1.8814729452133179, 'epoch': 4.17}
{'loss': 0.0444, 'grad_norm': 24.084630966186523, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.03647688403725624, 'loss_2': 0.00791168212890625, 'loss_3': -15.689468383789062, 'loss_4': 1.965419054031372, 'epoch': 4.18}
{'loss': 0.0219, 'grad_norm': 8.309300422668457, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.016527149826288223, 'loss_2': 0.00536346435546875, 'loss_3': -15.770950317382812, 'loss_4': 1.965834140777588, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 09:44:41,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:41,469 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:08<1:16:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:48,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016165588051080704, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012446466833353043, 'eval_loss_2': 0.003719121217727661, 'eval_loss_3': -18.17963981628418, 'eval_loss_4': 1.5544379949569702, 'epoch': 4.19}
{'loss': 0.0285, 'grad_norm': 10.188606262207031, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.025585290044546127, 'loss_2': 0.0029449462890625, 'loss_3': -15.694439888000488, 'loss_4': 1.910984754562378, 'epoch': 4.19}
{'loss': 0.0177, 'grad_norm': 9.084305763244629, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.01669171266257763, 'loss_2': 0.001033782958984375, 'loss_3': -15.6019287109375, 'loss_4': 1.5877559185028076, 'epoch': 4.2}
{'loss': 0.0189, 'grad_norm': 7.871395587921143, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.018765054643154144, 'loss_2': 0.00010591745376586914, 'loss_3': -15.72296142578125, 'loss_4': 1.631697416305542, 'epoch': 4.2}
{'loss': 0.0409, 'grad_norm': 13.76357650756836, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.03385506942868233, 'loss_2': 0.00702667236328125, 'loss_3': -15.456635475158691, 'loss_4': 2.0785584449768066, 'epoch': 4.21}
{'loss': 0.0305, 'grad_norm': 12.136588096618652, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.02106870897114277, 'loss_2': 0.0094146728515625, 'loss_3': -15.997903823852539, 'loss_4': 1.5758857727050781, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 09:44:48,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:48,812 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:15<1:16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:56,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021973468363285065, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.187, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.017346421256661415, 'eval_loss_2': 0.004627048969268799, 'eval_loss_3': -18.106813430786133, 'eval_loss_4': 1.5386576652526855, 'epoch': 4.22}
{'loss': 0.0321, 'grad_norm': 10.319581985473633, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.02189389057457447, 'loss_2': 0.01019287109375, 'loss_3': -15.510638236999512, 'loss_4': 1.7728461027145386, 'epoch': 4.22}
{'loss': 0.0375, 'grad_norm': 12.490143775939941, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.036663126200437546, 'loss_2': 0.0007910728454589844, 'loss_3': -15.762587547302246, 'loss_4': 1.4953386783599854, 'epoch': 4.23}
{'loss': 0.0263, 'grad_norm': 9.426314353942871, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.02567887306213379, 'loss_2': 0.0006480216979980469, 'loss_3': -15.71463680267334, 'loss_4': 0.9375362992286682, 'epoch': 4.23}
{'loss': 0.0307, 'grad_norm': 13.563493728637695, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.026475653052330017, 'loss_2': 0.00421142578125, 'loss_3': -16.018342971801758, 'loss_4': 1.8017690181732178, 'epoch': 4.24}
{'loss': 0.0422, 'grad_norm': 15.603883743286133, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.036769673228263855, 'loss_2': 0.0054779052734375, 'loss_3': -15.667900085449219, 'loss_4': 1.0021066665649414, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 09:44:56,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:56,142 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:23<1:16:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:03,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029298176988959312, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.025026798248291016, 'eval_loss_2': 0.004271380603313446, 'eval_loss_3': -18.102792739868164, 'eval_loss_4': 1.253071665763855, 'epoch': 4.24}
{'loss': 0.0308, 'grad_norm': 11.838484764099121, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.02828449383378029, 'loss_2': 0.00250244140625, 'loss_3': -15.670823097229004, 'loss_4': 1.450348138809204, 'epoch': 4.25}
{'loss': 0.0253, 'grad_norm': 8.177441596984863, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.019731802865862846, 'loss_2': 0.005584716796875, 'loss_3': -15.817061424255371, 'loss_4': 0.9634344577789307, 'epoch': 4.26}
{'loss': 0.036, 'grad_norm': 10.63442611694336, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.0286568496376276, 'loss_2': 0.00731658935546875, 'loss_3': -15.639182090759277, 'loss_4': 1.1038881540298462, 'epoch': 4.26}
{'loss': 0.0193, 'grad_norm': 6.326294422149658, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.01919572427868843, 'loss_2': 7.408857345581055e-05, 'loss_3': -15.848775863647461, 'loss_4': 1.074146032333374, 'epoch': 4.27}
{'loss': 0.0276, 'grad_norm': 8.138039588928223, 'learning_rate': 2.575e-05, 'loss_1': 0.026393167674541473, 'loss_2': 0.0011882781982421875, 'loss_3': -15.664083480834961, 'loss_4': 0.3400442600250244, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 09:45:03,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:03,479 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:30<1:16:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:10,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036004919558763504, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.869, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.03177164867520332, 'eval_loss_2': 0.004233270883560181, 'eval_loss_3': -18.091567993164062, 'eval_loss_4': 1.4239078760147095, 'epoch': 4.27}
{'loss': 0.0567, 'grad_norm': 16.544084548950195, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.053483713418245316, 'loss_2': 0.003238677978515625, 'loss_3': -15.76165771484375, 'loss_4': 0.9902295470237732, 'epoch': 4.28}
{'loss': 0.0379, 'grad_norm': 10.43090534210205, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.0319010354578495, 'loss_2': 0.0059661865234375, 'loss_3': -15.582412719726562, 'loss_4': 2.2668774127960205, 'epoch': 4.28}
{'loss': 0.1109, 'grad_norm': 25.42650032043457, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.10740409791469574, 'loss_2': 0.0035400390625, 'loss_3': -15.582206726074219, 'loss_4': 1.5935299396514893, 'epoch': 4.29}
{'loss': 0.0281, 'grad_norm': 7.076779365539551, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.02448311448097229, 'loss_2': 0.003627777099609375, 'loss_3': -15.706494331359863, 'loss_4': 1.6551072597503662, 'epoch': 4.3}
{'loss': 0.0503, 'grad_norm': 13.931747436523438, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.048793915659189224, 'loss_2': 0.001468658447265625, 'loss_3': -15.939723014831543, 'loss_4': 1.1417832374572754, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 09:45:10,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:10,819 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:37<1:16:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:18,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05239976942539215, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.667, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.05036323145031929, 'eval_loss_2': 0.002036541700363159, 'eval_loss_3': -18.014921188354492, 'eval_loss_4': 2.066136360168457, 'epoch': 4.3}
{'loss': 0.0794, 'grad_norm': 21.208608627319336, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.07542488723993301, 'loss_2': 0.00395965576171875, 'loss_3': -15.58143424987793, 'loss_4': 2.1591687202453613, 'epoch': 4.31}
{'loss': 0.0663, 'grad_norm': 13.7498197555542, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.0635601058602333, 'loss_2': 0.0027294158935546875, 'loss_3': -15.777130126953125, 'loss_4': 2.278456926345825, 'epoch': 4.31}
{'loss': 0.0733, 'grad_norm': 19.937131881713867, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.06691378355026245, 'loss_2': 0.006351470947265625, 'loss_3': -15.575679779052734, 'loss_4': 1.7961370944976807, 'epoch': 4.32}
{'loss': 0.0967, 'grad_norm': 28.961511611938477, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.08489811420440674, 'loss_2': 0.0117950439453125, 'loss_3': -15.680736541748047, 'loss_4': 2.6373281478881836, 'epoch': 4.33}
{'loss': 0.0376, 'grad_norm': 9.43297290802002, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.02852267399430275, 'loss_2': 0.00910186767578125, 'loss_3': -15.63379955291748, 'loss_4': 2.2226526737213135, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 09:45:18,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:18,160 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:45<1:16:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:25,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04504983127117157, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.795, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.03245346248149872, 'eval_loss_2': 0.012596368789672852, 'eval_loss_3': -18.06397247314453, 'eval_loss_4': 2.4778687953948975, 'epoch': 4.33}
{'loss': 0.0484, 'grad_norm': 15.284085273742676, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.040087971836328506, 'loss_2': 0.00835418701171875, 'loss_3': -16.031721115112305, 'loss_4': 2.6081795692443848, 'epoch': 4.34}
{'loss': 0.0354, 'grad_norm': 7.3690314292907715, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.018205946311354637, 'loss_2': 0.0172271728515625, 'loss_3': -15.693202018737793, 'loss_4': 2.5532240867614746, 'epoch': 4.34}
{'loss': 0.051, 'grad_norm': 16.563127517700195, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.04661734029650688, 'loss_2': 0.004405975341796875, 'loss_3': -15.807612419128418, 'loss_4': 2.86653470993042, 'epoch': 4.35}
{'loss': 0.0291, 'grad_norm': 9.08956527709961, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.026581767946481705, 'loss_2': 0.002471923828125, 'loss_3': -15.697456359863281, 'loss_4': 3.1542460918426514, 'epoch': 4.35}
{'loss': 0.0282, 'grad_norm': 8.288725852966309, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.023182662203907967, 'loss_2': 0.00498199462890625, 'loss_3': -15.698779106140137, 'loss_4': 2.826974391937256, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 09:45:25,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:25,516 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [18:52<1:16:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:32,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015030073933303356, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012186888605356216, 'eval_loss_2': 0.0028431862592697144, 'eval_loss_3': -18.19847869873047, 'eval_loss_4': 3.225085735321045, 'epoch': 4.36}
{'loss': 0.0262, 'grad_norm': 11.167458534240723, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.022542012855410576, 'loss_2': 0.003696441650390625, 'loss_3': -15.88543701171875, 'loss_4': 3.8547208309173584, 'epoch': 4.37}
{'loss': 0.0226, 'grad_norm': 8.14415454864502, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.019490791484713554, 'loss_2': 0.0030975341796875, 'loss_3': -15.933158874511719, 'loss_4': 3.5871872901916504, 'epoch': 4.37}
{'loss': 0.0275, 'grad_norm': 8.666383743286133, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.023752471432089806, 'loss_2': 0.003765106201171875, 'loss_3': -15.620296478271484, 'loss_4': 3.2006099224090576, 'epoch': 4.38}
{'loss': 0.023, 'grad_norm': 8.163617134094238, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.01940683089196682, 'loss_2': 0.003574371337890625, 'loss_3': -15.883880615234375, 'loss_4': 3.0802745819091797, 'epoch': 4.38}
{'loss': 0.0345, 'grad_norm': 13.514264106750488, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.032337505370378494, 'loss_2': 0.002170562744140625, 'loss_3': -15.808120727539062, 'loss_4': 3.7551941871643066, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 09:45:32,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:32,856 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:00<1:16:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:40,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013990409672260284, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.983, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009968706406652927, 'eval_loss_2': 0.004021704196929932, 'eval_loss_3': -18.21146583557129, 'eval_loss_4': 3.506075620651245, 'epoch': 4.39}
{'loss': 0.0234, 'grad_norm': 7.672787189483643, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.01842137984931469, 'loss_2': 0.00502777099609375, 'loss_3': -15.766905784606934, 'loss_4': 3.2122249603271484, 'epoch': 4.4}
{'loss': 0.049, 'grad_norm': 23.730253219604492, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.04584329575300217, 'loss_2': 0.003147125244140625, 'loss_3': -15.833473205566406, 'loss_4': 3.6556038856506348, 'epoch': 4.4}
{'loss': 0.029, 'grad_norm': 10.447688102722168, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.02406860515475273, 'loss_2': 0.00495147705078125, 'loss_3': -15.909721374511719, 'loss_4': 3.7046709060668945, 'epoch': 4.41}
{'loss': 0.0566, 'grad_norm': 15.562189102172852, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.050231777131557465, 'loss_2': 0.00632476806640625, 'loss_3': -15.339231491088867, 'loss_4': 3.6213579177856445, 'epoch': 4.41}
{'loss': 0.0515, 'grad_norm': 19.798397064208984, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.048668667674064636, 'loss_2': 0.0028400421142578125, 'loss_3': -15.750848770141602, 'loss_4': 3.5430383682250977, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 09:45:40,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:40,201 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:07<1:16:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:47,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017226088792085648, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.184, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.008964498527348042, 'eval_loss_2': 0.00826159119606018, 'eval_loss_3': -18.23509407043457, 'eval_loss_4': 3.3628885746002197, 'epoch': 4.42}
{'loss': 0.0204, 'grad_norm': 5.793972015380859, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.013403256423771381, 'loss_2': 0.00695037841796875, 'loss_3': -15.866903305053711, 'loss_4': 3.025960922241211, 'epoch': 4.42}
{'loss': 0.037, 'grad_norm': 10.739056587219238, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.029022622853517532, 'loss_2': 0.00799560546875, 'loss_3': -15.65300178527832, 'loss_4': 4.333558082580566, 'epoch': 4.43}
{'loss': 0.056, 'grad_norm': 17.28223991394043, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.04982123523950577, 'loss_2': 0.006130218505859375, 'loss_3': -15.62987232208252, 'loss_4': 3.566821575164795, 'epoch': 4.44}
{'loss': 0.0297, 'grad_norm': 8.566612243652344, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.027260199189186096, 'loss_2': 0.002468109130859375, 'loss_3': -15.756648063659668, 'loss_4': 4.094720363616943, 'epoch': 4.44}
{'loss': 0.0328, 'grad_norm': 10.841764450073242, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.02757267653942108, 'loss_2': 0.0052642822265625, 'loss_3': -15.908831596374512, 'loss_4': 4.371345520019531, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 09:45:47,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:47,538 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:11<1:16:00,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:45:51,348 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765
[INFO|configuration_utils.py:420] 2025-01-21 09:45:51,350 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765/config.json                                                                              
{'eval_loss': 0.010828633792698383, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.833, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008447889238595963, 'eval_loss_2': 0.002380743622779846, 'eval_loss_3': -18.232160568237305, 'eval_loss_4': 3.211458921432495, 'epoch': 4.45}
[INFO|modeling_utils.py:2988] 2025-01-21 09:45:51,855 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:45:51,856 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:45:51,856 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:45:52,691 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-700] due to args.save_total_limit
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:16<1:23:29,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:45:56,326 >>
{'loss': 0.0442, 'grad_norm': 16.312000274658203, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.04120827838778496, 'loss_2': 0.00299072265625, 'loss_3': -15.836524963378906, 'loss_4': 4.105634689331055, 'epoch': 4.45}
{'loss': 0.0776, 'grad_norm': 27.361846923828125, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.07212672382593155, 'loss_2': 0.00551605224609375, 'loss_3': -15.901237487792969, 'loss_4': 3.2099504470825195, 'epoch': 4.46}
{'loss': 0.0332, 'grad_norm': 8.068164825439453, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.028568198904395103, 'loss_2': 0.00463104248046875, 'loss_3': -15.666744232177734, 'loss_4': 2.956648349761963, 'epoch': 4.47}
{'loss': 0.0423, 'grad_norm': 10.3475341796875, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.031559720635414124, 'loss_2': 0.010772705078125, 'loss_3': -15.848219871520996, 'loss_4': 3.645345687866211, 'epoch': 4.47}
{'loss': 0.0225, 'grad_norm': 7.287890911102295, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.020689168944954872, 'loss_2': 0.0018558502197265625, 'loss_3': -16.00518035888672, 'loss_4': 3.939274787902832, 'epoch': 4.48}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:45:56,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:56,327 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:23<1:17:09,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:46:03,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01273579616099596, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00904951710253954, 'eval_loss_2': 0.003686279058456421, 'eval_loss_3': -18.214447021484375, 'eval_loss_4': 2.8260161876678467, 'epoch': 4.48}
{'loss': 0.0388, 'grad_norm': 21.381000518798828, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.03427772969007492, 'loss_2': 0.0045318603515625, 'loss_3': -15.706138610839844, 'loss_4': 3.58259916305542, 'epoch': 4.48}
{'loss': 0.0311, 'grad_norm': 14.442173957824707, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.029649613425135612, 'loss_2': 0.0014257431030273438, 'loss_3': -15.782532691955566, 'loss_4': 2.8218770027160645, 'epoch': 4.49}
{'loss': 0.0842, 'grad_norm': 25.422563552856445, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.0745193213224411, 'loss_2': 0.0096588134765625, 'loss_3': -15.638337135314941, 'loss_4': 3.332646131515503, 'epoch': 4.49}
{'loss': 0.0302, 'grad_norm': 8.202360153198242, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.02030310593545437, 'loss_2': 0.0098724365234375, 'loss_3': -15.897218704223633, 'loss_4': 2.525102138519287, 'epoch': 4.5}
{'loss': 0.0294, 'grad_norm': 5.984141826629639, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.01434119138866663, 'loss_2': 0.0150909423828125, 'loss_3': -15.981841087341309, 'loss_4': 2.62572979927063, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 09:46:03,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:03,678 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:30<1:15:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:11,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02016225829720497, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.439, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008281861431896687, 'eval_loss_2': 0.01188039779663086, 'eval_loss_3': -18.26278305053711, 'eval_loss_4': 2.243386745452881, 'epoch': 4.51}
{'loss': 0.0193, 'grad_norm': 7.235801696777344, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.016412267461419106, 'loss_2': 0.00287628173828125, 'loss_3': -15.987008094787598, 'loss_4': 2.508976936340332, 'epoch': 4.51}
{'loss': 0.0193, 'grad_norm': 5.919007301330566, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.01673809066414833, 'loss_2': 0.00257110595703125, 'loss_3': -16.020076751708984, 'loss_4': 2.576657772064209, 'epoch': 4.52}
{'loss': 0.0275, 'grad_norm': 9.133103370666504, 'learning_rate': 2.55e-05, 'loss_1': 0.025280319154262543, 'loss_2': 0.0022411346435546875, 'loss_3': -15.880206108093262, 'loss_4': 2.9750452041625977, 'epoch': 4.52}
{'loss': 0.0935, 'grad_norm': 24.84992027282715, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.08639711886644363, 'loss_2': 0.00711822509765625, 'loss_3': -15.675727844238281, 'loss_4': 2.274294853210449, 'epoch': 4.53}
{'loss': 0.0277, 'grad_norm': 8.200119018554688, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.02760477177798748, 'loss_2': 4.798173904418945e-05, 'loss_3': -15.79052448272705, 'loss_4': 2.602527618408203, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 09:46:11,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:11,005 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:34<1:15:53,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:46:14,801 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780
[INFO|configuration_utils.py:420] 2025-01-21 09:46:14,803 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780/config.json                                                                              
{'eval_loss': 0.00971845630556345, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.851, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.006922089494764805, 'eval_loss_2': 0.002796366810798645, 'eval_loss_3': -18.269315719604492, 'eval_loss_4': 1.6077908277511597, 'epoch': 4.53}
[INFO|modeling_utils.py:2988] 2025-01-21 09:46:15,321 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:46:15,322 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:46:15,322 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:46:16,164 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-765] due to args.save_total_limit
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:39<1:23:21,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:46:19,819 >>
{'loss': 0.0342, 'grad_norm': 8.933062553405762, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.026253078132867813, 'loss_2': 0.0079193115234375, 'loss_3': -16.05657386779785, 'loss_4': 2.1259148120880127, 'epoch': 4.54}
{'loss': 0.0256, 'grad_norm': 6.821440696716309, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.019886616617441177, 'loss_2': 0.0056915283203125, 'loss_3': -15.73905086517334, 'loss_4': 2.2883262634277344, 'epoch': 4.55}
{'loss': 0.0316, 'grad_norm': 7.227511882781982, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.01943611353635788, 'loss_2': 0.0121612548828125, 'loss_3': -15.9417724609375, 'loss_4': 1.704984188079834, 'epoch': 4.55}
{'loss': 0.0332, 'grad_norm': 8.032915115356445, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.027162592858076096, 'loss_2': 0.0059967041015625, 'loss_3': -15.932394027709961, 'loss_4': 1.5606251955032349, 'epoch': 4.56}
{'loss': 0.0283, 'grad_norm': 9.357780456542969, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.024772528558969498, 'loss_2': 0.003482818603515625, 'loss_3': -15.711433410644531, 'loss_4': 1.642750859260559, 'epoch': 4.56}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:46:19,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:19,819 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:46<1:16:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:46:27,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015737242996692657, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0069012101739645, 'eval_loss_2': 0.008836030960083008, 'eval_loss_3': -18.256473541259766, 'eval_loss_4': 1.1431198120117188, 'epoch': 4.56}
{'loss': 0.0186, 'grad_norm': 6.093984603881836, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.011520775966346264, 'loss_2': 0.007045745849609375, 'loss_3': -16.168405532836914, 'loss_4': 1.6454637050628662, 'epoch': 4.57}
{'loss': 0.0203, 'grad_norm': 6.149590969085693, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.013415869325399399, 'loss_2': 0.006862640380859375, 'loss_3': -16.13477325439453, 'loss_4': 1.1883201599121094, 'epoch': 4.58}
{'loss': 0.02, 'grad_norm': 6.445728302001953, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.01573076657950878, 'loss_2': 0.00426483154296875, 'loss_3': -16.23109245300293, 'loss_4': 1.0845540761947632, 'epoch': 4.58}
{'loss': 0.0416, 'grad_norm': 9.42611312866211, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.025196827948093414, 'loss_2': 0.0163726806640625, 'loss_3': -15.969255447387695, 'loss_4': 1.469428539276123, 'epoch': 4.59}
{'loss': 0.052, 'grad_norm': 17.402294158935547, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.04312810301780701, 'loss_2': 0.00884246826171875, 'loss_3': -16.04151153564453, 'loss_4': 0.8483763337135315, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 09:46:27,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:27,147 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [19:54<1:15:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:34,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012899525463581085, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00824094470590353, 'eval_loss_2': 0.0046585798263549805, 'eval_loss_3': -18.263029098510742, 'eval_loss_4': 0.574688196182251, 'epoch': 4.59}
{'loss': 0.0301, 'grad_norm': 10.565292358398438, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.02412664331495762, 'loss_2': 0.0059967041015625, 'loss_3': -16.068702697753906, 'loss_4': 0.9990659356117249, 'epoch': 4.6}
{'loss': 0.0276, 'grad_norm': 13.307347297668457, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.027237582951784134, 'loss_2': 0.0003783702850341797, 'loss_3': -15.839065551757812, 'loss_4': 0.9080585241317749, 'epoch': 4.6}
{'loss': 0.0377, 'grad_norm': 9.118614196777344, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.03221358731389046, 'loss_2': 0.005523681640625, 'loss_3': -15.925724029541016, 'loss_4': 0.6737864017486572, 'epoch': 4.61}
{'loss': 0.0195, 'grad_norm': 5.812785625457764, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.017885180190205574, 'loss_2': 0.0016231536865234375, 'loss_3': -16.267728805541992, 'loss_4': 0.9716067910194397, 'epoch': 4.62}
{'loss': 0.0162, 'grad_norm': 5.482017993927002, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.011127338744699955, 'loss_2': 0.00502777099609375, 'loss_3': -16.090810775756836, 'loss_4': 1.4443373680114746, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 09:46:34,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:34,486 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:01<1:15:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:41,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013571683317422867, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.556, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010318178683519363, 'eval_loss_2': 0.0032535046339035034, 'eval_loss_3': -18.255577087402344, 'eval_loss_4': 0.26734036207199097, 'epoch': 4.62}
{'loss': 0.022, 'grad_norm': 6.657403469085693, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.016579262912273407, 'loss_2': 0.00542449951171875, 'loss_3': -16.0202579498291, 'loss_4': 0.47747209668159485, 'epoch': 4.63}
{'loss': 0.0369, 'grad_norm': 11.144732475280762, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.02948232926428318, 'loss_2': 0.0074615478515625, 'loss_3': -16.03715705871582, 'loss_4': 0.3177570402622223, 'epoch': 4.63}
{'loss': 0.0467, 'grad_norm': 15.250665664672852, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.035030148923397064, 'loss_2': 0.01163482666015625, 'loss_3': -16.054561614990234, 'loss_4': 0.39918336272239685, 'epoch': 4.64}
{'loss': 0.0377, 'grad_norm': 13.263699531555176, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.032435446977615356, 'loss_2': 0.005214691162109375, 'loss_3': -15.942745208740234, 'loss_4': 0.31039372086524963, 'epoch': 4.65}
{'loss': 0.0282, 'grad_norm': 5.925443172454834, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.014180444180965424, 'loss_2': 0.0139923095703125, 'loss_3': -16.16646385192871, 'loss_4': 0.08432050049304962, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 09:46:41,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:41,831 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:08<1:15:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:49,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023442082107067108, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.452, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010880044661462307, 'eval_loss_2': 0.012562036514282227, 'eval_loss_3': -18.288705825805664, 'eval_loss_4': 0.05367392674088478, 'epoch': 4.65}
{'loss': 0.0343, 'grad_norm': 8.014321327209473, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.028394412249326706, 'loss_2': 0.005859375, 'loss_3': -16.12260627746582, 'loss_4': 0.4322904944419861, 'epoch': 4.66}
{'loss': 0.0827, 'grad_norm': 22.623689651489258, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.07328552007675171, 'loss_2': 0.00940704345703125, 'loss_3': -16.137699127197266, 'loss_4': 0.7260024547576904, 'epoch': 4.66}
{'loss': 0.0261, 'grad_norm': 8.321785926818848, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.019212447106838226, 'loss_2': 0.00689697265625, 'loss_3': -16.046655654907227, 'loss_4': 1.4073426723480225, 'epoch': 4.67}
{'loss': 0.0425, 'grad_norm': 16.001087188720703, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.037768736481666565, 'loss_2': 0.00472259521484375, 'loss_3': -15.988845825195312, 'loss_4': -0.2909466028213501, 'epoch': 4.67}
{'loss': 0.0548, 'grad_norm': 20.781028747558594, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.05016477778553963, 'loss_2': 0.0046234130859375, 'loss_3': -15.59420108795166, 'loss_4': 0.5173061490058899, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 09:46:49,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:49,195 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:16<1:15:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:56,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01370299607515335, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.259, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01120630744844675, 'eval_loss_2': 0.002496689558029175, 'eval_loss_3': -18.256641387939453, 'eval_loss_4': 0.19238656759262085, 'epoch': 4.68}
{'loss': 0.0431, 'grad_norm': 8.40552806854248, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.03224201500415802, 'loss_2': 0.01085662841796875, 'loss_3': -15.82990837097168, 'loss_4': 0.959494411945343, 'epoch': 4.69}
{'loss': 0.0292, 'grad_norm': 10.214890480041504, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.020763948559761047, 'loss_2': 0.0084686279296875, 'loss_3': -15.916686058044434, 'loss_4': 0.6522415280342102, 'epoch': 4.69}
{'loss': 0.0482, 'grad_norm': 17.77687644958496, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.04435938224196434, 'loss_2': 0.0038433074951171875, 'loss_3': -16.018264770507812, 'loss_4': 0.5007886290550232, 'epoch': 4.7}
{'loss': 0.019, 'grad_norm': 6.770185470581055, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.018728313967585564, 'loss_2': 0.00026607513427734375, 'loss_3': -16.028587341308594, 'loss_4': 0.8881460428237915, 'epoch': 4.7}
{'loss': 0.0272, 'grad_norm': 8.11759090423584, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.017631953582167625, 'loss_2': 0.0095977783203125, 'loss_3': -15.970483779907227, 'loss_4': 0.21911203861236572, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 09:46:56,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:56,542 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:23<1:15:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:03,887 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015358091332018375, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011557521298527718, 'eval_loss_2': 0.0038005709648132324, 'eval_loss_3': -18.21540069580078, 'eval_loss_4': 0.490550696849823, 'epoch': 4.71}
{'loss': 0.0366, 'grad_norm': 8.728822708129883, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.025657884776592255, 'loss_2': 0.010894775390625, 'loss_3': -15.796518325805664, 'loss_4': 0.5540723204612732, 'epoch': 4.72}
{'loss': 0.02, 'grad_norm': 6.4586100578308105, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.018984783440828323, 'loss_2': 0.0009984970092773438, 'loss_3': -15.945294380187988, 'loss_4': 1.040391445159912, 'epoch': 4.72}
{'loss': 0.0279, 'grad_norm': 12.410195350646973, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.02606908604502678, 'loss_2': 0.0018777847290039062, 'loss_3': -15.905821800231934, 'loss_4': 0.7163184881210327, 'epoch': 4.73}
{'loss': 0.0292, 'grad_norm': 6.604109764099121, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.020824994891881943, 'loss_2': 0.00836944580078125, 'loss_3': -16.068674087524414, 'loss_4': 0.5844846367835999, 'epoch': 4.73}
{'loss': 0.0231, 'grad_norm': 8.44887924194336, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.02250092104077339, 'loss_2': 0.0005593299865722656, 'loss_3': -15.792457580566406, 'loss_4': 0.4353543519973755, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 09:47:03,887 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:03,887 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:31<1:15:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:11,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014279808849096298, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011912557296454906, 'eval_loss_2': 0.002367250621318817, 'eval_loss_3': -18.17571258544922, 'eval_loss_4': 0.4843369126319885, 'epoch': 4.74}
{'loss': 0.023, 'grad_norm': 6.424076557159424, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.01677083596587181, 'loss_2': 0.00627899169921875, 'loss_3': -16.099912643432617, 'loss_4': 0.5760787725448608, 'epoch': 4.74}
{'loss': 0.0264, 'grad_norm': 9.478385925292969, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.02277243509888649, 'loss_2': 0.0036067962646484375, 'loss_3': -15.893298149108887, 'loss_4': 0.30097872018814087, 'epoch': 4.75}
{'loss': 0.0196, 'grad_norm': 7.352020740509033, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.018591150641441345, 'loss_2': 0.0010128021240234375, 'loss_3': -15.843269348144531, 'loss_4': 0.8266544938087463, 'epoch': 4.76}
{'loss': 0.0458, 'grad_norm': 12.288800239562988, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.03884907811880112, 'loss_2': 0.00693511962890625, 'loss_3': -15.653390884399414, 'loss_4': 0.38552653789520264, 'epoch': 4.76}
{'loss': 0.0318, 'grad_norm': 11.562856674194336, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.0303262360394001, 'loss_2': 0.0014858245849609375, 'loss_3': -15.929802894592285, 'loss_4': 0.4155503809452057, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 09:47:11,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:11,240 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:38<1:15:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:18,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014637665823101997, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012170294299721718, 'eval_loss_2': 0.0024673715233802795, 'eval_loss_3': -18.106746673583984, 'eval_loss_4': 0.5417091846466064, 'epoch': 4.77}
{'loss': 0.0539, 'grad_norm': 13.681388854980469, 'learning_rate': 2.525e-05, 'loss_1': 0.048115670680999756, 'loss_2': 0.005809783935546875, 'loss_3': -15.81495475769043, 'loss_4': 0.7185779213905334, 'epoch': 4.77}
{'loss': 0.0109, 'grad_norm': 5.492241859436035, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.00803088117390871, 'loss_2': 0.002910614013671875, 'loss_3': -15.801687240600586, 'loss_4': 0.8942971229553223, 'epoch': 4.78}
{'loss': 0.0523, 'grad_norm': 21.88921546936035, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.046562641859054565, 'loss_2': 0.0056915283203125, 'loss_3': -15.903444290161133, 'loss_4': 1.1142041683197021, 'epoch': 4.78}
{'loss': 0.02, 'grad_norm': 8.22214126586914, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.014593854546546936, 'loss_2': 0.005382537841796875, 'loss_3': -15.834171295166016, 'loss_4': 0.06770569086074829, 'epoch': 4.79}
{'loss': 0.0397, 'grad_norm': 10.755352020263672, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.03301962465047836, 'loss_2': 0.00664520263671875, 'loss_3': -15.608527183532715, 'loss_4': 0.47364580631256104, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 09:47:18,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:18,602 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:45<1:14:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:25,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020290128886699677, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.78, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.018076471984386444, 'eval_loss_2': 0.0022136569023132324, 'eval_loss_3': -18.05183982849121, 'eval_loss_4': 0.5550087690353394, 'epoch': 4.8}
{'loss': 0.014, 'grad_norm': 5.832982063293457, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.012711313553154469, 'loss_2': 0.00128173828125, 'loss_3': -15.731412887573242, 'loss_4': 0.04717734456062317, 'epoch': 4.8}
{'loss': 0.0359, 'grad_norm': 10.036430358886719, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.0314406119287014, 'loss_2': 0.0044708251953125, 'loss_3': -15.837099075317383, 'loss_4': 0.760455846786499, 'epoch': 4.81}
{'loss': 0.0334, 'grad_norm': 14.24170970916748, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.03305963799357414, 'loss_2': 0.0003178119659423828, 'loss_3': -15.726469993591309, 'loss_4': 0.8884425759315491, 'epoch': 4.81}
{'loss': 0.0431, 'grad_norm': 22.31966209411621, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.03946516662836075, 'loss_2': 0.003643035888671875, 'loss_3': -15.768531799316406, 'loss_4': 0.7828524708747864, 'epoch': 4.82}
{'loss': 0.0298, 'grad_norm': 6.870603084564209, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.018147336319088936, 'loss_2': 0.01161956787109375, 'loss_3': -15.723862648010254, 'loss_4': 0.705552339553833, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 09:47:25,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:25,959 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:53<1:15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:33,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03332368656992912, 'eval_runtime': 3.8321, 'eval_samples_per_second': 267.219, 'eval_steps_per_second': 4.175, 'eval_loss_1': 0.030749311670660973, 'eval_loss_2': 0.0025743767619132996, 'eval_loss_3': -17.99702262878418, 'eval_loss_4': 0.5964891314506531, 'epoch': 4.83}
{'loss': 0.0272, 'grad_norm': 13.466560363769531, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.024765143170952797, 'loss_2': 0.002471923828125, 'loss_3': -15.750024795532227, 'loss_4': 0.4112280309200287, 'epoch': 4.83}
{'loss': 0.0335, 'grad_norm': 11.983061790466309, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.033184245228767395, 'loss_2': 0.0003085136413574219, 'loss_3': -15.638248443603516, 'loss_4': 0.4751846194267273, 'epoch': 4.84}
{'loss': 0.0538, 'grad_norm': 20.273283004760742, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.045410607010126114, 'loss_2': 0.00835418701171875, 'loss_3': -15.891748428344727, 'loss_4': 0.3854469656944275, 'epoch': 4.84}
{'loss': 0.029, 'grad_norm': 11.53512954711914, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.026627173647284508, 'loss_2': 0.0023746490478515625, 'loss_3': -15.710113525390625, 'loss_4': 0.35674551129341125, 'epoch': 4.85}
{'loss': 0.0388, 'grad_norm': 10.699564933776855, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.03462431579828262, 'loss_2': 0.00414276123046875, 'loss_3': -15.947599411010742, 'loss_4': 0.8695037364959717, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 09:47:33,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:33,337 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:00<1:14:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:40,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019752640277147293, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016052203252911568, 'eval_loss_2': 0.003700435161590576, 'eval_loss_3': -18.076797485351562, 'eval_loss_4': 0.5242096781730652, 'epoch': 4.85}
{'loss': 0.0303, 'grad_norm': 9.785876274108887, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.022610224783420563, 'loss_2': 0.0077362060546875, 'loss_3': -15.824542999267578, 'loss_4': 0.8594503402709961, 'epoch': 4.86}
{'loss': 0.0434, 'grad_norm': 13.184024810791016, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.0418858639895916, 'loss_2': 0.00146484375, 'loss_3': -15.746960639953613, 'loss_4': 0.5025436282157898, 'epoch': 4.87}
{'loss': 0.0443, 'grad_norm': 18.853845596313477, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.04230854660272598, 'loss_2': 0.0020046234130859375, 'loss_3': -15.716444969177246, 'loss_4': 0.8742195963859558, 'epoch': 4.87}
{'loss': 0.0289, 'grad_norm': 9.443853378295898, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.021907014772295952, 'loss_2': 0.00699615478515625, 'loss_3': -15.766439437866211, 'loss_4': 1.1155273914337158, 'epoch': 4.88}
{'loss': 0.0624, 'grad_norm': 25.129688262939453, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.06122758984565735, 'loss_2': 0.0012111663818359375, 'loss_3': -15.5764799118042, 'loss_4': 0.30258363485336304, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 09:47:40,685 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:40,685 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:07<1:14:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:48,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0160968080163002, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014236359857022762, 'eval_loss_2': 0.0018604472279548645, 'eval_loss_3': -18.118816375732422, 'eval_loss_4': 0.7480041980743408, 'epoch': 4.88}
{'loss': 0.0391, 'grad_norm': 15.726530075073242, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.03644276782870293, 'loss_2': 0.00262451171875, 'loss_3': -15.842460632324219, 'loss_4': 0.7932517528533936, 'epoch': 4.89}
{'loss': 0.0205, 'grad_norm': 7.95318603515625, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.019962267950177193, 'loss_2': 0.0004954338073730469, 'loss_3': -15.777591705322266, 'loss_4': 0.7596571445465088, 'epoch': 4.9}
{'loss': 0.0328, 'grad_norm': 12.033072471618652, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.02593010850250721, 'loss_2': 0.0068817138671875, 'loss_3': -15.776128768920898, 'loss_4': 1.587939977645874, 'epoch': 4.9}
{'loss': 0.0466, 'grad_norm': 11.037644386291504, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.045735448598861694, 'loss_2': 0.0008606910705566406, 'loss_3': -15.838330268859863, 'loss_4': 0.7399681806564331, 'epoch': 4.91}
{'loss': 0.0345, 'grad_norm': 8.385954856872559, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.030471879988908768, 'loss_2': 0.004009246826171875, 'loss_3': -15.598987579345703, 'loss_4': 1.9256948232650757, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 09:47:48,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:48,042 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:15<1:14:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:55,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01542384922504425, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.73, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011299117468297482, 'eval_loss_2': 0.004124730825424194, 'eval_loss_3': -18.165023803710938, 'eval_loss_4': 1.4294551610946655, 'epoch': 4.91}
{'loss': 0.0176, 'grad_norm': 6.094930648803711, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.015144474804401398, 'loss_2': 0.0025005340576171875, 'loss_3': -15.731791496276855, 'loss_4': 0.9695945382118225, 'epoch': 4.92}
{'loss': 0.023, 'grad_norm': 9.334254264831543, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.021365512162446976, 'loss_2': 0.0016574859619140625, 'loss_3': -15.786630630493164, 'loss_4': 1.901094913482666, 'epoch': 4.92}
{'loss': 0.027, 'grad_norm': 11.260390281677246, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.02632223442196846, 'loss_2': 0.0007219314575195312, 'loss_3': -15.796709060668945, 'loss_4': 1.8282283544540405, 'epoch': 4.93}
{'loss': 0.0306, 'grad_norm': 12.485055923461914, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.026709340512752533, 'loss_2': 0.0038909912109375, 'loss_3': -16.00309181213379, 'loss_4': 1.704744577407837, 'epoch': 4.94}
{'loss': 0.0583, 'grad_norm': 16.01382827758789, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.056602463126182556, 'loss_2': 0.0016937255859375, 'loss_3': -15.739843368530273, 'loss_4': 1.47819185256958, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 09:47:55,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:55,404 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:22<1:14:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:02,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011906227096915245, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008815995417535305, 'eval_loss_2': 0.0030902326107025146, 'eval_loss_3': -18.226390838623047, 'eval_loss_4': 1.7772364616394043, 'epoch': 4.94}
{'loss': 0.0587, 'grad_norm': 22.39500617980957, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.05192490667104721, 'loss_2': 0.0068206787109375, 'loss_3': -15.602388381958008, 'loss_4': 1.8099031448364258, 'epoch': 4.95}
{'loss': 0.0377, 'grad_norm': 18.880840301513672, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.03539973124861717, 'loss_2': 0.0023193359375, 'loss_3': -15.667323112487793, 'loss_4': 1.6938432455062866, 'epoch': 4.95}
{'loss': 0.0222, 'grad_norm': 10.436951637268066, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.01936819590628147, 'loss_2': 0.002864837646484375, 'loss_3': -15.887104034423828, 'loss_4': 2.2232022285461426, 'epoch': 4.96}
{'loss': 0.0154, 'grad_norm': 6.657743453979492, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.015358615666627884, 'loss_2': 4.506111145019531e-05, 'loss_3': -15.678577423095703, 'loss_4': 2.8515703678131104, 'epoch': 4.97}
{'loss': 0.051, 'grad_norm': 17.051319122314453, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.05036956071853638, 'loss_2': 0.0006213188171386719, 'loss_3': -16.046388626098633, 'loss_4': 3.860257863998413, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 09:48:02,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:02,756 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:29<1:07:01,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 09:48:09,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018191972747445107, 'eval_runtime': 3.8213, 'eval_samples_per_second': 267.97, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.010328571312129498, 'eval_loss_2': 0.007863402366638184, 'eval_loss_3': -18.29107666015625, 'eval_loss_4': 3.169250965118408, 'epoch': 4.97}
{'loss': 0.0287, 'grad_norm': 9.633666038513184, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.02245407924056053, 'loss_2': 0.006198883056640625, 'loss_3': -15.781584739685059, 'loss_4': 3.7485909461975098, 'epoch': 4.98}
{'loss': 0.0474, 'grad_norm': 11.768345832824707, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.037196118384599686, 'loss_2': 0.0102386474609375, 'loss_3': -15.967412948608398, 'loss_4': 4.05148983001709, 'epoch': 4.98}
{'loss': 0.0369, 'grad_norm': 7.902279376983643, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.019956475123763084, 'loss_2': 0.01690673828125, 'loss_3': -15.844460487365723, 'loss_4': 3.9929347038269043, 'epoch': 4.99}
{'loss': 0.0342, 'grad_norm': 7.62354850769043, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.023814087733626366, 'loss_2': 0.01038360595703125, 'loss_3': -15.827000617980957, 'loss_4': 5.467953681945801, 'epoch': 4.99}
{'loss': 0.0163, 'grad_norm': 8.409318923950195, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.013574477285146713, 'loss_2': 0.0027523040771484375, 'loss_3': -15.944191932678223, 'loss_4': 4.24368143081665, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 09:48:09,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:09,770 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:36<1:13:18,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:48:17,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016639091074466705, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.99, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011785723268985748, 'eval_loss_2': 0.004853367805480957, 'eval_loss_3': -18.312204360961914, 'eval_loss_4': 4.043270111083984, 'epoch': 5.0}
{'loss': 0.0408, 'grad_norm': 10.194465637207031, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.027461709454655647, 'loss_2': 0.0132904052734375, 'loss_3': -15.938961029052734, 'loss_4': 4.203863143920898, 'epoch': 5.01}
{'loss': 0.0387, 'grad_norm': 12.757013320922852, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.036483000963926315, 'loss_2': 0.0022430419921875, 'loss_3': -15.946784019470215, 'loss_4': 4.762564659118652, 'epoch': 5.01}
{'loss': 0.0427, 'grad_norm': 11.496533393859863, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.03437400981783867, 'loss_2': 0.00830078125, 'loss_3': -16.015422821044922, 'loss_4': 4.288750648498535, 'epoch': 5.02}
{'loss': 0.0248, 'grad_norm': 7.105419635772705, 'learning_rate': 2.5e-05, 'loss_1': 0.019690636545419693, 'loss_2': 0.00514984130859375, 'loss_3': -15.668498992919922, 'loss_4': 4.304403781890869, 'epoch': 5.02}
{'loss': 0.0343, 'grad_norm': 8.572649002075195, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.029766684398055077, 'loss_2': 0.0045166015625, 'loss_3': -16.012710571289062, 'loss_4': 3.7863545417785645, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 09:48:17,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:17,164 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:44<1:14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:24,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012969639152288437, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.697, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009279278106987476, 'eval_loss_2': 0.003690361976623535, 'eval_loss_3': -18.334226608276367, 'eval_loss_4': 3.730281352996826, 'epoch': 5.03}
{'loss': 0.0448, 'grad_norm': 13.1212739944458, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.03949853777885437, 'loss_2': 0.005340576171875, 'loss_3': -15.983552932739258, 'loss_4': 3.9878883361816406, 'epoch': 5.03}
{'loss': 0.0248, 'grad_norm': 6.370758056640625, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.01772199384868145, 'loss_2': 0.007083892822265625, 'loss_3': -15.846872329711914, 'loss_4': 4.026953220367432, 'epoch': 5.04}
{'loss': 0.0307, 'grad_norm': 9.42119026184082, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.029960354790091515, 'loss_2': 0.0006918907165527344, 'loss_3': -15.893156051635742, 'loss_4': 4.3416948318481445, 'epoch': 5.05}
{'loss': 0.0511, 'grad_norm': 18.110815048217773, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.049557480961084366, 'loss_2': 0.0015773773193359375, 'loss_3': -15.769407272338867, 'loss_4': 4.325619697570801, 'epoch': 5.05}
{'loss': 0.052, 'grad_norm': 13.543017387390137, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.041988518089056015, 'loss_2': 0.010009765625, 'loss_3': -15.968917846679688, 'loss_4': 4.1350998878479, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 09:48:24,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:24,520 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:51<1:14:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:31,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01852438971400261, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.712, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010210853070020676, 'eval_loss_2': 0.008313536643981934, 'eval_loss_3': -18.305538177490234, 'eval_loss_4': 3.174245595932007, 'epoch': 5.06}
{'loss': 0.0532, 'grad_norm': 18.808683395385742, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.0488056018948555, 'loss_2': 0.00435638427734375, 'loss_3': -15.663435935974121, 'loss_4': 3.621530532836914, 'epoch': 5.06}
{'loss': 0.0453, 'grad_norm': 14.763594627380371, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.03663129359483719, 'loss_2': 0.00867462158203125, 'loss_3': -15.693669319152832, 'loss_4': 3.3206984996795654, 'epoch': 5.07}
{'loss': 0.0266, 'grad_norm': 8.487486839294434, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.0202631838619709, 'loss_2': 0.0063018798828125, 'loss_3': -15.915754318237305, 'loss_4': 3.4309113025665283, 'epoch': 5.08}
{'loss': 0.0293, 'grad_norm': 9.186881065368652, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.024439267814159393, 'loss_2': 0.0048980712890625, 'loss_3': -15.87855052947998, 'loss_4': 2.624695062637329, 'epoch': 5.08}
{'loss': 0.0302, 'grad_norm': 10.24280834197998, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.027660273015499115, 'loss_2': 0.0025119781494140625, 'loss_3': -15.923333168029785, 'loss_4': 3.5116617679595947, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 09:48:31,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:31,879 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [21:59<1:14:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:39,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016063256189227104, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.888, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010734273120760918, 'eval_loss_2': 0.0053289830684661865, 'eval_loss_3': -18.285236358642578, 'eval_loss_4': 2.823000192642212, 'epoch': 5.09}
{'loss': 0.0117, 'grad_norm': 5.664390563964844, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.00900590792298317, 'loss_2': 0.0026760101318359375, 'loss_3': -15.99921989440918, 'loss_4': 2.652710437774658, 'epoch': 5.09}
{'loss': 0.0144, 'grad_norm': 5.134890556335449, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.011305849999189377, 'loss_2': 0.003124237060546875, 'loss_3': -15.837873458862305, 'loss_4': 2.72450590133667, 'epoch': 5.1}
{'loss': 0.0771, 'grad_norm': 24.210847854614258, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.07430698722600937, 'loss_2': 0.002811431884765625, 'loss_3': -15.686513900756836, 'loss_4': 3.3537838459014893, 'epoch': 5.1}
{'loss': 0.0186, 'grad_norm': 5.828359603881836, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.01207741443067789, 'loss_2': 0.00656890869140625, 'loss_3': -15.884025573730469, 'loss_4': 2.8051795959472656, 'epoch': 5.11}
{'loss': 0.0338, 'grad_norm': 9.989042282104492, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.02857990376651287, 'loss_2': 0.005191802978515625, 'loss_3': -15.836912155151367, 'loss_4': 2.755490303039551, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 09:48:39,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:39,235 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:06<1:14:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:46,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01449510082602501, 'eval_runtime': 3.8226, 'eval_samples_per_second': 267.883, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.011964407749474049, 'eval_loss_2': 0.002530694007873535, 'eval_loss_3': -18.256132125854492, 'eval_loss_4': 2.5049662590026855, 'epoch': 5.12}
{'loss': 0.0293, 'grad_norm': 10.383259773254395, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.026217592880129814, 'loss_2': 0.0030574798583984375, 'loss_3': -15.890851020812988, 'loss_4': 2.6672744750976562, 'epoch': 5.12}
{'loss': 0.0335, 'grad_norm': 9.045434951782227, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.025717679411172867, 'loss_2': 0.007747650146484375, 'loss_3': -15.964447975158691, 'loss_4': 2.4715089797973633, 'epoch': 5.13}
{'loss': 0.0297, 'grad_norm': 9.568132400512695, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.029700331389904022, 'loss_2': 4.9233436584472656e-05, 'loss_3': -15.807964324951172, 'loss_4': 2.4492125511169434, 'epoch': 5.13}
{'loss': 0.0562, 'grad_norm': 15.570112228393555, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.04725886136293411, 'loss_2': 0.00896453857421875, 'loss_3': -15.92977523803711, 'loss_4': 3.029945135116577, 'epoch': 5.14}
{'loss': 0.0137, 'grad_norm': 5.844829559326172, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.013196525163948536, 'loss_2': 0.0005049705505371094, 'loss_3': -15.768749237060547, 'loss_4': 2.35514235496521, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 09:48:46,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:46,617 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:13<1:14:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:53,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01863100379705429, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.235, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011360756121575832, 'eval_loss_2': 0.007270246744155884, 'eval_loss_3': -18.25529670715332, 'eval_loss_4': 2.443347930908203, 'epoch': 5.15}
{'loss': 0.0277, 'grad_norm': 7.700966835021973, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.025979578495025635, 'loss_2': 0.0017375946044921875, 'loss_3': -15.837835311889648, 'loss_4': 2.3933353424072266, 'epoch': 5.15}
{'loss': 0.0416, 'grad_norm': 10.616464614868164, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.03344275429844856, 'loss_2': 0.0081634521484375, 'loss_3': -15.98271369934082, 'loss_4': 3.040771245956421, 'epoch': 5.16}
{'loss': 0.0207, 'grad_norm': 6.102443218231201, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.015789290890097618, 'loss_2': 0.0049591064453125, 'loss_3': -15.775975227355957, 'loss_4': 2.481546640396118, 'epoch': 5.16}
{'loss': 0.0538, 'grad_norm': 14.761100769042969, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.05190185457468033, 'loss_2': 0.001865386962890625, 'loss_3': -15.990716934204102, 'loss_4': 2.7983908653259277, 'epoch': 5.17}
{'loss': 0.0226, 'grad_norm': 6.330593109130859, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.015632133930921555, 'loss_2': 0.0070037841796875, 'loss_3': -16.011436462402344, 'loss_4': 2.521606683731079, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 09:48:53,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:53,975 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:21<1:13:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:01,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016285385936498642, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.247, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013036239892244339, 'eval_loss_2': 0.003249146044254303, 'eval_loss_3': -18.242084503173828, 'eval_loss_4': 2.554368019104004, 'epoch': 5.17}
{'loss': 0.0213, 'grad_norm': 7.748282432556152, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.0206117182970047, 'loss_2': 0.0006847381591796875, 'loss_3': -15.817317962646484, 'loss_4': 2.6202735900878906, 'epoch': 5.18}
{'loss': 0.0475, 'grad_norm': 16.143224716186523, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.04069101810455322, 'loss_2': 0.0068206787109375, 'loss_3': -15.890714645385742, 'loss_4': 2.9342050552368164, 'epoch': 5.19}
{'loss': 0.0417, 'grad_norm': 10.163818359375, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.02760910615324974, 'loss_2': 0.01404571533203125, 'loss_3': -15.764888763427734, 'loss_4': 2.617884874343872, 'epoch': 5.19}
{'loss': 0.0184, 'grad_norm': 6.510878562927246, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.01621454581618309, 'loss_2': 0.00213623046875, 'loss_3': -15.875812530517578, 'loss_4': 2.7812914848327637, 'epoch': 5.2}
{'loss': 0.0306, 'grad_norm': 6.963195323944092, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.01953127421438694, 'loss_2': 0.01105499267578125, 'loss_3': -15.839542388916016, 'loss_4': 2.6299185752868652, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 09:49:01,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:01,322 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:28<1:13:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:08,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023864734917879105, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013745295815169811, 'eval_loss_2': 0.010119438171386719, 'eval_loss_3': -18.273454666137695, 'eval_loss_4': 2.426067590713501, 'epoch': 5.2}
{'loss': 0.0539, 'grad_norm': 13.673260688781738, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.042308978736400604, 'loss_2': 0.0115814208984375, 'loss_3': -15.822715759277344, 'loss_4': 2.5029306411743164, 'epoch': 5.21}
{'loss': 0.0668, 'grad_norm': 20.165042877197266, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.057126957923173904, 'loss_2': 0.0097198486328125, 'loss_3': -15.958978652954102, 'loss_4': 3.0520362854003906, 'epoch': 5.22}
{'loss': 0.0605, 'grad_norm': 28.397411346435547, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.0544472299516201, 'loss_2': 0.00600433349609375, 'loss_3': -15.927206993103027, 'loss_4': 2.5371549129486084, 'epoch': 5.22}
{'loss': 0.0238, 'grad_norm': 6.492705345153809, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.017450908198952675, 'loss_2': 0.00630950927734375, 'loss_3': -15.888187408447266, 'loss_4': 2.2474799156188965, 'epoch': 5.23}
{'loss': 0.0259, 'grad_norm': 9.921906471252441, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.023158704861998558, 'loss_2': 0.002727508544921875, 'loss_3': -15.977848052978516, 'loss_4': 2.5696661472320557, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 09:49:08,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:08,667 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:35<1:13:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:16,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02103772759437561, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.468, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016357988119125366, 'eval_loss_2': 0.004679739475250244, 'eval_loss_3': -18.249067306518555, 'eval_loss_4': 2.15970516204834, 'epoch': 5.23}
{'loss': 0.0158, 'grad_norm': 7.049037456512451, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.013469519093632698, 'loss_2': 0.00232696533203125, 'loss_3': -15.87236213684082, 'loss_4': 2.230679512023926, 'epoch': 5.24}
{'loss': 0.0417, 'grad_norm': 15.602407455444336, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.03569719195365906, 'loss_2': 0.0060272216796875, 'loss_3': -15.897848129272461, 'loss_4': 2.8334226608276367, 'epoch': 5.24}
{'loss': 0.0255, 'grad_norm': 8.551176071166992, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.017503799870610237, 'loss_2': 0.00798797607421875, 'loss_3': -16.08072280883789, 'loss_4': 2.4007275104522705, 'epoch': 5.25}
{'loss': 0.0785, 'grad_norm': 26.401504516601562, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.07440011203289032, 'loss_2': 0.00406646728515625, 'loss_3': -15.865716934204102, 'loss_4': 2.3669486045837402, 'epoch': 5.26}
{'loss': 0.0644, 'grad_norm': 17.82951545715332, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.054192543029785156, 'loss_2': 0.01019287109375, 'loss_3': -15.890000343322754, 'loss_4': 1.6618258953094482, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 09:49:16,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:16,009 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:43<1:13:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:23,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025199709460139275, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.016171393916010857, 'eval_loss_2': 0.009028315544128418, 'eval_loss_3': -18.246559143066406, 'eval_loss_4': 1.7579669952392578, 'epoch': 5.26}
{'loss': 0.0247, 'grad_norm': 5.702940464019775, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.012084957212209702, 'loss_2': 0.01263427734375, 'loss_3': -15.97304916381836, 'loss_4': 1.8302161693572998, 'epoch': 5.27}
{'loss': 0.0208, 'grad_norm': 9.08630657196045, 'learning_rate': 2.475e-05, 'loss_1': 0.020562177523970604, 'loss_2': 0.000202178955078125, 'loss_3': -15.825439453125, 'loss_4': 1.9285047054290771, 'epoch': 5.27}
{'loss': 0.0161, 'grad_norm': 7.141643047332764, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.01605490781366825, 'loss_2': 5.799531936645508e-05, 'loss_3': -15.933719635009766, 'loss_4': 2.107788562774658, 'epoch': 5.28}
{'loss': 0.0273, 'grad_norm': 10.221373558044434, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.022189779207110405, 'loss_2': 0.0051422119140625, 'loss_3': -15.769187927246094, 'loss_4': 1.7878551483154297, 'epoch': 5.28}
{'loss': 0.0319, 'grad_norm': 10.584285736083984, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.031320296227931976, 'loss_2': 0.0005993843078613281, 'loss_3': -16.062660217285156, 'loss_4': 1.8285918235778809, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 09:49:23,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:23,362 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:50<1:13:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:30,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020055582746863365, 'eval_runtime': 3.846, 'eval_samples_per_second': 266.249, 'eval_steps_per_second': 4.16, 'eval_loss_1': 0.017046738415956497, 'eval_loss_2': 0.0030088424682617188, 'eval_loss_3': -18.236783981323242, 'eval_loss_4': 1.4168661832809448, 'epoch': 5.29}
{'loss': 0.0559, 'grad_norm': 15.460088729858398, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.050747018307447433, 'loss_2': 0.005161285400390625, 'loss_3': -15.978939056396484, 'loss_4': 1.8850371837615967, 'epoch': 5.3}
{'loss': 0.076, 'grad_norm': 22.13983154296875, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.06860517710447311, 'loss_2': 0.00734710693359375, 'loss_3': -15.931660652160645, 'loss_4': 1.5818618535995483, 'epoch': 5.3}
{'loss': 0.0436, 'grad_norm': 10.212108612060547, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.03358908370137215, 'loss_2': 0.010009765625, 'loss_3': -15.895438194274902, 'loss_4': 1.9054038524627686, 'epoch': 5.31}
{'loss': 0.0256, 'grad_norm': 6.116783618927002, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.018047908321022987, 'loss_2': 0.007568359375, 'loss_3': -15.892391204833984, 'loss_4': 1.853651762008667, 'epoch': 5.31}
{'loss': 0.0309, 'grad_norm': 9.226913452148438, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.02352912165224552, 'loss_2': 0.007343292236328125, 'loss_3': -16.05716323852539, 'loss_4': 1.9500651359558105, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 09:49:30,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:30,753 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [22:57<1:13:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:38,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017878130078315735, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013400828465819359, 'eval_loss_2': 0.004477303475141525, 'eval_loss_3': -18.30118179321289, 'eval_loss_4': 1.5256054401397705, 'epoch': 5.32}
{'loss': 0.0242, 'grad_norm': 5.658153057098389, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.017203180119395256, 'loss_2': 0.0070343017578125, 'loss_3': -16.184032440185547, 'loss_4': 1.8160345554351807, 'epoch': 5.33}
{'loss': 0.0218, 'grad_norm': 8.535012245178223, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.019084271043539047, 'loss_2': 0.00269317626953125, 'loss_3': -16.10770034790039, 'loss_4': 2.010057210922241, 'epoch': 5.33}
{'loss': 0.0315, 'grad_norm': 10.668587684631348, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.029441334307193756, 'loss_2': 0.00202178955078125, 'loss_3': -15.994656562805176, 'loss_4': 2.6105880737304688, 'epoch': 5.34}
{'loss': 0.0302, 'grad_norm': 6.283022880554199, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.017156334593892097, 'loss_2': 0.0130767822265625, 'loss_3': -16.216835021972656, 'loss_4': 1.5438525676727295, 'epoch': 5.34}
{'loss': 0.0333, 'grad_norm': 9.744114875793457, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.02654854953289032, 'loss_2': 0.0067291259765625, 'loss_3': -16.139015197753906, 'loss_4': 2.0523693561553955, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 09:49:38,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:38,100 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:05<1:13:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:45,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019157912582159042, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.391, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012700583785772324, 'eval_loss_2': 0.006457328796386719, 'eval_loss_3': -18.27927017211914, 'eval_loss_4': 1.7376036643981934, 'epoch': 5.35}
{'loss': 0.0356, 'grad_norm': 10.583477020263672, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.024701207876205444, 'loss_2': 0.01090240478515625, 'loss_3': -16.179046630859375, 'loss_4': 2.227994441986084, 'epoch': 5.35}
{'loss': 0.0417, 'grad_norm': 15.35716438293457, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.04056142270565033, 'loss_2': 0.001132965087890625, 'loss_3': -16.154632568359375, 'loss_4': 2.1957175731658936, 'epoch': 5.36}
{'loss': 0.0251, 'grad_norm': 15.34451961517334, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.022262083366513252, 'loss_2': 0.00281524658203125, 'loss_3': -16.019027709960938, 'loss_4': 2.2284624576568604, 'epoch': 5.37}
{'loss': 0.0161, 'grad_norm': 6.971750736236572, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.014953156001865864, 'loss_2': 0.0011377334594726562, 'loss_3': -15.944851875305176, 'loss_4': 2.192315101623535, 'epoch': 5.37}
{'loss': 0.0307, 'grad_norm': 8.233922004699707, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.027476266026496887, 'loss_2': 0.0031890869140625, 'loss_3': -16.122241973876953, 'loss_4': 2.42175030708313, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 09:49:45,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:45,442 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:12<1:13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:52,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014200691133737564, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010971656069159508, 'eval_loss_2': 0.003229033201932907, 'eval_loss_3': -18.272382736206055, 'eval_loss_4': 1.938930869102478, 'epoch': 5.38}
{'loss': 0.0165, 'grad_norm': 5.8313822746276855, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.015003226697444916, 'loss_2': 0.0014829635620117188, 'loss_3': -15.983257293701172, 'loss_4': 2.233412742614746, 'epoch': 5.38}
{'loss': 0.0455, 'grad_norm': 17.038686752319336, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.04451426491141319, 'loss_2': 0.0010223388671875, 'loss_3': -16.063173294067383, 'loss_4': 2.8424150943756104, 'epoch': 5.39}
{'loss': 0.0189, 'grad_norm': 10.397993087768555, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.017224736511707306, 'loss_2': 0.001644134521484375, 'loss_3': -15.868544578552246, 'loss_4': 2.7422080039978027, 'epoch': 5.4}
{'loss': 0.0204, 'grad_norm': 11.507184028625488, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.017925601452589035, 'loss_2': 0.0024776458740234375, 'loss_3': -16.11982536315918, 'loss_4': 1.8344736099243164, 'epoch': 5.4}
{'loss': 0.036, 'grad_norm': 10.926168441772461, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.030274735763669014, 'loss_2': 0.005741119384765625, 'loss_3': -16.115375518798828, 'loss_4': 3.1837658882141113, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 09:49:52,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:52,788 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:19<1:13:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:00,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017872752621769905, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013760031200945377, 'eval_loss_2': 0.004112720489501953, 'eval_loss_3': -18.21906852722168, 'eval_loss_4': 2.116264581680298, 'epoch': 5.41}
{'loss': 0.0348, 'grad_norm': 12.938072204589844, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.025272497907280922, 'loss_2': 0.0095367431640625, 'loss_3': -15.930057525634766, 'loss_4': 2.00618052482605, 'epoch': 5.41}
{'loss': 0.0175, 'grad_norm': 6.562747478485107, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.016762571409344673, 'loss_2': 0.000762939453125, 'loss_3': -15.975373268127441, 'loss_4': 2.122718572616577, 'epoch': 5.42}
{'loss': 0.0368, 'grad_norm': 10.721278190612793, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.035248320549726486, 'loss_2': 0.00157928466796875, 'loss_3': -15.906557083129883, 'loss_4': 2.075993299484253, 'epoch': 5.42}
{'loss': 0.0156, 'grad_norm': 5.6217875480651855, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.014340618625283241, 'loss_2': 0.0012731552124023438, 'loss_3': -16.151569366455078, 'loss_4': 2.439976215362549, 'epoch': 5.43}
{'loss': 0.018, 'grad_norm': 5.34849214553833, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.0088597247377038, 'loss_2': 0.00909423828125, 'loss_3': -15.934718132019043, 'loss_4': 2.3606371879577637, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 09:50:00,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:00,137 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:27<1:13:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:07,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015147116035223007, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.804, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011924631893634796, 'eval_loss_2': 0.003222484141588211, 'eval_loss_3': -18.252761840820312, 'eval_loss_4': 2.195035934448242, 'epoch': 5.44}
{'loss': 0.0237, 'grad_norm': 9.157896041870117, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.01919175498187542, 'loss_2': 0.004489898681640625, 'loss_3': -15.91776180267334, 'loss_4': 2.331212282180786, 'epoch': 5.44}
{'loss': 0.0241, 'grad_norm': 11.562817573547363, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.02281956560909748, 'loss_2': 0.001277923583984375, 'loss_3': -16.04904556274414, 'loss_4': 2.5559325218200684, 'epoch': 5.45}
{'loss': 0.0272, 'grad_norm': 8.100476264953613, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.024868838489055634, 'loss_2': 0.002368927001953125, 'loss_3': -15.965021133422852, 'loss_4': 2.297586441040039, 'epoch': 5.45}
{'loss': 0.0382, 'grad_norm': 19.720041275024414, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.03301302716135979, 'loss_2': 0.0051727294921875, 'loss_3': -16.083528518676758, 'loss_4': 2.608793258666992, 'epoch': 5.46}
{'loss': 0.0156, 'grad_norm': 5.941514015197754, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.015523013658821583, 'loss_2': 0.00010406970977783203, 'loss_3': -16.227888107299805, 'loss_4': 2.824547052383423, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 09:50:07,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:07,507 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:34<1:13:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:14,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014824269339442253, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.071, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01168772391974926, 'eval_loss_2': 0.003136545419692993, 'eval_loss_3': -18.264732360839844, 'eval_loss_4': 1.9433000087738037, 'epoch': 5.47}
{'loss': 0.045, 'grad_norm': 13.409408569335938, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.04124701768159866, 'loss_2': 0.00374603271484375, 'loss_3': -15.94384765625, 'loss_4': 2.694084882736206, 'epoch': 5.47}
{'loss': 0.0206, 'grad_norm': 5.688360214233398, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.012172052636742592, 'loss_2': 0.008453369140625, 'loss_3': -15.86347770690918, 'loss_4': 2.4290690422058105, 'epoch': 5.48}
{'loss': 0.0342, 'grad_norm': 7.1140875816345215, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.025619668886065483, 'loss_2': 0.00858306884765625, 'loss_3': -16.021934509277344, 'loss_4': 2.1065142154693604, 'epoch': 5.48}
{'loss': 0.0301, 'grad_norm': 9.544700622558594, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.02329239249229431, 'loss_2': 0.0067596435546875, 'loss_3': -16.213027954101562, 'loss_4': 2.4731454849243164, 'epoch': 5.49}
{'loss': 0.03, 'grad_norm': 9.258429527282715, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.024902760982513428, 'loss_2': 0.0050811767578125, 'loss_3': -16.077964782714844, 'loss_4': 2.4979500770568848, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 09:50:14,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:14,864 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:42<1:12:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:22,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01697560027241707, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012675484642386436, 'eval_loss_2': 0.004300117492675781, 'eval_loss_3': -18.272645950317383, 'eval_loss_4': 1.85773503780365, 'epoch': 5.49}
{'loss': 0.0201, 'grad_norm': 8.788167953491211, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.017104750499129295, 'loss_2': 0.002994537353515625, 'loss_3': -16.021385192871094, 'loss_4': 2.197953462600708, 'epoch': 5.5}
{'loss': 0.0249, 'grad_norm': 11.08436107635498, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.02308017760515213, 'loss_2': 0.0018444061279296875, 'loss_3': -15.963846206665039, 'loss_4': 2.489454746246338, 'epoch': 5.51}
{'loss': 0.0261, 'grad_norm': 6.300854206085205, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.019171951338648796, 'loss_2': 0.0068817138671875, 'loss_3': -16.126937866210938, 'loss_4': 2.250882148742676, 'epoch': 5.51}
{'loss': 0.0477, 'grad_norm': 23.884103775024414, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.03700952231884003, 'loss_2': 0.01073455810546875, 'loss_3': -15.89930534362793, 'loss_4': 2.631432056427002, 'epoch': 5.52}
{'loss': 0.0468, 'grad_norm': 14.387606620788574, 'learning_rate': 2.45e-05, 'loss_1': 0.03819235414266586, 'loss_2': 0.0086212158203125, 'loss_3': -15.97274398803711, 'loss_4': 2.6297318935394287, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 09:50:22,219 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:22,219 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:49<1:12:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:29,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023396087810397148, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.998, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011937215924263, 'eval_loss_2': 0.011458873748779297, 'eval_loss_3': -18.27686882019043, 'eval_loss_4': 2.0023021697998047, 'epoch': 5.52}
{'loss': 0.0717, 'grad_norm': 20.997272491455078, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.05567589029669762, 'loss_2': 0.01605224609375, 'loss_3': -15.971504211425781, 'loss_4': 3.158884048461914, 'epoch': 5.53}
{'loss': 0.0412, 'grad_norm': 12.088765144348145, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.03342452645301819, 'loss_2': 0.007762908935546875, 'loss_3': -15.856735229492188, 'loss_4': 2.247283935546875, 'epoch': 5.53}
{'loss': 0.0324, 'grad_norm': 6.098480224609375, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.016584087163209915, 'loss_2': 0.015777587890625, 'loss_3': -15.891151428222656, 'loss_4': 2.495136260986328, 'epoch': 5.54}
{'loss': 0.0329, 'grad_norm': 8.47457504272461, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.027284950017929077, 'loss_2': 0.0056304931640625, 'loss_3': -16.14392852783203, 'loss_4': 2.5625901222229004, 'epoch': 5.55}
{'loss': 0.0344, 'grad_norm': 10.93891716003418, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.026428746059536934, 'loss_2': 0.0079803466796875, 'loss_3': -15.95677661895752, 'loss_4': 3.078061580657959, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 09:50:29,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:29,572 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [23:56<1:12:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:36,922 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012885547243058681, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.362, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010519138537347317, 'eval_loss_2': 0.0023664087057113647, 'eval_loss_3': -18.306066513061523, 'eval_loss_4': 1.9335286617279053, 'epoch': 5.55}
{'loss': 0.0271, 'grad_norm': 7.52081298828125, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.02451351098716259, 'loss_2': 0.002620697021484375, 'loss_3': -15.845108985900879, 'loss_4': 2.2297122478485107, 'epoch': 5.56}
{'loss': 0.0253, 'grad_norm': 7.267054557800293, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.019790269434452057, 'loss_2': 0.00553131103515625, 'loss_3': -16.113054275512695, 'loss_4': 1.953150749206543, 'epoch': 5.56}
{'loss': 0.0273, 'grad_norm': 8.226068496704102, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.020436633378267288, 'loss_2': 0.006877899169921875, 'loss_3': -15.967758178710938, 'loss_4': 1.9829332828521729, 'epoch': 5.57}
{'loss': 0.0249, 'grad_norm': 7.46164083480835, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.021117081865668297, 'loss_2': 0.003780364990234375, 'loss_3': -15.882495880126953, 'loss_4': 2.5703885555267334, 'epoch': 5.58}
{'loss': 0.0323, 'grad_norm': 11.709342956542969, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.027599167078733444, 'loss_2': 0.004730224609375, 'loss_3': -16.031587600708008, 'loss_4': 2.3839712142944336, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 09:50:36,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:36,922 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:04<1:12:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:44,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018034543842077255, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.924, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011152325198054314, 'eval_loss_2': 0.006882220506668091, 'eval_loss_3': -18.2904109954834, 'eval_loss_4': 1.7345877885818481, 'epoch': 5.58}
{'loss': 0.0337, 'grad_norm': 11.624702453613281, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.032893840223550797, 'loss_2': 0.000774383544921875, 'loss_3': -16.31204605102539, 'loss_4': 2.62882137298584, 'epoch': 5.59}
{'loss': 0.0224, 'grad_norm': 5.556240081787109, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.013904240913689137, 'loss_2': 0.00850677490234375, 'loss_3': -15.971757888793945, 'loss_4': 2.5441040992736816, 'epoch': 5.59}
{'loss': 0.031, 'grad_norm': 11.062254905700684, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.022741898894309998, 'loss_2': 0.0082244873046875, 'loss_3': -15.99987506866455, 'loss_4': 2.3714675903320312, 'epoch': 5.6}
{'loss': 0.0409, 'grad_norm': 9.156270027160645, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.030195802450180054, 'loss_2': 0.01068115234375, 'loss_3': -15.862276077270508, 'loss_4': 1.865752935409546, 'epoch': 5.6}
{'loss': 0.0189, 'grad_norm': 6.446323871612549, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.014302374795079231, 'loss_2': 0.0045928955078125, 'loss_3': -15.903889656066895, 'loss_4': 1.962583303451538, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 09:50:44,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:44,273 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:11<1:12:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:51,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01835234835743904, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.679, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011213202960789204, 'eval_loss_2': 0.007139146327972412, 'eval_loss_3': -18.23183822631836, 'eval_loss_4': 1.9001069068908691, 'epoch': 5.61}
{'loss': 0.0437, 'grad_norm': 9.866559982299805, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.03721892833709717, 'loss_2': 0.006500244140625, 'loss_3': -16.16016960144043, 'loss_4': 2.452970027923584, 'epoch': 5.62}
{'loss': 0.0326, 'grad_norm': 8.199646949768066, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.020860398188233376, 'loss_2': 0.011749267578125, 'loss_3': -16.223798751831055, 'loss_4': 2.5806663036346436, 'epoch': 5.62}
{'loss': 0.0171, 'grad_norm': 5.5240864753723145, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.008311044424772263, 'loss_2': 0.00881195068359375, 'loss_3': -15.994571685791016, 'loss_4': 2.389618396759033, 'epoch': 5.63}
{'loss': 0.0123, 'grad_norm': 5.502199172973633, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.008056746795773506, 'loss_2': 0.004283905029296875, 'loss_3': -15.970523834228516, 'loss_4': 2.3384249210357666, 'epoch': 5.63}
{'loss': 0.0182, 'grad_norm': 6.948524475097656, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.017579244449734688, 'loss_2': 0.0005903244018554688, 'loss_3': -15.879839897155762, 'loss_4': 2.2935004234313965, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 09:50:51,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:51,625 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:18<1:13:24,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:50:59,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014667697250843048, 'eval_runtime': 3.9902, 'eval_samples_per_second': 256.632, 'eval_steps_per_second': 4.01, 'eval_loss_1': 0.012239716947078705, 'eval_loss_2': 0.0024279803037643433, 'eval_loss_3': -18.21392059326172, 'eval_loss_4': 2.136458396911621, 'epoch': 5.64}
{'loss': 0.0417, 'grad_norm': 13.212311744689941, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.038970254361629486, 'loss_2': 0.002696990966796875, 'loss_3': -15.718711853027344, 'loss_4': 2.5770316123962402, 'epoch': 5.65}
{'loss': 0.0184, 'grad_norm': 6.2904558181762695, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.015638455748558044, 'loss_2': 0.002803802490234375, 'loss_3': -15.849291801452637, 'loss_4': 2.558816432952881, 'epoch': 5.65}
{'loss': 0.0288, 'grad_norm': 9.791608810424805, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.027874983847141266, 'loss_2': 0.0009059906005859375, 'loss_3': -15.894710540771484, 'loss_4': 2.6425538063049316, 'epoch': 5.66}
{'loss': 0.0259, 'grad_norm': 8.17475414276123, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.021619098260998726, 'loss_2': 0.0042877197265625, 'loss_3': -15.718365669250488, 'loss_4': 2.191166877746582, 'epoch': 5.66}
{'loss': 0.0252, 'grad_norm': 9.2333984375, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.024481145665049553, 'loss_2': 0.0006775856018066406, 'loss_3': -15.752482414245605, 'loss_4': 3.013190269470215, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 09:50:59,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:59,165 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:26<1:12:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:06,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015122311189770699, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011452170088887215, 'eval_loss_2': 0.003670141100883484, 'eval_loss_3': -18.239633560180664, 'eval_loss_4': 2.2770354747772217, 'epoch': 5.67}
{'loss': 0.0271, 'grad_norm': 8.156720161437988, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.025734540075063705, 'loss_2': 0.0014019012451171875, 'loss_3': -15.74850082397461, 'loss_4': 2.36234712600708, 'epoch': 5.67}
{'loss': 0.0138, 'grad_norm': 6.89396333694458, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.013804695568978786, 'loss_2': 2.9027462005615234e-05, 'loss_3': -15.981775283813477, 'loss_4': 2.178251266479492, 'epoch': 5.68}
{'loss': 0.0343, 'grad_norm': 9.162520408630371, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.0306413434445858, 'loss_2': 0.003635406494140625, 'loss_3': -15.842642784118652, 'loss_4': 2.7704787254333496, 'epoch': 5.69}
{'loss': 0.0412, 'grad_norm': 10.075660705566406, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.029462778940796852, 'loss_2': 0.01171112060546875, 'loss_3': -15.973882675170898, 'loss_4': 2.5349485874176025, 'epoch': 5.69}
{'loss': 0.018, 'grad_norm': 7.644731044769287, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.017450382933020592, 'loss_2': 0.0005197525024414062, 'loss_3': -15.877789497375488, 'loss_4': 2.235708713531494, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 09:51:06,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:06,524 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:33<1:12:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:13,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017002616077661514, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01432566624134779, 'eval_loss_2': 0.00267694890499115, 'eval_loss_3': -18.249849319458008, 'eval_loss_4': 2.383500576019287, 'epoch': 5.7}
{'loss': 0.0515, 'grad_norm': 13.752053260803223, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.05014357715845108, 'loss_2': 0.0013828277587890625, 'loss_3': -15.667742729187012, 'loss_4': 2.4455485343933105, 'epoch': 5.7}
{'loss': 0.0442, 'grad_norm': 15.910628318786621, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.041601695120334625, 'loss_2': 0.002605438232421875, 'loss_3': -15.72970199584961, 'loss_4': 2.473250150680542, 'epoch': 5.71}
{'loss': 0.0253, 'grad_norm': 6.672924518585205, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.018330633640289307, 'loss_2': 0.00701904296875, 'loss_3': -15.844646453857422, 'loss_4': 2.2622640132904053, 'epoch': 5.72}
{'loss': 0.025, 'grad_norm': 6.73962926864624, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.020858509466052055, 'loss_2': 0.0041656494140625, 'loss_3': -15.794408798217773, 'loss_4': 2.77797794342041, 'epoch': 5.72}
{'loss': 0.0693, 'grad_norm': 17.359149932861328, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.05960460752248764, 'loss_2': 0.009735107421875, 'loss_3': -15.848492622375488, 'loss_4': 2.374886989593506, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 09:51:13,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:13,888 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:41<1:12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:21,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02247645892202854, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.393, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018043989315629005, 'eval_loss_2': 0.004432469606399536, 'eval_loss_3': -18.22637176513672, 'eval_loss_4': 2.1775922775268555, 'epoch': 5.73}
{'loss': 0.0231, 'grad_norm': 6.331298828125, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.019461356103420258, 'loss_2': 0.003589630126953125, 'loss_3': -15.86349105834961, 'loss_4': 2.4586267471313477, 'epoch': 5.73}
{'loss': 0.028, 'grad_norm': 11.961780548095703, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.026035649701952934, 'loss_2': 0.0019350051879882812, 'loss_3': -16.06058692932129, 'loss_4': 2.692533493041992, 'epoch': 5.74}
{'loss': 0.0225, 'grad_norm': 7.411990165710449, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.021068064495921135, 'loss_2': 0.001461029052734375, 'loss_3': -15.796884536743164, 'loss_4': 1.5995113849639893, 'epoch': 5.74}
{'loss': 0.0263, 'grad_norm': 10.415750503540039, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.023338422179222107, 'loss_2': 0.0029296875, 'loss_3': -15.945931434631348, 'loss_4': 2.00056791305542, 'epoch': 5.75}
{'loss': 0.0251, 'grad_norm': 8.682136535644531, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.023901840671896935, 'loss_2': 0.0011806488037109375, 'loss_3': -15.921028137207031, 'loss_4': 1.7585735321044922, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 09:51:21,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:21,233 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:48<1:12:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:28,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028939584270119667, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02543581649661064, 'eval_loss_2': 0.003503769636154175, 'eval_loss_3': -18.192800521850586, 'eval_loss_4': 1.9693520069122314, 'epoch': 5.76}
{'loss': 0.024, 'grad_norm': 7.160168170928955, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.021877331659197807, 'loss_2': 0.0021209716796875, 'loss_3': -15.989371299743652, 'loss_4': 2.0930614471435547, 'epoch': 5.76}
{'loss': 0.0225, 'grad_norm': 7.211348533630371, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.01452944427728653, 'loss_2': 0.00799560546875, 'loss_3': -16.01876449584961, 'loss_4': 1.903886079788208, 'epoch': 5.77}
{'loss': 0.0312, 'grad_norm': 9.741100311279297, 'learning_rate': 2.425e-05, 'loss_1': 0.022627847269177437, 'loss_2': 0.008544921875, 'loss_3': -15.622950553894043, 'loss_4': 1.5334510803222656, 'epoch': 5.77}
{'loss': 0.0238, 'grad_norm': 7.477800369262695, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.01844526268541813, 'loss_2': 0.00534820556640625, 'loss_3': -15.978842735290527, 'loss_4': 1.8565083742141724, 'epoch': 5.78}
{'loss': 0.0181, 'grad_norm': 7.138681888580322, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.01798664778470993, 'loss_2': 0.00014698505401611328, 'loss_3': -16.143810272216797, 'loss_4': 2.4189960956573486, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 09:51:28,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:28,592 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [24:55<1:12:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:35,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03938838094472885, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.03611528128385544, 'eval_loss_2': 0.003273099660873413, 'eval_loss_3': -18.162498474121094, 'eval_loss_4': 2.0369300842285156, 'epoch': 5.78}
{'loss': 0.033, 'grad_norm': 9.460349082946777, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.02964717522263527, 'loss_2': 0.0033931732177734375, 'loss_3': -15.757498741149902, 'loss_4': 2.2188546657562256, 'epoch': 5.79}
{'loss': 0.0366, 'grad_norm': 11.492369651794434, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.02520938590168953, 'loss_2': 0.0113525390625, 'loss_3': -15.841697692871094, 'loss_4': 2.188626766204834, 'epoch': 5.8}
{'loss': 0.0364, 'grad_norm': 10.623466491699219, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.029036622494459152, 'loss_2': 0.007354736328125, 'loss_3': -15.972761154174805, 'loss_4': 2.1340694427490234, 'epoch': 5.8}
{'loss': 0.0278, 'grad_norm': 7.405074596405029, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.014269686304032803, 'loss_2': 0.013519287109375, 'loss_3': -15.993796348571777, 'loss_4': 2.045440673828125, 'epoch': 5.81}
{'loss': 0.0596, 'grad_norm': 19.09341049194336, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.044560741633176804, 'loss_2': 0.01505279541015625, 'loss_3': -15.882867813110352, 'loss_4': 2.3390119075775146, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 09:51:35,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:35,942 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:03<1:11:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:43,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030392266809940338, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0269246157258749, 'eval_loss_2': 0.003467649221420288, 'eval_loss_3': -18.209915161132812, 'eval_loss_4': 2.4952468872070312, 'epoch': 5.81}
{'loss': 0.0947, 'grad_norm': 15.546573638916016, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.09159767627716064, 'loss_2': 0.003116607666015625, 'loss_3': -16.087318420410156, 'loss_4': 2.5848610401153564, 'epoch': 5.82}
{'loss': 0.1158, 'grad_norm': 31.5509033203125, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.11153902113437653, 'loss_2': 0.0042724609375, 'loss_3': -16.14472198486328, 'loss_4': 2.9233760833740234, 'epoch': 5.83}
{'loss': 0.0272, 'grad_norm': 7.183606147766113, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.019727416336536407, 'loss_2': 0.00751495361328125, 'loss_3': -15.849502563476562, 'loss_4': 2.4165287017822266, 'epoch': 5.83}
{'loss': 0.0351, 'grad_norm': 9.635215759277344, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.030952859669923782, 'loss_2': 0.004150390625, 'loss_3': -16.032054901123047, 'loss_4': 3.057271718978882, 'epoch': 5.84}
{'loss': 0.0362, 'grad_norm': 11.749199867248535, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.03477095812559128, 'loss_2': 0.001430511474609375, 'loss_3': -15.972734451293945, 'loss_4': 3.39898681640625, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 09:51:43,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:43,295 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:10<1:11:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:50,639 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024882525205612183, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015280334278941154, 'eval_loss_2': 0.009602189064025879, 'eval_loss_3': -18.293792724609375, 'eval_loss_4': 3.0250720977783203, 'epoch': 5.84}
{'loss': 0.0839, 'grad_norm': 25.283891677856445, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.07285590469837189, 'loss_2': 0.01108551025390625, 'loss_3': -15.978530883789062, 'loss_4': 2.861804246902466, 'epoch': 5.85}
{'loss': 0.0397, 'grad_norm': 11.359206199645996, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.022293971851468086, 'loss_2': 0.017364501953125, 'loss_3': -15.901605606079102, 'loss_4': 3.173912525177002, 'epoch': 5.85}
{'loss': 0.0678, 'grad_norm': 24.68720054626465, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.06319519877433777, 'loss_2': 0.00464630126953125, 'loss_3': -15.892459869384766, 'loss_4': 3.260852336883545, 'epoch': 5.86}
{'loss': 0.0469, 'grad_norm': 11.180572509765625, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.02863466925919056, 'loss_2': 0.018280029296875, 'loss_3': -16.101085662841797, 'loss_4': 3.467402458190918, 'epoch': 5.87}
{'loss': 0.0411, 'grad_norm': 12.709705352783203, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.03769758343696594, 'loss_2': 0.00335693359375, 'loss_3': -16.054636001586914, 'loss_4': 3.313843250274658, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 09:51:50,639 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:50,639 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:17<1:11:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:57,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02239055559039116, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012214615941047668, 'eval_loss_2': 0.010175943374633789, 'eval_loss_3': -18.33025360107422, 'eval_loss_4': 3.213778495788574, 'epoch': 5.87}
{'loss': 0.0747, 'grad_norm': 22.850326538085938, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.06642002612352371, 'loss_2': 0.008270263671875, 'loss_3': -15.930864334106445, 'loss_4': 3.359614372253418, 'epoch': 5.88}
{'loss': 0.0398, 'grad_norm': 10.977276802062988, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.039572812616825104, 'loss_2': 0.0001804828643798828, 'loss_3': -15.795412063598633, 'loss_4': 3.2850165367126465, 'epoch': 5.88}
{'loss': 0.0258, 'grad_norm': 6.105520725250244, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.016985051333904266, 'loss_2': 0.008819580078125, 'loss_3': -15.976045608520508, 'loss_4': 3.2097549438476562, 'epoch': 5.89}
{'loss': 0.0239, 'grad_norm': 8.38371467590332, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.01899043470621109, 'loss_2': 0.004947662353515625, 'loss_3': -15.980958938598633, 'loss_4': 3.460524559020996, 'epoch': 5.9}
{'loss': 0.0536, 'grad_norm': 24.864545822143555, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.05130314454436302, 'loss_2': 0.002277374267578125, 'loss_3': -16.076414108276367, 'loss_4': 3.3092217445373535, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 09:51:57,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:57,993 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:25<1:11:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:05,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01593003049492836, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.666, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010231112129986286, 'eval_loss_2': 0.0056989192962646484, 'eval_loss_3': -18.326353073120117, 'eval_loss_4': 3.075687885284424, 'epoch': 5.9}
{'loss': 0.0216, 'grad_norm': 12.643270492553711, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.01996644027531147, 'loss_2': 0.001678466796875, 'loss_3': -16.051292419433594, 'loss_4': 3.074580192565918, 'epoch': 5.91}
{'loss': 0.0229, 'grad_norm': 7.4316935539245605, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.01917739398777485, 'loss_2': 0.0037174224853515625, 'loss_3': -16.185819625854492, 'loss_4': 3.1284232139587402, 'epoch': 5.91}
{'loss': 0.0292, 'grad_norm': 10.575016021728516, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.025502124801278114, 'loss_2': 0.003688812255859375, 'loss_3': -15.896034240722656, 'loss_4': 3.0726218223571777, 'epoch': 5.92}
{'loss': 0.026, 'grad_norm': 7.864841461181641, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.02205914445221424, 'loss_2': 0.00394439697265625, 'loss_3': -16.196964263916016, 'loss_4': 3.2937302589416504, 'epoch': 5.92}
{'loss': 0.0386, 'grad_norm': 12.673833847045898, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.035242341458797455, 'loss_2': 0.003368377685546875, 'loss_3': -16.0748233795166, 'loss_4': 3.042459011077881, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 09:52:05,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:05,356 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:32<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:12,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012662909924983978, 'eval_runtime': 3.8218, 'eval_samples_per_second': 267.933, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.009513302706182003, 'eval_loss_2': 0.0031496062874794006, 'eval_loss_3': -18.31383514404297, 'eval_loss_4': 2.8252272605895996, 'epoch': 5.93}
{'loss': 0.0459, 'grad_norm': 17.124677658081055, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.04296628013253212, 'loss_2': 0.0029506683349609375, 'loss_3': -16.093894958496094, 'loss_4': 3.5326929092407227, 'epoch': 5.94}
{'loss': 0.0265, 'grad_norm': 23.110794067382812, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.02587324008345604, 'loss_2': 0.0006551742553710938, 'loss_3': -16.12802505493164, 'loss_4': 3.10598087310791, 'epoch': 5.94}
{'loss': 0.026, 'grad_norm': 8.786316871643066, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.019418537616729736, 'loss_2': 0.0065765380859375, 'loss_3': -16.045475006103516, 'loss_4': 2.778813600540161, 'epoch': 5.95}
{'loss': 0.0235, 'grad_norm': 11.826726913452148, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.020638935267925262, 'loss_2': 0.0028667449951171875, 'loss_3': -15.93461799621582, 'loss_4': 3.0382871627807617, 'epoch': 5.95}
{'loss': 0.0173, 'grad_norm': 4.878320217132568, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.008217951282858849, 'loss_2': 0.009124755859375, 'loss_3': -16.187240600585938, 'loss_4': 2.6428756713867188, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 09:52:12,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:12,727 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:39<1:11:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:20,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012109591625630856, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009299053810536861, 'eval_loss_2': 0.002810537815093994, 'eval_loss_3': -18.264787673950195, 'eval_loss_4': 2.677025079727173, 'epoch': 5.96}
{'loss': 0.023, 'grad_norm': 8.847125053405762, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.021394943818449974, 'loss_2': 0.0016241073608398438, 'loss_3': -16.013050079345703, 'loss_4': 3.152437210083008, 'epoch': 5.97}
{'loss': 0.031, 'grad_norm': 10.574039459228516, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.0252750925719738, 'loss_2': 0.0056915283203125, 'loss_3': -16.218128204345703, 'loss_4': 2.6954760551452637, 'epoch': 5.97}
{'loss': 0.0203, 'grad_norm': 7.280930995941162, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.018431736156344414, 'loss_2': 0.0019073486328125, 'loss_3': -16.05569076538086, 'loss_4': 3.1931352615356445, 'epoch': 5.98}
{'loss': 0.0165, 'grad_norm': 5.735706806182861, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.013922376558184624, 'loss_2': 0.002574920654296875, 'loss_3': -15.899181365966797, 'loss_4': 2.745011806488037, 'epoch': 5.98}
{'loss': 0.0248, 'grad_norm': 10.885319709777832, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.02290831133723259, 'loss_2': 0.00189208984375, 'loss_3': -15.91108226776123, 'loss_4': 2.306077003479004, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 09:52:20,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:20,084 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:46<1:09:22,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 09:52:27,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015014450065791607, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.677, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011896382085978985, 'eval_loss_2': 0.003118067979812622, 'eval_loss_3': -18.246902465820312, 'eval_loss_4': 2.6367568969726562, 'epoch': 5.99}
{'loss': 0.027, 'grad_norm': 20.374221801757812, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.026781799271702766, 'loss_2': 0.00021004676818847656, 'loss_3': -16.016555786132812, 'loss_4': 2.63877010345459, 'epoch': 5.99}
{'loss': 0.011, 'grad_norm': 6.427487373352051, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.007222730200737715, 'loss_2': 0.003803253173828125, 'loss_3': -16.033836364746094, 'loss_4': 2.523021936416626, 'epoch': 6.0}
{'loss': 0.0161, 'grad_norm': 5.857248783111572, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.011386272497475147, 'loss_2': 0.00473785400390625, 'loss_3': -16.053844451904297, 'loss_4': 2.8762617111206055, 'epoch': 6.01}
{'loss': 0.0351, 'grad_norm': 11.608092308044434, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.03440823778510094, 'loss_2': 0.0006656646728515625, 'loss_3': -16.124019622802734, 'loss_4': 3.227597951889038, 'epoch': 6.01}
{'loss': 0.0143, 'grad_norm': 5.97239875793457, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.013107890263199806, 'loss_2': 0.001201629638671875, 'loss_3': -16.133676528930664, 'loss_4': 3.231564521789551, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 09:52:27,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:27,131 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [25:54<1:10:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:52:34,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015345849096775055, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.259, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013227634131908417, 'eval_loss_2': 0.002118214964866638, 'eval_loss_3': -18.245023727416992, 'eval_loss_4': 2.8402628898620605, 'epoch': 6.02}
{'loss': 0.0229, 'grad_norm': 8.018211364746094, 'learning_rate': 2.4e-05, 'loss_1': 0.02106703817844391, 'loss_2': 0.0018520355224609375, 'loss_3': -15.96157169342041, 'loss_4': 3.0315725803375244, 'epoch': 6.02}
{'loss': 0.0184, 'grad_norm': 7.454242706298828, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.017226723954081535, 'loss_2': 0.0011730194091796875, 'loss_3': -16.196807861328125, 'loss_4': 3.1252212524414062, 'epoch': 6.03}
{'loss': 0.0198, 'grad_norm': 7.050147533416748, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.018919726833701134, 'loss_2': 0.0008563995361328125, 'loss_3': -15.869978904724121, 'loss_4': 3.0444748401641846, 'epoch': 6.03}
{'loss': 0.027, 'grad_norm': 6.454136848449707, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.01682993955910206, 'loss_2': 0.01015472412109375, 'loss_3': -15.987544059753418, 'loss_4': 2.9634242057800293, 'epoch': 6.04}
{'loss': 0.0277, 'grad_norm': 7.148341655731201, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.019762014970183372, 'loss_2': 0.0079193115234375, 'loss_3': -16.065248489379883, 'loss_4': 2.6618800163269043, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 09:52:34,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:34,476 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:01<1:11:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:41,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015775781124830246, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.503, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012006562203168869, 'eval_loss_2': 0.003769218921661377, 'eval_loss_3': -18.260211944580078, 'eval_loss_4': 2.587038993835449, 'epoch': 6.05}
{'loss': 0.0342, 'grad_norm': 10.44827938079834, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.027372905984520912, 'loss_2': 0.006832122802734375, 'loss_3': -15.993270874023438, 'loss_4': 2.745384454727173, 'epoch': 6.05}
{'loss': 0.028, 'grad_norm': 8.623929023742676, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.024909937754273415, 'loss_2': 0.003063201904296875, 'loss_3': -16.189769744873047, 'loss_4': 2.900195360183716, 'epoch': 6.06}
{'loss': 0.0191, 'grad_norm': 5.713916778564453, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.012445679865777493, 'loss_2': 0.00662994384765625, 'loss_3': -15.948617935180664, 'loss_4': 2.161585807800293, 'epoch': 6.06}
{'loss': 0.0243, 'grad_norm': 6.451325416564941, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.01898767612874508, 'loss_2': 0.0053253173828125, 'loss_3': -16.018474578857422, 'loss_4': 2.5082921981811523, 'epoch': 6.07}
{'loss': 0.0802, 'grad_norm': 24.92183494567871, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.07869517803192139, 'loss_2': 0.0015401840209960938, 'loss_3': -15.77100658416748, 'loss_4': 2.9732069969177246, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 09:52:41,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:41,820 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:08<1:11:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:49,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017273642122745514, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011189884506165981, 'eval_loss_2': 0.006083756685256958, 'eval_loss_3': -18.290098190307617, 'eval_loss_4': 2.2701399326324463, 'epoch': 6.08}
{'loss': 0.0269, 'grad_norm': 8.636519432067871, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.018560295924544334, 'loss_2': 0.0083770751953125, 'loss_3': -15.946338653564453, 'loss_4': 2.1283950805664062, 'epoch': 6.08}
{'loss': 0.0286, 'grad_norm': 7.021240711212158, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.0176992304623127, 'loss_2': 0.01091766357421875, 'loss_3': -16.097028732299805, 'loss_4': 2.812765598297119, 'epoch': 6.09}
{'loss': 0.0182, 'grad_norm': 6.633479118347168, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.01768302544951439, 'loss_2': 0.0005550384521484375, 'loss_3': -15.973944664001465, 'loss_4': 2.0648746490478516, 'epoch': 6.09}
{'loss': 0.0175, 'grad_norm': 6.472531795501709, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.011218582279980183, 'loss_2': 0.006282806396484375, 'loss_3': -16.11239242553711, 'loss_4': 2.0045270919799805, 'epoch': 6.1}
{'loss': 0.0242, 'grad_norm': 7.848189353942871, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.02329818159341812, 'loss_2': 0.000911712646484375, 'loss_3': -15.933908462524414, 'loss_4': 1.6267056465148926, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 09:52:49,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:49,170 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:16<1:11:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:56,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015403589233756065, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010166307911276817, 'eval_loss_2': 0.005237281322479248, 'eval_loss_3': -18.297975540161133, 'eval_loss_4': 2.0139212608337402, 'epoch': 6.1}
{'loss': 0.0178, 'grad_norm': 6.463792324066162, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.014874652959406376, 'loss_2': 0.00293731689453125, 'loss_3': -15.934188842773438, 'loss_4': 2.2323529720306396, 'epoch': 6.11}
{'loss': 0.0219, 'grad_norm': 7.897052764892578, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.02062808722257614, 'loss_2': 0.0012836456298828125, 'loss_3': -15.86610221862793, 'loss_4': 1.9106584787368774, 'epoch': 6.12}
{'loss': 0.0226, 'grad_norm': 7.138633728027344, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.014999868348240852, 'loss_2': 0.007568359375, 'loss_3': -16.119365692138672, 'loss_4': 2.7932686805725098, 'epoch': 6.12}
{'loss': 0.0211, 'grad_norm': 7.038065433502197, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.01878705620765686, 'loss_2': 0.00229644775390625, 'loss_3': -16.035327911376953, 'loss_4': 2.2986865043640137, 'epoch': 6.13}
{'loss': 0.0437, 'grad_norm': 19.570388793945312, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.03789383918046951, 'loss_2': 0.00583648681640625, 'loss_3': -15.946316719055176, 'loss_4': 2.28657865524292, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 09:52:56,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:56,521 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:23<1:10:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:03,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013541940599679947, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009453787468373775, 'eval_loss_2': 0.004088152199983597, 'eval_loss_3': -18.320201873779297, 'eval_loss_4': 1.9039777517318726, 'epoch': 6.13}
{'loss': 0.0205, 'grad_norm': 8.537800788879395, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.02013418823480606, 'loss_2': 0.0004057884216308594, 'loss_3': -16.151199340820312, 'loss_4': 2.5135276317596436, 'epoch': 6.14}
{'loss': 0.018, 'grad_norm': 5.194728374481201, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.012299316935241222, 'loss_2': 0.00572967529296875, 'loss_3': -16.008384704589844, 'loss_4': 2.126939535140991, 'epoch': 6.15}
{'loss': 0.0149, 'grad_norm': 5.975844860076904, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.010780098848044872, 'loss_2': 0.004119873046875, 'loss_3': -16.111297607421875, 'loss_4': 2.0928051471710205, 'epoch': 6.15}
{'loss': 0.0318, 'grad_norm': 18.135608673095703, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.03150001913309097, 'loss_2': 0.00026869773864746094, 'loss_3': -16.052051544189453, 'loss_4': 2.3109724521636963, 'epoch': 6.16}
{'loss': 0.0305, 'grad_norm': 13.773030281066895, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.02619834616780281, 'loss_2': 0.0043182373046875, 'loss_3': -15.951910018920898, 'loss_4': 1.843235969543457, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 09:53:03,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:03,863 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:31<1:10:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:11,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012579360976815224, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009070554748177528, 'eval_loss_2': 0.0035088062286376953, 'eval_loss_3': -18.333703994750977, 'eval_loss_4': 2.183243989944458, 'epoch': 6.16}
{'loss': 0.0301, 'grad_norm': 10.51045036315918, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.029141129925847054, 'loss_2': 0.0009698867797851562, 'loss_3': -15.892072677612305, 'loss_4': 2.4310388565063477, 'epoch': 6.17}
{'loss': 0.0227, 'grad_norm': 8.220442771911621, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.020859338343143463, 'loss_2': 0.0018148422241210938, 'loss_3': -16.195560455322266, 'loss_4': 2.3486390113830566, 'epoch': 6.17}
{'loss': 0.0365, 'grad_norm': 13.395524024963379, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.031104663386940956, 'loss_2': 0.0053558349609375, 'loss_3': -16.125389099121094, 'loss_4': 2.0870001316070557, 'epoch': 6.18}
{'loss': 0.0712, 'grad_norm': 15.266791343688965, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.06932833045721054, 'loss_2': 0.0018367767333984375, 'loss_3': -16.10897445678711, 'loss_4': 3.22684383392334, 'epoch': 6.19}
{'loss': 0.029, 'grad_norm': 10.164770126342773, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.024761172011494637, 'loss_2': 0.00420379638671875, 'loss_3': -16.0931339263916, 'loss_4': 2.9147582054138184, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 09:53:11,196 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:11,196 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:38<1:10:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:18,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014646405354142189, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009653711691498756, 'eval_loss_2': 0.004992693662643433, 'eval_loss_3': -18.331920623779297, 'eval_loss_4': 2.4641687870025635, 'epoch': 6.19}
{'loss': 0.0583, 'grad_norm': 17.214265823364258, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.05117400363087654, 'loss_2': 0.0071563720703125, 'loss_3': -15.924680709838867, 'loss_4': 3.0922536849975586, 'epoch': 6.2}
{'loss': 0.0287, 'grad_norm': 6.05617618560791, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.014549806714057922, 'loss_2': 0.01416015625, 'loss_3': -16.05237579345703, 'loss_4': 2.6944518089294434, 'epoch': 6.2}
{'loss': 0.0229, 'grad_norm': 6.765185832977295, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.015358470380306244, 'loss_2': 0.007564544677734375, 'loss_3': -16.165868759155273, 'loss_4': 2.511219024658203, 'epoch': 6.21}
{'loss': 0.0187, 'grad_norm': 5.881783485412598, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.013288980349898338, 'loss_2': 0.005435943603515625, 'loss_3': -16.132535934448242, 'loss_4': 2.5317635536193848, 'epoch': 6.22}
{'loss': 0.0158, 'grad_norm': 5.670018196105957, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.012021590024232864, 'loss_2': 0.0037288665771484375, 'loss_3': -15.926397323608398, 'loss_4': 2.455329418182373, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 09:53:18,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:18,543 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:45<1:10:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:25,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01504907850176096, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009845071472227573, 'eval_loss_2': 0.005204007029533386, 'eval_loss_3': -18.313030242919922, 'eval_loss_4': 2.336251735687256, 'epoch': 6.22}
{'loss': 0.0226, 'grad_norm': 7.467259407043457, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.018540728837251663, 'loss_2': 0.00409698486328125, 'loss_3': -16.12156867980957, 'loss_4': 2.378432273864746, 'epoch': 6.23}
{'loss': 0.0262, 'grad_norm': 8.438899993896484, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.02338423579931259, 'loss_2': 0.00281524658203125, 'loss_3': -15.877907752990723, 'loss_4': 3.144160270690918, 'epoch': 6.23}
{'loss': 0.0203, 'grad_norm': 5.357746601104736, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.01028653047978878, 'loss_2': 0.01001739501953125, 'loss_3': -16.044761657714844, 'loss_4': 2.4249937534332275, 'epoch': 6.24}
{'loss': 0.0285, 'grad_norm': 8.666258811950684, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.020468633621931076, 'loss_2': 0.00800323486328125, 'loss_3': -16.055744171142578, 'loss_4': 2.120607852935791, 'epoch': 6.24}
{'loss': 0.0308, 'grad_norm': 9.059656143188477, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.02265082113444805, 'loss_2': 0.0081024169921875, 'loss_3': -15.886597633361816, 'loss_4': 2.0001211166381836, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 09:53:25,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:25,906 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [26:53<1:10:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:33,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016810905188322067, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.88, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00972724985331297, 'eval_loss_2': 0.0070836544036865234, 'eval_loss_3': -18.27985191345215, 'eval_loss_4': 2.2015388011932373, 'epoch': 6.25}
{'loss': 0.0267, 'grad_norm': 6.735398292541504, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.01544988714158535, 'loss_2': 0.0112152099609375, 'loss_3': -15.959351539611816, 'loss_4': 2.0656211376190186, 'epoch': 6.26}
{'loss': 0.0394, 'grad_norm': 10.065305709838867, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.03313175588846207, 'loss_2': 0.006252288818359375, 'loss_3': -15.887779235839844, 'loss_4': 1.7588251829147339, 'epoch': 6.26}
{'loss': 0.0206, 'grad_norm': 7.566486835479736, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.019573302939534187, 'loss_2': 0.0010623931884765625, 'loss_3': -16.096057891845703, 'loss_4': 1.9350801706314087, 'epoch': 6.27}
{'loss': 0.0167, 'grad_norm': 7.472413539886475, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.014951896853744984, 'loss_2': 0.0017023086547851562, 'loss_3': -16.09142303466797, 'loss_4': 2.096189022064209, 'epoch': 6.27}
{'loss': 0.0216, 'grad_norm': 6.964629650115967, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.020601816475391388, 'loss_2': 0.0009860992431640625, 'loss_3': -15.927179336547852, 'loss_4': 1.84708833694458, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 09:53:33,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:33,289 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:00<1:10:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:40,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013864701613783836, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.755, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00983103085309267, 'eval_loss_2': 0.004033669829368591, 'eval_loss_3': -18.20388412475586, 'eval_loss_4': 2.0202436447143555, 'epoch': 6.28}
{'loss': 0.019, 'grad_norm': 7.814932346343994, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.018021441996097565, 'loss_2': 0.0009307861328125, 'loss_3': -15.838279724121094, 'loss_4': 2.3860414028167725, 'epoch': 6.28}
{'loss': 0.0272, 'grad_norm': 10.095773696899414, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.02397213689982891, 'loss_2': 0.00324249267578125, 'loss_3': -15.991764068603516, 'loss_4': 1.5039331912994385, 'epoch': 6.29}
{'loss': 0.0214, 'grad_norm': 7.148297309875488, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.016871383413672447, 'loss_2': 0.004566192626953125, 'loss_3': -15.955672264099121, 'loss_4': 2.5175671577453613, 'epoch': 6.3}
{'loss': 0.0421, 'grad_norm': 13.985335350036621, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.04142230376601219, 'loss_2': 0.0006866455078125, 'loss_3': -15.925411224365234, 'loss_4': 2.218447208404541, 'epoch': 6.3}
{'loss': 0.0497, 'grad_norm': 11.808563232421875, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.043227482587099075, 'loss_2': 0.00649261474609375, 'loss_3': -15.956075668334961, 'loss_4': 2.0998024940490723, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 09:53:40,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:40,629 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:07<1:10:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:47,989 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014247484505176544, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.131, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.010651716031134129, 'eval_loss_2': 0.0035957694053649902, 'eval_loss_3': -18.14863395690918, 'eval_loss_4': 2.1202659606933594, 'epoch': 6.31}
{'loss': 0.0396, 'grad_norm': 15.131192207336426, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.039171524345874786, 'loss_2': 0.0004100799560546875, 'loss_3': -15.978250503540039, 'loss_4': 2.8554606437683105, 'epoch': 6.31}
{'loss': 0.0229, 'grad_norm': 6.141289234161377, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.01713825762271881, 'loss_2': 0.005802154541015625, 'loss_3': -16.039348602294922, 'loss_4': 2.201202869415283, 'epoch': 6.32}
{'loss': 0.0299, 'grad_norm': 9.191923141479492, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.02323738858103752, 'loss_2': 0.006641387939453125, 'loss_3': -15.93693733215332, 'loss_4': 2.173119068145752, 'epoch': 6.33}
{'loss': 0.0328, 'grad_norm': 9.220540046691895, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.024281788617372513, 'loss_2': 0.008544921875, 'loss_3': -16.16904067993164, 'loss_4': 2.902986764907837, 'epoch': 6.33}
{'loss': 0.0269, 'grad_norm': 7.177536487579346, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.018163932487368584, 'loss_2': 0.008697509765625, 'loss_3': -16.13079833984375, 'loss_4': 2.574068546295166, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 09:53:47,989 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:47,989 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:15<1:10:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:55,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015227795578539371, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010968848131597042, 'eval_loss_2': 0.00425894558429718, 'eval_loss_3': -18.160888671875, 'eval_loss_4': 2.1058454513549805, 'epoch': 6.34}
{'loss': 0.0169, 'grad_norm': 6.857871055603027, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.015627382323145866, 'loss_2': 0.0012617111206054688, 'loss_3': -15.992765426635742, 'loss_4': 2.007641077041626, 'epoch': 6.34}
{'loss': 0.0202, 'grad_norm': 5.866262912750244, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.01204549428075552, 'loss_2': 0.00820159912109375, 'loss_3': -16.150856018066406, 'loss_4': 2.2611868381500244, 'epoch': 6.35}
{'loss': 0.028, 'grad_norm': 8.06539249420166, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.01972378045320511, 'loss_2': 0.00823211669921875, 'loss_3': -16.044641494750977, 'loss_4': 2.084805727005005, 'epoch': 6.35}
{'loss': 0.0171, 'grad_norm': 5.85690450668335, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.014239205047488213, 'loss_2': 0.002910614013671875, 'loss_3': -16.055747985839844, 'loss_4': 2.3755898475646973, 'epoch': 6.36}
{'loss': 0.0255, 'grad_norm': 10.7966890335083, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.021818632259964943, 'loss_2': 0.00365447998046875, 'loss_3': -15.958687782287598, 'loss_4': 2.2141406536102295, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 09:53:55,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:55,329 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:22<1:10:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:02,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016105465590953827, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011704855598509312, 'eval_loss_2': 0.00440061092376709, 'eval_loss_3': -18.164743423461914, 'eval_loss_4': 2.013106107711792, 'epoch': 6.37}
{'loss': 0.0396, 'grad_norm': 10.76905632019043, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.03427838906645775, 'loss_2': 0.00531768798828125, 'loss_3': -15.989343643188477, 'loss_4': 2.0493526458740234, 'epoch': 6.37}
{'loss': 0.0303, 'grad_norm': 7.182835102081299, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.02003253996372223, 'loss_2': 0.01026153564453125, 'loss_3': -16.038799285888672, 'loss_4': 1.9494898319244385, 'epoch': 6.38}
{'loss': 0.0218, 'grad_norm': 6.516086101531982, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.01697733998298645, 'loss_2': 0.00479888916015625, 'loss_3': -16.0479736328125, 'loss_4': 2.3253753185272217, 'epoch': 6.38}
{'loss': 0.0177, 'grad_norm': 5.560795783996582, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.014130214229226112, 'loss_2': 0.003566741943359375, 'loss_3': -16.166236877441406, 'loss_4': 1.5011073350906372, 'epoch': 6.39}
{'loss': 0.0179, 'grad_norm': 5.4228410720825195, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.01462214533239603, 'loss_2': 0.003314971923828125, 'loss_3': -15.982592582702637, 'loss_4': 1.925195336341858, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 09:54:02,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:02,674 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:29<1:10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:10,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023579102009534836, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.897, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019773881882429123, 'eval_loss_2': 0.003805220127105713, 'eval_loss_3': -18.14899253845215, 'eval_loss_4': 2.0153520107269287, 'epoch': 6.4}
{'loss': 0.018, 'grad_norm': 8.645902633666992, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.016023989766836166, 'loss_2': 0.0019817352294921875, 'loss_3': -15.782736778259277, 'loss_4': 2.1278185844421387, 'epoch': 6.4}
{'loss': 0.0309, 'grad_norm': 10.889737129211426, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.026415729895234108, 'loss_2': 0.00449371337890625, 'loss_3': -16.035114288330078, 'loss_4': 2.533163070678711, 'epoch': 6.41}
{'loss': 0.0541, 'grad_norm': 15.54548168182373, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.050773985683918, 'loss_2': 0.003284454345703125, 'loss_3': -15.900753021240234, 'loss_4': 2.4910635948181152, 'epoch': 6.41}
{'loss': 0.016, 'grad_norm': 6.649839878082275, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.015231228433549404, 'loss_2': 0.0007457733154296875, 'loss_3': -16.07509994506836, 'loss_4': 2.673211097717285, 'epoch': 6.42}
{'loss': 0.0345, 'grad_norm': 11.434664726257324, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.03328542038798332, 'loss_2': 0.00124359130859375, 'loss_3': -15.970722198486328, 'loss_4': 2.1183688640594482, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 09:54:10,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:10,044 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:37<1:10:36,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:54:17,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03365321457386017, 'eval_runtime': 3.8686, 'eval_samples_per_second': 264.693, 'eval_steps_per_second': 4.136, 'eval_loss_1': 0.022651035338640213, 'eval_loss_2': 0.011002182960510254, 'eval_loss_3': -18.13530921936035, 'eval_loss_4': 2.0310847759246826, 'epoch': 6.42}
{'loss': 0.0315, 'grad_norm': 7.95721960067749, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.026810459792613983, 'loss_2': 0.00472259521484375, 'loss_3': -16.026540756225586, 'loss_4': 1.941754698753357, 'epoch': 6.43}
{'loss': 0.0386, 'grad_norm': 11.551745414733887, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.03345775604248047, 'loss_2': 0.005107879638671875, 'loss_3': -15.963958740234375, 'loss_4': 2.2157504558563232, 'epoch': 6.44}
{'loss': 0.0676, 'grad_norm': 23.51202392578125, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.062494371086359024, 'loss_2': 0.00514984130859375, 'loss_3': -15.978209495544434, 'loss_4': 2.344845771789551, 'epoch': 6.44}
{'loss': 0.0256, 'grad_norm': 7.792469024658203, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.022578947246074677, 'loss_2': 0.002979278564453125, 'loss_3': -16.103099822998047, 'loss_4': 2.1779122352600098, 'epoch': 6.45}
{'loss': 0.0212, 'grad_norm': 5.075196266174316, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.015208594501018524, 'loss_2': 0.00598907470703125, 'loss_3': -16.16289520263672, 'loss_4': 1.858605980873108, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 09:54:17,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:17,486 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:44<1:10:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:24,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018862638622522354, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013144229538738728, 'eval_loss_2': 0.005718410015106201, 'eval_loss_3': -18.172775268554688, 'eval_loss_4': 2.061574935913086, 'epoch': 6.45}
{'loss': 0.0214, 'grad_norm': 6.72587251663208, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.01580197550356388, 'loss_2': 0.005615234375, 'loss_3': -15.881467819213867, 'loss_4': 2.192091941833496, 'epoch': 6.46}
{'loss': 0.0236, 'grad_norm': 7.448690414428711, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.02127470262348652, 'loss_2': 0.002307891845703125, 'loss_3': -16.047765731811523, 'loss_4': 2.393930196762085, 'epoch': 6.47}
{'loss': 0.014, 'grad_norm': 5.992812633514404, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.012871844694018364, 'loss_2': 0.0011539459228515625, 'loss_3': -15.964442253112793, 'loss_4': 2.317214250564575, 'epoch': 6.47}
{'loss': 0.0215, 'grad_norm': 7.628346920013428, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.013093030080199242, 'loss_2': 0.008453369140625, 'loss_3': -16.168922424316406, 'loss_4': 2.2960002422332764, 'epoch': 6.48}
{'loss': 0.0326, 'grad_norm': 7.623096942901611, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.025789346545934677, 'loss_2': 0.00682830810546875, 'loss_3': -16.180957794189453, 'loss_4': 2.3158984184265137, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 09:54:24,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:24,837 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [27:51<1:09:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:32,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01952775940299034, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012733155861496925, 'eval_loss_2': 0.006794601678848267, 'eval_loss_3': -18.193283081054688, 'eval_loss_4': 2.20330810546875, 'epoch': 6.48}
{'loss': 0.0246, 'grad_norm': 5.9459943771362305, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.011969617567956448, 'loss_2': 0.012664794921875, 'loss_3': -16.08241081237793, 'loss_4': 2.1481451988220215, 'epoch': 6.49}
{'loss': 0.0291, 'grad_norm': 10.12292766571045, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.022119300439953804, 'loss_2': 0.006969451904296875, 'loss_3': -15.908863067626953, 'loss_4': 2.5137341022491455, 'epoch': 6.49}
{'loss': 0.0621, 'grad_norm': 18.67120933532715, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.05184277147054672, 'loss_2': 0.01025390625, 'loss_3': -16.04404067993164, 'loss_4': 2.166555404663086, 'epoch': 6.5}
{'loss': 0.0169, 'grad_norm': 6.772396087646484, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.01375111285597086, 'loss_2': 0.003173828125, 'loss_3': -16.15251922607422, 'loss_4': 2.106724739074707, 'epoch': 6.51}
{'loss': 0.024, 'grad_norm': 11.466522216796875, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.016787931323051453, 'loss_2': 0.007259368896484375, 'loss_3': -16.231063842773438, 'loss_4': 2.174316644668579, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 09:54:32,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:32,184 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [27:59<1:09:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:39,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01572139747440815, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011774050071835518, 'eval_loss_2': 0.003947347402572632, 'eval_loss_3': -18.1961727142334, 'eval_loss_4': 2.3892762660980225, 'epoch': 6.51}
{'loss': 0.0187, 'grad_norm': 6.171700477600098, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.01594996638596058, 'loss_2': 0.0027828216552734375, 'loss_3': -15.984720230102539, 'loss_4': 2.89608097076416, 'epoch': 6.52}
{'loss': 0.0106, 'grad_norm': 5.374467372894287, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.00947175920009613, 'loss_2': 0.001094818115234375, 'loss_3': -16.146610260009766, 'loss_4': 2.2440383434295654, 'epoch': 6.52}
{'loss': 0.0175, 'grad_norm': 6.561548709869385, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.012224170379340649, 'loss_2': 0.0053253173828125, 'loss_3': -16.002811431884766, 'loss_4': 2.26600980758667, 'epoch': 6.53}
{'loss': 0.0252, 'grad_norm': 7.5594377517700195, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.02294650673866272, 'loss_2': 0.00225067138671875, 'loss_3': -15.871851921081543, 'loss_4': 2.4755921363830566, 'epoch': 6.53}
{'loss': 0.0189, 'grad_norm': 7.852602481842041, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.012611176818609238, 'loss_2': 0.00629425048828125, 'loss_3': -16.040138244628906, 'loss_4': 2.4143147468566895, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 09:54:39,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:39,536 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:06<1:09:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:46,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0128884706646204, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.703, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010391289368271828, 'eval_loss_2': 0.0024971812963485718, 'eval_loss_3': -18.192453384399414, 'eval_loss_4': 2.459221124649048, 'epoch': 6.54}
{'loss': 0.0159, 'grad_norm': 5.700555801391602, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.012055379338562489, 'loss_2': 0.00384521484375, 'loss_3': -15.942895889282227, 'loss_4': 2.750199794769287, 'epoch': 6.55}
{'loss': 0.0145, 'grad_norm': 6.441278457641602, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.013147953897714615, 'loss_2': 0.0013942718505859375, 'loss_3': -15.818133354187012, 'loss_4': 2.7374348640441895, 'epoch': 6.55}
{'loss': 0.0267, 'grad_norm': 12.109390258789062, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.026221923530101776, 'loss_2': 0.0004448890686035156, 'loss_3': -16.020387649536133, 'loss_4': 2.662475824356079, 'epoch': 6.56}
{'loss': 0.0295, 'grad_norm': 8.386012077331543, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.017919791862368584, 'loss_2': 0.0115509033203125, 'loss_3': -15.806525230407715, 'loss_4': 2.4962074756622314, 'epoch': 6.56}
{'loss': 0.0253, 'grad_norm': 8.285782814025879, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.018454555422067642, 'loss_2': 0.00682830810546875, 'loss_3': -16.042999267578125, 'loss_4': 2.521557569503784, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 09:54:46,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:46,889 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:14<1:10:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:54,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012613316997885704, 'eval_runtime': 3.8586, 'eval_samples_per_second': 265.38, 'eval_steps_per_second': 4.147, 'eval_loss_1': 0.009871205314993858, 'eval_loss_2': 0.0027421116828918457, 'eval_loss_3': -18.19548797607422, 'eval_loss_4': 2.410566806793213, 'epoch': 6.57}
{'loss': 0.0253, 'grad_norm': 14.281586647033691, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.023922154679894447, 'loss_2': 0.0013332366943359375, 'loss_3': -16.14560890197754, 'loss_4': 1.826840877532959, 'epoch': 6.58}
{'loss': 0.0368, 'grad_norm': 14.373262405395508, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.03101583942770958, 'loss_2': 0.005767822265625, 'loss_3': -16.093597412109375, 'loss_4': 2.7365942001342773, 'epoch': 6.58}
{'loss': 0.015, 'grad_norm': 5.285226821899414, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.009979660622775555, 'loss_2': 0.005016326904296875, 'loss_3': -16.271499633789062, 'loss_4': 2.3895254135131836, 'epoch': 6.59}
{'loss': 0.0338, 'grad_norm': 13.432806968688965, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.02345919981598854, 'loss_2': 0.0103302001953125, 'loss_3': -16.0167179107666, 'loss_4': 2.175102949142456, 'epoch': 6.59}
{'loss': 0.0311, 'grad_norm': 11.4153413772583, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.02336752600967884, 'loss_2': 0.007740020751953125, 'loss_3': -16.09881591796875, 'loss_4': 2.3544399738311768, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 09:54:54,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:54,307 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:21<1:09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:01,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015438255853950977, 'eval_runtime': 3.8381, 'eval_samples_per_second': 266.798, 'eval_steps_per_second': 4.169, 'eval_loss_1': 0.00854414515197277, 'eval_loss_2': 0.006894111633300781, 'eval_loss_3': -18.235410690307617, 'eval_loss_4': 2.2448904514312744, 'epoch': 6.6}
{'loss': 0.0219, 'grad_norm': 6.598152160644531, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.009142153896391392, 'loss_2': 0.012725830078125, 'loss_3': -16.113323211669922, 'loss_4': 2.359173059463501, 'epoch': 6.6}
{'loss': 0.0088, 'grad_norm': 5.336814880371094, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.008322551846504211, 'loss_2': 0.0004901885986328125, 'loss_3': -16.16202735900879, 'loss_4': 2.484524726867676, 'epoch': 6.61}
{'loss': 0.0263, 'grad_norm': 8.59793472290039, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.023916954174637794, 'loss_2': 0.00235748291015625, 'loss_3': -15.93985366821289, 'loss_4': 2.621302604675293, 'epoch': 6.62}
{'loss': 0.0226, 'grad_norm': 7.046149253845215, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.019909074530005455, 'loss_2': 0.00264739990234375, 'loss_3': -16.06332015991211, 'loss_4': 2.3191416263580322, 'epoch': 6.62}
{'loss': 0.0614, 'grad_norm': 27.105892181396484, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.058514345437288284, 'loss_2': 0.0028629302978515625, 'loss_3': -15.689311981201172, 'loss_4': 2.404294967651367, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 09:55:01,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:01,686 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:28<1:09:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:09,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01178270298987627, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.33, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008454223163425922, 'eval_loss_2': 0.003328479826450348, 'eval_loss_3': -18.263296127319336, 'eval_loss_4': 1.9280908107757568, 'epoch': 6.63}
{'loss': 0.0181, 'grad_norm': 10.365854263305664, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.017726944759488106, 'loss_2': 0.0003724098205566406, 'loss_3': -16.178836822509766, 'loss_4': 2.3645148277282715, 'epoch': 6.63}
{'loss': 0.016, 'grad_norm': 7.802175045013428, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.01222392451018095, 'loss_2': 0.003818511962890625, 'loss_3': -16.055198669433594, 'loss_4': 1.909730315208435, 'epoch': 6.64}
{'loss': 0.0118, 'grad_norm': 5.38461971282959, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.01073423121124506, 'loss_2': 0.00106048583984375, 'loss_3': -16.188385009765625, 'loss_4': 2.1675918102264404, 'epoch': 6.65}
{'loss': 0.0237, 'grad_norm': 9.126587867736816, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.01585921086370945, 'loss_2': 0.0078887939453125, 'loss_3': -15.839203834533691, 'loss_4': 1.4673526287078857, 'epoch': 6.65}
{'loss': 0.0193, 'grad_norm': 6.735163688659668, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.011705947108566761, 'loss_2': 0.00762939453125, 'loss_3': -16.136056900024414, 'loss_4': 2.3464126586914062, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 09:55:09,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:09,034 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:36<1:09:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:16,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016057906672358513, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008485493250191212, 'eval_loss_2': 0.0075724124908447266, 'eval_loss_3': -18.297100067138672, 'eval_loss_4': 1.809415578842163, 'epoch': 6.66}
{'loss': 0.0194, 'grad_norm': 5.097906589508057, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.010908817872405052, 'loss_2': 0.0085296630859375, 'loss_3': -15.992308616638184, 'loss_4': 1.619279384613037, 'epoch': 6.66}
{'loss': 0.0249, 'grad_norm': 6.608455657958984, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.018081841990351677, 'loss_2': 0.006778717041015625, 'loss_3': -16.092823028564453, 'loss_4': 2.3626158237457275, 'epoch': 6.67}
{'loss': 0.0145, 'grad_norm': 5.635315895080566, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.009573775343596935, 'loss_2': 0.00493621826171875, 'loss_3': -16.060243606567383, 'loss_4': 2.167762517929077, 'epoch': 6.67}
{'loss': 0.0267, 'grad_norm': 9.473451614379883, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.021347008645534515, 'loss_2': 0.0053863525390625, 'loss_3': -15.95195198059082, 'loss_4': 2.1251487731933594, 'epoch': 6.68}
{'loss': 0.022, 'grad_norm': 9.810632705688477, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.019419604912400246, 'loss_2': 0.002536773681640625, 'loss_3': -15.876702308654785, 'loss_4': 1.546757698059082, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 09:55:16,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:16,373 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:43<1:09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:23,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015950597822666168, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.976, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010699547827243805, 'eval_loss_2': 0.005251049995422363, 'eval_loss_3': -18.292463302612305, 'eval_loss_4': 1.5150781869888306, 'epoch': 6.69}
{'loss': 0.0332, 'grad_norm': 6.287642478942871, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.026917479932308197, 'loss_2': 0.00627899169921875, 'loss_3': -15.977651596069336, 'loss_4': 2.3263754844665527, 'epoch': 6.69}
{'loss': 0.0306, 'grad_norm': 10.928183555603027, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.029500136151909828, 'loss_2': 0.0010519027709960938, 'loss_3': -16.010318756103516, 'loss_4': 1.8178987503051758, 'epoch': 6.7}
{'loss': 0.0398, 'grad_norm': 15.268754959106445, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.03783392906188965, 'loss_2': 0.00199127197265625, 'loss_3': -16.006216049194336, 'loss_4': 1.344842553138733, 'epoch': 6.7}
{'loss': 0.0191, 'grad_norm': 7.856645107269287, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.018875140696763992, 'loss_2': 0.00020563602447509766, 'loss_3': -16.00491714477539, 'loss_4': 1.8824660778045654, 'epoch': 6.71}
{'loss': 0.0129, 'grad_norm': 5.696105480194092, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.010367614217102528, 'loss_2': 0.002490997314453125, 'loss_3': -16.20293617248535, 'loss_4': 1.6486616134643555, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 09:55:23,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:23,729 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [28:50<1:09:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:31,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023230168968439102, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.934, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01253041997551918, 'eval_loss_2': 0.010699748992919922, 'eval_loss_3': -18.250381469726562, 'eval_loss_4': 1.359217643737793, 'epoch': 6.72}
{'loss': 0.0178, 'grad_norm': 7.409341335296631, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.012217981740832329, 'loss_2': 0.00555419921875, 'loss_3': -16.04256820678711, 'loss_4': 1.3449528217315674, 'epoch': 6.72}
{'loss': 0.0213, 'grad_norm': 5.560043811798096, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.007116321939975023, 'loss_2': 0.01419830322265625, 'loss_3': -16.07149887084961, 'loss_4': 1.5648987293243408, 'epoch': 6.73}
{'loss': 0.0471, 'grad_norm': 10.621394157409668, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.030147237703204155, 'loss_2': 0.016998291015625, 'loss_3': -15.978536605834961, 'loss_4': 1.2430217266082764, 'epoch': 6.73}
{'loss': 0.054, 'grad_norm': 14.668357849121094, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.039011869579553604, 'loss_2': 0.0149688720703125, 'loss_3': -15.83334732055664, 'loss_4': 1.7469602823257446, 'epoch': 6.74}
{'loss': 0.0278, 'grad_norm': 8.120712280273438, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.017965825274586678, 'loss_2': 0.0098114013671875, 'loss_3': -15.975502967834473, 'loss_4': 1.4970463514328003, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 09:55:31,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:31,083 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [28:58<1:09:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:38,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02481655776500702, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.125, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.01613156497478485, 'eval_loss_2': 0.008684992790222168, 'eval_loss_3': -18.2185115814209, 'eval_loss_4': 1.148447036743164, 'epoch': 6.74}
{'loss': 0.0596, 'grad_norm': 15.955374717712402, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.04746967554092407, 'loss_2': 0.01213836669921875, 'loss_3': -15.897067070007324, 'loss_4': 1.4921698570251465, 'epoch': 6.75}
{'loss': 0.0365, 'grad_norm': 13.091431617736816, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.0234565120190382, 'loss_2': 0.013092041015625, 'loss_3': -15.930668830871582, 'loss_4': 1.3092904090881348, 'epoch': 6.76}
{'loss': 0.0143, 'grad_norm': 6.449934482574463, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.010992463678121567, 'loss_2': 0.003276824951171875, 'loss_3': -15.804523468017578, 'loss_4': 1.023870825767517, 'epoch': 6.76}
{'loss': 0.0181, 'grad_norm': 8.15187931060791, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.01751694083213806, 'loss_2': 0.000614166259765625, 'loss_3': -16.061166763305664, 'loss_4': 1.1486995220184326, 'epoch': 6.77}
{'loss': 0.0339, 'grad_norm': 12.256406784057617, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.028350919485092163, 'loss_2': 0.005504608154296875, 'loss_3': -16.122217178344727, 'loss_4': 1.2899761199951172, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 09:55:38,447 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:38,447 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:05<1:09:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:45,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019579701125621796, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014624802395701408, 'eval_loss_2': 0.004954896867275238, 'eval_loss_3': -18.24188804626465, 'eval_loss_4': 1.1408761739730835, 'epoch': 6.77}
{'loss': 0.0201, 'grad_norm': 6.352813243865967, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.014680047519505024, 'loss_2': 0.0054473876953125, 'loss_3': -16.038204193115234, 'loss_4': 0.9917541146278381, 'epoch': 6.78}
{'loss': 0.0199, 'grad_norm': 6.217540740966797, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.010054954327642918, 'loss_2': 0.0098876953125, 'loss_3': -16.076061248779297, 'loss_4': 1.4399478435516357, 'epoch': 6.78}
{'loss': 0.0237, 'grad_norm': 7.553595066070557, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.017806751653552055, 'loss_2': 0.0058441162109375, 'loss_3': -15.984493255615234, 'loss_4': 1.1530872583389282, 'epoch': 6.79}
{'loss': 0.0193, 'grad_norm': 7.82867431640625, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.017889322713017464, 'loss_2': 0.0013751983642578125, 'loss_3': -16.04352569580078, 'loss_4': 1.0639092922210693, 'epoch': 6.8}
{'loss': 0.0228, 'grad_norm': 7.3881516456604, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.017975464463233948, 'loss_2': 0.0047760009765625, 'loss_3': -15.864910125732422, 'loss_4': 1.6145011186599731, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 09:55:45,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:45,797 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:12<1:08:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:53,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01593286171555519, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012679781764745712, 'eval_loss_2': 0.0032530799508094788, 'eval_loss_3': -18.23500633239746, 'eval_loss_4': 1.2922136783599854, 'epoch': 6.8}
{'loss': 0.0316, 'grad_norm': 15.985264778137207, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.02652779407799244, 'loss_2': 0.00505828857421875, 'loss_3': -16.173656463623047, 'loss_4': 1.7584972381591797, 'epoch': 6.81}
{'loss': 0.0233, 'grad_norm': 8.325581550598145, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.020696738734841347, 'loss_2': 0.002635955810546875, 'loss_3': -16.010112762451172, 'loss_4': 1.0785958766937256, 'epoch': 6.81}
{'loss': 0.0227, 'grad_norm': 8.888456344604492, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.016564898192882538, 'loss_2': 0.006103515625, 'loss_3': -15.916326522827148, 'loss_4': 1.4713034629821777, 'epoch': 6.82}
{'loss': 0.0171, 'grad_norm': 6.469996452331543, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.01267833448946476, 'loss_2': 0.00444793701171875, 'loss_3': -15.946500778198242, 'loss_4': 1.6371009349822998, 'epoch': 6.83}
{'loss': 0.0271, 'grad_norm': 17.625276565551758, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.025122731924057007, 'loss_2': 0.001956939697265625, 'loss_3': -15.927804946899414, 'loss_4': 1.407626748085022, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 09:55:53,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:53,151 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:20<1:09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:00,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01573258638381958, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.561, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012291021645069122, 'eval_loss_2': 0.0034415647387504578, 'eval_loss_3': -18.243595123291016, 'eval_loss_4': 1.4769542217254639, 'epoch': 6.83}
{'loss': 0.0268, 'grad_norm': 7.157844066619873, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.022184107452630997, 'loss_2': 0.004619598388671875, 'loss_3': -16.049142837524414, 'loss_4': 1.5974986553192139, 'epoch': 6.84}
{'loss': 0.0231, 'grad_norm': 9.875213623046875, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.019262094050645828, 'loss_2': 0.0037994384765625, 'loss_3': -15.900772094726562, 'loss_4': 1.4282714128494263, 'epoch': 6.84}
{'loss': 0.0175, 'grad_norm': 6.594229698181152, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.016010351479053497, 'loss_2': 0.0015039443969726562, 'loss_3': -16.132152557373047, 'loss_4': 2.1853761672973633, 'epoch': 6.85}
{'loss': 0.0312, 'grad_norm': 10.460148811340332, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.029609182849526405, 'loss_2': 0.0016269683837890625, 'loss_3': -15.816007614135742, 'loss_4': 1.5416616201400757, 'epoch': 6.85}
{'loss': 0.0247, 'grad_norm': 9.966262817382812, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.022567395120859146, 'loss_2': 0.0021343231201171875, 'loss_3': -16.104843139648438, 'loss_4': 1.445102334022522, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 09:56:00,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:00,521 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:27<1:09:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:07,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01758137159049511, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.852, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014814389869570732, 'eval_loss_2': 0.0027669817209243774, 'eval_loss_3': -18.23543930053711, 'eval_loss_4': 1.4641362428665161, 'epoch': 6.86}
{'loss': 0.0458, 'grad_norm': 16.659423828125, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.0455608069896698, 'loss_2': 0.00023031234741210938, 'loss_3': -15.850517272949219, 'loss_4': 1.3394291400909424, 'epoch': 6.87}
{'loss': 0.09, 'grad_norm': 28.13157081604004, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.08497364073991776, 'loss_2': 0.00506591796875, 'loss_3': -15.842665672302246, 'loss_4': 1.3390116691589355, 'epoch': 6.87}
{'loss': 0.0181, 'grad_norm': 5.338560581207275, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.01281779259443283, 'loss_2': 0.005329132080078125, 'loss_3': -15.975753784179688, 'loss_4': 1.688453197479248, 'epoch': 6.88}
{'loss': 0.0276, 'grad_norm': 8.25054931640625, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.020077744498848915, 'loss_2': 0.007549285888671875, 'loss_3': -16.01801300048828, 'loss_4': 1.3108723163604736, 'epoch': 6.88}
{'loss': 0.0274, 'grad_norm': 9.25805950164795, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.02477041631937027, 'loss_2': 0.0026397705078125, 'loss_3': -16.06475067138672, 'loss_4': 1.8083312511444092, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 09:56:07,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:07,885 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:35<1:08:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:15,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0175505131483078, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.201, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.01289574708789587, 'eval_loss_2': 0.0046547651290893555, 'eval_loss_3': -18.259296417236328, 'eval_loss_4': 1.5937566757202148, 'epoch': 6.89}
{'loss': 0.0469, 'grad_norm': 18.967988967895508, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.03984774276614189, 'loss_2': 0.007061004638671875, 'loss_3': -15.946075439453125, 'loss_4': 2.155059337615967, 'epoch': 6.9}
{'loss': 0.034, 'grad_norm': 8.00256633758545, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.02617766708135605, 'loss_2': 0.00782012939453125, 'loss_3': -16.063480377197266, 'loss_4': 1.6766371726989746, 'epoch': 6.9}
{'loss': 0.0335, 'grad_norm': 10.31098461151123, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.03105791099369526, 'loss_2': 0.0024013519287109375, 'loss_3': -16.103713989257812, 'loss_4': 1.6934666633605957, 'epoch': 6.91}
{'loss': 0.0168, 'grad_norm': 5.88400936126709, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.012116952799260616, 'loss_2': 0.00467681884765625, 'loss_3': -16.011505126953125, 'loss_4': 1.7220207452774048, 'epoch': 6.91}
{'loss': 0.0327, 'grad_norm': 8.703716278076172, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.03134177625179291, 'loss_2': 0.001407623291015625, 'loss_3': -16.10101318359375, 'loss_4': 2.325443744659424, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 09:56:15,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:15,255 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:42<1:08:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:22,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016514509916305542, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.58, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012214906513690948, 'eval_loss_2': 0.0042996034026145935, 'eval_loss_3': -18.30866813659668, 'eval_loss_4': 1.841947317123413, 'epoch': 6.92}
{'loss': 0.0349, 'grad_norm': 12.651723861694336, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.0281501617282629, 'loss_2': 0.006702423095703125, 'loss_3': -16.021465301513672, 'loss_4': 2.386976957321167, 'epoch': 6.92}
{'loss': 0.0809, 'grad_norm': 22.10012435913086, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.0692412257194519, 'loss_2': 0.01168060302734375, 'loss_3': -15.821708679199219, 'loss_4': 2.3320603370666504, 'epoch': 6.93}
{'loss': 0.0413, 'grad_norm': 12.74168586730957, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.026579398661851883, 'loss_2': 0.01473236083984375, 'loss_3': -16.124122619628906, 'loss_4': 2.4989304542541504, 'epoch': 6.94}
{'loss': 0.0294, 'grad_norm': 7.355040073394775, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.028238646686077118, 'loss_2': 0.00113677978515625, 'loss_3': -16.048404693603516, 'loss_4': 2.003401279449463, 'epoch': 6.94}
{'loss': 0.0677, 'grad_norm': 21.8935489654541, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.06739847362041473, 'loss_2': 0.00029468536376953125, 'loss_3': -16.065086364746094, 'loss_4': 2.971503734588623, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 09:56:22,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:22,615 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [29:49<1:08:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:29,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014560692012310028, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010604904033243656, 'eval_loss_2': 0.0039557889103889465, 'eval_loss_3': -18.3280029296875, 'eval_loss_4': 2.045295238494873, 'epoch': 6.95}
{'loss': 0.0233, 'grad_norm': 6.482951641082764, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.020368101075291634, 'loss_2': 0.002899169921875, 'loss_3': -16.316822052001953, 'loss_4': 2.8797812461853027, 'epoch': 6.95}
{'loss': 0.0231, 'grad_norm': 11.56782054901123, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.02090943045914173, 'loss_2': 0.002231597900390625, 'loss_3': -16.080642700195312, 'loss_4': 2.089364767074585, 'epoch': 6.96}
{'loss': 0.028, 'grad_norm': 10.080459594726562, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.022253492847085, 'loss_2': 0.00579071044921875, 'loss_3': -16.04191017150879, 'loss_4': 3.1710824966430664, 'epoch': 6.97}
{'loss': 0.032, 'grad_norm': 10.252857208251953, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.026787662878632545, 'loss_2': 0.005191802978515625, 'loss_3': -16.02951431274414, 'loss_4': 3.739776134490967, 'epoch': 6.97}
{'loss': 0.0335, 'grad_norm': 9.26674747467041, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.03185733035206795, 'loss_2': 0.0015974044799804688, 'loss_3': -15.86838436126709, 'loss_4': 2.741518974304199, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 09:56:29,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:29,963 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [29:56<1:04:24,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:56:36,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015793099999427795, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010393709875643253, 'eval_loss_2': 0.005399391055107117, 'eval_loss_3': -18.34075927734375, 'eval_loss_4': 2.2026705741882324, 'epoch': 6.98}
{'loss': 0.0246, 'grad_norm': 7.252511024475098, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.023073146119713783, 'loss_2': 0.0014781951904296875, 'loss_3': -16.12598991394043, 'loss_4': 2.7100791931152344, 'epoch': 6.98}
{'loss': 0.0287, 'grad_norm': 10.458386421203613, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.025344334542751312, 'loss_2': 0.00335693359375, 'loss_3': -16.159360885620117, 'loss_4': 2.83327579498291, 'epoch': 6.99}
{'loss': 0.0187, 'grad_norm': 5.771846771240234, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.014849917963147163, 'loss_2': 0.0038909912109375, 'loss_3': -16.1641902923584, 'loss_4': 3.077230453491211, 'epoch': 6.99}
{'loss': 0.0077, 'grad_norm': 5.572896957397461, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.003090991172939539, 'loss_2': 0.004638671875, 'loss_3': -16.228240966796875, 'loss_4': 2.6360881328582764, 'epoch': 7.0}
{'loss': 0.0241, 'grad_norm': 6.366463661193848, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.01789218559861183, 'loss_2': 0.0062103271484375, 'loss_3': -16.19256591796875, 'loss_4': 2.602916955947876, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 09:56:36,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:36,994 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:04<1:07:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:56:44,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014547549188137054, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009945358149707317, 'eval_loss_2': 0.0046021901071071625, 'eval_loss_3': -18.301952362060547, 'eval_loss_4': 2.04624342918396, 'epoch': 7.01}
{'loss': 0.0212, 'grad_norm': 5.740504741668701, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.015421664342284203, 'loss_2': 0.005802154541015625, 'loss_3': -16.099382400512695, 'loss_4': 2.4864187240600586, 'epoch': 7.01}
{'loss': 0.0598, 'grad_norm': 29.876541137695312, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.0535820834338665, 'loss_2': 0.00617218017578125, 'loss_3': -15.848418235778809, 'loss_4': 2.631434202194214, 'epoch': 7.02}
{'loss': 0.0291, 'grad_norm': 9.152210235595703, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.022515831515192986, 'loss_2': 0.006595611572265625, 'loss_3': -15.968421936035156, 'loss_4': 2.874197483062744, 'epoch': 7.02}
{'loss': 0.0225, 'grad_norm': 8.726253509521484, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.021650556474924088, 'loss_2': 0.0008230209350585938, 'loss_3': -15.999213218688965, 'loss_4': 2.6978230476379395, 'epoch': 7.03}
{'loss': 0.0208, 'grad_norm': 6.511291027069092, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.018884625285863876, 'loss_2': 0.0019512176513671875, 'loss_3': -15.938783645629883, 'loss_4': 2.2535078525543213, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 09:56:44,343 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:44,343 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:11<1:08:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:51,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014997969381511211, 'eval_runtime': 3.82, 'eval_samples_per_second': 268.06, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.009846964851021767, 'eval_loss_2': 0.00515100359916687, 'eval_loss_3': -18.32837677001953, 'eval_loss_4': 2.558004379272461, 'epoch': 7.03}
{'loss': 0.0249, 'grad_norm': 7.911320209503174, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.020691843703389168, 'loss_2': 0.00421905517578125, 'loss_3': -16.01636505126953, 'loss_4': 3.1905603408813477, 'epoch': 7.04}
{'loss': 0.0358, 'grad_norm': 9.292948722839355, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.02292814292013645, 'loss_2': 0.01290130615234375, 'loss_3': -16.06764793395996, 'loss_4': 3.192343235015869, 'epoch': 7.05}
{'loss': 0.0803, 'grad_norm': 27.939359664916992, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.08015850931406021, 'loss_2': 0.00015282630920410156, 'loss_3': -16.115779876708984, 'loss_4': 3.7216715812683105, 'epoch': 7.05}
{'loss': 0.0213, 'grad_norm': 6.18671989440918, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.015052847564220428, 'loss_2': 0.006290435791015625, 'loss_3': -16.30999755859375, 'loss_4': 3.6960511207580566, 'epoch': 7.06}
{'loss': 0.0328, 'grad_norm': 9.799927711486816, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.02932949736714363, 'loss_2': 0.0034656524658203125, 'loss_3': -16.23167610168457, 'loss_4': 4.210321426391602, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 09:56:51,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:51,719 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:18<1:08:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:59,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012570979073643684, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008324090391397476, 'eval_loss_2': 0.004246890544891357, 'eval_loss_3': -18.32459831237793, 'eval_loss_4': 2.770596742630005, 'epoch': 7.06}
{'loss': 0.0271, 'grad_norm': 8.625832557678223, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.02703041397035122, 'loss_2': 8.296966552734375e-05, 'loss_3': -16.111164093017578, 'loss_4': 3.338010311126709, 'epoch': 7.07}
{'loss': 0.0365, 'grad_norm': 9.679028511047363, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.03152632340788841, 'loss_2': 0.00495147705078125, 'loss_3': -16.06637954711914, 'loss_4': 4.257518768310547, 'epoch': 7.08}
{'loss': 0.0131, 'grad_norm': 6.299671173095703, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.012285254895687103, 'loss_2': 0.0008296966552734375, 'loss_3': -16.056100845336914, 'loss_4': 3.763178586959839, 'epoch': 7.08}
{'loss': 0.023, 'grad_norm': 7.8488969802856445, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.013904689811170101, 'loss_2': 0.0090789794921875, 'loss_3': -16.354602813720703, 'loss_4': 2.3538296222686768, 'epoch': 7.09}
{'loss': 0.0338, 'grad_norm': 10.315408706665039, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.02826291136443615, 'loss_2': 0.00553131103515625, 'loss_3': -16.0805721282959, 'loss_4': 3.47458815574646, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 09:56:59,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:59,073 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:26<1:08:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:06,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013568352907896042, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008557570166885853, 'eval_loss_2': 0.005010783672332764, 'eval_loss_3': -18.325075149536133, 'eval_loss_4': 2.3555240631103516, 'epoch': 7.09}
{'loss': 0.0356, 'grad_norm': 8.634984016418457, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.031216073781251907, 'loss_2': 0.004337310791015625, 'loss_3': -16.212249755859375, 'loss_4': 2.9006433486938477, 'epoch': 7.1}
{'loss': 0.0597, 'grad_norm': 20.786035537719727, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.05179579183459282, 'loss_2': 0.007904052734375, 'loss_3': -16.11292839050293, 'loss_4': 3.5518898963928223, 'epoch': 7.1}
{'loss': 0.0302, 'grad_norm': 7.387665271759033, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.019052449613809586, 'loss_2': 0.0111083984375, 'loss_3': -16.183454513549805, 'loss_4': 2.804999828338623, 'epoch': 7.11}
{'loss': 0.0227, 'grad_norm': 6.574862003326416, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.01801973395049572, 'loss_2': 0.0046844482421875, 'loss_3': -16.281923294067383, 'loss_4': 2.6808178424835205, 'epoch': 7.12}
{'loss': 0.0324, 'grad_norm': 10.629073143005371, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.027378106489777565, 'loss_2': 0.0049896240234375, 'loss_3': -16.07686424255371, 'loss_4': 2.4599270820617676, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 09:57:06,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:06,424 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:33<1:07:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:13,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016814999282360077, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010056291706860065, 'eval_loss_2': 0.006758708506822586, 'eval_loss_3': -18.288188934326172, 'eval_loss_4': 2.078263282775879, 'epoch': 7.12}
{'loss': 0.0328, 'grad_norm': 11.891556739807129, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.024992551654577255, 'loss_2': 0.007781982421875, 'loss_3': -16.072101593017578, 'loss_4': 2.433634042739868, 'epoch': 7.13}
{'loss': 0.0333, 'grad_norm': 10.943479537963867, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.029448406770825386, 'loss_2': 0.00388336181640625, 'loss_3': -16.18764877319336, 'loss_4': 2.0423245429992676, 'epoch': 7.13}
{'loss': 0.0349, 'grad_norm': 9.94827938079834, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.02921181358397007, 'loss_2': 0.00568389892578125, 'loss_3': -16.149246215820312, 'loss_4': 1.7239936590194702, 'epoch': 7.14}
{'loss': 0.0128, 'grad_norm': 5.570336818695068, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.010560649447143078, 'loss_2': 0.00223541259765625, 'loss_3': -16.149063110351562, 'loss_4': 2.0175211429595947, 'epoch': 7.15}
{'loss': 0.0208, 'grad_norm': 6.627148151397705, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.01645391620695591, 'loss_2': 0.0043182373046875, 'loss_3': -16.255348205566406, 'loss_4': 2.3418819904327393, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 09:57:13,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:13,768 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:40<1:07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:21,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02132166549563408, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.494, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014915356412529945, 'eval_loss_2': 0.006406307220458984, 'eval_loss_3': -18.23954963684082, 'eval_loss_4': 2.3517439365386963, 'epoch': 7.15}
{'loss': 0.0231, 'grad_norm': 8.936820030212402, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.01815137267112732, 'loss_2': 0.00499725341796875, 'loss_3': -16.125112533569336, 'loss_4': 2.483686923980713, 'epoch': 7.16}
{'loss': 0.0638, 'grad_norm': 18.682090759277344, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.058505579829216, 'loss_2': 0.00533294677734375, 'loss_3': -16.066232681274414, 'loss_4': 2.744530200958252, 'epoch': 7.16}
{'loss': 0.025, 'grad_norm': 7.414053916931152, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.016699235886335373, 'loss_2': 0.0082855224609375, 'loss_3': -16.203418731689453, 'loss_4': 2.762629747390747, 'epoch': 7.17}
{'loss': 0.0167, 'grad_norm': 6.429514408111572, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.013481257483363152, 'loss_2': 0.003215789794921875, 'loss_3': -16.199909210205078, 'loss_4': 2.763850212097168, 'epoch': 7.17}
{'loss': 0.0325, 'grad_norm': 10.794066429138184, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.020859060809016228, 'loss_2': 0.0116729736328125, 'loss_3': -16.251827239990234, 'loss_4': 2.7606048583984375, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 09:57:21,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:21,111 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:48<1:07:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:28,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02446613274514675, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.019160162657499313, 'eval_loss_2': 0.005305968225002289, 'eval_loss_3': -18.175575256347656, 'eval_loss_4': 2.4944748878479004, 'epoch': 7.18}
{'loss': 0.0239, 'grad_norm': 9.990066528320312, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.017998555675148964, 'loss_2': 0.0059051513671875, 'loss_3': -15.871092796325684, 'loss_4': 2.173250675201416, 'epoch': 7.19}
{'loss': 0.0345, 'grad_norm': 9.07219409942627, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.023014608770608902, 'loss_2': 0.01148223876953125, 'loss_3': -15.962803840637207, 'loss_4': 2.4021353721618652, 'epoch': 7.19}
{'loss': 0.0288, 'grad_norm': 9.907224655151367, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.02877727337181568, 'loss_2': 2.2172927856445312e-05, 'loss_3': -16.21535873413086, 'loss_4': 2.258181095123291, 'epoch': 7.2}
{'loss': 0.0161, 'grad_norm': 6.404447078704834, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.014428879134356976, 'loss_2': 0.0016469955444335938, 'loss_3': -16.041099548339844, 'loss_4': 2.7961976528167725, 'epoch': 7.2}
{'loss': 0.0148, 'grad_norm': 5.357432842254639, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.010290390811860561, 'loss_2': 0.00446319580078125, 'loss_3': -16.013822555541992, 'loss_4': 2.4035887718200684, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 09:57:28,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:28,466 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [30:55<1:07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:35,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0268268920481205, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.161, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.018746977671980858, 'eval_loss_2': 0.00807991623878479, 'eval_loss_3': -18.17595672607422, 'eval_loss_4': 2.5656986236572266, 'epoch': 7.21}
{'loss': 0.0185, 'grad_norm': 5.608894348144531, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.00933812279254198, 'loss_2': 0.00920867919921875, 'loss_3': -16.162654876708984, 'loss_4': 2.680356502532959, 'epoch': 7.22}
{'loss': 0.0443, 'grad_norm': 27.913692474365234, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.03800707682967186, 'loss_2': 0.00630950927734375, 'loss_3': -16.265827178955078, 'loss_4': 2.8065731525421143, 'epoch': 7.22}
{'loss': 0.0273, 'grad_norm': 7.309842586517334, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.01814262941479683, 'loss_2': 0.009185791015625, 'loss_3': -15.920891761779785, 'loss_4': 2.7433743476867676, 'epoch': 7.23}
{'loss': 0.0488, 'grad_norm': 11.68521785736084, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.034032873809337616, 'loss_2': 0.014739990234375, 'loss_3': -16.078262329101562, 'loss_4': 3.0240492820739746, 'epoch': 7.23}
{'loss': 0.0537, 'grad_norm': 17.75048065185547, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.03762045130133629, 'loss_2': 0.01605224609375, 'loss_3': -15.994518280029297, 'loss_4': 2.6551647186279297, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 09:57:35,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:35,837 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:02<1:07:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:43,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028960755094885826, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018624117597937584, 'eval_loss_2': 0.010336637496948242, 'eval_loss_3': -18.17807960510254, 'eval_loss_4': 2.7144479751586914, 'epoch': 7.24}
{'loss': 0.0306, 'grad_norm': 6.119080543518066, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.017313795164227486, 'loss_2': 0.0132904052734375, 'loss_3': -16.015716552734375, 'loss_4': 2.9367904663085938, 'epoch': 7.24}
{'loss': 0.036, 'grad_norm': 9.85334587097168, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.027340779080986977, 'loss_2': 0.00865936279296875, 'loss_3': -16.15312957763672, 'loss_4': 2.9975719451904297, 'epoch': 7.25}
{'loss': 0.0218, 'grad_norm': 7.095972537994385, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.020634343847632408, 'loss_2': 0.0011777877807617188, 'loss_3': -16.15286636352539, 'loss_4': 2.6692066192626953, 'epoch': 7.26}
{'loss': 0.0098, 'grad_norm': 5.503439903259277, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.007814479060471058, 'loss_2': 0.00202178955078125, 'loss_3': -16.24242401123047, 'loss_4': 2.5881004333496094, 'epoch': 7.26}
{'loss': 0.0303, 'grad_norm': 7.658290386199951, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.01966673508286476, 'loss_2': 0.010650634765625, 'loss_3': -16.329544067382812, 'loss_4': 2.9609313011169434, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 09:57:43,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:43,184 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:10<1:07:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:50,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0191599503159523, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015197163447737694, 'eval_loss_2': 0.003962785005569458, 'eval_loss_3': -18.21086311340332, 'eval_loss_4': 2.441380739212036, 'epoch': 7.27}
{'loss': 0.0246, 'grad_norm': 10.609590530395508, 'learning_rate': 2.275e-05, 'loss_1': 0.023796264082193375, 'loss_2': 0.0007543563842773438, 'loss_3': -15.871288299560547, 'loss_4': 2.622231960296631, 'epoch': 7.27}
{'loss': 0.0171, 'grad_norm': 5.629720211029053, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.0143035389482975, 'loss_2': 0.0027751922607421875, 'loss_3': -16.189159393310547, 'loss_4': 2.4223878383636475, 'epoch': 7.28}
{'loss': 0.0172, 'grad_norm': 5.795333385467529, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.013243366032838821, 'loss_2': 0.00391387939453125, 'loss_3': -16.25634765625, 'loss_4': 2.1283326148986816, 'epoch': 7.28}
{'loss': 0.029, 'grad_norm': 10.327713966369629, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.025704875588417053, 'loss_2': 0.003284454345703125, 'loss_3': -16.02102279663086, 'loss_4': 2.8449153900146484, 'epoch': 7.29}
{'loss': 0.0321, 'grad_norm': 11.461614608764648, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.028783947229385376, 'loss_2': 0.003314971923828125, 'loss_3': -15.944231033325195, 'loss_4': 2.4596731662750244, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 09:57:50,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:50,528 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:17<1:07:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:57,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016954466700553894, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012482695281505585, 'eval_loss_2': 0.004471771419048309, 'eval_loss_3': -18.228713989257812, 'eval_loss_4': 2.1034650802612305, 'epoch': 7.3}
{'loss': 0.0237, 'grad_norm': 6.516788005828857, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.017472609877586365, 'loss_2': 0.006214141845703125, 'loss_3': -16.309736251831055, 'loss_4': 2.0824832916259766, 'epoch': 7.3}
{'loss': 0.0268, 'grad_norm': 8.938688278198242, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.024842916056513786, 'loss_2': 0.001956939697265625, 'loss_3': -16.04253387451172, 'loss_4': 1.953145980834961, 'epoch': 7.31}
{'loss': 0.035, 'grad_norm': 11.748859405517578, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.03192908689379692, 'loss_2': 0.00311279296875, 'loss_3': -16.121315002441406, 'loss_4': 2.200706958770752, 'epoch': 7.31}
{'loss': 0.0299, 'grad_norm': 12.026678085327148, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.02813236601650715, 'loss_2': 0.0017290115356445312, 'loss_3': -15.979290962219238, 'loss_4': 2.3599681854248047, 'epoch': 7.32}
{'loss': 0.0135, 'grad_norm': 5.672903060913086, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.013323375023901463, 'loss_2': 0.00019431114196777344, 'loss_3': -16.017383575439453, 'loss_4': 1.6902202367782593, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 09:57:57,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:57,884 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:25<1:07:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:05,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014487108215689659, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.218, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010661421343684196, 'eval_loss_2': 0.0038256868720054626, 'eval_loss_3': -18.20521354675293, 'eval_loss_4': 1.773012399673462, 'epoch': 7.33}
{'loss': 0.045, 'grad_norm': 13.074138641357422, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.040433838963508606, 'loss_2': 0.004596710205078125, 'loss_3': -16.111787796020508, 'loss_4': 2.420290231704712, 'epoch': 7.33}
{'loss': 0.0621, 'grad_norm': 20.249879837036133, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.058570969849824905, 'loss_2': 0.003543853759765625, 'loss_3': -16.02265167236328, 'loss_4': 1.3898954391479492, 'epoch': 7.34}
{'loss': 0.0195, 'grad_norm': 6.85253381729126, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.01640850119292736, 'loss_2': 0.003047943115234375, 'loss_3': -16.078845977783203, 'loss_4': 1.2397148609161377, 'epoch': 7.34}
{'loss': 0.0286, 'grad_norm': 9.106575965881348, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.02036544866859913, 'loss_2': 0.00823974609375, 'loss_3': -16.23613739013672, 'loss_4': 1.4617993831634521, 'epoch': 7.35}
{'loss': 0.0387, 'grad_norm': 11.029939651489258, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.037763964384794235, 'loss_2': 0.000965118408203125, 'loss_3': -16.111669540405273, 'loss_4': 2.0465030670166016, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 09:58:05,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:05,235 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:32<1:07:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:12,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014238509349524975, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00997694581747055, 'eval_loss_2': 0.004261564463376999, 'eval_loss_3': -18.191011428833008, 'eval_loss_4': 1.5839675664901733, 'epoch': 7.35}
{'loss': 0.1294, 'grad_norm': 18.85425567626953, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.1269194483757019, 'loss_2': 0.00252532958984375, 'loss_3': -15.730022430419922, 'loss_4': 1.5170750617980957, 'epoch': 7.36}
{'loss': 0.0254, 'grad_norm': 9.147440910339355, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.016920167952775955, 'loss_2': 0.0085296630859375, 'loss_3': -15.99252986907959, 'loss_4': 2.0987439155578613, 'epoch': 7.37}
{'loss': 0.02, 'grad_norm': 7.71238374710083, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.016953470185399055, 'loss_2': 0.003078460693359375, 'loss_3': -15.956525802612305, 'loss_4': 1.9250379800796509, 'epoch': 7.37}
{'loss': 0.0207, 'grad_norm': 8.34288501739502, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.01752445101737976, 'loss_2': 0.0031528472900390625, 'loss_3': -15.947771072387695, 'loss_4': 1.7096290588378906, 'epoch': 7.38}
{'loss': 0.0515, 'grad_norm': 15.560294151306152, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.05117110535502434, 'loss_2': 0.000339508056640625, 'loss_3': -15.869410514831543, 'loss_4': 1.6634007692337036, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 09:58:12,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:12,592 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:39<1:07:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:19,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01109883189201355, 'eval_runtime': 3.8216, 'eval_samples_per_second': 267.949, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.008031029254198074, 'eval_loss_2': 0.0030678026378154755, 'eval_loss_3': -18.17656135559082, 'eval_loss_4': 1.5976651906967163, 'epoch': 7.38}
{'loss': 0.0485, 'grad_norm': 14.226971626281738, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.04425615072250366, 'loss_2': 0.004268646240234375, 'loss_3': -16.096267700195312, 'loss_4': 1.882584571838379, 'epoch': 7.39}
{'loss': 0.0123, 'grad_norm': 4.897548198699951, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.007063524331897497, 'loss_2': 0.00524139404296875, 'loss_3': -16.268516540527344, 'loss_4': 1.629051685333252, 'epoch': 7.4}
{'loss': 0.0149, 'grad_norm': 6.272063732147217, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.011722682975232601, 'loss_2': 0.0031890869140625, 'loss_3': -16.066082000732422, 'loss_4': 1.8025269508361816, 'epoch': 7.4}
{'loss': 0.019, 'grad_norm': 8.847480773925781, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.013229918666183949, 'loss_2': 0.00580596923828125, 'loss_3': -16.233997344970703, 'loss_4': 2.3796706199645996, 'epoch': 7.41}
{'loss': 0.0235, 'grad_norm': 8.744434356689453, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.022141683846712112, 'loss_2': 0.0013332366943359375, 'loss_3': -16.018747329711914, 'loss_4': 1.3550294637680054, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 09:58:19,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:19,953 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:47<1:07:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:27,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01098441518843174, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.276, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008200326934456825, 'eval_loss_2': 0.0027840882539749146, 'eval_loss_3': -18.16986846923828, 'eval_loss_4': 1.4499313831329346, 'epoch': 7.41}
{'loss': 0.0209, 'grad_norm': 8.574136734008789, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.019386829808354378, 'loss_2': 0.001522064208984375, 'loss_3': -16.15602684020996, 'loss_4': 1.4114394187927246, 'epoch': 7.42}
{'loss': 0.0162, 'grad_norm': 6.046301364898682, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.014392009936273098, 'loss_2': 0.0017604827880859375, 'loss_3': -15.878942489624023, 'loss_4': 1.4138081073760986, 'epoch': 7.42}
{'loss': 0.0199, 'grad_norm': 7.143394947052002, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.012755932286381721, 'loss_2': 0.00716400146484375, 'loss_3': -16.097549438476562, 'loss_4': 1.8318105936050415, 'epoch': 7.43}
{'loss': 0.0155, 'grad_norm': 8.099808692932129, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.015135920606553555, 'loss_2': 0.0003974437713623047, 'loss_3': -15.994428634643555, 'loss_4': 1.2081077098846436, 'epoch': 7.44}
{'loss': 0.0153, 'grad_norm': 6.657499313354492, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.013610461726784706, 'loss_2': 0.00164794921875, 'loss_3': -15.89046859741211, 'loss_4': 1.3070068359375, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 09:58:27,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:27,292 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [31:54<1:06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:34,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015511719509959221, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010908331722021103, 'eval_loss_2': 0.004603385925292969, 'eval_loss_3': -18.139240264892578, 'eval_loss_4': 1.3600006103515625, 'epoch': 7.44}
{'loss': 0.0184, 'grad_norm': 6.065810203552246, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.011445100419223309, 'loss_2': 0.006961822509765625, 'loss_3': -15.855891227722168, 'loss_4': 1.3169164657592773, 'epoch': 7.45}
{'loss': 0.0161, 'grad_norm': 6.556197166442871, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.015073067508637905, 'loss_2': 0.001033782958984375, 'loss_3': -15.970840454101562, 'loss_4': 1.41750168800354, 'epoch': 7.45}
{'loss': 0.0196, 'grad_norm': 5.061697483062744, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.005332356784492731, 'loss_2': 0.0142364501953125, 'loss_3': -16.018115997314453, 'loss_4': 1.6195721626281738, 'epoch': 7.46}
{'loss': 0.0243, 'grad_norm': 7.284510612487793, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.012748513370752335, 'loss_2': 0.0115203857421875, 'loss_3': -16.080562591552734, 'loss_4': 1.3746213912963867, 'epoch': 7.47}
{'loss': 0.0163, 'grad_norm': 5.704748153686523, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.01047307625412941, 'loss_2': 0.005840301513671875, 'loss_3': -15.879660606384277, 'loss_4': 1.8611029386520386, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 09:58:34,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:34,632 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:01<1:06:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:41,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019706012681126595, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.54, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0175687987357378, 'eval_loss_2': 0.002137213945388794, 'eval_loss_3': -18.13728904724121, 'eval_loss_4': 1.3352879285812378, 'epoch': 7.47}
{'loss': 0.0286, 'grad_norm': 10.489701271057129, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.02682945877313614, 'loss_2': 0.001796722412109375, 'loss_3': -16.04387855529785, 'loss_4': 1.506866455078125, 'epoch': 7.48}
{'loss': 0.0171, 'grad_norm': 4.985114574432373, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.006186520215123892, 'loss_2': 0.0109100341796875, 'loss_3': -16.26024055480957, 'loss_4': 1.6469056606292725, 'epoch': 7.48}
{'loss': 0.0098, 'grad_norm': 5.762436866760254, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.006955832242965698, 'loss_2': 0.002880096435546875, 'loss_3': -16.340744018554688, 'loss_4': 1.226445198059082, 'epoch': 7.49}
{'loss': 0.0097, 'grad_norm': 5.638948917388916, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.008803893812000751, 'loss_2': 0.0009293556213378906, 'loss_3': -15.985886573791504, 'loss_4': 1.2977828979492188, 'epoch': 7.49}
{'loss': 0.021, 'grad_norm': 6.4165849685668945, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.015361189842224121, 'loss_2': 0.005603790283203125, 'loss_3': -15.923203468322754, 'loss_4': 1.0457067489624023, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 09:58:41,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:41,973 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:09<1:06:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:49,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03130996972322464, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01914251782000065, 'eval_loss_2': 0.01216745376586914, 'eval_loss_3': -18.174823760986328, 'eval_loss_4': 1.104933261871338, 'epoch': 7.5}
{'loss': 0.0156, 'grad_norm': 6.036202907562256, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.010748803615570068, 'loss_2': 0.0048980712890625, 'loss_3': -16.1226806640625, 'loss_4': 0.9215899705886841, 'epoch': 7.51}
{'loss': 0.0309, 'grad_norm': 9.43106746673584, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.01693425327539444, 'loss_2': 0.01397705078125, 'loss_3': -16.052139282226562, 'loss_4': 1.3136873245239258, 'epoch': 7.51}
{'loss': 0.0314, 'grad_norm': 5.889560222625732, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.016715921461582184, 'loss_2': 0.0147247314453125, 'loss_3': -16.01442527770996, 'loss_4': 1.3486292362213135, 'epoch': 7.52}
{'loss': 0.0567, 'grad_norm': 20.997394561767578, 'learning_rate': 2.25e-05, 'loss_1': 0.048520125448703766, 'loss_2': 0.0081787109375, 'loss_3': -16.054277420043945, 'loss_4': 0.853922963142395, 'epoch': 7.52}
{'loss': 0.0322, 'grad_norm': 7.517153739929199, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.014958184212446213, 'loss_2': 0.0172576904296875, 'loss_3': -16.092790603637695, 'loss_4': 0.970205545425415, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 09:58:49,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:49,315 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:16<1:07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:56,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029073413461446762, 'eval_runtime': 3.8381, 'eval_samples_per_second': 266.8, 'eval_steps_per_second': 4.169, 'eval_loss_1': 0.01757686957716942, 'eval_loss_2': 0.011496543884277344, 'eval_loss_3': -18.19680404663086, 'eval_loss_4': 1.0439823865890503, 'epoch': 7.53}
{'loss': 0.0363, 'grad_norm': 7.367123603820801, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.01786220259964466, 'loss_2': 0.018463134765625, 'loss_3': -16.10249900817871, 'loss_4': 1.115543007850647, 'epoch': 7.53}
{'loss': 0.0314, 'grad_norm': 9.20052433013916, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.021093251183629036, 'loss_2': 0.0102996826171875, 'loss_3': -16.127473831176758, 'loss_4': 1.0591236352920532, 'epoch': 7.54}
{'loss': 0.0253, 'grad_norm': 8.815093994140625, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.021584488451480865, 'loss_2': 0.0036907196044921875, 'loss_3': -16.195709228515625, 'loss_4': 2.098184108734131, 'epoch': 7.55}
{'loss': 0.0234, 'grad_norm': 7.790122032165527, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.022864386439323425, 'loss_2': 0.0004901885986328125, 'loss_3': -16.083852767944336, 'loss_4': 1.8025094270706177, 'epoch': 7.55}
{'loss': 0.0198, 'grad_norm': 8.309569358825684, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.018412219360470772, 'loss_2': 0.0013418197631835938, 'loss_3': -16.074323654174805, 'loss_4': 1.553770661354065, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 09:58:56,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:56,714 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:23<1:06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:04,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01766212098300457, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.349, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013771145604550838, 'eval_loss_2': 0.003890976309776306, 'eval_loss_3': -18.222618103027344, 'eval_loss_4': 1.0114704370498657, 'epoch': 7.56}
{'loss': 0.032, 'grad_norm': 14.914422988891602, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.029351569712162018, 'loss_2': 0.0026702880859375, 'loss_3': -16.009798049926758, 'loss_4': 1.138924479484558, 'epoch': 7.56}
{'loss': 0.0149, 'grad_norm': 5.930675983428955, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.011624234728515148, 'loss_2': 0.003299713134765625, 'loss_3': -16.132875442504883, 'loss_4': 1.2346210479736328, 'epoch': 7.57}
{'loss': 0.0198, 'grad_norm': 6.117364406585693, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.013851692900061607, 'loss_2': 0.00592803955078125, 'loss_3': -16.17215347290039, 'loss_4': 0.9531153440475464, 'epoch': 7.58}
{'loss': 0.0229, 'grad_norm': 7.006025791168213, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.01792597398161888, 'loss_2': 0.0049591064453125, 'loss_3': -15.826804161071777, 'loss_4': 1.1838842630386353, 'epoch': 7.58}
{'loss': 0.0295, 'grad_norm': 8.813755989074707, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.02563505247235298, 'loss_2': 0.003833770751953125, 'loss_3': -16.250160217285156, 'loss_4': 0.6023777723312378, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 09:59:04,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:04,058 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:31<1:06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:11,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015622853301465511, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011866924352943897, 'eval_loss_2': 0.003755927085876465, 'eval_loss_3': -18.256553649902344, 'eval_loss_4': 1.0039128065109253, 'epoch': 7.59}
{'loss': 0.0369, 'grad_norm': 11.627264022827148, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.03561432659626007, 'loss_2': 0.0012454986572265625, 'loss_3': -16.11800193786621, 'loss_4': 1.6719250679016113, 'epoch': 7.59}
{'loss': 0.0425, 'grad_norm': 10.338849067687988, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.0400836244225502, 'loss_2': 0.002410888671875, 'loss_3': -16.099328994750977, 'loss_4': 1.0652920007705688, 'epoch': 7.6}
{'loss': 0.0365, 'grad_norm': 12.440129280090332, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.03335680067539215, 'loss_2': 0.003154754638671875, 'loss_3': -15.968128204345703, 'loss_4': 0.9149402976036072, 'epoch': 7.6}
{'loss': 0.021, 'grad_norm': 7.893677711486816, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.019207537174224854, 'loss_2': 0.0018415451049804688, 'loss_3': -16.22555923461914, 'loss_4': 1.5636365413665771, 'epoch': 7.61}
{'loss': 0.0295, 'grad_norm': 11.490102767944336, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.01854769140481949, 'loss_2': 0.01094818115234375, 'loss_3': -16.233734130859375, 'loss_4': 1.4037964344024658, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 09:59:11,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:11,400 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:38<1:06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:18,740 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018580490723252296, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.682, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012746448628604412, 'eval_loss_2': 0.005834043025970459, 'eval_loss_3': -18.25128936767578, 'eval_loss_4': 1.086700439453125, 'epoch': 7.62}
{'loss': 0.0272, 'grad_norm': 8.160370826721191, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.019048966467380524, 'loss_2': 0.0081939697265625, 'loss_3': -16.141910552978516, 'loss_4': 0.907072901725769, 'epoch': 7.62}
{'loss': 0.0275, 'grad_norm': 6.876721382141113, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.02400360256433487, 'loss_2': 0.003459930419921875, 'loss_3': -16.002979278564453, 'loss_4': 0.8582672476768494, 'epoch': 7.63}
{'loss': 0.0264, 'grad_norm': 7.949354648590088, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.02151137962937355, 'loss_2': 0.0048828125, 'loss_3': -16.090404510498047, 'loss_4': 1.189077377319336, 'epoch': 7.63}
{'loss': 0.0561, 'grad_norm': 18.606246948242188, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.051834750920534134, 'loss_2': 0.00423431396484375, 'loss_3': -16.066513061523438, 'loss_4': 1.2054996490478516, 'epoch': 7.64}
{'loss': 0.0676, 'grad_norm': 22.234394073486328, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.05301527678966522, 'loss_2': 0.0145721435546875, 'loss_3': -16.038530349731445, 'loss_4': 1.4758038520812988, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 09:59:18,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:18,741 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:45<1:06:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:26,085 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01653073914349079, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01271768193691969, 'eval_loss_2': 0.0038130581378936768, 'eval_loss_3': -18.240358352661133, 'eval_loss_4': 1.2195353507995605, 'epoch': 7.65}
{'loss': 0.0177, 'grad_norm': 8.62318229675293, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.015863802284002304, 'loss_2': 0.0018529891967773438, 'loss_3': -16.001842498779297, 'loss_4': 1.4844348430633545, 'epoch': 7.65}
{'loss': 0.0169, 'grad_norm': 6.734628200531006, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.013545277528464794, 'loss_2': 0.003337860107421875, 'loss_3': -16.193466186523438, 'loss_4': 1.629579782485962, 'epoch': 7.66}
{'loss': 0.0334, 'grad_norm': 9.984877586364746, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.025031231343746185, 'loss_2': 0.008331298828125, 'loss_3': -15.985225677490234, 'loss_4': 1.4869400262832642, 'epoch': 7.66}
{'loss': 0.0215, 'grad_norm': 8.86007308959961, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.020218154415488243, 'loss_2': 0.001239776611328125, 'loss_3': -16.10433578491211, 'loss_4': 1.6324222087860107, 'epoch': 7.67}
{'loss': 0.0102, 'grad_norm': 5.529332160949707, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.009662012569606304, 'loss_2': 0.0005292892456054688, 'loss_3': -16.053037643432617, 'loss_4': 1.215818166732788, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 09:59:26,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:26,086 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [32:53<1:07:14,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:59:33,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01668514311313629, 'eval_runtime': 3.9933, 'eval_samples_per_second': 256.432, 'eval_steps_per_second': 4.007, 'eval_loss_1': 0.01244813296943903, 'eval_loss_2': 0.004237011075019836, 'eval_loss_3': -18.265419006347656, 'eval_loss_4': 1.316131353378296, 'epoch': 7.67}
{'loss': 0.033, 'grad_norm': 8.239702224731445, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.0293611828237772, 'loss_2': 0.003665924072265625, 'loss_3': -16.085811614990234, 'loss_4': 1.675566554069519, 'epoch': 7.68}
{'loss': 0.0118, 'grad_norm': 5.677314281463623, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.011322599835693836, 'loss_2': 0.00043892860412597656, 'loss_3': -15.989907264709473, 'loss_4': 1.114927053451538, 'epoch': 7.69}
{'loss': 0.0187, 'grad_norm': 5.944258213043213, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.01594769023358822, 'loss_2': 0.002735137939453125, 'loss_3': -16.06053924560547, 'loss_4': 1.9942569732666016, 'epoch': 7.69}
{'loss': 0.0268, 'grad_norm': 7.816514492034912, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.0226298738270998, 'loss_2': 0.004154205322265625, 'loss_3': -15.929361343383789, 'loss_4': 1.4432282447814941, 'epoch': 7.7}
{'loss': 0.0201, 'grad_norm': 7.246009826660156, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.01770794205367565, 'loss_2': 0.00244140625, 'loss_3': -16.22660255432129, 'loss_4': 1.4799931049346924, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 09:59:33,627 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:33,627 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:00<1:06:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:40,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01457380410283804, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.129, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.010618738830089569, 'eval_loss_2': 0.003955066204071045, 'eval_loss_3': -18.2730655670166, 'eval_loss_4': 1.342167615890503, 'epoch': 7.7}
{'loss': 0.0341, 'grad_norm': 13.32717227935791, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.026016077026724815, 'loss_2': 0.00811767578125, 'loss_3': -15.990265846252441, 'loss_4': 1.8832347393035889, 'epoch': 7.71}
{'loss': 0.0354, 'grad_norm': 12.021806716918945, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.033193159848451614, 'loss_2': 0.002227783203125, 'loss_3': -15.937211990356445, 'loss_4': 1.8957915306091309, 'epoch': 7.72}
{'loss': 0.0265, 'grad_norm': 6.995050430297852, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.02060552127659321, 'loss_2': 0.005863189697265625, 'loss_3': -16.062854766845703, 'loss_4': 2.1615428924560547, 'epoch': 7.72}
{'loss': 0.0282, 'grad_norm': 9.175193786621094, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.02044406346976757, 'loss_2': 0.007717132568359375, 'loss_3': -16.06885528564453, 'loss_4': 1.713636875152588, 'epoch': 7.73}
{'loss': 0.0117, 'grad_norm': 5.278372764587402, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.008349454961717129, 'loss_2': 0.0033588409423828125, 'loss_3': -16.106700897216797, 'loss_4': 1.3351466655731201, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 09:59:40,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:40,993 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:08<1:06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:48,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014157688245177269, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011026371270418167, 'eval_loss_2': 0.0031313151121139526, 'eval_loss_3': -18.291187286376953, 'eval_loss_4': 1.3858479261398315, 'epoch': 7.73}
{'loss': 0.0353, 'grad_norm': 11.822616577148438, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.03181983157992363, 'loss_2': 0.003437042236328125, 'loss_3': -16.13239288330078, 'loss_4': 1.1898503303527832, 'epoch': 7.74}
{'loss': 0.0203, 'grad_norm': 7.446044445037842, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.019593795761466026, 'loss_2': 0.000728607177734375, 'loss_3': -16.1507625579834, 'loss_4': 1.7863852977752686, 'epoch': 7.74}
{'loss': 0.0129, 'grad_norm': 6.320965766906738, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.012518010102212429, 'loss_2': 0.0003666877746582031, 'loss_3': -16.386882781982422, 'loss_4': 1.3091284036636353, 'epoch': 7.75}
{'loss': 0.0117, 'grad_norm': 6.118412017822266, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.009898098185658455, 'loss_2': 0.0018072128295898438, 'loss_3': -15.87299919128418, 'loss_4': 1.2610869407653809, 'epoch': 7.76}
{'loss': 0.0171, 'grad_norm': 6.215675354003906, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.014777238480746746, 'loss_2': 0.002292633056640625, 'loss_3': -16.120792388916016, 'loss_4': 2.1799981594085693, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 09:59:48,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:48,341 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:15<1:06:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:55,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013813402503728867, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010487253777682781, 'eval_loss_2': 0.0033261477947235107, 'eval_loss_3': -18.294021606445312, 'eval_loss_4': 1.4584165811538696, 'epoch': 7.76}
{'loss': 0.0427, 'grad_norm': 18.08994483947754, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.04063670337200165, 'loss_2': 0.00209808349609375, 'loss_3': -16.31817626953125, 'loss_4': 1.949535846710205, 'epoch': 7.77}
{'loss': 0.0282, 'grad_norm': 8.536060333251953, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.024544693529605865, 'loss_2': 0.003692626953125, 'loss_3': -16.050857543945312, 'loss_4': 1.4839348793029785, 'epoch': 7.77}
{'loss': 0.0658, 'grad_norm': 22.04947280883789, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.05902833491563797, 'loss_2': 0.0067901611328125, 'loss_3': -16.131874084472656, 'loss_4': 1.6455159187316895, 'epoch': 7.78}
{'loss': 0.0399, 'grad_norm': 13.155294418334961, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.03312389552593231, 'loss_2': 0.00679779052734375, 'loss_3': -15.940674781799316, 'loss_4': 1.576838493347168, 'epoch': 7.78}
{'loss': 0.0225, 'grad_norm': 7.300652980804443, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.01479108352214098, 'loss_2': 0.00769805908203125, 'loss_3': -16.092060089111328, 'loss_4': 1.4730420112609863, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 09:59:55,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:55,686 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:22<1:06:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:03,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020971443504095078, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012448932975530624, 'eval_loss_2': 0.008522510528564453, 'eval_loss_3': -18.296846389770508, 'eval_loss_4': 1.4085161685943604, 'epoch': 7.79}
{'loss': 0.0314, 'grad_norm': 15.248003959655762, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.02075343020260334, 'loss_2': 0.01065826416015625, 'loss_3': -16.194229125976562, 'loss_4': 2.1547467708587646, 'epoch': 7.8}
{'loss': 0.0377, 'grad_norm': 8.681951522827148, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.027989469468593597, 'loss_2': 0.0097503662109375, 'loss_3': -16.249698638916016, 'loss_4': 1.722395658493042, 'epoch': 7.8}
{'loss': 0.0406, 'grad_norm': 7.123341083526611, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.028717631474137306, 'loss_2': 0.0118865966796875, 'loss_3': -16.2263240814209, 'loss_4': 1.3683627843856812, 'epoch': 7.81}
{'loss': 0.018, 'grad_norm': 5.875396251678467, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.010862620547413826, 'loss_2': 0.007144927978515625, 'loss_3': -16.14373016357422, 'loss_4': 1.7489097118377686, 'epoch': 7.81}
{'loss': 0.0099, 'grad_norm': 5.421008586883545, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.007874609902501106, 'loss_2': 0.00206756591796875, 'loss_3': -16.106765747070312, 'loss_4': 1.4081209897994995, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 10:00:03,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:03,032 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:30<1:05:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:10,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015957364812493324, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.556, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012320946902036667, 'eval_loss_2': 0.0036364197731018066, 'eval_loss_3': -18.265487670898438, 'eval_loss_4': 1.1898672580718994, 'epoch': 7.82}
{'loss': 0.0596, 'grad_norm': 14.006802558898926, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.05023936554789543, 'loss_2': 0.0093536376953125, 'loss_3': -16.19061279296875, 'loss_4': 1.711465835571289, 'epoch': 7.83}
{'loss': 0.028, 'grad_norm': 8.52713680267334, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.02220229245722294, 'loss_2': 0.00580596923828125, 'loss_3': -16.113189697265625, 'loss_4': 1.7808306217193604, 'epoch': 7.83}
{'loss': 0.0267, 'grad_norm': 7.081982135772705, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.02172663062810898, 'loss_2': 0.004974365234375, 'loss_3': -15.910947799682617, 'loss_4': 1.0430494546890259, 'epoch': 7.84}
{'loss': 0.0204, 'grad_norm': 6.680599689483643, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.014842174015939236, 'loss_2': 0.005519866943359375, 'loss_3': -16.103517532348633, 'loss_4': 1.5062353610992432, 'epoch': 7.84}
{'loss': 0.0213, 'grad_norm': 8.240152359008789, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.017402833327651024, 'loss_2': 0.00385284423828125, 'loss_3': -15.961278915405273, 'loss_4': 1.67203688621521, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 10:00:10,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:10,384 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:37<1:05:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:17,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02433750405907631, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.242, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.013744208961725235, 'eval_loss_2': 0.010593295097351074, 'eval_loss_3': -18.236040115356445, 'eval_loss_4': 0.9881777763366699, 'epoch': 7.85}
{'loss': 0.125, 'grad_norm': 39.30448913574219, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.11141698807477951, 'loss_2': 0.0135345458984375, 'loss_3': -16.038076400756836, 'loss_4': 1.51193106174469, 'epoch': 7.85}
{'loss': 0.0259, 'grad_norm': 7.449594497680664, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.013367092236876488, 'loss_2': 0.01251220703125, 'loss_3': -16.067928314208984, 'loss_4': 0.9544752836227417, 'epoch': 7.86}
{'loss': 0.0078, 'grad_norm': 4.7040019035339355, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.006189863663166761, 'loss_2': 0.0016345977783203125, 'loss_3': -16.264453887939453, 'loss_4': 0.9656504392623901, 'epoch': 7.87}
{'loss': 0.0295, 'grad_norm': 6.073734760284424, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.014853146858513355, 'loss_2': 0.01468658447265625, 'loss_3': -16.22988510131836, 'loss_4': 1.7740185260772705, 'epoch': 7.87}
{'loss': 0.0191, 'grad_norm': 5.783572673797607, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.009170809760689735, 'loss_2': 0.0099639892578125, 'loss_3': -16.14725685119629, 'loss_4': 1.4739484786987305, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 10:00:17,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:17,759 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:44<1:05:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:25,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028735414147377014, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.194, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.020345939323306084, 'eval_loss_2': 0.008389472961425781, 'eval_loss_3': -18.17313575744629, 'eval_loss_4': 1.075671672821045, 'epoch': 7.88}
{'loss': 0.0202, 'grad_norm': 5.914872646331787, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.01065685972571373, 'loss_2': 0.0095367431640625, 'loss_3': -16.03266143798828, 'loss_4': 1.298120379447937, 'epoch': 7.88}
{'loss': 0.0227, 'grad_norm': 6.031552314758301, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.011510517448186874, 'loss_2': 0.01122283935546875, 'loss_3': -16.004810333251953, 'loss_4': 1.5574277639389038, 'epoch': 7.89}
{'loss': 0.0157, 'grad_norm': 5.862181186676025, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.013675203546881676, 'loss_2': 0.0019855499267578125, 'loss_3': -16.344558715820312, 'loss_4': 1.0331950187683105, 'epoch': 7.9}
{'loss': 0.0367, 'grad_norm': 13.1328706741333, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.035190481692552567, 'loss_2': 0.0014801025390625, 'loss_3': -16.064302444458008, 'loss_4': 1.958770990371704, 'epoch': 7.9}
{'loss': 0.0229, 'grad_norm': 12.24657917022705, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.020654916763305664, 'loss_2': 0.0022640228271484375, 'loss_3': -16.282958984375, 'loss_4': 2.186673879623413, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 10:00:25,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:25,109 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [33:52<1:05:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:32,455 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022872261703014374, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.019306352362036705, 'eval_loss_2': 0.0035659074783325195, 'eval_loss_3': -18.18815803527832, 'eval_loss_4': 1.4653581380844116, 'epoch': 7.91}
{'loss': 0.0248, 'grad_norm': 6.544567584991455, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.015609792433679104, 'loss_2': 0.00921630859375, 'loss_3': -16.120952606201172, 'loss_4': 1.4817476272583008, 'epoch': 7.91}
{'loss': 0.0281, 'grad_norm': 6.754517555236816, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.01843005046248436, 'loss_2': 0.00970458984375, 'loss_3': -16.259044647216797, 'loss_4': 1.7286518812179565, 'epoch': 7.92}
{'loss': 0.0167, 'grad_norm': 6.062022686004639, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.013783972710371017, 'loss_2': 0.00293731689453125, 'loss_3': -15.99809455871582, 'loss_4': 1.995974063873291, 'epoch': 7.92}
{'loss': 0.0225, 'grad_norm': 7.986301898956299, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.01733282580971718, 'loss_2': 0.005191802978515625, 'loss_3': -16.163454055786133, 'loss_4': 2.403799533843994, 'epoch': 7.93}
{'loss': 0.0188, 'grad_norm': 9.43758773803711, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.01606360264122486, 'loss_2': 0.0027637481689453125, 'loss_3': -16.119781494140625, 'loss_4': 1.9726635217666626, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 10:00:32,455 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:32,455 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [33:59<1:05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:39,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01834862306714058, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.339, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014851050451397896, 'eval_loss_2': 0.003497570753097534, 'eval_loss_3': -18.263883590698242, 'eval_loss_4': 1.7792582511901855, 'epoch': 7.94}
{'loss': 0.0216, 'grad_norm': 9.198678016662598, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.019322380423545837, 'loss_2': 0.002239227294921875, 'loss_3': -16.158552169799805, 'loss_4': 1.5925467014312744, 'epoch': 7.94}
{'loss': 0.0183, 'grad_norm': 7.856595039367676, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.01752663403749466, 'loss_2': 0.0007829666137695312, 'loss_3': -15.938623428344727, 'loss_4': 1.8967618942260742, 'epoch': 7.95}
{'loss': 0.0387, 'grad_norm': 14.617544174194336, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.03711744770407677, 'loss_2': 0.001567840576171875, 'loss_3': -16.16887855529785, 'loss_4': 2.3466339111328125, 'epoch': 7.95}
{'loss': 0.0366, 'grad_norm': 13.929449081420898, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.03227418288588524, 'loss_2': 0.004302978515625, 'loss_3': -16.023204803466797, 'loss_4': 2.5591678619384766, 'epoch': 7.96}
{'loss': 0.0654, 'grad_norm': 15.322128295898438, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.04910915344953537, 'loss_2': 0.0163116455078125, 'loss_3': -16.099491119384766, 'loss_4': 2.5051403045654297, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 10:00:39,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:39,809 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:06<1:05:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:00:47,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020537957549095154, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014729843474924564, 'eval_loss_2': 0.005808115005493164, 'eval_loss_3': -18.311809539794922, 'eval_loss_4': 2.149836301803589, 'epoch': 7.97}
{'loss': 0.0454, 'grad_norm': 19.292993545532227, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.03932623565196991, 'loss_2': 0.00605010986328125, 'loss_3': -16.31715202331543, 'loss_4': 3.0101850032806396, 'epoch': 7.97}
{'loss': 0.0184, 'grad_norm': 8.442473411560059, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.01830732636153698, 'loss_2': 4.3511390686035156e-05, 'loss_3': -16.183307647705078, 'loss_4': 2.19315242767334, 'epoch': 7.98}
{'loss': 0.0278, 'grad_norm': 14.198899269104004, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.02509395405650139, 'loss_2': 0.00269317626953125, 'loss_3': -16.306396484375, 'loss_4': 3.187386989593506, 'epoch': 7.98}
{'loss': 0.0272, 'grad_norm': 10.413361549377441, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.019195226952433586, 'loss_2': 0.008026123046875, 'loss_3': -16.179080963134766, 'loss_4': 2.3715364933013916, 'epoch': 7.99}
{'loss': 0.0194, 'grad_norm': 8.376057624816895, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.017062058672308922, 'loss_2': 0.002384185791015625, 'loss_3': -16.103103637695312, 'loss_4': 2.721092700958252, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 10:00:47,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:47,138 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:14<1:04:14,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:00:54,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01695953495800495, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.55, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011501284316182137, 'eval_loss_2': 0.005458250641822815, 'eval_loss_3': -18.313112258911133, 'eval_loss_4': 2.2267768383026123, 'epoch': 7.99}
{'loss': 0.0107, 'grad_norm': 6.328408718109131, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.007045278325676918, 'loss_2': 0.0036468505859375, 'loss_3': -16.05095672607422, 'loss_4': 1.717706322669983, 'epoch': 8.0}
{'loss': 0.0277, 'grad_norm': 5.803186893463135, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.015610696747899055, 'loss_2': 0.01213836669921875, 'loss_3': -16.227298736572266, 'loss_4': 2.8774054050445557, 'epoch': 8.01}
{'loss': 0.0283, 'grad_norm': 8.90634536743164, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.02400214597582817, 'loss_2': 0.00424957275390625, 'loss_3': -16.347496032714844, 'loss_4': 2.581726312637329, 'epoch': 8.01}
{'loss': 0.0232, 'grad_norm': 9.83441162109375, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.016962930560112, 'loss_2': 0.006275177001953125, 'loss_3': -16.363222122192383, 'loss_4': 2.1968929767608643, 'epoch': 8.02}
{'loss': 0.026, 'grad_norm': 9.43845272064209, 'learning_rate': 2.2e-05, 'loss_1': 0.021973298862576485, 'loss_2': 0.004039764404296875, 'loss_3': -16.19732666015625, 'loss_4': 2.171525239944458, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 10:00:54,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:54,214 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:21<1:05:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:01,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017465699464082718, 'eval_runtime': 3.8298, 'eval_samples_per_second': 267.378, 'eval_steps_per_second': 4.178, 'eval_loss_1': 0.009830104187130928, 'eval_loss_2': 0.007635593414306641, 'eval_loss_3': -18.309938430786133, 'eval_loss_4': 2.151073455810547, 'epoch': 8.02}
{'loss': 0.0195, 'grad_norm': 7.615289688110352, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.016028523445129395, 'loss_2': 0.003421783447265625, 'loss_3': -16.12298583984375, 'loss_4': 2.429473876953125, 'epoch': 8.03}
{'loss': 0.0224, 'grad_norm': 8.28945541381836, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.018200676888227463, 'loss_2': 0.0042266845703125, 'loss_3': -16.08418083190918, 'loss_4': 2.4960544109344482, 'epoch': 8.03}
{'loss': 0.0131, 'grad_norm': 5.467878818511963, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.011752849444746971, 'loss_2': 0.001346588134765625, 'loss_3': -16.265705108642578, 'loss_4': 2.440490484237671, 'epoch': 8.04}
{'loss': 0.0296, 'grad_norm': 8.275556564331055, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.020285682752728462, 'loss_2': 0.009307861328125, 'loss_3': -16.292654037475586, 'loss_4': 2.1152353286743164, 'epoch': 8.05}
{'loss': 0.054, 'grad_norm': 14.631753921508789, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.03408464789390564, 'loss_2': 0.0198974609375, 'loss_3': -16.200918197631836, 'loss_4': 2.2453806400299072, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 10:01:01,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:01,592 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:28<1:05:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:08,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02361840009689331, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010721861384809017, 'eval_loss_2': 0.012896537780761719, 'eval_loss_3': -18.292829513549805, 'eval_loss_4': 2.1716866493225098, 'epoch': 8.05}
{'loss': 0.0347, 'grad_norm': 8.94941234588623, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.02571326307952404, 'loss_2': 0.00897979736328125, 'loss_3': -16.23282241821289, 'loss_4': 2.797776699066162, 'epoch': 8.06}
{'loss': 0.0407, 'grad_norm': 12.74389934539795, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.026840193197131157, 'loss_2': 0.013885498046875, 'loss_3': -16.090618133544922, 'loss_4': 2.834514617919922, 'epoch': 8.06}
{'loss': 0.0248, 'grad_norm': 6.7489848136901855, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.014130893163383007, 'loss_2': 0.010711669921875, 'loss_3': -16.325693130493164, 'loss_4': 2.626960515975952, 'epoch': 8.07}
{'loss': 0.0267, 'grad_norm': 5.889233589172363, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.009936610236763954, 'loss_2': 0.016754150390625, 'loss_3': -16.080188751220703, 'loss_4': 2.464755058288574, 'epoch': 8.08}
{'loss': 0.0255, 'grad_norm': 5.108468055725098, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.012795020826160908, 'loss_2': 0.0127105712890625, 'loss_3': -16.090559005737305, 'loss_4': 2.072835922241211, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 10:01:08,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:08,937 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:36<1:05:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:16,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016041066497564316, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0107589615508914, 'eval_loss_2': 0.005282104015350342, 'eval_loss_3': -18.271373748779297, 'eval_loss_4': 1.8918312788009644, 'epoch': 8.08}
{'loss': 0.0182, 'grad_norm': 6.070296287536621, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.013447270728647709, 'loss_2': 0.00476837158203125, 'loss_3': -16.34810447692871, 'loss_4': 2.953232765197754, 'epoch': 8.09}
{'loss': 0.0382, 'grad_norm': 8.775215148925781, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.030792322009801865, 'loss_2': 0.0074462890625, 'loss_3': -16.154041290283203, 'loss_4': 1.5779571533203125, 'epoch': 8.09}
{'loss': 0.0308, 'grad_norm': 7.116729736328125, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.018348395824432373, 'loss_2': 0.012481689453125, 'loss_3': -16.289566040039062, 'loss_4': 1.9014575481414795, 'epoch': 8.1}
{'loss': 0.0223, 'grad_norm': 6.348155498504639, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.013165205717086792, 'loss_2': 0.0091400146484375, 'loss_3': -16.234201431274414, 'loss_4': 1.9179494380950928, 'epoch': 8.1}
{'loss': 0.0207, 'grad_norm': 5.563880443572998, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.010234094224870205, 'loss_2': 0.0105133056640625, 'loss_3': -16.230289459228516, 'loss_4': 2.476452350616455, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 10:01:16,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:16,283 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:43<1:05:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:23,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02129340171813965, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011929034255445004, 'eval_loss_2': 0.00936436653137207, 'eval_loss_3': -18.280296325683594, 'eval_loss_4': 1.579024314880371, 'epoch': 8.11}
{'loss': 0.037, 'grad_norm': 6.159022331237793, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.01858268864452839, 'loss_2': 0.0184326171875, 'loss_3': -16.093687057495117, 'loss_4': 1.8997825384140015, 'epoch': 8.12}
{'loss': 0.0339, 'grad_norm': 11.852707862854004, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.022594504058361053, 'loss_2': 0.01129150390625, 'loss_3': -16.05845832824707, 'loss_4': 2.0798392295837402, 'epoch': 8.12}
{'loss': 0.0306, 'grad_norm': 7.44815731048584, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.017666658386588097, 'loss_2': 0.01297760009765625, 'loss_3': -16.19776153564453, 'loss_4': 1.8241777420043945, 'epoch': 8.13}
{'loss': 0.02, 'grad_norm': 6.5825018882751465, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.012058213353157043, 'loss_2': 0.00789642333984375, 'loss_3': -16.009807586669922, 'loss_4': 1.3176636695861816, 'epoch': 8.13}
{'loss': 0.0203, 'grad_norm': 8.121452331542969, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.018779991194605827, 'loss_2': 0.0015316009521484375, 'loss_3': -16.21851921081543, 'loss_4': 1.8640110492706299, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 10:01:23,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:23,636 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [34:50<1:05:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:30,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014806048944592476, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010968762449920177, 'eval_loss_2': 0.003837287425994873, 'eval_loss_3': -18.23744010925293, 'eval_loss_4': 1.399448275566101, 'epoch': 8.14}
{'loss': 0.0116, 'grad_norm': 5.683409690856934, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.006970194634050131, 'loss_2': 0.00467681884765625, 'loss_3': -16.10246467590332, 'loss_4': 1.2892637252807617, 'epoch': 8.15}
{'loss': 0.0179, 'grad_norm': 6.4014201164245605, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.012224867939949036, 'loss_2': 0.005641937255859375, 'loss_3': -16.116840362548828, 'loss_4': 1.6678862571716309, 'epoch': 8.15}
{'loss': 0.0235, 'grad_norm': 9.153653144836426, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.020168356597423553, 'loss_2': 0.003326416015625, 'loss_3': -16.223068237304688, 'loss_4': 1.3220514059066772, 'epoch': 8.16}
{'loss': 0.015, 'grad_norm': 8.074666976928711, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.013006865978240967, 'loss_2': 0.002040863037109375, 'loss_3': -16.086299896240234, 'loss_4': 1.873267412185669, 'epoch': 8.16}
{'loss': 0.0138, 'grad_norm': 5.484518527984619, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.011734689585864544, 'loss_2': 0.002040863037109375, 'loss_3': -16.033098220825195, 'loss_4': 0.8039635419845581, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 10:01:30,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:30,993 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [34:58<1:05:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:38,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014811807312071323, 'eval_runtime': 3.8214, 'eval_samples_per_second': 267.967, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.011748923920094967, 'eval_loss_2': 0.0030628815293312073, 'eval_loss_3': -18.204687118530273, 'eval_loss_4': 1.111541986465454, 'epoch': 8.17}
{'loss': 0.0227, 'grad_norm': 7.695780277252197, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.019262338057160378, 'loss_2': 0.0034332275390625, 'loss_3': -16.053543090820312, 'loss_4': 1.6026438474655151, 'epoch': 8.17}
{'loss': 0.0232, 'grad_norm': 8.25752067565918, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.01836831122636795, 'loss_2': 0.00481414794921875, 'loss_3': -15.985441207885742, 'loss_4': 1.6460886001586914, 'epoch': 8.18}
{'loss': 0.0213, 'grad_norm': 7.431879043579102, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.01620515249669552, 'loss_2': 0.005138397216796875, 'loss_3': -16.12896728515625, 'loss_4': 0.956454873085022, 'epoch': 8.19}
{'loss': 0.0206, 'grad_norm': 6.633269786834717, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.016019046306610107, 'loss_2': 0.0045318603515625, 'loss_3': -16.241004943847656, 'loss_4': 1.2133913040161133, 'epoch': 8.19}
{'loss': 0.0306, 'grad_norm': 9.688447952270508, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.028164736926555634, 'loss_2': 0.00244903564453125, 'loss_3': -16.118005752563477, 'loss_4': 2.1531970500946045, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 10:01:38,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:38,363 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:05<1:04:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:45,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014642595313489437, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.239, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011649668216705322, 'eval_loss_2': 0.0029929280281066895, 'eval_loss_3': -18.215904235839844, 'eval_loss_4': 0.9195758104324341, 'epoch': 8.2}
{'loss': 0.0239, 'grad_norm': 6.8458733558654785, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.022853799164295197, 'loss_2': 0.00104522705078125, 'loss_3': -15.973523139953613, 'loss_4': 1.0612916946411133, 'epoch': 8.2}
{'loss': 0.0187, 'grad_norm': 7.4702301025390625, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.01500002946704626, 'loss_2': 0.003742218017578125, 'loss_3': -16.04102325439453, 'loss_4': 1.1629199981689453, 'epoch': 8.21}
{'loss': 0.0227, 'grad_norm': 6.110980033874512, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.016621297225356102, 'loss_2': 0.006046295166015625, 'loss_3': -16.081174850463867, 'loss_4': 1.3070935010910034, 'epoch': 8.22}
{'loss': 0.0119, 'grad_norm': 5.854640483856201, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.009065312333405018, 'loss_2': 0.00279998779296875, 'loss_3': -16.206390380859375, 'loss_4': 1.436104655265808, 'epoch': 8.22}
{'loss': 0.0201, 'grad_norm': 7.296750068664551, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.017419693991541862, 'loss_2': 0.0026493072509765625, 'loss_3': -16.041406631469727, 'loss_4': 1.3471097946166992, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 10:01:45,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:45,713 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:12<1:04:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:53,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01376385148614645, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.751, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010982460342347622, 'eval_loss_2': 0.002781391143798828, 'eval_loss_3': -18.22947120666504, 'eval_loss_4': 1.1808267831802368, 'epoch': 8.23}
{'loss': 0.0433, 'grad_norm': 18.501611709594727, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.039427801966667175, 'loss_2': 0.003894805908203125, 'loss_3': -16.099170684814453, 'loss_4': 1.6960878372192383, 'epoch': 8.23}
{'loss': 0.0184, 'grad_norm': 6.285800457000732, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.015442471019923687, 'loss_2': 0.0029926300048828125, 'loss_3': -16.173351287841797, 'loss_4': 1.8192788362503052, 'epoch': 8.24}
{'loss': 0.0196, 'grad_norm': 9.269744873046875, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.01894795522093773, 'loss_2': 0.0006718635559082031, 'loss_3': -16.065208435058594, 'loss_4': 1.8005480766296387, 'epoch': 8.24}
{'loss': 0.044, 'grad_norm': 16.584606170654297, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.037915416061878204, 'loss_2': 0.0061187744140625, 'loss_3': -16.11536407470703, 'loss_4': 1.2684800624847412, 'epoch': 8.25}
{'loss': 0.0212, 'grad_norm': 8.01251220703125, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.020546870306134224, 'loss_2': 0.0006098747253417969, 'loss_3': -15.940641403198242, 'loss_4': 2.0679404735565186, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 10:01:53,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:53,069 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:20<1:04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:00,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013642124831676483, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01056798454374075, 'eval_loss_2': 0.003074139356613159, 'eval_loss_3': -18.230056762695312, 'eval_loss_4': 1.399133324623108, 'epoch': 8.26}
{'loss': 0.023, 'grad_norm': 9.310088157653809, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.021381430327892303, 'loss_2': 0.00165557861328125, 'loss_3': -15.823919296264648, 'loss_4': 2.0580837726593018, 'epoch': 8.26}
{'loss': 0.0369, 'grad_norm': 18.769994735717773, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.03462205082178116, 'loss_2': 0.002315521240234375, 'loss_3': -16.040491104125977, 'loss_4': 1.5660003423690796, 'epoch': 8.27}
{'loss': 0.0194, 'grad_norm': 8.068135261535645, 'learning_rate': 2.175e-05, 'loss_1': 0.017517365515232086, 'loss_2': 0.0019073486328125, 'loss_3': -16.105424880981445, 'loss_4': 1.7713887691497803, 'epoch': 8.27}
{'loss': 0.022, 'grad_norm': 6.551727294921875, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.019302627071738243, 'loss_2': 0.0026798248291015625, 'loss_3': -16.143890380859375, 'loss_4': 1.7312850952148438, 'epoch': 8.28}
{'loss': 0.0116, 'grad_norm': 5.4334611892700195, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.0082565201446414, 'loss_2': 0.003391265869140625, 'loss_3': -16.088016510009766, 'loss_4': 1.292382836341858, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 10:02:00,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:00,424 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:27<1:04:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:07,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020835233852267265, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012185052037239075, 'eval_loss_2': 0.00865018367767334, 'eval_loss_3': -18.203556060791016, 'eval_loss_4': 1.4362070560455322, 'epoch': 8.28}
{'loss': 0.0179, 'grad_norm': 5.953307628631592, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.012739916332066059, 'loss_2': 0.005157470703125, 'loss_3': -16.060787200927734, 'loss_4': 1.1377627849578857, 'epoch': 8.29}
{'loss': 0.0202, 'grad_norm': 5.382536888122559, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.010581757873296738, 'loss_2': 0.009613037109375, 'loss_3': -16.136432647705078, 'loss_4': 1.6879932880401611, 'epoch': 8.3}
{'loss': 0.015, 'grad_norm': 4.81480073928833, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.009943858720362186, 'loss_2': 0.005069732666015625, 'loss_3': -15.940443992614746, 'loss_4': 1.8062973022460938, 'epoch': 8.3}
{'loss': 0.0396, 'grad_norm': 10.233376502990723, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.039244022220373154, 'loss_2': 0.0003170967102050781, 'loss_3': -15.61421012878418, 'loss_4': 2.735992908477783, 'epoch': 8.31}
{'loss': 0.0134, 'grad_norm': 5.357870101928711, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.007952552288770676, 'loss_2': 0.005401611328125, 'loss_3': -16.16162109375, 'loss_4': 1.927691102027893, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 10:02:07,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:07,774 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:34<1:04:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:15,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018360640853643417, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.817, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011868740431964397, 'eval_loss_2': 0.006491899490356445, 'eval_loss_3': -18.16712188720703, 'eval_loss_4': 1.3819366693496704, 'epoch': 8.31}
{'loss': 0.0232, 'grad_norm': 7.857970714569092, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.015128806233406067, 'loss_2': 0.008056640625, 'loss_3': -16.07000160217285, 'loss_4': 2.0594828128814697, 'epoch': 8.32}
{'loss': 0.03, 'grad_norm': 10.806550025939941, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.017498869448900223, 'loss_2': 0.01247406005859375, 'loss_3': -15.904362678527832, 'loss_4': 1.6806817054748535, 'epoch': 8.33}
{'loss': 0.0283, 'grad_norm': 8.644689559936523, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.020782843232154846, 'loss_2': 0.007541656494140625, 'loss_3': -15.907685279846191, 'loss_4': 1.8482286930084229, 'epoch': 8.33}
{'loss': 0.0113, 'grad_norm': 5.682976245880127, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.0083148879930377, 'loss_2': 0.002986907958984375, 'loss_3': -15.830942153930664, 'loss_4': 1.19552743434906, 'epoch': 8.34}
{'loss': 0.0232, 'grad_norm': 7.498113632202148, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.014068382792174816, 'loss_2': 0.00909423828125, 'loss_3': -16.02617835998535, 'loss_4': 1.4214558601379395, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 10:02:15,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:15,130 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:42<1:04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:22,494 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016432875767350197, 'eval_runtime': 3.8224, 'eval_samples_per_second': 267.893, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.01300542801618576, 'eval_loss_2': 0.003427445888519287, 'eval_loss_3': -18.137819290161133, 'eval_loss_4': 1.4711138010025024, 'epoch': 8.34}
{'loss': 0.0127, 'grad_norm': 5.147521495819092, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.0075547886081039906, 'loss_2': 0.00518035888671875, 'loss_3': -16.017541885375977, 'loss_4': 1.5525462627410889, 'epoch': 8.35}
{'loss': 0.009, 'grad_norm': 4.750967025756836, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.0061172861605882645, 'loss_2': 0.0029125213623046875, 'loss_3': -15.963470458984375, 'loss_4': 1.3763892650604248, 'epoch': 8.35}
{'loss': 0.0398, 'grad_norm': 13.934562683105469, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.0369417667388916, 'loss_2': 0.0028362274169921875, 'loss_3': -15.613714218139648, 'loss_4': 1.8953603506088257, 'epoch': 8.36}
{'loss': 0.027, 'grad_norm': 7.771489143371582, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.023001987487077713, 'loss_2': 0.004009246826171875, 'loss_3': -15.987818717956543, 'loss_4': 2.361786365509033, 'epoch': 8.37}
{'loss': 0.0541, 'grad_norm': 17.253725051879883, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.047889694571495056, 'loss_2': 0.00617218017578125, 'loss_3': -15.703298568725586, 'loss_4': 1.6298004388809204, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 10:02:22,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:22,495 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [35:49<1:04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:29,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01568944938480854, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01197388768196106, 'eval_loss_2': 0.0037155598402023315, 'eval_loss_3': -18.15804100036621, 'eval_loss_4': 1.6177988052368164, 'epoch': 8.37}
{'loss': 0.0272, 'grad_norm': 14.992871284484863, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.023387908935546875, 'loss_2': 0.003841400146484375, 'loss_3': -15.996068954467773, 'loss_4': 1.4675761461257935, 'epoch': 8.38}
{'loss': 0.015, 'grad_norm': 7.218044757843018, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.010325524024665356, 'loss_2': 0.0047149658203125, 'loss_3': -15.894819259643555, 'loss_4': 2.053157329559326, 'epoch': 8.38}
{'loss': 0.0111, 'grad_norm': 5.077691078186035, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.006280530244112015, 'loss_2': 0.00485992431640625, 'loss_3': -16.20998764038086, 'loss_4': 2.293180465698242, 'epoch': 8.39}
{'loss': 0.0221, 'grad_norm': 7.190528869628906, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.01991984061896801, 'loss_2': 0.002140045166015625, 'loss_3': -16.067197799682617, 'loss_4': 1.7005105018615723, 'epoch': 8.4}
{'loss': 0.02, 'grad_norm': 10.876893997192383, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.01665031537413597, 'loss_2': 0.003391265869140625, 'loss_3': -15.837844848632812, 'loss_4': 1.9907758235931396, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 10:02:29,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:29,836 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [35:56<1:04:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:37,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018025200814008713, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.564, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013114774599671364, 'eval_loss_2': 0.0049104243516922, 'eval_loss_3': -18.17795181274414, 'eval_loss_4': 1.9232243299484253, 'epoch': 8.4}
{'loss': 0.02, 'grad_norm': 6.789283752441406, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.01601453498005867, 'loss_2': 0.0039825439453125, 'loss_3': -15.891782760620117, 'loss_4': 2.4343788623809814, 'epoch': 8.41}
{'loss': 0.0667, 'grad_norm': 25.356555938720703, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.06372497230768204, 'loss_2': 0.0029735565185546875, 'loss_3': -15.929598808288574, 'loss_4': 1.9777194261550903, 'epoch': 8.41}
{'loss': 0.0156, 'grad_norm': 7.239837169647217, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.012658991850912571, 'loss_2': 0.002986907958984375, 'loss_3': -15.971784591674805, 'loss_4': 2.327984571456909, 'epoch': 8.42}
{'loss': 0.0259, 'grad_norm': 8.318280220031738, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.02234422042965889, 'loss_2': 0.0035858154296875, 'loss_3': -15.96539306640625, 'loss_4': 1.969156265258789, 'epoch': 8.42}
{'loss': 0.0082, 'grad_norm': 4.90807580947876, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.006250081583857536, 'loss_2': 0.0019702911376953125, 'loss_3': -16.024776458740234, 'loss_4': 1.721897840499878, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 10:02:37,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:37,179 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:04<1:04:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:44,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018969401717185974, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014698969200253487, 'eval_loss_2': 0.004270434379577637, 'eval_loss_3': -18.180553436279297, 'eval_loss_4': 2.011551856994629, 'epoch': 8.43}
{'loss': 0.0169, 'grad_norm': 5.57391357421875, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.008880294859409332, 'loss_2': 0.00801849365234375, 'loss_3': -16.221649169921875, 'loss_4': 2.0300705432891846, 'epoch': 8.44}
{'loss': 0.0312, 'grad_norm': 10.418153762817383, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.023942919448018074, 'loss_2': 0.00722503662109375, 'loss_3': -15.987750053405762, 'loss_4': 2.479346752166748, 'epoch': 8.44}
{'loss': 0.0232, 'grad_norm': 7.157436847686768, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.015779554843902588, 'loss_2': 0.007373809814453125, 'loss_3': -16.02126693725586, 'loss_4': 2.1809165477752686, 'epoch': 8.45}
{'loss': 0.0219, 'grad_norm': 7.281467914581299, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.019483759999275208, 'loss_2': 0.0024566650390625, 'loss_3': -16.03693199157715, 'loss_4': 2.3542885780334473, 'epoch': 8.45}
{'loss': 0.0138, 'grad_norm': 6.0972418785095215, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.010525371879339218, 'loss_2': 0.0032596588134765625, 'loss_3': -16.307392120361328, 'loss_4': 2.328704595565796, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 10:02:44,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:44,524 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:11<1:04:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:51,883 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0154043547809124, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011241684667766094, 'eval_loss_2': 0.0041626691818237305, 'eval_loss_3': -18.207059860229492, 'eval_loss_4': 1.9556078910827637, 'epoch': 8.46}
{'loss': 0.0341, 'grad_norm': 12.725882530212402, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.03110550343990326, 'loss_2': 0.0029754638671875, 'loss_3': -16.01987075805664, 'loss_4': 2.3976221084594727, 'epoch': 8.47}
{'loss': 0.0103, 'grad_norm': 6.037285327911377, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.007404160685837269, 'loss_2': 0.00290679931640625, 'loss_3': -15.946096420288086, 'loss_4': 1.8080066442489624, 'epoch': 8.47}
{'loss': 0.0092, 'grad_norm': 5.269118309020996, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.009101885370910168, 'loss_2': 8.875131607055664e-05, 'loss_3': -16.218643188476562, 'loss_4': 2.0529863834381104, 'epoch': 8.48}
{'loss': 0.0153, 'grad_norm': 5.562286853790283, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.009219355881214142, 'loss_2': 0.00605010986328125, 'loss_3': -16.13858413696289, 'loss_4': 2.484802722930908, 'epoch': 8.48}
{'loss': 0.0216, 'grad_norm': 10.527974128723145, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.02085196226835251, 'loss_2': 0.0007147789001464844, 'loss_3': -15.997063636779785, 'loss_4': 1.9580464363098145, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 10:02:51,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:51,883 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:19<1:03:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:59,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013749653473496437, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.539, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.00950117688626051, 'eval_loss_2': 0.004248477518558502, 'eval_loss_3': -18.2419490814209, 'eval_loss_4': 1.596946358680725, 'epoch': 8.49}
{'loss': 0.0141, 'grad_norm': 6.80694055557251, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.013900399208068848, 'loss_2': 0.0001838207244873047, 'loss_3': -16.113903045654297, 'loss_4': 2.2026312351226807, 'epoch': 8.49}
{'loss': 0.0243, 'grad_norm': 9.369194984436035, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.022410143166780472, 'loss_2': 0.0018939971923828125, 'loss_3': -16.132389068603516, 'loss_4': 1.5974482297897339, 'epoch': 8.5}
{'loss': 0.0105, 'grad_norm': 6.025129318237305, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.010296374559402466, 'loss_2': 0.000179290771484375, 'loss_3': -16.112655639648438, 'loss_4': 1.3061387538909912, 'epoch': 8.51}
{'loss': 0.0364, 'grad_norm': 11.4307861328125, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.02589872106909752, 'loss_2': 0.0105438232421875, 'loss_3': -16.02471160888672, 'loss_4': 2.0731053352355957, 'epoch': 8.51}
{'loss': 0.0241, 'grad_norm': 8.69412612915039, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.023533035069704056, 'loss_2': 0.0005540847778320312, 'loss_3': -16.201473236083984, 'loss_4': 2.0464236736297607, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 10:02:59,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:59,239 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:26<1:03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:06,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014419571496546268, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010725096799433231, 'eval_loss_2': 0.003694474697113037, 'eval_loss_3': -18.222858428955078, 'eval_loss_4': 1.4114749431610107, 'epoch': 8.52}
{'loss': 0.0159, 'grad_norm': 6.127923011779785, 'learning_rate': 2.15e-05, 'loss_1': 0.013702664524316788, 'loss_2': 0.00222015380859375, 'loss_3': -16.182273864746094, 'loss_4': 2.0232017040252686, 'epoch': 8.52}
{'loss': 0.0175, 'grad_norm': 7.208639621734619, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.016054024919867516, 'loss_2': 0.0014801025390625, 'loss_3': -16.088863372802734, 'loss_4': 1.5906734466552734, 'epoch': 8.53}
{'loss': 0.0142, 'grad_norm': 7.721937656402588, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.012806471437215805, 'loss_2': 0.0013828277587890625, 'loss_3': -16.227537155151367, 'loss_4': 1.5478250980377197, 'epoch': 8.53}
{'loss': 0.0259, 'grad_norm': 6.695586204528809, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.016285711899399757, 'loss_2': 0.00957489013671875, 'loss_3': -16.148500442504883, 'loss_4': 1.2974536418914795, 'epoch': 8.54}
{'loss': 0.0215, 'grad_norm': 5.451012134552002, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.012161707505583763, 'loss_2': 0.0093841552734375, 'loss_3': -16.309131622314453, 'loss_4': 1.111070990562439, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 10:03:06,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:06,580 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:33<1:03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:13,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014202723279595375, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010563233867287636, 'eval_loss_2': 0.0036394894123077393, 'eval_loss_3': -18.219425201416016, 'eval_loss_4': 1.185001015663147, 'epoch': 8.55}
{'loss': 0.0227, 'grad_norm': 5.598196029663086, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.01190712209790945, 'loss_2': 0.01078033447265625, 'loss_3': -16.181217193603516, 'loss_4': 1.3372955322265625, 'epoch': 8.55}
{'loss': 0.0544, 'grad_norm': 21.092817306518555, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.0477868989109993, 'loss_2': 0.00664520263671875, 'loss_3': -16.132762908935547, 'loss_4': 1.3807766437530518, 'epoch': 8.56}
{'loss': 0.0377, 'grad_norm': 13.876310348510742, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.03326183557510376, 'loss_2': 0.00440216064453125, 'loss_3': -16.182212829589844, 'loss_4': 1.2828062772750854, 'epoch': 8.56}
{'loss': 0.017, 'grad_norm': 7.560268402099609, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.015014070086181164, 'loss_2': 0.002017974853515625, 'loss_3': -16.19417953491211, 'loss_4': 0.7436189651489258, 'epoch': 8.57}
{'loss': 0.0514, 'grad_norm': 20.60369110107422, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.04583688825368881, 'loss_2': 0.0055999755859375, 'loss_3': -16.10140609741211, 'loss_4': 1.9905498027801514, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 10:03:13,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:13,917 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:41<1:03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:21,256 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01815926842391491, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.79, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01218965370208025, 'eval_loss_2': 0.005969613790512085, 'eval_loss_3': -18.215496063232422, 'eval_loss_4': 1.1853286027908325, 'epoch': 8.58}
{'loss': 0.0208, 'grad_norm': 7.639475345611572, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.015654338523745537, 'loss_2': 0.005107879638671875, 'loss_3': -16.264366149902344, 'loss_4': 1.5444819927215576, 'epoch': 8.58}
{'loss': 0.021, 'grad_norm': 6.888912677764893, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.017166482284665108, 'loss_2': 0.003841400146484375, 'loss_3': -16.140884399414062, 'loss_4': 1.2512571811676025, 'epoch': 8.59}
{'loss': 0.0176, 'grad_norm': 5.529313564300537, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.015498078428208828, 'loss_2': 0.0021305084228515625, 'loss_3': -16.23690414428711, 'loss_4': 0.9011407494544983, 'epoch': 8.59}
{'loss': 0.0309, 'grad_norm': 15.311186790466309, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.029349587857723236, 'loss_2': 0.0015468597412109375, 'loss_3': -16.43219757080078, 'loss_4': 1.7246615886688232, 'epoch': 8.6}
{'loss': 0.0139, 'grad_norm': 5.7481303215026855, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.012453350238502026, 'loss_2': 0.001415252685546875, 'loss_3': -16.145275115966797, 'loss_4': 1.1979604959487915, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 10:03:21,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:21,256 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [36:48<1:03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:28,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014515151269733906, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.469, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010582921095192432, 'eval_loss_2': 0.003932230174541473, 'eval_loss_3': -18.24850082397461, 'eval_loss_4': 1.32394540309906, 'epoch': 8.6}
{'loss': 0.0189, 'grad_norm': 7.5772929191589355, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.017461789771914482, 'loss_2': 0.0014286041259765625, 'loss_3': -16.278430938720703, 'loss_4': 1.2670015096664429, 'epoch': 8.61}
{'loss': 0.0165, 'grad_norm': 5.233066082000732, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.009278806857764721, 'loss_2': 0.007205963134765625, 'loss_3': -16.185354232788086, 'loss_4': 1.3909507989883423, 'epoch': 8.62}
{'loss': 0.0259, 'grad_norm': 6.699232578277588, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.0206373892724514, 'loss_2': 0.0052490234375, 'loss_3': -15.845670700073242, 'loss_4': 1.4862744808197021, 'epoch': 8.62}
{'loss': 0.0172, 'grad_norm': 6.150595188140869, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.014478931203484535, 'loss_2': 0.002727508544921875, 'loss_3': -16.148534774780273, 'loss_4': 1.2987920045852661, 'epoch': 8.63}
{'loss': 0.0134, 'grad_norm': 5.3988938331604, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.013012783601880074, 'loss_2': 0.000354766845703125, 'loss_3': -16.23072052001953, 'loss_4': 1.6355897188186646, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 10:03:28,598 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:28,598 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [36:55<1:03:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:35,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015535788610577583, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.51, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011229399591684341, 'eval_loss_2': 0.004306387156248093, 'eval_loss_3': -18.26341438293457, 'eval_loss_4': 1.2686469554901123, 'epoch': 8.63}
{'loss': 0.0232, 'grad_norm': 7.674769401550293, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.018446842208504677, 'loss_2': 0.00479888916015625, 'loss_3': -16.560909271240234, 'loss_4': 1.8097500801086426, 'epoch': 8.64}
{'loss': 0.0234, 'grad_norm': 5.730189323425293, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.016537457704544067, 'loss_2': 0.00688934326171875, 'loss_3': -16.090097427368164, 'loss_4': 1.3264729976654053, 'epoch': 8.65}
{'loss': 0.0241, 'grad_norm': 8.812393188476562, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.018067024648189545, 'loss_2': 0.00598907470703125, 'loss_3': -16.3210391998291, 'loss_4': 1.3819093704223633, 'epoch': 8.65}
{'loss': 0.0383, 'grad_norm': 14.939590454101562, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.02888629026710987, 'loss_2': 0.00942230224609375, 'loss_3': -16.345260620117188, 'loss_4': 1.5171120166778564, 'epoch': 8.66}
{'loss': 0.0325, 'grad_norm': 11.04886531829834, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.028496243059635162, 'loss_2': 0.004032135009765625, 'loss_3': -16.174577713012695, 'loss_4': 1.8991565704345703, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 10:03:35,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:35,964 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:03<1:03:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:43,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015789790078997612, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012219471856951714, 'eval_loss_2': 0.0035703182220458984, 'eval_loss_3': -18.23097038269043, 'eval_loss_4': 1.0789592266082764, 'epoch': 8.66}
{'loss': 0.0181, 'grad_norm': 13.020750999450684, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.0177016519010067, 'loss_2': 0.0004093647003173828, 'loss_3': -16.393108367919922, 'loss_4': 1.28675377368927, 'epoch': 8.67}
{'loss': 0.0139, 'grad_norm': 5.0068230628967285, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.009941214695572853, 'loss_2': 0.0039825439453125, 'loss_3': -16.317401885986328, 'loss_4': 0.9189856052398682, 'epoch': 8.67}
{'loss': 0.0196, 'grad_norm': 7.809137344360352, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.018507715314626694, 'loss_2': 0.0011157989501953125, 'loss_3': -16.227611541748047, 'loss_4': 1.1538543701171875, 'epoch': 8.68}
{'loss': 0.0468, 'grad_norm': 11.701952934265137, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.037723440676927567, 'loss_2': 0.009033203125, 'loss_3': -16.271480560302734, 'loss_4': 0.9632933139801025, 'epoch': 8.69}
{'loss': 0.0179, 'grad_norm': 12.432291030883789, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.015244788490235806, 'loss_2': 0.0026702880859375, 'loss_3': -16.198074340820312, 'loss_4': 1.629295825958252, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 10:03:43,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:43,311 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:10<1:03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:50,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017093908041715622, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.723, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011978459544479847, 'eval_loss_2': 0.00511544942855835, 'eval_loss_3': -18.21082305908203, 'eval_loss_4': 1.1459579467773438, 'epoch': 8.69}
{'loss': 0.0179, 'grad_norm': 5.869038105010986, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.011721362359821796, 'loss_2': 0.00614166259765625, 'loss_3': -15.951684951782227, 'loss_4': 1.5596656799316406, 'epoch': 8.7}
{'loss': 0.0515, 'grad_norm': 17.957138061523438, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.043538570404052734, 'loss_2': 0.0079498291015625, 'loss_3': -16.263822555541992, 'loss_4': 0.837857723236084, 'epoch': 8.7}
{'loss': 0.0214, 'grad_norm': 7.70742130279541, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.017752693966031075, 'loss_2': 0.0036773681640625, 'loss_3': -16.212535858154297, 'loss_4': 1.5782461166381836, 'epoch': 8.71}
{'loss': 0.0214, 'grad_norm': 10.859325408935547, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.02008042111992836, 'loss_2': 0.0012969970703125, 'loss_3': -16.299827575683594, 'loss_4': 1.2072858810424805, 'epoch': 8.72}
{'loss': 0.0363, 'grad_norm': 13.175180435180664, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.032711613923311234, 'loss_2': 0.003570556640625, 'loss_3': -16.33959197998047, 'loss_4': 0.9351439476013184, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 10:03:50,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:50,653 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:17<1:03:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:57,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014477401971817017, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.656, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010314010083675385, 'eval_loss_2': 0.004163391888141632, 'eval_loss_3': -18.270309448242188, 'eval_loss_4': 1.1267175674438477, 'epoch': 8.72}
{'loss': 0.0218, 'grad_norm': 6.2480058670043945, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.019605210050940514, 'loss_2': 0.002197265625, 'loss_3': -16.270044326782227, 'loss_4': 1.6281311511993408, 'epoch': 8.73}
{'loss': 0.0127, 'grad_norm': 5.462275505065918, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.011511956341564655, 'loss_2': 0.0012111663818359375, 'loss_3': -16.178009033203125, 'loss_4': 1.6401582956314087, 'epoch': 8.73}
{'loss': 0.0183, 'grad_norm': 7.134121894836426, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.01772678643465042, 'loss_2': 0.0005869865417480469, 'loss_3': -16.216472625732422, 'loss_4': 0.9772793054580688, 'epoch': 8.74}
{'loss': 0.014, 'grad_norm': 5.756789684295654, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.01212025061249733, 'loss_2': 0.0018930435180664062, 'loss_3': -16.153316497802734, 'loss_4': 1.4290858507156372, 'epoch': 8.74}
{'loss': 0.021, 'grad_norm': 7.428542137145996, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.019574454054236412, 'loss_2': 0.001422882080078125, 'loss_3': -16.25670051574707, 'loss_4': 1.2590277194976807, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 10:03:57,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:57,991 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:25<1:03:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:05,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014091040939092636, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010665740817785263, 'eval_loss_2': 0.003425300121307373, 'eval_loss_3': -18.317611694335938, 'eval_loss_4': 1.073834776878357, 'epoch': 8.75}
{'loss': 0.0271, 'grad_norm': 9.954269409179688, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.019792933017015457, 'loss_2': 0.00734710693359375, 'loss_3': -16.219106674194336, 'loss_4': 1.777129054069519, 'epoch': 8.76}
{'loss': 0.0332, 'grad_norm': 8.713692665100098, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.026569725945591927, 'loss_2': 0.00664520263671875, 'loss_3': -16.210153579711914, 'loss_4': 1.7304185628890991, 'epoch': 8.76}
{'loss': 0.0176, 'grad_norm': 5.746703624725342, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.011658457107841969, 'loss_2': 0.00592041015625, 'loss_3': -16.148300170898438, 'loss_4': 1.756148099899292, 'epoch': 8.77}
{'loss': 0.0188, 'grad_norm': 7.265566349029541, 'learning_rate': 2.125e-05, 'loss_1': 0.018700668588280678, 'loss_2': 8.70823860168457e-05, 'loss_3': -16.285560607910156, 'loss_4': 1.1566674709320068, 'epoch': 8.77}
{'loss': 0.0264, 'grad_norm': 9.250176429748535, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.022021545097231865, 'loss_2': 0.004383087158203125, 'loss_3': -16.33324432373047, 'loss_4': 1.1023776531219482, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 10:04:05,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:05,340 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:32<1:03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:12,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014567496255040169, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.557, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011452007107436657, 'eval_loss_2': 0.0031154900789260864, 'eval_loss_3': -18.29637908935547, 'eval_loss_4': 0.9227856993675232, 'epoch': 8.78}
{'loss': 0.0174, 'grad_norm': 6.012866020202637, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.013225533999502659, 'loss_2': 0.00421142578125, 'loss_3': -16.453262329101562, 'loss_4': 0.9204257726669312, 'epoch': 8.78}
{'loss': 0.029, 'grad_norm': 10.175337791442871, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.02599307894706726, 'loss_2': 0.00299072265625, 'loss_3': -16.263723373413086, 'loss_4': 0.9728750586509705, 'epoch': 8.79}
{'loss': 0.0277, 'grad_norm': 6.577174663543701, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.0184031892567873, 'loss_2': 0.00927734375, 'loss_3': -16.270931243896484, 'loss_4': 1.4377152919769287, 'epoch': 8.8}
{'loss': 0.021, 'grad_norm': 6.014703750610352, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.017647599801421165, 'loss_2': 0.003383636474609375, 'loss_3': -16.188167572021484, 'loss_4': 0.9152514934539795, 'epoch': 8.8}
{'loss': 0.0339, 'grad_norm': 9.91515827178955, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.029962297528982162, 'loss_2': 0.003971099853515625, 'loss_3': -16.14446449279785, 'loss_4': 0.9317877292633057, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 10:04:12,683 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:12,683 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:39<1:03:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:20,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013782097026705742, 'eval_runtime': 3.8231, 'eval_samples_per_second': 267.846, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.010866597294807434, 'eval_loss_2': 0.002915501594543457, 'eval_loss_3': -18.288047790527344, 'eval_loss_4': 0.7102530002593994, 'epoch': 8.81}
{'loss': 0.0168, 'grad_norm': 7.026658535003662, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.016575012356042862, 'loss_2': 0.00025177001953125, 'loss_3': -16.285823822021484, 'loss_4': 0.9092682600021362, 'epoch': 8.81}
{'loss': 0.0153, 'grad_norm': 6.166922569274902, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.013512256555259228, 'loss_2': 0.0017795562744140625, 'loss_3': -16.105175018310547, 'loss_4': 0.8486216068267822, 'epoch': 8.82}
{'loss': 0.0238, 'grad_norm': 7.655300617218018, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.020745083689689636, 'loss_2': 0.00304412841796875, 'loss_3': -16.247522354125977, 'loss_4': 0.8521381616592407, 'epoch': 8.83}
{'loss': 0.0219, 'grad_norm': 10.13875675201416, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.01730388216674328, 'loss_2': 0.00463104248046875, 'loss_3': -16.1706485748291, 'loss_4': 0.43301859498023987, 'epoch': 8.83}
{'loss': 0.0318, 'grad_norm': 16.228004455566406, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.030491052195429802, 'loss_2': 0.0013322830200195312, 'loss_3': -16.16634750366211, 'loss_4': 1.0485596656799316, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 10:04:20,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:20,059 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [37:47<1:02:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:27,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014419153332710266, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.357, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010575056076049805, 'eval_loss_2': 0.0038440972566604614, 'eval_loss_3': -18.21373176574707, 'eval_loss_4': 0.6590653657913208, 'epoch': 8.84}
{'loss': 0.0168, 'grad_norm': 6.586829662322998, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.0123383654281497, 'loss_2': 0.004436492919921875, 'loss_3': -16.167924880981445, 'loss_4': 1.0699563026428223, 'epoch': 8.84}
{'loss': 0.0184, 'grad_norm': 6.759097099304199, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.01691422238945961, 'loss_2': 0.0014972686767578125, 'loss_3': -16.252525329589844, 'loss_4': 0.8109424114227295, 'epoch': 8.85}
{'loss': 0.031, 'grad_norm': 15.646730422973633, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.030994929373264313, 'loss_2': 5.137920379638672e-05, 'loss_3': -16.36266326904297, 'loss_4': 0.9803845882415771, 'epoch': 8.85}
{'loss': 0.0231, 'grad_norm': 7.994587421417236, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.021585913375020027, 'loss_2': 0.0015630722045898438, 'loss_3': -16.234912872314453, 'loss_4': 1.5852620601654053, 'epoch': 8.86}
{'loss': 0.0304, 'grad_norm': 10.496086120605469, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.029658179730176926, 'loss_2': 0.000751495361328125, 'loss_3': -16.235107421875, 'loss_4': 1.4788836240768433, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 10:04:27,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:27,400 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [37:54<1:02:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:34,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01561400294303894, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.697, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012007126584649086, 'eval_loss_2': 0.003606874495744705, 'eval_loss_3': -18.229022979736328, 'eval_loss_4': 0.6015406250953674, 'epoch': 8.87}
{'loss': 0.0213, 'grad_norm': 5.435988903045654, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.010730546899139881, 'loss_2': 0.0106048583984375, 'loss_3': -16.182039260864258, 'loss_4': 1.0325870513916016, 'epoch': 8.87}
{'loss': 0.0204, 'grad_norm': 6.4299821853637695, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.013162078335881233, 'loss_2': 0.0072784423828125, 'loss_3': -16.260406494140625, 'loss_4': 1.1737414598464966, 'epoch': 8.88}
{'loss': 0.0324, 'grad_norm': 9.334734916687012, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.030348410829901695, 'loss_2': 0.002017974853515625, 'loss_3': -16.342809677124023, 'loss_4': 0.8528625965118408, 'epoch': 8.88}
{'loss': 0.0267, 'grad_norm': 9.943942070007324, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.025821518152952194, 'loss_2': 0.0008392333984375, 'loss_3': -16.04997444152832, 'loss_4': 1.0726280212402344, 'epoch': 8.89}
{'loss': 0.0096, 'grad_norm': 5.304146766662598, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.005962328519672155, 'loss_2': 0.003658294677734375, 'loss_3': -16.2496280670166, 'loss_4': 0.4410145878791809, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 10:04:34,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:34,744 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:01<1:02:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:42,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017720039933919907, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.807, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014142419211566448, 'eval_loss_2': 0.003577619791030884, 'eval_loss_3': -18.288345336914062, 'eval_loss_4': 0.41498738527297974, 'epoch': 8.9}
{'loss': 0.035, 'grad_norm': 11.961527824401855, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.033177804201841354, 'loss_2': 0.0017786026000976562, 'loss_3': -16.25614356994629, 'loss_4': 0.6553203463554382, 'epoch': 8.9}
{'loss': 0.0167, 'grad_norm': 6.562891006469727, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.014594016596674919, 'loss_2': 0.002086639404296875, 'loss_3': -16.402008056640625, 'loss_4': 0.7814387083053589, 'epoch': 8.91}
{'loss': 0.0306, 'grad_norm': 13.243837356567383, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.029751606285572052, 'loss_2': 0.0008392333984375, 'loss_3': -16.421781539916992, 'loss_4': 0.4407908320426941, 'epoch': 8.91}
{'loss': 0.0253, 'grad_norm': 8.7153902053833, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.02295832522213459, 'loss_2': 0.002349853515625, 'loss_3': -16.23577880859375, 'loss_4': 0.9964014291763306, 'epoch': 8.92}
{'loss': 0.0291, 'grad_norm': 8.305319786071777, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.026466665789484978, 'loss_2': 0.0025959014892578125, 'loss_3': -16.396129608154297, 'loss_4': 0.7773324847221375, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 10:04:42,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:42,072 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:09<1:02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:49,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017534852027893066, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014354988001286983, 'eval_loss_2': 0.0031798630952835083, 'eval_loss_3': -18.291893005371094, 'eval_loss_4': 0.35044562816619873, 'epoch': 8.92}
{'loss': 0.0182, 'grad_norm': 5.309215545654297, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.014145614579319954, 'loss_2': 0.004039764404296875, 'loss_3': -16.303333282470703, 'loss_4': 0.42055463790893555, 'epoch': 8.93}
{'loss': 0.0231, 'grad_norm': 8.601985931396484, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.021396003663539886, 'loss_2': 0.0017528533935546875, 'loss_3': -16.268985748291016, 'loss_4': 0.8420575857162476, 'epoch': 8.94}
{'loss': 0.0285, 'grad_norm': 9.196330070495605, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.025554481893777847, 'loss_2': 0.002994537353515625, 'loss_3': -16.24214744567871, 'loss_4': 0.2538522183895111, 'epoch': 8.94}
{'loss': 0.0294, 'grad_norm': 6.916343688964844, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.0184719767421484, 'loss_2': 0.0109100341796875, 'loss_3': -16.121984481811523, 'loss_4': 0.25871241092681885, 'epoch': 8.95}
{'loss': 0.023, 'grad_norm': 6.06168270111084, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.018525484949350357, 'loss_2': 0.00444793701171875, 'loss_3': -16.178394317626953, 'loss_4': 0.5667762756347656, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 10:04:49,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:49,410 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:16<1:02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:56,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017036547884345055, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.878, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013099960051476955, 'eval_loss_2': 0.003936588764190674, 'eval_loss_3': -18.291393280029297, 'eval_loss_4': 0.42572784423828125, 'epoch': 8.95}
{'loss': 0.0125, 'grad_norm': 6.489740371704102, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.012433810159564018, 'loss_2': 4.45246696472168e-05, 'loss_3': -16.210308074951172, 'loss_4': 0.9952179193496704, 'epoch': 8.96}
{'loss': 0.0899, 'grad_norm': 22.5821590423584, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.08412839472293854, 'loss_2': 0.00582122802734375, 'loss_3': -16.23851776123047, 'loss_4': 0.4125826358795166, 'epoch': 8.97}
{'loss': 0.0271, 'grad_norm': 8.821002960205078, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.02500523440539837, 'loss_2': 0.00213623046875, 'loss_3': -16.372682571411133, 'loss_4': 0.6528291702270508, 'epoch': 8.97}
{'loss': 0.0208, 'grad_norm': 8.986810684204102, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.018596068024635315, 'loss_2': 0.002166748046875, 'loss_3': -16.28636932373047, 'loss_4': 0.3849983215332031, 'epoch': 8.98}
{'loss': 0.0282, 'grad_norm': 6.889253616333008, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.022784989327192307, 'loss_2': 0.005420684814453125, 'loss_3': -16.250194549560547, 'loss_4': 0.7130228877067566, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 10:04:56,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:56,759 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:23<59:52,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:05:03,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01685287617146969, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.226, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.012777229771018028, 'eval_loss_2': 0.00407564640045166, 'eval_loss_3': -18.29020118713379, 'eval_loss_4': 0.5196214318275452, 'epoch': 8.98}
{'loss': 0.0318, 'grad_norm': 12.759832382202148, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.030148008838295937, 'loss_2': 0.0016918182373046875, 'loss_3': -16.23825454711914, 'loss_4': 0.4898066818714142, 'epoch': 8.99}
{'loss': 0.0195, 'grad_norm': 6.1573333740234375, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.015804994851350784, 'loss_2': 0.003704071044921875, 'loss_3': -16.165977478027344, 'loss_4': 1.0265403985977173, 'epoch': 8.99}
{'loss': 0.0291, 'grad_norm': 19.34219741821289, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.016346430405974388, 'loss_2': 0.0127716064453125, 'loss_3': -16.083290100097656, 'loss_4': 0.36867353320121765, 'epoch': 9.0}
{'loss': 0.0232, 'grad_norm': 11.864005088806152, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.022793959826231003, 'loss_2': 0.0004372596740722656, 'loss_3': -16.34527587890625, 'loss_4': 0.6728629469871521, 'epoch': 9.01}
{'loss': 0.0165, 'grad_norm': 7.256126880645752, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.016317855566740036, 'loss_2': 0.00019061565399169922, 'loss_3': -16.264232635498047, 'loss_4': 0.7863194942474365, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 10:05:03,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:03,803 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:30<1:01:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:05:11,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015593774616718292, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.571, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011642400175333023, 'eval_loss_2': 0.003951370716094971, 'eval_loss_3': -18.237194061279297, 'eval_loss_4': 0.779727041721344, 'epoch': 9.01}
{'loss': 0.0432, 'grad_norm': 13.800065040588379, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.04238704591989517, 'loss_2': 0.0008077621459960938, 'loss_3': -16.13609504699707, 'loss_4': 0.7261689305305481, 'epoch': 9.02}
{'loss': 0.0215, 'grad_norm': 5.825509071350098, 'learning_rate': 2.1e-05, 'loss_1': 0.014583948068320751, 'loss_2': 0.006908416748046875, 'loss_3': -16.109233856201172, 'loss_4': 0.13707083463668823, 'epoch': 9.02}
{'loss': 0.0163, 'grad_norm': 5.781091213226318, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.007165913935750723, 'loss_2': 0.0091705322265625, 'loss_3': -16.389511108398438, 'loss_4': 0.8361093997955322, 'epoch': 9.03}
{'loss': 0.0302, 'grad_norm': 8.039844512939453, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.024855520576238632, 'loss_2': 0.00533294677734375, 'loss_3': -16.317012786865234, 'loss_4': 1.2078708410263062, 'epoch': 9.03}
{'loss': 0.0157, 'grad_norm': 6.32996940612793, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.014734087511897087, 'loss_2': 0.0010023117065429688, 'loss_3': -16.04871368408203, 'loss_4': 1.3461456298828125, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 10:05:11,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:11,148 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:38<1:02:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:18,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012909621000289917, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009683315642178059, 'eval_loss_2': 0.003226306289434433, 'eval_loss_3': -18.219343185424805, 'eval_loss_4': 0.8483090400695801, 'epoch': 9.04}
{'loss': 0.0179, 'grad_norm': 8.316293716430664, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.01719130575656891, 'loss_2': 0.0007228851318359375, 'loss_3': -16.31136703491211, 'loss_4': 1.0222406387329102, 'epoch': 9.05}
{'loss': 0.0223, 'grad_norm': 7.267001628875732, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.020160334184765816, 'loss_2': 0.0021114349365234375, 'loss_3': -16.317903518676758, 'loss_4': 1.0634328126907349, 'epoch': 9.05}
{'loss': 0.015, 'grad_norm': 5.8373026847839355, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.009829125367105007, 'loss_2': 0.005207061767578125, 'loss_3': -16.34065055847168, 'loss_4': 1.088172197341919, 'epoch': 9.06}
{'loss': 0.025, 'grad_norm': 6.831097602844238, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.013117693364620209, 'loss_2': 0.01186370849609375, 'loss_3': -16.16119956970215, 'loss_4': 1.4351701736450195, 'epoch': 9.06}
{'loss': 0.0459, 'grad_norm': 10.642848014831543, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.03743688389658928, 'loss_2': 0.008453369140625, 'loss_3': -16.363006591796875, 'loss_4': 1.4369243383407593, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 10:05:18,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:18,492 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [38:45<1:02:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:25,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018263693898916245, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.966, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010503767989575863, 'eval_loss_2': 0.0077599287033081055, 'eval_loss_3': -18.207660675048828, 'eval_loss_4': 1.0560389757156372, 'epoch': 9.07}
{'loss': 0.0363, 'grad_norm': 10.669588088989258, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.023818330839276314, 'loss_2': 0.01250457763671875, 'loss_3': -16.152320861816406, 'loss_4': 1.5450993776321411, 'epoch': 9.08}
{'loss': 0.0205, 'grad_norm': 8.646988868713379, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.015865635126829147, 'loss_2': 0.00467681884765625, 'loss_3': -16.244165420532227, 'loss_4': 1.363431692123413, 'epoch': 9.08}
{'loss': 0.0186, 'grad_norm': 6.12297248840332, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.014610275626182556, 'loss_2': 0.004009246826171875, 'loss_3': -16.26744842529297, 'loss_4': 1.2842005491256714, 'epoch': 9.09}
{'loss': 0.0163, 'grad_norm': 6.507022857666016, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.015963146463036537, 'loss_2': 0.0003428459167480469, 'loss_3': -16.298688888549805, 'loss_4': 1.6893672943115234, 'epoch': 9.09}
{'loss': 0.0159, 'grad_norm': 5.670718193054199, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.01232734601944685, 'loss_2': 0.0036029815673828125, 'loss_3': -16.32611656188965, 'loss_4': 1.428425908088684, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 10:05:25,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:25,834 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [38:52<1:02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:33,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01362837664783001, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009938343428075314, 'eval_loss_2': 0.0036900341510772705, 'eval_loss_3': -18.22800636291504, 'eval_loss_4': 1.163448691368103, 'epoch': 9.1}
{'loss': 0.0647, 'grad_norm': 15.732279777526855, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.059207212179899216, 'loss_2': 0.00548553466796875, 'loss_3': -16.203109741210938, 'loss_4': 1.5916670560836792, 'epoch': 9.1}
{'loss': 0.0207, 'grad_norm': 7.491819858551025, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.01909046806395054, 'loss_2': 0.00165557861328125, 'loss_3': -16.386226654052734, 'loss_4': 2.017789363861084, 'epoch': 9.11}
{'loss': 0.0242, 'grad_norm': 6.054195404052734, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.016638370230793953, 'loss_2': 0.00759124755859375, 'loss_3': -16.311622619628906, 'loss_4': 1.7321068048477173, 'epoch': 9.12}
{'loss': 0.0213, 'grad_norm': 7.976235389709473, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.015972746536135674, 'loss_2': 0.005344390869140625, 'loss_3': -16.31460952758789, 'loss_4': 1.8238739967346191, 'epoch': 9.12}
{'loss': 0.029, 'grad_norm': 12.730570793151855, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.02680925279855728, 'loss_2': 0.0021572113037109375, 'loss_3': -15.99456787109375, 'loss_4': 1.7054009437561035, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 10:05:33,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:33,182 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:00<1:02:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:40,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01391447614878416, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008295038715004921, 'eval_loss_2': 0.005619436502456665, 'eval_loss_3': -18.24561309814453, 'eval_loss_4': 1.5097596645355225, 'epoch': 9.13}
{'loss': 0.0148, 'grad_norm': 6.104569435119629, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.013144364580512047, 'loss_2': 0.001628875732421875, 'loss_3': -16.331867218017578, 'loss_4': 1.5338594913482666, 'epoch': 9.13}
{'loss': 0.0245, 'grad_norm': 7.7119574546813965, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.01942051574587822, 'loss_2': 0.00508880615234375, 'loss_3': -15.979440689086914, 'loss_4': 1.9045484066009521, 'epoch': 9.14}
{'loss': 0.0578, 'grad_norm': 13.686710357666016, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.05268155783414841, 'loss_2': 0.005115509033203125, 'loss_3': -16.003276824951172, 'loss_4': 2.2991466522216797, 'epoch': 9.15}
{'loss': 0.0392, 'grad_norm': 16.864011764526367, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.032260697335004807, 'loss_2': 0.0069580078125, 'loss_3': -16.189659118652344, 'loss_4': 1.7427518367767334, 'epoch': 9.15}
{'loss': 0.0277, 'grad_norm': 9.021878242492676, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.02697867527604103, 'loss_2': 0.0007014274597167969, 'loss_3': -16.23436737060547, 'loss_4': 2.063978433609009, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 10:05:40,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:40,529 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:07<1:01:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:47,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01194343063980341, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.699, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009392574429512024, 'eval_loss_2': 0.002550855278968811, 'eval_loss_3': -18.267776489257812, 'eval_loss_4': 1.790442943572998, 'epoch': 9.16}
{'loss': 0.0216, 'grad_norm': 7.848987102508545, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.01949499361217022, 'loss_2': 0.0021533966064453125, 'loss_3': -16.14012908935547, 'loss_4': 1.5587635040283203, 'epoch': 9.16}
{'loss': 0.0996, 'grad_norm': 18.842634201049805, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.09878074377775192, 'loss_2': 0.0008087158203125, 'loss_3': -16.247455596923828, 'loss_4': 1.7959034442901611, 'epoch': 9.17}
{'loss': 0.0224, 'grad_norm': 8.513312339782715, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.018855266273021698, 'loss_2': 0.0035381317138671875, 'loss_3': -16.41962432861328, 'loss_4': 2.790890693664551, 'epoch': 9.17}
{'loss': 0.0337, 'grad_norm': 14.346785545349121, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.023004921153187752, 'loss_2': 0.0107421875, 'loss_3': -16.323551177978516, 'loss_4': 2.437960624694824, 'epoch': 9.18}
{'loss': 0.0507, 'grad_norm': 15.648787498474121, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.03702426701784134, 'loss_2': 0.013671875, 'loss_3': -16.343814849853516, 'loss_4': 2.5343263149261475, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 10:05:47,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:47,867 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:15<1:01:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:55,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017826497554779053, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.653, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010098336264491081, 'eval_loss_2': 0.007728159427642822, 'eval_loss_3': -18.2396183013916, 'eval_loss_4': 1.7430859804153442, 'epoch': 9.19}
{'loss': 0.041, 'grad_norm': 13.906272888183594, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.03028370812535286, 'loss_2': 0.01076507568359375, 'loss_3': -15.904458045959473, 'loss_4': 2.1726555824279785, 'epoch': 9.19}
{'loss': 0.045, 'grad_norm': 11.50947380065918, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.03842363879084587, 'loss_2': 0.00653076171875, 'loss_3': -16.23248863220215, 'loss_4': 1.9937134981155396, 'epoch': 9.2}
{'loss': 0.0225, 'grad_norm': 7.6856231689453125, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.01895485259592533, 'loss_2': 0.003559112548828125, 'loss_3': -16.028446197509766, 'loss_4': 2.2336466312408447, 'epoch': 9.2}
{'loss': 0.0181, 'grad_norm': 9.679359436035156, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.0165371336042881, 'loss_2': 0.0016088485717773438, 'loss_3': -16.415237426757812, 'loss_4': 1.6409810781478882, 'epoch': 9.21}
{'loss': 0.0183, 'grad_norm': 6.987669944763184, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.013863503001630306, 'loss_2': 0.004486083984375, 'loss_3': -16.441652297973633, 'loss_4': 1.3453322649002075, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 10:05:55,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:55,203 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:22<1:01:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:02,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014495857059955597, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.899, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009286648593842983, 'eval_loss_2': 0.005209207534790039, 'eval_loss_3': -18.237878799438477, 'eval_loss_4': 1.5490589141845703, 'epoch': 9.22}
{'loss': 0.0258, 'grad_norm': 11.25887393951416, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.017882663756608963, 'loss_2': 0.00787353515625, 'loss_3': -16.244585037231445, 'loss_4': 1.607560396194458, 'epoch': 9.22}
{'loss': 0.0251, 'grad_norm': 8.422770500183105, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.022204693406820297, 'loss_2': 0.00286865234375, 'loss_3': -16.489334106445312, 'loss_4': 1.9424843788146973, 'epoch': 9.23}
{'loss': 0.0119, 'grad_norm': 5.756229400634766, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.01031225360929966, 'loss_2': 0.0015392303466796875, 'loss_3': -16.220975875854492, 'loss_4': 1.1240630149841309, 'epoch': 9.23}
{'loss': 0.0229, 'grad_norm': 10.222262382507324, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.021038223057985306, 'loss_2': 0.0018405914306640625, 'loss_3': -16.26604461669922, 'loss_4': 2.381751775741577, 'epoch': 9.24}
{'loss': 0.0256, 'grad_norm': 9.295412063598633, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.02229953557252884, 'loss_2': 0.00330352783203125, 'loss_3': -16.181961059570312, 'loss_4': 2.0595192909240723, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 10:06:02,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:02,539 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:29<1:01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:09,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011425300501286983, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008068248629570007, 'eval_loss_2': 0.0033570528030395508, 'eval_loss_3': -18.259029388427734, 'eval_loss_4': 1.4079509973526, 'epoch': 9.24}
{'loss': 0.0211, 'grad_norm': 6.77040433883667, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.013854419812560081, 'loss_2': 0.007228851318359375, 'loss_3': -16.308876037597656, 'loss_4': 1.4719550609588623, 'epoch': 9.25}
{'loss': 0.0315, 'grad_norm': 12.514527320861816, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.023897012695670128, 'loss_2': 0.0076446533203125, 'loss_3': -16.172636032104492, 'loss_4': 1.5159833431243896, 'epoch': 9.26}
{'loss': 0.0083, 'grad_norm': 5.381809711456299, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.00753684900701046, 'loss_2': 0.000736236572265625, 'loss_3': -16.058156967163086, 'loss_4': 1.9875510931015015, 'epoch': 9.26}
{'loss': 0.0293, 'grad_norm': 9.669404983520508, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.02271830476820469, 'loss_2': 0.0065460205078125, 'loss_3': -16.289731979370117, 'loss_4': 2.087484836578369, 'epoch': 9.27}
{'loss': 0.016, 'grad_norm': 7.179913520812988, 'learning_rate': 2.075e-05, 'loss_1': 0.014881279319524765, 'loss_2': 0.0011425018310546875, 'loss_3': -16.21555519104004, 'loss_4': 2.130887031555176, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 10:06:09,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:09,882 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:37<1:01:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:17,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01334424503147602, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010111259296536446, 'eval_loss_2': 0.003232985734939575, 'eval_loss_3': -18.2655086517334, 'eval_loss_4': 1.360007643699646, 'epoch': 9.27}
{'loss': 0.0155, 'grad_norm': 7.923983097076416, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.015400777570903301, 'loss_2': 0.00013899803161621094, 'loss_3': -16.241724014282227, 'loss_4': 1.069362998008728, 'epoch': 9.28}
{'loss': 0.0348, 'grad_norm': 17.993635177612305, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.034257326275110245, 'loss_2': 0.000507354736328125, 'loss_3': -16.28359603881836, 'loss_4': 1.4160163402557373, 'epoch': 9.28}
{'loss': 0.0099, 'grad_norm': 5.290379524230957, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.009839256294071674, 'loss_2': 4.482269287109375e-05, 'loss_3': -16.231657028198242, 'loss_4': 1.9754304885864258, 'epoch': 9.29}
{'loss': 0.0148, 'grad_norm': 6.896587371826172, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.01368798315525055, 'loss_2': 0.001087188720703125, 'loss_3': -16.269397735595703, 'loss_4': 1.6165708303451538, 'epoch': 9.3}
{'loss': 0.0113, 'grad_norm': 5.0926408767700195, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.006448166910558939, 'loss_2': 0.004863739013671875, 'loss_3': -16.24073600769043, 'loss_4': 1.5951656103134155, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 10:06:17,234 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:17,234 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:44<1:01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:24,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013656577095389366, 'eval_runtime': 3.8218, 'eval_samples_per_second': 267.937, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.008962711319327354, 'eval_loss_2': 0.004693865776062012, 'eval_loss_3': -18.291990280151367, 'eval_loss_4': 1.2681353092193604, 'epoch': 9.3}
{'loss': 0.0201, 'grad_norm': 9.350126266479492, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.01735776662826538, 'loss_2': 0.0027484893798828125, 'loss_3': -16.368331909179688, 'loss_4': 1.7069073915481567, 'epoch': 9.31}
{'loss': 0.0299, 'grad_norm': 10.35145092010498, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.02788451313972473, 'loss_2': 0.00203704833984375, 'loss_3': -16.28424835205078, 'loss_4': 1.4241266250610352, 'epoch': 9.31}
{'loss': 0.0092, 'grad_norm': 5.216308116912842, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.009138746187090874, 'loss_2': 5.650520324707031e-05, 'loss_3': -16.46450424194336, 'loss_4': 1.7064104080200195, 'epoch': 9.32}
{'loss': 0.0208, 'grad_norm': 5.95432710647583, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.01496956218034029, 'loss_2': 0.005847930908203125, 'loss_3': -16.268342971801758, 'loss_4': 1.4048869609832764, 'epoch': 9.33}
{'loss': 0.0104, 'grad_norm': 5.1088547706604, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.009783375076949596, 'loss_2': 0.0006437301635742188, 'loss_3': -16.36337661743164, 'loss_4': 1.4710034132003784, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 10:06:24,598 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:24,598 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [39:51<1:01:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:31,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013129886239767075, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.6, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00953697506338358, 'eval_loss_2': 0.00359291210770607, 'eval_loss_3': -18.324718475341797, 'eval_loss_4': 0.8622705936431885, 'epoch': 9.33}
{'loss': 0.0115, 'grad_norm': 5.263082981109619, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.010557053610682487, 'loss_2': 0.000965118408203125, 'loss_3': -16.360782623291016, 'loss_4': 1.0673556327819824, 'epoch': 9.34}
{'loss': 0.0286, 'grad_norm': 12.894425392150879, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.023517506197094917, 'loss_2': 0.0050506591796875, 'loss_3': -16.35574722290039, 'loss_4': 1.2678296566009521, 'epoch': 9.34}
{'loss': 0.0157, 'grad_norm': 6.489117622375488, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.011844484135508537, 'loss_2': 0.003871917724609375, 'loss_3': -16.373172760009766, 'loss_4': 0.6048922538757324, 'epoch': 9.35}
{'loss': 0.0278, 'grad_norm': 9.22070598602295, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.021279769018292427, 'loss_2': 0.00653076171875, 'loss_3': -16.235082626342773, 'loss_4': 0.6426231861114502, 'epoch': 9.35}
{'loss': 0.0095, 'grad_norm': 4.8814520835876465, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.008312501013278961, 'loss_2': 0.0012035369873046875, 'loss_3': -16.370901107788086, 'loss_4': 0.9555401802062988, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 10:06:31,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:31,938 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [39:59<1:01:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:39,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017285645008087158, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009864749386906624, 'eval_loss_2': 0.007420897483825684, 'eval_loss_3': -18.335344314575195, 'eval_loss_4': 0.546937882900238, 'epoch': 9.36}
{'loss': 0.054, 'grad_norm': 21.097009658813477, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.04335746541619301, 'loss_2': 0.01065826416015625, 'loss_3': -16.274477005004883, 'loss_4': 1.3498789072036743, 'epoch': 9.37}
{'loss': 0.0241, 'grad_norm': 8.221269607543945, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.01892775297164917, 'loss_2': 0.005161285400390625, 'loss_3': -16.29191780090332, 'loss_4': 0.44816380739212036, 'epoch': 9.37}
{'loss': 0.0282, 'grad_norm': 6.137722969055176, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.020016489550471306, 'loss_2': 0.00815582275390625, 'loss_3': -16.42456817626953, 'loss_4': 0.46476686000823975, 'epoch': 9.38}
{'loss': 0.0367, 'grad_norm': 11.516277313232422, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.032344140112400055, 'loss_2': 0.00434112548828125, 'loss_3': -16.34316635131836, 'loss_4': 1.0141494274139404, 'epoch': 9.38}
{'loss': 0.0179, 'grad_norm': 7.227949619293213, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.015734640881419182, 'loss_2': 0.00215911865234375, 'loss_3': -16.394485473632812, 'loss_4': 1.2143502235412598, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 10:06:39,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:39,280 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:06<1:01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:46,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015154327265918255, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010199242271482944, 'eval_loss_2': 0.004955083131790161, 'eval_loss_3': -18.351110458374023, 'eval_loss_4': 0.44975021481513977, 'epoch': 9.39}
{'loss': 0.0238, 'grad_norm': 8.24046516418457, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.017354441806674004, 'loss_2': 0.006458282470703125, 'loss_3': -16.221281051635742, 'loss_4': 0.9961109161376953, 'epoch': 9.4}
{'loss': 0.0219, 'grad_norm': 8.190027236938477, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.018539199605584145, 'loss_2': 0.0033588409423828125, 'loss_3': -16.303176879882812, 'loss_4': 0.7564371824264526, 'epoch': 9.4}
{'loss': 0.0256, 'grad_norm': 7.806326389312744, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.01973971165716648, 'loss_2': 0.0058441162109375, 'loss_3': -16.391765594482422, 'loss_4': 1.2535425424575806, 'epoch': 9.41}
{'loss': 0.0166, 'grad_norm': 5.183254718780518, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.009173132479190826, 'loss_2': 0.00740814208984375, 'loss_3': -16.397079467773438, 'loss_4': 0.6843572854995728, 'epoch': 9.41}
{'loss': 0.0135, 'grad_norm': 4.729466915130615, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.011655128560960293, 'loss_2': 0.0018682479858398438, 'loss_3': -15.974393844604492, 'loss_4': 0.6121484041213989, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 10:06:46,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:46,628 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:13<1:01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:53,988 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013583136722445488, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010809524916112423, 'eval_loss_2': 0.0027736127376556396, 'eval_loss_3': -18.340225219726562, 'eval_loss_4': 0.4344499111175537, 'epoch': 9.42}
{'loss': 0.019, 'grad_norm': 7.487860679626465, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.015215420164167881, 'loss_2': 0.0037441253662109375, 'loss_3': -16.3775691986084, 'loss_4': 0.6672121286392212, 'epoch': 9.42}
{'loss': 0.0174, 'grad_norm': 5.638032913208008, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.008168009109795094, 'loss_2': 0.00923919677734375, 'loss_3': -16.319061279296875, 'loss_4': 0.34339386224746704, 'epoch': 9.43}
{'loss': 0.0074, 'grad_norm': 4.763577461242676, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.007220246363431215, 'loss_2': 0.00017845630645751953, 'loss_3': -16.415971755981445, 'loss_4': 1.1194992065429688, 'epoch': 9.44}
{'loss': 0.0187, 'grad_norm': 8.560332298278809, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.01712707243859768, 'loss_2': 0.0015916824340820312, 'loss_3': -16.162092208862305, 'loss_4': 0.657037079334259, 'epoch': 9.44}
{'loss': 0.019, 'grad_norm': 5.820211410522461, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.016420910134911537, 'loss_2': 0.002536773681640625, 'loss_3': -16.367036819458008, 'loss_4': 0.769922137260437, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 10:06:53,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:53,988 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:21<1:01:34,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:07:01,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014235571026802063, 'eval_runtime': 3.8682, 'eval_samples_per_second': 264.719, 'eval_steps_per_second': 4.136, 'eval_loss_1': 0.010746254585683346, 'eval_loss_2': 0.0034893155097961426, 'eval_loss_3': -18.325084686279297, 'eval_loss_4': 0.3508308529853821, 'epoch': 9.45}
{'loss': 0.0167, 'grad_norm': 5.779243469238281, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.01187196560204029, 'loss_2': 0.00482940673828125, 'loss_3': -16.39398765563965, 'loss_4': 0.6757490634918213, 'epoch': 9.45}
{'loss': 0.017, 'grad_norm': 6.140414237976074, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.012022317387163639, 'loss_2': 0.004974365234375, 'loss_3': -16.253829956054688, 'loss_4': 0.5041228532791138, 'epoch': 9.46}
{'loss': 0.0349, 'grad_norm': 19.227806091308594, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.029461905360221863, 'loss_2': 0.0054168701171875, 'loss_3': -16.10445785522461, 'loss_4': 0.3274814784526825, 'epoch': 9.47}
{'loss': 0.0139, 'grad_norm': 6.553858757019043, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.012402622029185295, 'loss_2': 0.0015316009521484375, 'loss_3': -16.187313079833984, 'loss_4': 0.871821939945221, 'epoch': 9.47}
{'loss': 0.027, 'grad_norm': 10.733128547668457, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.0260683111846447, 'loss_2': 0.0009784698486328125, 'loss_3': -16.22879409790039, 'loss_4': 0.36899858713150024, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 10:07:01,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:01,425 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:28<1:01:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:08,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014833101071417332, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.363, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01089067105203867, 'eval_loss_2': 0.003942430019378662, 'eval_loss_3': -18.283517837524414, 'eval_loss_4': 0.43579554557800293, 'epoch': 9.48}
{'loss': 0.0241, 'grad_norm': 9.357402801513672, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.023635948076844215, 'loss_2': 0.0004506111145019531, 'loss_3': -16.194374084472656, 'loss_4': 0.3103482723236084, 'epoch': 9.48}
{'loss': 0.0163, 'grad_norm': 5.61397647857666, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.011066146194934845, 'loss_2': 0.005252838134765625, 'loss_3': -16.21147918701172, 'loss_4': 0.43628329038619995, 'epoch': 9.49}
{'loss': 0.0149, 'grad_norm': 5.3044939041137695, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.014640839770436287, 'loss_2': 0.0002884864807128906, 'loss_3': -16.224315643310547, 'loss_4': 0.7364480495452881, 'epoch': 9.49}
{'loss': 0.0998, 'grad_norm': 17.72903060913086, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.09848108887672424, 'loss_2': 0.0013170242309570312, 'loss_3': -16.1241455078125, 'loss_4': 0.8332229256629944, 'epoch': 9.5}
{'loss': 0.0123, 'grad_norm': 5.330574035644531, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.008222077041864395, 'loss_2': 0.004058837890625, 'loss_3': -16.511293411254883, 'loss_4': 0.6815295219421387, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 10:07:08,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:08,770 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:35<1:00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:16,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026044901460409164, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01892894320189953, 'eval_loss_2': 0.007115960121154785, 'eval_loss_3': -18.21402359008789, 'eval_loss_4': 0.6678180694580078, 'epoch': 9.51}
{'loss': 0.0244, 'grad_norm': 6.677202224731445, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.012213382869958878, 'loss_2': 0.012176513671875, 'loss_3': -16.234703063964844, 'loss_4': 0.5937176942825317, 'epoch': 9.51}
{'loss': 0.0343, 'grad_norm': 10.312557220458984, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.026372110471129417, 'loss_2': 0.0078887939453125, 'loss_3': -16.438343048095703, 'loss_4': 0.8480144739151001, 'epoch': 9.52}
{'loss': 0.0534, 'grad_norm': 14.209508895874023, 'learning_rate': 2.05e-05, 'loss_1': 0.03919724002480507, 'loss_2': 0.014190673828125, 'loss_3': -16.253007888793945, 'loss_4': 0.7853342294692993, 'epoch': 9.52}
{'loss': 0.0225, 'grad_norm': 6.71681547164917, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.016027744859457016, 'loss_2': 0.0064849853515625, 'loss_3': -16.220947265625, 'loss_4': 0.463954895734787, 'epoch': 9.53}
{'loss': 0.0155, 'grad_norm': 4.879096508026123, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.008353471755981445, 'loss_2': 0.00716400146484375, 'loss_3': -16.441268920898438, 'loss_4': 0.6771989464759827, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 10:07:16,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:16,106 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [40:43<1:00:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:23,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03626105189323425, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03183147311210632, 'eval_loss_2': 0.00442957878112793, 'eval_loss_3': -18.168989181518555, 'eval_loss_4': 0.7955740690231323, 'epoch': 9.53}
{'loss': 0.0174, 'grad_norm': 5.222990036010742, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.00810160394757986, 'loss_2': 0.00933074951171875, 'loss_3': -16.395357131958008, 'loss_4': 1.0022014379501343, 'epoch': 9.54}
{'loss': 0.0396, 'grad_norm': 13.266160011291504, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.038696687668561935, 'loss_2': 0.0009098052978515625, 'loss_3': -16.40178108215332, 'loss_4': 0.8618267178535461, 'epoch': 9.55}
{'loss': 0.0216, 'grad_norm': 6.651773929595947, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.01670735515654087, 'loss_2': 0.004871368408203125, 'loss_3': -16.15169906616211, 'loss_4': 0.39855921268463135, 'epoch': 9.55}
{'loss': 0.0234, 'grad_norm': 9.701513290405273, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.019492432475090027, 'loss_2': 0.003887176513671875, 'loss_3': -16.21981430053711, 'loss_4': 0.5788863301277161, 'epoch': 9.56}
{'loss': 0.0226, 'grad_norm': 9.83455753326416, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.018478496000170708, 'loss_2': 0.004093170166015625, 'loss_3': -16.158628463745117, 'loss_4': 0.649254560470581, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 10:07:23,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:23,451 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [40:50<1:00:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:30,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020200636237859726, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.825, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015836860984563828, 'eval_loss_2': 0.0043637752532958984, 'eval_loss_3': -18.199810028076172, 'eval_loss_4': 0.8692834973335266, 'epoch': 9.56}
{'loss': 0.0689, 'grad_norm': 24.400344848632812, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.06347062438726425, 'loss_2': 0.0054168701171875, 'loss_3': -16.36920738220215, 'loss_4': 0.9671081304550171, 'epoch': 9.57}
{'loss': 0.0117, 'grad_norm': 6.359851360321045, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.010324456728994846, 'loss_2': 0.00136566162109375, 'loss_3': -16.386640548706055, 'loss_4': 1.0163325071334839, 'epoch': 9.58}
{'loss': 0.0303, 'grad_norm': 11.085734367370605, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.025301329791545868, 'loss_2': 0.0049591064453125, 'loss_3': -16.322219848632812, 'loss_4': 1.410733938217163, 'epoch': 9.58}
{'loss': 0.022, 'grad_norm': 14.290329933166504, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.019404824823141098, 'loss_2': 0.002590179443359375, 'loss_3': -16.252084732055664, 'loss_4': 1.5418355464935303, 'epoch': 9.59}
{'loss': 0.017, 'grad_norm': 5.240251064300537, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.00754733057692647, 'loss_2': 0.00943756103515625, 'loss_3': -16.370962142944336, 'loss_4': 1.0042674541473389, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 10:07:30,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:30,790 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [40:57<1:00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:38,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014082711189985275, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009381604380905628, 'eval_loss_2': 0.004701107740402222, 'eval_loss_3': -18.283618927001953, 'eval_loss_4': 1.1626042127609253, 'epoch': 9.59}
{'loss': 0.0171, 'grad_norm': 6.483926296234131, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.012089978903532028, 'loss_2': 0.005008697509765625, 'loss_3': -16.319297790527344, 'loss_4': 0.9873429536819458, 'epoch': 9.6}
{'loss': 0.0233, 'grad_norm': 11.70131778717041, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.01626088283956051, 'loss_2': 0.0070037841796875, 'loss_3': -16.298038482666016, 'loss_4': 1.1548657417297363, 'epoch': 9.6}
{'loss': 0.0166, 'grad_norm': 6.61901330947876, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.01619921624660492, 'loss_2': 0.00044727325439453125, 'loss_3': -16.33776092529297, 'loss_4': 1.6068830490112305, 'epoch': 9.61}
{'loss': 0.0213, 'grad_norm': 5.977494239807129, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.017512626945972443, 'loss_2': 0.003742218017578125, 'loss_3': -16.345111846923828, 'loss_4': 1.0356509685516357, 'epoch': 9.62}
{'loss': 0.0224, 'grad_norm': 11.906914710998535, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.01579340547323227, 'loss_2': 0.00664520263671875, 'loss_3': -16.217853546142578, 'loss_4': 1.6754741668701172, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 10:07:38,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:38,136 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:05<1:00:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:45,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013112448155879974, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.756, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008838397450745106, 'eval_loss_2': 0.004274047911167145, 'eval_loss_3': -18.2979736328125, 'eval_loss_4': 1.4207011461257935, 'epoch': 9.62}
{'loss': 0.0107, 'grad_norm': 5.265230178833008, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.008030450902879238, 'loss_2': 0.002635955810546875, 'loss_3': -16.14594841003418, 'loss_4': 1.6846195459365845, 'epoch': 9.63}
{'loss': 0.0181, 'grad_norm': 5.646850109100342, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.00815653894096613, 'loss_2': 0.009979248046875, 'loss_3': -16.36705780029297, 'loss_4': 1.9007041454315186, 'epoch': 9.63}
{'loss': 0.0126, 'grad_norm': 5.351630687713623, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.00700787641108036, 'loss_2': 0.005615234375, 'loss_3': -16.041500091552734, 'loss_4': 1.5949493646621704, 'epoch': 9.64}
{'loss': 0.0125, 'grad_norm': 5.862608909606934, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.009907392784953117, 'loss_2': 0.002605438232421875, 'loss_3': -16.25469970703125, 'loss_4': 1.6303099393844604, 'epoch': 9.65}
{'loss': 0.0092, 'grad_norm': 5.075140953063965, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.006734177470207214, 'loss_2': 0.002429962158203125, 'loss_3': -16.405948638916016, 'loss_4': 1.860495924949646, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 10:07:45,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:45,466 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:12<1:00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:52,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013110846281051636, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007707984186708927, 'eval_loss_2': 0.005402863025665283, 'eval_loss_3': -18.302440643310547, 'eval_loss_4': 1.439846396446228, 'epoch': 9.65}
{'loss': 0.0104, 'grad_norm': 4.841135501861572, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.006464394275099039, 'loss_2': 0.00395965576171875, 'loss_3': -16.21009635925293, 'loss_4': 1.7162911891937256, 'epoch': 9.66}
{'loss': 0.0123, 'grad_norm': 5.24173641204834, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.008609970100224018, 'loss_2': 0.003662109375, 'loss_3': -16.37790298461914, 'loss_4': 1.4782536029815674, 'epoch': 9.66}
{'loss': 0.014, 'grad_norm': 6.386255264282227, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.013473383150994778, 'loss_2': 0.0004954338073730469, 'loss_3': -16.375717163085938, 'loss_4': 1.7101224660873413, 'epoch': 9.67}
{'loss': 0.0348, 'grad_norm': 11.506239891052246, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.027688410133123398, 'loss_2': 0.007083892822265625, 'loss_3': -16.332138061523438, 'loss_4': 1.6635029315948486, 'epoch': 9.67}
{'loss': 0.0452, 'grad_norm': 11.658355712890625, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.04459775984287262, 'loss_2': 0.0005970001220703125, 'loss_3': -16.269433975219727, 'loss_4': 1.9399760961532593, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 10:07:52,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:52,816 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:19<1:00:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:00,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014208542183041573, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0080071110278368, 'eval_loss_2': 0.006201431155204773, 'eval_loss_3': -18.29397964477539, 'eval_loss_4': 1.2314746379852295, 'epoch': 9.68}
{'loss': 0.016, 'grad_norm': 5.938041687011719, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.009214657358825207, 'loss_2': 0.006744384765625, 'loss_3': -16.388349533081055, 'loss_4': 1.500563621520996, 'epoch': 9.69}
{'loss': 0.0289, 'grad_norm': 8.863519668579102, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.021573849022388458, 'loss_2': 0.0073699951171875, 'loss_3': -16.456357955932617, 'loss_4': 2.139923095703125, 'epoch': 9.69}
{'loss': 0.0189, 'grad_norm': 6.473103046417236, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.011001120321452618, 'loss_2': 0.00788116455078125, 'loss_3': -16.32219696044922, 'loss_4': 1.81525719165802, 'epoch': 9.7}
{'loss': 0.0451, 'grad_norm': 13.938187599182129, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.0410180389881134, 'loss_2': 0.00412750244140625, 'loss_3': -16.262737274169922, 'loss_4': 1.0173107385635376, 'epoch': 9.7}
{'loss': 0.0194, 'grad_norm': 7.2666168212890625, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.01590893417596817, 'loss_2': 0.00351715087890625, 'loss_3': -16.446552276611328, 'loss_4': 0.9778236150741577, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 10:08:00,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:00,164 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:27<1:00:53,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:08:07,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012250145897269249, 'eval_runtime': 3.9817, 'eval_samples_per_second': 257.179, 'eval_steps_per_second': 4.018, 'eval_loss_1': 0.007090276572853327, 'eval_loss_2': 0.0051598697900772095, 'eval_loss_3': -18.282169342041016, 'eval_loss_4': 1.076470971107483, 'epoch': 9.71}
{'loss': 0.0269, 'grad_norm': 11.099102020263672, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.02159864455461502, 'loss_2': 0.005321502685546875, 'loss_3': -16.24860382080078, 'loss_4': 1.0450338125228882, 'epoch': 9.72}
{'loss': 0.0198, 'grad_norm': 6.236448764801025, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.018446190282702446, 'loss_2': 0.0013837814331054688, 'loss_3': -16.22006607055664, 'loss_4': 2.3440160751342773, 'epoch': 9.72}
{'loss': 0.0184, 'grad_norm': 7.106781482696533, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.01662488281726837, 'loss_2': 0.00174713134765625, 'loss_3': -16.203243255615234, 'loss_4': 0.9822991490364075, 'epoch': 9.73}
{'loss': 0.0226, 'grad_norm': 8.220857620239258, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.01973659172654152, 'loss_2': 0.0028667449951171875, 'loss_3': -16.35730743408203, 'loss_4': 1.515674352645874, 'epoch': 9.73}
{'loss': 0.0237, 'grad_norm': 7.224643230438232, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.013613077811896801, 'loss_2': 0.01006317138671875, 'loss_3': -16.362930297851562, 'loss_4': 1.3357322216033936, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 10:08:07,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:07,678 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:34<1:00:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:15,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011652370914816856, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.128, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007197251543402672, 'eval_loss_2': 0.004455119371414185, 'eval_loss_3': -18.269798278808594, 'eval_loss_4': 0.9090463519096375, 'epoch': 9.74}
{'loss': 0.0124, 'grad_norm': 5.948848724365234, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.009424278512597084, 'loss_2': 0.003025054931640625, 'loss_3': -16.431245803833008, 'loss_4': 1.0666896104812622, 'epoch': 9.74}
{'loss': 0.0135, 'grad_norm': 5.24681282043457, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.009613262489438057, 'loss_2': 0.00383758544921875, 'loss_3': -16.362979888916016, 'loss_4': 0.9376764297485352, 'epoch': 9.75}
{'loss': 0.0141, 'grad_norm': 5.668927192687988, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.013763980939984322, 'loss_2': 0.0003170967102050781, 'loss_3': -16.310827255249023, 'loss_4': 0.2411009669303894, 'epoch': 9.76}
{'loss': 0.0177, 'grad_norm': 5.225700855255127, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.010512268170714378, 'loss_2': 0.00720977783203125, 'loss_3': -16.46176528930664, 'loss_4': 0.8324277400970459, 'epoch': 9.76}
{'loss': 0.0156, 'grad_norm': 7.119103908538818, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.01178439799696207, 'loss_2': 0.003795623779296875, 'loss_3': -16.24237060546875, 'loss_4': 0.8808143138885498, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 10:08:15,006 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:15,006 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:42<1:00:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:22,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015926849097013474, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007968079298734665, 'eval_loss_2': 0.007958769798278809, 'eval_loss_3': -18.265892028808594, 'eval_loss_4': 0.6350470185279846, 'epoch': 9.77}
{'loss': 0.0126, 'grad_norm': 5.580965042114258, 'learning_rate': 2.025e-05, 'loss_1': 0.00955903995782137, 'loss_2': 0.003063201904296875, 'loss_3': -16.413589477539062, 'loss_4': 0.6136967539787292, 'epoch': 9.77}
{'loss': 0.0253, 'grad_norm': 7.78626823425293, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.013915957883000374, 'loss_2': 0.011383056640625, 'loss_3': -16.232168197631836, 'loss_4': 1.10781729221344, 'epoch': 9.78}
{'loss': 0.0265, 'grad_norm': 9.013772010803223, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.0201296154409647, 'loss_2': 0.0063934326171875, 'loss_3': -16.440732955932617, 'loss_4': 0.5990962982177734, 'epoch': 9.78}
{'loss': 0.0166, 'grad_norm': 6.972717761993408, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.011760569177567959, 'loss_2': 0.00482177734375, 'loss_3': -16.332822799682617, 'loss_4': 0.3018299341201782, 'epoch': 9.79}
{'loss': 0.0222, 'grad_norm': 6.775235652923584, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.015030782669782639, 'loss_2': 0.007129669189453125, 'loss_3': -16.459468841552734, 'loss_4': 0.714006245136261, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 10:08:22,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:22,361 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1690/5160 [41:49<59:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:29,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01898428425192833, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.602, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009765352122485638, 'eval_loss_2': 0.009218931198120117, 'eval_loss_3': -18.261547088623047, 'eval_loss_4': 0.4298301935195923, 'epoch': 9.8}
{'loss': 0.0211, 'grad_norm': 7.437459468841553, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.018256856128573418, 'loss_2': 0.002834320068359375, 'loss_3': -16.447925567626953, 'loss_4': 0.35595959424972534, 'epoch': 9.8}
{'loss': 0.0245, 'grad_norm': 9.61542797088623, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.01709863357245922, 'loss_2': 0.007358551025390625, 'loss_3': -16.433685302734375, 'loss_4': 0.9376925230026245, 'epoch': 9.81}
{'loss': 0.0202, 'grad_norm': 5.17894172668457, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.009068836458027363, 'loss_2': 0.0111083984375, 'loss_3': -16.60106086730957, 'loss_4': 1.1951504945755005, 'epoch': 9.81}
{'loss': 0.0217, 'grad_norm': 7.354523181915283, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.01807388663291931, 'loss_2': 0.003620147705078125, 'loss_3': -16.600475311279297, 'loss_4': 0.44672292470932007, 'epoch': 9.82}
{'loss': 0.0134, 'grad_norm': 6.671257495880127, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.012671239674091339, 'loss_2': 0.000732421875, 'loss_3': -16.531898498535156, 'loss_4': 0.4621127247810364, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 10:08:29,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:29,697 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [41:56<59:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:37,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015776291489601135, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.493, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.010787861421704292, 'eval_loss_2': 0.004988431930541992, 'eval_loss_3': -18.27642822265625, 'eval_loss_4': 0.21447879076004028, 'epoch': 9.83}
{'loss': 0.0273, 'grad_norm': 10.928690910339355, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.01873643696308136, 'loss_2': 0.008575439453125, 'loss_3': -16.351131439208984, 'loss_4': 1.0511358976364136, 'epoch': 9.83}
{'loss': 0.0152, 'grad_norm': 5.420413017272949, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.012395028956234455, 'loss_2': 0.0028400421142578125, 'loss_3': -16.352783203125, 'loss_4': 0.16311326622962952, 'epoch': 9.84}
{'loss': 0.0366, 'grad_norm': 12.668328285217285, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.030578074976801872, 'loss_2': 0.006011962890625, 'loss_3': -16.221683502197266, 'loss_4': 0.7063152194023132, 'epoch': 9.84}
{'loss': 0.0217, 'grad_norm': 4.926713943481445, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.009387743659317493, 'loss_2': 0.012359619140625, 'loss_3': -16.355247497558594, 'loss_4': 0.3339694142341614, 'epoch': 9.85}
{'loss': 0.033, 'grad_norm': 7.693417072296143, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.021015599370002747, 'loss_2': 0.0120086669921875, 'loss_3': -16.39263153076172, 'loss_4': 0.6955280303955078, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 10:08:37,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:37,019 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:04<59:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:44,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018410690128803253, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.068, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011094787158071995, 'eval_loss_2': 0.007315903902053833, 'eval_loss_3': -18.269790649414062, 'eval_loss_4': 0.27839455008506775, 'epoch': 9.85}
{'loss': 0.0158, 'grad_norm': 4.815211772918701, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.008138959296047688, 'loss_2': 0.007617950439453125, 'loss_3': -16.4729061126709, 'loss_4': 0.3756723403930664, 'epoch': 9.86}
{'loss': 0.0165, 'grad_norm': 5.8484721183776855, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.012694998644292355, 'loss_2': 0.0037994384765625, 'loss_3': -16.531597137451172, 'loss_4': 0.3508051633834839, 'epoch': 9.87}
{'loss': 0.0161, 'grad_norm': 7.132864475250244, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.015382332727313042, 'loss_2': 0.0007457733154296875, 'loss_3': -16.44156837463379, 'loss_4': 1.2181265354156494, 'epoch': 9.87}
{'loss': 0.0363, 'grad_norm': 9.78294563293457, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.025845162570476532, 'loss_2': 0.01049041748046875, 'loss_3': -16.520292282104492, 'loss_4': 0.7498165965080261, 'epoch': 9.88}
{'loss': 0.0277, 'grad_norm': 9.74764347076416, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.02684956230223179, 'loss_2': 0.00081634521484375, 'loss_3': -16.346595764160156, 'loss_4': 0.8322928547859192, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 10:08:44,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:44,356 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:11<59:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:51,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015755923464894295, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.183, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.00863698311150074, 'eval_loss_2': 0.007118940353393555, 'eval_loss_3': -18.30376625061035, 'eval_loss_4': 0.7228640913963318, 'epoch': 9.88}
{'loss': 0.0285, 'grad_norm': 11.429401397705078, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.026351619511842728, 'loss_2': 0.002193450927734375, 'loss_3': -16.30855369567871, 'loss_4': 1.1122139692306519, 'epoch': 9.89}
{'loss': 0.0381, 'grad_norm': 9.465560913085938, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.0286552757024765, 'loss_2': 0.00945281982421875, 'loss_3': -16.469375610351562, 'loss_4': 1.8714543581008911, 'epoch': 9.9}
{'loss': 0.0306, 'grad_norm': 6.03798246383667, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.020406311377882957, 'loss_2': 0.0101470947265625, 'loss_3': -16.176734924316406, 'loss_4': 0.8043444156646729, 'epoch': 9.9}
{'loss': 0.0288, 'grad_norm': 8.080097198486328, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.02019534260034561, 'loss_2': 0.00864410400390625, 'loss_3': -16.358722686767578, 'loss_4': 2.414802312850952, 'epoch': 9.91}
{'loss': 0.0433, 'grad_norm': 8.059959411621094, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.030318941920995712, 'loss_2': 0.0129547119140625, 'loss_3': -16.426494598388672, 'loss_4': 1.720197081565857, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 10:08:51,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:51,681 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:18<59:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:59,006 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020366255193948746, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.394, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008833710104227066, 'eval_loss_2': 0.01153254508972168, 'eval_loss_3': -18.293561935424805, 'eval_loss_4': 1.1374356746673584, 'epoch': 9.91}
{'loss': 0.0371, 'grad_norm': 9.04349136352539, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.023235365748405457, 'loss_2': 0.013885498046875, 'loss_3': -16.15854263305664, 'loss_4': 1.6373828649520874, 'epoch': 9.92}
{'loss': 0.0314, 'grad_norm': 7.571168422698975, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.02040511555969715, 'loss_2': 0.010955810546875, 'loss_3': -16.436351776123047, 'loss_4': 1.6345018148422241, 'epoch': 9.92}
{'loss': 0.0269, 'grad_norm': 7.650500774383545, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.023393625393509865, 'loss_2': 0.003475189208984375, 'loss_3': -16.41219139099121, 'loss_4': 1.6372921466827393, 'epoch': 9.93}
{'loss': 0.0376, 'grad_norm': 8.416540145874023, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.030022576451301575, 'loss_2': 0.00757598876953125, 'loss_3': -16.5419979095459, 'loss_4': 2.465496063232422, 'epoch': 9.94}
{'loss': 0.0431, 'grad_norm': 13.882661819458008, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.037461262196302414, 'loss_2': 0.005611419677734375, 'loss_3': -16.267471313476562, 'loss_4': 1.396852970123291, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 10:08:59,006 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:59,006 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:26<59:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:06,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014428782276809216, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.462, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009222808293998241, 'eval_loss_2': 0.005205973982810974, 'eval_loss_3': -18.278139114379883, 'eval_loss_4': 1.3673710823059082, 'epoch': 9.94}
{'loss': 0.0171, 'grad_norm': 6.403840065002441, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.01399726327508688, 'loss_2': 0.00311279296875, 'loss_3': -16.36443328857422, 'loss_4': 2.0433292388916016, 'epoch': 9.95}
{'loss': 0.0293, 'grad_norm': 14.839964866638184, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.02577853761613369, 'loss_2': 0.003566741943359375, 'loss_3': -16.269060134887695, 'loss_4': 1.210270643234253, 'epoch': 9.95}
{'loss': 0.0215, 'grad_norm': 5.965322017669678, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.011986864730715752, 'loss_2': 0.009490966796875, 'loss_3': -16.388050079345703, 'loss_4': 1.8403992652893066, 'epoch': 9.96}
{'loss': 0.0256, 'grad_norm': 8.810807228088379, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.023200251162052155, 'loss_2': 0.002384185791015625, 'loss_3': -16.173416137695312, 'loss_4': 1.185774803161621, 'epoch': 9.97}
{'loss': 0.0072, 'grad_norm': 4.380224227905273, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.006846179720014334, 'loss_2': 0.00037860870361328125, 'loss_3': -16.443058013916016, 'loss_4': 1.4249372482299805, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 10:09:06,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:06,353 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:33<53:25,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:09:13,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013033819384872913, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.168, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008784707635641098, 'eval_loss_2': 0.004249110817909241, 'eval_loss_3': -18.266414642333984, 'eval_loss_4': 1.469369888305664, 'epoch': 9.97}
{'loss': 0.028, 'grad_norm': 12.25015926361084, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.023804372176527977, 'loss_2': 0.0042266845703125, 'loss_3': -16.614233016967773, 'loss_4': 1.5087589025497437, 'epoch': 9.98}
{'loss': 0.0137, 'grad_norm': 7.808228015899658, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.012419129721820354, 'loss_2': 0.0013294219970703125, 'loss_3': -16.44139289855957, 'loss_4': 1.728212833404541, 'epoch': 9.98}
{'loss': 0.0178, 'grad_norm': 9.1677827835083, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.01717945747077465, 'loss_2': 0.0005750656127929688, 'loss_3': -16.613229751586914, 'loss_4': 1.8129267692565918, 'epoch': 9.99}
{'loss': 0.0344, 'grad_norm': 12.476866722106934, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.031508103013038635, 'loss_2': 0.002918243408203125, 'loss_3': -16.56450080871582, 'loss_4': 1.77175772190094, 'epoch': 9.99}
{'loss': 0.0152, 'grad_norm': 8.116789817810059, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.005197917111217976, 'loss_2': 0.010040283203125, 'loss_3': -16.40230941772461, 'loss_4': 2.086270809173584, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 10:09:13,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:13,330 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:40<58:30,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:09:20,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012262663803994656, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007239128462970257, 'eval_loss_2': 0.005023535341024399, 'eval_loss_3': -18.255653381347656, 'eval_loss_4': 1.5682696104049683, 'epoch': 10.0}
{'loss': 0.008, 'grad_norm': 4.7699809074401855, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.0075578405521810055, 'loss_2': 0.0004372596740722656, 'loss_3': -16.466262817382812, 'loss_4': 1.6063555479049683, 'epoch': 10.01}
{'loss': 0.0139, 'grad_norm': 6.5666375160217285, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.01302359439432621, 'loss_2': 0.0008950233459472656, 'loss_3': -16.080928802490234, 'loss_4': 1.7082310914993286, 'epoch': 10.01}
{'loss': 0.0238, 'grad_norm': 6.870711326599121, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.015518762171268463, 'loss_2': 0.00827789306640625, 'loss_3': -16.307945251464844, 'loss_4': 2.2811808586120605, 'epoch': 10.02}
{'loss': 0.0239, 'grad_norm': 7.047591209411621, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.016896985471248627, 'loss_2': 0.00702667236328125, 'loss_3': -16.434186935424805, 'loss_4': 2.178919553756714, 'epoch': 10.02}
{'loss': 0.0084, 'grad_norm': 5.1581292152404785, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.007596265058964491, 'loss_2': 0.0007801055908203125, 'loss_3': -16.339378356933594, 'loss_4': 1.407743215560913, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 10:09:20,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:20,709 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [42:47<59:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:09:28,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010647792369127274, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.089, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007716304622590542, 'eval_loss_2': 0.002931486815214157, 'eval_loss_3': -18.24829864501953, 'eval_loss_4': 1.66523015499115, 'epoch': 10.03}
{'loss': 0.0332, 'grad_norm': 11.967052459716797, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.02729243040084839, 'loss_2': 0.005889892578125, 'loss_3': -16.382354736328125, 'loss_4': 1.9285917282104492, 'epoch': 10.03}
{'loss': 0.0273, 'grad_norm': 7.487668037414551, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.024882949888706207, 'loss_2': 0.002414703369140625, 'loss_3': -16.519407272338867, 'loss_4': 2.4032702445983887, 'epoch': 10.04}
{'loss': 0.0063, 'grad_norm': 4.457068920135498, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.005904311314225197, 'loss_2': 0.00039887428283691406, 'loss_3': -16.355451583862305, 'loss_4': 1.9556398391723633, 'epoch': 10.05}
{'loss': 0.013, 'grad_norm': 5.919321060180664, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.011332211084663868, 'loss_2': 0.0016937255859375, 'loss_3': -16.308326721191406, 'loss_4': 1.7067832946777344, 'epoch': 10.05}
{'loss': 0.0211, 'grad_norm': 6.318272113800049, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.014187709428369999, 'loss_2': 0.006862640380859375, 'loss_3': -16.24837875366211, 'loss_4': 1.6630007028579712, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 10:09:28,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:28,045 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [42:55<59:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:35,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01201496459543705, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00786391831934452, 'eval_loss_2': 0.004151046276092529, 'eval_loss_3': -18.281299591064453, 'eval_loss_4': 1.6976215839385986, 'epoch': 10.06}
{'loss': 0.0165, 'grad_norm': 4.7300124168396, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.006510995794087648, 'loss_2': 0.0099639892578125, 'loss_3': -16.304004669189453, 'loss_4': 1.6303861141204834, 'epoch': 10.06}
{'loss': 0.0195, 'grad_norm': 9.210822105407715, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.019145363941788673, 'loss_2': 0.00030684471130371094, 'loss_3': -16.342967987060547, 'loss_4': 1.5808297395706177, 'epoch': 10.07}
{'loss': 0.0205, 'grad_norm': 9.392470359802246, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.01839420199394226, 'loss_2': 0.002063751220703125, 'loss_3': -16.296167373657227, 'loss_4': 1.7940714359283447, 'epoch': 10.08}
{'loss': 0.0378, 'grad_norm': 18.15521240234375, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.033733416348695755, 'loss_2': 0.00402069091796875, 'loss_3': -16.320539474487305, 'loss_4': 2.457373857498169, 'epoch': 10.08}
{'loss': 0.0301, 'grad_norm': 7.984018325805664, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.02459430694580078, 'loss_2': 0.005489349365234375, 'loss_3': -16.4329891204834, 'loss_4': 1.7128280401229858, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 10:09:35,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:35,374 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:02<59:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:42,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0125392721965909, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.302, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.008760249242186546, 'eval_loss_2': 0.0037790238857269287, 'eval_loss_3': -18.290328979492188, 'eval_loss_4': 1.7411690950393677, 'epoch': 10.09}
{'loss': 0.0138, 'grad_norm': 4.817684173583984, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.008265925571322441, 'loss_2': 0.00551605224609375, 'loss_3': -16.40310287475586, 'loss_4': 1.7077103853225708, 'epoch': 10.09}
{'loss': 0.0316, 'grad_norm': 8.543286323547363, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.026894211769104004, 'loss_2': 0.00466156005859375, 'loss_3': -16.254114151000977, 'loss_4': 2.365412950515747, 'epoch': 10.1}
{'loss': 0.0135, 'grad_norm': 7.5999555587768555, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.012409966439008713, 'loss_2': 0.0011081695556640625, 'loss_3': -16.162410736083984, 'loss_4': 1.8556784391403198, 'epoch': 10.1}
{'loss': 0.0179, 'grad_norm': 7.878567695617676, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.016095243394374847, 'loss_2': 0.001796722412109375, 'loss_3': -16.6059627532959, 'loss_4': 1.923454761505127, 'epoch': 10.11}
{'loss': 0.0628, 'grad_norm': 15.294532775878906, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.05436039716005325, 'loss_2': 0.00848388671875, 'loss_3': -16.168418884277344, 'loss_4': 2.1091103553771973, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 10:09:42,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:42,705 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:09<58:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:50,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01216889452189207, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.961, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008579382672905922, 'eval_loss_2': 0.0035895109176635742, 'eval_loss_3': -18.304811477661133, 'eval_loss_4': 1.623581051826477, 'epoch': 10.12}
{'loss': 0.0205, 'grad_norm': 8.333136558532715, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.01604594476521015, 'loss_2': 0.00445556640625, 'loss_3': -16.238338470458984, 'loss_4': 2.4291727542877197, 'epoch': 10.12}
{'loss': 0.0199, 'grad_norm': 10.012581825256348, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.01957128942012787, 'loss_2': 0.0003066062927246094, 'loss_3': -16.28028678894043, 'loss_4': 1.8837666511535645, 'epoch': 10.13}
{'loss': 0.0119, 'grad_norm': 4.846906661987305, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.007014053873717785, 'loss_2': 0.00489044189453125, 'loss_3': -16.301986694335938, 'loss_4': 1.991272211074829, 'epoch': 10.13}
{'loss': 0.0098, 'grad_norm': 5.761545658111572, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.00884430855512619, 'loss_2': 0.000911712646484375, 'loss_3': -16.310382843017578, 'loss_4': 1.7014249563217163, 'epoch': 10.14}
{'loss': 0.0329, 'grad_norm': 11.566390037536621, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.0299531240016222, 'loss_2': 0.002964019775390625, 'loss_3': -16.417325973510742, 'loss_4': 1.4358879327774048, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 10:09:50,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:50,037 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:17<58:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:57,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012145472690463066, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.113, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008574887178838253, 'eval_loss_2': 0.0035705864429473877, 'eval_loss_3': -18.266881942749023, 'eval_loss_4': 1.4422470331192017, 'epoch': 10.15}
{'loss': 0.0202, 'grad_norm': 6.901034832000732, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.019643107429146767, 'loss_2': 0.0005702972412109375, 'loss_3': -16.308507919311523, 'loss_4': 1.6249908208847046, 'epoch': 10.15}
{'loss': 0.0152, 'grad_norm': 6.013628005981445, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.011363858357071877, 'loss_2': 0.003875732421875, 'loss_3': -16.068866729736328, 'loss_4': 1.4336750507354736, 'epoch': 10.16}
{'loss': 0.0258, 'grad_norm': 7.136523723602295, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.022386038675904274, 'loss_2': 0.003459930419921875, 'loss_3': -16.316749572753906, 'loss_4': 1.0238499641418457, 'epoch': 10.16}
{'loss': 0.0111, 'grad_norm': 5.193733215332031, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.00943514984101057, 'loss_2': 0.0016803741455078125, 'loss_3': -16.322633743286133, 'loss_4': 0.9534693360328674, 'epoch': 10.17}
{'loss': 0.0257, 'grad_norm': 5.796276092529297, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.014628507196903229, 'loss_2': 0.0111083984375, 'loss_3': -16.529773712158203, 'loss_4': 1.7832202911376953, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 10:09:57,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:57,370 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:24<58:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:10:04,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01782708242535591, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.396, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008917856961488724, 'eval_loss_2': 0.008909225463867188, 'eval_loss_3': -18.268901824951172, 'eval_loss_4': 1.2374241352081299, 'epoch': 10.17}
{'loss': 0.0203, 'grad_norm': 5.188419342041016, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.00922122411429882, 'loss_2': 0.01110076904296875, 'loss_3': -16.398967742919922, 'loss_4': 1.3719284534454346, 'epoch': 10.18}
{'loss': 0.0107, 'grad_norm': 5.166567802429199, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.008977033197879791, 'loss_2': 0.001705169677734375, 'loss_3': -16.19449806213379, 'loss_4': 1.6884865760803223, 'epoch': 10.19}
{'loss': 0.0305, 'grad_norm': 6.632129669189453, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.014555810019373894, 'loss_2': 0.01593017578125, 'loss_3': -16.30303192138672, 'loss_4': 1.0279144048690796, 'epoch': 10.19}
{'loss': 0.0153, 'grad_norm': 4.749041557312012, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.007149174809455872, 'loss_2': 0.00812530517578125, 'loss_3': -16.37605857849121, 'loss_4': 0.5316122770309448, 'epoch': 10.2}
{'loss': 0.038, 'grad_norm': 18.647157669067383, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.03564219921827316, 'loss_2': 0.002338409423828125, 'loss_3': -16.197540283203125, 'loss_4': 0.6672263145446777, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 10:10:04,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:04,691 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:31<58:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:10:12,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015351299196481705, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.484, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.009884838946163654, 'eval_loss_2': 0.005466461181640625, 'eval_loss_3': -18.279651641845703, 'eval_loss_4': 0.8071621060371399, 'epoch': 10.2}
{'loss': 0.0147, 'grad_norm': 6.417128086090088, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.014209061861038208, 'loss_2': 0.0005235671997070312, 'loss_3': -16.086692810058594, 'loss_4': 0.746790885925293, 'epoch': 10.21}
{'loss': 0.0155, 'grad_norm': 5.401336669921875, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.011953235603868961, 'loss_2': 0.0035381317138671875, 'loss_3': -16.273283004760742, 'loss_4': 0.6904460191726685, 'epoch': 10.22}
{'loss': 0.0132, 'grad_norm': 8.288612365722656, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.012282065115869045, 'loss_2': 0.0009431838989257812, 'loss_3': -16.253782272338867, 'loss_4': 1.0476484298706055, 'epoch': 10.22}
{'loss': 0.0255, 'grad_norm': 6.678791522979736, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.02140307053923607, 'loss_2': 0.004058837890625, 'loss_3': -16.404050827026367, 'loss_4': 0.3674713671207428, 'epoch': 10.23}
{'loss': 0.0177, 'grad_norm': 6.671332836151123, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.016941945999860764, 'loss_2': 0.000762939453125, 'loss_3': -16.337472915649414, 'loss_4': 0.5224040746688843, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 10:10:12,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:12,012 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:39<58:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:19,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012576214969158173, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.008754365146160126, 'eval_loss_2': 0.003821849822998047, 'eval_loss_3': -18.25468635559082, 'eval_loss_4': 0.5152000188827515, 'epoch': 10.23}
{'loss': 0.017, 'grad_norm': 8.406612396240234, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.015067441388964653, 'loss_2': 0.0018939971923828125, 'loss_3': -16.168601989746094, 'loss_4': 0.7790151834487915, 'epoch': 10.24}
{'loss': 0.0096, 'grad_norm': 5.487363338470459, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.007335369475185871, 'loss_2': 0.0022678375244140625, 'loss_3': -16.287052154541016, 'loss_4': 0.096067413687706, 'epoch': 10.24}
{'loss': 0.0223, 'grad_norm': 7.6036376953125, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.01657058857381344, 'loss_2': 0.00574493408203125, 'loss_3': -16.15186309814453, 'loss_4': 0.7994893789291382, 'epoch': 10.25}
{'loss': 0.0235, 'grad_norm': 6.95636510848999, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.01936982199549675, 'loss_2': 0.004116058349609375, 'loss_3': -16.15055274963379, 'loss_4': 0.5796417593955994, 'epoch': 10.26}
{'loss': 0.0356, 'grad_norm': 6.155127048492432, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.022013859823346138, 'loss_2': 0.013580322265625, 'loss_3': -16.14566421508789, 'loss_4': 0.7832052111625671, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 10:10:19,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:19,345 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [43:46<58:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:26,699 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019381310790777206, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010314607992768288, 'eval_loss_2': 0.00906670093536377, 'eval_loss_3': -18.20789909362793, 'eval_loss_4': 0.48361167311668396, 'epoch': 10.26}
{'loss': 0.0203, 'grad_norm': 7.04889440536499, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.013968476094305515, 'loss_2': 0.0063629150390625, 'loss_3': -16.382339477539062, 'loss_4': 0.4458625316619873, 'epoch': 10.27}
{'loss': 0.0143, 'grad_norm': 5.351592063903809, 'learning_rate': 1.975e-05, 'loss_1': 0.008913249708712101, 'loss_2': 0.0053863525390625, 'loss_3': -16.617000579833984, 'loss_4': 1.1651207208633423, 'epoch': 10.27}
{'loss': 0.0311, 'grad_norm': 8.552895545959473, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.013893913477659225, 'loss_2': 0.0172271728515625, 'loss_3': -16.302997589111328, 'loss_4': 0.7979851365089417, 'epoch': 10.28}
{'loss': 0.0276, 'grad_norm': 5.2506914138793945, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.008455134928226471, 'loss_2': 0.019134521484375, 'loss_3': -16.26992416381836, 'loss_4': 0.71273273229599, 'epoch': 10.28}
{'loss': 0.0428, 'grad_norm': 15.230201721191406, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.04013986140489578, 'loss_2': 0.002655029296875, 'loss_3': -16.252422332763672, 'loss_4': 1.1203653812408447, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 10:10:26,699 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:26,699 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [43:53<58:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:34,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017402224242687225, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.29, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013410203158855438, 'eval_loss_2': 0.003992021083831787, 'eval_loss_3': -18.1919002532959, 'eval_loss_4': 0.7783790826797485, 'epoch': 10.29}
{'loss': 0.0142, 'grad_norm': 5.122981548309326, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.012549499981105328, 'loss_2': 0.0016155242919921875, 'loss_3': -16.4398193359375, 'loss_4': 0.9698799252510071, 'epoch': 10.3}
{'loss': 0.0114, 'grad_norm': 5.418783664703369, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.010663106106221676, 'loss_2': 0.0007233619689941406, 'loss_3': -16.250619888305664, 'loss_4': 1.134129285812378, 'epoch': 10.3}
{'loss': 0.0218, 'grad_norm': 9.38939380645752, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.019969811663031578, 'loss_2': 0.0018768310546875, 'loss_3': -16.246692657470703, 'loss_4': 1.1588091850280762, 'epoch': 10.31}
{'loss': 0.047, 'grad_norm': 22.60195541381836, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.04412966966629028, 'loss_2': 0.002841949462890625, 'loss_3': -16.13039207458496, 'loss_4': 0.557982325553894, 'epoch': 10.31}
{'loss': 0.0172, 'grad_norm': 5.743397235870361, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.01312307734042406, 'loss_2': 0.00409698486328125, 'loss_3': -16.007116317749023, 'loss_4': 0.34440797567367554, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 10:10:34,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:34,028 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:01<58:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:41,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02504800260066986, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.548, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0202204380184412, 'eval_loss_2': 0.004827558994293213, 'eval_loss_3': -18.17214584350586, 'eval_loss_4': 0.8808812499046326, 'epoch': 10.32}
{'loss': 0.0206, 'grad_norm': 7.447573184967041, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.012226720340549946, 'loss_2': 0.008331298828125, 'loss_3': -16.27865219116211, 'loss_4': 1.0567834377288818, 'epoch': 10.33}
{'loss': 0.0184, 'grad_norm': 7.276660919189453, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.014678919687867165, 'loss_2': 0.003753662109375, 'loss_3': -16.16839599609375, 'loss_4': 0.3763669431209564, 'epoch': 10.33}
{'loss': 0.0205, 'grad_norm': 4.870154857635498, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.009244612418115139, 'loss_2': 0.01120758056640625, 'loss_3': -16.277305603027344, 'loss_4': 1.241102695465088, 'epoch': 10.34}
{'loss': 0.0127, 'grad_norm': 5.428089141845703, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.007977337576448917, 'loss_2': 0.00469207763671875, 'loss_3': -16.297239303588867, 'loss_4': 0.833572268486023, 'epoch': 10.34}
{'loss': 0.0253, 'grad_norm': 9.226947784423828, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.02279660664498806, 'loss_2': 0.002521514892578125, 'loss_3': -16.042030334472656, 'loss_4': 0.6085916757583618, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 10:10:41,350 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:41,350 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:08<58:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:48,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029492322355508804, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.056, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.025805983692407608, 'eval_loss_2': 0.0036863386631011963, 'eval_loss_3': -18.147090911865234, 'eval_loss_4': 1.0249556303024292, 'epoch': 10.35}
{'loss': 0.0247, 'grad_norm': 9.092594146728516, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.023796526715159416, 'loss_2': 0.000888824462890625, 'loss_3': -16.096744537353516, 'loss_4': 1.0865331888198853, 'epoch': 10.35}
{'loss': 0.0235, 'grad_norm': 8.98235034942627, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.02296651154756546, 'loss_2': 0.0005598068237304688, 'loss_3': -16.183029174804688, 'loss_4': 1.7354544401168823, 'epoch': 10.36}
{'loss': 0.0074, 'grad_norm': 5.541361331939697, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.006880904082208872, 'loss_2': 0.0004940032958984375, 'loss_3': -16.263713836669922, 'loss_4': 0.659766435623169, 'epoch': 10.37}
{'loss': 0.0127, 'grad_norm': 4.811324596405029, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.010491907596588135, 'loss_2': 0.002227783203125, 'loss_3': -16.2231388092041, 'loss_4': 0.6158674955368042, 'epoch': 10.37}
{'loss': 0.0147, 'grad_norm': 5.016674041748047, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.010306688025593758, 'loss_2': 0.00440216064453125, 'loss_3': -16.374162673950195, 'loss_4': 1.0462170839309692, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 10:10:48,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:48,684 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:15<58:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:56,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025368213653564453, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.182, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.021939696744084358, 'eval_loss_2': 0.003428518772125244, 'eval_loss_3': -18.162704467773438, 'eval_loss_4': 1.0338813066482544, 'epoch': 10.38}
{'loss': 0.0224, 'grad_norm': 7.018615245819092, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.015644539147615433, 'loss_2': 0.0067291259765625, 'loss_3': -15.97612190246582, 'loss_4': 0.7919201850891113, 'epoch': 10.38}
{'loss': 0.0177, 'grad_norm': 9.075704574584961, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.013742232695221901, 'loss_2': 0.00397491455078125, 'loss_3': -16.35956382751465, 'loss_4': 1.0729632377624512, 'epoch': 10.39}
{'loss': 0.0224, 'grad_norm': 6.982490539550781, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.01753024011850357, 'loss_2': 0.004840850830078125, 'loss_3': -16.271337509155273, 'loss_4': 1.2473454475402832, 'epoch': 10.4}
{'loss': 0.0078, 'grad_norm': 4.889765739440918, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.007308640517294407, 'loss_2': 0.0004649162292480469, 'loss_3': -16.166025161743164, 'loss_4': 1.066770076751709, 'epoch': 10.4}
{'loss': 0.0235, 'grad_norm': 7.323089599609375, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.022961994633078575, 'loss_2': 0.00058746337890625, 'loss_3': -16.400325775146484, 'loss_4': 0.7610548734664917, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 10:10:56,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:56,025 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:23<58:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:03,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025993742048740387, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.191, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02261768840253353, 'eval_loss_2': 0.0033760517835617065, 'eval_loss_3': -18.127151489257812, 'eval_loss_4': 0.9906784296035767, 'epoch': 10.41}
{'loss': 0.0179, 'grad_norm': 6.7052998542785645, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.0147267896682024, 'loss_2': 0.00316619873046875, 'loss_3': -16.2500057220459, 'loss_4': 1.2108123302459717, 'epoch': 10.41}
{'loss': 0.0083, 'grad_norm': 4.991456031799316, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.007833593524992466, 'loss_2': 0.0004825592041015625, 'loss_3': -16.302030563354492, 'loss_4': 0.44870585203170776, 'epoch': 10.42}
{'loss': 0.0142, 'grad_norm': 5.423671722412109, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.01403655856847763, 'loss_2': 0.00020885467529296875, 'loss_3': -16.022891998291016, 'loss_4': 0.43630313873291016, 'epoch': 10.42}
{'loss': 0.0156, 'grad_norm': 5.642711639404297, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.0086084408685565, 'loss_2': 0.006988525390625, 'loss_3': -16.160213470458984, 'loss_4': 0.7413849830627441, 'epoch': 10.43}
{'loss': 0.036, 'grad_norm': 20.229923248291016, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.02713455632328987, 'loss_2': 0.008819580078125, 'loss_3': -16.33804702758789, 'loss_4': 0.8082031011581421, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 10:11:03,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:03,361 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:30<58:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:10,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021377013996243477, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.29, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.014842675998806953, 'eval_loss_2': 0.0065343379974365234, 'eval_loss_3': -18.16834259033203, 'eval_loss_4': 0.7249405980110168, 'epoch': 10.44}
{'loss': 0.0107, 'grad_norm': 4.890235900878906, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.007076016161590815, 'loss_2': 0.003635406494140625, 'loss_3': -16.287845611572266, 'loss_4': 0.8892478942871094, 'epoch': 10.44}
{'loss': 0.0313, 'grad_norm': 7.435235500335693, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.02827402949333191, 'loss_2': 0.0030155181884765625, 'loss_3': -16.10264778137207, 'loss_4': 0.2634652256965637, 'epoch': 10.45}
{'loss': 0.0327, 'grad_norm': 11.962444305419922, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.024003833532333374, 'loss_2': 0.00872802734375, 'loss_3': -16.304161071777344, 'loss_4': 0.368280827999115, 'epoch': 10.45}
{'loss': 0.0176, 'grad_norm': 5.481156349182129, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.00860614888370037, 'loss_2': 0.00902557373046875, 'loss_3': -16.2796630859375, 'loss_4': 0.5175966024398804, 'epoch': 10.46}
{'loss': 0.018, 'grad_norm': 6.030966758728027, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.012275590561330318, 'loss_2': 0.005767822265625, 'loss_3': -16.282114028930664, 'loss_4': 0.9839174747467041, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 10:11:10,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:10,716 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:37<57:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:18,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016719065606594086, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013447439298033714, 'eval_loss_2': 0.003271624445915222, 'eval_loss_3': -18.21842384338379, 'eval_loss_4': 0.500104546546936, 'epoch': 10.47}
{'loss': 0.0124, 'grad_norm': 5.598691463470459, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.011111268773674965, 'loss_2': 0.001270294189453125, 'loss_3': -16.368860244750977, 'loss_4': 0.19276198744773865, 'epoch': 10.47}
{'loss': 0.0161, 'grad_norm': 6.239837169647217, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.012967298738658428, 'loss_2': 0.003093719482421875, 'loss_3': -16.35251235961914, 'loss_4': 0.592296838760376, 'epoch': 10.48}
{'loss': 0.0194, 'grad_norm': 7.683342933654785, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.01693209446966648, 'loss_2': 0.002513885498046875, 'loss_3': -16.313030242919922, 'loss_4': 0.11948579549789429, 'epoch': 10.48}
{'loss': 0.0297, 'grad_norm': 18.340625762939453, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.026766415685415268, 'loss_2': 0.002941131591796875, 'loss_3': -16.394941329956055, 'loss_4': 0.5378119349479675, 'epoch': 10.49}
{'loss': 0.0078, 'grad_norm': 5.115547180175781, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.00750107504427433, 'loss_2': 0.00033855438232421875, 'loss_3': -16.241239547729492, 'loss_4': 0.5190720558166504, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 10:11:18,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:18,044 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [44:45<57:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:25,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017452843487262726, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.591, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014062412083148956, 'eval_loss_2': 0.0033904314041137695, 'eval_loss_3': -18.233522415161133, 'eval_loss_4': 0.4821391701698303, 'epoch': 10.49}
{'loss': 0.0211, 'grad_norm': 10.48263168334961, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.016666308045387268, 'loss_2': 0.00440216064453125, 'loss_3': -16.105710983276367, 'loss_4': -0.15008099377155304, 'epoch': 10.5}
{'loss': 0.021, 'grad_norm': 5.91406774520874, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.017047617584466934, 'loss_2': 0.00396728515625, 'loss_3': -16.117355346679688, 'loss_4': 0.3095490336418152, 'epoch': 10.51}
{'loss': 0.0454, 'grad_norm': 12.35177993774414, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.04334953427314758, 'loss_2': 0.002071380615234375, 'loss_3': -16.22713851928711, 'loss_4': 0.5885387659072876, 'epoch': 10.51}
{'loss': 0.0076, 'grad_norm': 5.509618282318115, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.006862926296889782, 'loss_2': 0.000701904296875, 'loss_3': -16.37204933166504, 'loss_4': 0.5423418283462524, 'epoch': 10.52}
{'loss': 0.0123, 'grad_norm': 6.030046463012695, 'learning_rate': 1.95e-05, 'loss_1': 0.009567531757056713, 'loss_2': 0.0027618408203125, 'loss_3': -16.199235916137695, 'loss_4': 0.6175656318664551, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 10:11:25,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:25,371 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [44:52<57:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:32,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018061373382806778, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.794, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015489358454942703, 'eval_loss_2': 0.0025720149278640747, 'eval_loss_3': -18.218029022216797, 'eval_loss_4': 0.5612539649009705, 'epoch': 10.52}
{'loss': 0.0162, 'grad_norm': 7.5766777992248535, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.01238327194005251, 'loss_2': 0.003849029541015625, 'loss_3': -16.12806510925293, 'loss_4': 0.0388321690261364, 'epoch': 10.53}
{'loss': 0.0172, 'grad_norm': 6.802148818969727, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.012606418691575527, 'loss_2': 0.00458526611328125, 'loss_3': -16.307209014892578, 'loss_4': 0.19703203439712524, 'epoch': 10.53}
{'loss': 0.0422, 'grad_norm': 9.112325668334961, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.038238365203142166, 'loss_2': 0.00400543212890625, 'loss_3': -16.161651611328125, 'loss_4': 0.5217402577400208, 'epoch': 10.54}
{'loss': 0.0229, 'grad_norm': 7.814709186553955, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.020846545696258545, 'loss_2': 0.002063751220703125, 'loss_3': -16.027225494384766, 'loss_4': 0.7953563332557678, 'epoch': 10.55}
{'loss': 0.0111, 'grad_norm': 5.4208292961120605, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.00995722133666277, 'loss_2': 0.0011892318725585938, 'loss_3': -16.174585342407227, 'loss_4': 0.9641079902648926, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 10:11:32,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:32,705 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [44:59<57:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:40,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02147117257118225, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.307, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.018233876675367355, 'eval_loss_2': 0.0032372958958148956, 'eval_loss_3': -18.194725036621094, 'eval_loss_4': 0.8204278945922852, 'epoch': 10.55}
{'loss': 0.0211, 'grad_norm': 7.629212379455566, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.019184887409210205, 'loss_2': 0.001922607421875, 'loss_3': -16.12354278564453, 'loss_4': 0.8937621116638184, 'epoch': 10.56}
{'loss': 0.019, 'grad_norm': 5.710076332092285, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.016895780339837074, 'loss_2': 0.0020847320556640625, 'loss_3': -16.3751220703125, 'loss_4': 1.1111838817596436, 'epoch': 10.56}
{'loss': 0.0321, 'grad_norm': 9.926047325134277, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.02909478172659874, 'loss_2': 0.0029850006103515625, 'loss_3': -16.160934448242188, 'loss_4': 1.4170689582824707, 'epoch': 10.57}
{'loss': 0.0164, 'grad_norm': 8.924391746520996, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.01623012311756611, 'loss_2': 0.00020599365234375, 'loss_3': -16.19654083251953, 'loss_4': 0.6437373161315918, 'epoch': 10.58}
{'loss': 0.0302, 'grad_norm': 8.195158004760742, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.022515632212162018, 'loss_2': 0.007720947265625, 'loss_3': -15.977104187011719, 'loss_4': 0.7804005742073059, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 10:11:40,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:40,033 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:07<57:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:47,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02663150615990162, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.918, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019751759245991707, 'eval_loss_2': 0.006879746913909912, 'eval_loss_3': -18.156112670898438, 'eval_loss_4': 0.9725615382194519, 'epoch': 10.58}
{'loss': 0.018, 'grad_norm': 6.227407455444336, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.011161736212670803, 'loss_2': 0.0068206787109375, 'loss_3': -16.14474105834961, 'loss_4': 0.9212707281112671, 'epoch': 10.59}
{'loss': 0.0225, 'grad_norm': 5.9270758628845215, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.013284124433994293, 'loss_2': 0.0092620849609375, 'loss_3': -16.32576560974121, 'loss_4': 0.7757648229598999, 'epoch': 10.59}
{'loss': 0.021, 'grad_norm': 8.040764808654785, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.018962297588586807, 'loss_2': 0.0020294189453125, 'loss_3': -16.133159637451172, 'loss_4': 1.0661484003067017, 'epoch': 10.6}
{'loss': 0.0191, 'grad_norm': 7.772798538208008, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.018432293087244034, 'loss_2': 0.0007171630859375, 'loss_3': -16.313322067260742, 'loss_4': 1.0184869766235352, 'epoch': 10.6}
{'loss': 0.02, 'grad_norm': 6.905290126800537, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.017427455633878708, 'loss_2': 0.0026073455810546875, 'loss_3': -16.042377471923828, 'loss_4': 0.9831773042678833, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 10:11:47,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:47,375 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:14<57:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:54,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019565820693969727, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017288297414779663, 'eval_loss_2': 0.0022775232791900635, 'eval_loss_3': -18.156396865844727, 'eval_loss_4': 1.112359642982483, 'epoch': 10.61}
{'loss': 0.0377, 'grad_norm': 12.141349792480469, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.033519621938467026, 'loss_2': 0.00421142578125, 'loss_3': -16.374526977539062, 'loss_4': 1.711064338684082, 'epoch': 10.62}
{'loss': 0.0229, 'grad_norm': 8.516031265258789, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.021341480314731598, 'loss_2': 0.0016031265258789062, 'loss_3': -16.224224090576172, 'loss_4': 1.1800618171691895, 'epoch': 10.62}
{'loss': 0.0232, 'grad_norm': 20.618968963623047, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.022858258336782455, 'loss_2': 0.0003533363342285156, 'loss_3': -16.17372703552246, 'loss_4': 0.8845516443252563, 'epoch': 10.63}
{'loss': 0.0083, 'grad_norm': 5.718696594238281, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.007793027441948652, 'loss_2': 0.0005321502685546875, 'loss_3': -16.268508911132812, 'loss_4': 1.1289352178573608, 'epoch': 10.63}
{'loss': 0.0407, 'grad_norm': 7.670654773712158, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.0388621985912323, 'loss_2': 0.00180816650390625, 'loss_3': -16.26075553894043, 'loss_4': 1.863064169883728, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 10:11:54,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:54,714 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:21<57:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:02,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013166209682822227, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.072, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010346071794629097, 'eval_loss_2': 0.0028201378881931305, 'eval_loss_3': -18.255672454833984, 'eval_loss_4': 1.5091100931167603, 'epoch': 10.64}
{'loss': 0.0247, 'grad_norm': 8.874882698059082, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.024184372276067734, 'loss_2': 0.000518798828125, 'loss_3': -16.31739044189453, 'loss_4': 1.3825654983520508, 'epoch': 10.65}
{'loss': 0.0217, 'grad_norm': 7.055225372314453, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.019074978306889534, 'loss_2': 0.00262451171875, 'loss_3': -16.137779235839844, 'loss_4': 1.9832841157913208, 'epoch': 10.65}
{'loss': 0.0365, 'grad_norm': 15.146055221557617, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.03510414808988571, 'loss_2': 0.0014057159423828125, 'loss_3': -16.289207458496094, 'loss_4': 2.2990012168884277, 'epoch': 10.66}
{'loss': 0.0191, 'grad_norm': 7.5838704109191895, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.018944934010505676, 'loss_2': 0.00018668174743652344, 'loss_3': -16.167661666870117, 'loss_4': 2.2307114601135254, 'epoch': 10.66}
{'loss': 0.0291, 'grad_norm': 9.444235801696777, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.02354268729686737, 'loss_2': 0.00554656982421875, 'loss_3': -16.37861442565918, 'loss_4': 2.273930072784424, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 10:12:02,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:02,043 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:29<57:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:09,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013317606411874294, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.103, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010262927040457726, 'eval_loss_2': 0.003054678440093994, 'eval_loss_3': -18.260393142700195, 'eval_loss_4': 1.9718735218048096, 'epoch': 10.67}
{'loss': 0.0335, 'grad_norm': 8.126251220703125, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.02585640177130699, 'loss_2': 0.00768280029296875, 'loss_3': -16.1160945892334, 'loss_4': 2.50189471244812, 'epoch': 10.67}
{'loss': 0.0196, 'grad_norm': 7.7675323486328125, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.01610529236495495, 'loss_2': 0.00353240966796875, 'loss_3': -16.129606246948242, 'loss_4': 2.8274288177490234, 'epoch': 10.68}
{'loss': 0.0251, 'grad_norm': 9.687287330627441, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.018951380625367165, 'loss_2': 0.0061187744140625, 'loss_3': -15.986573219299316, 'loss_4': 2.4730589389801025, 'epoch': 10.69}
{'loss': 0.0167, 'grad_norm': 9.769826889038086, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.01604333706200123, 'loss_2': 0.0007023811340332031, 'loss_3': -16.110610961914062, 'loss_4': 2.156834602355957, 'epoch': 10.69}
{'loss': 0.0171, 'grad_norm': 5.992919445037842, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.01350314449518919, 'loss_2': 0.0035495758056640625, 'loss_3': -16.359142303466797, 'loss_4': 2.8122801780700684, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 10:12:09,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:09,373 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:36<57:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:16,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013578885234892368, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.902, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010130488313734531, 'eval_loss_2': 0.003448396921157837, 'eval_loss_3': -18.27989959716797, 'eval_loss_4': 2.440368175506592, 'epoch': 10.7}
{'loss': 0.0144, 'grad_norm': 4.692823886871338, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.004856969229876995, 'loss_2': 0.009521484375, 'loss_3': -16.372013092041016, 'loss_4': 2.6431589126586914, 'epoch': 10.7}
{'loss': 0.0346, 'grad_norm': 11.484057426452637, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.027831755578517914, 'loss_2': 0.006763458251953125, 'loss_3': -16.236492156982422, 'loss_4': 2.819180488586426, 'epoch': 10.71}
{'loss': 0.0151, 'grad_norm': 7.39645528793335, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.012704476714134216, 'loss_2': 0.00237274169921875, 'loss_3': -16.33392333984375, 'loss_4': 2.668466806411743, 'epoch': 10.72}
{'loss': 0.031, 'grad_norm': 9.884932518005371, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.025646409019827843, 'loss_2': 0.005382537841796875, 'loss_3': -16.230268478393555, 'loss_4': 2.827552080154419, 'epoch': 10.72}
{'loss': 0.0123, 'grad_norm': 5.50814962387085, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.012295987457036972, 'loss_2': 4.887580871582031e-05, 'loss_3': -16.115379333496094, 'loss_4': 2.841735363006592, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 10:12:16,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:16,712 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [45:43<57:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:24,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01360377948731184, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.022, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.00917011871933937, 'eval_loss_2': 0.004433661699295044, 'eval_loss_3': -18.29568099975586, 'eval_loss_4': 2.6587233543395996, 'epoch': 10.73}
{'loss': 0.0134, 'grad_norm': 5.242707252502441, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.011869573034346104, 'loss_2': 0.001491546630859375, 'loss_3': -16.105682373046875, 'loss_4': 2.960083484649658, 'epoch': 10.73}
{'loss': 0.0269, 'grad_norm': 14.793351173400879, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.02315272018313408, 'loss_2': 0.003726959228515625, 'loss_3': -16.423259735107422, 'loss_4': 3.355876922607422, 'epoch': 10.74}
{'loss': 0.0135, 'grad_norm': 6.1792120933532715, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.012712829746305943, 'loss_2': 0.0007371902465820312, 'loss_3': -16.15913963317871, 'loss_4': 2.5563433170318604, 'epoch': 10.74}
{'loss': 0.0216, 'grad_norm': 7.272329330444336, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.018505526706576347, 'loss_2': 0.003086090087890625, 'loss_3': -16.212940216064453, 'loss_4': 3.236532688140869, 'epoch': 10.75}
{'loss': 0.0212, 'grad_norm': 7.423303127288818, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.02115166373550892, 'loss_2': 1.2040138244628906e-05, 'loss_3': -16.521419525146484, 'loss_4': 3.181286334991455, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 10:12:24,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:24,047 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [45:51<57:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:31,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012970604933798313, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009549596346914768, 'eval_loss_2': 0.003421008586883545, 'eval_loss_3': -18.301895141601562, 'eval_loss_4': 2.4349474906921387, 'epoch': 10.76}
{'loss': 0.0178, 'grad_norm': 4.6964569091796875, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.0059448047541081905, 'loss_2': 0.01183319091796875, 'loss_3': -16.304983139038086, 'loss_4': 2.7725253105163574, 'epoch': 10.76}
{'loss': 0.0196, 'grad_norm': 9.565450668334961, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.014552381820976734, 'loss_2': 0.00501251220703125, 'loss_3': -16.458328247070312, 'loss_4': 2.154397964477539, 'epoch': 10.77}
{'loss': 0.0241, 'grad_norm': 8.176939010620117, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.017077278345823288, 'loss_2': 0.00702667236328125, 'loss_3': -16.342252731323242, 'loss_4': 2.6618618965148926, 'epoch': 10.77}
{'loss': 0.0166, 'grad_norm': 6.5078325271606445, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.013943827711045742, 'loss_2': 0.0027027130126953125, 'loss_3': -16.28948974609375, 'loss_4': 3.0197207927703857, 'epoch': 10.78}
{'loss': 0.0126, 'grad_norm': 5.338281154632568, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.009044304490089417, 'loss_2': 0.0035877227783203125, 'loss_3': -16.335302352905273, 'loss_4': 1.9695653915405273, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 10:12:31,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:31,385 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [45:58<57:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:38,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012859218753874302, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.161, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.009658090770244598, 'eval_loss_2': 0.003201127052307129, 'eval_loss_3': -18.302295684814453, 'eval_loss_4': 2.2885537147521973, 'epoch': 10.78}
{'loss': 0.0148, 'grad_norm': 5.293121337890625, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.013313373550772667, 'loss_2': 0.0014972686767578125, 'loss_3': -16.3798885345459, 'loss_4': 2.84513783454895, 'epoch': 10.79}
{'loss': 0.02, 'grad_norm': 5.721441745758057, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.01096682995557785, 'loss_2': 0.009002685546875, 'loss_3': -16.492801666259766, 'loss_4': 2.82977294921875, 'epoch': 10.8}
{'loss': 0.025, 'grad_norm': 7.592288494110107, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.01980798877775669, 'loss_2': 0.00521087646484375, 'loss_3': -16.33502960205078, 'loss_4': 2.4041666984558105, 'epoch': 10.8}
{'loss': 0.0348, 'grad_norm': 12.981598854064941, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.029553774744272232, 'loss_2': 0.0052490234375, 'loss_3': -16.40426254272461, 'loss_4': 2.531132698059082, 'epoch': 10.81}
{'loss': 0.0207, 'grad_norm': 6.426491737365723, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.018584005534648895, 'loss_2': 0.0021228790283203125, 'loss_3': -16.369800567626953, 'loss_4': 2.2543139457702637, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 10:12:38,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:38,718 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:05<57:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:46,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014712486416101456, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010250364430248737, 'eval_loss_2': 0.004462122917175293, 'eval_loss_3': -18.31357765197754, 'eval_loss_4': 2.1508145332336426, 'epoch': 10.81}
{'loss': 0.0163, 'grad_norm': 5.328943252563477, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.010508342646062374, 'loss_2': 0.00579833984375, 'loss_3': -16.469974517822266, 'loss_4': 2.557742118835449, 'epoch': 10.82}
{'loss': 0.0112, 'grad_norm': 5.073063850402832, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.006956545636057854, 'loss_2': 0.0041961669921875, 'loss_3': -16.582088470458984, 'loss_4': 1.9269115924835205, 'epoch': 10.83}
{'loss': 0.0129, 'grad_norm': 5.503000736236572, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.008160395547747612, 'loss_2': 0.004734039306640625, 'loss_3': -16.453094482421875, 'loss_4': 2.0705487728118896, 'epoch': 10.83}
{'loss': 0.0224, 'grad_norm': 7.991265773773193, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.017989713698625565, 'loss_2': 0.004364013671875, 'loss_3': -16.181562423706055, 'loss_4': 1.6095657348632812, 'epoch': 10.84}
{'loss': 0.0193, 'grad_norm': 6.839908123016357, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.012535659596323967, 'loss_2': 0.00677490234375, 'loss_3': -16.43886947631836, 'loss_4': 2.0918867588043213, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 10:12:46,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:46,062 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:13<56:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:53,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014858143404126167, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.825, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010290877893567085, 'eval_loss_2': 0.004567265510559082, 'eval_loss_3': -18.30882453918457, 'eval_loss_4': 1.8652353286743164, 'epoch': 10.84}
{'loss': 0.0149, 'grad_norm': 7.150367259979248, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.009581287391483784, 'loss_2': 0.0052947998046875, 'loss_3': -16.287031173706055, 'loss_4': 2.196920871734619, 'epoch': 10.85}
{'loss': 0.0128, 'grad_norm': 5.270208835601807, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.009898129850625992, 'loss_2': 0.0029048919677734375, 'loss_3': -16.388587951660156, 'loss_4': 1.926412582397461, 'epoch': 10.85}
{'loss': 0.0157, 'grad_norm': 5.838332176208496, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.015349401161074638, 'loss_2': 0.0003612041473388672, 'loss_3': -16.282337188720703, 'loss_4': 1.970686674118042, 'epoch': 10.86}
{'loss': 0.0116, 'grad_norm': 6.124402046203613, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.009019192308187485, 'loss_2': 0.0025615692138671875, 'loss_3': -16.468704223632812, 'loss_4': 1.7269978523254395, 'epoch': 10.87}
{'loss': 0.0173, 'grad_norm': 5.661157131195068, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.011326361447572708, 'loss_2': 0.00594329833984375, 'loss_3': -16.500118255615234, 'loss_4': 2.03824520111084, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 10:12:53,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:53,397 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:20<56:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:00,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012912421487271786, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010275987908244133, 'eval_loss_2': 0.002636432647705078, 'eval_loss_3': -18.279756546020508, 'eval_loss_4': 1.5953378677368164, 'epoch': 10.87}
{'loss': 0.0185, 'grad_norm': 9.98173999786377, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.01830059476196766, 'loss_2': 0.00022113323211669922, 'loss_3': -16.507755279541016, 'loss_4': 2.03594970703125, 'epoch': 10.88}
{'loss': 0.0158, 'grad_norm': 6.087392330169678, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.015017434023320675, 'loss_2': 0.0007843971252441406, 'loss_3': -16.306745529174805, 'loss_4': 1.878033995628357, 'epoch': 10.88}
{'loss': 0.0352, 'grad_norm': 14.848956108093262, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.034613706171512604, 'loss_2': 0.0005950927734375, 'loss_3': -16.390426635742188, 'loss_4': 2.179656505584717, 'epoch': 10.89}
{'loss': 0.0122, 'grad_norm': 6.128912925720215, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.010914620943367481, 'loss_2': 0.0012903213500976562, 'loss_3': -16.47971534729004, 'loss_4': 1.5712034702301025, 'epoch': 10.9}
{'loss': 0.0132, 'grad_norm': 5.187904357910156, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.008787301369011402, 'loss_2': 0.004405975341796875, 'loss_3': -16.51227378845215, 'loss_4': 1.4930202960968018, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 10:13:00,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:00,731 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:27<56:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:08,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015274730511009693, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.97, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01242734119296074, 'eval_loss_2': 0.0028473883867263794, 'eval_loss_3': -18.273176193237305, 'eval_loss_4': 1.525689959526062, 'epoch': 10.9}
{'loss': 0.0214, 'grad_norm': 7.185341835021973, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.013925410807132721, 'loss_2': 0.0074462890625, 'loss_3': -16.304691314697266, 'loss_4': 1.693602442741394, 'epoch': 10.91}
{'loss': 0.0193, 'grad_norm': 7.238430023193359, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.01600436493754387, 'loss_2': 0.0032482147216796875, 'loss_3': -16.23256492614746, 'loss_4': 1.6847981214523315, 'epoch': 10.91}
{'loss': 0.0213, 'grad_norm': 6.986800193786621, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.013262015767395496, 'loss_2': 0.0080718994140625, 'loss_3': -16.452491760253906, 'loss_4': 1.4995968341827393, 'epoch': 10.92}
{'loss': 0.0256, 'grad_norm': 8.625472068786621, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.02000054344534874, 'loss_2': 0.0056304931640625, 'loss_3': -16.425582885742188, 'loss_4': 1.198460578918457, 'epoch': 10.92}
{'loss': 0.0159, 'grad_norm': 6.706557273864746, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.013597328215837479, 'loss_2': 0.0022563934326171875, 'loss_3': -16.514076232910156, 'loss_4': 0.9257469773292542, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 10:13:08,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:08,065 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:35<56:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:15,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014230655506253242, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.714, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011755109764635563, 'eval_loss_2': 0.002475544810295105, 'eval_loss_3': -18.278247833251953, 'eval_loss_4': 1.4497934579849243, 'epoch': 10.93}
{'loss': 0.0158, 'grad_norm': 6.118008613586426, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.013846088200807571, 'loss_2': 0.001956939697265625, 'loss_3': -16.47419548034668, 'loss_4': 1.644078016281128, 'epoch': 10.94}
{'loss': 0.0293, 'grad_norm': 11.53279972076416, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.025436514988541603, 'loss_2': 0.0038509368896484375, 'loss_3': -16.35515022277832, 'loss_4': 1.8828680515289307, 'epoch': 10.94}
{'loss': 0.0328, 'grad_norm': 8.625587463378906, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.026586459949612617, 'loss_2': 0.00618743896484375, 'loss_3': -16.327796936035156, 'loss_4': 1.991875171661377, 'epoch': 10.95}
{'loss': 0.019, 'grad_norm': 6.875901699066162, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.01210580114275217, 'loss_2': 0.0068817138671875, 'loss_3': -16.216075897216797, 'loss_4': 1.659409523010254, 'epoch': 10.95}
{'loss': 0.0217, 'grad_norm': 7.688906192779541, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.013602734543383121, 'loss_2': 0.008087158203125, 'loss_3': -16.73039436340332, 'loss_4': 2.245349407196045, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 10:13:15,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:15,403 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [46:42<56:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:22,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01627328246831894, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.437, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.010250468738377094, 'eval_loss_2': 0.006022810935974121, 'eval_loss_3': -18.28476333618164, 'eval_loss_4': 1.5425575971603394, 'epoch': 10.96}
{'loss': 0.0135, 'grad_norm': 5.597549915313721, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.012960657477378845, 'loss_2': 0.000514984130859375, 'loss_3': -16.409818649291992, 'loss_4': 1.5754313468933105, 'epoch': 10.97}
{'loss': 0.0209, 'grad_norm': 9.26727294921875, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.018407128751277924, 'loss_2': 0.0024814605712890625, 'loss_3': -16.319080352783203, 'loss_4': 1.7117538452148438, 'epoch': 10.97}
{'loss': 0.0248, 'grad_norm': 8.479838371276855, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.018290620297193527, 'loss_2': 0.006481170654296875, 'loss_3': -16.675439834594727, 'loss_4': 1.813948154449463, 'epoch': 10.98}
{'loss': 0.0211, 'grad_norm': 8.822741508483887, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.01835985668003559, 'loss_2': 0.00278472900390625, 'loss_3': -16.354646682739258, 'loss_4': 1.53253173828125, 'epoch': 10.98}
{'loss': 0.0183, 'grad_norm': 8.039838790893555, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.0177446436136961, 'loss_2': 0.0005831718444824219, 'loss_3': -16.24211883544922, 'loss_4': 2.0770397186279297, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 10:13:22,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:22,729 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [46:49<54:40,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 10:13:29,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01263329479843378, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.081, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00995823834091425, 'eval_loss_2': 0.0026750564575195312, 'eval_loss_3': -18.293378829956055, 'eval_loss_4': 1.5687800645828247, 'epoch': 10.99}
{'loss': 0.0075, 'grad_norm': 4.945644378662109, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.0060905697755515575, 'loss_2': 0.001373291015625, 'loss_3': -16.42399024963379, 'loss_4': 2.1343002319335938, 'epoch': 10.99}
{'loss': 0.0128, 'grad_norm': 6.163790702819824, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.00403479253873229, 'loss_2': 0.008758544921875, 'loss_3': -16.533052444458008, 'loss_4': 2.0361979007720947, 'epoch': 11.0}
{'loss': 0.0159, 'grad_norm': 7.7196784019470215, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.011874489486217499, 'loss_2': 0.003997802734375, 'loss_3': -16.489967346191406, 'loss_4': 2.230106830596924, 'epoch': 11.01}
{'loss': 0.0242, 'grad_norm': 6.579671859741211, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.013541609048843384, 'loss_2': 0.01062774658203125, 'loss_3': -16.317485809326172, 'loss_4': 1.7003588676452637, 'epoch': 11.01}
{'loss': 0.0172, 'grad_norm': 5.996323585510254, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.008630477823317051, 'loss_2': 0.0085296630859375, 'loss_3': -16.32326316833496, 'loss_4': 1.5658202171325684, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 10:13:29,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:29,742 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [46:56<55:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:13:37,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017933612689375877, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010895316489040852, 'eval_loss_2': 0.007038295269012451, 'eval_loss_3': -18.31171226501465, 'eval_loss_4': 1.4881548881530762, 'epoch': 11.02}
{'loss': 0.0151, 'grad_norm': 7.154543876647949, 'learning_rate': 1.9e-05, 'loss_1': 0.011318371631205082, 'loss_2': 0.003787994384765625, 'loss_3': -16.34231185913086, 'loss_4': 1.3968322277069092, 'epoch': 11.02}
{'loss': 0.0289, 'grad_norm': 8.446924209594727, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.022535176947712898, 'loss_2': 0.0063629150390625, 'loss_3': -16.519123077392578, 'loss_4': 2.188664436340332, 'epoch': 11.03}
{'loss': 0.0108, 'grad_norm': 5.095514297485352, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.00691559724509716, 'loss_2': 0.0038928985595703125, 'loss_3': -16.21193504333496, 'loss_4': 1.5295889377593994, 'epoch': 11.03}
{'loss': 0.0226, 'grad_norm': 8.267419815063477, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.014100585132837296, 'loss_2': 0.00853729248046875, 'loss_3': -16.33588218688965, 'loss_4': 2.3158926963806152, 'epoch': 11.04}
{'loss': 0.0116, 'grad_norm': 5.572413921356201, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.010736553929746151, 'loss_2': 0.0008678436279296875, 'loss_3': -16.40877342224121, 'loss_4': 1.6531658172607422, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 10:13:37,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:37,073 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:04<56:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:44,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013882706873118877, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.011548098176717758, 'eval_loss_2': 0.002334609627723694, 'eval_loss_3': -18.29355239868164, 'eval_loss_4': 1.3873568773269653, 'epoch': 11.05}
{'loss': 0.0219, 'grad_norm': 8.570116996765137, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.02125364914536476, 'loss_2': 0.0006155967712402344, 'loss_3': -16.367034912109375, 'loss_4': 1.6797704696655273, 'epoch': 11.05}
{'loss': 0.0225, 'grad_norm': 9.225410461425781, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.020615139976143837, 'loss_2': 0.0019245147705078125, 'loss_3': -16.437837600708008, 'loss_4': 1.9088879823684692, 'epoch': 11.06}
{'loss': 0.0084, 'grad_norm': 5.347859859466553, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.007660292088985443, 'loss_2': 0.0007238388061523438, 'loss_3': -16.534412384033203, 'loss_4': 1.4097408056259155, 'epoch': 11.06}
{'loss': 0.0168, 'grad_norm': 6.392332077026367, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.014226604253053665, 'loss_2': 0.0025730133056640625, 'loss_3': -16.264347076416016, 'loss_4': 1.637660026550293, 'epoch': 11.07}
{'loss': 0.0244, 'grad_norm': 8.8250093460083, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.01979224756360054, 'loss_2': 0.004581451416015625, 'loss_3': -16.555469512939453, 'loss_4': 1.9532933235168457, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 10:13:44,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:44,403 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:11<56:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:51,762 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01439694594591856, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.222, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011920077726244926, 'eval_loss_2': 0.002476867288351059, 'eval_loss_3': -18.302635192871094, 'eval_loss_4': 1.3441821336746216, 'epoch': 11.08}
{'loss': 0.0192, 'grad_norm': 10.529475212097168, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.017420440912246704, 'loss_2': 0.0017480850219726562, 'loss_3': -16.340373992919922, 'loss_4': 1.7724609375, 'epoch': 11.08}
{'loss': 0.0084, 'grad_norm': 5.333074569702148, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.008270778693258762, 'loss_2': 8.767843246459961e-05, 'loss_3': -16.189319610595703, 'loss_4': 1.339397668838501, 'epoch': 11.09}
{'loss': 0.0146, 'grad_norm': 5.4383463859558105, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.010737107135355473, 'loss_2': 0.00390625, 'loss_3': -16.3746280670166, 'loss_4': 1.2833880186080933, 'epoch': 11.09}
{'loss': 0.0495, 'grad_norm': 20.28950309753418, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.04732583090662956, 'loss_2': 0.0021820068359375, 'loss_3': -16.46548080444336, 'loss_4': 1.5934935808181763, 'epoch': 11.1}
{'loss': 0.0636, 'grad_norm': 20.366262435913086, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.06256799399852753, 'loss_2': 0.0009937286376953125, 'loss_3': -16.378440856933594, 'loss_4': 1.4248371124267578, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 10:13:51,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:51,762 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:18<56:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:59,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01936154253780842, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.196, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013187156990170479, 'eval_loss_2': 0.0061743855476379395, 'eval_loss_3': -18.276363372802734, 'eval_loss_4': 1.453723669052124, 'epoch': 11.1}
{'loss': 0.0153, 'grad_norm': 7.025444507598877, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.014291121624410152, 'loss_2': 0.0009775161743164062, 'loss_3': -16.23192024230957, 'loss_4': 1.2808393239974976, 'epoch': 11.11}
{'loss': 0.0273, 'grad_norm': 14.481842994689941, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.0255414005368948, 'loss_2': 0.0018024444580078125, 'loss_3': -16.221553802490234, 'loss_4': 1.413743257522583, 'epoch': 11.12}
{'loss': 0.0249, 'grad_norm': 6.552748203277588, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.013838796876370907, 'loss_2': 0.0110626220703125, 'loss_3': -16.296775817871094, 'loss_4': 1.665018916130066, 'epoch': 11.12}
{'loss': 0.0156, 'grad_norm': 6.568339824676514, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.011964801698923111, 'loss_2': 0.003627777099609375, 'loss_3': -16.346452713012695, 'loss_4': 1.6407411098480225, 'epoch': 11.13}
{'loss': 0.0205, 'grad_norm': 8.503602027893066, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.018175141885876656, 'loss_2': 0.0023097991943359375, 'loss_3': -16.19428825378418, 'loss_4': 1.8075040578842163, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 10:13:59,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:59,092 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:26<55:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:06,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01899481937289238, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.274, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.011952054686844349, 'eval_loss_2': 0.0070427656173706055, 'eval_loss_3': -18.231163024902344, 'eval_loss_4': 1.5370430946350098, 'epoch': 11.13}
{'loss': 0.0197, 'grad_norm': 7.28336238861084, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.014703375287353992, 'loss_2': 0.004985809326171875, 'loss_3': -16.184219360351562, 'loss_4': 1.8062078952789307, 'epoch': 11.14}
{'loss': 0.0157, 'grad_norm': 6.206857204437256, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.011225638911128044, 'loss_2': 0.00452423095703125, 'loss_3': -16.25283432006836, 'loss_4': 1.760322093963623, 'epoch': 11.15}
{'loss': 0.0114, 'grad_norm': 4.398535251617432, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.008541434071958065, 'loss_2': 0.002849578857421875, 'loss_3': -16.32241439819336, 'loss_4': 1.217602014541626, 'epoch': 11.15}
{'loss': 0.0104, 'grad_norm': 5.418898582458496, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.009088967926800251, 'loss_2': 0.0012683868408203125, 'loss_3': -16.30756378173828, 'loss_4': 1.3227972984313965, 'epoch': 11.16}
{'loss': 0.0188, 'grad_norm': 9.383341789245605, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.014467567205429077, 'loss_2': 0.004375457763671875, 'loss_3': -16.426448822021484, 'loss_4': 1.726958990097046, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 10:14:06,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:06,423 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:33<55:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:13,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014455730095505714, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01245307270437479, 'eval_loss_2': 0.0020026564598083496, 'eval_loss_3': -18.205183029174805, 'eval_loss_4': 1.575927734375, 'epoch': 11.16}
{'loss': 0.0075, 'grad_norm': 5.241793632507324, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.00627879286184907, 'loss_2': 0.0012683868408203125, 'loss_3': -16.415496826171875, 'loss_4': 2.1715645790100098, 'epoch': 11.17}
{'loss': 0.0189, 'grad_norm': 9.651261329650879, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.016866492107510567, 'loss_2': 0.0020580291748046875, 'loss_3': -16.309078216552734, 'loss_4': 1.8303015232086182, 'epoch': 11.17}
{'loss': 0.0071, 'grad_norm': 4.615200042724609, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.004371300805360079, 'loss_2': 0.002750396728515625, 'loss_3': -16.367801666259766, 'loss_4': 1.6753685474395752, 'epoch': 11.18}
{'loss': 0.038, 'grad_norm': 9.797106742858887, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.02263800799846649, 'loss_2': 0.0153350830078125, 'loss_3': -16.249771118164062, 'loss_4': 1.560434103012085, 'epoch': 11.19}
{'loss': 0.0195, 'grad_norm': 6.9659953117370605, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.014296681620180607, 'loss_2': 0.005157470703125, 'loss_3': -16.14597511291504, 'loss_4': 1.6160304546356201, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 10:14:13,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:13,764 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:40<55:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:21,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017034996300935745, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.236, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013863551430404186, 'eval_loss_2': 0.0031714439392089844, 'eval_loss_3': -18.189350128173828, 'eval_loss_4': 1.5151991844177246, 'epoch': 11.19}
{'loss': 0.0206, 'grad_norm': 5.979211807250977, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.010199150070548058, 'loss_2': 0.01042938232421875, 'loss_3': -16.462282180786133, 'loss_4': 1.6610970497131348, 'epoch': 11.2}
{'loss': 0.0177, 'grad_norm': 7.274604797363281, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.016906550154089928, 'loss_2': 0.000774383544921875, 'loss_3': -16.33588218688965, 'loss_4': 1.6193866729736328, 'epoch': 11.2}
{'loss': 0.0302, 'grad_norm': 5.890195846557617, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.012825884856283665, 'loss_2': 0.0173492431640625, 'loss_3': -16.11261558532715, 'loss_4': 1.849353313446045, 'epoch': 11.21}
{'loss': 0.0173, 'grad_norm': 7.237764835357666, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.014437487348914146, 'loss_2': 0.002834320068359375, 'loss_3': -16.427942276000977, 'loss_4': 1.986302375793457, 'epoch': 11.22}
{'loss': 0.0106, 'grad_norm': 5.947729587554932, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.008732747286558151, 'loss_2': 0.0018434524536132812, 'loss_3': -16.411094665527344, 'loss_4': 1.085105061531067, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 10:14:21,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:21,090 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [47:48<55:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:28,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01512129232287407, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.903, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013107995502650738, 'eval_loss_2': 0.002013295888900757, 'eval_loss_3': -18.169742584228516, 'eval_loss_4': 1.44217050075531, 'epoch': 11.22}
{'loss': 0.0111, 'grad_norm': 4.957351207733154, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.005091649014502764, 'loss_2': 0.00597381591796875, 'loss_3': -16.249881744384766, 'loss_4': 1.6800835132598877, 'epoch': 11.23}
{'loss': 0.0094, 'grad_norm': 5.859198093414307, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.008640251122415066, 'loss_2': 0.0007152557373046875, 'loss_3': -16.310102462768555, 'loss_4': 1.6432867050170898, 'epoch': 11.23}
{'loss': 0.0098, 'grad_norm': 5.895526885986328, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.009741561487317085, 'loss_2': 3.904104232788086e-05, 'loss_3': -16.18124008178711, 'loss_4': 1.765460729598999, 'epoch': 11.24}
{'loss': 0.0069, 'grad_norm': 4.6799845695495605, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.0058095864951610565, 'loss_2': 0.0010700225830078125, 'loss_3': -16.199504852294922, 'loss_4': 0.8722336292266846, 'epoch': 11.24}
{'loss': 0.0132, 'grad_norm': 5.470416069030762, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.01076702680438757, 'loss_2': 0.002437591552734375, 'loss_3': -16.289947509765625, 'loss_4': 1.2843581438064575, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 10:14:28,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:28,434 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [47:55<55:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:35,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015153076499700546, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.423, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.012862023897469044, 'eval_loss_2': 0.002291053533554077, 'eval_loss_3': -18.129350662231445, 'eval_loss_4': 1.5018788576126099, 'epoch': 11.25}
{'loss': 0.0223, 'grad_norm': 7.939270973205566, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.016677215695381165, 'loss_2': 0.00559234619140625, 'loss_3': -16.16242218017578, 'loss_4': 1.498159646987915, 'epoch': 11.26}
{'loss': 0.0157, 'grad_norm': 7.40814733505249, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.014633606187999249, 'loss_2': 0.0010995864868164062, 'loss_3': -16.32241439819336, 'loss_4': 1.8158259391784668, 'epoch': 11.26}
{'loss': 0.0151, 'grad_norm': 8.574007987976074, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.01425014529377222, 'loss_2': 0.000843048095703125, 'loss_3': -16.048267364501953, 'loss_4': 1.4079251289367676, 'epoch': 11.27}
{'loss': 0.0089, 'grad_norm': 5.436042308807373, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.008748050779104233, 'loss_2': 0.00017714500427246094, 'loss_3': -16.025474548339844, 'loss_4': 1.5211275815963745, 'epoch': 11.27}
{'loss': 0.0169, 'grad_norm': 7.94104528427124, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.015228728763759136, 'loss_2': 0.0016222000122070312, 'loss_3': -16.257356643676758, 'loss_4': 2.221803665161133, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 10:14:35,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:35,786 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:02<55:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:43,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014102190732955933, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.838, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011886111460626125, 'eval_loss_2': 0.0022160783410072327, 'eval_loss_3': -18.135746002197266, 'eval_loss_4': 1.5748233795166016, 'epoch': 11.28}
{'loss': 0.0123, 'grad_norm': 6.053203582763672, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.009663458913564682, 'loss_2': 0.002651214599609375, 'loss_3': -16.21627426147461, 'loss_4': 1.5793094635009766, 'epoch': 11.28}
{'loss': 0.0287, 'grad_norm': 12.476484298706055, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.02827865071594715, 'loss_2': 0.0004038810729980469, 'loss_3': -16.360868453979492, 'loss_4': 1.8877860307693481, 'epoch': 11.29}
{'loss': 0.0243, 'grad_norm': 9.726887702941895, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.020298724994063377, 'loss_2': 0.0040283203125, 'loss_3': -16.01502227783203, 'loss_4': 2.2243642807006836, 'epoch': 11.3}
{'loss': 0.0208, 'grad_norm': 5.706008434295654, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.012518413364887238, 'loss_2': 0.00823211669921875, 'loss_3': -16.168060302734375, 'loss_4': 1.541090726852417, 'epoch': 11.3}
{'loss': 0.011, 'grad_norm': 6.660886287689209, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.009761943481862545, 'loss_2': 0.0012750625610351562, 'loss_3': -16.2001953125, 'loss_4': 1.8236808776855469, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 10:14:43,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:43,123 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:10<55:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:50,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014446381479501724, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.28, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01241752877831459, 'eval_loss_2': 0.002028852701187134, 'eval_loss_3': -18.147178649902344, 'eval_loss_4': 1.4896796941757202, 'epoch': 11.31}
{'loss': 0.0169, 'grad_norm': 5.971379280090332, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.014203782193362713, 'loss_2': 0.0027008056640625, 'loss_3': -16.24062728881836, 'loss_4': 1.9921901226043701, 'epoch': 11.31}
{'loss': 0.0203, 'grad_norm': 7.60822868347168, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.017334286123514175, 'loss_2': 0.002979278564453125, 'loss_3': -16.57338523864746, 'loss_4': 1.357893943786621, 'epoch': 11.32}
{'loss': 0.0115, 'grad_norm': 5.620377063751221, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.009008429013192654, 'loss_2': 0.002460479736328125, 'loss_3': -16.287755966186523, 'loss_4': 1.8669377565383911, 'epoch': 11.33}
{'loss': 0.0268, 'grad_norm': 7.205592155456543, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.021091818809509277, 'loss_2': 0.0057373046875, 'loss_3': -16.323423385620117, 'loss_4': 1.1792144775390625, 'epoch': 11.33}
{'loss': 0.0279, 'grad_norm': 8.477433204650879, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.01967594213783741, 'loss_2': 0.0081787109375, 'loss_3': -16.406871795654297, 'loss_4': 1.5102819204330444, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 10:14:50,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:50,453 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:17<55:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:57,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0171956904232502, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.15, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013329911977052689, 'eval_loss_2': 0.0038657784461975098, 'eval_loss_3': -18.155508041381836, 'eval_loss_4': 1.5715633630752563, 'epoch': 11.34}
{'loss': 0.0187, 'grad_norm': 9.944766998291016, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.014055765233933926, 'loss_2': 0.0046234130859375, 'loss_3': -16.532405853271484, 'loss_4': 2.0585551261901855, 'epoch': 11.34}
{'loss': 0.0168, 'grad_norm': 7.467973232269287, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.015155154280364513, 'loss_2': 0.0016841888427734375, 'loss_3': -16.11136245727539, 'loss_4': 1.8135371208190918, 'epoch': 11.35}
{'loss': 0.0228, 'grad_norm': 8.447837829589844, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.01639595627784729, 'loss_2': 0.006404876708984375, 'loss_3': -16.129255294799805, 'loss_4': 2.6392369270324707, 'epoch': 11.35}
{'loss': 0.0093, 'grad_norm': 5.664401531219482, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.008810725063085556, 'loss_2': 0.00047206878662109375, 'loss_3': -16.203935623168945, 'loss_4': 1.4769593477249146, 'epoch': 11.36}
{'loss': 0.0088, 'grad_norm': 4.8926849365234375, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.00498516671359539, 'loss_2': 0.0037994384765625, 'loss_3': -16.08278465270996, 'loss_4': 1.9031496047973633, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 10:14:57,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:57,786 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:24<55:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:15:05,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015460014343261719, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.335, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011488855816423893, 'eval_loss_2': 0.0039711594581604, 'eval_loss_3': -18.193735122680664, 'eval_loss_4': 1.6366631984710693, 'epoch': 11.37}
{'loss': 0.0275, 'grad_norm': 13.398445129394531, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.023955782875418663, 'loss_2': 0.0035400390625, 'loss_3': -16.064605712890625, 'loss_4': 1.7418373823165894, 'epoch': 11.37}
{'loss': 0.0156, 'grad_norm': 7.131333351135254, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.01045982912182808, 'loss_2': 0.0051422119140625, 'loss_3': -16.29649543762207, 'loss_4': 1.5748672485351562, 'epoch': 11.38}
{'loss': 0.0211, 'grad_norm': 6.894172191619873, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.01757550984621048, 'loss_2': 0.0034942626953125, 'loss_3': -16.331571578979492, 'loss_4': 1.6942346096038818, 'epoch': 11.38}
{'loss': 0.019, 'grad_norm': 9.237756729125977, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.015929028391838074, 'loss_2': 0.00312042236328125, 'loss_3': -16.122840881347656, 'loss_4': 1.7135419845581055, 'epoch': 11.39}
{'loss': 0.0138, 'grad_norm': 6.23847770690918, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.010804413817822933, 'loss_2': 0.002948760986328125, 'loss_3': -16.072153091430664, 'loss_4': 1.3575663566589355, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 10:15:05,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:05,114 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:32<55:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:12,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016955817118287086, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013286644592881203, 'eval_loss_2': 0.003669172525405884, 'eval_loss_3': -18.222415924072266, 'eval_loss_4': 1.6589463949203491, 'epoch': 11.4}
{'loss': 0.018, 'grad_norm': 5.6249237060546875, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.014302386902272701, 'loss_2': 0.0036907196044921875, 'loss_3': -16.463512420654297, 'loss_4': 2.211892604827881, 'epoch': 11.4}
{'loss': 0.0123, 'grad_norm': 5.608609199523926, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.011981986463069916, 'loss_2': 0.0003123283386230469, 'loss_3': -16.257747650146484, 'loss_4': 2.022164821624756, 'epoch': 11.41}
{'loss': 0.0223, 'grad_norm': 5.647693157196045, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.011394437402486801, 'loss_2': 0.01093292236328125, 'loss_3': -16.227031707763672, 'loss_4': 1.776432991027832, 'epoch': 11.41}
{'loss': 0.0135, 'grad_norm': 7.579512596130371, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.01218358613550663, 'loss_2': 0.001277923583984375, 'loss_3': -16.40216827392578, 'loss_4': 1.549920678138733, 'epoch': 11.42}
{'loss': 0.0162, 'grad_norm': 6.279506683349609, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.012103516608476639, 'loss_2': 0.00412750244140625, 'loss_3': -16.30599594116211, 'loss_4': 2.000523805618286, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 10:15:12,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:12,460 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:39<55:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:19,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017606932669878006, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012937599793076515, 'eval_loss_2': 0.0046693310141563416, 'eval_loss_3': -18.235837936401367, 'eval_loss_4': 1.5441293716430664, 'epoch': 11.42}
{'loss': 0.0158, 'grad_norm': 7.031922340393066, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.013308331370353699, 'loss_2': 0.002532958984375, 'loss_3': -16.234561920166016, 'loss_4': 1.9703500270843506, 'epoch': 11.43}
{'loss': 0.0149, 'grad_norm': 7.595185279846191, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.012717209756374359, 'loss_2': 0.002162933349609375, 'loss_3': -16.235563278198242, 'loss_4': 1.589561939239502, 'epoch': 11.44}
{'loss': 0.0115, 'grad_norm': 5.005068302154541, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.008950761519372463, 'loss_2': 0.002506256103515625, 'loss_3': -16.28501319885254, 'loss_4': 1.6336723566055298, 'epoch': 11.44}
{'loss': 0.0142, 'grad_norm': 6.510787010192871, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.013405314646661282, 'loss_2': 0.0008001327514648438, 'loss_3': -16.23644256591797, 'loss_4': 1.7379616498947144, 'epoch': 11.45}
{'loss': 0.0321, 'grad_norm': 10.569845199584961, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.03125402331352234, 'loss_2': 0.0008344650268554688, 'loss_3': -16.444618225097656, 'loss_4': 1.5376229286193848, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 10:15:19,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:19,801 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [48:46<55:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:27,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017455613240599632, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.463, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012172974646091461, 'eval_loss_2': 0.00528264045715332, 'eval_loss_3': -18.257949829101562, 'eval_loss_4': 1.5335063934326172, 'epoch': 11.45}
{'loss': 0.0309, 'grad_norm': 10.340914726257324, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.02904360555112362, 'loss_2': 0.0018367767333984375, 'loss_3': -16.37066078186035, 'loss_4': 2.2963037490844727, 'epoch': 11.46}
{'loss': 0.0121, 'grad_norm': 4.983277797698975, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.010094638913869858, 'loss_2': 0.001964569091796875, 'loss_3': -16.326297760009766, 'loss_4': 2.1448121070861816, 'epoch': 11.47}
{'loss': 0.038, 'grad_norm': 18.756763458251953, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.030273333191871643, 'loss_2': 0.00771331787109375, 'loss_3': -16.076812744140625, 'loss_4': 1.2018051147460938, 'epoch': 11.47}
{'loss': 0.034, 'grad_norm': 9.398273468017578, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.028120439499616623, 'loss_2': 0.0059051513671875, 'loss_3': -16.416908264160156, 'loss_4': 1.7847750186920166, 'epoch': 11.48}
{'loss': 0.0155, 'grad_norm': 4.262824058532715, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.008192835375666618, 'loss_2': 0.0072784423828125, 'loss_3': -16.479461669921875, 'loss_4': 2.1023623943328857, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 10:15:27,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:27,133 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [48:54<54:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:34,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021784409880638123, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.132, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012518271803855896, 'eval_loss_2': 0.009266138076782227, 'eval_loss_3': -18.26608657836914, 'eval_loss_4': 1.5666170120239258, 'epoch': 11.48}
{'loss': 0.0235, 'grad_norm': 6.0743865966796875, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.014007032848894596, 'loss_2': 0.0094451904296875, 'loss_3': -16.26456069946289, 'loss_4': 1.681382417678833, 'epoch': 11.49}
{'loss': 0.0241, 'grad_norm': 5.020036697387695, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.008736487478017807, 'loss_2': 0.01532745361328125, 'loss_3': -16.467082977294922, 'loss_4': 1.691172480583191, 'epoch': 11.49}
{'loss': 0.0261, 'grad_norm': 8.53697395324707, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.024498306214809418, 'loss_2': 0.001560211181640625, 'loss_3': -16.3142147064209, 'loss_4': 1.838564395904541, 'epoch': 11.5}
{'loss': 0.0208, 'grad_norm': 7.904973030090332, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.016342956572771072, 'loss_2': 0.004467010498046875, 'loss_3': -16.34833335876465, 'loss_4': 2.0753870010375977, 'epoch': 11.51}
{'loss': 0.0153, 'grad_norm': 6.342533588409424, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.01115497201681137, 'loss_2': 0.004100799560546875, 'loss_3': -16.455596923828125, 'loss_4': 2.2667593955993652, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 10:15:34,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:34,469 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:01<54:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:41,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015122967772185802, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.182, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012372198514640331, 'eval_loss_2': 0.002750769257545471, 'eval_loss_3': -18.282573699951172, 'eval_loss_4': 1.6682595014572144, 'epoch': 11.51}
{'loss': 0.0435, 'grad_norm': 14.3494291305542, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.0401611402630806, 'loss_2': 0.003376007080078125, 'loss_3': -16.173023223876953, 'loss_4': 2.0431694984436035, 'epoch': 11.52}
{'loss': 0.0157, 'grad_norm': 6.839454174041748, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.014551038853824139, 'loss_2': 0.0011806488037109375, 'loss_3': -16.23177719116211, 'loss_4': 1.3117682933807373, 'epoch': 11.52}
{'loss': 0.0184, 'grad_norm': 7.714428901672363, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.015881095081567764, 'loss_2': 0.0025634765625, 'loss_3': -16.366498947143555, 'loss_4': 1.9026514291763306, 'epoch': 11.53}
{'loss': 0.02, 'grad_norm': 8.055160522460938, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.013192843645811081, 'loss_2': 0.00678253173828125, 'loss_3': -16.078720092773438, 'loss_4': 1.7071974277496338, 'epoch': 11.53}
{'loss': 0.0146, 'grad_norm': 5.70445442199707, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.012933945283293724, 'loss_2': 0.001628875732421875, 'loss_3': -16.16814613342285, 'loss_4': 1.8963873386383057, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 10:15:41,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:41,792 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:08<54:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:49,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014962250366806984, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.494, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.011824931018054485, 'eval_loss_2': 0.0031373202800750732, 'eval_loss_3': -18.268598556518555, 'eval_loss_4': 1.5295836925506592, 'epoch': 11.54}
{'loss': 0.0181, 'grad_norm': 5.353954315185547, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.01643478125333786, 'loss_2': 0.001678466796875, 'loss_3': -16.254688262939453, 'loss_4': 1.7895097732543945, 'epoch': 11.55}
{'loss': 0.0197, 'grad_norm': 8.236395835876465, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.016875501722097397, 'loss_2': 0.0027828216552734375, 'loss_3': -16.25448226928711, 'loss_4': 1.3483600616455078, 'epoch': 11.55}
{'loss': 0.014, 'grad_norm': 5.443896293640137, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.011358026415109634, 'loss_2': 0.002681732177734375, 'loss_3': -16.37681770324707, 'loss_4': 2.3950154781341553, 'epoch': 11.56}
{'loss': 0.0119, 'grad_norm': 5.815935134887695, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.010531798005104065, 'loss_2': 0.0013980865478515625, 'loss_3': -16.354633331298828, 'loss_4': 1.4923385381698608, 'epoch': 11.56}
{'loss': 0.0211, 'grad_norm': 8.941272735595703, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.01981915533542633, 'loss_2': 0.0012874603271484375, 'loss_3': -16.211708068847656, 'loss_4': 1.4113132953643799, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 10:15:49,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:49,124 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:16<54:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:56,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01532568596303463, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.891, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010237683542072773, 'eval_loss_2': 0.005088001489639282, 'eval_loss_3': -18.275691986083984, 'eval_loss_4': 1.3558564186096191, 'epoch': 11.57}
{'loss': 0.0208, 'grad_norm': 7.041610240936279, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.016943924129009247, 'loss_2': 0.00385284423828125, 'loss_3': -16.3087158203125, 'loss_4': 1.462038516998291, 'epoch': 11.58}
{'loss': 0.0134, 'grad_norm': 6.113307952880859, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.012248428538441658, 'loss_2': 0.0011577606201171875, 'loss_3': -16.238222122192383, 'loss_4': 1.5921450853347778, 'epoch': 11.58}
{'loss': 0.0268, 'grad_norm': 6.70763635635376, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.023917172104120255, 'loss_2': 0.002857208251953125, 'loss_3': -16.303462982177734, 'loss_4': 1.4349830150604248, 'epoch': 11.59}
{'loss': 0.0251, 'grad_norm': 8.419045448303223, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.023742420598864555, 'loss_2': 0.00133514404296875, 'loss_3': -16.491512298583984, 'loss_4': 1.375882625579834, 'epoch': 11.59}
{'loss': 0.0159, 'grad_norm': 5.6402268409729, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.010355785489082336, 'loss_2': 0.005550384521484375, 'loss_3': -16.393386840820312, 'loss_4': 1.225216269493103, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 10:15:56,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:56,463 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:23<54:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:03,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013804011046886444, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.974, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010702663101255894, 'eval_loss_2': 0.003101348876953125, 'eval_loss_3': -18.271263122558594, 'eval_loss_4': 1.3104658126831055, 'epoch': 11.6}
{'loss': 0.0145, 'grad_norm': 6.498381614685059, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.012020952999591827, 'loss_2': 0.002460479736328125, 'loss_3': -16.253582000732422, 'loss_4': 1.5919438600540161, 'epoch': 11.6}
{'loss': 0.0182, 'grad_norm': 7.744434356689453, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.015659362077713013, 'loss_2': 0.0025424957275390625, 'loss_3': -16.348648071289062, 'loss_4': 1.7669172286987305, 'epoch': 11.61}
{'loss': 0.0439, 'grad_norm': 17.184276580810547, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.04101438447833061, 'loss_2': 0.0029163360595703125, 'loss_3': -16.383846282958984, 'loss_4': 1.2047595977783203, 'epoch': 11.62}
{'loss': 0.0269, 'grad_norm': 10.434052467346191, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.026413530111312866, 'loss_2': 0.0005016326904296875, 'loss_3': -16.09038734436035, 'loss_4': 1.3558781147003174, 'epoch': 11.62}
{'loss': 0.023, 'grad_norm': 6.758840560913086, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.012842196971178055, 'loss_2': 0.01015472412109375, 'loss_3': -16.115909576416016, 'loss_4': 1.8155698776245117, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 10:16:03,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:03,802 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:30<54:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:11,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013819420710206032, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.876, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010238999500870705, 'eval_loss_2': 0.003580421209335327, 'eval_loss_3': -18.240816116333008, 'eval_loss_4': 1.1644113063812256, 'epoch': 11.63}
{'loss': 0.0167, 'grad_norm': 7.8502936363220215, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.015056867152452469, 'loss_2': 0.0016727447509765625, 'loss_3': -16.32624626159668, 'loss_4': 1.5014737844467163, 'epoch': 11.63}
{'loss': 0.0589, 'grad_norm': 22.554222106933594, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.0535101518034935, 'loss_2': 0.005401611328125, 'loss_3': -16.150936126708984, 'loss_4': 1.141632080078125, 'epoch': 11.64}
{'loss': 0.0188, 'grad_norm': 6.233069896697998, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.014421195723116398, 'loss_2': 0.004352569580078125, 'loss_3': -16.291427612304688, 'loss_4': 1.4357876777648926, 'epoch': 11.65}
{'loss': 0.095, 'grad_norm': 13.90907096862793, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.09181319177150726, 'loss_2': 0.00323486328125, 'loss_3': -16.05845069885254, 'loss_4': 1.5851079225540161, 'epoch': 11.65}
{'loss': 0.0151, 'grad_norm': 5.449391841888428, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.01140725426375866, 'loss_2': 0.00366973876953125, 'loss_3': -16.146846771240234, 'loss_4': 1.679573655128479, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 10:16:11,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:11,147 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:38<54:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:18,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017177630215883255, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.131, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013228491879999638, 'eval_loss_2': 0.003949139267206192, 'eval_loss_3': -18.239673614501953, 'eval_loss_4': 0.9579907655715942, 'epoch': 11.66}
{'loss': 0.0332, 'grad_norm': 12.796327590942383, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.025333240628242493, 'loss_2': 0.0078277587890625, 'loss_3': -16.19091033935547, 'loss_4': 1.4045710563659668, 'epoch': 11.66}
{'loss': 0.019, 'grad_norm': 7.807714462280273, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.01641981117427349, 'loss_2': 0.002593994140625, 'loss_3': -16.41928482055664, 'loss_4': 1.4665019512176514, 'epoch': 11.67}
{'loss': 0.0184, 'grad_norm': 6.868465423583984, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.017124053090810776, 'loss_2': 0.0012874603271484375, 'loss_3': -16.22357177734375, 'loss_4': 1.0612801313400269, 'epoch': 11.67}
{'loss': 0.0233, 'grad_norm': 6.168489456176758, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.016281215474009514, 'loss_2': 0.00699615478515625, 'loss_3': -16.456993103027344, 'loss_4': 1.0096689462661743, 'epoch': 11.68}
{'loss': 0.0174, 'grad_norm': 6.837960720062256, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.017163816839456558, 'loss_2': 0.0002818107604980469, 'loss_3': -16.198131561279297, 'loss_4': 1.3167779445648193, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 10:16:18,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:18,481 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [49:45<54:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:25,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024101924151182175, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.325, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.020943643525242805, 'eval_loss_2': 0.00315827876329422, 'eval_loss_3': -18.220123291015625, 'eval_loss_4': 0.8660741448402405, 'epoch': 11.69}
{'loss': 0.0292, 'grad_norm': 12.197293281555176, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.0259922556579113, 'loss_2': 0.0032215118408203125, 'loss_3': -16.250263214111328, 'loss_4': 1.1746634244918823, 'epoch': 11.69}
{'loss': 0.0388, 'grad_norm': 18.087806701660156, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.03801995515823364, 'loss_2': 0.0007686614990234375, 'loss_3': -16.307706832885742, 'loss_4': 1.2330851554870605, 'epoch': 11.7}
{'loss': 0.0218, 'grad_norm': 7.733183860778809, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.01698974519968033, 'loss_2': 0.004779815673828125, 'loss_3': -16.165821075439453, 'loss_4': 1.0762226581573486, 'epoch': 11.7}
{'loss': 0.0272, 'grad_norm': 6.7567853927612305, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.022053569555282593, 'loss_2': 0.00516510009765625, 'loss_3': -16.15008544921875, 'loss_4': 1.0323525667190552, 'epoch': 11.71}
{'loss': 0.0229, 'grad_norm': 9.001508712768555, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.021178264170885086, 'loss_2': 0.0017137527465820312, 'loss_3': -16.248220443725586, 'loss_4': 1.243343710899353, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 10:16:25,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:25,809 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [49:52<54:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:33,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03674484044313431, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.030025489628314972, 'eval_loss_2': 0.006719350814819336, 'eval_loss_3': -18.15430450439453, 'eval_loss_4': 1.0089983940124512, 'epoch': 11.72}
{'loss': 0.0149, 'grad_norm': 6.357889175415039, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.013900356367230415, 'loss_2': 0.0010385513305664062, 'loss_3': -16.213558197021484, 'loss_4': 1.3690096139907837, 'epoch': 11.72}
{'loss': 0.0527, 'grad_norm': 18.41655731201172, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.044212520122528076, 'loss_2': 0.008453369140625, 'loss_3': -16.185213088989258, 'loss_4': 0.9861308336257935, 'epoch': 11.73}
{'loss': 0.0192, 'grad_norm': 4.747659683227539, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.008386501111090183, 'loss_2': 0.01078033447265625, 'loss_3': -16.251792907714844, 'loss_4': 1.434470772743225, 'epoch': 11.73}
{'loss': 0.0469, 'grad_norm': 10.705769538879395, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.03405609354376793, 'loss_2': 0.012847900390625, 'loss_3': -16.244470596313477, 'loss_4': 1.9873740673065186, 'epoch': 11.74}
{'loss': 0.0206, 'grad_norm': 6.231474876403809, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.017281923443078995, 'loss_2': 0.0032901763916015625, 'loss_3': -16.1351318359375, 'loss_4': 1.1742709875106812, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 10:16:33,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:33,156 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:00<54:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:40,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04273901507258415, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.03680086508393288, 'eval_loss_2': 0.005938142538070679, 'eval_loss_3': -18.154006958007812, 'eval_loss_4': 1.2617212533950806, 'epoch': 11.74}
{'loss': 0.0318, 'grad_norm': 12.790786743164062, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.026517678052186966, 'loss_2': 0.0053253173828125, 'loss_3': -16.18123435974121, 'loss_4': 1.6399521827697754, 'epoch': 11.75}
{'loss': 0.0206, 'grad_norm': 5.545706748962402, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.01384406816214323, 'loss_2': 0.00679779052734375, 'loss_3': -16.435684204101562, 'loss_4': 1.6076246500015259, 'epoch': 11.76}
{'loss': 0.0117, 'grad_norm': 5.1113104820251465, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.010644487105309963, 'loss_2': 0.0010223388671875, 'loss_3': -16.40669822692871, 'loss_4': 1.0852081775665283, 'epoch': 11.76}
{'loss': 0.035, 'grad_norm': 12.810949325561523, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.02731449343264103, 'loss_2': 0.007678985595703125, 'loss_3': -16.192737579345703, 'loss_4': 1.8684587478637695, 'epoch': 11.77}
{'loss': 0.0349, 'grad_norm': 14.756194114685059, 'learning_rate': 1.825e-05, 'loss_1': 0.025297783315181732, 'loss_2': 0.0096435546875, 'loss_3': -16.388729095458984, 'loss_4': 1.601691722869873, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 10:16:40,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:40,508 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:07<54:50,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:16:48,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026555165648460388, 'eval_runtime': 3.9788, 'eval_samples_per_second': 257.366, 'eval_steps_per_second': 4.021, 'eval_loss_1': 0.02297796681523323, 'eval_loss_2': 0.003577202558517456, 'eval_loss_3': -18.21695327758789, 'eval_loss_4': 1.304057240486145, 'epoch': 11.77}
{'loss': 0.0179, 'grad_norm': 5.520928859710693, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.010596856474876404, 'loss_2': 0.00731658935546875, 'loss_3': -16.028783798217773, 'loss_4': 1.5667884349822998, 'epoch': 11.78}
{'loss': 0.0401, 'grad_norm': 12.441032409667969, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.033976368606090546, 'loss_2': 0.00611114501953125, 'loss_3': -16.33428192138672, 'loss_4': 2.171853542327881, 'epoch': 11.78}
{'loss': 0.0104, 'grad_norm': 5.170662879943848, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.008682751096785069, 'loss_2': 0.0016803741455078125, 'loss_3': -16.438636779785156, 'loss_4': 1.2647548913955688, 'epoch': 11.79}
{'loss': 0.0192, 'grad_norm': 5.465056419372559, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.012500523589551449, 'loss_2': 0.0066680908203125, 'loss_3': -16.045822143554688, 'loss_4': 1.529866337776184, 'epoch': 11.8}
{'loss': 0.0318, 'grad_norm': 16.0487117767334, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.030256623402237892, 'loss_2': 0.001529693603515625, 'loss_3': -16.40699005126953, 'loss_4': 1.9308334589004517, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 10:16:48,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:48,034 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:15<54:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:55,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013497505336999893, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.091, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01139245554804802, 'eval_loss_2': 0.0021050497889518738, 'eval_loss_3': -18.29192352294922, 'eval_loss_4': 1.5043591260910034, 'epoch': 11.8}
{'loss': 0.0245, 'grad_norm': 5.165716648101807, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.01267323363572359, 'loss_2': 0.01177978515625, 'loss_3': -16.166213989257812, 'loss_4': 1.751093864440918, 'epoch': 11.81}
{'loss': 0.0315, 'grad_norm': 9.343537330627441, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.02707422897219658, 'loss_2': 0.00444793701171875, 'loss_3': -16.274839401245117, 'loss_4': 1.5979011058807373, 'epoch': 11.81}
{'loss': 0.0287, 'grad_norm': 12.97905158996582, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.028297238051891327, 'loss_2': 0.0003581047058105469, 'loss_3': -16.137832641601562, 'loss_4': 2.6678004264831543, 'epoch': 11.82}
{'loss': 0.024, 'grad_norm': 7.966012477874756, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.01852177083492279, 'loss_2': 0.005489349365234375, 'loss_3': -16.337984085083008, 'loss_4': 2.0604031085968018, 'epoch': 11.83}
{'loss': 0.0112, 'grad_norm': 8.388168334960938, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.011053377762436867, 'loss_2': 0.00019288063049316406, 'loss_3': -16.303104400634766, 'loss_4': 1.641645908355713, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 10:16:55,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:55,368 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:22<53:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:02,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01758669503033161, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010465013794600964, 'eval_loss_2': 0.007121682167053223, 'eval_loss_3': -18.267385482788086, 'eval_loss_4': 1.7436268329620361, 'epoch': 11.83}
{'loss': 0.0165, 'grad_norm': 6.711777687072754, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.015942582860589027, 'loss_2': 0.0005626678466796875, 'loss_3': -16.108348846435547, 'loss_4': 2.214700698852539, 'epoch': 11.84}
{'loss': 0.0371, 'grad_norm': 12.970820426940918, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.028287213295698166, 'loss_2': 0.00884246826171875, 'loss_3': -16.124645233154297, 'loss_4': 2.3592164516448975, 'epoch': 11.84}
{'loss': 0.0147, 'grad_norm': 6.060892581939697, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.01131165400147438, 'loss_2': 0.0033550262451171875, 'loss_3': -16.308109283447266, 'loss_4': 2.2219884395599365, 'epoch': 11.85}
{'loss': 0.0595, 'grad_norm': 15.614489555358887, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.04913116991519928, 'loss_2': 0.010345458984375, 'loss_3': -16.265087127685547, 'loss_4': 2.242133378982544, 'epoch': 11.85}
{'loss': 0.0117, 'grad_norm': 6.061285972595215, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.011520365253090858, 'loss_2': 0.00017642974853515625, 'loss_3': -16.410858154296875, 'loss_4': 2.3429555892944336, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 10:17:02,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:02,703 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:29<53:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:10,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01565822772681713, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010152190923690796, 'eval_loss_2': 0.005506038665771484, 'eval_loss_3': -18.287729263305664, 'eval_loss_4': 1.983931064605713, 'epoch': 11.86}
{'loss': 0.0122, 'grad_norm': 5.518085956573486, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.008465168066322803, 'loss_2': 0.00368499755859375, 'loss_3': -16.253686904907227, 'loss_4': 2.704141855239868, 'epoch': 11.87}
{'loss': 0.0148, 'grad_norm': 7.247311592102051, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.012281207367777824, 'loss_2': 0.00251007080078125, 'loss_3': -16.178686141967773, 'loss_4': 2.2189829349517822, 'epoch': 11.87}
{'loss': 0.0156, 'grad_norm': 7.375736236572266, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.013263479806482792, 'loss_2': 0.002346038818359375, 'loss_3': -16.34382438659668, 'loss_4': 2.504249095916748, 'epoch': 11.88}
{'loss': 0.0213, 'grad_norm': 5.925196647644043, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.009887457825243473, 'loss_2': 0.0113983154296875, 'loss_3': -16.15664291381836, 'loss_4': 2.3386430740356445, 'epoch': 11.88}
{'loss': 0.0214, 'grad_norm': 6.158229351043701, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.012448524124920368, 'loss_2': 0.00891876220703125, 'loss_3': -16.42648696899414, 'loss_4': 2.0874245166778564, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 10:17:10,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:10,045 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:37<53:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:17,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013120048679411411, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009624866768717766, 'eval_loss_2': 0.00349518284201622, 'eval_loss_3': -18.270885467529297, 'eval_loss_4': 1.8850576877593994, 'epoch': 11.89}
{'loss': 0.0136, 'grad_norm': 9.357473373413086, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.012951333075761795, 'loss_2': 0.0006632804870605469, 'loss_3': -16.180156707763672, 'loss_4': 2.645617961883545, 'epoch': 11.9}
{'loss': 0.0151, 'grad_norm': 6.214107036590576, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.013074101880192757, 'loss_2': 0.00199127197265625, 'loss_3': -16.248857498168945, 'loss_4': 2.8027966022491455, 'epoch': 11.9}
{'loss': 0.0123, 'grad_norm': 5.780006408691406, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.008206046186387539, 'loss_2': 0.00405120849609375, 'loss_3': -16.37567138671875, 'loss_4': 2.2262518405914307, 'epoch': 11.91}
{'loss': 0.0135, 'grad_norm': 8.124811172485352, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.013205388560891151, 'loss_2': 0.0003314018249511719, 'loss_3': -16.26321029663086, 'loss_4': 1.294339656829834, 'epoch': 11.91}
{'loss': 0.0284, 'grad_norm': 15.023496627807617, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.021997472271323204, 'loss_2': 0.00635528564453125, 'loss_3': -16.30818748474121, 'loss_4': 1.759283185005188, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 10:17:17,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:17,403 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [50:44<53:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:24,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012018311768770218, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009690451435744762, 'eval_loss_2': 0.002327859401702881, 'eval_loss_3': -18.271257400512695, 'eval_loss_4': 1.5980286598205566, 'epoch': 11.92}
{'loss': 0.0069, 'grad_norm': 5.09560489654541, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.006176610477268696, 'loss_2': 0.0007410049438476562, 'loss_3': -16.219141006469727, 'loss_4': 1.9175001382827759, 'epoch': 11.92}
{'loss': 0.0161, 'grad_norm': 5.621036529541016, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.010652046650648117, 'loss_2': 0.00548553466796875, 'loss_3': -16.139310836791992, 'loss_4': 1.690321922302246, 'epoch': 11.93}
{'loss': 0.0158, 'grad_norm': 6.326356410980225, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.011216653510928154, 'loss_2': 0.004543304443359375, 'loss_3': -16.28374481201172, 'loss_4': 2.212238073348999, 'epoch': 11.94}
{'loss': 0.0093, 'grad_norm': 5.375894546508789, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.008374787867069244, 'loss_2': 0.0009617805480957031, 'loss_3': -16.365325927734375, 'loss_4': 2.248429775238037, 'epoch': 11.94}
{'loss': 0.0122, 'grad_norm': 5.137389659881592, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.011689536273479462, 'loss_2': 0.0005087852478027344, 'loss_3': -16.253829956054688, 'loss_4': 2.3525190353393555, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 10:17:24,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:24,747 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [50:51<53:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:32,091 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013950293883681297, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010599039494991302, 'eval_loss_2': 0.003351256251335144, 'eval_loss_3': -18.28493881225586, 'eval_loss_4': 1.409972906112671, 'epoch': 11.95}
{'loss': 0.0246, 'grad_norm': 5.413026332855225, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.0139017878100276, 'loss_2': 0.010711669921875, 'loss_3': -16.324682235717773, 'loss_4': 1.2505617141723633, 'epoch': 11.95}
{'loss': 0.0136, 'grad_norm': 5.9356184005737305, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.010348610579967499, 'loss_2': 0.0032749176025390625, 'loss_3': -16.3557071685791, 'loss_4': 1.9486198425292969, 'epoch': 11.96}
{'loss': 0.0176, 'grad_norm': 7.620608329772949, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.015798067674040794, 'loss_2': 0.0018291473388671875, 'loss_3': -16.451637268066406, 'loss_4': 2.1330971717834473, 'epoch': 11.97}
{'loss': 0.0446, 'grad_norm': 26.33623695373535, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.03579806908965111, 'loss_2': 0.0088043212890625, 'loss_3': -16.337045669555664, 'loss_4': 1.1445618867874146, 'epoch': 11.97}
{'loss': 0.0205, 'grad_norm': 12.791810989379883, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.013532369397580624, 'loss_2': 0.00693511962890625, 'loss_3': -16.33442497253418, 'loss_4': 1.463012456893921, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 10:17:32,091 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:32,092 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [50:58<50:20,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:17:39,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013420846313238144, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.04, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010543625801801682, 'eval_loss_2': 0.0028772205114364624, 'eval_loss_3': -18.283321380615234, 'eval_loss_4': 1.3187583684921265, 'epoch': 11.98}
{'loss': 0.0395, 'grad_norm': 12.873043060302734, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.034648895263671875, 'loss_2': 0.00481414794921875, 'loss_3': -16.085878372192383, 'loss_4': 2.0867421627044678, 'epoch': 11.98}
{'loss': 0.0161, 'grad_norm': 5.578410625457764, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.008337440900504589, 'loss_2': 0.00780487060546875, 'loss_3': -16.399703979492188, 'loss_4': 1.491109013557434, 'epoch': 11.99}
{'loss': 0.0236, 'grad_norm': 9.791007995605469, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.019983267411589622, 'loss_2': 0.003650665283203125, 'loss_3': -16.288293838500977, 'loss_4': 1.8984732627868652, 'epoch': 11.99}
{'loss': 0.0105, 'grad_norm': 9.565964698791504, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.008592752739787102, 'loss_2': 0.0018901824951171875, 'loss_3': -16.187238693237305, 'loss_4': 0.7583242058753967, 'epoch': 12.0}
{'loss': 0.0328, 'grad_norm': 15.016865730285645, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.031480029225349426, 'loss_2': 0.0012912750244140625, 'loss_3': -16.22231674194336, 'loss_4': 2.0083401203155518, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 10:17:39,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:39,115 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:06<52:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:17:46,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014506218954920769, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010493815876543522, 'eval_loss_2': 0.004012402147054672, 'eval_loss_3': -18.288393020629883, 'eval_loss_4': 1.3532603979110718, 'epoch': 12.01}
{'loss': 0.0253, 'grad_norm': 13.46517562866211, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.01867312379181385, 'loss_2': 0.00666046142578125, 'loss_3': -16.19883918762207, 'loss_4': 1.918959617614746, 'epoch': 12.01}
{'loss': 0.0129, 'grad_norm': 5.029411792755127, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.0063452087342739105, 'loss_2': 0.006526947021484375, 'loss_3': -16.48826789855957, 'loss_4': 2.2089955806732178, 'epoch': 12.02}
{'loss': 0.0102, 'grad_norm': 4.79680061340332, 'learning_rate': 1.8e-05, 'loss_1': 0.008754554204642773, 'loss_2': 0.001453399658203125, 'loss_3': -16.322813034057617, 'loss_4': 2.1160898208618164, 'epoch': 12.02}
{'loss': 0.029, 'grad_norm': 11.125998497009277, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.025627512484788895, 'loss_2': 0.00335693359375, 'loss_3': -16.40680694580078, 'loss_4': 1.2307047843933105, 'epoch': 12.03}
{'loss': 0.0175, 'grad_norm': 7.616543292999268, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.01394721306860447, 'loss_2': 0.003597259521484375, 'loss_3': -16.31554412841797, 'loss_4': 2.037242889404297, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 10:17:46,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:46,449 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:13<53:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:53,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012690454721450806, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009486764669418335, 'eval_loss_2': 0.0032036900520324707, 'eval_loss_3': -18.302539825439453, 'eval_loss_4': 1.2349709272384644, 'epoch': 12.03}
{'loss': 0.0231, 'grad_norm': 14.752534866333008, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.020790519192814827, 'loss_2': 0.0023059844970703125, 'loss_3': -16.531339645385742, 'loss_4': 2.0254311561584473, 'epoch': 12.04}
{'loss': 0.0182, 'grad_norm': 8.081326484680176, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.016297534108161926, 'loss_2': 0.00188446044921875, 'loss_3': -16.30002212524414, 'loss_4': 1.4498921632766724, 'epoch': 12.05}
{'loss': 0.0118, 'grad_norm': 7.184636116027832, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.009006618522107601, 'loss_2': 0.002803802490234375, 'loss_3': -16.325645446777344, 'loss_4': 1.9822988510131836, 'epoch': 12.05}
{'loss': 0.0238, 'grad_norm': 10.503886222839355, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.021768435835838318, 'loss_2': 0.002079010009765625, 'loss_3': -16.433208465576172, 'loss_4': 1.739850401878357, 'epoch': 12.06}
{'loss': 0.0278, 'grad_norm': 11.308755874633789, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.02307239919900894, 'loss_2': 0.00472259521484375, 'loss_3': -16.373199462890625, 'loss_4': 1.3526180982589722, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 10:17:53,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:53,805 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:20<53:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:01,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01324150338768959, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.384, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.010212497785687447, 'eval_loss_2': 0.0030290037393569946, 'eval_loss_3': -18.276704788208008, 'eval_loss_4': 1.1404378414154053, 'epoch': 12.06}
{'loss': 0.0286, 'grad_norm': 8.871859550476074, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.025356590747833252, 'loss_2': 0.003238677978515625, 'loss_3': -16.515920639038086, 'loss_4': 1.6116689443588257, 'epoch': 12.07}
{'loss': 0.0179, 'grad_norm': 6.399872779846191, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.016281016170978546, 'loss_2': 0.0016384124755859375, 'loss_3': -16.42127227783203, 'loss_4': 1.285767912864685, 'epoch': 12.08}
{'loss': 0.0154, 'grad_norm': 8.131155967712402, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.013894743286073208, 'loss_2': 0.0014553070068359375, 'loss_3': -16.446653366088867, 'loss_4': 1.2284846305847168, 'epoch': 12.08}
{'loss': 0.0468, 'grad_norm': 16.463762283325195, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.04433809965848923, 'loss_2': 0.002452850341796875, 'loss_3': -16.174304962158203, 'loss_4': 1.763643741607666, 'epoch': 12.09}
{'loss': 0.0238, 'grad_norm': 11.981884002685547, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.023391278460621834, 'loss_2': 0.0004477500915527344, 'loss_3': -16.429004669189453, 'loss_4': 1.3299429416656494, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 10:18:01,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:01,161 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:28<53:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:08,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01523706503212452, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011135714128613472, 'eval_loss_2': 0.004101350903511047, 'eval_loss_3': -18.239944458007812, 'eval_loss_4': 1.3180359601974487, 'epoch': 12.09}
{'loss': 0.0174, 'grad_norm': 5.816143035888672, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.010401738807559013, 'loss_2': 0.007045745849609375, 'loss_3': -16.314611434936523, 'loss_4': 1.7156810760498047, 'epoch': 12.1}
{'loss': 0.009, 'grad_norm': 5.467189311981201, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.008528180420398712, 'loss_2': 0.0004892349243164062, 'loss_3': -16.40010643005371, 'loss_4': 1.5090450048446655, 'epoch': 12.1}
{'loss': 0.0339, 'grad_norm': 13.558302879333496, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.033637214452028275, 'loss_2': 0.0002980232238769531, 'loss_3': -15.977153778076172, 'loss_4': 1.410098910331726, 'epoch': 12.11}
{'loss': 0.0068, 'grad_norm': 4.809301376342773, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.005948134232312441, 'loss_2': 0.0008230209350585938, 'loss_3': -16.195037841796875, 'loss_4': 1.6180092096328735, 'epoch': 12.12}
{'loss': 0.0206, 'grad_norm': 11.790511131286621, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.01820150390267372, 'loss_2': 0.0024051666259765625, 'loss_3': -16.19789695739746, 'loss_4': 1.4315588474273682, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 10:18:08,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:08,489 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:35<52:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:15,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01615806668996811, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.533, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.011615296825766563, 'eval_loss_2': 0.0045427680015563965, 'eval_loss_3': -18.216684341430664, 'eval_loss_4': 1.356265664100647, 'epoch': 12.12}
{'loss': 0.0248, 'grad_norm': 8.150821685791016, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.019036896526813507, 'loss_2': 0.0057220458984375, 'loss_3': -16.199567794799805, 'loss_4': 1.4408178329467773, 'epoch': 12.13}
{'loss': 0.0164, 'grad_norm': 7.625314712524414, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.013897859491407871, 'loss_2': 0.002460479736328125, 'loss_3': -16.431400299072266, 'loss_4': 1.3657556772232056, 'epoch': 12.13}
{'loss': 0.0053, 'grad_norm': 5.088211536407471, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.004991521593183279, 'loss_2': 0.0003294944763183594, 'loss_3': -16.423892974853516, 'loss_4': 1.4819555282592773, 'epoch': 12.14}
{'loss': 0.0141, 'grad_norm': 6.729984283447266, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.01411560270935297, 'loss_2': 1.430511474609375e-06, 'loss_3': -16.26070785522461, 'loss_4': 1.8275970220565796, 'epoch': 12.15}
{'loss': 0.0114, 'grad_norm': 5.202849864959717, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.011003298684954643, 'loss_2': 0.00042819976806640625, 'loss_3': -16.221887588500977, 'loss_4': 1.8493599891662598, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 10:18:15,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:15,815 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [51:42<52:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:23,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015534603036940098, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.973, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010720990598201752, 'eval_loss_2': 0.0048136115074157715, 'eval_loss_3': -18.21997833251953, 'eval_loss_4': 1.4720635414123535, 'epoch': 12.15}
{'loss': 0.0279, 'grad_norm': 8.875614166259766, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.023770958185195923, 'loss_2': 0.00417327880859375, 'loss_3': -16.4816951751709, 'loss_4': 1.6679036617279053, 'epoch': 12.16}
{'loss': 0.0156, 'grad_norm': 5.318701267242432, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.012028512544929981, 'loss_2': 0.003536224365234375, 'loss_3': -16.264863967895508, 'loss_4': 1.5772119760513306, 'epoch': 12.16}
{'loss': 0.0691, 'grad_norm': 25.786718368530273, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.06781598180532455, 'loss_2': 0.0012960433959960938, 'loss_3': -16.07633399963379, 'loss_4': 1.8020856380462646, 'epoch': 12.17}
{'loss': 0.0343, 'grad_norm': 12.485092163085938, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.03386396914720535, 'loss_2': 0.00040435791015625, 'loss_3': -16.33123016357422, 'loss_4': 1.3730485439300537, 'epoch': 12.17}
{'loss': 0.0426, 'grad_norm': 9.2793550491333, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.04207400605082512, 'loss_2': 0.0005578994750976562, 'loss_3': -16.320606231689453, 'loss_4': 2.465224504470825, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 10:18:23,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:23,151 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [51:50<52:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:30,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01363158505409956, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.094, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009448493830859661, 'eval_loss_2': 0.004183091223239899, 'eval_loss_3': -18.20916748046875, 'eval_loss_4': 1.5225789546966553, 'epoch': 12.18}
{'loss': 0.0158, 'grad_norm': 7.166925430297852, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.014291615225374699, 'loss_2': 0.0015277862548828125, 'loss_3': -16.339778900146484, 'loss_4': 1.850403070449829, 'epoch': 12.19}
{'loss': 0.0114, 'grad_norm': 5.771722793579102, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.010714595206081867, 'loss_2': 0.0007305145263671875, 'loss_3': -16.227827072143555, 'loss_4': 1.4707038402557373, 'epoch': 12.19}
{'loss': 0.0091, 'grad_norm': 4.948999881744385, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.007157009560614824, 'loss_2': 0.001956939697265625, 'loss_3': -16.096576690673828, 'loss_4': 1.5601389408111572, 'epoch': 12.2}
{'loss': 0.0319, 'grad_norm': 9.320664405822754, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.028957024216651917, 'loss_2': 0.002925872802734375, 'loss_3': -16.43880844116211, 'loss_4': 2.381608247756958, 'epoch': 12.2}
{'loss': 0.0098, 'grad_norm': 5.467189311981201, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.009408332407474518, 'loss_2': 0.0003600120544433594, 'loss_3': -16.199020385742188, 'loss_4': 1.4277069568634033, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 10:18:30,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:30,493 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [51:57<52:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:37,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014756307005882263, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.771, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009590700268745422, 'eval_loss_2': 0.005165606737136841, 'eval_loss_3': -18.209186553955078, 'eval_loss_4': 1.643568515777588, 'epoch': 12.21}
{'loss': 0.0195, 'grad_norm': 5.149486064910889, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.007735265418887138, 'loss_2': 0.0117645263671875, 'loss_3': -16.370330810546875, 'loss_4': 2.088407516479492, 'epoch': 12.22}
{'loss': 0.0167, 'grad_norm': 4.508162498474121, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.005316566675901413, 'loss_2': 0.0114288330078125, 'loss_3': -16.290245056152344, 'loss_4': 1.5896453857421875, 'epoch': 12.22}
{'loss': 0.0283, 'grad_norm': 9.608865737915039, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.013570090755820274, 'loss_2': 0.01473236083984375, 'loss_3': -16.099611282348633, 'loss_4': 1.5185579061508179, 'epoch': 12.23}
{'loss': 0.0214, 'grad_norm': 6.93965482711792, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.019902454689145088, 'loss_2': 0.0014505386352539062, 'loss_3': -15.943822860717773, 'loss_4': 2.219834089279175, 'epoch': 12.23}
{'loss': 0.0131, 'grad_norm': 5.052592754364014, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.009713834151625633, 'loss_2': 0.0033817291259765625, 'loss_3': -16.19420623779297, 'loss_4': 2.16226863861084, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 10:18:37,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:37,840 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:04<52:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:45,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012742274440824986, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.008652024902403355, 'eval_loss_2': 0.004090249538421631, 'eval_loss_3': -18.220762252807617, 'eval_loss_4': 1.6296048164367676, 'epoch': 12.24}
{'loss': 0.0119, 'grad_norm': 5.9176836013793945, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.009995227679610252, 'loss_2': 0.0019092559814453125, 'loss_3': -16.287155151367188, 'loss_4': 2.0859451293945312, 'epoch': 12.24}
{'loss': 0.0077, 'grad_norm': 5.069093704223633, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.0076582785695791245, 'loss_2': 8.195638656616211e-05, 'loss_3': -16.19678497314453, 'loss_4': 1.5757687091827393, 'epoch': 12.25}
{'loss': 0.0246, 'grad_norm': 7.321589469909668, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.019977742806077003, 'loss_2': 0.004608154296875, 'loss_3': -16.216625213623047, 'loss_4': 1.7911394834518433, 'epoch': 12.26}
{'loss': 0.0292, 'grad_norm': 14.256616592407227, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.026608906686306, 'loss_2': 0.0026397705078125, 'loss_3': -16.316341400146484, 'loss_4': 2.5249671936035156, 'epoch': 12.26}
{'loss': 0.0238, 'grad_norm': 11.086753845214844, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.023215802386403084, 'loss_2': 0.00054931640625, 'loss_3': -15.948545455932617, 'loss_4': 1.9823459386825562, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 10:18:45,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:45,178 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:12<52:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:52,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015468105673789978, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.098, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007687792181968689, 'eval_loss_2': 0.007780313491821289, 'eval_loss_3': -18.24254608154297, 'eval_loss_4': 1.5391318798065186, 'epoch': 12.27}
{'loss': 0.017, 'grad_norm': 6.931609153747559, 'learning_rate': 1.775e-05, 'loss_1': 0.011707700788974762, 'loss_2': 0.00525665283203125, 'loss_3': -16.41245460510254, 'loss_4': 1.7414627075195312, 'epoch': 12.27}
{'loss': 0.0208, 'grad_norm': 7.872300624847412, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.01878257468342781, 'loss_2': 0.0020599365234375, 'loss_3': -16.312318801879883, 'loss_4': 1.305458903312683, 'epoch': 12.28}
{'loss': 0.0236, 'grad_norm': 8.133237838745117, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.02141456864774227, 'loss_2': 0.0021686553955078125, 'loss_3': -16.168109893798828, 'loss_4': 2.303307056427002, 'epoch': 12.28}
{'loss': 0.0208, 'grad_norm': 5.7442450523376465, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.014139316976070404, 'loss_2': 0.00670623779296875, 'loss_3': -16.330440521240234, 'loss_4': 2.072619676589966, 'epoch': 12.29}
{'loss': 0.0192, 'grad_norm': 8.878124237060547, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.016544165089726448, 'loss_2': 0.002685546875, 'loss_3': -16.256044387817383, 'loss_4': 2.0669891834259033, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 10:18:52,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:52,513 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:19<52:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:59,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015684302896261215, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008598503656685352, 'eval_loss_2': 0.0070858001708984375, 'eval_loss_3': -18.22751235961914, 'eval_loss_4': 1.453967571258545, 'epoch': 12.3}
{'loss': 0.0072, 'grad_norm': 4.951516151428223, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.005384877324104309, 'loss_2': 0.0018634796142578125, 'loss_3': -16.388124465942383, 'loss_4': 1.9019718170166016, 'epoch': 12.3}
{'loss': 0.0442, 'grad_norm': 15.923812866210938, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.03622717410326004, 'loss_2': 0.0079498291015625, 'loss_3': -16.202247619628906, 'loss_4': 1.5302059650421143, 'epoch': 12.31}
{'loss': 0.0112, 'grad_norm': 4.582345485687256, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.005572606343775988, 'loss_2': 0.005645751953125, 'loss_3': -16.359952926635742, 'loss_4': 1.584428310394287, 'epoch': 12.31}
{'loss': 0.046, 'grad_norm': 13.424479484558105, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.04423825442790985, 'loss_2': 0.0017824172973632812, 'loss_3': -16.170272827148438, 'loss_4': 2.0188841819763184, 'epoch': 12.32}
{'loss': 0.0184, 'grad_norm': 7.356460094451904, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.01374438963830471, 'loss_2': 0.0046234130859375, 'loss_3': -16.193933486938477, 'loss_4': 2.458024024963379, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 10:18:59,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:59,860 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:27<52:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:07,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01161382719874382, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.1, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008837636560201645, 'eval_loss_2': 0.0027761906385421753, 'eval_loss_3': -18.258831024169922, 'eval_loss_4': 1.551721453666687, 'epoch': 12.33}
{'loss': 0.018, 'grad_norm': 10.302387237548828, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.017759498208761215, 'loss_2': 0.0002849102020263672, 'loss_3': -16.23056411743164, 'loss_4': 2.354522705078125, 'epoch': 12.33}
{'loss': 0.0196, 'grad_norm': 5.685516834259033, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.011653240770101547, 'loss_2': 0.0079345703125, 'loss_3': -16.23259735107422, 'loss_4': 2.314089298248291, 'epoch': 12.34}
{'loss': 0.0156, 'grad_norm': 5.242687702178955, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.006608396302908659, 'loss_2': 0.009033203125, 'loss_3': -16.226932525634766, 'loss_4': 1.600611925125122, 'epoch': 12.34}
{'loss': 0.0257, 'grad_norm': 13.807514190673828, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.023925650864839554, 'loss_2': 0.0017547607421875, 'loss_3': -16.259479522705078, 'loss_4': 2.384005546569824, 'epoch': 12.35}
{'loss': 0.0112, 'grad_norm': 4.828151226043701, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.00872120913118124, 'loss_2': 0.002521514892578125, 'loss_3': -16.210689544677734, 'loss_4': 2.104428768157959, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 10:19:07,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:07,202 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:34<52:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:14,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01274422649294138, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.929, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009927988052368164, 'eval_loss_2': 0.002816237509250641, 'eval_loss_3': -18.262027740478516, 'eval_loss_4': 1.547531008720398, 'epoch': 12.35}
{'loss': 0.0178, 'grad_norm': 7.197965145111084, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.014205132611095905, 'loss_2': 0.003612518310546875, 'loss_3': -16.232147216796875, 'loss_4': 2.3262531757354736, 'epoch': 12.36}
{'loss': 0.0212, 'grad_norm': 6.7613654136657715, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.01834513619542122, 'loss_2': 0.002811431884765625, 'loss_3': -16.256153106689453, 'loss_4': 1.7389603853225708, 'epoch': 12.37}
{'loss': 0.0125, 'grad_norm': 6.842280387878418, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.011061526834964752, 'loss_2': 0.001422882080078125, 'loss_3': -16.33717155456543, 'loss_4': 2.319330930709839, 'epoch': 12.37}
{'loss': 0.0133, 'grad_norm': 5.300749778747559, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.008775382302701473, 'loss_2': 0.004497528076171875, 'loss_3': -16.287504196166992, 'loss_4': 2.1655445098876953, 'epoch': 12.38}
{'loss': 0.0105, 'grad_norm': 6.686586856842041, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.010369645431637764, 'loss_2': 0.00013315677642822266, 'loss_3': -16.45646095275879, 'loss_4': 1.8144993782043457, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 10:19:14,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:14,550 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [52:41<52:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:21,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014162534847855568, 'eval_runtime': 3.8256, 'eval_samples_per_second': 267.668, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.00996377319097519, 'eval_loss_2': 0.0041987597942352295, 'eval_loss_3': -18.288381576538086, 'eval_loss_4': 1.4415926933288574, 'epoch': 12.38}
{'loss': 0.0178, 'grad_norm': 7.197957992553711, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.01462383009493351, 'loss_2': 0.003204345703125, 'loss_3': -16.425329208374023, 'loss_4': 1.8690128326416016, 'epoch': 12.39}
{'loss': 0.0155, 'grad_norm': 7.276679039001465, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.010332582518458366, 'loss_2': 0.005176544189453125, 'loss_3': -16.3978328704834, 'loss_4': 1.7718143463134766, 'epoch': 12.4}
{'loss': 0.0155, 'grad_norm': 5.093306064605713, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.011480488814413548, 'loss_2': 0.00399017333984375, 'loss_3': -16.471691131591797, 'loss_4': 2.0503616333007812, 'epoch': 12.4}
{'loss': 0.0427, 'grad_norm': 11.64341926574707, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.037302810698747635, 'loss_2': 0.0053558349609375, 'loss_3': -16.423030853271484, 'loss_4': 1.7069227695465088, 'epoch': 12.41}
{'loss': 0.0179, 'grad_norm': 6.060009002685547, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.009749307297170162, 'loss_2': 0.00818634033203125, 'loss_3': -16.428871154785156, 'loss_4': 2.346592903137207, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 10:19:21,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:21,920 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [52:49<52:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:29,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01339105423539877, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.202, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.00967115443199873, 'eval_loss_2': 0.0037198998034000397, 'eval_loss_3': -18.284011840820312, 'eval_loss_4': 1.1380141973495483, 'epoch': 12.41}
{'loss': 0.0291, 'grad_norm': 17.471696853637695, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.027921881526708603, 'loss_2': 0.0012063980102539062, 'loss_3': -16.32986068725586, 'loss_4': 1.3654972314834595, 'epoch': 12.42}
{'loss': 0.0199, 'grad_norm': 6.135984420776367, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.014202730730175972, 'loss_2': 0.00567626953125, 'loss_3': -16.089706420898438, 'loss_4': 1.2893164157867432, 'epoch': 12.42}
{'loss': 0.0197, 'grad_norm': 11.481472969055176, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.01661127246916294, 'loss_2': 0.0030689239501953125, 'loss_3': -16.046104431152344, 'loss_4': 2.006326675415039, 'epoch': 12.43}
{'loss': 0.0221, 'grad_norm': 6.9049763679504395, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.015984397381544113, 'loss_2': 0.006160736083984375, 'loss_3': -16.313831329345703, 'loss_4': 1.4397523403167725, 'epoch': 12.44}
{'loss': 0.0193, 'grad_norm': 8.49790096282959, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.017538998275995255, 'loss_2': 0.0017337799072265625, 'loss_3': -16.330957412719727, 'loss_4': 1.2118377685546875, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 10:19:29,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:29,251 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [52:56<52:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:36,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013461894355714321, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.275, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.009464196860790253, 'eval_loss_2': 0.003997698426246643, 'eval_loss_3': -18.314390182495117, 'eval_loss_4': 1.0282469987869263, 'epoch': 12.44}
{'loss': 0.0241, 'grad_norm': 5.846066474914551, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.00870000571012497, 'loss_2': 0.01544189453125, 'loss_3': -16.483718872070312, 'loss_4': 1.6113736629486084, 'epoch': 12.45}
{'loss': 0.01, 'grad_norm': 5.397624969482422, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.009080030955374241, 'loss_2': 0.0009331703186035156, 'loss_3': -16.473114013671875, 'loss_4': 1.5124330520629883, 'epoch': 12.45}
{'loss': 0.0161, 'grad_norm': 5.744627952575684, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.011050065979361534, 'loss_2': 0.005046844482421875, 'loss_3': -16.260452270507812, 'loss_4': 1.544631838798523, 'epoch': 12.46}
{'loss': 0.0163, 'grad_norm': 5.455321788787842, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.007278659380972385, 'loss_2': 0.0089874267578125, 'loss_3': -16.50081443786621, 'loss_4': 1.450554609298706, 'epoch': 12.47}
{'loss': 0.0161, 'grad_norm': 5.116903305053711, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.010108616203069687, 'loss_2': 0.006008148193359375, 'loss_3': -16.57608413696289, 'loss_4': 0.8531614542007446, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 10:19:36,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:36,577 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:03<51:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:43,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012051569297909737, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00856630690395832, 'eval_loss_2': 0.003485262393951416, 'eval_loss_3': -18.322429656982422, 'eval_loss_4': 0.9864227771759033, 'epoch': 12.47}
{'loss': 0.0145, 'grad_norm': 7.079284191131592, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.013582373037934303, 'loss_2': 0.0009112358093261719, 'loss_3': -16.275846481323242, 'loss_4': 1.5857208967208862, 'epoch': 12.48}
{'loss': 0.0063, 'grad_norm': 4.3717427253723145, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.004484724253416061, 'loss_2': 0.0018405914306640625, 'loss_3': -16.282682418823242, 'loss_4': 1.0675058364868164, 'epoch': 12.48}
{'loss': 0.0116, 'grad_norm': 4.52638053894043, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.005961451213806868, 'loss_2': 0.0055999755859375, 'loss_3': -16.447551727294922, 'loss_4': 1.0324585437774658, 'epoch': 12.49}
{'loss': 0.0114, 'grad_norm': 5.717600345611572, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.011042690835893154, 'loss_2': 0.00035262107849121094, 'loss_3': -16.215045928955078, 'loss_4': 1.1978390216827393, 'epoch': 12.49}
{'loss': 0.0251, 'grad_norm': 7.160730361938477, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.012860974296927452, 'loss_2': 0.0121917724609375, 'loss_3': -16.34160614013672, 'loss_4': 1.8179107904434204, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 10:19:43,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:43,907 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:11<51:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:51,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016348544508218765, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.682, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00967361405491829, 'eval_loss_2': 0.006674930453300476, 'eval_loss_3': -18.33878517150879, 'eval_loss_4': 0.9715089797973633, 'epoch': 12.5}
{'loss': 0.0082, 'grad_norm': 5.1433610916137695, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.007497840560972691, 'loss_2': 0.0006666183471679688, 'loss_3': -16.387386322021484, 'loss_4': 1.8312277793884277, 'epoch': 12.51}
{'loss': 0.0339, 'grad_norm': 8.60375690460205, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.028880804777145386, 'loss_2': 0.00501251220703125, 'loss_3': -16.511293411254883, 'loss_4': 1.1860361099243164, 'epoch': 12.51}
{'loss': 0.0119, 'grad_norm': 5.806472301483154, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.011083406396210194, 'loss_2': 0.0008368492126464844, 'loss_3': -16.188108444213867, 'loss_4': 1.7379591464996338, 'epoch': 12.52}
{'loss': 0.0176, 'grad_norm': 5.227182865142822, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.009106975048780441, 'loss_2': 0.00852203369140625, 'loss_3': -16.2304630279541, 'loss_4': 0.9284155368804932, 'epoch': 12.52}
{'loss': 0.0187, 'grad_norm': 5.473695755004883, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.010140322148799896, 'loss_2': 0.008575439453125, 'loss_3': -16.325611114501953, 'loss_4': 0.940173864364624, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 10:19:51,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:51,250 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:18<51:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:58,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017864592373371124, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.943, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009605237282812595, 'eval_loss_2': 0.008259356021881104, 'eval_loss_3': -18.33794593811035, 'eval_loss_4': 0.9108274579048157, 'epoch': 12.53}
{'loss': 0.012, 'grad_norm': 4.972827911376953, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.005901138763874769, 'loss_2': 0.006072998046875, 'loss_3': -16.352550506591797, 'loss_4': 1.3440979719161987, 'epoch': 12.53}
{'loss': 0.0234, 'grad_norm': 13.126688957214355, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.019086124375462532, 'loss_2': 0.00434112548828125, 'loss_3': -16.441364288330078, 'loss_4': 1.2167285680770874, 'epoch': 12.54}
{'loss': 0.0115, 'grad_norm': 6.738269329071045, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.00958479568362236, 'loss_2': 0.0018701553344726562, 'loss_3': -16.491268157958984, 'loss_4': 1.0930485725402832, 'epoch': 12.55}
{'loss': 0.0203, 'grad_norm': 7.549935817718506, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.012961824424564838, 'loss_2': 0.00737762451171875, 'loss_3': -16.56177520751953, 'loss_4': 1.176830530166626, 'epoch': 12.55}
{'loss': 0.0149, 'grad_norm': 6.797483921051025, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.010938815772533417, 'loss_2': 0.003948211669921875, 'loss_3': -16.410465240478516, 'loss_4': 0.9043341875076294, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 10:19:58,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:58,591 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:25<51:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:05,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013003552332520485, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00962057989090681, 'eval_loss_2': 0.0033829733729362488, 'eval_loss_3': -18.347475051879883, 'eval_loss_4': 0.8570327758789062, 'epoch': 12.56}
{'loss': 0.0088, 'grad_norm': 5.23787260055542, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.006229149177670479, 'loss_2': 0.002567291259765625, 'loss_3': -16.48930549621582, 'loss_4': 1.0149824619293213, 'epoch': 12.56}
{'loss': 0.0271, 'grad_norm': 20.91796112060547, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.02296549640595913, 'loss_2': 0.004146575927734375, 'loss_3': -16.38801383972168, 'loss_4': 0.8469736576080322, 'epoch': 12.57}
{'loss': 0.0268, 'grad_norm': 15.474939346313477, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.021553020924329758, 'loss_2': 0.005275726318359375, 'loss_3': -16.589290618896484, 'loss_4': 1.2617733478546143, 'epoch': 12.58}
{'loss': 0.0195, 'grad_norm': 7.029277801513672, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.01750369183719158, 'loss_2': 0.001956939697265625, 'loss_3': -16.471588134765625, 'loss_4': 1.3682533502578735, 'epoch': 12.58}
{'loss': 0.0355, 'grad_norm': 10.880237579345703, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.02284088358283043, 'loss_2': 0.0126953125, 'loss_3': -16.240930557250977, 'loss_4': 2.1731362342834473, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 10:20:05,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:05,944 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:33<51:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:13,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016678085550665855, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009857555851340294, 'eval_loss_2': 0.0068205296993255615, 'eval_loss_3': -18.360048294067383, 'eval_loss_4': 1.0427604913711548, 'epoch': 12.59}
{'loss': 0.0365, 'grad_norm': 8.581117630004883, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.027370229363441467, 'loss_2': 0.0091094970703125, 'loss_3': -16.448925018310547, 'loss_4': 1.3657628297805786, 'epoch': 12.59}
{'loss': 0.0178, 'grad_norm': 6.456628322601318, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.013623109087347984, 'loss_2': 0.0041351318359375, 'loss_3': -16.56094741821289, 'loss_4': 0.9725446701049805, 'epoch': 12.6}
{'loss': 0.027, 'grad_norm': 5.902240753173828, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.010233699344098568, 'loss_2': 0.0167694091796875, 'loss_3': -16.475385665893555, 'loss_4': 1.4040229320526123, 'epoch': 12.6}
{'loss': 0.0104, 'grad_norm': 4.94290018081665, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.006194599438458681, 'loss_2': 0.0042266845703125, 'loss_3': -16.4307861328125, 'loss_4': 1.5871918201446533, 'epoch': 12.61}
{'loss': 0.026, 'grad_norm': 8.4273042678833, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.02230837009847164, 'loss_2': 0.00368499755859375, 'loss_3': -16.50275421142578, 'loss_4': 1.4648863077163696, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 10:20:13,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:13,286 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:40<51:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:20,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013044995255768299, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.224, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009528628550469875, 'eval_loss_2': 0.003516368567943573, 'eval_loss_3': -18.36688995361328, 'eval_loss_4': 1.287395715713501, 'epoch': 12.62}
{'loss': 0.0213, 'grad_norm': 5.529322147369385, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.008734817616641521, 'loss_2': 0.01251983642578125, 'loss_3': -16.28376007080078, 'loss_4': 1.9954124689102173, 'epoch': 12.62}
{'loss': 0.0294, 'grad_norm': 9.261360168457031, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.029275469481945038, 'loss_2': 0.00010013580322265625, 'loss_3': -16.324806213378906, 'loss_4': 1.2891302108764648, 'epoch': 12.63}
{'loss': 0.0081, 'grad_norm': 5.5262932777404785, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.006952792871743441, 'loss_2': 0.0011739730834960938, 'loss_3': -16.72716522216797, 'loss_4': 1.445364236831665, 'epoch': 12.63}
{'loss': 0.0163, 'grad_norm': 5.20613431930542, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.00817207433283329, 'loss_2': 0.0081024169921875, 'loss_3': -16.23892593383789, 'loss_4': 2.5143299102783203, 'epoch': 12.64}
{'loss': 0.0158, 'grad_norm': 5.461040496826172, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.008777698501944542, 'loss_2': 0.0070037841796875, 'loss_3': -16.615203857421875, 'loss_4': 2.6526637077331543, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 10:20:20,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:20,617 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [53:47<51:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:27,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013408790342509747, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.085, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009557201527059078, 'eval_loss_2': 0.0038515888154506683, 'eval_loss_3': -18.373767852783203, 'eval_loss_4': 1.2881221771240234, 'epoch': 12.65}
{'loss': 0.0166, 'grad_norm': 6.286901473999023, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.013437584042549133, 'loss_2': 0.003147125244140625, 'loss_3': -16.53295135498047, 'loss_4': 2.89953875541687, 'epoch': 12.65}
{'loss': 0.0133, 'grad_norm': 5.811389923095703, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.010047742165625095, 'loss_2': 0.003204345703125, 'loss_3': -16.340816497802734, 'loss_4': 1.8236279487609863, 'epoch': 12.66}
{'loss': 0.0214, 'grad_norm': 6.881663799285889, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.016389695927500725, 'loss_2': 0.004985809326171875, 'loss_3': -16.482221603393555, 'loss_4': 1.3499672412872314, 'epoch': 12.66}
{'loss': 0.0355, 'grad_norm': 22.405948638916016, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.034836988896131516, 'loss_2': 0.0006928443908691406, 'loss_3': -16.541460037231445, 'loss_4': 2.519265651702881, 'epoch': 12.67}
{'loss': 0.0185, 'grad_norm': 5.912130832672119, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.010215607471764088, 'loss_2': 0.0082550048828125, 'loss_3': -16.55634117126465, 'loss_4': 1.4456720352172852, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 10:20:27,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:27,947 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [53:55<51:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:35,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015001148916780949, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009548516944050789, 'eval_loss_2': 0.005452632904052734, 'eval_loss_3': -18.366140365600586, 'eval_loss_4': 1.138252854347229, 'epoch': 12.67}
{'loss': 0.0254, 'grad_norm': 8.361710548400879, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.017877629026770592, 'loss_2': 0.00748443603515625, 'loss_3': -16.64745330810547, 'loss_4': 1.0787866115570068, 'epoch': 12.68}
{'loss': 0.0242, 'grad_norm': 8.96059513092041, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.01852373406291008, 'loss_2': 0.005706787109375, 'loss_3': -16.27374839782715, 'loss_4': 1.3885917663574219, 'epoch': 12.69}
{'loss': 0.0377, 'grad_norm': 15.488686561584473, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.028951309621334076, 'loss_2': 0.0087432861328125, 'loss_3': -16.295801162719727, 'loss_4': 1.8016146421432495, 'epoch': 12.69}
{'loss': 0.0207, 'grad_norm': 16.063716888427734, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.018469693139195442, 'loss_2': 0.0022411346435546875, 'loss_3': -16.597503662109375, 'loss_4': 1.4592483043670654, 'epoch': 12.7}
{'loss': 0.0127, 'grad_norm': 5.4560394287109375, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.00858316384255886, 'loss_2': 0.0041046142578125, 'loss_3': -16.43280601501465, 'loss_4': 0.7624553442001343, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 10:20:35,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:35,275 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:02<51:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:42,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013880139216780663, 'eval_runtime': 3.8192, 'eval_samples_per_second': 268.12, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.010144686326384544, 'eval_loss_2': 0.003735452890396118, 'eval_loss_3': -18.343143463134766, 'eval_loss_4': 0.9028489589691162, 'epoch': 12.7}
{'loss': 0.0252, 'grad_norm': 7.964199066162109, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.01709830015897751, 'loss_2': 0.0081329345703125, 'loss_3': -16.41832733154297, 'loss_4': 0.9509192705154419, 'epoch': 12.71}
{'loss': 0.0176, 'grad_norm': 7.722690105438232, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.014785345643758774, 'loss_2': 0.0027790069580078125, 'loss_3': -16.44284439086914, 'loss_4': 1.0710225105285645, 'epoch': 12.72}
{'loss': 0.0144, 'grad_norm': 6.650763511657715, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.011729259975254536, 'loss_2': 0.0027103424072265625, 'loss_3': -16.42265510559082, 'loss_4': 1.557807445526123, 'epoch': 12.72}
{'loss': 0.0094, 'grad_norm': 5.107714653015137, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.008546734228730202, 'loss_2': 0.0008840560913085938, 'loss_3': -16.48489761352539, 'loss_4': 0.9829584360122681, 'epoch': 12.73}
{'loss': 0.009, 'grad_norm': 4.835443496704102, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.007777793798595667, 'loss_2': 0.001255035400390625, 'loss_3': -16.414718627929688, 'loss_4': 1.913620948791504, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 10:20:42,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:42,642 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:09<51:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:49,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01243041642010212, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.247, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008681879378855228, 'eval_loss_2': 0.0037485361099243164, 'eval_loss_3': -18.34425926208496, 'eval_loss_4': 0.6363465189933777, 'epoch': 12.73}
{'loss': 0.0322, 'grad_norm': 13.209216117858887, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.03004373237490654, 'loss_2': 0.002155303955078125, 'loss_3': -16.455768585205078, 'loss_4': 1.1180516481399536, 'epoch': 12.74}
{'loss': 0.0468, 'grad_norm': 12.535355567932129, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.032572969794273376, 'loss_2': 0.0142669677734375, 'loss_3': -16.384666442871094, 'loss_4': 1.2879364490509033, 'epoch': 12.74}
{'loss': 0.019, 'grad_norm': 5.789921283721924, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.008738002739846706, 'loss_2': 0.010284423828125, 'loss_3': -16.469676971435547, 'loss_4': 0.7964386940002441, 'epoch': 12.75}
{'loss': 0.0248, 'grad_norm': 8.545363426208496, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.0216632429510355, 'loss_2': 0.00316619873046875, 'loss_3': -16.473175048828125, 'loss_4': 1.1066362857818604, 'epoch': 12.76}
{'loss': 0.0102, 'grad_norm': 5.2241129875183105, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.009800690226256847, 'loss_2': 0.00037860870361328125, 'loss_3': -16.40087890625, 'loss_4': 1.569741129875183, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 10:20:49,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:49,978 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:17<51:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:57,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012067979201674461, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.137, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008170250803232193, 'eval_loss_2': 0.003897726535797119, 'eval_loss_3': -18.329256057739258, 'eval_loss_4': 0.36393874883651733, 'epoch': 12.76}
{'loss': 0.0253, 'grad_norm': 7.160421371459961, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.017421789467334747, 'loss_2': 0.00792694091796875, 'loss_3': -16.49814224243164, 'loss_4': 0.6607824563980103, 'epoch': 12.77}
{'loss': 0.0185, 'grad_norm': 7.237037181854248, 'learning_rate': 1.725e-05, 'loss_1': 0.014372117817401886, 'loss_2': 0.004169464111328125, 'loss_3': -16.488449096679688, 'loss_4': 0.5644031763076782, 'epoch': 12.77}
{'loss': 0.0071, 'grad_norm': 4.870676040649414, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.006823443807661533, 'loss_2': 0.00028705596923828125, 'loss_3': -16.527973175048828, 'loss_4': 1.0196685791015625, 'epoch': 12.78}
{'loss': 0.0292, 'grad_norm': 9.078763008117676, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.02774723246693611, 'loss_2': 0.001476287841796875, 'loss_3': -16.38990592956543, 'loss_4': 0.3934497833251953, 'epoch': 12.78}
{'loss': 0.0277, 'grad_norm': 13.02221965789795, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.02442202903330326, 'loss_2': 0.003284454345703125, 'loss_3': -16.390274047851562, 'loss_4': 0.9366896152496338, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 10:20:57,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:57,311 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:24<51:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:04,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014255674555897713, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.03, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008227142505347729, 'eval_loss_2': 0.006028532981872559, 'eval_loss_3': -18.312883377075195, 'eval_loss_4': 0.19185733795166016, 'epoch': 12.79}
{'loss': 0.0143, 'grad_norm': 4.894973278045654, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.00521306786686182, 'loss_2': 0.009124755859375, 'loss_3': -16.25572967529297, 'loss_4': 0.4951341450214386, 'epoch': 12.8}
{'loss': 0.0124, 'grad_norm': 4.691187381744385, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.007286943029612303, 'loss_2': 0.005092620849609375, 'loss_3': -16.52688217163086, 'loss_4': 0.5822876691818237, 'epoch': 12.8}
{'loss': 0.0265, 'grad_norm': 7.44392204284668, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.02059558592736721, 'loss_2': 0.005870819091796875, 'loss_3': -16.431194305419922, 'loss_4': 0.9308322668075562, 'epoch': 12.81}
{'loss': 0.0141, 'grad_norm': 5.208664894104004, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.00646165618672967, 'loss_2': 0.0076141357421875, 'loss_3': -16.458803176879883, 'loss_4': 0.2627078890800476, 'epoch': 12.81}
{'loss': 0.021, 'grad_norm': 8.159224510192871, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.01858377829194069, 'loss_2': 0.00244140625, 'loss_3': -16.44573211669922, 'loss_4': 0.5397878885269165, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 10:21:04,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:04,645 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:31<50:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:11,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011823274195194244, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.084, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00840994156897068, 'eval_loss_2': 0.0034133344888687134, 'eval_loss_3': -18.301509857177734, 'eval_loss_4': 0.10558868199586868, 'epoch': 12.82}
{'loss': 0.0116, 'grad_norm': 5.383800506591797, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.009877389296889305, 'loss_2': 0.00173187255859375, 'loss_3': -16.301677703857422, 'loss_4': 0.9867931604385376, 'epoch': 12.83}
{'loss': 0.021, 'grad_norm': 8.099903106689453, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.018917255103588104, 'loss_2': 0.00205230712890625, 'loss_3': -16.341598510742188, 'loss_4': 0.6958205699920654, 'epoch': 12.83}
{'loss': 0.0156, 'grad_norm': 6.447819709777832, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.01144703384488821, 'loss_2': 0.0041656494140625, 'loss_3': -16.30027961730957, 'loss_4': 0.7506094574928284, 'epoch': 12.84}
{'loss': 0.0045, 'grad_norm': 4.771045684814453, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.0038506202399730682, 'loss_2': 0.0006847381591796875, 'loss_3': -16.319133758544922, 'loss_4': 0.14404025673866272, 'epoch': 12.84}
{'loss': 0.0096, 'grad_norm': 5.4344072341918945, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.009491865523159504, 'loss_2': 8.749961853027344e-05, 'loss_3': -16.71811294555664, 'loss_4': 0.3201519250869751, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 10:21:11,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:11,975 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:39<50:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:19,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011858937330543995, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.489, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008819439448416233, 'eval_loss_2': 0.003039497882127762, 'eval_loss_3': -18.315380096435547, 'eval_loss_4': -0.11407901346683502, 'epoch': 12.85}
{'loss': 0.0139, 'grad_norm': 4.8290252685546875, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.010949081741273403, 'loss_2': 0.0029296875, 'loss_3': -16.59994125366211, 'loss_4': 0.20394109189510345, 'epoch': 12.85}
{'loss': 0.0224, 'grad_norm': 12.01644515991211, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.020806286484003067, 'loss_2': 0.0016002655029296875, 'loss_3': -16.538944244384766, 'loss_4': 0.304317831993103, 'epoch': 12.86}
{'loss': 0.0131, 'grad_norm': 5.2146501541137695, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.008548465557396412, 'loss_2': 0.0045928955078125, 'loss_3': -16.658559799194336, 'loss_4': -0.07232420146465302, 'epoch': 12.87}
{'loss': 0.0158, 'grad_norm': 6.716982364654541, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.014046614989638329, 'loss_2': 0.001728057861328125, 'loss_3': -16.574539184570312, 'loss_4': 0.6663354635238647, 'epoch': 12.87}
{'loss': 0.0214, 'grad_norm': 4.874836444854736, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.010255720466375351, 'loss_2': 0.01117706298828125, 'loss_3': -16.639488220214844, 'loss_4': -0.11331991106271744, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 10:21:19,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:19,320 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [54:46<50:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:26,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014051372185349464, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.221, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.010066712275147438, 'eval_loss_2': 0.003984659910202026, 'eval_loss_3': -18.336313247680664, 'eval_loss_4': -0.3083867132663727, 'epoch': 12.88}
{'loss': 0.0516, 'grad_norm': 32.082881927490234, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.04860188066959381, 'loss_2': 0.0030117034912109375, 'loss_3': -16.515960693359375, 'loss_4': 0.3111173212528229, 'epoch': 12.88}
{'loss': 0.0415, 'grad_norm': 16.519285202026367, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.03788358345627785, 'loss_2': 0.003650665283203125, 'loss_3': -16.473243713378906, 'loss_4': -0.05447770655155182, 'epoch': 12.89}
{'loss': 0.0252, 'grad_norm': 6.84578800201416, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.018853910267353058, 'loss_2': 0.006366729736328125, 'loss_3': -16.520992279052734, 'loss_4': -0.07246133685112, 'epoch': 12.9}
{'loss': 0.0096, 'grad_norm': 4.83026647567749, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.008507556281983852, 'loss_2': 0.001056671142578125, 'loss_3': -16.415027618408203, 'loss_4': 0.11183509230613708, 'epoch': 12.9}
{'loss': 0.0178, 'grad_norm': 4.539348125457764, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.011275467462837696, 'loss_2': 0.00655364990234375, 'loss_3': -16.416717529296875, 'loss_4': -0.2879807651042938, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 10:21:26,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:26,677 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [54:53<50:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:34,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012799892574548721, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009658101946115494, 'eval_loss_2': 0.0031417906284332275, 'eval_loss_3': -18.330120086669922, 'eval_loss_4': -0.5382769107818604, 'epoch': 12.91}
{'loss': 0.0243, 'grad_norm': 12.524728775024414, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.01983318291604519, 'loss_2': 0.00446319580078125, 'loss_3': -16.344642639160156, 'loss_4': -0.0746414065361023, 'epoch': 12.91}
{'loss': 0.0102, 'grad_norm': 4.723317623138428, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.008150085806846619, 'loss_2': 0.002017974853515625, 'loss_3': -16.669342041015625, 'loss_4': -0.0807415023446083, 'epoch': 12.92}
{'loss': 0.0202, 'grad_norm': 5.9314188957214355, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.009730263613164425, 'loss_2': 0.010467529296875, 'loss_3': -16.623628616333008, 'loss_4': -0.11977408826351166, 'epoch': 12.92}
{'loss': 0.0177, 'grad_norm': 7.70131778717041, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.013193899765610695, 'loss_2': 0.00452423095703125, 'loss_3': -16.543418884277344, 'loss_4': -0.16654901206493378, 'epoch': 12.93}
{'loss': 0.0331, 'grad_norm': 12.331841468811035, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.02488144487142563, 'loss_2': 0.00823974609375, 'loss_3': -16.495012283325195, 'loss_4': -0.2926562428474426, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 10:21:34,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:34,016 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:01<50:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:41,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013144098222255707, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009296860545873642, 'eval_loss_2': 0.003847237676382065, 'eval_loss_3': -18.341611862182617, 'eval_loss_4': -0.6088228821754456, 'epoch': 12.94}
{'loss': 0.0435, 'grad_norm': 11.939178466796875, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.032466769218444824, 'loss_2': 0.010986328125, 'loss_3': -16.52364730834961, 'loss_4': -0.08942830562591553, 'epoch': 12.94}
{'loss': 0.0216, 'grad_norm': 6.477157115936279, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.016270168125629425, 'loss_2': 0.00536346435546875, 'loss_3': -16.412147521972656, 'loss_4': -0.3169586658477783, 'epoch': 12.95}
{'loss': 0.0381, 'grad_norm': 13.979236602783203, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.03356059268116951, 'loss_2': 0.00455474853515625, 'loss_3': -16.401996612548828, 'loss_4': -0.6804068684577942, 'epoch': 12.95}
{'loss': 0.0372, 'grad_norm': 14.91356086730957, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.03233848139643669, 'loss_2': 0.00487518310546875, 'loss_3': -16.46593475341797, 'loss_4': -0.5089004039764404, 'epoch': 12.96}
{'loss': 0.0216, 'grad_norm': 7.736401081085205, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.020653655752539635, 'loss_2': 0.000957489013671875, 'loss_3': -16.381900787353516, 'loss_4': -0.12466301023960114, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 10:21:41,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:41,348 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:08<50:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:21:48,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012662921100854874, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.742, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009400072507560253, 'eval_loss_2': 0.003262847661972046, 'eval_loss_3': -18.340744018554688, 'eval_loss_4': -0.5232204794883728, 'epoch': 12.97}
{'loss': 0.0254, 'grad_norm': 11.76854419708252, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.022923003882169724, 'loss_2': 0.0024566650390625, 'loss_3': -16.502073287963867, 'loss_4': -0.5642378330230713, 'epoch': 12.97}
{'loss': 0.0354, 'grad_norm': 17.05435562133789, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.032911598682403564, 'loss_2': 0.0024852752685546875, 'loss_3': -16.45829200744629, 'loss_4': -0.019281864166259766, 'epoch': 12.98}
{'loss': 0.0149, 'grad_norm': 5.19873571395874, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.009540149010717869, 'loss_2': 0.0053558349609375, 'loss_3': -16.457538604736328, 'loss_4': 0.020491838455200195, 'epoch': 12.98}
{'loss': 0.0259, 'grad_norm': 8.481444358825684, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.019777221605181694, 'loss_2': 0.00616455078125, 'loss_3': -16.52484893798828, 'loss_4': 0.38259774446487427, 'epoch': 12.99}
{'loss': 0.0142, 'grad_norm': 6.387298583984375, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.013725092634558678, 'loss_2': 0.000492095947265625, 'loss_3': -16.464332580566406, 'loss_4': -0.3102021813392639, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 10:21:48,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:48,662 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:15<49:23,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:21:55,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01195597369223833, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.776, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00908888690173626, 'eval_loss_2': 0.002867087721824646, 'eval_loss_3': -18.35377311706543, 'eval_loss_4': -0.38263869285583496, 'epoch': 12.99}
{'loss': 0.008, 'grad_norm': 7.29684591293335, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.005015326663851738, 'loss_2': 0.00293731689453125, 'loss_3': -16.483808517456055, 'loss_4': -0.5550612211227417, 'epoch': 13.0}
{'loss': 0.0216, 'grad_norm': 12.626051902770996, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.01765236258506775, 'loss_2': 0.003917694091796875, 'loss_3': -16.59868049621582, 'loss_4': 0.7897334098815918, 'epoch': 13.01}
{'loss': 0.0229, 'grad_norm': 6.829440593719482, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.018032677471637726, 'loss_2': 0.00482177734375, 'loss_3': -16.498821258544922, 'loss_4': 0.1992400735616684, 'epoch': 13.01}
{'loss': 0.0208, 'grad_norm': 5.41454553604126, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.011714369058609009, 'loss_2': 0.009063720703125, 'loss_3': -16.55389404296875, 'loss_4': 0.07362443208694458, 'epoch': 13.02}
{'loss': 0.0209, 'grad_norm': 6.898704528808594, 'learning_rate': 1.7e-05, 'loss_1': 0.017948700115084648, 'loss_2': 0.002971649169921875, 'loss_3': -16.592227935791016, 'loss_4': -0.05132031440734863, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 10:21:55,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:55,700 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:22<50:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:22:03,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014069613069295883, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010084357112646103, 'eval_loss_2': 0.00398525595664978, 'eval_loss_3': -18.354042053222656, 'eval_loss_4': -0.3383342921733856, 'epoch': 13.02}
{'loss': 0.0216, 'grad_norm': 7.5247039794921875, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.01843445561826229, 'loss_2': 0.0031890869140625, 'loss_3': -16.733280181884766, 'loss_4': -0.13650694489479065, 'epoch': 13.03}
{'loss': 0.0281, 'grad_norm': 9.371195793151855, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.026215938851237297, 'loss_2': 0.001850128173828125, 'loss_3': -16.27812957763672, 'loss_4': -0.017757847905158997, 'epoch': 13.03}
{'loss': 0.0197, 'grad_norm': 5.581121921539307, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.015392709523439407, 'loss_2': 0.0043182373046875, 'loss_3': -16.500471115112305, 'loss_4': 0.08044944703578949, 'epoch': 13.04}
{'loss': 0.021, 'grad_norm': 8.99228286743164, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.01939985901117325, 'loss_2': 0.0016460418701171875, 'loss_3': -16.664440155029297, 'loss_4': -0.08905738592147827, 'epoch': 13.05}
{'loss': 0.0185, 'grad_norm': 6.158038139343262, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.007883946411311626, 'loss_2': 0.010650634765625, 'loss_3': -16.741329193115234, 'loss_4': -0.16525517404079437, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 10:22:03,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:03,043 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:30<50:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:22:10,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013984812423586845, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.141, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010117357596755028, 'eval_loss_2': 0.0038674548268318176, 'eval_loss_3': -18.353185653686523, 'eval_loss_4': -0.3255080580711365, 'epoch': 13.05}
{'loss': 0.0191, 'grad_norm': 7.461920261383057, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.013624319806694984, 'loss_2': 0.00550079345703125, 'loss_3': -16.37303352355957, 'loss_4': 0.40200352668762207, 'epoch': 13.06}
{'loss': 0.0121, 'grad_norm': 5.403355598449707, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.008756846189498901, 'loss_2': 0.00333404541015625, 'loss_3': -16.593889236450195, 'loss_4': 0.33538323640823364, 'epoch': 13.06}
{'loss': 0.0149, 'grad_norm': 5.421171188354492, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.01087462529540062, 'loss_2': 0.004009246826171875, 'loss_3': -16.56633949279785, 'loss_4': 0.2691064774990082, 'epoch': 13.07}
{'loss': 0.0189, 'grad_norm': 6.812416076660156, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.01604224182665348, 'loss_2': 0.0028171539306640625, 'loss_3': -16.650726318359375, 'loss_4': 0.16610971093177795, 'epoch': 13.08}
{'loss': 0.0139, 'grad_norm': 6.706867218017578, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.012920617125928402, 'loss_2': 0.0009546279907226562, 'loss_3': -16.462812423706055, 'loss_4': 0.29289424419403076, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 10:22:10,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:10,367 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:37<50:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:17,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013249149546027184, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.074, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009548237547278404, 'eval_loss_2': 0.0037009119987487793, 'eval_loss_3': -18.35324478149414, 'eval_loss_4': -0.17096047103405, 'epoch': 13.08}
{'loss': 0.022, 'grad_norm': 7.024143695831299, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.015538542531430721, 'loss_2': 0.00646209716796875, 'loss_3': -16.43918800354004, 'loss_4': -0.15413914620876312, 'epoch': 13.09}
{'loss': 0.0123, 'grad_norm': 4.887388229370117, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.009855465963482857, 'loss_2': 0.002422332763671875, 'loss_3': -16.619369506835938, 'loss_4': 0.7290862202644348, 'epoch': 13.09}
{'loss': 0.0197, 'grad_norm': 6.478673934936523, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.014249829575419426, 'loss_2': 0.005489349365234375, 'loss_3': -16.530553817749023, 'loss_4': 0.6257468461990356, 'epoch': 13.1}
{'loss': 0.0209, 'grad_norm': 7.2311835289001465, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.01619061641395092, 'loss_2': 0.0047454833984375, 'loss_3': -16.356094360351562, 'loss_4': 0.3351961076259613, 'epoch': 13.1}
{'loss': 0.0153, 'grad_norm': 4.8469390869140625, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.006381179206073284, 'loss_2': 0.0089111328125, 'loss_3': -16.6841983795166, 'loss_4': 0.49465397000312805, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 10:22:17,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:17,695 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [55:44<50:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:25,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014004858210682869, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.561, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00883561559021473, 'eval_loss_2': 0.00516924262046814, 'eval_loss_3': -18.322919845581055, 'eval_loss_4': -0.04639385640621185, 'epoch': 13.11}
{'loss': 0.0267, 'grad_norm': 6.1899333000183105, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.019178183749318123, 'loss_2': 0.0074920654296875, 'loss_3': -16.604055404663086, 'loss_4': 0.661975622177124, 'epoch': 13.12}
{'loss': 0.018, 'grad_norm': 7.665456771850586, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.014421341009438038, 'loss_2': 0.0036163330078125, 'loss_3': -16.64838409423828, 'loss_4': 0.3861228823661804, 'epoch': 13.12}
{'loss': 0.0151, 'grad_norm': 5.697010040283203, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.013172144070267677, 'loss_2': 0.0019178390502929688, 'loss_3': -16.530521392822266, 'loss_4': 0.2540310025215149, 'epoch': 13.13}
{'loss': 0.0216, 'grad_norm': 7.005126476287842, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.01868603192269802, 'loss_2': 0.002895355224609375, 'loss_3': -16.5926456451416, 'loss_4': 0.08817151188850403, 'epoch': 13.13}
{'loss': 0.0139, 'grad_norm': 5.439916133880615, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.010035411454737186, 'loss_2': 0.00389862060546875, 'loss_3': -16.6204833984375, 'loss_4': 0.29177364706993103, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 10:22:25,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:25,025 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [55:52<49:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:32,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01206002663820982, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009344208054244518, 'eval_loss_2': 0.0027158185839653015, 'eval_loss_3': -18.32522964477539, 'eval_loss_4': -0.0919424295425415, 'epoch': 13.14}
{'loss': 0.0104, 'grad_norm': 5.531038761138916, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.009615672752261162, 'loss_2': 0.00080108642578125, 'loss_3': -16.478992462158203, 'loss_4': 0.5387160778045654, 'epoch': 13.15}
{'loss': 0.0205, 'grad_norm': 6.057265281677246, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.01779882423579693, 'loss_2': 0.002750396728515625, 'loss_3': -16.50749969482422, 'loss_4': 0.309910386800766, 'epoch': 13.15}
{'loss': 0.0202, 'grad_norm': 6.578866004943848, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.01175839826464653, 'loss_2': 0.0084228515625, 'loss_3': -16.581411361694336, 'loss_4': 0.7544460296630859, 'epoch': 13.16}
{'loss': 0.0153, 'grad_norm': 6.5273847579956055, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.01022251695394516, 'loss_2': 0.00511932373046875, 'loss_3': -16.531782150268555, 'loss_4': 0.31848400831222534, 'epoch': 13.16}
{'loss': 0.0137, 'grad_norm': 6.32094144821167, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.011185002513229847, 'loss_2': 0.002544403076171875, 'loss_3': -16.56502914428711, 'loss_4': 0.22427725791931152, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 10:22:32,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:32,357 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [55:59<49:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:39,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013184267096221447, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.976, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008582795970141888, 'eval_loss_2': 0.004601471126079559, 'eval_loss_3': -18.342914581298828, 'eval_loss_4': -0.0758635476231575, 'epoch': 13.17}
{'loss': 0.0371, 'grad_norm': 14.436466217041016, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.028049355372786522, 'loss_2': 0.0090789794921875, 'loss_3': -16.404293060302734, 'loss_4': -0.07379832863807678, 'epoch': 13.17}
{'loss': 0.0183, 'grad_norm': 13.31266975402832, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.016377002000808716, 'loss_2': 0.0019321441650390625, 'loss_3': -16.534137725830078, 'loss_4': 0.12138471007347107, 'epoch': 13.18}
{'loss': 0.0468, 'grad_norm': 11.170766830444336, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.03934318572282791, 'loss_2': 0.0074615478515625, 'loss_3': -16.381135940551758, 'loss_4': -0.17756585776805878, 'epoch': 13.19}
{'loss': 0.0132, 'grad_norm': 5.273317813873291, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.00917431153357029, 'loss_2': 0.003997802734375, 'loss_3': -16.482872009277344, 'loss_4': 0.16854405403137207, 'epoch': 13.19}
{'loss': 0.0298, 'grad_norm': 10.164763450622559, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.025121284648776054, 'loss_2': 0.0046539306640625, 'loss_3': -16.54214096069336, 'loss_4': 0.20257167518138885, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 10:22:39,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:39,694 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:06<49:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:47,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014319267123937607, 'eval_runtime': 3.831, 'eval_samples_per_second': 267.29, 'eval_steps_per_second': 4.176, 'eval_loss_1': 0.00856932532042265, 'eval_loss_2': 0.005749940872192383, 'eval_loss_3': -18.3305721282959, 'eval_loss_4': 0.08774641156196594, 'epoch': 13.2}
{'loss': 0.0201, 'grad_norm': 5.913486003875732, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.012775764800608158, 'loss_2': 0.007282257080078125, 'loss_3': -16.606273651123047, 'loss_4': 0.5697519779205322, 'epoch': 13.2}
{'loss': 0.0264, 'grad_norm': 10.33594036102295, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.02532382495701313, 'loss_2': 0.001087188720703125, 'loss_3': -16.520130157470703, 'loss_4': 0.7961345911026001, 'epoch': 13.21}
{'loss': 0.0169, 'grad_norm': 8.43066120147705, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.015653857961297035, 'loss_2': 0.0012912750244140625, 'loss_3': -16.492353439331055, 'loss_4': 0.30746376514434814, 'epoch': 13.22}
{'loss': 0.0135, 'grad_norm': 4.460351943969727, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.008166183717548847, 'loss_2': 0.00534820556640625, 'loss_3': -16.378013610839844, 'loss_4': 0.31412869691848755, 'epoch': 13.22}
{'loss': 0.0211, 'grad_norm': 6.337135314941406, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.012503167614340782, 'loss_2': 0.0085601806640625, 'loss_3': -16.618816375732422, 'loss_4': 0.6199297308921814, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 10:22:47,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:47,067 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:14<49:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:54,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012321443296968937, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.353, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.00885897595435381, 'eval_loss_2': 0.0034624673426151276, 'eval_loss_3': -18.331865310668945, 'eval_loss_4': 0.39295536279678345, 'epoch': 13.23}
{'loss': 0.0226, 'grad_norm': 11.996681213378906, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.020972048863768578, 'loss_2': 0.0016431808471679688, 'loss_3': -16.527667999267578, 'loss_4': 1.208919644355774, 'epoch': 13.23}
{'loss': 0.0181, 'grad_norm': 7.317577838897705, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.017394499853253365, 'loss_2': 0.0006947517395019531, 'loss_3': -16.408096313476562, 'loss_4': 0.9721184968948364, 'epoch': 13.24}
{'loss': 0.0145, 'grad_norm': 5.180686950683594, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.008053273893892765, 'loss_2': 0.00640106201171875, 'loss_3': -16.60354995727539, 'loss_4': 1.0741593837738037, 'epoch': 13.24}
{'loss': 0.0428, 'grad_norm': 8.849979400634766, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.027543701231479645, 'loss_2': 0.0152435302734375, 'loss_3': -16.500595092773438, 'loss_4': 1.0598403215408325, 'epoch': 13.25}
{'loss': 0.0126, 'grad_norm': 5.256996154785156, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.007391916122287512, 'loss_2': 0.00521087646484375, 'loss_3': -16.25816535949707, 'loss_4': 0.4015271067619324, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 10:22:54,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:54,404 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:21<49:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:23:01,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014276688918471336, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.009846125729382038, 'eval_loss_2': 0.004430562257766724, 'eval_loss_3': -18.33047103881836, 'eval_loss_4': 0.6034883856773376, 'epoch': 13.26}
{'loss': 0.0217, 'grad_norm': 11.075901985168457, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.01987040974199772, 'loss_2': 0.0018711090087890625, 'loss_3': -16.385530471801758, 'loss_4': 0.7848289012908936, 'epoch': 13.26}
{'loss': 0.0162, 'grad_norm': 5.52916145324707, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.009594958275556564, 'loss_2': 0.0066375732421875, 'loss_3': -16.608394622802734, 'loss_4': 0.9878615140914917, 'epoch': 13.27}
{'loss': 0.0378, 'grad_norm': 8.252211570739746, 'learning_rate': 1.675e-05, 'loss_1': 0.03239630162715912, 'loss_2': 0.00539398193359375, 'loss_3': -16.532360076904297, 'loss_4': 0.8998727798461914, 'epoch': 13.27}
{'loss': 0.0194, 'grad_norm': 5.0823822021484375, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.008289135992527008, 'loss_2': 0.01113128662109375, 'loss_3': -16.607959747314453, 'loss_4': 0.5222262144088745, 'epoch': 13.28}
{'loss': 0.0309, 'grad_norm': 9.64544677734375, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.028688162565231323, 'loss_2': 0.00220489501953125, 'loss_3': -16.489797592163086, 'loss_4': 1.5836796760559082, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 10:23:01,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:01,723 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:28<49:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:09,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012997007928788662, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.397, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.009332618676126003, 'eval_loss_2': 0.0036643892526626587, 'eval_loss_3': -18.33867645263672, 'eval_loss_4': 0.6281148791313171, 'epoch': 13.28}
{'loss': 0.0091, 'grad_norm': 5.512695789337158, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.007120210211724043, 'loss_2': 0.0019330978393554688, 'loss_3': -16.617420196533203, 'loss_4': 1.0570025444030762, 'epoch': 13.29}
{'loss': 0.0079, 'grad_norm': 4.441502094268799, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.0047296639531850815, 'loss_2': 0.00321197509765625, 'loss_3': -16.66509246826172, 'loss_4': 1.1874290704727173, 'epoch': 13.3}
{'loss': 0.0234, 'grad_norm': 8.926527976989746, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.021663391962647438, 'loss_2': 0.0017633438110351562, 'loss_3': -16.215557098388672, 'loss_4': 1.0879218578338623, 'epoch': 13.3}
{'loss': 0.0172, 'grad_norm': 5.42382287979126, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.01079275831580162, 'loss_2': 0.0063629150390625, 'loss_3': -16.39374351501465, 'loss_4': 1.0047392845153809, 'epoch': 13.31}
{'loss': 0.0269, 'grad_norm': 7.289071559906006, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.017496826127171516, 'loss_2': 0.00945281982421875, 'loss_3': -16.536479949951172, 'loss_4': 0.8903411030769348, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 10:23:09,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:09,051 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:36<49:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:16,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013632891699671745, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.286, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00968570914119482, 'eval_loss_2': 0.0039471834897994995, 'eval_loss_3': -18.33841896057129, 'eval_loss_4': 0.6283487677574158, 'epoch': 13.31}
{'loss': 0.028, 'grad_norm': 13.972894668579102, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.024118022993206978, 'loss_2': 0.003849029541015625, 'loss_3': -16.580310821533203, 'loss_4': 0.8294128775596619, 'epoch': 13.32}
{'loss': 0.0118, 'grad_norm': 5.395092964172363, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.00883594248443842, 'loss_2': 0.002918243408203125, 'loss_3': -16.49374771118164, 'loss_4': 1.2728464603424072, 'epoch': 13.33}
{'loss': 0.0176, 'grad_norm': 6.268786907196045, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.01739669404923916, 'loss_2': 0.00023794174194335938, 'loss_3': -16.44873809814453, 'loss_4': 1.3006441593170166, 'epoch': 13.33}
{'loss': 0.0119, 'grad_norm': 8.584774017333984, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.010826562531292439, 'loss_2': 0.0011005401611328125, 'loss_3': -16.58319854736328, 'loss_4': 1.046083927154541, 'epoch': 13.34}
{'loss': 0.0142, 'grad_norm': 5.782809734344482, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.011148269288241863, 'loss_2': 0.003032684326171875, 'loss_3': -16.587482452392578, 'loss_4': 0.6646428108215332, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 10:23:16,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:16,384 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [56:43<49:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:23,735 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0141972117125988, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009867529384791851, 'eval_loss_2': 0.004329681396484375, 'eval_loss_3': -18.344083786010742, 'eval_loss_4': 0.7238543629646301, 'epoch': 13.34}
{'loss': 0.0163, 'grad_norm': 7.808966159820557, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.013507362455129623, 'loss_2': 0.002811431884765625, 'loss_3': -16.258033752441406, 'loss_4': 0.9773693680763245, 'epoch': 13.35}
{'loss': 0.0174, 'grad_norm': 5.927903175354004, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.01087125949561596, 'loss_2': 0.006504058837890625, 'loss_3': -16.30203628540039, 'loss_4': 0.9932497143745422, 'epoch': 13.35}
{'loss': 0.0138, 'grad_norm': 5.390915393829346, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.008326278068125248, 'loss_2': 0.005466461181640625, 'loss_3': -16.384023666381836, 'loss_4': 1.1334331035614014, 'epoch': 13.36}
{'loss': 0.0183, 'grad_norm': 6.204775810241699, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.016531597822904587, 'loss_2': 0.001743316650390625, 'loss_3': -16.37372589111328, 'loss_4': 0.5383129119873047, 'epoch': 13.37}
{'loss': 0.016, 'grad_norm': 6.680065631866455, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.01263753417879343, 'loss_2': 0.0033130645751953125, 'loss_3': -16.602981567382812, 'loss_4': 0.8173368573188782, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 10:23:23,735 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:23,735 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [56:50<49:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:31,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01392202265560627, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.744, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010488064959645271, 'eval_loss_2': 0.0034339576959609985, 'eval_loss_3': -18.306779861450195, 'eval_loss_4': 0.7981318235397339, 'epoch': 13.37}
{'loss': 0.0098, 'grad_norm': 4.417038917541504, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.005281499121338129, 'loss_2': 0.00450897216796875, 'loss_3': -16.37295913696289, 'loss_4': 1.0513759851455688, 'epoch': 13.38}
{'loss': 0.0218, 'grad_norm': 9.449581146240234, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.021134909242391586, 'loss_2': 0.0006995201110839844, 'loss_3': -16.393539428710938, 'loss_4': 1.1110889911651611, 'epoch': 13.38}
{'loss': 0.013, 'grad_norm': 4.566817760467529, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.005836217664182186, 'loss_2': 0.00720977783203125, 'loss_3': -16.290361404418945, 'loss_4': 0.6416088342666626, 'epoch': 13.39}
{'loss': 0.015, 'grad_norm': 5.330661296844482, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.009532654657959938, 'loss_2': 0.00547027587890625, 'loss_3': -16.256996154785156, 'loss_4': 1.1376588344573975, 'epoch': 13.4}
{'loss': 0.0129, 'grad_norm': 6.149856090545654, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.00866194162517786, 'loss_2': 0.004268646240234375, 'loss_3': -16.427513122558594, 'loss_4': 1.0333093404769897, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 10:23:31,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:31,073 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [56:58<49:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:38,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013049552217125893, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.156, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.009068679995834827, 'eval_loss_2': 0.003980871289968491, 'eval_loss_3': -18.31275177001953, 'eval_loss_4': 1.0552232265472412, 'epoch': 13.4}
{'loss': 0.0075, 'grad_norm': 4.434648513793945, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.006763986777514219, 'loss_2': 0.0007171630859375, 'loss_3': -16.790828704833984, 'loss_4': 1.6809501647949219, 'epoch': 13.41}
{'loss': 0.0107, 'grad_norm': 5.24610710144043, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.006295781582593918, 'loss_2': 0.004425048828125, 'loss_3': -16.50151824951172, 'loss_4': 1.6202372312545776, 'epoch': 13.41}
{'loss': 0.0175, 'grad_norm': 9.170746803283691, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.014506815932691097, 'loss_2': 0.0029811859130859375, 'loss_3': -16.463533401489258, 'loss_4': 1.3106313943862915, 'epoch': 13.42}
{'loss': 0.0344, 'grad_norm': 9.93199348449707, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.03075934760272503, 'loss_2': 0.003620147705078125, 'loss_3': -16.322383880615234, 'loss_4': 1.9559071063995361, 'epoch': 13.42}
{'loss': 0.0156, 'grad_norm': 8.530770301818848, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.013154126703739166, 'loss_2': 0.002410888671875, 'loss_3': -16.56097984313965, 'loss_4': 2.2165889739990234, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 10:23:38,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:38,405 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:05<49:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:45,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013404338620603085, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.404, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.009554684162139893, 'eval_loss_2': 0.0038496553897857666, 'eval_loss_3': -18.33098030090332, 'eval_loss_4': 1.3437633514404297, 'epoch': 13.43}
{'loss': 0.0072, 'grad_norm': 5.126828670501709, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.007167526986449957, 'loss_2': 4.07099723815918e-05, 'loss_3': -16.365955352783203, 'loss_4': 1.5019880533218384, 'epoch': 13.44}
{'loss': 0.0114, 'grad_norm': 5.526791095733643, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.007715956773608923, 'loss_2': 0.00370025634765625, 'loss_3': -16.395830154418945, 'loss_4': 1.7153745889663696, 'epoch': 13.44}
{'loss': 0.0157, 'grad_norm': 6.051138877868652, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.01013137400150299, 'loss_2': 0.005527496337890625, 'loss_3': -16.436952590942383, 'loss_4': 1.7198991775512695, 'epoch': 13.45}
{'loss': 0.0345, 'grad_norm': 19.214330673217773, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.03129564970731735, 'loss_2': 0.00321197509765625, 'loss_3': -16.489246368408203, 'loss_4': 2.2086076736450195, 'epoch': 13.45}
{'loss': 0.0091, 'grad_norm': 4.571427822113037, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.005457496270537376, 'loss_2': 0.003635406494140625, 'loss_3': -16.445465087890625, 'loss_4': 1.771632194519043, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 10:23:45,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:45,730 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:12<48:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:23:53,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014165669679641724, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01077607274055481, 'eval_loss_2': 0.003389596939086914, 'eval_loss_3': -18.33109474182129, 'eval_loss_4': 1.3805104494094849, 'epoch': 13.46}
{'loss': 0.01, 'grad_norm': 4.894876003265381, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.009823380038142204, 'loss_2': 0.0002224445343017578, 'loss_3': -16.592571258544922, 'loss_4': 2.0827977657318115, 'epoch': 13.47}
{'loss': 0.0175, 'grad_norm': 5.172666072845459, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.009040896780788898, 'loss_2': 0.0084686279296875, 'loss_3': -16.481203079223633, 'loss_4': 2.1966335773468018, 'epoch': 13.47}
{'loss': 0.01, 'grad_norm': 4.591763019561768, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.009226882830262184, 'loss_2': 0.0008020401000976562, 'loss_3': -16.589130401611328, 'loss_4': 1.2414686679840088, 'epoch': 13.48}
{'loss': 0.0064, 'grad_norm': 5.375626087188721, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.005466064438223839, 'loss_2': 0.0009684562683105469, 'loss_3': -16.528888702392578, 'loss_4': 1.545687198638916, 'epoch': 13.48}
{'loss': 0.014, 'grad_norm': 6.0909647941589355, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.011676693335175514, 'loss_2': 0.00231170654296875, 'loss_3': -16.47283172607422, 'loss_4': 1.8100131750106812, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 10:23:53,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:53,053 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:20<48:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:00,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014827298000454903, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01116243191063404, 'eval_loss_2': 0.003664866089820862, 'eval_loss_3': -18.32147216796875, 'eval_loss_4': 1.4008691310882568, 'epoch': 13.49}
{'loss': 0.0246, 'grad_norm': 12.255594253540039, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.021887974813580513, 'loss_2': 0.0027313232421875, 'loss_3': -16.284212112426758, 'loss_4': 1.614583969116211, 'epoch': 13.49}
{'loss': 0.0162, 'grad_norm': 7.353387355804443, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.01570543460547924, 'loss_2': 0.00054168701171875, 'loss_3': -16.463088989257812, 'loss_4': 1.7446622848510742, 'epoch': 13.5}
{'loss': 0.0104, 'grad_norm': 6.6579413414001465, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.008343343622982502, 'loss_2': 0.00201416015625, 'loss_3': -16.258628845214844, 'loss_4': 1.6164137125015259, 'epoch': 13.51}
{'loss': 0.0096, 'grad_norm': 4.965892791748047, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.009093997068703175, 'loss_2': 0.0005440711975097656, 'loss_3': -16.338573455810547, 'loss_4': 1.5801959037780762, 'epoch': 13.51}
{'loss': 0.0087, 'grad_norm': 5.026017665863037, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.0072089312598109245, 'loss_2': 0.00152587890625, 'loss_3': -16.45241928100586, 'loss_4': 1.6760680675506592, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 10:24:00,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:00,379 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:27<48:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:07,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016637839376926422, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010252037085592747, 'eval_loss_2': 0.00638580322265625, 'eval_loss_3': -18.349502563476562, 'eval_loss_4': 1.4429540634155273, 'epoch': 13.52}
{'loss': 0.0156, 'grad_norm': 4.627331733703613, 'learning_rate': 1.65e-05, 'loss_1': 0.006061050109565258, 'loss_2': 0.0095062255859375, 'loss_3': -16.4478816986084, 'loss_4': 1.7380114793777466, 'epoch': 13.52}
{'loss': 0.0125, 'grad_norm': 4.681616306304932, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.0101748863235116, 'loss_2': 0.002292633056640625, 'loss_3': -16.251670837402344, 'loss_4': 1.982551097869873, 'epoch': 13.53}
{'loss': 0.0093, 'grad_norm': 4.6883721351623535, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.004874967969954014, 'loss_2': 0.004375457763671875, 'loss_3': -16.384042739868164, 'loss_4': 1.4590065479278564, 'epoch': 13.53}
{'loss': 0.0443, 'grad_norm': 10.613693237304688, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.03283440321683884, 'loss_2': 0.01146697998046875, 'loss_3': -16.410018920898438, 'loss_4': 1.8533973693847656, 'epoch': 13.54}
{'loss': 0.0132, 'grad_norm': 6.496071815490723, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.011416986584663391, 'loss_2': 0.001750946044921875, 'loss_3': -16.592798233032227, 'loss_4': 1.0621886253356934, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 10:24:07,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:07,714 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:34<48:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:15,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014500079676508904, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010309755802154541, 'eval_loss_2': 0.004190325736999512, 'eval_loss_3': -18.341045379638672, 'eval_loss_4': 1.2704219818115234, 'epoch': 13.55}
{'loss': 0.0198, 'grad_norm': 6.684915542602539, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.010556519031524658, 'loss_2': 0.00921630859375, 'loss_3': -16.32792091369629, 'loss_4': 1.2281370162963867, 'epoch': 13.55}
{'loss': 0.0231, 'grad_norm': 9.081581115722656, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.0196632519364357, 'loss_2': 0.003398895263671875, 'loss_3': -16.211654663085938, 'loss_4': 1.4602162837982178, 'epoch': 13.56}
{'loss': 0.0156, 'grad_norm': 5.035764694213867, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.006915678735822439, 'loss_2': 0.008636474609375, 'loss_3': -16.419898986816406, 'loss_4': 1.4361436367034912, 'epoch': 13.56}
{'loss': 0.03, 'grad_norm': 12.289729118347168, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.02959698997437954, 'loss_2': 0.0004429817199707031, 'loss_3': -16.26898956298828, 'loss_4': 1.51448392868042, 'epoch': 13.57}
{'loss': 0.0099, 'grad_norm': 5.798203945159912, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.0070783416740596294, 'loss_2': 0.0028514862060546875, 'loss_3': -16.447067260742188, 'loss_4': 1.3282560110092163, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 10:24:15,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:15,044 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [57:42<48:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:22,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013979818671941757, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.175, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00937291607260704, 'eval_loss_2': 0.004606902599334717, 'eval_loss_3': -18.324743270874023, 'eval_loss_4': 1.0423307418823242, 'epoch': 13.58}
{'loss': 0.0128, 'grad_norm': 4.9491071701049805, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.007425571326166391, 'loss_2': 0.00537872314453125, 'loss_3': -16.58570671081543, 'loss_4': 1.0953400135040283, 'epoch': 13.58}
{'loss': 0.009, 'grad_norm': 4.7657551765441895, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.007933183573186398, 'loss_2': 0.0010404586791992188, 'loss_3': -16.36910629272461, 'loss_4': 1.5586330890655518, 'epoch': 13.59}
{'loss': 0.0095, 'grad_norm': 5.545483112335205, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.007823577150702477, 'loss_2': 0.0016345977783203125, 'loss_3': -16.507266998291016, 'loss_4': 0.9151521325111389, 'epoch': 13.59}
{'loss': 0.0083, 'grad_norm': 5.0997772216796875, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.00829586572945118, 'loss_2': 5.02467155456543e-05, 'loss_3': -16.186847686767578, 'loss_4': 0.6152343153953552, 'epoch': 13.6}
{'loss': 0.0129, 'grad_norm': 6.180379867553711, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.012459714896976948, 'loss_2': 0.0004696846008300781, 'loss_3': -16.308734893798828, 'loss_4': 1.6593087911605835, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 10:24:22,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:22,372 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [57:49<48:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:24:29,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016705837100744247, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.497, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.010168631561100483, 'eval_loss_2': 0.006537206470966339, 'eval_loss_3': -18.310169219970703, 'eval_loss_4': 0.9420377612113953, 'epoch': 13.6}
{'loss': 0.0128, 'grad_norm': 4.846255779266357, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.007565924432128668, 'loss_2': 0.0052032470703125, 'loss_3': -16.27033233642578, 'loss_4': 1.4077421426773071, 'epoch': 13.61}
{'loss': 0.0254, 'grad_norm': 6.386970520019531, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.013772360980510712, 'loss_2': 0.01160430908203125, 'loss_3': -16.35291290283203, 'loss_4': 1.3828343152999878, 'epoch': 13.62}
{'loss': 0.0161, 'grad_norm': 4.567135334014893, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.005386022385209799, 'loss_2': 0.010711669921875, 'loss_3': -16.326797485351562, 'loss_4': 0.7702546119689941, 'epoch': 13.62}
{'loss': 0.0272, 'grad_norm': 12.14819049835205, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.024233724921941757, 'loss_2': 0.00301361083984375, 'loss_3': -16.542892456054688, 'loss_4': 1.4570338726043701, 'epoch': 13.63}
{'loss': 0.0178, 'grad_norm': 5.23777961730957, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.011912149377167225, 'loss_2': 0.0059051513671875, 'loss_3': -16.37944984436035, 'loss_4': 0.7550761699676514, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 10:24:29,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:29,691 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [57:56<48:28,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:24:37,013 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015443887561559677, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.34, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.010438438504934311, 'eval_loss_2': 0.005005449056625366, 'eval_loss_3': -18.295936584472656, 'eval_loss_4': 0.8976160883903503, 'epoch': 13.63}
{'loss': 0.0231, 'grad_norm': 15.382760047912598, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.01784033700823784, 'loss_2': 0.005214691162109375, 'loss_3': -16.202085494995117, 'loss_4': 1.5144445896148682, 'epoch': 13.64}
{'loss': 0.0181, 'grad_norm': 5.518611431121826, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.011543714441359043, 'loss_2': 0.0065765380859375, 'loss_3': -16.465354919433594, 'loss_4': 0.9913927316665649, 'epoch': 13.65}
{'loss': 0.0154, 'grad_norm': 6.726988315582275, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.014187635853886604, 'loss_2': 0.0012521743774414062, 'loss_3': -16.31110954284668, 'loss_4': 1.237985610961914, 'epoch': 13.65}
{'loss': 0.0104, 'grad_norm': 4.906712055206299, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.008028409443795681, 'loss_2': 0.0023651123046875, 'loss_3': -16.526641845703125, 'loss_4': 1.2161164283752441, 'epoch': 13.66}
{'loss': 0.0328, 'grad_norm': 11.275732040405273, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.027950119227170944, 'loss_2': 0.0048370361328125, 'loss_3': -16.730758666992188, 'loss_4': 1.186017632484436, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 10:24:37,013 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:37,013 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:04<48:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:44,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012895515188574791, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.044, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009674250148236752, 'eval_loss_2': 0.003221265971660614, 'eval_loss_3': -18.306001663208008, 'eval_loss_4': 0.8856455683708191, 'epoch': 13.66}
{'loss': 0.0126, 'grad_norm': 5.400178909301758, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.009770486503839493, 'loss_2': 0.002819061279296875, 'loss_3': -16.399194717407227, 'loss_4': 1.077283501625061, 'epoch': 13.67}
{'loss': 0.0144, 'grad_norm': 4.6231584548950195, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.008617018349468708, 'loss_2': 0.00582122802734375, 'loss_3': -16.31346893310547, 'loss_4': 0.859387218952179, 'epoch': 13.67}
{'loss': 0.0215, 'grad_norm': 8.262802124023438, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.01614275760948658, 'loss_2': 0.00531005859375, 'loss_3': -16.32798957824707, 'loss_4': 1.2452702522277832, 'epoch': 13.68}
{'loss': 0.0194, 'grad_norm': 8.398331642150879, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.014088502153754234, 'loss_2': 0.00530242919921875, 'loss_3': -16.40927505493164, 'loss_4': 1.1302320957183838, 'epoch': 13.69}
{'loss': 0.0074, 'grad_norm': 4.8464274406433105, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.006129643879830837, 'loss_2': 0.001247406005859375, 'loss_3': -16.394737243652344, 'loss_4': 1.0830237865447998, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 10:24:44,350 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:44,350 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:11<48:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:51,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012060057371854782, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.613, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009006473235785961, 'eval_loss_2': 0.0030535832047462463, 'eval_loss_3': -18.30159568786621, 'eval_loss_4': 0.9431667923927307, 'epoch': 13.69}
{'loss': 0.0077, 'grad_norm': 5.204133033752441, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.0072139776311814785, 'loss_2': 0.0004820823669433594, 'loss_3': -16.454296112060547, 'loss_4': 1.3148212432861328, 'epoch': 13.7}
{'loss': 0.0127, 'grad_norm': 5.438289642333984, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.012259663082659245, 'loss_2': 0.0004489421844482422, 'loss_3': -16.094192504882812, 'loss_4': 1.1975784301757812, 'epoch': 13.7}
{'loss': 0.0127, 'grad_norm': 5.844791889190674, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.011267117224633694, 'loss_2': 0.0014553070068359375, 'loss_3': -16.47503662109375, 'loss_4': 1.2227153778076172, 'epoch': 13.71}
{'loss': 0.0107, 'grad_norm': 4.999364376068115, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.009650160558521748, 'loss_2': 0.0010509490966796875, 'loss_3': -16.407611846923828, 'loss_4': 1.4035203456878662, 'epoch': 13.72}
{'loss': 0.0144, 'grad_norm': 12.47876262664795, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.012817761860787868, 'loss_2': 0.0015506744384765625, 'loss_3': -16.48444938659668, 'loss_4': 1.2771902084350586, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 10:24:51,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:51,701 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:18<48:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:59,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010594462975859642, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007597660645842552, 'eval_loss_2': 0.00299680233001709, 'eval_loss_3': -18.296571731567383, 'eval_loss_4': 0.9352084398269653, 'epoch': 13.72}
{'loss': 0.0153, 'grad_norm': 7.0545973777771, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.014196036383509636, 'loss_2': 0.0011091232299804688, 'loss_3': -16.20098304748535, 'loss_4': 1.3069572448730469, 'epoch': 13.73}
{'loss': 0.0259, 'grad_norm': 9.252463340759277, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.019170571118593216, 'loss_2': 0.00673675537109375, 'loss_3': -16.216073989868164, 'loss_4': 1.3548309803009033, 'epoch': 13.73}
{'loss': 0.0169, 'grad_norm': 7.985942363739014, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.014729195274412632, 'loss_2': 0.00215911865234375, 'loss_3': -16.41427230834961, 'loss_4': 1.5314579010009766, 'epoch': 13.74}
{'loss': 0.0121, 'grad_norm': 5.154264450073242, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.006889919750392437, 'loss_2': 0.005252838134765625, 'loss_3': -16.364723205566406, 'loss_4': 1.0117669105529785, 'epoch': 13.74}
{'loss': 0.0101, 'grad_norm': 5.139187335968018, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.009299148805439472, 'loss_2': 0.0007996559143066406, 'loss_3': -16.34076690673828, 'loss_4': 0.5102298259735107, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 10:24:59,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:59,040 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:26<48:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:06,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011269839480519295, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.244, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00684595201164484, 'eval_loss_2': 0.00442388653755188, 'eval_loss_3': -18.29536247253418, 'eval_loss_4': 0.7985392212867737, 'epoch': 13.75}
{'loss': 0.0082, 'grad_norm': 4.937897682189941, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.005856620147824287, 'loss_2': 0.0023193359375, 'loss_3': -16.46617317199707, 'loss_4': 0.6622453927993774, 'epoch': 13.76}
{'loss': 0.0212, 'grad_norm': 9.08133316040039, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.01476273313164711, 'loss_2': 0.00641632080078125, 'loss_3': -16.17014503479004, 'loss_4': 1.6626858711242676, 'epoch': 13.76}
{'loss': 0.0253, 'grad_norm': 8.152017593383789, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.019988125190138817, 'loss_2': 0.0052642822265625, 'loss_3': -16.189817428588867, 'loss_4': 0.9920985698699951, 'epoch': 13.77}
{'loss': 0.0241, 'grad_norm': 8.41931438446045, 'learning_rate': 1.625e-05, 'loss_1': 0.02380659244954586, 'loss_2': 0.00032520294189453125, 'loss_3': -16.279239654541016, 'loss_4': 1.0827484130859375, 'epoch': 13.77}
{'loss': 0.0279, 'grad_norm': 9.239825248718262, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.021819818764925003, 'loss_2': 0.0061187744140625, 'loss_3': -16.397310256958008, 'loss_4': 0.6958729028701782, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 10:25:06,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:06,374 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:29<48:13,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 10:25:10,163 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370
[INFO|configuration_utils.py:420] 2025-01-21 10:25:10,165 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370/config.json                                                                             
{'eval_loss': 0.009341602213680744, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.349, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0063912332989275455, 'eval_loss_2': 0.0029503703117370605, 'eval_loss_3': -18.282690048217773, 'eval_loss_4': 0.7781618237495422, 'epoch': 13.78}
[INFO|modeling_utils.py:2988] 2025-01-21 10:25:10,639 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:25:10,640 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:25:10,641 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:25:11,501 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-780] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:34<52:56,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 10:25:15,146 >>
{'loss': 0.0058, 'grad_norm': 4.221284866333008, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.00453179283067584, 'loss_2': 0.0012912750244140625, 'loss_3': -16.430908203125, 'loss_4': 0.3881155252456665, 'epoch': 13.78}
{'loss': 0.0155, 'grad_norm': 5.159859657287598, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.007375616114586592, 'loss_2': 0.008087158203125, 'loss_3': -16.352767944335938, 'loss_4': 1.437833309173584, 'epoch': 13.79}
{'loss': 0.0143, 'grad_norm': 7.088934898376465, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.010462249629199505, 'loss_2': 0.0038242340087890625, 'loss_3': -16.359861373901367, 'loss_4': 1.0837754011154175, 'epoch': 13.8}
{'loss': 0.0077, 'grad_norm': 5.273700714111328, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.007653582375496626, 'loss_2': 2.7418136596679688e-06, 'loss_3': -16.22225570678711, 'loss_4': 0.7074272632598877, 'epoch': 13.8}
{'loss': 0.0106, 'grad_norm': 4.707760810852051, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.005286829546093941, 'loss_2': 0.005279541015625, 'loss_3': -16.3864803314209, 'loss_4': 1.3085718154907227, 'epoch': 13.81}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:25:15,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:15,146 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:38<52:56,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 10:25:18,938 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375
[INFO|configuration_utils.py:420] 2025-01-21 10:25:18,939 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375/config.json                                                                             
{'eval_loss': 0.008698164485394955, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.116, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.006763241719454527, 'eval_loss_2': 0.001934923231601715, 'eval_loss_3': -18.30460548400879, 'eval_loss_4': 0.8677242398262024, 'epoch': 13.81}
[INFO|modeling_utils.py:2988] 2025-01-21 10:25:19,439 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:25:19,440 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:25:19,441 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:25:20,388 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2370] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [58:44<54:51,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 10:25:24,211 >>
{'loss': 0.0229, 'grad_norm': 12.961295127868652, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.019029855728149414, 'loss_2': 0.003833770751953125, 'loss_3': -16.244884490966797, 'loss_4': 1.8284926414489746, 'epoch': 13.81}
{'loss': 0.0193, 'grad_norm': 7.299466133117676, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.01693011447787285, 'loss_2': 0.002384185791015625, 'loss_3': -16.561260223388672, 'loss_4': 1.275657296180725, 'epoch': 13.82}
{'loss': 0.0252, 'grad_norm': 7.149275302886963, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.02010251209139824, 'loss_2': 0.0051422119140625, 'loss_3': -16.39385986328125, 'loss_4': 0.8783218264579773, 'epoch': 13.83}
{'loss': 0.0269, 'grad_norm': 6.132197856903076, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.020487170666456223, 'loss_2': 0.006420135498046875, 'loss_3': -16.302459716796875, 'loss_4': 1.1621114015579224, 'epoch': 13.83}
{'loss': 0.0096, 'grad_norm': 4.833892822265625, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.0093638114631176, 'loss_2': 0.00028514862060546875, 'loss_3': -16.40622329711914, 'loss_4': 1.2013846635818481, 'epoch': 13.84}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:25:24,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:24,211 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [58:51<49:05,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:25:31,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009787863120436668, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007289220578968525, 'eval_loss_2': 0.002498641610145569, 'eval_loss_3': -18.30978775024414, 'eval_loss_4': 0.9597319960594177, 'epoch': 13.84}
{'loss': 0.0144, 'grad_norm': 6.470948219299316, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.010891767218708992, 'loss_2': 0.003498077392578125, 'loss_3': -16.62582778930664, 'loss_4': 1.3417171239852905, 'epoch': 13.84}
{'loss': 0.0096, 'grad_norm': 4.459168434143066, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.008758395910263062, 'loss_2': 0.000881195068359375, 'loss_3': -16.320219039916992, 'loss_4': 1.5299177169799805, 'epoch': 13.85}
{'loss': 0.0238, 'grad_norm': 6.709188938140869, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.016739893704652786, 'loss_2': 0.00701141357421875, 'loss_3': -16.328969955444336, 'loss_4': 1.1701241731643677, 'epoch': 13.85}
{'loss': 0.01, 'grad_norm': 4.955310821533203, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.007935947738587856, 'loss_2': 0.002017974853515625, 'loss_3': -16.396240234375, 'loss_4': 1.646332025527954, 'epoch': 13.86}
{'loss': 0.011, 'grad_norm': 4.523991584777832, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.007539287209510803, 'loss_2': 0.00341796875, 'loss_3': -16.389545440673828, 'loss_4': 1.1773557662963867, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 10:25:31,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:31,558 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [58:58<47:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:38,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00983019731938839, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.642, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.007440587040036917, 'eval_loss_2': 0.0023896098136901855, 'eval_loss_3': -18.324283599853516, 'eval_loss_4': 0.9678418636322021, 'epoch': 13.87}
{'loss': 0.026, 'grad_norm': 9.371172904968262, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.024665219709277153, 'loss_2': 0.001308441162109375, 'loss_3': -16.37899398803711, 'loss_4': 1.4069907665252686, 'epoch': 13.87}
{'loss': 0.0137, 'grad_norm': 7.069298267364502, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.013612220995128155, 'loss_2': 4.267692565917969e-05, 'loss_3': -16.49718475341797, 'loss_4': 1.7062753438949585, 'epoch': 13.88}
{'loss': 0.0208, 'grad_norm': 7.912503242492676, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.017849892377853394, 'loss_2': 0.002910614013671875, 'loss_3': -16.634016036987305, 'loss_4': 1.422242283821106, 'epoch': 13.88}
{'loss': 0.0154, 'grad_norm': 6.752491474151611, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.014608109369874, 'loss_2': 0.0007448196411132812, 'loss_3': -16.295713424682617, 'loss_4': 1.1056134700775146, 'epoch': 13.89}
{'loss': 0.0072, 'grad_norm': 4.686924457550049, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.005654701963067055, 'loss_2': 0.0015583038330078125, 'loss_3': -16.499900817871094, 'loss_4': 1.157637596130371, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 10:25:38,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:38,872 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:06<47:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:46,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009706521406769753, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006963388994336128, 'eval_loss_2': 0.0027431324124336243, 'eval_loss_3': -18.311525344848633, 'eval_loss_4': 0.898147463798523, 'epoch': 13.9}
{'loss': 0.0268, 'grad_norm': 8.303176879882812, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.019285010173916817, 'loss_2': 0.00756072998046875, 'loss_3': -16.309755325317383, 'loss_4': 0.7629379034042358, 'epoch': 13.9}
{'loss': 0.023, 'grad_norm': 10.312151908874512, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.020672280341386795, 'loss_2': 0.002300262451171875, 'loss_3': -16.50345230102539, 'loss_4': 0.843652606010437, 'epoch': 13.91}
{'loss': 0.0094, 'grad_norm': 4.258315086364746, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.004713345784693956, 'loss_2': 0.00470733642578125, 'loss_3': -16.52121353149414, 'loss_4': 1.1102648973464966, 'epoch': 13.91}
{'loss': 0.0221, 'grad_norm': 11.127104759216309, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.016016118228435516, 'loss_2': 0.00603485107421875, 'loss_3': -16.287595748901367, 'loss_4': 1.4352383613586426, 'epoch': 13.92}
{'loss': 0.0144, 'grad_norm': 4.484342575073242, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.013512177392840385, 'loss_2': 0.0009107589721679688, 'loss_3': -16.558128356933594, 'loss_4': 1.8286066055297852, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 10:25:46,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:46,195 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:13<47:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:53,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011051188223063946, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.596, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007581096142530441, 'eval_loss_2': 0.003470093011856079, 'eval_loss_3': -18.298885345458984, 'eval_loss_4': 0.7808840274810791, 'epoch': 13.92}
{'loss': 0.0243, 'grad_norm': 11.182305335998535, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.02428828366100788, 'loss_2': 5.930662155151367e-05, 'loss_3': -16.43929100036621, 'loss_4': 1.1775645017623901, 'epoch': 13.93}
{'loss': 0.0085, 'grad_norm': 4.682858467102051, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.00799702201038599, 'loss_2': 0.0005245208740234375, 'loss_3': -16.35895538330078, 'loss_4': 1.2212343215942383, 'epoch': 13.94}
{'loss': 0.0137, 'grad_norm': 6.271584510803223, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.011906985193490982, 'loss_2': 0.0017518997192382812, 'loss_3': -16.469560623168945, 'loss_4': 0.5395174026489258, 'epoch': 13.94}
{'loss': 0.014, 'grad_norm': 4.5859904289245605, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.007803198881447315, 'loss_2': 0.006195068359375, 'loss_3': -16.42092514038086, 'loss_4': 0.8343533277511597, 'epoch': 13.95}
{'loss': 0.0195, 'grad_norm': 6.58169412612915, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.016912497580051422, 'loss_2': 0.00260162353515625, 'loss_3': -16.396591186523438, 'loss_4': 0.8717058897018433, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 10:25:53,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:53,521 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:20<47:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:00,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010835682973265648, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.06, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007786860223859549, 'eval_loss_2': 0.003048822283744812, 'eval_loss_3': -18.301998138427734, 'eval_loss_4': 0.5980062484741211, 'epoch': 13.95}
{'loss': 0.0221, 'grad_norm': 5.785409450531006, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.015169581398367882, 'loss_2': 0.00695037841796875, 'loss_3': -16.363304138183594, 'loss_4': 0.9953664541244507, 'epoch': 13.96}
{'loss': 0.0138, 'grad_norm': 4.975091457366943, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.007940223440527916, 'loss_2': 0.0058746337890625, 'loss_3': -16.522438049316406, 'loss_4': 1.0640754699707031, 'epoch': 13.97}
{'loss': 0.0162, 'grad_norm': 6.762185573577881, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.010738415643572807, 'loss_2': 0.005462646484375, 'loss_3': -16.37495994567871, 'loss_4': 0.5355541706085205, 'epoch': 13.97}
{'loss': 0.013, 'grad_norm': 5.325749397277832, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.00878139678388834, 'loss_2': 0.00421142578125, 'loss_3': -16.536975860595703, 'loss_4': 0.6926699876785278, 'epoch': 13.98}
{'loss': 0.033, 'grad_norm': 9.769864082336426, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.0223707165569067, 'loss_2': 0.0106658935546875, 'loss_3': -16.34827423095703, 'loss_4': 0.6646490097045898, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 10:26:00,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:00,872 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:27<45:40,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:26:07,912 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014391828328371048, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007854271680116653, 'eval_loss_2': 0.0065375566482543945, 'eval_loss_3': -18.313844680786133, 'eval_loss_4': 0.3892137110233307, 'epoch': 13.98}
{'loss': 0.0283, 'grad_norm': 10.349954605102539, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.021222013980150223, 'loss_2': 0.007030487060546875, 'loss_3': -16.25562286376953, 'loss_4': 0.3862902820110321, 'epoch': 13.99}
{'loss': 0.0379, 'grad_norm': 12.19814395904541, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.027940548956394196, 'loss_2': 0.0099945068359375, 'loss_3': -16.33440589904785, 'loss_4': 0.563720703125, 'epoch': 13.99}
{'loss': 0.0128, 'grad_norm': 6.363044261932373, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.0032374903094023466, 'loss_2': 0.0095977783203125, 'loss_3': -16.660022735595703, 'loss_4': 0.9247657656669617, 'epoch': 14.0}
{'loss': 0.0187, 'grad_norm': 6.207254886627197, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.01629764772951603, 'loss_2': 0.002384185791015625, 'loss_3': -16.40808868408203, 'loss_4': 0.4508191645145416, 'epoch': 14.01}
{'loss': 0.0307, 'grad_norm': 10.687055587768555, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.019737757742404938, 'loss_2': 0.0109710693359375, 'loss_3': -16.54170799255371, 'loss_4': 0.4702574908733368, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 10:26:07,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:07,912 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:35<47:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:26:15,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013818961568176746, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.672, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0078053888864815235, 'eval_loss_2': 0.0060135722160339355, 'eval_loss_3': -18.330015182495117, 'eval_loss_4': 0.26190704107284546, 'epoch': 14.01}
{'loss': 0.0108, 'grad_norm': 5.097285747528076, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.005369642749428749, 'loss_2': 0.00540924072265625, 'loss_3': -16.41021156311035, 'loss_4': 0.6878868341445923, 'epoch': 14.02}
{'loss': 0.013, 'grad_norm': 5.2815775871276855, 'learning_rate': 1.6e-05, 'loss_1': 0.008502609096467495, 'loss_2': 0.00446319580078125, 'loss_3': -16.598304748535156, 'loss_4': 0.8747594356536865, 'epoch': 14.02}
{'loss': 0.0121, 'grad_norm': 4.363755226135254, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.006570682395249605, 'loss_2': 0.005535125732421875, 'loss_3': -16.43208885192871, 'loss_4': 0.8553535342216492, 'epoch': 14.03}
{'loss': 0.0148, 'grad_norm': 7.180734157562256, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.014216427691280842, 'loss_2': 0.0005769729614257812, 'loss_3': -16.368925094604492, 'loss_4': 1.2148092985153198, 'epoch': 14.03}
{'loss': 0.0228, 'grad_norm': 5.5659098625183105, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.013554085046052933, 'loss_2': 0.0092926025390625, 'loss_3': -16.413227081298828, 'loss_4': 0.4428805112838745, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 10:26:15,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:15,251 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:42<47:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:22,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01136940810829401, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.154, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00746238324791193, 'eval_loss_2': 0.00390702486038208, 'eval_loss_3': -18.320568084716797, 'eval_loss_4': 0.34520938992500305, 'epoch': 14.04}
{'loss': 0.032, 'grad_norm': 11.181577682495117, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.028421789407730103, 'loss_2': 0.0035800933837890625, 'loss_3': -16.314634323120117, 'loss_4': 0.5771002769470215, 'epoch': 14.05}
{'loss': 0.0298, 'grad_norm': 8.050010681152344, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.023297250270843506, 'loss_2': 0.00649261474609375, 'loss_3': -16.40570068359375, 'loss_4': 0.26582640409469604, 'epoch': 14.05}
{'loss': 0.0155, 'grad_norm': 5.5593085289001465, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.012419281527400017, 'loss_2': 0.003086090087890625, 'loss_3': -16.512065887451172, 'loss_4': 0.6452654600143433, 'epoch': 14.06}
{'loss': 0.017, 'grad_norm': 8.324277877807617, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.015095001086592674, 'loss_2': 0.001873016357421875, 'loss_3': -16.541810989379883, 'loss_4': 0.860849916934967, 'epoch': 14.06}
{'loss': 0.0129, 'grad_norm': 5.307082176208496, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.007600216194987297, 'loss_2': 0.00525665283203125, 'loss_3': -16.340206146240234, 'loss_4': 1.0522618293762207, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 10:26:22,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:22,588 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 2425/5160 [59:49<47:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:29,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012324709445238113, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.168, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00725569250062108, 'eval_loss_2': 0.00506901741027832, 'eval_loss_3': -18.313125610351562, 'eval_loss_4': 0.524868905544281, 'epoch': 14.07}
{'loss': 0.011, 'grad_norm': 4.850209712982178, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.00960505660623312, 'loss_2': 0.0014295578002929688, 'loss_3': -16.391937255859375, 'loss_4': 0.605679988861084, 'epoch': 14.08}
{'loss': 0.0236, 'grad_norm': 7.052173614501953, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.019588502123951912, 'loss_2': 0.00397491455078125, 'loss_3': -16.34674072265625, 'loss_4': 1.0617434978485107, 'epoch': 14.08}
{'loss': 0.0254, 'grad_norm': 9.189289093017578, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.019905120134353638, 'loss_2': 0.005462646484375, 'loss_3': -16.49388885498047, 'loss_4': 1.0065362453460693, 'epoch': 14.09}
{'loss': 0.0088, 'grad_norm': 4.7732439041137695, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.007405842654407024, 'loss_2': 0.001392364501953125, 'loss_3': -16.62687110900879, 'loss_4': 1.076378345489502, 'epoch': 14.09}
{'loss': 0.0055, 'grad_norm': 4.652666091918945, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.004315190017223358, 'loss_2': 0.0011472702026367188, 'loss_3': -16.339143753051758, 'loss_4': 0.848004162311554, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 10:26:29,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:29,933 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 2425/5160 [59:53<47:19,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 10:26:33,724 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425
[INFO|configuration_utils.py:420] 2025-01-21 10:26:33,726 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425/config.json                                                                             
{'eval_loss': 0.00856318511068821, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.184, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.005877132061868906, 'eval_loss_2': 0.002686053514480591, 'eval_loss_3': -18.297809600830078, 'eval_loss_4': 0.84386146068573, 'epoch': 14.1}
[INFO|modeling_utils.py:2988] 2025-01-21 10:26:34,207 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:26:34,208 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:26:34,209 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:26:35,066 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2375] due to args.save_total_limit
 47%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                     | 2430/5160 [59:58<51:52,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 10:26:38,702 >>
{'loss': 0.0236, 'grad_norm': 12.10500717163086, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.02321222983300686, 'loss_2': 0.0004286766052246094, 'loss_3': -16.414676666259766, 'loss_4': 1.4353296756744385, 'epoch': 14.1}
{'loss': 0.0229, 'grad_norm': 13.650729179382324, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.020226968452334404, 'loss_2': 0.002643585205078125, 'loss_3': -16.406272888183594, 'loss_4': 0.7084291577339172, 'epoch': 14.11}
{'loss': 0.0077, 'grad_norm': 4.668857574462891, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.0068022338673472404, 'loss_2': 0.0009241104125976562, 'loss_3': -16.49204444885254, 'loss_4': 0.8893986940383911, 'epoch': 14.12}
{'loss': 0.0115, 'grad_norm': 4.812416076660156, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.009553080424666405, 'loss_2': 0.00196075439453125, 'loss_3': -16.49675750732422, 'loss_4': 1.5447827577590942, 'epoch': 14.12}
{'loss': 0.0166, 'grad_norm': 5.395153999328613, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.010692098177969456, 'loss_2': 0.005954742431640625, 'loss_3': -16.276527404785156, 'loss_4': 1.0823125839233398, 'epoch': 14.13}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:26:38,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:38,702 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:02<51:52,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 10:26:42,494 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430
[INFO|configuration_utils.py:420] 2025-01-21 10:26:42,495 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430/config.json                                                                             
{'eval_loss': 0.008089235983788967, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.109, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.005932077299803495, 'eval_loss_2': 0.002157159149646759, 'eval_loss_3': -18.295320510864258, 'eval_loss_4': 1.072587251663208, 'epoch': 14.13}
[INFO|modeling_utils.py:2988] 2025-01-21 10:26:43,013 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:26:43,014 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:26:43,014 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:26:43,930 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2425] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:07<52:43,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 10:26:47,544 >>
{'loss': 0.0178, 'grad_norm': 7.050968647003174, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.014977974817156792, 'loss_2': 0.0027923583984375, 'loss_3': -16.505077362060547, 'loss_4': 1.13572359085083, 'epoch': 14.13}
{'loss': 0.0175, 'grad_norm': 8.015904426574707, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.0132629768922925, 'loss_2': 0.0042572021484375, 'loss_3': -16.358959197998047, 'loss_4': 1.7335455417633057, 'epoch': 14.14}
{'loss': 0.0151, 'grad_norm': 5.527559757232666, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.015055445022881031, 'loss_2': 7.212162017822266e-05, 'loss_3': -16.45545196533203, 'loss_4': 1.4153451919555664, 'epoch': 14.15}
{'loss': 0.0151, 'grad_norm': 6.435551643371582, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.011729354970157146, 'loss_2': 0.0033512115478515625, 'loss_3': -16.66097640991211, 'loss_4': 1.7682750225067139, 'epoch': 14.15}
{'loss': 0.0132, 'grad_norm': 5.242314338684082, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.010351324453949928, 'loss_2': 0.00286865234375, 'loss_3': -16.476682662963867, 'loss_4': 1.409471035003662, 'epoch': 14.16}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:26:47,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:47,544 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:14<48:05,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:26:54,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009362977929413319, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.272, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007733565755188465, 'eval_loss_2': 0.0016294121742248535, 'eval_loss_3': -18.288013458251953, 'eval_loss_4': 1.1756163835525513, 'epoch': 14.16}
{'loss': 0.0184, 'grad_norm': 5.819819927215576, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.01820145733654499, 'loss_2': 0.0001919269561767578, 'loss_3': -16.55193328857422, 'loss_4': 1.2144198417663574, 'epoch': 14.16}
{'loss': 0.0153, 'grad_norm': 5.2572784423828125, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.011231213808059692, 'loss_2': 0.004100799560546875, 'loss_3': -16.198719024658203, 'loss_4': 1.6199345588684082, 'epoch': 14.17}
{'loss': 0.0204, 'grad_norm': 5.617815971374512, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.010239657945930958, 'loss_2': 0.0102081298828125, 'loss_3': -16.338415145874023, 'loss_4': 1.168832540512085, 'epoch': 14.17}
{'loss': 0.0214, 'grad_norm': 5.35671854019165, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.013044551014900208, 'loss_2': 0.008331298828125, 'loss_3': -16.508451461791992, 'loss_4': 1.180821418762207, 'epoch': 14.18}
{'loss': 0.0209, 'grad_norm': 9.467083930969238, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.01847734861075878, 'loss_2': 0.002460479736328125, 'loss_3': -16.294841766357422, 'loss_4': 1.3036565780639648, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 10:26:54,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:54,913 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:22<47:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:02,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011419735848903656, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.966, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00884004682302475, 'eval_loss_2': 0.0025796890258789062, 'eval_loss_3': -18.276222229003906, 'eval_loss_4': 1.1699302196502686, 'epoch': 14.19}
{'loss': 0.0417, 'grad_norm': 11.949743270874023, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.03922397270798683, 'loss_2': 0.002475738525390625, 'loss_3': -16.57309341430664, 'loss_4': 1.291046142578125, 'epoch': 14.19}
{'loss': 0.0172, 'grad_norm': 5.2144598960876465, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.012757038697600365, 'loss_2': 0.00440216064453125, 'loss_3': -16.29509735107422, 'loss_4': 1.124646782875061, 'epoch': 14.2}
{'loss': 0.0224, 'grad_norm': 6.898253440856934, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.02156728506088257, 'loss_2': 0.0008535385131835938, 'loss_3': -16.348526000976562, 'loss_4': 1.3138415813446045, 'epoch': 14.2}
{'loss': 0.0112, 'grad_norm': 4.847609996795654, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.008597255684435368, 'loss_2': 0.00264739990234375, 'loss_3': -16.230958938598633, 'loss_4': 1.5628938674926758, 'epoch': 14.21}
{'loss': 0.0135, 'grad_norm': 5.973539352416992, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.011874816380441189, 'loss_2': 0.0015974044799804688, 'loss_3': -16.271392822265625, 'loss_4': 1.6616077423095703, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 10:27:02,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:02,253 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:29<46:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:09,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010314919985830784, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.94, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00809684582054615, 'eval_loss_2': 0.0022180750966072083, 'eval_loss_3': -18.282909393310547, 'eval_loss_4': 1.1295008659362793, 'epoch': 14.22}
{'loss': 0.0148, 'grad_norm': 6.210382461547852, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.014645115472376347, 'loss_2': 0.00018274784088134766, 'loss_3': -16.56607437133789, 'loss_4': 1.1572520732879639, 'epoch': 14.22}
{'loss': 0.0188, 'grad_norm': 8.361479759216309, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.01780158281326294, 'loss_2': 0.0009937286376953125, 'loss_3': -16.518817901611328, 'loss_4': 1.4283592700958252, 'epoch': 14.23}
{'loss': 0.0186, 'grad_norm': 5.430724620819092, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.014928502030670643, 'loss_2': 0.0036640167236328125, 'loss_3': -16.102367401123047, 'loss_4': 1.3077569007873535, 'epoch': 14.23}
{'loss': 0.0201, 'grad_norm': 7.757659912109375, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.017197180539369583, 'loss_2': 0.0029449462890625, 'loss_3': -16.31692886352539, 'loss_4': 1.7817484140396118, 'epoch': 14.24}
{'loss': 0.027, 'grad_norm': 5.173399925231934, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.023236196488142014, 'loss_2': 0.0037689208984375, 'loss_3': -16.459035873413086, 'loss_4': 1.6110491752624512, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 10:27:09,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:09,593 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:36<46:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:16,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010377415455877781, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.931, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00799662433564663, 'eval_loss_2': 0.002380792051553726, 'eval_loss_3': -18.27837562561035, 'eval_loss_4': 1.013146996498108, 'epoch': 14.24}
{'loss': 0.0258, 'grad_norm': 11.659290313720703, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.023431509733200073, 'loss_2': 0.0023956298828125, 'loss_3': -16.326541900634766, 'loss_4': 1.339381456375122, 'epoch': 14.25}
{'loss': 0.0137, 'grad_norm': 4.960354328155518, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.010484007187187672, 'loss_2': 0.003192901611328125, 'loss_3': -16.431272506713867, 'loss_4': 1.1406395435333252, 'epoch': 14.26}
{'loss': 0.0308, 'grad_norm': 10.178083419799805, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.02812882699072361, 'loss_2': 0.00266265869140625, 'loss_3': -16.46002769470215, 'loss_4': 1.7506706714630127, 'epoch': 14.26}
{'loss': 0.0138, 'grad_norm': 5.320534706115723, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.008712190203368664, 'loss_2': 0.005096435546875, 'loss_3': -16.27203369140625, 'loss_4': 0.9848524928092957, 'epoch': 14.27}
{'loss': 0.0106, 'grad_norm': 5.499839782714844, 'learning_rate': 1.575e-05, 'loss_1': 0.009273277595639229, 'loss_2': 0.0012845993041992188, 'loss_3': -16.319177627563477, 'loss_4': 1.2222604751586914, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 10:27:16,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:16,937 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:44<46:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:24,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009969479404389858, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.896, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00789486151188612, 'eval_loss_2': 0.0020746178925037384, 'eval_loss_3': -18.28590965270996, 'eval_loss_4': 1.0801944732666016, 'epoch': 14.27}
{'loss': 0.0203, 'grad_norm': 5.730374336242676, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.010957580991089344, 'loss_2': 0.009368896484375, 'loss_3': -16.421916961669922, 'loss_4': 1.6796541213989258, 'epoch': 14.28}
{'loss': 0.0275, 'grad_norm': 12.403059005737305, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.024748530238866806, 'loss_2': 0.002750396728515625, 'loss_3': -16.30044174194336, 'loss_4': 0.8869131207466125, 'epoch': 14.28}
{'loss': 0.0124, 'grad_norm': 6.198559284210205, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.011575746349990368, 'loss_2': 0.0008463859558105469, 'loss_3': -16.481679916381836, 'loss_4': 1.8353850841522217, 'epoch': 14.29}
{'loss': 0.0096, 'grad_norm': 5.208466053009033, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.008152985945343971, 'loss_2': 0.0014190673828125, 'loss_3': -16.496746063232422, 'loss_4': 1.370704174041748, 'epoch': 14.3}
{'loss': 0.0103, 'grad_norm': 4.756959915161133, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.0071103875525295734, 'loss_2': 0.0031585693359375, 'loss_3': -16.400325775146484, 'loss_4': 0.9545868039131165, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 10:27:24,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:24,276 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:00:51<46:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:31,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0107701001688838, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007947908714413643, 'eval_loss_2': 0.002822190523147583, 'eval_loss_3': -18.290895462036133, 'eval_loss_4': 1.0889503955841064, 'epoch': 14.3}
{'loss': 0.0308, 'grad_norm': 17.829025268554688, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.025857480242848396, 'loss_2': 0.004955291748046875, 'loss_3': -16.30255699157715, 'loss_4': 0.9470523595809937, 'epoch': 14.31}
{'loss': 0.0106, 'grad_norm': 4.398056983947754, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.004405219107866287, 'loss_2': 0.006214141845703125, 'loss_3': -16.477523803710938, 'loss_4': 1.057199478149414, 'epoch': 14.31}
{'loss': 0.015, 'grad_norm': 7.82790994644165, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.014291966333985329, 'loss_2': 0.00070953369140625, 'loss_3': -16.39599609375, 'loss_4': 1.642853021621704, 'epoch': 14.32}
{'loss': 0.0211, 'grad_norm': 8.046625137329102, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.016151029616594315, 'loss_2': 0.0049285888671875, 'loss_3': -16.44601821899414, 'loss_4': 1.1003003120422363, 'epoch': 14.33}
{'loss': 0.0332, 'grad_norm': 11.200817108154297, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.03129272162914276, 'loss_2': 0.001956939697265625, 'loss_3': -16.392518997192383, 'loss_4': 1.590895414352417, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 10:27:31,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:31,618 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:00:58<46:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:38,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01126817800104618, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.219, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.008249909617006779, 'eval_loss_2': 0.0030182674527168274, 'eval_loss_3': -18.27004623413086, 'eval_loss_4': 1.241358757019043, 'epoch': 14.33}
{'loss': 0.03, 'grad_norm': 14.031146049499512, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.025555172935128212, 'loss_2': 0.004428863525390625, 'loss_3': -16.46196746826172, 'loss_4': 1.5791223049163818, 'epoch': 14.34}
{'loss': 0.0177, 'grad_norm': 6.124441146850586, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.013321470469236374, 'loss_2': 0.00437164306640625, 'loss_3': -16.509309768676758, 'loss_4': 1.5501585006713867, 'epoch': 14.34}
{'loss': 0.0141, 'grad_norm': 4.97637414932251, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.008465961553156376, 'loss_2': 0.005588531494140625, 'loss_3': -16.517850875854492, 'loss_4': 1.8444684743881226, 'epoch': 14.35}
{'loss': 0.0062, 'grad_norm': 4.59876012802124, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.005011200904846191, 'loss_2': 0.0011577606201171875, 'loss_3': -16.39902114868164, 'loss_4': 1.69632887840271, 'epoch': 14.35}
{'loss': 0.0108, 'grad_norm': 5.322288990020752, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.010004912503063679, 'loss_2': 0.0008020401000976562, 'loss_3': -16.417282104492188, 'loss_4': 1.5860800743103027, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 10:27:38,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:38,956 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:06<46:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:46,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010405763983726501, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007512597367167473, 'eval_loss_2': 0.0028931647539138794, 'eval_loss_3': -18.255149841308594, 'eval_loss_4': 1.3330661058425903, 'epoch': 14.36}
{'loss': 0.0156, 'grad_norm': 7.345714092254639, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.014621448703110218, 'loss_2': 0.001018524169921875, 'loss_3': -16.297504425048828, 'loss_4': 1.890796422958374, 'epoch': 14.37}
{'loss': 0.0167, 'grad_norm': 4.655537128448486, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.006197313778102398, 'loss_2': 0.01047515869140625, 'loss_3': -16.377307891845703, 'loss_4': 1.9100037813186646, 'epoch': 14.37}
{'loss': 0.0238, 'grad_norm': 7.5899248123168945, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.018988775089383125, 'loss_2': 0.004802703857421875, 'loss_3': -16.46500015258789, 'loss_4': 1.3610329627990723, 'epoch': 14.38}
{'loss': 0.0215, 'grad_norm': 5.050442218780518, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.008948360569775105, 'loss_2': 0.0125732421875, 'loss_3': -16.266204833984375, 'loss_4': 1.6621427536010742, 'epoch': 14.38}
{'loss': 0.015, 'grad_norm': 4.560102939605713, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.009111794643104076, 'loss_2': 0.005840301513671875, 'loss_3': -16.330785751342773, 'loss_4': 1.3470063209533691, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 10:27:46,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:46,300 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:13<46:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:53,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010485603474080563, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007297827862203121, 'eval_loss_2': 0.0031877756118774414, 'eval_loss_3': -18.27379035949707, 'eval_loss_4': 1.3035117387771606, 'epoch': 14.39}
{'loss': 0.0197, 'grad_norm': 7.671692848205566, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.01859758049249649, 'loss_2': 0.0011186599731445312, 'loss_3': -16.105945587158203, 'loss_4': 1.1519556045532227, 'epoch': 14.4}
{'loss': 0.023, 'grad_norm': 11.991527557373047, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.018340254202485085, 'loss_2': 0.004611968994140625, 'loss_3': -16.38515853881836, 'loss_4': 1.3361213207244873, 'epoch': 14.4}
{'loss': 0.0117, 'grad_norm': 5.885260581970215, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.007216358091682196, 'loss_2': 0.0045166015625, 'loss_3': -16.167781829833984, 'loss_4': 0.8726932406425476, 'epoch': 14.41}
{'loss': 0.0093, 'grad_norm': 5.038081645965576, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.008291478268802166, 'loss_2': 0.0010128021240234375, 'loss_3': -16.468339920043945, 'loss_4': 1.5414948463439941, 'epoch': 14.41}
{'loss': 0.01, 'grad_norm': 5.5595245361328125, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.00984936859458685, 'loss_2': 0.00012350082397460938, 'loss_3': -16.242752075195312, 'loss_4': 1.5490483045578003, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 10:27:53,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:53,648 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:20<46:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:00,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011074820533394814, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.022, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0076932404190301895, 'eval_loss_2': 0.003381580114364624, 'eval_loss_3': -18.23070526123047, 'eval_loss_4': 1.230173110961914, 'epoch': 14.42}
{'loss': 0.0573, 'grad_norm': 15.123018264770508, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.045819491147994995, 'loss_2': 0.01143646240234375, 'loss_3': -16.51835060119629, 'loss_4': 0.9772288799285889, 'epoch': 14.42}
{'loss': 0.0148, 'grad_norm': 5.4396748542785645, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.011616348288953304, 'loss_2': 0.0031490325927734375, 'loss_3': -16.344390869140625, 'loss_4': 1.907187581062317, 'epoch': 14.43}
{'loss': 0.0207, 'grad_norm': 10.211030960083008, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.01568245142698288, 'loss_2': 0.004974365234375, 'loss_3': -16.34205436706543, 'loss_4': 1.1998056173324585, 'epoch': 14.44}
{'loss': 0.0364, 'grad_norm': 20.382402420043945, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.034512344747781754, 'loss_2': 0.001865386962890625, 'loss_3': -16.343475341796875, 'loss_4': 1.1172051429748535, 'epoch': 14.44}
{'loss': 0.0114, 'grad_norm': 4.475955486297607, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.0054027969017624855, 'loss_2': 0.005985260009765625, 'loss_3': -16.522809982299805, 'loss_4': 1.5137560367584229, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 10:28:00,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:00,994 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:28<46:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:08,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012270843610167503, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006764567457139492, 'eval_loss_2': 0.005506277084350586, 'eval_loss_3': -18.18229866027832, 'eval_loss_4': 1.3037461042404175, 'epoch': 14.45}
{'loss': 0.0125, 'grad_norm': 5.141384601593018, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.00742706935852766, 'loss_2': 0.005096435546875, 'loss_3': -16.28211212158203, 'loss_4': 1.0682493448257446, 'epoch': 14.45}
{'loss': 0.039, 'grad_norm': 11.614399909973145, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.028647206723690033, 'loss_2': 0.01039886474609375, 'loss_3': -16.302200317382812, 'loss_4': 1.0261181592941284, 'epoch': 14.46}
{'loss': 0.0094, 'grad_norm': 5.038491725921631, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.0046980357728898525, 'loss_2': 0.00469970703125, 'loss_3': -16.471651077270508, 'loss_4': 1.187699556350708, 'epoch': 14.47}
{'loss': 0.0223, 'grad_norm': 6.8809919357299805, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.013375850394368172, 'loss_2': 0.00896453857421875, 'loss_3': -16.41819190979004, 'loss_4': 1.0944015979766846, 'epoch': 14.47}
{'loss': 0.0067, 'grad_norm': 4.673707962036133, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.006602735724300146, 'loss_2': 5.638599395751953e-05, 'loss_3': -16.369131088256836, 'loss_4': 1.6320911645889282, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 10:28:08,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:08,332 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:35<46:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:15,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008562927134335041, 'eval_runtime': 3.8175, 'eval_samples_per_second': 268.239, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.0067390622571110725, 'eval_loss_2': 0.0018238648772239685, 'eval_loss_3': -18.17936897277832, 'eval_loss_4': 1.248289704322815, 'epoch': 14.48}
{'loss': 0.0096, 'grad_norm': 5.016965389251709, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.007381897885352373, 'loss_2': 0.0022125244140625, 'loss_3': -16.127840042114258, 'loss_4': 1.396155834197998, 'epoch': 14.48}
{'loss': 0.0319, 'grad_norm': 14.110978126525879, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.028744462877511978, 'loss_2': 0.003204345703125, 'loss_3': -16.18166732788086, 'loss_4': 1.587479829788208, 'epoch': 14.49}
{'loss': 0.0235, 'grad_norm': 8.90617561340332, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.02173420414328575, 'loss_2': 0.0017681121826171875, 'loss_3': -16.174875259399414, 'loss_4': 1.0972304344177246, 'epoch': 14.49}
{'loss': 0.0094, 'grad_norm': 4.954504489898682, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.008884605951607227, 'loss_2': 0.00046896934509277344, 'loss_3': -16.539674758911133, 'loss_4': 0.7487610578536987, 'epoch': 14.5}
{'loss': 0.0111, 'grad_norm': 5.819095134735107, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.01032163668423891, 'loss_2': 0.0007886886596679688, 'loss_3': -16.306909561157227, 'loss_4': 1.0900654792785645, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 10:28:15,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:15,694 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:42<46:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:23,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009690186940133572, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007263503037393093, 'eval_loss_2': 0.0024266839027404785, 'eval_loss_3': -18.171398162841797, 'eval_loss_4': 1.056730031967163, 'epoch': 14.51}
{'loss': 0.012, 'grad_norm': 5.505446434020996, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.00866458099335432, 'loss_2': 0.0033168792724609375, 'loss_3': -16.29938507080078, 'loss_4': 0.7905862331390381, 'epoch': 14.51}
{'loss': 0.022, 'grad_norm': 9.724189758300781, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.021339837461709976, 'loss_2': 0.0006699562072753906, 'loss_3': -16.256921768188477, 'loss_4': 1.1576859951019287, 'epoch': 14.52}
{'loss': 0.0111, 'grad_norm': 6.061795711517334, 'learning_rate': 1.55e-05, 'loss_1': 0.010534526780247688, 'loss_2': 0.0005464553833007812, 'loss_3': -16.359634399414062, 'loss_4': 0.9333803653717041, 'epoch': 14.52}
{'loss': 0.014, 'grad_norm': 5.642622470855713, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.010521411895751953, 'loss_2': 0.00351715087890625, 'loss_3': -16.250829696655273, 'loss_4': 0.8345128893852234, 'epoch': 14.53}
{'loss': 0.0102, 'grad_norm': 5.287775993347168, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.0075729889795184135, 'loss_2': 0.002620697021484375, 'loss_3': -16.515827178955078, 'loss_4': 0.9143287539482117, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 10:28:23,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:23,035 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:01:50<45:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:30,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010489560663700104, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.71, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00823718961328268, 'eval_loss_2': 0.0022523701190948486, 'eval_loss_3': -18.153507232666016, 'eval_loss_4': 0.9335975050926208, 'epoch': 14.53}
{'loss': 0.0092, 'grad_norm': 5.464157581329346, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.006321297027170658, 'loss_2': 0.002895355224609375, 'loss_3': -16.375455856323242, 'loss_4': 0.1584623157978058, 'epoch': 14.54}
{'loss': 0.0165, 'grad_norm': 7.401442050933838, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.014319786801934242, 'loss_2': 0.002140045166015625, 'loss_3': -16.433320999145508, 'loss_4': 0.8186796307563782, 'epoch': 14.55}
{'loss': 0.0188, 'grad_norm': 6.409158229827881, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.014078278094530106, 'loss_2': 0.004680633544921875, 'loss_3': -16.03167724609375, 'loss_4': 1.0346550941467285, 'epoch': 14.55}
{'loss': 0.0214, 'grad_norm': 5.221299648284912, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.012461953796446323, 'loss_2': 0.00896453857421875, 'loss_3': -16.20816421508789, 'loss_4': 1.088386058807373, 'epoch': 14.56}
{'loss': 0.021, 'grad_norm': 6.647470474243164, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.01306641660630703, 'loss_2': 0.0078887939453125, 'loss_3': -16.265884399414062, 'loss_4': 1.193649172782898, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 10:28:30,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:30,383 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:01:57<45:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:37,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012467446736991405, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009444179944694042, 'eval_loss_2': 0.0030232667922973633, 'eval_loss_3': -18.136032104492188, 'eval_loss_4': 0.8886309862136841, 'epoch': 14.56}
{'loss': 0.0108, 'grad_norm': 4.474971294403076, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.005403493531048298, 'loss_2': 0.0053558349609375, 'loss_3': -16.590572357177734, 'loss_4': 0.7800596356391907, 'epoch': 14.57}
{'loss': 0.0314, 'grad_norm': 11.305628776550293, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.02931603044271469, 'loss_2': 0.0020923614501953125, 'loss_3': -16.341777801513672, 'loss_4': 0.9344044923782349, 'epoch': 14.58}
{'loss': 0.0065, 'grad_norm': 5.1463494300842285, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.006228058598935604, 'loss_2': 0.0002789497375488281, 'loss_3': -16.425336837768555, 'loss_4': 0.7842186689376831, 'epoch': 14.58}
{'loss': 0.013, 'grad_norm': 7.429941177368164, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.011841944418847561, 'loss_2': 0.0011138916015625, 'loss_3': -16.219928741455078, 'loss_4': 0.770217776298523, 'epoch': 14.59}
{'loss': 0.0149, 'grad_norm': 6.131117343902588, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.012984761036932468, 'loss_2': 0.0018978118896484375, 'loss_3': -16.32377052307129, 'loss_4': 0.8533416390419006, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 10:28:37,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:37,727 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:04<45:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:45,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010760731995105743, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00881270319223404, 'eval_loss_2': 0.001948028802871704, 'eval_loss_3': -18.145793914794922, 'eval_loss_4': 0.7530858516693115, 'epoch': 14.59}
{'loss': 0.0094, 'grad_norm': 5.469071388244629, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.00904036033898592, 'loss_2': 0.0003418922424316406, 'loss_3': -16.36163330078125, 'loss_4': 0.9160091876983643, 'epoch': 14.6}
{'loss': 0.0143, 'grad_norm': 6.285837173461914, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.013949647545814514, 'loss_2': 0.000362396240234375, 'loss_3': -16.469684600830078, 'loss_4': 0.1414426565170288, 'epoch': 14.6}
{'loss': 0.0135, 'grad_norm': 6.119989395141602, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.013066119514405727, 'loss_2': 0.0004799365997314453, 'loss_3': -16.43448257446289, 'loss_4': 0.7216326594352722, 'epoch': 14.61}
{'loss': 0.0175, 'grad_norm': 5.628296852111816, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.011101902462542057, 'loss_2': 0.00643157958984375, 'loss_3': -16.4455623626709, 'loss_4': 0.33502307534217834, 'epoch': 14.62}
{'loss': 0.0176, 'grad_norm': 6.7662434577941895, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.013666752725839615, 'loss_2': 0.003978729248046875, 'loss_3': -16.38772964477539, 'loss_4': 0.244211807847023, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 10:28:45,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:45,070 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:12<45:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:52,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013267243281006813, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009870374575257301, 'eval_loss_2': 0.0033968687057495117, 'eval_loss_3': -18.175447463989258, 'eval_loss_4': 0.6378096342086792, 'epoch': 14.62}
{'loss': 0.0208, 'grad_norm': 8.046465873718262, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.013892408460378647, 'loss_2': 0.006870269775390625, 'loss_3': -16.304903030395508, 'loss_4': 0.8054794073104858, 'epoch': 14.63}
{'loss': 0.0111, 'grad_norm': 5.685494899749756, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.01010893378406763, 'loss_2': 0.0009899139404296875, 'loss_3': -16.231721878051758, 'loss_4': 0.8550562262535095, 'epoch': 14.63}
{'loss': 0.0313, 'grad_norm': 14.751591682434082, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.028934026136994362, 'loss_2': 0.00240325927734375, 'loss_3': -16.21265983581543, 'loss_4': 0.1537792831659317, 'epoch': 14.64}
{'loss': 0.0091, 'grad_norm': 4.618257522583008, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.006675265729427338, 'loss_2': 0.0024433135986328125, 'loss_3': -16.57724952697754, 'loss_4': 0.45519500970840454, 'epoch': 14.65}
{'loss': 0.068, 'grad_norm': 26.400081634521484, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.061399735510349274, 'loss_2': 0.00664520263671875, 'loss_3': -16.163604736328125, 'loss_4': 0.22706934809684753, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 10:28:52,422 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:52,423 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:19<45:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:59,775 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010467346757650375, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.33, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008163671009242535, 'eval_loss_2': 0.002303674817085266, 'eval_loss_3': -18.202674865722656, 'eval_loss_4': 0.659932017326355, 'epoch': 14.65}
{'loss': 0.0134, 'grad_norm': 5.281693935394287, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.01036571804434061, 'loss_2': 0.0030651092529296875, 'loss_3': -16.25865364074707, 'loss_4': 0.08958084136247635, 'epoch': 14.66}
{'loss': 0.0409, 'grad_norm': 9.40300178527832, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.030500328168272972, 'loss_2': 0.010406494140625, 'loss_3': -16.240793228149414, 'loss_4': 1.085343360900879, 'epoch': 14.66}
{'loss': 0.0163, 'grad_norm': 7.968204498291016, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.015309644863009453, 'loss_2': 0.0009622573852539062, 'loss_3': -16.282487869262695, 'loss_4': 0.7794642448425293, 'epoch': 14.67}
{'loss': 0.0132, 'grad_norm': 6.038018703460693, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.01285703107714653, 'loss_2': 0.00030159950256347656, 'loss_3': -16.43285369873047, 'loss_4': 0.8763315081596375, 'epoch': 14.67}
{'loss': 0.0054, 'grad_norm': 5.055147647857666, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.00502394326031208, 'loss_2': 0.0003693103790283203, 'loss_3': -16.343338012695312, 'loss_4': 0.5728961825370789, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 10:28:59,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:59,776 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:26<45:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:07,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010072775185108185, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.51, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007817382924258709, 'eval_loss_2': 0.0022553913295269012, 'eval_loss_3': -18.260478973388672, 'eval_loss_4': 0.7693048715591431, 'epoch': 14.68}
{'loss': 0.0151, 'grad_norm': 5.0705108642578125, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.005750691052526236, 'loss_2': 0.0093536376953125, 'loss_3': -16.474946975708008, 'loss_4': 0.5995609760284424, 'epoch': 14.69}
{'loss': 0.0277, 'grad_norm': 6.798546314239502, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.019325576722621918, 'loss_2': 0.00841522216796875, 'loss_3': -16.478511810302734, 'loss_4': 0.8035444021224976, 'epoch': 14.69}
{'loss': 0.0077, 'grad_norm': 5.770280361175537, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.0076912869699299335, 'loss_2': 1.800060272216797e-05, 'loss_3': -16.241683959960938, 'loss_4': 0.8628968596458435, 'epoch': 14.7}
{'loss': 0.0166, 'grad_norm': 6.423916816711426, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.013484562747180462, 'loss_2': 0.003124237060546875, 'loss_3': -16.586925506591797, 'loss_4': 1.0392675399780273, 'epoch': 14.7}
{'loss': 0.0247, 'grad_norm': 7.666279315948486, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.018122222274541855, 'loss_2': 0.006591796875, 'loss_3': -16.454601287841797, 'loss_4': 1.3106385469436646, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 10:29:07,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:07,122 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:34<45:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:14,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011954904533922672, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.415, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008144469000399113, 'eval_loss_2': 0.0038104355335235596, 'eval_loss_3': -18.304561614990234, 'eval_loss_4': 0.88874751329422, 'epoch': 14.71}
{'loss': 0.0168, 'grad_norm': 7.773857593536377, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.009981480427086353, 'loss_2': 0.00677490234375, 'loss_3': -16.39682388305664, 'loss_4': 1.0798850059509277, 'epoch': 14.72}
{'loss': 0.0096, 'grad_norm': 5.306556224822998, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.007989604026079178, 'loss_2': 0.0015687942504882812, 'loss_3': -16.495229721069336, 'loss_4': 1.0723401308059692, 'epoch': 14.72}
{'loss': 0.0067, 'grad_norm': 4.6655473709106445, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.004768255166709423, 'loss_2': 0.00196075439453125, 'loss_3': -16.434232711791992, 'loss_4': 0.756883978843689, 'epoch': 14.73}
{'loss': 0.0171, 'grad_norm': 5.93209171295166, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.01377561129629612, 'loss_2': 0.00333404541015625, 'loss_3': -16.44588851928711, 'loss_4': 0.9257347583770752, 'epoch': 14.73}
{'loss': 0.0079, 'grad_norm': 4.7543816566467285, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.007817507721483707, 'loss_2': 7.587671279907227e-05, 'loss_3': -16.415302276611328, 'loss_4': 1.3908891677856445, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 10:29:14,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:14,452 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:41<45:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:21,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012037429958581924, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.101, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009041492827236652, 'eval_loss_2': 0.0029959380626678467, 'eval_loss_3': -18.306623458862305, 'eval_loss_4': 0.9953984022140503, 'epoch': 14.74}
{'loss': 0.0168, 'grad_norm': 4.9156293869018555, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.00803892221301794, 'loss_2': 0.00872802734375, 'loss_3': -16.29262351989746, 'loss_4': 0.8878294229507446, 'epoch': 14.74}
{'loss': 0.0184, 'grad_norm': 6.3710246086120605, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.016388004645705223, 'loss_2': 0.0020294189453125, 'loss_3': -16.659252166748047, 'loss_4': 1.2332723140716553, 'epoch': 14.75}
{'loss': 0.024, 'grad_norm': 8.0789213180542, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.021332185715436935, 'loss_2': 0.0026874542236328125, 'loss_3': -16.327062606811523, 'loss_4': 1.7271697521209717, 'epoch': 14.76}
{'loss': 0.0137, 'grad_norm': 6.222150802612305, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.011121092364192009, 'loss_2': 0.0026035308837890625, 'loss_3': -16.368751525878906, 'loss_4': 1.9121012687683105, 'epoch': 14.76}
{'loss': 0.0174, 'grad_norm': 5.199536323547363, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.011330239474773407, 'loss_2': 0.00605010986328125, 'loss_3': -16.482664108276367, 'loss_4': 1.3613380193710327, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 10:29:21,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:21,789 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:02:48<45:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:29,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01091698557138443, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.93, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008405692875385284, 'eval_loss_2': 0.0025112926959991455, 'eval_loss_3': -18.287654876708984, 'eval_loss_4': 0.9621708393096924, 'epoch': 14.77}
{'loss': 0.0171, 'grad_norm': 4.763340950012207, 'learning_rate': 1.525e-05, 'loss_1': 0.012576906941831112, 'loss_2': 0.0045318603515625, 'loss_3': -16.478591918945312, 'loss_4': 2.050565481185913, 'epoch': 14.77}
{'loss': 0.0108, 'grad_norm': 4.8358073234558105, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.0071360161527991295, 'loss_2': 0.0037136077880859375, 'loss_3': -16.37165069580078, 'loss_4': 0.7563860416412354, 'epoch': 14.78}
{'loss': 0.0303, 'grad_norm': 7.779299259185791, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.022337637841701508, 'loss_2': 0.00799560546875, 'loss_3': -16.30462646484375, 'loss_4': 0.6767301559448242, 'epoch': 14.78}
{'loss': 0.0215, 'grad_norm': 6.164611339569092, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.016013436019420624, 'loss_2': 0.00550079345703125, 'loss_3': -16.284561157226562, 'loss_4': 0.9133923053741455, 'epoch': 14.79}
{'loss': 0.0147, 'grad_norm': 6.503250598907471, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.01113330852240324, 'loss_2': 0.00356292724609375, 'loss_3': -16.247413635253906, 'loss_4': 0.867794394493103, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 10:29:29,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:29,124 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:02:56<45:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:36,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009896744042634964, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007611822336912155, 'eval_loss_2': 0.002284921705722809, 'eval_loss_3': -18.308914184570312, 'eval_loss_4': 0.864635705947876, 'epoch': 14.8}
{'loss': 0.0148, 'grad_norm': 5.284670829772949, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.013234775513410568, 'loss_2': 0.001537322998046875, 'loss_3': -16.434003829956055, 'loss_4': 0.38277336955070496, 'epoch': 14.8}
{'loss': 0.0068, 'grad_norm': 4.819565773010254, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.006606812588870525, 'loss_2': 0.00021755695343017578, 'loss_3': -16.50727081298828, 'loss_4': 1.006927728652954, 'epoch': 14.81}
{'loss': 0.008, 'grad_norm': 4.951440811157227, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.007249834947288036, 'loss_2': 0.0007085800170898438, 'loss_3': -16.162811279296875, 'loss_4': 0.6894034743309021, 'epoch': 14.81}
{'loss': 0.0167, 'grad_norm': 4.801802635192871, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.007572577800601721, 'loss_2': 0.009124755859375, 'loss_3': -16.539018630981445, 'loss_4': 1.2947850227355957, 'epoch': 14.82}
{'loss': 0.0129, 'grad_norm': 4.673113822937012, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.007241389248520136, 'loss_2': 0.005626678466796875, 'loss_3': -16.4388427734375, 'loss_4': 1.1088449954986572, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 10:29:36,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:36,484 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:03<45:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:43,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009727541357278824, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.296, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007578941993415356, 'eval_loss_2': 0.0021485984325408936, 'eval_loss_3': -18.296911239624023, 'eval_loss_4': 0.9596155881881714, 'epoch': 14.83}
{'loss': 0.0158, 'grad_norm': 8.205759048461914, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.013045551255345345, 'loss_2': 0.002712249755859375, 'loss_3': -16.27427864074707, 'loss_4': 1.6239222288131714, 'epoch': 14.83}
{'loss': 0.0181, 'grad_norm': 7.879769802093506, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.017660560086369514, 'loss_2': 0.00039386749267578125, 'loss_3': -16.29138946533203, 'loss_4': 1.1411993503570557, 'epoch': 14.84}
{'loss': 0.0086, 'grad_norm': 4.8220930099487305, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.006685367785394192, 'loss_2': 0.001941680908203125, 'loss_3': -16.52433204650879, 'loss_4': 0.6173726320266724, 'epoch': 14.84}
{'loss': 0.0151, 'grad_norm': 4.760547161102295, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.010789923369884491, 'loss_2': 0.0042877197265625, 'loss_3': -16.545856475830078, 'loss_4': 1.233123540878296, 'epoch': 14.85}
{'loss': 0.0178, 'grad_norm': 5.799211502075195, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.009411447681486607, 'loss_2': 0.0084228515625, 'loss_3': -16.431747436523438, 'loss_4': 0.9688698649406433, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 10:29:43,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:43,819 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:10<44:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:51,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009998034685850143, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007952620275318623, 'eval_loss_2': 0.0020454153418540955, 'eval_loss_3': -18.289386749267578, 'eval_loss_4': 1.0586947202682495, 'epoch': 14.85}
{'loss': 0.0057, 'grad_norm': 4.655989646911621, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.00561188580468297, 'loss_2': 9.846687316894531e-05, 'loss_3': -16.41658592224121, 'loss_4': 1.3011553287506104, 'epoch': 14.86}
{'loss': 0.0581, 'grad_norm': 15.117693901062012, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.0490337610244751, 'loss_2': 0.0091094970703125, 'loss_3': -16.153785705566406, 'loss_4': 1.672478199005127, 'epoch': 14.87}
{'loss': 0.0128, 'grad_norm': 5.862826824188232, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.01224965788424015, 'loss_2': 0.000507354736328125, 'loss_3': -16.557546615600586, 'loss_4': 0.5560257434844971, 'epoch': 14.87}
{'loss': 0.0177, 'grad_norm': 6.568277835845947, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.011681481264531612, 'loss_2': 0.0060272216796875, 'loss_3': -16.374038696289062, 'loss_4': 0.80724036693573, 'epoch': 14.88}
{'loss': 0.011, 'grad_norm': 6.26818323135376, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.010242991149425507, 'loss_2': 0.0007305145263671875, 'loss_3': -16.59130859375, 'loss_4': 1.2133159637451172, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 10:29:51,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:51,150 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:18<44:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:58,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010148769244551659, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.239, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007675776723772287, 'eval_loss_2': 0.0024729929864406586, 'eval_loss_3': -18.26987648010254, 'eval_loss_4': 1.0764038562774658, 'epoch': 14.88}
{'loss': 0.0129, 'grad_norm': 4.640988349914551, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.00781309325248003, 'loss_2': 0.00510406494140625, 'loss_3': -16.444747924804688, 'loss_4': 1.1279561519622803, 'epoch': 14.89}
{'loss': 0.0141, 'grad_norm': 5.867667198181152, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.010889369994401932, 'loss_2': 0.003253936767578125, 'loss_3': -16.446914672851562, 'loss_4': 0.8392537832260132, 'epoch': 14.9}
{'loss': 0.0144, 'grad_norm': 6.770008563995361, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.012557314708828926, 'loss_2': 0.0018863677978515625, 'loss_3': -16.31723976135254, 'loss_4': 0.7631224393844604, 'epoch': 14.9}
{'loss': 0.0262, 'grad_norm': 9.841663360595703, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.020682094618678093, 'loss_2': 0.00551605224609375, 'loss_3': -16.344144821166992, 'loss_4': 1.0659446716308594, 'epoch': 14.91}
{'loss': 0.0359, 'grad_norm': 11.473721504211426, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.02508709952235222, 'loss_2': 0.010833740234375, 'loss_3': -16.266515731811523, 'loss_4': 1.359431505203247, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 10:29:58,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:58,483 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:25<44:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:05,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01192640420049429, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.507, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007884614169597626, 'eval_loss_2': 0.004041790962219238, 'eval_loss_3': -18.25007438659668, 'eval_loss_4': 1.1481409072875977, 'epoch': 14.91}
{'loss': 0.0173, 'grad_norm': 13.272015571594238, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.01405343972146511, 'loss_2': 0.003215789794921875, 'loss_3': -16.44698715209961, 'loss_4': 1.1338250637054443, 'epoch': 14.92}
{'loss': 0.0164, 'grad_norm': 4.85317850112915, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.008234013803303242, 'loss_2': 0.00811767578125, 'loss_3': -16.229520797729492, 'loss_4': 1.2653546333312988, 'epoch': 14.92}
{'loss': 0.0137, 'grad_norm': 4.899413585662842, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.01140289194881916, 'loss_2': 0.0022945404052734375, 'loss_3': -16.389497756958008, 'loss_4': 1.2072935104370117, 'epoch': 14.93}
{'loss': 0.0155, 'grad_norm': 9.543559074401855, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.013840297237038612, 'loss_2': 0.0016460418701171875, 'loss_3': -16.25130271911621, 'loss_4': 1.2537641525268555, 'epoch': 14.94}
{'loss': 0.0079, 'grad_norm': 5.004674911499023, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.0058059366419911385, 'loss_2': 0.002124786376953125, 'loss_3': -16.416982650756836, 'loss_4': 1.4443297386169434, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 10:30:05,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:05,806 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:32<44:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:13,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009338702075183392, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006915295962244272, 'eval_loss_2': 0.002423405647277832, 'eval_loss_3': -18.260536193847656, 'eval_loss_4': 1.2782888412475586, 'epoch': 14.94}
{'loss': 0.0116, 'grad_norm': 5.225357532501221, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.009324736893177032, 'loss_2': 0.00225830078125, 'loss_3': -16.321094512939453, 'loss_4': 1.9022955894470215, 'epoch': 14.95}
{'loss': 0.0151, 'grad_norm': 7.1656012535095215, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.01037236675620079, 'loss_2': 0.004741668701171875, 'loss_3': -16.52798843383789, 'loss_4': 1.033276915550232, 'epoch': 14.95}
{'loss': 0.019, 'grad_norm': 5.841634750366211, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.015846271067857742, 'loss_2': 0.00319671630859375, 'loss_3': -16.120479583740234, 'loss_4': 1.7757154703140259, 'epoch': 14.96}
{'loss': 0.008, 'grad_norm': 4.967689514160156, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.007209929637610912, 'loss_2': 0.0007905960083007812, 'loss_3': -16.2855281829834, 'loss_4': 0.7080360651016235, 'epoch': 14.97}
{'loss': 0.0127, 'grad_norm': 5.051350116729736, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.011410598643124104, 'loss_2': 0.0012598037719726562, 'loss_3': -16.421329498291016, 'loss_4': 0.7629791498184204, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 10:30:13,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:13,135 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:39<40:06,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:30:20,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009164873510599136, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.102, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.006238999310880899, 'eval_loss_2': 0.002925872802734375, 'eval_loss_3': -18.255191802978516, 'eval_loss_4': 1.2876826524734497, 'epoch': 14.97}
{'loss': 0.0154, 'grad_norm': 7.861409664154053, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.013726571574807167, 'loss_2': 0.0016994476318359375, 'loss_3': -16.52869987487793, 'loss_4': 1.5430641174316406, 'epoch': 14.98}
{'loss': 0.0265, 'grad_norm': 9.847887992858887, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.02521531656384468, 'loss_2': 0.0012369155883789062, 'loss_3': -16.571582794189453, 'loss_4': 1.3750927448272705, 'epoch': 14.98}
{'loss': 0.0075, 'grad_norm': 4.475222110748291, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.0051777558401227, 'loss_2': 0.0023136138916015625, 'loss_3': -16.45709228515625, 'loss_4': 0.9679058790206909, 'epoch': 14.99}
{'loss': 0.0116, 'grad_norm': 5.442623615264893, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.009507118724286556, 'loss_2': 0.0020580291748046875, 'loss_3': -16.133346557617188, 'loss_4': 1.330986738204956, 'epoch': 14.99}
{'loss': 0.0104, 'grad_norm': 6.453346252441406, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.0033191386610269547, 'loss_2': 0.007080078125, 'loss_3': -16.231828689575195, 'loss_4': 1.4979320764541626, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 10:30:20,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:20,124 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:03:47<43:50,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:30:27,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012497203424572945, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.176, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007392334286123514, 'eval_loss_2': 0.005104869604110718, 'eval_loss_3': -18.265220642089844, 'eval_loss_4': 1.1891789436340332, 'epoch': 15.0}
{'loss': 0.013, 'grad_norm': 4.4461493492126465, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.006010601297020912, 'loss_2': 0.00702667236328125, 'loss_3': -16.28400230407715, 'loss_4': 1.5879244804382324, 'epoch': 15.01}
{'loss': 0.0063, 'grad_norm': 4.577946186065674, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.006028272211551666, 'loss_2': 0.00023746490478515625, 'loss_3': -16.43325424194336, 'loss_4': 1.2239717245101929, 'epoch': 15.01}
{'loss': 0.0183, 'grad_norm': 6.974293231964111, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.015748193487524986, 'loss_2': 0.0025634765625, 'loss_3': -16.418188095092773, 'loss_4': 1.1399309635162354, 'epoch': 15.02}
{'loss': 0.0178, 'grad_norm': 6.7067341804504395, 'learning_rate': 1.5e-05, 'loss_1': 0.01648578606545925, 'loss_2': 0.001316070556640625, 'loss_3': -16.332815170288086, 'loss_4': 1.3972020149230957, 'epoch': 15.02}
{'loss': 0.0109, 'grad_norm': 4.473599433898926, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.004964050836861134, 'loss_2': 0.005893707275390625, 'loss_3': -16.321983337402344, 'loss_4': 1.428818702697754, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 10:30:27,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:27,498 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:03:54<44:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:30:34,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012745664454996586, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.601, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007593678310513496, 'eval_loss_2': 0.005151987075805664, 'eval_loss_3': -18.25994110107422, 'eval_loss_4': 1.0347700119018555, 'epoch': 15.03}
{'loss': 0.0105, 'grad_norm': 4.612045764923096, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.006142898462712765, 'loss_2': 0.004360198974609375, 'loss_3': -16.44659423828125, 'loss_4': 1.0100141763687134, 'epoch': 15.03}
{'loss': 0.0056, 'grad_norm': 4.988931179046631, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.005290951579809189, 'loss_2': 0.0003237724304199219, 'loss_3': -16.226917266845703, 'loss_4': 1.2309422492980957, 'epoch': 15.04}
{'loss': 0.0164, 'grad_norm': 6.596884727478027, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.0162570271641016, 'loss_2': 0.00017380714416503906, 'loss_3': -16.493709564208984, 'loss_4': 1.5464428663253784, 'epoch': 15.05}
{'loss': 0.0133, 'grad_norm': 5.404167175292969, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.009501893073320389, 'loss_2': 0.003814697265625, 'loss_3': -16.379892349243164, 'loss_4': 1.4724229574203491, 'epoch': 15.05}
{'loss': 0.0162, 'grad_norm': 5.573051929473877, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.010480107739567757, 'loss_2': 0.00567626953125, 'loss_3': -16.261707305908203, 'loss_4': 0.5447345972061157, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 10:30:34,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:34,820 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:01<44:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:42,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010842833667993546, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.495, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008450229652225971, 'eval_loss_2': 0.002392604947090149, 'eval_loss_3': -18.231395721435547, 'eval_loss_4': 0.9866660237312317, 'epoch': 15.06}
{'loss': 0.0093, 'grad_norm': 5.005992889404297, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.007093430031090975, 'loss_2': 0.00222015380859375, 'loss_3': -16.235427856445312, 'loss_4': 0.7644861340522766, 'epoch': 15.06}
{'loss': 0.0314, 'grad_norm': 13.647069931030273, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.029851175844669342, 'loss_2': 0.00159454345703125, 'loss_3': -16.30751609802246, 'loss_4': 0.9634848833084106, 'epoch': 15.07}
{'loss': 0.0166, 'grad_norm': 13.783020973205566, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.013346369378268719, 'loss_2': 0.00322723388671875, 'loss_3': -16.45208168029785, 'loss_4': 1.3116967678070068, 'epoch': 15.08}
{'loss': 0.0274, 'grad_norm': 7.537014007568359, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.020727841183543205, 'loss_2': 0.006687164306640625, 'loss_3': -16.35778045654297, 'loss_4': 1.3993473052978516, 'epoch': 15.08}
{'loss': 0.012, 'grad_norm': 5.4011125564575195, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.006702374666929245, 'loss_2': 0.005290985107421875, 'loss_3': -16.427316665649414, 'loss_4': 1.0659046173095703, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 10:30:42,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:42,153 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:09<44:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:49,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0105845732614398, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.358, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008106286637485027, 'eval_loss_2': 0.002478286623954773, 'eval_loss_3': -18.230417251586914, 'eval_loss_4': 1.0193337202072144, 'epoch': 15.09}
{'loss': 0.0256, 'grad_norm': 7.04388427734375, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.021044105291366577, 'loss_2': 0.00457000732421875, 'loss_3': -16.30708885192871, 'loss_4': 1.120384693145752, 'epoch': 15.09}
{'loss': 0.0174, 'grad_norm': 6.756829738616943, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.012018335051834583, 'loss_2': 0.005420684814453125, 'loss_3': -16.40691375732422, 'loss_4': 0.9662138223648071, 'epoch': 15.1}
{'loss': 0.0142, 'grad_norm': 7.713159561157227, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.012875490821897984, 'loss_2': 0.0013275146484375, 'loss_3': -16.43901824951172, 'loss_4': 0.9576252102851868, 'epoch': 15.1}
{'loss': 0.0161, 'grad_norm': 6.017428874969482, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.011338314041495323, 'loss_2': 0.00478363037109375, 'loss_3': -16.491044998168945, 'loss_4': 0.8376574516296387, 'epoch': 15.11}
{'loss': 0.0121, 'grad_norm': 4.634275913238525, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.006548263132572174, 'loss_2': 0.0055084228515625, 'loss_3': -16.196250915527344, 'loss_4': 1.33048677444458, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 10:30:49,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:49,483 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:16<44:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:56,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01215687021613121, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.429, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008816014043986797, 'eval_loss_2': 0.0033408552408218384, 'eval_loss_3': -18.20229721069336, 'eval_loss_4': 0.8727102279663086, 'epoch': 15.12}
{'loss': 0.021, 'grad_norm': 11.075997352600098, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.01712675206363201, 'loss_2': 0.003887176513671875, 'loss_3': -16.215410232543945, 'loss_4': 0.963283896446228, 'epoch': 15.12}
{'loss': 0.0163, 'grad_norm': 6.138205051422119, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.010136505588889122, 'loss_2': 0.006160736083984375, 'loss_3': -16.265926361083984, 'loss_4': 0.8258408308029175, 'epoch': 15.13}
{'loss': 0.0245, 'grad_norm': 6.917276859283447, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.022311478853225708, 'loss_2': 0.002227783203125, 'loss_3': -16.201515197753906, 'loss_4': 0.9419770240783691, 'epoch': 15.13}
{'loss': 0.0166, 'grad_norm': 5.698524475097656, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.012820631265640259, 'loss_2': 0.0038089752197265625, 'loss_3': -16.3936824798584, 'loss_4': 1.1118156909942627, 'epoch': 15.14}
{'loss': 0.0082, 'grad_norm': 5.145943641662598, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.006010082550346851, 'loss_2': 0.002185821533203125, 'loss_3': -16.446664810180664, 'loss_4': 0.978013277053833, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 10:30:56,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:56,833 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:23<44:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:04,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011641164310276508, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.593, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.008339752443134785, 'eval_loss_2': 0.0033014118671417236, 'eval_loss_3': -18.201629638671875, 'eval_loss_4': 0.7562583684921265, 'epoch': 15.15}
{'loss': 0.0127, 'grad_norm': 4.860075950622559, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.007305723614990711, 'loss_2': 0.005443572998046875, 'loss_3': -16.349180221557617, 'loss_4': 0.9646133780479431, 'epoch': 15.15}
{'loss': 0.0072, 'grad_norm': 5.251891136169434, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.005138780921697617, 'loss_2': 0.0020599365234375, 'loss_3': -16.378684997558594, 'loss_4': 1.1724932193756104, 'epoch': 15.16}
{'loss': 0.0142, 'grad_norm': 6.880379676818848, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.013438102789223194, 'loss_2': 0.0007510185241699219, 'loss_3': -16.34996795654297, 'loss_4': 0.9678816795349121, 'epoch': 15.16}
{'loss': 0.034, 'grad_norm': 12.576035499572754, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.030469348654150963, 'loss_2': 0.0035495758056640625, 'loss_3': -16.297710418701172, 'loss_4': 0.4541674256324768, 'epoch': 15.17}
{'loss': 0.0093, 'grad_norm': 5.013072967529297, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.007486335933208466, 'loss_2': 0.001842498779296875, 'loss_3': -16.45861053466797, 'loss_4': 0.9272736310958862, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 10:31:04,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:04,159 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:31<44:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:11,502 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010570308193564415, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.987, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007408898323774338, 'eval_loss_2': 0.003161408007144928, 'eval_loss_3': -18.236186981201172, 'eval_loss_4': 0.7461573481559753, 'epoch': 15.17}
{'loss': 0.0107, 'grad_norm': 5.550064563751221, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.010221896693110466, 'loss_2': 0.0004968643188476562, 'loss_3': -16.49542236328125, 'loss_4': 1.071643590927124, 'epoch': 15.18}
{'loss': 0.0184, 'grad_norm': 5.9099812507629395, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.01716464012861252, 'loss_2': 0.001239776611328125, 'loss_3': -16.43691062927246, 'loss_4': 1.0162818431854248, 'epoch': 15.19}
{'loss': 0.0092, 'grad_norm': 5.318782329559326, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.008419704623520374, 'loss_2': 0.0007996559143066406, 'loss_3': -16.363492965698242, 'loss_4': 1.1635196208953857, 'epoch': 15.19}
{'loss': 0.0155, 'grad_norm': 5.114038944244385, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.010480170138180256, 'loss_2': 0.00499725341796875, 'loss_3': -16.39492416381836, 'loss_4': 0.9562027454376221, 'epoch': 15.2}
{'loss': 0.0366, 'grad_norm': 10.874703407287598, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.035699084401130676, 'loss_2': 0.0009355545043945312, 'loss_3': -16.3182373046875, 'loss_4': 1.5913331508636475, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 10:31:11,502 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:11,502 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:38<43:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:18,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010701318271458149, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0076409922912716866, 'eval_loss_2': 0.0030603259801864624, 'eval_loss_3': -18.24796485900879, 'eval_loss_4': 0.8452740907669067, 'epoch': 15.2}
{'loss': 0.0134, 'grad_norm': 9.044992446899414, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.01219460554420948, 'loss_2': 0.0011930465698242188, 'loss_3': -16.27962875366211, 'loss_4': 0.9261977672576904, 'epoch': 15.21}
{'loss': 0.0093, 'grad_norm': 5.051780700683594, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.006487861275672913, 'loss_2': 0.002849578857421875, 'loss_3': -16.296607971191406, 'loss_4': 0.8464764952659607, 'epoch': 15.22}
{'loss': 0.034, 'grad_norm': 17.095863342285156, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.029445109888911247, 'loss_2': 0.004547119140625, 'loss_3': -16.258106231689453, 'loss_4': 1.0103553533554077, 'epoch': 15.22}
{'loss': 0.0152, 'grad_norm': 5.828968524932861, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.008984745480120182, 'loss_2': 0.00617218017578125, 'loss_3': -16.556476593017578, 'loss_4': 1.480884313583374, 'epoch': 15.23}
{'loss': 0.0125, 'grad_norm': 5.717307090759277, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.00979352556169033, 'loss_2': 0.0026836395263671875, 'loss_3': -16.235071182250977, 'loss_4': 1.2115484476089478, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 10:31:18,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:18,843 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:45<43:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:26,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012162581086158752, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.389, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008013010956346989, 'eval_loss_2': 0.004149571061134338, 'eval_loss_3': -18.269868850708008, 'eval_loss_4': 0.904567539691925, 'epoch': 15.23}
{'loss': 0.0259, 'grad_norm': 5.663346767425537, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.017681889235973358, 'loss_2': 0.0082244873046875, 'loss_3': -16.311857223510742, 'loss_4': 1.6238758563995361, 'epoch': 15.24}
{'loss': 0.0173, 'grad_norm': 7.377446174621582, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.016702748835086823, 'loss_2': 0.0006194114685058594, 'loss_3': -16.639217376708984, 'loss_4': 1.4802628755569458, 'epoch': 15.24}
{'loss': 0.0094, 'grad_norm': 4.898507118225098, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.00376516068354249, 'loss_2': 0.005649566650390625, 'loss_3': -16.33694076538086, 'loss_4': 1.1231788396835327, 'epoch': 15.25}
{'loss': 0.0138, 'grad_norm': 4.459275722503662, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.004117713309824467, 'loss_2': 0.00963592529296875, 'loss_3': -16.564472198486328, 'loss_4': 0.8815778493881226, 'epoch': 15.26}
{'loss': 0.0101, 'grad_norm': 5.151489734649658, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.008249396458268166, 'loss_2': 0.0018053054809570312, 'loss_3': -16.343006134033203, 'loss_4': 0.692582905292511, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 10:31:26,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:26,183 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:04:53<43:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:33,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01163719967007637, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.985, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007609922904521227, 'eval_loss_2': 0.004027277231216431, 'eval_loss_3': -18.306671142578125, 'eval_loss_4': 0.8957440853118896, 'epoch': 15.26}
{'loss': 0.0229, 'grad_norm': 7.167941093444824, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.018382692709565163, 'loss_2': 0.004558563232421875, 'loss_3': -16.284011840820312, 'loss_4': 1.0422942638397217, 'epoch': 15.27}
{'loss': 0.0078, 'grad_norm': 5.104567527770996, 'learning_rate': 1.475e-05, 'loss_1': 0.007584631908684969, 'loss_2': 0.00023758411407470703, 'loss_3': -16.41228485107422, 'loss_4': 0.8556246757507324, 'epoch': 15.27}
{'loss': 0.0155, 'grad_norm': 5.088245391845703, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.014638753607869148, 'loss_2': 0.0008268356323242188, 'loss_3': -16.57861328125, 'loss_4': 1.047542929649353, 'epoch': 15.28}
{'loss': 0.0135, 'grad_norm': 4.8356614112854, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.008499802090227604, 'loss_2': 0.004974365234375, 'loss_3': -16.294769287109375, 'loss_4': 1.2773101329803467, 'epoch': 15.28}
{'loss': 0.0345, 'grad_norm': 10.201021194458008, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.02766009047627449, 'loss_2': 0.00687408447265625, 'loss_3': -16.372833251953125, 'loss_4': 0.9273866415023804, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 10:31:33,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:33,513 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:00<43:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:40,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010267751291394234, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.576, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007930966094136238, 'eval_loss_2': 0.0023367851972579956, 'eval_loss_3': -18.29526138305664, 'eval_loss_4': 0.8040417432785034, 'epoch': 15.29}
{'loss': 0.0162, 'grad_norm': 4.817931652069092, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.007557564880698919, 'loss_2': 0.00862884521484375, 'loss_3': -16.486726760864258, 'loss_4': 0.7859475612640381, 'epoch': 15.3}
{'loss': 0.021, 'grad_norm': 7.980762958526611, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.02091306261718273, 'loss_2': 5.996227264404297e-05, 'loss_3': -16.44676399230957, 'loss_4': 1.1580618619918823, 'epoch': 15.3}
{'loss': 0.0195, 'grad_norm': 11.882891654968262, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.018480675294995308, 'loss_2': 0.0010280609130859375, 'loss_3': -16.46430206298828, 'loss_4': 1.0633924007415771, 'epoch': 15.31}
{'loss': 0.0161, 'grad_norm': 6.743500232696533, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.013674426823854446, 'loss_2': 0.002460479736328125, 'loss_3': -16.588102340698242, 'loss_4': 1.5118541717529297, 'epoch': 15.31}
{'loss': 0.0088, 'grad_norm': 4.538468837738037, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.00783330574631691, 'loss_2': 0.0009250640869140625, 'loss_3': -16.385990142822266, 'loss_4': 1.2023513317108154, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 10:31:40,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:40,865 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:07<43:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:48,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01021514367312193, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00746047031134367, 'eval_loss_2': 0.0027546733617782593, 'eval_loss_3': -18.310317993164062, 'eval_loss_4': 0.9384320974349976, 'epoch': 15.32}
{'loss': 0.01, 'grad_norm': 4.843461990356445, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.007099120877683163, 'loss_2': 0.002948760986328125, 'loss_3': -16.240680694580078, 'loss_4': 1.4320907592773438, 'epoch': 15.33}
{'loss': 0.0263, 'grad_norm': 12.753560066223145, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.02618342451751232, 'loss_2': 0.0001327991485595703, 'loss_3': -16.429767608642578, 'loss_4': 0.9093817472457886, 'epoch': 15.33}
{'loss': 0.0096, 'grad_norm': 4.719298362731934, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.005070514045655727, 'loss_2': 0.00457000732421875, 'loss_3': -16.477386474609375, 'loss_4': 1.0497976541519165, 'epoch': 15.34}
{'loss': 0.0082, 'grad_norm': 4.572218894958496, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.007367528975009918, 'loss_2': 0.0008287429809570312, 'loss_3': -16.54931640625, 'loss_4': 1.2511968612670898, 'epoch': 15.34}
{'loss': 0.0135, 'grad_norm': 8.608180046081543, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.012775822542607784, 'loss_2': 0.0007658004760742188, 'loss_3': -16.519790649414062, 'loss_4': 1.0142476558685303, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 10:31:48,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:48,189 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:15<43:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:55,514 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011180773377418518, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.406, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008270933292806149, 'eval_loss_2': 0.002909839153289795, 'eval_loss_3': -18.312088012695312, 'eval_loss_4': 1.1135953664779663, 'epoch': 15.35}
{'loss': 0.0059, 'grad_norm': 4.501857280731201, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.005381850991398096, 'loss_2': 0.0005407333374023438, 'loss_3': -16.474803924560547, 'loss_4': 1.3285863399505615, 'epoch': 15.35}
{'loss': 0.0128, 'grad_norm': 5.525453567504883, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.012720254249870777, 'loss_2': 6.920099258422852e-05, 'loss_3': -16.28919219970703, 'loss_4': 0.9931796193122864, 'epoch': 15.36}
{'loss': 0.0186, 'grad_norm': 7.464357852935791, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.0130013981834054, 'loss_2': 0.005580902099609375, 'loss_3': -16.478008270263672, 'loss_4': 1.0075891017913818, 'epoch': 15.37}
{'loss': 0.0142, 'grad_norm': 5.7114410400390625, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.009433566592633724, 'loss_2': 0.0048065185546875, 'loss_3': -16.515634536743164, 'loss_4': 1.368646502494812, 'epoch': 15.37}
{'loss': 0.0052, 'grad_norm': 4.583189010620117, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.004540340509265661, 'loss_2': 0.0007042884826660156, 'loss_3': -16.3845157623291, 'loss_4': 1.390416145324707, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 10:31:55,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:55,515 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:22<43:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:02,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013890927657485008, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.404, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.010327287018299103, 'eval_loss_2': 0.0035636425018310547, 'eval_loss_3': -18.31122589111328, 'eval_loss_4': 1.1254229545593262, 'epoch': 15.38}
{'loss': 0.0186, 'grad_norm': 5.079626083374023, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.011181565001606941, 'loss_2': 0.00737762451171875, 'loss_3': -16.42015838623047, 'loss_4': 0.9600169062614441, 'epoch': 15.38}
{'loss': 0.0272, 'grad_norm': 7.728275299072266, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.02378973178565502, 'loss_2': 0.003376007080078125, 'loss_3': -16.534473419189453, 'loss_4': 1.5240557193756104, 'epoch': 15.39}
{'loss': 0.0378, 'grad_norm': 12.281881332397461, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.032553140074014664, 'loss_2': 0.005279541015625, 'loss_3': -16.38501739501953, 'loss_4': 1.395339012145996, 'epoch': 15.4}
{'loss': 0.0298, 'grad_norm': 10.331121444702148, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.02231593057513237, 'loss_2': 0.0074615478515625, 'loss_3': -16.506240844726562, 'loss_4': 2.200326442718506, 'epoch': 15.4}
{'loss': 0.0196, 'grad_norm': 6.051425457000732, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.015560049563646317, 'loss_2': 0.0040435791015625, 'loss_3': -16.353111267089844, 'loss_4': 1.8136975765228271, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 10:32:02,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:02,844 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:29<43:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:10,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012557940557599068, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.009125546552240849, 'eval_loss_2': 0.0034323930740356445, 'eval_loss_3': -18.328275680541992, 'eval_loss_4': 1.1815721988677979, 'epoch': 15.41}
{'loss': 0.0111, 'grad_norm': 4.345975875854492, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.007284440565854311, 'loss_2': 0.0038204193115234375, 'loss_3': -16.659944534301758, 'loss_4': 1.60991370677948, 'epoch': 15.41}
{'loss': 0.0166, 'grad_norm': 6.554094314575195, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.014779695309698582, 'loss_2': 0.0018634796142578125, 'loss_3': -16.448715209960938, 'loss_4': 1.3167997598648071, 'epoch': 15.42}
{'loss': 0.0114, 'grad_norm': 4.910216808319092, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.008035955019295216, 'loss_2': 0.0033321380615234375, 'loss_3': -16.60424041748047, 'loss_4': 1.7660421133041382, 'epoch': 15.42}
{'loss': 0.0168, 'grad_norm': 6.518234729766846, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.013710788451135159, 'loss_2': 0.00307464599609375, 'loss_3': -16.587860107421875, 'loss_4': 1.137060523033142, 'epoch': 15.43}
{'loss': 0.0174, 'grad_norm': 5.879120826721191, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.012604758143424988, 'loss_2': 0.004817962646484375, 'loss_3': -16.41999626159668, 'loss_4': 1.6345319747924805, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 10:32:10,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:10,171 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:37<43:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:17,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013113318011164665, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.68, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010677080601453781, 'eval_loss_2': 0.002436235547065735, 'eval_loss_3': -18.3419189453125, 'eval_loss_4': 1.2852592468261719, 'epoch': 15.44}
{'loss': 0.0122, 'grad_norm': 5.599789142608643, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.00791490450501442, 'loss_2': 0.004299163818359375, 'loss_3': -16.353551864624023, 'loss_4': 1.5059747695922852, 'epoch': 15.44}
{'loss': 0.0323, 'grad_norm': 11.305970191955566, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.024077756330370903, 'loss_2': 0.0082550048828125, 'loss_3': -16.46200180053711, 'loss_4': 1.4809582233428955, 'epoch': 15.45}
{'loss': 0.0111, 'grad_norm': 5.892810344696045, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.008449656888842583, 'loss_2': 0.002628326416015625, 'loss_3': -16.671310424804688, 'loss_4': 1.1867378950119019, 'epoch': 15.45}
{'loss': 0.0482, 'grad_norm': 16.539567947387695, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.044421806931495667, 'loss_2': 0.00376129150390625, 'loss_3': -16.685115814208984, 'loss_4': 1.8434250354766846, 'epoch': 15.46}
{'loss': 0.028, 'grad_norm': 11.204826354980469, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.019648317247629166, 'loss_2': 0.00835418701171875, 'loss_3': -16.432165145874023, 'loss_4': 1.9689240455627441, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 10:32:17,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:17,525 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:44<43:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:24,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014757020398974419, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.396, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011919408105313778, 'eval_loss_2': 0.0028376132249832153, 'eval_loss_3': -18.331653594970703, 'eval_loss_4': 1.29374361038208, 'epoch': 15.47}
{'loss': 0.0172, 'grad_norm': 5.050691604614258, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.01408088207244873, 'loss_2': 0.00308990478515625, 'loss_3': -16.66192626953125, 'loss_4': 1.7541053295135498, 'epoch': 15.47}
{'loss': 0.0165, 'grad_norm': 6.19633150100708, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.011670026928186417, 'loss_2': 0.004787445068359375, 'loss_3': -16.377544403076172, 'loss_4': 1.06162428855896, 'epoch': 15.48}
{'loss': 0.0115, 'grad_norm': 4.822359561920166, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.0069985901936888695, 'loss_2': 0.0045166015625, 'loss_3': -16.295764923095703, 'loss_4': 1.5399086475372314, 'epoch': 15.48}
{'loss': 0.0172, 'grad_norm': 6.917043209075928, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.013784497044980526, 'loss_2': 0.00342559814453125, 'loss_3': -16.520174026489258, 'loss_4': 2.0829219818115234, 'epoch': 15.49}
{'loss': 0.0173, 'grad_norm': 8.336389541625977, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.013816706836223602, 'loss_2': 0.00344085693359375, 'loss_3': -16.461109161376953, 'loss_4': 2.222715377807617, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 10:32:24,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:24,851 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:05:51<43:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:32,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015079578384757042, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.147, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012294281274080276, 'eval_loss_2': 0.002785295248031616, 'eval_loss_3': -18.324352264404297, 'eval_loss_4': 1.3234155178070068, 'epoch': 15.49}
{'loss': 0.021, 'grad_norm': 6.850706100463867, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.013000008650124073, 'loss_2': 0.007965087890625, 'loss_3': -16.288204193115234, 'loss_4': 1.8527910709381104, 'epoch': 15.5}
{'loss': 0.0115, 'grad_norm': 5.367669582366943, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.010544960387051105, 'loss_2': 0.0009446144104003906, 'loss_3': -16.329362869262695, 'loss_4': 1.5765535831451416, 'epoch': 15.51}
{'loss': 0.0139, 'grad_norm': 4.770954132080078, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.006621283013373613, 'loss_2': 0.007328033447265625, 'loss_3': -16.553035736083984, 'loss_4': 1.4630365371704102, 'epoch': 15.51}
{'loss': 0.0168, 'grad_norm': 6.391299247741699, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.014125777408480644, 'loss_2': 0.00263214111328125, 'loss_3': -16.51711082458496, 'loss_4': 1.7208678722381592, 'epoch': 15.52}
{'loss': 0.0116, 'grad_norm': 4.765902042388916, 'learning_rate': 1.45e-05, 'loss_1': 0.009136507287621498, 'loss_2': 0.00244140625, 'loss_3': -16.259199142456055, 'loss_4': 1.6149604320526123, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 10:32:32,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:32,185 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:05:59<42:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:39,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0130973681807518, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.359, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.010523968376219273, 'eval_loss_2': 0.0025734007358551025, 'eval_loss_3': -18.3242130279541, 'eval_loss_4': 1.3936842679977417, 'epoch': 15.52}
{'loss': 0.0112, 'grad_norm': 5.927987575531006, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.010159790515899658, 'loss_2': 0.0009965896606445312, 'loss_3': -16.48967170715332, 'loss_4': 1.3719815015792847, 'epoch': 15.53}
{'loss': 0.0135, 'grad_norm': 5.7854132652282715, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.008836821652948856, 'loss_2': 0.0046844482421875, 'loss_3': -16.62335968017578, 'loss_4': 2.0116515159606934, 'epoch': 15.53}
{'loss': 0.0187, 'grad_norm': 5.922457218170166, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.011259641498327255, 'loss_2': 0.00740814208984375, 'loss_3': -16.226402282714844, 'loss_4': 1.8954763412475586, 'epoch': 15.54}
{'loss': 0.0467, 'grad_norm': 19.6677303314209, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.04439114034175873, 'loss_2': 0.002307891845703125, 'loss_3': -16.589248657226562, 'loss_4': 1.9911495447158813, 'epoch': 15.55}
{'loss': 0.0319, 'grad_norm': 11.328164100646973, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.02955378033220768, 'loss_2': 0.00229644775390625, 'loss_3': -16.526702880859375, 'loss_4': 1.6026268005371094, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 10:32:39,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:39,521 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:06<42:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:46,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012040659785270691, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.923, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009267852641642094, 'eval_loss_2': 0.002772808074951172, 'eval_loss_3': -18.314104080200195, 'eval_loss_4': 1.4426422119140625, 'epoch': 15.55}
{'loss': 0.0154, 'grad_norm': 5.076852321624756, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.006365032866597176, 'loss_2': 0.00902557373046875, 'loss_3': -16.409313201904297, 'loss_4': 1.204404592514038, 'epoch': 15.56}
{'loss': 0.0196, 'grad_norm': 7.142997741699219, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.01787099801003933, 'loss_2': 0.0017671585083007812, 'loss_3': -16.517839431762695, 'loss_4': 1.5246680974960327, 'epoch': 15.56}
{'loss': 0.0161, 'grad_norm': 5.030868053436279, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.008873113431036472, 'loss_2': 0.00725555419921875, 'loss_3': -16.46946907043457, 'loss_4': 0.7779983878135681, 'epoch': 15.57}
{'loss': 0.0091, 'grad_norm': 4.214972019195557, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.006142222322523594, 'loss_2': 0.00296783447265625, 'loss_3': -16.470638275146484, 'loss_4': 1.2750588655471802, 'epoch': 15.58}
{'loss': 0.0202, 'grad_norm': 6.4656662940979, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.01418514084070921, 'loss_2': 0.0059814453125, 'loss_3': -16.614351272583008, 'loss_4': 1.2913635969161987, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 10:32:46,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:46,859 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:13<42:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:54,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012286636978387833, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.225, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.008404197171330452, 'eval_loss_2': 0.0038824379444122314, 'eval_loss_3': -18.293378829956055, 'eval_loss_4': 1.3548951148986816, 'epoch': 15.58}
{'loss': 0.0055, 'grad_norm': 4.609522819519043, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.004439137410372496, 'loss_2': 0.001056671142578125, 'loss_3': -16.696260452270508, 'loss_4': 1.2060627937316895, 'epoch': 15.59}
{'loss': 0.0123, 'grad_norm': 4.824526309967041, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.005172717850655317, 'loss_2': 0.007171630859375, 'loss_3': -16.392763137817383, 'loss_4': 1.4276390075683594, 'epoch': 15.59}
{'loss': 0.0316, 'grad_norm': 15.855087280273438, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.024028927087783813, 'loss_2': 0.007537841796875, 'loss_3': -16.499069213867188, 'loss_4': 1.2861849069595337, 'epoch': 15.6}
{'loss': 0.026, 'grad_norm': 8.840821266174316, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.022863520309329033, 'loss_2': 0.003147125244140625, 'loss_3': -16.405590057373047, 'loss_4': 1.4956119060516357, 'epoch': 15.6}
{'loss': 0.0362, 'grad_norm': 8.999937057495117, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.03168944641947746, 'loss_2': 0.00453948974609375, 'loss_3': -16.502521514892578, 'loss_4': 1.345857858657837, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 10:32:54,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:54,190 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:21<42:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:33:01,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012621895410120487, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.898, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00838805828243494, 'eval_loss_2': 0.004233837127685547, 'eval_loss_3': -18.276569366455078, 'eval_loss_4': 1.2793313264846802, 'epoch': 15.61}
{'loss': 0.0091, 'grad_norm': 5.205209255218506, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.00592718506231904, 'loss_2': 0.00315093994140625, 'loss_3': -16.61368179321289, 'loss_4': 1.0119516849517822, 'epoch': 15.62}
{'loss': 0.0064, 'grad_norm': 4.776172637939453, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.004865424241870642, 'loss_2': 0.00152587890625, 'loss_3': -16.476266860961914, 'loss_4': 1.2736672163009644, 'epoch': 15.62}
{'loss': 0.0111, 'grad_norm': 5.0942487716674805, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.006624894216656685, 'loss_2': 0.0044708251953125, 'loss_3': -16.481155395507812, 'loss_4': 1.2184371948242188, 'epoch': 15.63}
{'loss': 0.0454, 'grad_norm': 18.317415237426758, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.04507455974817276, 'loss_2': 0.0003159046173095703, 'loss_3': -16.370201110839844, 'loss_4': 1.572364330291748, 'epoch': 15.63}
{'loss': 0.0115, 'grad_norm': 4.886106967926025, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.003926164470613003, 'loss_2': 0.007598876953125, 'loss_3': -16.54940414428711, 'loss_4': 1.6159180402755737, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 10:33:01,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:01,519 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:28<42:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:08,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01172904297709465, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.09, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008228477090597153, 'eval_loss_2': 0.0035005658864974976, 'eval_loss_3': -18.275463104248047, 'eval_loss_4': 1.2649381160736084, 'epoch': 15.64}
{'loss': 0.0126, 'grad_norm': 6.423034191131592, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.010633215308189392, 'loss_2': 0.001956939697265625, 'loss_3': -16.403961181640625, 'loss_4': 1.3689701557159424, 'epoch': 15.65}
{'loss': 0.0038, 'grad_norm': 5.09934139251709, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.003059027250856161, 'loss_2': 0.0007257461547851562, 'loss_3': -16.629573822021484, 'loss_4': 1.3107655048370361, 'epoch': 15.65}
{'loss': 0.0143, 'grad_norm': 6.041449546813965, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.007825497537851334, 'loss_2': 0.0065155029296875, 'loss_3': -16.488101959228516, 'loss_4': 1.2286906242370605, 'epoch': 15.66}
{'loss': 0.0112, 'grad_norm': 5.613564491271973, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.009034045971930027, 'loss_2': 0.002132415771484375, 'loss_3': -16.499725341796875, 'loss_4': 1.320378065109253, 'epoch': 15.66}
{'loss': 0.0111, 'grad_norm': 5.688697338104248, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.007305032107979059, 'loss_2': 0.003818511962890625, 'loss_3': -16.540109634399414, 'loss_4': 1.2022359371185303, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 10:33:08,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:08,847 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:35<42:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:16,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013245302252471447, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.459, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008396493270993233, 'eval_loss_2': 0.00484880805015564, 'eval_loss_3': -18.274534225463867, 'eval_loss_4': 1.3183544874191284, 'epoch': 15.67}
{'loss': 0.0104, 'grad_norm': 6.09693717956543, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.00856386311352253, 'loss_2': 0.00185394287109375, 'loss_3': -16.498226165771484, 'loss_4': 1.2876752614974976, 'epoch': 15.67}
{'loss': 0.0137, 'grad_norm': 6.1024627685546875, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.011765900999307632, 'loss_2': 0.0019054412841796875, 'loss_3': -16.5196475982666, 'loss_4': 1.51622474193573, 'epoch': 15.68}
{'loss': 0.0287, 'grad_norm': 17.348676681518555, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.027165332809090614, 'loss_2': 0.001506805419921875, 'loss_3': -16.350725173950195, 'loss_4': 1.0684535503387451, 'epoch': 15.69}
{'loss': 0.0078, 'grad_norm': 4.874566078186035, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.006859061773866415, 'loss_2': 0.000919342041015625, 'loss_3': -16.70130157470703, 'loss_4': 1.585858941078186, 'epoch': 15.69}
{'loss': 0.0339, 'grad_norm': 9.080911636352539, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.030717963352799416, 'loss_2': 0.003147125244140625, 'loss_3': -16.553871154785156, 'loss_4': 1.6512751579284668, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 10:33:16,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:16,175 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:43<42:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:23,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012575480155646801, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007788989692926407, 'eval_loss_2': 0.004786491394042969, 'eval_loss_3': -18.272598266601562, 'eval_loss_4': 1.4735628366470337, 'epoch': 15.7}
{'loss': 0.0072, 'grad_norm': 4.816858291625977, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.0050835683941841125, 'loss_2': 0.002132415771484375, 'loss_3': -16.601123809814453, 'loss_4': 1.6454520225524902, 'epoch': 15.7}
{'loss': 0.0179, 'grad_norm': 7.358538627624512, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.01380949281156063, 'loss_2': 0.004108428955078125, 'loss_3': -16.6197509765625, 'loss_4': 1.4298388957977295, 'epoch': 15.71}
{'loss': 0.0101, 'grad_norm': 4.885275363922119, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.007927767932415009, 'loss_2': 0.00213623046875, 'loss_3': -16.567705154418945, 'loss_4': 1.5416492223739624, 'epoch': 15.72}
{'loss': 0.0253, 'grad_norm': 10.088094711303711, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.01737389899790287, 'loss_2': 0.00788116455078125, 'loss_3': -16.34804916381836, 'loss_4': 1.3836601972579956, 'epoch': 15.72}
{'loss': 0.0128, 'grad_norm': 5.58405065536499, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.00790482573211193, 'loss_2': 0.004913330078125, 'loss_3': -16.39875602722168, 'loss_4': 1.7413389682769775, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 10:33:23,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:23,512 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:06:50<42:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:30,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01638437807559967, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.509, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007765664719045162, 'eval_loss_2': 0.008618712425231934, 'eval_loss_3': -18.304244995117188, 'eval_loss_4': 1.454695701599121, 'epoch': 15.73}
{'loss': 0.0368, 'grad_norm': 16.146005630493164, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.03300232067704201, 'loss_2': 0.003814697265625, 'loss_3': -16.388837814331055, 'loss_4': 1.2652437686920166, 'epoch': 15.73}
{'loss': 0.0178, 'grad_norm': 6.790639400482178, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.011577485129237175, 'loss_2': 0.00624847412109375, 'loss_3': -16.382007598876953, 'loss_4': 1.8604737520217896, 'epoch': 15.74}
{'loss': 0.0166, 'grad_norm': 5.791092872619629, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.011574674397706985, 'loss_2': 0.005008697509765625, 'loss_3': -16.410438537597656, 'loss_4': 1.7530410289764404, 'epoch': 15.74}
{'loss': 0.0391, 'grad_norm': 12.883634567260742, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.030553214251995087, 'loss_2': 0.008575439453125, 'loss_3': -16.220687866210938, 'loss_4': 2.194115161895752, 'epoch': 15.75}
{'loss': 0.0201, 'grad_norm': 5.606293678283691, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.00963125005364418, 'loss_2': 0.0104217529296875, 'loss_3': -16.571029663085938, 'loss_4': 1.6027553081512451, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 10:33:30,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:30,839 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:06:57<42:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:38,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014558345079421997, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00643232511356473, 'eval_loss_2': 0.008126020431518555, 'eval_loss_3': -18.331865310668945, 'eval_loss_4': 1.6092517375946045, 'epoch': 15.76}
{'loss': 0.0093, 'grad_norm': 5.611555576324463, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.009084400720894337, 'loss_2': 0.00024700164794921875, 'loss_3': -16.411901473999023, 'loss_4': 1.6600377559661865, 'epoch': 15.76}
{'loss': 0.0253, 'grad_norm': 7.802844524383545, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.014550658874213696, 'loss_2': 0.01079559326171875, 'loss_3': -16.316383361816406, 'loss_4': 2.1014552116394043, 'epoch': 15.77}
{'loss': 0.0195, 'grad_norm': 4.542598724365234, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.008594118058681488, 'loss_2': 0.01090240478515625, 'loss_3': -16.29043960571289, 'loss_4': 2.130516529083252, 'epoch': 15.77}
{'loss': 0.0139, 'grad_norm': 5.712058067321777, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.010769428685307503, 'loss_2': 0.00308990478515625, 'loss_3': -16.397411346435547, 'loss_4': 2.153873920440674, 'epoch': 15.78}
{'loss': 0.0233, 'grad_norm': 6.835083961486816, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.013325453735888004, 'loss_2': 0.01001739501953125, 'loss_3': -16.48223876953125, 'loss_4': 2.2001757621765137, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 10:33:38,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:38,188 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:05<42:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:45,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01206942182034254, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.222, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0062270937487483025, 'eval_loss_2': 0.005842328071594238, 'eval_loss_3': -18.334285736083984, 'eval_loss_4': 1.7321678400039673, 'epoch': 15.78}
{'loss': 0.0156, 'grad_norm': 5.365922451019287, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.007716476451605558, 'loss_2': 0.0078887939453125, 'loss_3': -16.485214233398438, 'loss_4': 1.8860950469970703, 'epoch': 15.79}
{'loss': 0.025, 'grad_norm': 10.12252140045166, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.022757338359951973, 'loss_2': 0.0022430419921875, 'loss_3': -16.449316024780273, 'loss_4': 2.2653427124023438, 'epoch': 15.8}
{'loss': 0.0132, 'grad_norm': 8.883121490478516, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.011614566668868065, 'loss_2': 0.0015716552734375, 'loss_3': -16.61349868774414, 'loss_4': 1.97134268283844, 'epoch': 15.8}
{'loss': 0.0174, 'grad_norm': 6.404474258422852, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.010900424793362617, 'loss_2': 0.00647735595703125, 'loss_3': -16.368057250976562, 'loss_4': 2.3911352157592773, 'epoch': 15.81}
{'loss': 0.0079, 'grad_norm': 4.739563941955566, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.004090824630111456, 'loss_2': 0.003841400146484375, 'loss_3': -16.519546508789062, 'loss_4': 1.6651277542114258, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 10:33:45,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:45,515 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:12<42:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:52,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01091739721596241, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.008046123199164867, 'eval_loss_2': 0.002871274948120117, 'eval_loss_3': -18.343769073486328, 'eval_loss_4': 1.8907393217086792, 'epoch': 15.81}
{'loss': 0.0104, 'grad_norm': 5.597413063049316, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.006597026251256466, 'loss_2': 0.0038394927978515625, 'loss_3': -16.442840576171875, 'loss_4': 2.2706432342529297, 'epoch': 15.82}
{'loss': 0.0282, 'grad_norm': 9.49773120880127, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.027394792065024376, 'loss_2': 0.0008234977722167969, 'loss_3': -16.248733520507812, 'loss_4': 2.105945110321045, 'epoch': 15.83}
{'loss': 0.0167, 'grad_norm': 7.84385347366333, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.012293603271245956, 'loss_2': 0.00445556640625, 'loss_3': -16.42706871032715, 'loss_4': 2.3316972255706787, 'epoch': 15.83}
{'loss': 0.0105, 'grad_norm': 4.987829685211182, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.007224205881357193, 'loss_2': 0.0033092498779296875, 'loss_3': -16.523752212524414, 'loss_4': 1.9277186393737793, 'epoch': 15.84}
{'loss': 0.0182, 'grad_norm': 8.531982421875, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.013525930233299732, 'loss_2': 0.0046539306640625, 'loss_3': -16.295211791992188, 'loss_4': 2.1947710514068604, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 10:33:52,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:52,846 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:19<41:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:00,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011184923350811005, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.799, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007711104117333889, 'eval_loss_2': 0.003473818302154541, 'eval_loss_3': -18.34418487548828, 'eval_loss_4': 1.9957174062728882, 'epoch': 15.84}
{'loss': 0.0203, 'grad_norm': 6.726093769073486, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.018644412979483604, 'loss_2': 0.0016145706176757812, 'loss_3': -16.421791076660156, 'loss_4': 2.062464714050293, 'epoch': 15.85}
{'loss': 0.0108, 'grad_norm': 4.558667182922363, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.0049163768999278545, 'loss_2': 0.005931854248046875, 'loss_3': -16.35420799255371, 'loss_4': 1.7627084255218506, 'epoch': 15.85}
{'loss': 0.0158, 'grad_norm': 6.42832088470459, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.012265978381037712, 'loss_2': 0.003505706787109375, 'loss_3': -16.635711669921875, 'loss_4': 1.8442416191101074, 'epoch': 15.86}
{'loss': 0.0178, 'grad_norm': 9.077449798583984, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.015414710156619549, 'loss_2': 0.00241851806640625, 'loss_3': -16.537580490112305, 'loss_4': 3.2748982906341553, 'epoch': 15.87}
{'loss': 0.0221, 'grad_norm': 5.726864337921143, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.009876779280602932, 'loss_2': 0.01226806640625, 'loss_3': -16.393260955810547, 'loss_4': 2.473855495452881, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 10:34:00,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:00,178 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:27<41:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:07,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01275283470749855, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.569, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007836643606424332, 'eval_loss_2': 0.004916191101074219, 'eval_loss_3': -18.344554901123047, 'eval_loss_4': 1.9562952518463135, 'epoch': 15.87}
{'loss': 0.0657, 'grad_norm': 21.90011978149414, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.06121141463518143, 'loss_2': 0.004486083984375, 'loss_3': -16.457069396972656, 'loss_4': 2.3910446166992188, 'epoch': 15.88}
{'loss': 0.0211, 'grad_norm': 6.255923271179199, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.013764924369752407, 'loss_2': 0.00733184814453125, 'loss_3': -16.501998901367188, 'loss_4': 2.660828113555908, 'epoch': 15.88}
{'loss': 0.0161, 'grad_norm': 6.1086554527282715, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.014023983851075172, 'loss_2': 0.002044677734375, 'loss_3': -16.447406768798828, 'loss_4': 2.39847993850708, 'epoch': 15.89}
{'loss': 0.0147, 'grad_norm': 5.642873764038086, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.012337908148765564, 'loss_2': 0.002407073974609375, 'loss_3': -16.540180206298828, 'loss_4': 2.527799606323242, 'epoch': 15.9}
{'loss': 0.0197, 'grad_norm': 7.451207160949707, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.016819672659039497, 'loss_2': 0.002864837646484375, 'loss_3': -16.318187713623047, 'loss_4': 1.917263150215149, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 10:34:07,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:07,506 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:34<42:18,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:34:15,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01281639002263546, 'eval_runtime': 3.9857, 'eval_samples_per_second': 256.919, 'eval_steps_per_second': 4.014, 'eval_loss_1': 0.008219857700169086, 'eval_loss_2': 0.004596531391143799, 'eval_loss_3': -18.331235885620117, 'eval_loss_4': 1.8019170761108398, 'epoch': 15.9}
{'loss': 0.0148, 'grad_norm': 4.985363483428955, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.0061666108667850494, 'loss_2': 0.008636474609375, 'loss_3': -16.271278381347656, 'loss_4': 1.8496692180633545, 'epoch': 15.91}
{'loss': 0.0255, 'grad_norm': 7.700743198394775, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.014625591225922108, 'loss_2': 0.010894775390625, 'loss_3': -16.40826416015625, 'loss_4': 2.2811994552612305, 'epoch': 15.91}
{'loss': 0.0214, 'grad_norm': 6.4275689125061035, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.014272835105657578, 'loss_2': 0.00714111328125, 'loss_3': -16.40283966064453, 'loss_4': 2.419755697250366, 'epoch': 15.92}
{'loss': 0.0154, 'grad_norm': 5.868465900421143, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.011542671360075474, 'loss_2': 0.0038299560546875, 'loss_3': -16.295324325561523, 'loss_4': 1.624280571937561, 'epoch': 15.92}
{'loss': 0.0264, 'grad_norm': 11.26429271697998, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.02529117651283741, 'loss_2': 0.0011386871337890625, 'loss_3': -16.56463050842285, 'loss_4': 1.825685977935791, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 10:34:15,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:15,028 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:42<41:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:22,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009441031143069267, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.006952522322535515, 'eval_loss_2': 0.0024885088205337524, 'eval_loss_3': -18.341550827026367, 'eval_loss_4': 1.6653764247894287, 'epoch': 15.93}
{'loss': 0.0211, 'grad_norm': 5.665288925170898, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.013876484706997871, 'loss_2': 0.007232666015625, 'loss_3': -16.445301055908203, 'loss_4': 2.1734061241149902, 'epoch': 15.94}
{'loss': 0.0115, 'grad_norm': 5.076705455780029, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.007832174189388752, 'loss_2': 0.003650665283203125, 'loss_3': -16.302715301513672, 'loss_4': 2.539043426513672, 'epoch': 15.94}
{'loss': 0.0171, 'grad_norm': 4.944663047790527, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.007288075517863035, 'loss_2': 0.00982666015625, 'loss_3': -16.438823699951172, 'loss_4': 2.185530424118042, 'epoch': 15.95}
{'loss': 0.0177, 'grad_norm': 10.846559524536133, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.01683102920651436, 'loss_2': 0.0008668899536132812, 'loss_3': -16.503803253173828, 'loss_4': 2.320598602294922, 'epoch': 15.95}
{'loss': 0.0198, 'grad_norm': 5.837645053863525, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.013328174129128456, 'loss_2': 0.0064544677734375, 'loss_3': -16.395877838134766, 'loss_4': 1.2839939594268799, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 10:34:22,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:22,370 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:07:49<41:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:29,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010559609159827232, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.045, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007703803479671478, 'eval_loss_2': 0.0028558075428009033, 'eval_loss_3': -18.326740264892578, 'eval_loss_4': 1.6016147136688232, 'epoch': 15.96}
{'loss': 0.0116, 'grad_norm': 4.916801452636719, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.007789954077452421, 'loss_2': 0.00379180908203125, 'loss_3': -16.295825958251953, 'loss_4': 1.6748602390289307, 'epoch': 15.97}
{'loss': 0.0189, 'grad_norm': 6.280712604522705, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.013271761126816273, 'loss_2': 0.0055999755859375, 'loss_3': -16.2889404296875, 'loss_4': 2.5108306407928467, 'epoch': 15.97}
{'loss': 0.0247, 'grad_norm': 7.24326753616333, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.02058073878288269, 'loss_2': 0.004138946533203125, 'loss_3': -16.618770599365234, 'loss_4': 2.4274802207946777, 'epoch': 15.98}
{'loss': 0.0107, 'grad_norm': 5.295506000518799, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.006224528886377811, 'loss_2': 0.00446319580078125, 'loss_3': -16.53168296813965, 'loss_4': 1.7062323093414307, 'epoch': 15.98}
{'loss': 0.0121, 'grad_norm': 4.61677360534668, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.009648078121244907, 'loss_2': 0.00244903564453125, 'loss_3': -16.48623275756836, 'loss_4': 2.113973617553711, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 10:34:29,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:29,707 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:07:56<40:20,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:34:36,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010598378255963326, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.354, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006919401697814465, 'eval_loss_2': 0.0036789774894714355, 'eval_loss_3': -18.317842483520508, 'eval_loss_4': 1.531211256980896, 'epoch': 15.99}
{'loss': 0.0205, 'grad_norm': 6.377569675445557, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.010003388859331608, 'loss_2': 0.0104522705078125, 'loss_3': -16.471729278564453, 'loss_4': 1.9058167934417725, 'epoch': 15.99}
{'loss': 0.0107, 'grad_norm': 7.1103129386901855, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.0054591260850429535, 'loss_2': 0.005218505859375, 'loss_3': -16.171052932739258, 'loss_4': 1.6116905212402344, 'epoch': 16.0}
{'loss': 0.0101, 'grad_norm': 5.826419830322266, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.009677939116954803, 'loss_2': 0.0004496574401855469, 'loss_3': -16.48249626159668, 'loss_4': 1.7214727401733398, 'epoch': 16.01}
{'loss': 0.0318, 'grad_norm': 18.85048484802246, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.028831778094172478, 'loss_2': 0.00293731689453125, 'loss_3': -16.293766021728516, 'loss_4': 1.3575007915496826, 'epoch': 16.01}
{'loss': 0.0278, 'grad_norm': 6.955632209777832, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.01586323417723179, 'loss_2': 0.011932373046875, 'loss_3': -16.359769821166992, 'loss_4': 1.8180902004241943, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 10:34:36,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:36,724 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:03<41:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:34:44,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010154005140066147, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.698, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0072170160710811615, 'eval_loss_2': 0.0029369890689849854, 'eval_loss_3': -18.315675735473633, 'eval_loss_4': 1.4088265895843506, 'epoch': 16.02}
{'loss': 0.0329, 'grad_norm': 13.062460899353027, 'learning_rate': 1.4e-05, 'loss_1': 0.029915250837802887, 'loss_2': 0.0029697418212890625, 'loss_3': -16.299564361572266, 'loss_4': 1.8510773181915283, 'epoch': 16.02}
{'loss': 0.0098, 'grad_norm': 5.1382904052734375, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.009194093756377697, 'loss_2': 0.0006265640258789062, 'loss_3': -16.346195220947266, 'loss_4': 1.667583703994751, 'epoch': 16.03}
{'loss': 0.0163, 'grad_norm': 6.021829128265381, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.012214996851980686, 'loss_2': 0.00411224365234375, 'loss_3': -16.52555274963379, 'loss_4': 1.9575061798095703, 'epoch': 16.03}
{'loss': 0.0191, 'grad_norm': 7.203248500823975, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.016644077375531197, 'loss_2': 0.00246429443359375, 'loss_3': -16.303497314453125, 'loss_4': 1.910595417022705, 'epoch': 16.04}
{'loss': 0.0243, 'grad_norm': 9.922098159790039, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.022319119423627853, 'loss_2': 0.0019474029541015625, 'loss_3': -16.547407150268555, 'loss_4': 1.91405189037323, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 10:34:44,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:44,061 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:11<41:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:51,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008199676871299744, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.921, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.005817785859107971, 'eval_loss_2': 0.0023818910121917725, 'eval_loss_3': -18.315338134765625, 'eval_loss_4': 1.2672086954116821, 'epoch': 16.05}
{'loss': 0.0086, 'grad_norm': 1.9168174266815186, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.008633515797555447, 'loss_2': 1.1920928955078125e-06, 'loss_3': -16.325313568115234, 'loss_4': 1.4460493326187134, 'epoch': 16.05}
{'loss': 0.016, 'grad_norm': 6.22983980178833, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.014715677127242088, 'loss_2': 0.0013027191162109375, 'loss_3': -16.24274444580078, 'loss_4': 1.6769474744796753, 'epoch': 16.06}
{'loss': 0.0148, 'grad_norm': 4.772860050201416, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.006936062127351761, 'loss_2': 0.007904052734375, 'loss_3': -16.479522705078125, 'loss_4': 1.6567965745925903, 'epoch': 16.06}
{'loss': 0.014, 'grad_norm': 5.895227432250977, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.010391445830464363, 'loss_2': 0.00360870361328125, 'loss_3': -16.349971771240234, 'loss_4': 1.2158761024475098, 'epoch': 16.07}
{'loss': 0.0292, 'grad_norm': 8.143377304077148, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.0158451646566391, 'loss_2': 0.013336181640625, 'loss_3': -16.353076934814453, 'loss_4': 1.7173089981079102, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 10:34:51,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:51,401 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:18<41:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:58,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008696500211954117, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.929, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006043632049113512, 'eval_loss_2': 0.002652868628501892, 'eval_loss_3': -18.297643661499023, 'eval_loss_4': 1.0712480545043945, 'epoch': 16.08}
{'loss': 0.0211, 'grad_norm': 12.375164031982422, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.015578128397464752, 'loss_2': 0.00548553466796875, 'loss_3': -16.52089500427246, 'loss_4': 1.1254470348358154, 'epoch': 16.08}
{'loss': 0.0352, 'grad_norm': 16.139421463012695, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.03391442075371742, 'loss_2': 0.0013065338134765625, 'loss_3': -16.399076461791992, 'loss_4': 1.0716545581817627, 'epoch': 16.09}
{'loss': 0.0108, 'grad_norm': 5.479841709136963, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.007079300004988909, 'loss_2': 0.003681182861328125, 'loss_3': -16.27267837524414, 'loss_4': 1.2461726665496826, 'epoch': 16.09}
{'loss': 0.017, 'grad_norm': 7.488376617431641, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.012066226452589035, 'loss_2': 0.004947662353515625, 'loss_3': -16.494686126708984, 'loss_4': 1.3344640731811523, 'epoch': 16.1}
{'loss': 0.0081, 'grad_norm': 5.320008754730225, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.007867985405027866, 'loss_2': 0.0002694129943847656, 'loss_3': -16.404067993164062, 'loss_4': 0.9197475910186768, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 10:34:58,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:58,742 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:25<41:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:06,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010152227245271206, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.928, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007101929746568203, 'eval_loss_2': 0.003050297498703003, 'eval_loss_3': -18.2607364654541, 'eval_loss_4': 0.9437525272369385, 'epoch': 16.1}
{'loss': 0.0203, 'grad_norm': 5.47271203994751, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.012853450141847134, 'loss_2': 0.007404327392578125, 'loss_3': -16.380714416503906, 'loss_4': 0.23599424958229065, 'epoch': 16.11}
{'loss': 0.0127, 'grad_norm': 4.802063941955566, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.006790294777601957, 'loss_2': 0.00589752197265625, 'loss_3': -16.432296752929688, 'loss_4': 1.0524511337280273, 'epoch': 16.12}
{'loss': 0.0104, 'grad_norm': 4.767879486083984, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.008395286276936531, 'loss_2': 0.0019931793212890625, 'loss_3': -16.3038272857666, 'loss_4': 1.1418797969818115, 'epoch': 16.12}
{'loss': 0.0069, 'grad_norm': 4.660456657409668, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.0051630716770887375, 'loss_2': 0.001743316650390625, 'loss_3': -16.380887985229492, 'loss_4': 0.9768675565719604, 'epoch': 16.13}
{'loss': 0.0179, 'grad_norm': 9.260080337524414, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.015597500838339329, 'loss_2': 0.002288818359375, 'loss_3': -16.383468627929688, 'loss_4': 0.7207313776016235, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 10:35:06,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:06,082 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:33<41:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:13,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01066327653825283, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.271, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00852995179593563, 'eval_loss_2': 0.0021333247423171997, 'eval_loss_3': -18.235824584960938, 'eval_loss_4': 0.7621797323226929, 'epoch': 16.13}
{'loss': 0.0101, 'grad_norm': 4.5393242835998535, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.007067617028951645, 'loss_2': 0.003055572509765625, 'loss_3': -16.247533798217773, 'loss_4': 0.6908099055290222, 'epoch': 16.14}
{'loss': 0.0106, 'grad_norm': 5.092371940612793, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.009701384231448174, 'loss_2': 0.0008769035339355469, 'loss_3': -16.52676773071289, 'loss_4': 0.47567179799079895, 'epoch': 16.15}
{'loss': 0.0106, 'grad_norm': 4.9132161140441895, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.006635905709117651, 'loss_2': 0.00400543212890625, 'loss_3': -16.58121681213379, 'loss_4': 0.33616626262664795, 'epoch': 16.15}
{'loss': 0.0307, 'grad_norm': 11.5576810836792, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.02882564440369606, 'loss_2': 0.0018310546875, 'loss_3': -16.33930206298828, 'loss_4': 0.782448410987854, 'epoch': 16.16}
{'loss': 0.0189, 'grad_norm': 10.62547492980957, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.016248399391770363, 'loss_2': 0.0026226043701171875, 'loss_3': -16.488590240478516, 'loss_4': 0.7328972220420837, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 10:35:13,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:13,411 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:40<40:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:20,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01161505002528429, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.235, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009094934910535812, 'eval_loss_2': 0.0025201141834259033, 'eval_loss_3': -18.242252349853516, 'eval_loss_4': 0.7090518474578857, 'epoch': 16.16}
{'loss': 0.0161, 'grad_norm': 5.930775165557861, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.012419819831848145, 'loss_2': 0.0036468505859375, 'loss_3': -16.468589782714844, 'loss_4': 0.639311671257019, 'epoch': 16.17}
{'loss': 0.0391, 'grad_norm': 8.88388442993164, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.035027388483285904, 'loss_2': 0.004058837890625, 'loss_3': -16.652891159057617, 'loss_4': 1.3382744789123535, 'epoch': 16.17}
{'loss': 0.0095, 'grad_norm': 5.118454456329346, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.006414733827114105, 'loss_2': 0.0030765533447265625, 'loss_3': -16.47780418395996, 'loss_4': 0.8249920606613159, 'epoch': 16.18}
{'loss': 0.0139, 'grad_norm': 6.224674224853516, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.013728439807891846, 'loss_2': 0.00014662742614746094, 'loss_3': -16.450729370117188, 'loss_4': 0.7688575387001038, 'epoch': 16.19}
{'loss': 0.0097, 'grad_norm': 4.908371448516846, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.006844745017588139, 'loss_2': 0.002841949462890625, 'loss_3': -16.5462703704834, 'loss_4': 0.9457904100418091, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 10:35:20,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:20,737 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:08:47<40:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:28,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011553402990102768, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.357, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.009106229990720749, 'eval_loss_2': 0.002447172999382019, 'eval_loss_3': -18.243274688720703, 'eval_loss_4': 0.6895855069160461, 'epoch': 16.19}
{'loss': 0.0092, 'grad_norm': 4.821742057800293, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.005905875004827976, 'loss_2': 0.0033245086669921875, 'loss_3': -16.409936904907227, 'loss_4': 0.6268794536590576, 'epoch': 16.2}
{'loss': 0.0259, 'grad_norm': 14.799459457397461, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.024739524349570274, 'loss_2': 0.0012044906616210938, 'loss_3': -16.185256958007812, 'loss_4': 0.894248366355896, 'epoch': 16.2}
{'loss': 0.0071, 'grad_norm': 5.425230503082275, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.0062797958962619305, 'loss_2': 0.0007853507995605469, 'loss_3': -16.47310447692871, 'loss_4': 0.37718260288238525, 'epoch': 16.21}
{'loss': 0.0179, 'grad_norm': 8.537193298339844, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.016509242355823517, 'loss_2': 0.00136566162109375, 'loss_3': -16.48931121826172, 'loss_4': 0.7067605257034302, 'epoch': 16.22}
{'loss': 0.021, 'grad_norm': 6.254516124725342, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.018817083910107613, 'loss_2': 0.0022144317626953125, 'loss_3': -16.271116256713867, 'loss_4': 0.8679872751235962, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 10:35:28,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:28,063 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:08:55<40:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:35,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013117654249072075, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.277, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.009263227693736553, 'eval_loss_2': 0.003854423761367798, 'eval_loss_3': -18.25481414794922, 'eval_loss_4': 0.5325251817703247, 'epoch': 16.22}
{'loss': 0.0102, 'grad_norm': 6.017337322235107, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.010012117214500904, 'loss_2': 0.00021386146545410156, 'loss_3': -16.332088470458984, 'loss_4': 0.32924923300743103, 'epoch': 16.23}
{'loss': 0.0155, 'grad_norm': 6.127950668334961, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.010720893740653992, 'loss_2': 0.004802703857421875, 'loss_3': -16.39923858642578, 'loss_4': 0.5011029243469238, 'epoch': 16.23}
{'loss': 0.0169, 'grad_norm': 4.173333644866943, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.0037655991036444902, 'loss_2': 0.01312255859375, 'loss_3': -16.58057403564453, 'loss_4': 0.8681252598762512, 'epoch': 16.24}
{'loss': 0.0096, 'grad_norm': 4.943083763122559, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.00798412598669529, 'loss_2': 0.0016374588012695312, 'loss_3': -16.516130447387695, 'loss_4': 1.0941472053527832, 'epoch': 16.24}
{'loss': 0.0209, 'grad_norm': 12.839543342590332, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.02025698311626911, 'loss_2': 0.0006628036499023438, 'loss_3': -16.500484466552734, 'loss_4': 0.98280930519104, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 10:35:35,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:35,394 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:02<40:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:42,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012034906074404716, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.828, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008701157756149769, 'eval_loss_2': 0.003333747386932373, 'eval_loss_3': -18.263439178466797, 'eval_loss_4': 0.4841383993625641, 'epoch': 16.25}
{'loss': 0.0168, 'grad_norm': 6.771687030792236, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.0154182817786932, 'loss_2': 0.0013408660888671875, 'loss_3': -16.45425033569336, 'loss_4': 0.620235800743103, 'epoch': 16.26}
{'loss': 0.0962, 'grad_norm': 21.176128387451172, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.09509466588497162, 'loss_2': 0.0011005401611328125, 'loss_3': -16.23615074157715, 'loss_4': 0.4005963206291199, 'epoch': 16.26}
{'loss': 0.0112, 'grad_norm': 4.62785530090332, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.00424135010689497, 'loss_2': 0.00693511962890625, 'loss_3': -16.41971206665039, 'loss_4': 0.6021499633789062, 'epoch': 16.27}
{'loss': 0.0158, 'grad_norm': 4.37847375869751, 'learning_rate': 1.375e-05, 'loss_1': 0.007759899832308292, 'loss_2': 0.00806427001953125, 'loss_3': -16.50701141357422, 'loss_4': 0.20043125748634338, 'epoch': 16.27}
{'loss': 0.0097, 'grad_norm': 5.310173988342285, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.008255861699581146, 'loss_2': 0.0014019012451171875, 'loss_3': -16.38275909423828, 'loss_4': 0.5092406272888184, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 10:35:42,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:42,730 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:09<40:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:50,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012181537225842476, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.397, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008986652828752995, 'eval_loss_2': 0.0031948834657669067, 'eval_loss_3': -18.257827758789062, 'eval_loss_4': 0.4919930696487427, 'epoch': 16.28}
{'loss': 0.0089, 'grad_norm': 5.093954086303711, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.0055383360013365746, 'loss_2': 0.003391265869140625, 'loss_3': -16.49410629272461, 'loss_4': 0.6338076591491699, 'epoch': 16.28}
{'loss': 0.0165, 'grad_norm': 5.904125213623047, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.011610413901507854, 'loss_2': 0.00493621826171875, 'loss_3': -16.38420867919922, 'loss_4': 0.46654361486434937, 'epoch': 16.29}
{'loss': 0.0136, 'grad_norm': 5.449857234954834, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.010064562782645226, 'loss_2': 0.003513336181640625, 'loss_3': -16.694108963012695, 'loss_4': 0.4442065954208374, 'epoch': 16.3}
{'loss': 0.0071, 'grad_norm': 4.807491779327393, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.0068825613707304, 'loss_2': 0.0001964569091796875, 'loss_3': -16.40774917602539, 'loss_4': 0.3411337733268738, 'epoch': 16.3}
{'loss': 0.0139, 'grad_norm': 4.415957927703857, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.008621010929346085, 'loss_2': 0.00528717041015625, 'loss_3': -16.44070053100586, 'loss_4': 0.6721085906028748, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 10:35:50,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:50,061 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:17<40:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:57,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01313806977123022, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.294, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.008723153732717037, 'eval_loss_2': 0.004414916038513184, 'eval_loss_3': -18.246238708496094, 'eval_loss_4': 0.595284640789032, 'epoch': 16.31}
{'loss': 0.0287, 'grad_norm': 15.362358093261719, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.028178557753562927, 'loss_2': 0.0005712509155273438, 'loss_3': -16.638431549072266, 'loss_4': 0.6704326868057251, 'epoch': 16.31}
{'loss': 0.016, 'grad_norm': 6.661715984344482, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.014010951854288578, 'loss_2': 0.0019445419311523438, 'loss_3': -16.494911193847656, 'loss_4': 1.1907355785369873, 'epoch': 16.32}
{'loss': 0.0136, 'grad_norm': 4.990268707275391, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.009762506000697613, 'loss_2': 0.00388336181640625, 'loss_3': -16.571258544921875, 'loss_4': 1.3595094680786133, 'epoch': 16.33}
{'loss': 0.018, 'grad_norm': 6.1837921142578125, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.014898775145411491, 'loss_2': 0.003063201904296875, 'loss_3': -16.443513870239258, 'loss_4': 0.30623146891593933, 'epoch': 16.33}
{'loss': 0.0075, 'grad_norm': 4.6318206787109375, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.006897804792970419, 'loss_2': 0.0006451606750488281, 'loss_3': -16.511951446533203, 'loss_4': 0.5963724255561829, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 10:35:57,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:57,388 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:24<40:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:04,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012555736117064953, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.083, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008231150917708874, 'eval_loss_2': 0.004324585199356079, 'eval_loss_3': -18.256677627563477, 'eval_loss_4': 0.6751623153686523, 'epoch': 16.34}
{'loss': 0.018, 'grad_norm': 6.662753582000732, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.01368170790374279, 'loss_2': 0.004302978515625, 'loss_3': -16.822099685668945, 'loss_4': 0.7775132060050964, 'epoch': 16.34}
{'loss': 0.0159, 'grad_norm': 5.464136123657227, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.010673992335796356, 'loss_2': 0.005214691162109375, 'loss_3': -16.58753204345703, 'loss_4': 0.6205395460128784, 'epoch': 16.35}
{'loss': 0.0168, 'grad_norm': 6.376955032348633, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.010544219985604286, 'loss_2': 0.00621795654296875, 'loss_3': -16.286151885986328, 'loss_4': 1.3296573162078857, 'epoch': 16.35}
{'loss': 0.0308, 'grad_norm': 12.70318603515625, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.024038124829530716, 'loss_2': 0.0067596435546875, 'loss_3': -16.57884979248047, 'loss_4': 1.38474440574646, 'epoch': 16.36}
{'loss': 0.011, 'grad_norm': 5.954720497131348, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.008397866040468216, 'loss_2': 0.0025634765625, 'loss_3': -16.605152130126953, 'loss_4': 0.7714626789093018, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 10:36:04,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:04,721 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:31<40:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:12,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010881617665290833, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.105, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008242234587669373, 'eval_loss_2': 0.00263938307762146, 'eval_loss_3': -18.25525665283203, 'eval_loss_4': 0.8903223276138306, 'epoch': 16.37}
{'loss': 0.0184, 'grad_norm': 7.241461277008057, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.01509160827845335, 'loss_2': 0.0032596588134765625, 'loss_3': -16.34021759033203, 'loss_4': 0.6446278095245361, 'epoch': 16.37}
{'loss': 0.0214, 'grad_norm': 13.621627807617188, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.020954040810465813, 'loss_2': 0.00049591064453125, 'loss_3': -16.587261199951172, 'loss_4': 1.2538349628448486, 'epoch': 16.38}
{'loss': 0.0131, 'grad_norm': 6.246848106384277, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.010436014272272587, 'loss_2': 0.00269317626953125, 'loss_3': -16.416397094726562, 'loss_4': 0.84672611951828, 'epoch': 16.38}
{'loss': 0.0087, 'grad_norm': 5.195229530334473, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.007399433758109808, 'loss_2': 0.0013484954833984375, 'loss_3': -16.502079010009766, 'loss_4': 0.9412757754325867, 'epoch': 16.39}
{'loss': 0.0155, 'grad_norm': 17.083539962768555, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.012956969439983368, 'loss_2': 0.0025882720947265625, 'loss_3': -16.41050910949707, 'loss_4': 1.640406608581543, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 10:36:12,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:12,056 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:39<40:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:19,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01340700313448906, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.341, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007531892973929644, 'eval_loss_2': 0.005875110626220703, 'eval_loss_3': -18.253726959228516, 'eval_loss_4': 1.0551061630249023, 'epoch': 16.4}
{'loss': 0.0105, 'grad_norm': 4.970763206481934, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.007025893311947584, 'loss_2': 0.0034332275390625, 'loss_3': -16.300092697143555, 'loss_4': 1.0530295372009277, 'epoch': 16.4}
{'loss': 0.0174, 'grad_norm': 6.398500919342041, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.012818200513720512, 'loss_2': 0.0045623779296875, 'loss_3': -16.406375885009766, 'loss_4': 1.4988539218902588, 'epoch': 16.41}
{'loss': 0.0093, 'grad_norm': 5.255784034729004, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.008096272125840187, 'loss_2': 0.0012483596801757812, 'loss_3': -16.44112205505371, 'loss_4': 1.2646639347076416, 'epoch': 16.41}
{'loss': 0.011, 'grad_norm': 6.736353397369385, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.008728209882974625, 'loss_2': 0.002307891845703125, 'loss_3': -16.438146591186523, 'loss_4': 1.007989525794983, 'epoch': 16.42}
{'loss': 0.0093, 'grad_norm': 5.10788631439209, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.006897931918501854, 'loss_2': 0.0024280548095703125, 'loss_3': -16.381492614746094, 'loss_4': 0.7789629697799683, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 10:36:19,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:19,387 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:09:46<40:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:26,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015713561326265335, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00763129023835063, 'eval_loss_2': 0.008082270622253418, 'eval_loss_3': -18.261526107788086, 'eval_loss_4': 1.1905955076217651, 'epoch': 16.42}
{'loss': 0.0115, 'grad_norm': 4.8602471351623535, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.005918898619711399, 'loss_2': 0.0055389404296875, 'loss_3': -16.54497718811035, 'loss_4': 0.9327199459075928, 'epoch': 16.43}
{'loss': 0.0153, 'grad_norm': 4.753974437713623, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.006135954987257719, 'loss_2': 0.009185791015625, 'loss_3': -16.35565757751465, 'loss_4': 1.3186819553375244, 'epoch': 16.44}
{'loss': 0.0136, 'grad_norm': 5.226651668548584, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.0070319101214408875, 'loss_2': 0.006519317626953125, 'loss_3': -16.460693359375, 'loss_4': 1.2655096054077148, 'epoch': 16.44}
{'loss': 0.009, 'grad_norm': 4.930889129638672, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.007623142562806606, 'loss_2': 0.0013427734375, 'loss_3': -16.28920555114746, 'loss_4': 1.4443087577819824, 'epoch': 16.45}
{'loss': 0.0154, 'grad_norm': 4.8718719482421875, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.005108030047267675, 'loss_2': 0.01032257080078125, 'loss_3': -16.546241760253906, 'loss_4': 1.2679412364959717, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 10:36:26,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:26,732 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:09:53<40:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:36:34,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010164524428546429, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.478, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007045741192996502, 'eval_loss_2': 0.0031187832355499268, 'eval_loss_3': -18.24359893798828, 'eval_loss_4': 1.270097255706787, 'epoch': 16.45}
{'loss': 0.027, 'grad_norm': 15.446990966796875, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.022263169288635254, 'loss_2': 0.00472259521484375, 'loss_3': -16.52553939819336, 'loss_4': 1.6816372871398926, 'epoch': 16.46}
{'loss': 0.0454, 'grad_norm': 17.341415405273438, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.0402894951403141, 'loss_2': 0.005100250244140625, 'loss_3': -16.494483947753906, 'loss_4': 1.3681670427322388, 'epoch': 16.47}
{'loss': 0.009, 'grad_norm': 4.641041278839111, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.0063971662893891335, 'loss_2': 0.002635955810546875, 'loss_3': -16.59787940979004, 'loss_4': 0.9836509227752686, 'epoch': 16.47}
{'loss': 0.0089, 'grad_norm': 4.794351100921631, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.008280027657747269, 'loss_2': 0.0006322860717773438, 'loss_3': -16.40559196472168, 'loss_4': 1.215929627418518, 'epoch': 16.48}
{'loss': 0.0152, 'grad_norm': 4.786805629730225, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.00483602425083518, 'loss_2': 0.01031494140625, 'loss_3': -16.527212142944336, 'loss_4': 1.2871627807617188, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 10:36:34,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:34,054 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:01<40:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:41,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012561332434415817, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.027, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007712866645306349, 'eval_loss_2': 0.004848465323448181, 'eval_loss_3': -18.24286460876465, 'eval_loss_4': 1.3278701305389404, 'epoch': 16.48}
{'loss': 0.0154, 'grad_norm': 5.105803489685059, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.00795869529247284, 'loss_2': 0.00745391845703125, 'loss_3': -16.29327964782715, 'loss_4': 1.1617441177368164, 'epoch': 16.49}
{'loss': 0.0071, 'grad_norm': 6.0231242179870605, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.006447154097259045, 'loss_2': 0.000701904296875, 'loss_3': -16.289873123168945, 'loss_4': 1.5626004934310913, 'epoch': 16.49}
{'loss': 0.0228, 'grad_norm': 13.637036323547363, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.018384143710136414, 'loss_2': 0.00441741943359375, 'loss_3': -16.395029067993164, 'loss_4': 1.3583194017410278, 'epoch': 16.5}
{'loss': 0.0083, 'grad_norm': 4.307945728302002, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.004174147732555866, 'loss_2': 0.004138946533203125, 'loss_3': -16.4189453125, 'loss_4': 1.5725146532058716, 'epoch': 16.51}
{'loss': 0.0088, 'grad_norm': 4.79739236831665, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.003493456868454814, 'loss_2': 0.005340576171875, 'loss_3': -16.491634368896484, 'loss_4': 1.7244523763656616, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 10:36:41,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:41,387 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:08<39:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:48,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010822746902704239, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.86, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007728134281933308, 'eval_loss_2': 0.003094613552093506, 'eval_loss_3': -18.212039947509766, 'eval_loss_4': 1.4131948947906494, 'epoch': 16.51}
{'loss': 0.0098, 'grad_norm': 5.199156761169434, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.009168852120637894, 'loss_2': 0.0005855560302734375, 'loss_3': -16.320632934570312, 'loss_4': 1.2815461158752441, 'epoch': 16.52}
{'loss': 0.0345, 'grad_norm': 17.097721099853516, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.031413543969392776, 'loss_2': 0.0030994415283203125, 'loss_3': -16.321693420410156, 'loss_4': 2.0297019481658936, 'epoch': 16.52}
{'loss': 0.0237, 'grad_norm': 8.787313461303711, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.015616769902408123, 'loss_2': 0.0080413818359375, 'loss_3': -16.54575538635254, 'loss_4': 1.167890191078186, 'epoch': 16.53}
{'loss': 0.0173, 'grad_norm': 5.210765361785889, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.0071046119555830956, 'loss_2': 0.01019287109375, 'loss_3': -16.551189422607422, 'loss_4': 1.5207023620605469, 'epoch': 16.53}
{'loss': 0.0302, 'grad_norm': 11.07087516784668, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.018217913806438446, 'loss_2': 0.0119476318359375, 'loss_3': -16.26166534423828, 'loss_4': 1.9317293167114258, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 10:36:48,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:48,723 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:15<39:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:56,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014728637412190437, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.159, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007651719730347395, 'eval_loss_2': 0.007076919078826904, 'eval_loss_3': -18.211734771728516, 'eval_loss_4': 1.4819533824920654, 'epoch': 16.54}
{'loss': 0.025, 'grad_norm': 6.602910041809082, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.017227713018655777, 'loss_2': 0.00772857666015625, 'loss_3': -16.486881256103516, 'loss_4': 1.6602672338485718, 'epoch': 16.55}
{'loss': 0.0213, 'grad_norm': 5.894430160522461, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.010753029957413673, 'loss_2': 0.01050567626953125, 'loss_3': -16.239635467529297, 'loss_4': 1.499613642692566, 'epoch': 16.55}
{'loss': 0.016, 'grad_norm': 4.791142463684082, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.008098493330180645, 'loss_2': 0.00794219970703125, 'loss_3': -16.452444076538086, 'loss_4': 1.5385057926177979, 'epoch': 16.56}
{'loss': 0.014, 'grad_norm': 7.150195598602295, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.00831915345042944, 'loss_2': 0.0056915283203125, 'loss_3': -16.45836067199707, 'loss_4': 1.6428864002227783, 'epoch': 16.56}
{'loss': 0.0084, 'grad_norm': 4.454823017120361, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.00519203394651413, 'loss_2': 0.00325775146484375, 'loss_3': -16.424211502075195, 'loss_4': 1.0614650249481201, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 10:36:56,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:56,053 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:23<39:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:03,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011864444240927696, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.902, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00690496526658535, 'eval_loss_2': 0.004959478974342346, 'eval_loss_3': -18.217445373535156, 'eval_loss_4': 1.5041730403900146, 'epoch': 16.57}
{'loss': 0.0154, 'grad_norm': 5.3674421310424805, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.008254410699009895, 'loss_2': 0.00719451904296875, 'loss_3': -16.442302703857422, 'loss_4': 1.4723349809646606, 'epoch': 16.58}
{'loss': 0.0124, 'grad_norm': 5.411404609680176, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.007981446571648121, 'loss_2': 0.00445556640625, 'loss_3': -16.379478454589844, 'loss_4': 1.35185968875885, 'epoch': 16.58}
{'loss': 0.0095, 'grad_norm': 4.405569553375244, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.008459466509521008, 'loss_2': 0.001033782958984375, 'loss_3': -16.362764358520508, 'loss_4': 1.4150946140289307, 'epoch': 16.59}
{'loss': 0.008, 'grad_norm': 4.506209373474121, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.005496159661561251, 'loss_2': 0.002471923828125, 'loss_3': -16.315013885498047, 'loss_4': 1.3086860179901123, 'epoch': 16.59}
{'loss': 0.0096, 'grad_norm': 6.345219612121582, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.007860935293138027, 'loss_2': 0.0017261505126953125, 'loss_3': -16.54938507080078, 'loss_4': 1.969673752784729, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 10:37:03,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:03,384 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:30<39:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:10,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00927930511534214, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006777038332074881, 'eval_loss_2': 0.0025022663176059723, 'eval_loss_3': -18.21711540222168, 'eval_loss_4': 1.427091121673584, 'epoch': 16.6}
{'loss': 0.0158, 'grad_norm': 8.27123737335205, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.014413952827453613, 'loss_2': 0.0014209747314453125, 'loss_3': -16.206796646118164, 'loss_4': 1.527693510055542, 'epoch': 16.6}
{'loss': 0.0092, 'grad_norm': 4.928094863891602, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.006292131729424, 'loss_2': 0.002880096435546875, 'loss_3': -16.472999572753906, 'loss_4': 1.3895931243896484, 'epoch': 16.61}
{'loss': 0.0121, 'grad_norm': 4.916004180908203, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.007310627959668636, 'loss_2': 0.004749298095703125, 'loss_3': -16.34564971923828, 'loss_4': 1.5634251832962036, 'epoch': 16.62}
{'loss': 0.0177, 'grad_norm': 8.972325325012207, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.01584715023636818, 'loss_2': 0.0018215179443359375, 'loss_3': -16.50164031982422, 'loss_4': 1.4106931686401367, 'epoch': 16.62}
{'loss': 0.0132, 'grad_norm': 4.949856281280518, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.007479905616492033, 'loss_2': 0.005706787109375, 'loss_3': -16.30016326904297, 'loss_4': 1.9932098388671875, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 10:37:10,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:10,726 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:37<39:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:18,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009604062885046005, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.191, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0072151534259319305, 'eval_loss_2': 0.0023889094591140747, 'eval_loss_3': -18.217655181884766, 'eval_loss_4': 1.3316549062728882, 'epoch': 16.63}
{'loss': 0.0161, 'grad_norm': 6.4779253005981445, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.011893407441675663, 'loss_2': 0.004230499267578125, 'loss_3': -16.281606674194336, 'loss_4': 1.429292917251587, 'epoch': 16.63}
{'loss': 0.0362, 'grad_norm': 15.994110107421875, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.03228335082530975, 'loss_2': 0.00392913818359375, 'loss_3': -16.335920333862305, 'loss_4': 1.634263277053833, 'epoch': 16.64}
{'loss': 0.0218, 'grad_norm': 13.839324951171875, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.018916737288236618, 'loss_2': 0.00284576416015625, 'loss_3': -16.436124801635742, 'loss_4': 0.9775106310844421, 'epoch': 16.65}
{'loss': 0.0106, 'grad_norm': 5.3896989822387695, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.0068239616230130196, 'loss_2': 0.00377655029296875, 'loss_3': -16.260744094848633, 'loss_4': 1.254166841506958, 'epoch': 16.65}
{'loss': 0.0123, 'grad_norm': 5.386614799499512, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.0076187895610928535, 'loss_2': 0.00472259521484375, 'loss_3': -16.336959838867188, 'loss_4': 1.1817994117736816, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 10:37:18,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:18,055 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:45<39:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:25,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009757131338119507, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.44, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007688992191106081, 'eval_loss_2': 0.002068139612674713, 'eval_loss_3': -18.216506958007812, 'eval_loss_4': 1.2605316638946533, 'epoch': 16.66}
{'loss': 0.0105, 'grad_norm': 4.6507954597473145, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.0047348905354738235, 'loss_2': 0.005809783935546875, 'loss_3': -16.459136962890625, 'loss_4': 1.0037145614624023, 'epoch': 16.66}
{'loss': 0.018, 'grad_norm': 8.376556396484375, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.016444131731987, 'loss_2': 0.001598358154296875, 'loss_3': -16.281635284423828, 'loss_4': 1.191606044769287, 'epoch': 16.67}
{'loss': 0.0158, 'grad_norm': 6.3502631187438965, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.011413191445171833, 'loss_2': 0.004364013671875, 'loss_3': -16.4293212890625, 'loss_4': 1.1327637434005737, 'epoch': 16.67}
{'loss': 0.0119, 'grad_norm': 5.147075176239014, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.010022645816206932, 'loss_2': 0.001842498779296875, 'loss_3': -16.26429557800293, 'loss_4': 1.4924724102020264, 'epoch': 16.68}
{'loss': 0.0107, 'grad_norm': 6.879536151885986, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.010448211804032326, 'loss_2': 0.0002510547637939453, 'loss_3': -16.39227294921875, 'loss_4': 1.4219670295715332, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 10:37:25,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:25,384 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:10:52<39:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:32,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009204518049955368, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.989, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.006961876060813665, 'eval_loss_2': 0.0022426433861255646, 'eval_loss_3': -18.21380615234375, 'eval_loss_4': 1.2936556339263916, 'epoch': 16.69}
{'loss': 0.0129, 'grad_norm': 5.654980182647705, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.010341152548789978, 'loss_2': 0.0025653839111328125, 'loss_3': -16.181415557861328, 'loss_4': 1.5079774856567383, 'epoch': 16.69}
{'loss': 0.0223, 'grad_norm': 7.687756061553955, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.02113989181816578, 'loss_2': 0.0011234283447265625, 'loss_3': -16.41280174255371, 'loss_4': 1.4455174207687378, 'epoch': 16.7}
{'loss': 0.0105, 'grad_norm': 4.8458781242370605, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.006534782703965902, 'loss_2': 0.003997802734375, 'loss_3': -16.21883201599121, 'loss_4': 1.5330761671066284, 'epoch': 16.7}
{'loss': 0.0112, 'grad_norm': 6.829575538635254, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.008632328361272812, 'loss_2': 0.0026149749755859375, 'loss_3': -16.399572372436523, 'loss_4': 1.1452062129974365, 'epoch': 16.71}
{'loss': 0.0176, 'grad_norm': 6.114524841308594, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.012516560032963753, 'loss_2': 0.005123138427734375, 'loss_3': -16.43964958190918, 'loss_4': 1.0973844528198242, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 10:37:32,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:32,721 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:10:59<39:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:40,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009121314622461796, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.367, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006677680648863316, 'eval_loss_2': 0.0024436339735984802, 'eval_loss_3': -18.22208595275879, 'eval_loss_4': 1.2147828340530396, 'epoch': 16.72}
{'loss': 0.0107, 'grad_norm': 5.795795917510986, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.00650386605411768, 'loss_2': 0.004238128662109375, 'loss_3': -16.348052978515625, 'loss_4': 1.478229284286499, 'epoch': 16.72}
{'loss': 0.0097, 'grad_norm': 4.740606784820557, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.006011937744915485, 'loss_2': 0.00368499755859375, 'loss_3': -16.3326416015625, 'loss_4': 1.1789442300796509, 'epoch': 16.73}
{'loss': 0.0047, 'grad_norm': 4.424737930297852, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.00262809987179935, 'loss_2': 0.002086639404296875, 'loss_3': -16.391096115112305, 'loss_4': 0.9952007532119751, 'epoch': 16.73}
{'loss': 0.0082, 'grad_norm': 4.964334487915039, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.005282572470605373, 'loss_2': 0.0029144287109375, 'loss_3': -16.388349533081055, 'loss_4': 1.4551085233688354, 'epoch': 16.74}
{'loss': 0.0092, 'grad_norm': 4.619363307952881, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.006364360451698303, 'loss_2': 0.0028133392333984375, 'loss_3': -16.306503295898438, 'loss_4': 1.148957371711731, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 10:37:40,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:40,053 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:07<39:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:47,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009108616039156914, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.74, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006367626134306192, 'eval_loss_2': 0.0027409903705120087, 'eval_loss_3': -18.215486526489258, 'eval_loss_4': 0.9945535659790039, 'epoch': 16.74}
{'loss': 0.0143, 'grad_norm': 5.955157279968262, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.01242463756352663, 'loss_2': 0.0018367767333984375, 'loss_3': -16.555137634277344, 'loss_4': 1.5501697063446045, 'epoch': 16.75}
{'loss': 0.0107, 'grad_norm': 4.702850341796875, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.006715588737279177, 'loss_2': 0.003997802734375, 'loss_3': -16.216259002685547, 'loss_4': 0.4694814682006836, 'epoch': 16.76}
{'loss': 0.0391, 'grad_norm': 13.266997337341309, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.03169848769903183, 'loss_2': 0.007354736328125, 'loss_3': -16.44716453552246, 'loss_4': 1.7121140956878662, 'epoch': 16.76}
{'loss': 0.0111, 'grad_norm': 6.240406513214111, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.009137753397226334, 'loss_2': 0.002002716064453125, 'loss_3': -16.24155044555664, 'loss_4': 0.5385217666625977, 'epoch': 16.77}
{'loss': 0.0117, 'grad_norm': 4.580585956573486, 'learning_rate': 1.325e-05, 'loss_1': 0.006805159151554108, 'loss_2': 0.004894256591796875, 'loss_3': -16.22378921508789, 'loss_4': 1.0410974025726318, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 10:37:47,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:47,392 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:14<39:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:54,720 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008381319232285023, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.396, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006102737970650196, 'eval_loss_2': 0.0022785812616348267, 'eval_loss_3': -18.19191551208496, 'eval_loss_4': 0.7656331062316895, 'epoch': 16.77}
{'loss': 0.0177, 'grad_norm': 6.169092178344727, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.01322381291538477, 'loss_2': 0.004482269287109375, 'loss_3': -16.310226440429688, 'loss_4': 0.8495569229125977, 'epoch': 16.78}
{'loss': 0.0184, 'grad_norm': 5.988525390625, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.012181099504232407, 'loss_2': 0.0061798095703125, 'loss_3': -16.545085906982422, 'loss_4': 1.019357442855835, 'epoch': 16.78}
{'loss': 0.0139, 'grad_norm': 6.854432106018066, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.010940777137875557, 'loss_2': 0.00299072265625, 'loss_3': -16.226398468017578, 'loss_4': 0.3395403027534485, 'epoch': 16.79}
{'loss': 0.0177, 'grad_norm': 7.467055797576904, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.011168736033141613, 'loss_2': 0.00650787353515625, 'loss_3': -16.208576202392578, 'loss_4': 0.5216100215911865, 'epoch': 16.8}
{'loss': 0.0337, 'grad_norm': 13.31334114074707, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.02280159667134285, 'loss_2': 0.0108642578125, 'loss_3': -16.25844383239746, 'loss_4': 1.0274735689163208, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 10:37:54,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:54,720 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:21<39:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:02,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00861746072769165, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.347, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006289094686508179, 'eval_loss_2': 0.0023283660411834717, 'eval_loss_3': -18.19557762145996, 'eval_loss_4': 0.5762296915054321, 'epoch': 16.8}
{'loss': 0.0123, 'grad_norm': 8.295145034790039, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.011086029931902885, 'loss_2': 0.001232147216796875, 'loss_3': -16.37981605529785, 'loss_4': 0.8695768117904663, 'epoch': 16.81}
{'loss': 0.0146, 'grad_norm': 6.526086330413818, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.008443855680525303, 'loss_2': 0.006160736083984375, 'loss_3': -16.42249870300293, 'loss_4': 0.5418282747268677, 'epoch': 16.81}
{'loss': 0.0062, 'grad_norm': 4.849474906921387, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.005966232158243656, 'loss_2': 0.00019359588623046875, 'loss_3': -16.54256820678711, 'loss_4': 0.48007720708847046, 'epoch': 16.82}
{'loss': 0.0077, 'grad_norm': 4.417802810668945, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.005738448351621628, 'loss_2': 0.0019741058349609375, 'loss_3': -16.401185989379883, 'loss_4': 0.48558199405670166, 'epoch': 16.83}
{'loss': 0.0112, 'grad_norm': 6.023025035858154, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.01054825447499752, 'loss_2': 0.0006160736083984375, 'loss_3': -16.45838165283203, 'loss_4': 0.865433931350708, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 10:38:02,046 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:02,046 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:29<38:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:38:09,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0086629968136549, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.319, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006011038087308407, 'eval_loss_2': 0.0026519596576690674, 'eval_loss_3': -18.21135711669922, 'eval_loss_4': 0.6091139912605286, 'epoch': 16.83}
{'loss': 0.0058, 'grad_norm': 4.543367385864258, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.004941572435200214, 'loss_2': 0.0008587837219238281, 'loss_3': -16.215627670288086, 'loss_4': 0.967397928237915, 'epoch': 16.84}
{'loss': 0.0131, 'grad_norm': 5.372103691101074, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.00897516030818224, 'loss_2': 0.0041351318359375, 'loss_3': -16.628353118896484, 'loss_4': 0.23055247962474823, 'epoch': 16.84}
{'loss': 0.0059, 'grad_norm': 4.869801044464111, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.004302800167351961, 'loss_2': 0.0016050338745117188, 'loss_3': -16.248794555664062, 'loss_4': 0.4706261456012726, 'epoch': 16.85}
{'loss': 0.0085, 'grad_norm': 4.385560512542725, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.007369079627096653, 'loss_2': 0.00115203857421875, 'loss_3': -16.489501953125, 'loss_4': 0.45611560344696045, 'epoch': 16.85}
{'loss': 0.0136, 'grad_norm': 14.836352348327637, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.011897832155227661, 'loss_2': 0.00173187255859375, 'loss_3': -16.401348114013672, 'loss_4': 1.6946617364883423, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 10:38:09,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:09,367 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:36<38:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:38:16,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008916081860661507, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.453, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006708736065775156, 'eval_loss_2': 0.002207346260547638, 'eval_loss_3': -18.228742599487305, 'eval_loss_4': 0.8057138323783875, 'epoch': 16.86}
{'loss': 0.0216, 'grad_norm': 6.664773464202881, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.018277432769536972, 'loss_2': 0.0032825469970703125, 'loss_3': -16.442611694335938, 'loss_4': 1.4166531562805176, 'epoch': 16.87}
{'loss': 0.0212, 'grad_norm': 14.156670570373535, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.020039396360516548, 'loss_2': 0.0011119842529296875, 'loss_3': -16.302940368652344, 'loss_4': 1.787032961845398, 'epoch': 16.87}
{'loss': 0.0187, 'grad_norm': 6.300533771514893, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.01708914525806904, 'loss_2': 0.0015735626220703125, 'loss_3': -16.53371810913086, 'loss_4': 1.5827052593231201, 'epoch': 16.88}
{'loss': 0.0089, 'grad_norm': 5.634314060211182, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.006418763659894466, 'loss_2': 0.0024776458740234375, 'loss_3': -16.435331344604492, 'loss_4': 1.1008516550064087, 'epoch': 16.88}
{'loss': 0.025, 'grad_norm': 9.15520191192627, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.020405255258083344, 'loss_2': 0.0046234130859375, 'loss_3': -16.36018180847168, 'loss_4': 1.6818110942840576, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 10:38:16,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:16,691 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:43<38:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:24,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009403136558830738, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007176519371569157, 'eval_loss_2': 0.0022266171872615814, 'eval_loss_3': -18.23482322692871, 'eval_loss_4': 0.8907448649406433, 'epoch': 16.89}
{'loss': 0.0139, 'grad_norm': 7.166096210479736, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.01026663277298212, 'loss_2': 0.00362396240234375, 'loss_3': -16.443817138671875, 'loss_4': 1.4350064992904663, 'epoch': 16.9}
{'loss': 0.0112, 'grad_norm': 6.913717269897461, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.009170850738883018, 'loss_2': 0.00205230712890625, 'loss_3': -16.430517196655273, 'loss_4': 1.8764283657073975, 'epoch': 16.9}
{'loss': 0.0251, 'grad_norm': 6.31144905090332, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.01292650867253542, 'loss_2': 0.012176513671875, 'loss_3': -16.315956115722656, 'loss_4': 1.4308254718780518, 'epoch': 16.91}
{'loss': 0.0149, 'grad_norm': 5.5749993324279785, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.01058334019035101, 'loss_2': 0.0043182373046875, 'loss_3': -16.365278244018555, 'loss_4': 1.1615427732467651, 'epoch': 16.91}
{'loss': 0.0087, 'grad_norm': 4.9301981925964355, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.007421588525176048, 'loss_2': 0.0012416839599609375, 'loss_3': -16.37761878967285, 'loss_4': 1.7720861434936523, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 10:38:24,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:24,036 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:11:51<38:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:31,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009082271717488766, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.628, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0068363286554813385, 'eval_loss_2': 0.002245943993330002, 'eval_loss_3': -18.226240158081055, 'eval_loss_4': 0.954635739326477, 'epoch': 16.92}
{'loss': 0.0144, 'grad_norm': 7.127051830291748, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.013207838870584965, 'loss_2': 0.0011806488037109375, 'loss_3': -16.423683166503906, 'loss_4': 1.7697689533233643, 'epoch': 16.92}
{'loss': 0.0141, 'grad_norm': 6.826746463775635, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.011397311463952065, 'loss_2': 0.0027103424072265625, 'loss_3': -16.468021392822266, 'loss_4': 0.8525903224945068, 'epoch': 16.93}
{'loss': 0.0083, 'grad_norm': 4.727151393890381, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.0049323225393891335, 'loss_2': 0.003360748291015625, 'loss_3': -16.304826736450195, 'loss_4': 1.467468023300171, 'epoch': 16.94}
{'loss': 0.0121, 'grad_norm': 5.055410385131836, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.007686867378652096, 'loss_2': 0.00438690185546875, 'loss_3': -16.384090423583984, 'loss_4': 0.7627754211425781, 'epoch': 16.94}
{'loss': 0.0204, 'grad_norm': 6.213440418243408, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.013228358700871468, 'loss_2': 0.007221221923828125, 'loss_3': -16.22475242614746, 'loss_4': 1.933997392654419, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 10:38:31,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:31,378 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:11:58<38:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:38,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010498730465769768, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.051, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.006420446094125509, 'eval_loss_2': 0.004078283905982971, 'eval_loss_3': -18.232646942138672, 'eval_loss_4': 0.9845181107521057, 'epoch': 16.95}
{'loss': 0.0051, 'grad_norm': 4.345903396606445, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.0031523159705102444, 'loss_2': 0.00189971923828125, 'loss_3': -16.42672348022461, 'loss_4': 1.067563533782959, 'epoch': 16.95}
{'loss': 0.0119, 'grad_norm': 4.694573402404785, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.007870323956012726, 'loss_2': 0.0040130615234375, 'loss_3': -16.508358001708984, 'loss_4': 1.296844244003296, 'epoch': 16.96}
{'loss': 0.0276, 'grad_norm': 6.213107109069824, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.01631140150129795, 'loss_2': 0.011260986328125, 'loss_3': -16.240449905395508, 'loss_4': 1.4319367408752441, 'epoch': 16.97}
{'loss': 0.012, 'grad_norm': 5.353011608123779, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.009166368283331394, 'loss_2': 0.00278472900390625, 'loss_3': -16.51468849182129, 'loss_4': 1.1080594062805176, 'epoch': 16.97}
{'loss': 0.0171, 'grad_norm': 6.751222610473633, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.0139608234167099, 'loss_2': 0.00310516357421875, 'loss_3': -16.255144119262695, 'loss_4': 1.1236543655395508, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 10:38:38,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:38,709 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:05<36:17,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 10:38:45,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010051884688436985, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0062326714396476746, 'eval_loss_2': 0.003819212317466736, 'eval_loss_3': -18.222999572753906, 'eval_loss_4': 0.9828232526779175, 'epoch': 16.98}
{'loss': 0.0296, 'grad_norm': 12.706365585327148, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.029423709958791733, 'loss_2': 0.00012958049774169922, 'loss_3': -16.427001953125, 'loss_4': 1.716112732887268, 'epoch': 16.98}
{'loss': 0.0187, 'grad_norm': 5.644564151763916, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.0109623484313488, 'loss_2': 0.007781982421875, 'loss_3': -16.500076293945312, 'loss_4': 1.2913633584976196, 'epoch': 16.99}
{'loss': 0.012, 'grad_norm': 5.737345218658447, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.010764095932245255, 'loss_2': 0.0012655258178710938, 'loss_3': -16.18549346923828, 'loss_4': 1.4850854873657227, 'epoch': 16.99}
{'loss': 0.0035, 'grad_norm': 7.206949710845947, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.0021741462405771017, 'loss_2': 0.0013332366943359375, 'loss_3': -16.496511459350586, 'loss_4': 1.6003862619400024, 'epoch': 17.0}
{'loss': 0.0226, 'grad_norm': 5.789424419403076, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.015701791271567345, 'loss_2': 0.00685882568359375, 'loss_3': -16.523197174072266, 'loss_4': 0.6500600576400757, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 10:38:45,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:45,721 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:12<38:04,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:38:53,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008459564298391342, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.464, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006082441657781601, 'eval_loss_2': 0.002377122640609741, 'eval_loss_3': -18.216283798217773, 'eval_loss_4': 0.9176496863365173, 'epoch': 17.01}
{'loss': 0.0145, 'grad_norm': 6.175817489624023, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.01375478133559227, 'loss_2': 0.0007710456848144531, 'loss_3': -16.496572494506836, 'loss_4': 1.407898187637329, 'epoch': 17.01}
{'loss': 0.0103, 'grad_norm': 5.006352424621582, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.008805549703538418, 'loss_2': 0.0015020370483398438, 'loss_3': -16.3555850982666, 'loss_4': 0.5467593669891357, 'epoch': 17.02}
{'loss': 0.0296, 'grad_norm': 9.365300178527832, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.02047090418636799, 'loss_2': 0.00914764404296875, 'loss_3': -16.129146575927734, 'loss_4': 0.7057410478591919, 'epoch': 17.02}
{'loss': 0.0113, 'grad_norm': 5.0377068519592285, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.007916165515780449, 'loss_2': 0.003360748291015625, 'loss_3': -16.626705169677734, 'loss_4': 0.8007848262786865, 'epoch': 17.03}
{'loss': 0.0293, 'grad_norm': 20.51443862915039, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.027341045439243317, 'loss_2': 0.001995086669921875, 'loss_3': -16.207170486450195, 'loss_4': 0.6927189826965332, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 10:38:53,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:53,043 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:20<38:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:39:00,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008534954860806465, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.595, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006442750338464975, 'eval_loss_2': 0.002092204988002777, 'eval_loss_3': -18.237865447998047, 'eval_loss_4': 0.9531136751174927, 'epoch': 17.03}
{'loss': 0.0074, 'grad_norm': 4.683751106262207, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.005942479241639376, 'loss_2': 0.0014276504516601562, 'loss_3': -16.507312774658203, 'loss_4': 1.0543596744537354, 'epoch': 17.04}
{'loss': 0.0141, 'grad_norm': 5.443858623504639, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.009340931661427021, 'loss_2': 0.004791259765625, 'loss_3': -16.271045684814453, 'loss_4': 1.3568239212036133, 'epoch': 17.05}
{'loss': 0.0222, 'grad_norm': 7.76568603515625, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.019750231876969337, 'loss_2': 0.002475738525390625, 'loss_3': -16.22733497619629, 'loss_4': 1.373110055923462, 'epoch': 17.05}
{'loss': 0.0145, 'grad_norm': 7.018959999084473, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.009648050181567669, 'loss_2': 0.00489044189453125, 'loss_3': -16.458778381347656, 'loss_4': 1.2423957586288452, 'epoch': 17.06}
{'loss': 0.0398, 'grad_norm': 15.919411659240723, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.03861360624432564, 'loss_2': 0.0011987686157226562, 'loss_3': -16.42363739013672, 'loss_4': 1.4286491870880127, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 10:39:00,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:00,361 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:27<38:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:07,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009101079776883125, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.771, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0066793556325137615, 'eval_loss_2': 0.0024217255413532257, 'eval_loss_3': -18.23076057434082, 'eval_loss_4': 1.0454533100128174, 'epoch': 17.06}
{'loss': 0.0088, 'grad_norm': 5.022114276885986, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.00875578261911869, 'loss_2': 1.2874603271484375e-05, 'loss_3': -16.30148696899414, 'loss_4': 1.2836685180664062, 'epoch': 17.07}
{'loss': 0.012, 'grad_norm': 4.947141170501709, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.007497294805943966, 'loss_2': 0.004482269287109375, 'loss_3': -16.57989501953125, 'loss_4': 1.399653434753418, 'epoch': 17.08}
{'loss': 0.0213, 'grad_norm': 7.111181735992432, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.016018161550164223, 'loss_2': 0.0052642822265625, 'loss_3': -16.362083435058594, 'loss_4': 1.2909858226776123, 'epoch': 17.08}
{'loss': 0.0085, 'grad_norm': 5.293634414672852, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.006646249908953905, 'loss_2': 0.0018978118896484375, 'loss_3': -16.48324966430664, 'loss_4': 1.300244688987732, 'epoch': 17.09}
{'loss': 0.0085, 'grad_norm': 4.956449508666992, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.008262748830020428, 'loss_2': 0.00020325183868408203, 'loss_3': -16.393918991088867, 'loss_4': 1.1546236276626587, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 10:39:07,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:07,704 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:34<38:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:15,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00962954293936491, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.1, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00678617786616087, 'eval_loss_2': 0.0028433650732040405, 'eval_loss_3': -18.239246368408203, 'eval_loss_4': 1.0657199621200562, 'epoch': 17.09}
{'loss': 0.0103, 'grad_norm': 6.226639270782471, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.007240744307637215, 'loss_2': 0.0030364990234375, 'loss_3': -16.400165557861328, 'loss_4': 1.382152795791626, 'epoch': 17.1}
{'loss': 0.0176, 'grad_norm': 8.414961814880371, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.01536901667714119, 'loss_2': 0.00218963623046875, 'loss_3': -16.450843811035156, 'loss_4': 1.474897861480713, 'epoch': 17.1}
{'loss': 0.0143, 'grad_norm': 8.994396209716797, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.010653254576027393, 'loss_2': 0.003662109375, 'loss_3': -16.406038284301758, 'loss_4': 1.3223718404769897, 'epoch': 17.11}
{'loss': 0.0278, 'grad_norm': 9.376182556152344, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.02403770573437214, 'loss_2': 0.0037994384765625, 'loss_3': -16.433277130126953, 'loss_4': 0.8622716069221497, 'epoch': 17.12}
{'loss': 0.0265, 'grad_norm': 7.613251686096191, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.026114339008927345, 'loss_2': 0.0004143714904785156, 'loss_3': -16.39665985107422, 'loss_4': 1.5852718353271484, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 10:39:15,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:15,043 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:42<38:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:22,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011743983253836632, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.411, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.007005204912275076, 'eval_loss_2': 0.0047387778759002686, 'eval_loss_3': -18.23589324951172, 'eval_loss_4': 1.2634024620056152, 'epoch': 17.12}
{'loss': 0.015, 'grad_norm': 5.805997848510742, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.011927708983421326, 'loss_2': 0.0030422210693359375, 'loss_3': -16.43132972717285, 'loss_4': 1.8686668872833252, 'epoch': 17.13}
{'loss': 0.0255, 'grad_norm': 13.523343086242676, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.02496367134153843, 'loss_2': 0.0005283355712890625, 'loss_3': -16.500879287719727, 'loss_4': 1.568697452545166, 'epoch': 17.13}
{'loss': 0.0113, 'grad_norm': 5.384334087371826, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.008910094387829304, 'loss_2': 0.00240325927734375, 'loss_3': -16.422426223754883, 'loss_4': 1.8581500053405762, 'epoch': 17.14}
{'loss': 0.0051, 'grad_norm': 5.251489639282227, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.004714834038168192, 'loss_2': 0.0003905296325683594, 'loss_3': -16.444936752319336, 'loss_4': 1.7086036205291748, 'epoch': 17.15}
{'loss': 0.0245, 'grad_norm': 10.639394760131836, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.022678349167108536, 'loss_2': 0.0018215179443359375, 'loss_3': -16.349552154541016, 'loss_4': 1.3278213739395142, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 10:39:22,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:22,375 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:12:49<38:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:29,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010383440181612968, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.972, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00729001872241497, 'eval_loss_2': 0.003093421459197998, 'eval_loss_3': -18.23211097717285, 'eval_loss_4': 1.3228721618652344, 'epoch': 17.15}
{'loss': 0.011, 'grad_norm': 4.860696792602539, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.007005454506725073, 'loss_2': 0.00397491455078125, 'loss_3': -16.271587371826172, 'loss_4': 1.711766004562378, 'epoch': 17.16}
{'loss': 0.0108, 'grad_norm': 5.7524638175964355, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.010596907697618008, 'loss_2': 0.00022339820861816406, 'loss_3': -16.41604995727539, 'loss_4': 1.4022140502929688, 'epoch': 17.16}
{'loss': 0.0141, 'grad_norm': 8.022767066955566, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.011743729934096336, 'loss_2': 0.00240325927734375, 'loss_3': -16.5140380859375, 'loss_4': 1.1675785779953003, 'epoch': 17.17}
{'loss': 0.0144, 'grad_norm': 8.416436195373535, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.012105457484722137, 'loss_2': 0.0023345947265625, 'loss_3': -16.40784454345703, 'loss_4': 1.6893333196640015, 'epoch': 17.17}
{'loss': 0.0098, 'grad_norm': 4.539956569671631, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.005287261214107275, 'loss_2': 0.00449371337890625, 'loss_3': -16.416866302490234, 'loss_4': 1.4199739694595337, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 10:39:29,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:29,714 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:12:56<37:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:37,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013920165598392487, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.432, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0072959428653120995, 'eval_loss_2': 0.0066242218017578125, 'eval_loss_3': -18.238645553588867, 'eval_loss_4': 1.1698718070983887, 'epoch': 17.18}
{'loss': 0.0142, 'grad_norm': 4.674384117126465, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.004581067711114883, 'loss_2': 0.0096282958984375, 'loss_3': -16.348533630371094, 'loss_4': 1.3100988864898682, 'epoch': 17.19}
{'loss': 0.015, 'grad_norm': 5.291766166687012, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.007167006842792034, 'loss_2': 0.007785797119140625, 'loss_3': -16.36031723022461, 'loss_4': 1.9314985275268555, 'epoch': 17.19}
{'loss': 0.0171, 'grad_norm': 7.061288833618164, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.013280355371534824, 'loss_2': 0.00379180908203125, 'loss_3': -16.063133239746094, 'loss_4': 1.9452590942382812, 'epoch': 17.2}
{'loss': 0.0109, 'grad_norm': 4.7742156982421875, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.005640791263431311, 'loss_2': 0.005275726318359375, 'loss_3': -16.25094223022461, 'loss_4': 1.2872885465621948, 'epoch': 17.2}
{'loss': 0.0063, 'grad_norm': 4.964252471923828, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.005503782536834478, 'loss_2': 0.0007772445678710938, 'loss_3': -16.252811431884766, 'loss_4': 0.7558015584945679, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 10:39:37,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:37,039 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:04<37:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:44,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015418462455272675, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.181, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.00694482633844018, 'eval_loss_2': 0.008473634719848633, 'eval_loss_3': -18.240434646606445, 'eval_loss_4': 0.9968288540840149, 'epoch': 17.21}
{'loss': 0.0213, 'grad_norm': 11.64173412322998, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.016518915072083473, 'loss_2': 0.00482177734375, 'loss_3': -16.30290985107422, 'loss_4': 1.096110463142395, 'epoch': 17.22}
{'loss': 0.0219, 'grad_norm': 7.471545696258545, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.015574119053781033, 'loss_2': 0.00632476806640625, 'loss_3': -16.377811431884766, 'loss_4': 1.169328212738037, 'epoch': 17.22}
{'loss': 0.0162, 'grad_norm': 4.533796787261963, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.003954406827688217, 'loss_2': 0.0122528076171875, 'loss_3': -16.539918899536133, 'loss_4': 1.4622082710266113, 'epoch': 17.23}
{'loss': 0.0163, 'grad_norm': 5.163393020629883, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.008517872542142868, 'loss_2': 0.00778961181640625, 'loss_3': -16.348596572875977, 'loss_4': 1.0218216180801392, 'epoch': 17.23}
{'loss': 0.0214, 'grad_norm': 7.1100029945373535, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.012963145971298218, 'loss_2': 0.00843048095703125, 'loss_3': -16.434024810791016, 'loss_4': 1.205676555633545, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 10:39:44,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:44,372 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:11<37:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:51,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013339831493794918, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00717289699241519, 'eval_loss_2': 0.006166934967041016, 'eval_loss_3': -18.255298614501953, 'eval_loss_4': 0.9593478441238403, 'epoch': 17.24}
{'loss': 0.0188, 'grad_norm': 5.529010772705078, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.010662714019417763, 'loss_2': 0.008148193359375, 'loss_3': -16.39483642578125, 'loss_4': 0.6820366382598877, 'epoch': 17.24}
{'loss': 0.0159, 'grad_norm': 4.656830310821533, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.0069868965074419975, 'loss_2': 0.0089111328125, 'loss_3': -16.328920364379883, 'loss_4': 1.3712518215179443, 'epoch': 17.25}
{'loss': 0.0135, 'grad_norm': 5.2370710372924805, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.012711120769381523, 'loss_2': 0.0008039474487304688, 'loss_3': -16.259254455566406, 'loss_4': 1.2315633296966553, 'epoch': 17.26}
{'loss': 0.0115, 'grad_norm': 6.70975923538208, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.008536168374121189, 'loss_2': 0.002971649169921875, 'loss_3': -16.289770126342773, 'loss_4': 0.878419041633606, 'epoch': 17.26}
{'loss': 0.0167, 'grad_norm': 6.109172821044922, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.012068744748830795, 'loss_2': 0.004619598388671875, 'loss_3': -16.471397399902344, 'loss_4': 1.3771799802780151, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 10:39:51,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:51,716 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:18<37:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:59,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009281190112233162, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.16, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007460193708539009, 'eval_loss_2': 0.0018209964036941528, 'eval_loss_3': -18.259302139282227, 'eval_loss_4': 0.9988364577293396, 'epoch': 17.27}
{'loss': 0.008, 'grad_norm': 5.1577582359313965, 'learning_rate': 1.275e-05, 'loss_1': 0.007547251880168915, 'loss_2': 0.0005016326904296875, 'loss_3': -16.30022430419922, 'loss_4': 1.3718554973602295, 'epoch': 17.27}
{'loss': 0.0436, 'grad_norm': 17.058900833129883, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.03836531937122345, 'loss_2': 0.00524139404296875, 'loss_3': -16.327579498291016, 'loss_4': 0.8373072147369385, 'epoch': 17.28}
{'loss': 0.0211, 'grad_norm': 5.918281555175781, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.017455866560339928, 'loss_2': 0.003631591796875, 'loss_3': -16.33352279663086, 'loss_4': 1.1710617542266846, 'epoch': 17.28}
{'loss': 0.0283, 'grad_norm': 6.416862964630127, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.012833815068006516, 'loss_2': 0.0155029296875, 'loss_3': -16.080228805541992, 'loss_4': 0.8414777517318726, 'epoch': 17.29}
{'loss': 0.017, 'grad_norm': 4.992485046386719, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.0051125455647706985, 'loss_2': 0.0118408203125, 'loss_3': -16.251953125, 'loss_4': 1.2102947235107422, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 10:39:59,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:59,051 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:26<37:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:06,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009967791847884655, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006909404415637255, 'eval_loss_2': 0.003058388829231262, 'eval_loss_3': -18.24818992614746, 'eval_loss_4': 0.9538631439208984, 'epoch': 17.3}
{'loss': 0.011, 'grad_norm': 7.188200950622559, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.010408482514321804, 'loss_2': 0.0006303787231445312, 'loss_3': -16.298078536987305, 'loss_4': 0.7027586102485657, 'epoch': 17.3}
{'loss': 0.0095, 'grad_norm': 5.832263946533203, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.00829098280519247, 'loss_2': 0.001209259033203125, 'loss_3': -16.234506607055664, 'loss_4': 1.1117373704910278, 'epoch': 17.31}
{'loss': 0.0088, 'grad_norm': 5.167757987976074, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.005425700452178717, 'loss_2': 0.003414154052734375, 'loss_3': -16.467269897460938, 'loss_4': 1.02550208568573, 'epoch': 17.31}
{'loss': 0.0294, 'grad_norm': 11.065113067626953, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.02047438733279705, 'loss_2': 0.00891876220703125, 'loss_3': -16.451210021972656, 'loss_4': 0.7881917953491211, 'epoch': 17.32}
{'loss': 0.017, 'grad_norm': 7.08999490737915, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.016105977818369865, 'loss_2': 0.0008726119995117188, 'loss_3': -16.15987777709961, 'loss_4': 1.2031803131103516, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 10:40:06,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:06,386 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:33<37:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:13,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0096898153424263, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.895, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007623366080224514, 'eval_loss_2': 0.0020664483308792114, 'eval_loss_3': -18.244443893432617, 'eval_loss_4': 0.8934585452079773, 'epoch': 17.33}
{'loss': 0.0362, 'grad_norm': 13.642087936401367, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.0330548919737339, 'loss_2': 0.0031414031982421875, 'loss_3': -16.307872772216797, 'loss_4': 1.0442626476287842, 'epoch': 17.33}
{'loss': 0.0084, 'grad_norm': 4.958876609802246, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.004258410539478064, 'loss_2': 0.00414276123046875, 'loss_3': -16.38544273376465, 'loss_4': 0.6773850321769714, 'epoch': 17.34}
{'loss': 0.0066, 'grad_norm': 4.526769161224365, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.003119908506050706, 'loss_2': 0.0034618377685546875, 'loss_3': -16.41210174560547, 'loss_4': 0.6766278743743896, 'epoch': 17.34}
{'loss': 0.026, 'grad_norm': 8.583999633789062, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.02493566833436489, 'loss_2': 0.0010967254638671875, 'loss_3': -16.247055053710938, 'loss_4': 1.1126974821090698, 'epoch': 17.35}
{'loss': 0.0128, 'grad_norm': 4.6644110679626465, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.008966168388724327, 'loss_2': 0.003879547119140625, 'loss_3': -16.300918579101562, 'loss_4': 1.082824468612671, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 10:40:13,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:13,723 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:40<37:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:21,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009412421844899654, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.663, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.007264277897775173, 'eval_loss_2': 0.002148143947124481, 'eval_loss_3': -18.217023849487305, 'eval_loss_4': 0.8694008588790894, 'epoch': 17.35}
{'loss': 0.0109, 'grad_norm': 6.5125041007995605, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.010353685356676579, 'loss_2': 0.0005321502685546875, 'loss_3': -16.34801483154297, 'loss_4': 1.2615536451339722, 'epoch': 17.36}
{'loss': 0.0075, 'grad_norm': 4.677098274230957, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.005849151872098446, 'loss_2': 0.0016880035400390625, 'loss_3': -16.186140060424805, 'loss_4': 1.3793201446533203, 'epoch': 17.37}
{'loss': 0.0138, 'grad_norm': 4.915114402770996, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.006445590872317553, 'loss_2': 0.007354736328125, 'loss_3': -16.343746185302734, 'loss_4': 0.8218038082122803, 'epoch': 17.37}
{'loss': 0.0107, 'grad_norm': 5.837007522583008, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.007500980980694294, 'loss_2': 0.0032291412353515625, 'loss_3': -16.290477752685547, 'loss_4': 0.8879737854003906, 'epoch': 17.38}
{'loss': 0.0072, 'grad_norm': 5.075754165649414, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.006935241632163525, 'loss_2': 0.00027751922607421875, 'loss_3': -16.346691131591797, 'loss_4': 1.0227453708648682, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 10:40:21,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:21,041 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:13:48<37:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:28,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010406022891402245, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007400637026876211, 'eval_loss_2': 0.003005385398864746, 'eval_loss_3': -18.199689865112305, 'eval_loss_4': 0.898780882358551, 'epoch': 17.38}
{'loss': 0.014, 'grad_norm': 8.644617080688477, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.011333633214235306, 'loss_2': 0.002658843994140625, 'loss_3': -16.18537139892578, 'loss_4': 1.3536282777786255, 'epoch': 17.39}
{'loss': 0.0144, 'grad_norm': 6.115672588348389, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.009770553559064865, 'loss_2': 0.004604339599609375, 'loss_3': -16.19056510925293, 'loss_4': 0.8785262107849121, 'epoch': 17.4}
{'loss': 0.0064, 'grad_norm': 4.460963249206543, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.004415491130203009, 'loss_2': 0.0019512176513671875, 'loss_3': -16.257898330688477, 'loss_4': 1.3428888320922852, 'epoch': 17.4}
{'loss': 0.0232, 'grad_norm': 6.731141567230225, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.018013328313827515, 'loss_2': 0.00521087646484375, 'loss_3': -16.201133728027344, 'loss_4': 1.2555992603302002, 'epoch': 17.41}
{'loss': 0.007, 'grad_norm': 4.834544658660889, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.0066072940826416016, 'loss_2': 0.0004322528839111328, 'loss_3': -16.216960906982422, 'loss_4': 1.0162550210952759, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 10:40:28,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:28,390 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:13:55<37:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:35,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010366499423980713, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007718996144831181, 'eval_loss_2': 0.002647504210472107, 'eval_loss_3': -18.15667152404785, 'eval_loss_4': 0.9485610723495483, 'epoch': 17.41}
{'loss': 0.0135, 'grad_norm': 5.687710285186768, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.007447782438248396, 'loss_2': 0.00608062744140625, 'loss_3': -16.186798095703125, 'loss_4': 1.0588213205337524, 'epoch': 17.42}
{'loss': 0.0122, 'grad_norm': 4.661076068878174, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.007547983434051275, 'loss_2': 0.004680633544921875, 'loss_3': -16.293045043945312, 'loss_4': 1.0100579261779785, 'epoch': 17.42}
{'loss': 0.0168, 'grad_norm': 5.221225261688232, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.007345225661993027, 'loss_2': 0.009490966796875, 'loss_3': -16.371122360229492, 'loss_4': 0.9749724268913269, 'epoch': 17.43}
{'loss': 0.024, 'grad_norm': 12.486227035522461, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.015332535840570927, 'loss_2': 0.00862884521484375, 'loss_3': -16.4464168548584, 'loss_4': 1.1494998931884766, 'epoch': 17.44}
{'loss': 0.0108, 'grad_norm': 5.358188152313232, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.00637660501524806, 'loss_2': 0.004390716552734375, 'loss_3': -16.21360206604004, 'loss_4': 0.9711599349975586, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 10:40:35,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:35,713 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:02<37:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:43,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009856174699962139, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.361, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006876329425722361, 'eval_loss_2': 0.002979844808578491, 'eval_loss_3': -18.157703399658203, 'eval_loss_4': 0.8257361650466919, 'epoch': 17.44}
{'loss': 0.0119, 'grad_norm': 4.282452583312988, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.004415959119796753, 'loss_2': 0.007434844970703125, 'loss_3': -16.329368591308594, 'loss_4': 0.9887785911560059, 'epoch': 17.45}
{'loss': 0.0083, 'grad_norm': 4.8579421043396, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.007298157084733248, 'loss_2': 0.0010385513305664062, 'loss_3': -16.322315216064453, 'loss_4': 0.7370932102203369, 'epoch': 17.45}
{'loss': 0.0225, 'grad_norm': 11.483149528503418, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.019325196743011475, 'loss_2': 0.003131866455078125, 'loss_3': -16.464927673339844, 'loss_4': 0.43100401759147644, 'epoch': 17.46}
{'loss': 0.0126, 'grad_norm': 4.7495551109313965, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.008233826607465744, 'loss_2': 0.00437164306640625, 'loss_3': -16.392126083374023, 'loss_4': 1.2012825012207031, 'epoch': 17.47}
{'loss': 0.011, 'grad_norm': 5.156557083129883, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.007498627994209528, 'loss_2': 0.003528594970703125, 'loss_3': -16.296802520751953, 'loss_4': 0.6569402813911438, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 10:40:43,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:43,040 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:10<37:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:50,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01150941289961338, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0075757307931780815, 'eval_loss_2': 0.0039336830377578735, 'eval_loss_3': -18.19013214111328, 'eval_loss_4': 0.6098342537879944, 'epoch': 17.47}
{'loss': 0.0167, 'grad_norm': 7.684144020080566, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.015873564407229424, 'loss_2': 0.0008106231689453125, 'loss_3': -16.295936584472656, 'loss_4': 0.6754591464996338, 'epoch': 17.48}
{'loss': 0.0091, 'grad_norm': 5.123631954193115, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.007743012625724077, 'loss_2': 0.0013446807861328125, 'loss_3': -16.387466430664062, 'loss_4': 0.6219912767410278, 'epoch': 17.48}
{'loss': 0.0114, 'grad_norm': 5.822227954864502, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.0073394193314015865, 'loss_2': 0.00406646728515625, 'loss_3': -16.331235885620117, 'loss_4': 0.28672224283218384, 'epoch': 17.49}
{'loss': 0.0161, 'grad_norm': 5.7051005363464355, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.011888427659869194, 'loss_2': 0.00417327880859375, 'loss_3': -16.29323959350586, 'loss_4': 0.6390104293823242, 'epoch': 17.49}
{'loss': 0.0181, 'grad_norm': 6.183196067810059, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.017273766919970512, 'loss_2': 0.000820159912109375, 'loss_3': -16.427730560302734, 'loss_4': 0.35122838616371155, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 10:40:50,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:50,366 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:17<36:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:57,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011243954300880432, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.00680823577567935, 'eval_loss_2': 0.004435718059539795, 'eval_loss_3': -18.174915313720703, 'eval_loss_4': 0.5667933821678162, 'epoch': 17.5}
{'loss': 0.0197, 'grad_norm': 5.581930160522461, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.012000144459307194, 'loss_2': 0.0077362060546875, 'loss_3': -16.273284912109375, 'loss_4': 0.8308441638946533, 'epoch': 17.51}
{'loss': 0.0172, 'grad_norm': 5.551939487457275, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.012138876132667065, 'loss_2': 0.005031585693359375, 'loss_3': -16.425369262695312, 'loss_4': 0.6709436178207397, 'epoch': 17.51}
{'loss': 0.0243, 'grad_norm': 5.7496018409729, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.02333705499768257, 'loss_2': 0.0009555816650390625, 'loss_3': -16.240211486816406, 'loss_4': 1.268398404121399, 'epoch': 17.52}
{'loss': 0.0092, 'grad_norm': 5.154078006744385, 'learning_rate': 1.25e-05, 'loss_1': 0.006717087235301733, 'loss_2': 0.0024776458740234375, 'loss_3': -16.40342903137207, 'loss_4': 0.3410924971103668, 'epoch': 17.52}
{'loss': 0.0107, 'grad_norm': 4.67672872543335, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.007408346980810165, 'loss_2': 0.0032978057861328125, 'loss_3': -16.267011642456055, 'loss_4': 1.04703950881958, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 10:40:57,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:57,691 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:24<36:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:05,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00889483280479908, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.373, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0060823289677500725, 'eval_loss_2': 0.002812504768371582, 'eval_loss_3': -18.1852970123291, 'eval_loss_4': 0.48497867584228516, 'epoch': 17.53}
{'loss': 0.0091, 'grad_norm': 5.550499439239502, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.008723998442292213, 'loss_2': 0.0003924369812011719, 'loss_3': -16.21592140197754, 'loss_4': 0.435153603553772, 'epoch': 17.53}
{'loss': 0.0076, 'grad_norm': 5.65703821182251, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.006984126754105091, 'loss_2': 0.00066375732421875, 'loss_3': -16.481307983398438, 'loss_4': 0.4784354567527771, 'epoch': 17.54}
{'loss': 0.0182, 'grad_norm': 6.343183994293213, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.013396124355494976, 'loss_2': 0.0047760009765625, 'loss_3': -16.4097957611084, 'loss_4': 0.3346697688102722, 'epoch': 17.55}
{'loss': 0.0164, 'grad_norm': 5.856362342834473, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.008549296297132969, 'loss_2': 0.0078125, 'loss_3': -16.421178817749023, 'loss_4': 0.8166966438293457, 'epoch': 17.55}
{'loss': 0.0091, 'grad_norm': 5.00401496887207, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.005339954048395157, 'loss_2': 0.003780364990234375, 'loss_3': -16.29494285583496, 'loss_4': 0.5042627453804016, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 10:41:05,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:05,018 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:32<36:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:12,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008904748596251011, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0059715211391448975, 'eval_loss_2': 0.002933226525783539, 'eval_loss_3': -18.20100975036621, 'eval_loss_4': 0.40466004610061646, 'epoch': 17.56}
{'loss': 0.015, 'grad_norm': 6.040227890014648, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.013096910901367664, 'loss_2': 0.001911163330078125, 'loss_3': -16.3143310546875, 'loss_4': 0.17755766212940216, 'epoch': 17.56}
{'loss': 0.0088, 'grad_norm': 4.973154067993164, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.006270654033869505, 'loss_2': 0.0025787353515625, 'loss_3': -16.253063201904297, 'loss_4': 0.6404653787612915, 'epoch': 17.57}
{'loss': 0.0136, 'grad_norm': 7.7141523361206055, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.012488052248954773, 'loss_2': 0.0011348724365234375, 'loss_3': -16.503494262695312, 'loss_4': 0.36601123213768005, 'epoch': 17.58}
{'loss': 0.019, 'grad_norm': 8.40377426147461, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.012360628694295883, 'loss_2': 0.0066680908203125, 'loss_3': -16.402185440063477, 'loss_4': 0.451250284910202, 'epoch': 17.58}
{'loss': 0.0133, 'grad_norm': 7.995824813842773, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.011858669109642506, 'loss_2': 0.0014362335205078125, 'loss_3': -16.422565460205078, 'loss_4': 0.9025734663009644, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 10:41:12,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:12,365 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:39<36:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:19,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011404341086745262, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.262, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00629778765141964, 'eval_loss_2': 0.0051065534353256226, 'eval_loss_3': -18.20209503173828, 'eval_loss_4': 0.5129897594451904, 'epoch': 17.59}
{'loss': 0.0128, 'grad_norm': 5.541852951049805, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.008517703041434288, 'loss_2': 0.00426483154296875, 'loss_3': -16.456621170043945, 'loss_4': 0.99251389503479, 'epoch': 17.59}
{'loss': 0.0258, 'grad_norm': 12.542866706848145, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.022805102169513702, 'loss_2': 0.00298309326171875, 'loss_3': -16.164459228515625, 'loss_4': 0.8497495651245117, 'epoch': 17.6}
{'loss': 0.0076, 'grad_norm': 5.715907573699951, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.0067770108580589294, 'loss_2': 0.0008411407470703125, 'loss_3': -16.383039474487305, 'loss_4': 0.9756361842155457, 'epoch': 17.6}
{'loss': 0.0101, 'grad_norm': 4.748486518859863, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.005398917477577925, 'loss_2': 0.00470733642578125, 'loss_3': -16.210159301757812, 'loss_4': 0.8056322336196899, 'epoch': 17.61}
{'loss': 0.0149, 'grad_norm': 9.773964881896973, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.013235611841082573, 'loss_2': 0.0016326904296875, 'loss_3': -16.41097068786621, 'loss_4': 1.6292123794555664, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 10:41:19,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:19,688 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:14:46<36:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:27,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01194748468697071, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.219, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0067977625876665115, 'eval_loss_2': 0.005149722099304199, 'eval_loss_3': -18.21361541748047, 'eval_loss_4': 0.602100133895874, 'epoch': 17.62}
{'loss': 0.0065, 'grad_norm': 5.139869689941406, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.005801783408969641, 'loss_2': 0.0006856918334960938, 'loss_3': -16.370830535888672, 'loss_4': 0.7277640104293823, 'epoch': 17.62}
{'loss': 0.0108, 'grad_norm': 5.744156360626221, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.006625772919505835, 'loss_2': 0.004184722900390625, 'loss_3': -16.293739318847656, 'loss_4': 0.9276248812675476, 'epoch': 17.63}
{'loss': 0.0093, 'grad_norm': 5.798301696777344, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.008692793548107147, 'loss_2': 0.0005755424499511719, 'loss_3': -16.353973388671875, 'loss_4': 0.9114751815795898, 'epoch': 17.63}
{'loss': 0.0068, 'grad_norm': 5.5586442947387695, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.005466682370752096, 'loss_2': 0.0013713836669921875, 'loss_3': -16.344097137451172, 'loss_4': 0.5267934203147888, 'epoch': 17.64}
{'loss': 0.0114, 'grad_norm': 9.210915565490723, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.008544507436454296, 'loss_2': 0.002902984619140625, 'loss_3': -16.389862060546875, 'loss_4': 1.0102260112762451, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 10:41:27,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:27,019 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:14:54<36:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:41:34,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010141546837985516, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.606, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006440888158977032, 'eval_loss_2': 0.003700658679008484, 'eval_loss_3': -18.223052978515625, 'eval_loss_4': 0.5777499079704285, 'epoch': 17.65}
{'loss': 0.0131, 'grad_norm': 9.253732681274414, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.00971935223788023, 'loss_2': 0.0033931732177734375, 'loss_3': -16.28362464904785, 'loss_4': 1.0327919721603394, 'epoch': 17.65}
{'loss': 0.0127, 'grad_norm': 8.254413604736328, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.007400281261652708, 'loss_2': 0.005306243896484375, 'loss_3': -16.371286392211914, 'loss_4': 0.6451204419136047, 'epoch': 17.66}
{'loss': 0.0089, 'grad_norm': 5.143157482147217, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.004537876229733229, 'loss_2': 0.004367828369140625, 'loss_3': -16.299678802490234, 'loss_4': 1.3404462337493896, 'epoch': 17.66}
{'loss': 0.0147, 'grad_norm': 6.058847904205322, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.012022466398775578, 'loss_2': 0.002655029296875, 'loss_3': -16.29238510131836, 'loss_4': 0.7330197095870972, 'epoch': 17.67}
{'loss': 0.0061, 'grad_norm': 6.000050067901611, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.005921836011111736, 'loss_2': 0.00021457672119140625, 'loss_3': -16.30145263671875, 'loss_4': 0.519748866558075, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 10:41:34,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:34,337 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:01<36:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:41,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009477898478507996, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.609, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006111427675932646, 'eval_loss_2': 0.0033664703369140625, 'eval_loss_3': -18.213197708129883, 'eval_loss_4': 0.6328314542770386, 'epoch': 17.67}
{'loss': 0.0169, 'grad_norm': 7.098206043243408, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.009471666067838669, 'loss_2': 0.00742340087890625, 'loss_3': -15.984095573425293, 'loss_4': 0.7631620168685913, 'epoch': 17.68}
{'loss': 0.0075, 'grad_norm': 5.477449893951416, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.006906415335834026, 'loss_2': 0.0005927085876464844, 'loss_3': -16.116931915283203, 'loss_4': 0.7675696611404419, 'epoch': 17.69}
{'loss': 0.0048, 'grad_norm': 5.199604511260986, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.003598649986088276, 'loss_2': 0.0012073516845703125, 'loss_3': -16.25321388244629, 'loss_4': 1.0748629570007324, 'epoch': 17.69}
{'loss': 0.0113, 'grad_norm': 7.066789150238037, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.00864114984869957, 'loss_2': 0.002689361572265625, 'loss_3': -16.25360870361328, 'loss_4': 0.8243967294692993, 'epoch': 17.7}
{'loss': 0.0137, 'grad_norm': 5.314066410064697, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.008626378141343594, 'loss_2': 0.00505828857421875, 'loss_3': -16.261959075927734, 'loss_4': 0.5104266405105591, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 10:41:41,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:41,665 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:08<36:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:48,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008860848844051361, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005699976813048124, 'eval_loss_2': 0.0031608715653419495, 'eval_loss_3': -18.212194442749023, 'eval_loss_4': 0.6796415448188782, 'epoch': 17.7}
{'loss': 0.012, 'grad_norm': 5.06899881362915, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.006836052983999252, 'loss_2': 0.005184173583984375, 'loss_3': -16.247737884521484, 'loss_4': 0.8281869888305664, 'epoch': 17.71}
{'loss': 0.0169, 'grad_norm': 7.132579326629639, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.014445369131863117, 'loss_2': 0.002498626708984375, 'loss_3': -16.30221939086914, 'loss_4': 1.0715367794036865, 'epoch': 17.72}
{'loss': 0.007, 'grad_norm': 5.252500057220459, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.0061952583491802216, 'loss_2': 0.0008115768432617188, 'loss_3': -16.294326782226562, 'loss_4': 1.1222035884857178, 'epoch': 17.72}
{'loss': 0.0075, 'grad_norm': 5.0915045738220215, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.004741954151540995, 'loss_2': 0.00278472900390625, 'loss_3': -16.24335479736328, 'loss_4': 1.0901930332183838, 'epoch': 17.73}
{'loss': 0.0062, 'grad_norm': 5.213028430938721, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.004861338064074516, 'loss_2': 0.0012969970703125, 'loss_3': -16.186120986938477, 'loss_4': 1.3587987422943115, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 10:41:48,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:48,993 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:16<36:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:41:56,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008951821364462376, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.334, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.005590119399130344, 'eval_loss_2': 0.0033617019653320312, 'eval_loss_3': -18.23857879638672, 'eval_loss_4': 0.7263098359107971, 'epoch': 17.73}
{'loss': 0.0227, 'grad_norm': 9.898388862609863, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.01891939714550972, 'loss_2': 0.0038089752197265625, 'loss_3': -16.336223602294922, 'loss_4': 0.9782867431640625, 'epoch': 17.74}
{'loss': 0.0061, 'grad_norm': 4.656957149505615, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.00398250762373209, 'loss_2': 0.00209808349609375, 'loss_3': -16.357757568359375, 'loss_4': 1.0608793497085571, 'epoch': 17.74}
{'loss': 0.009, 'grad_norm': 4.587178707122803, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.0032534890342503786, 'loss_2': 0.00577545166015625, 'loss_3': -16.202045440673828, 'loss_4': 0.549216091632843, 'epoch': 17.75}
{'loss': 0.0184, 'grad_norm': 8.380699157714844, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.0167548730969429, 'loss_2': 0.0016155242919921875, 'loss_3': -16.050689697265625, 'loss_4': 1.2413978576660156, 'epoch': 17.76}
{'loss': 0.017, 'grad_norm': 7.2515082359313965, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.011635813862085342, 'loss_2': 0.00534820556640625, 'loss_3': -16.28179168701172, 'loss_4': 0.9919135570526123, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 10:41:56,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:56,315 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:23<36:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:42:03,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008715571835637093, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.656, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005442167166620493, 'eval_loss_2': 0.003273405134677887, 'eval_loss_3': -18.241491317749023, 'eval_loss_4': 0.714400053024292, 'epoch': 17.76}
{'loss': 0.01, 'grad_norm': 5.267734050750732, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.005516816861927509, 'loss_2': 0.004486083984375, 'loss_3': -16.299724578857422, 'loss_4': 0.9774904251098633, 'epoch': 17.77}
{'loss': 0.0057, 'grad_norm': 4.414173603057861, 'learning_rate': 1.225e-05, 'loss_1': 0.00572029547765851, 'loss_2': 3.635883331298828e-06, 'loss_3': -16.487886428833008, 'loss_4': 1.1362026929855347, 'epoch': 17.77}
{'loss': 0.0076, 'grad_norm': 5.317016124725342, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.00590676162391901, 'loss_2': 0.001674652099609375, 'loss_3': -16.171432495117188, 'loss_4': 0.9352063536643982, 'epoch': 17.78}
{'loss': 0.012, 'grad_norm': 6.737318992614746, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.011842489242553711, 'loss_2': 0.0001804828643798828, 'loss_3': -16.295934677124023, 'loss_4': 1.3095240592956543, 'epoch': 17.78}
{'loss': 0.0122, 'grad_norm': 6.079566478729248, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.0087826456874609, 'loss_2': 0.003421783447265625, 'loss_3': -16.30422592163086, 'loss_4': 0.550771951675415, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 10:42:03,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:03,635 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:30<36:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:42:10,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008476262912154198, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006012813188135624, 'eval_loss_2': 0.002463448792695999, 'eval_loss_3': -18.25302505493164, 'eval_loss_4': 0.6519118547439575, 'epoch': 17.79}
{'loss': 0.0049, 'grad_norm': 5.099754333496094, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.003861539764329791, 'loss_2': 0.0010051727294921875, 'loss_3': -16.251903533935547, 'loss_4': 0.9128360748291016, 'epoch': 17.8}
{'loss': 0.0075, 'grad_norm': 5.283009052276611, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.007173867896199226, 'loss_2': 0.0003654956817626953, 'loss_3': -16.19472885131836, 'loss_4': 0.6216417551040649, 'epoch': 17.8}
{'loss': 0.0092, 'grad_norm': 4.605325222015381, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.0037548711989074945, 'loss_2': 0.005405426025390625, 'loss_3': -16.514719009399414, 'loss_4': 0.7724019289016724, 'epoch': 17.81}
{'loss': 0.0095, 'grad_norm': 5.423013687133789, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.007917575538158417, 'loss_2': 0.0016002655029296875, 'loss_3': -16.505413055419922, 'loss_4': 1.0782029628753662, 'epoch': 17.81}
{'loss': 0.0065, 'grad_norm': 4.774847984313965, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.005119694396853447, 'loss_2': 0.0013599395751953125, 'loss_3': -16.351903915405273, 'loss_4': 0.841442346572876, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 10:42:10,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:10,960 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:38<36:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:18,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01023076195269823, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.504, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005895597394555807, 'eval_loss_2': 0.004335165023803711, 'eval_loss_3': -18.239683151245117, 'eval_loss_4': 0.6418424844741821, 'epoch': 17.82}
{'loss': 0.0054, 'grad_norm': 4.826811790466309, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.004701250698417425, 'loss_2': 0.0006847381591796875, 'loss_3': -16.08627700805664, 'loss_4': 0.7789593935012817, 'epoch': 17.83}
{'loss': 0.0088, 'grad_norm': 5.072634696960449, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.004712010268121958, 'loss_2': 0.00411224365234375, 'loss_3': -16.172597885131836, 'loss_4': 0.9866442680358887, 'epoch': 17.83}
{'loss': 0.0122, 'grad_norm': 17.028430938720703, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.011074981652200222, 'loss_2': 0.0011358261108398438, 'loss_3': -16.143070220947266, 'loss_4': 1.3028267621994019, 'epoch': 17.84}
{'loss': 0.0048, 'grad_norm': 4.7586188316345215, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.004641517531126738, 'loss_2': 0.00016295909881591797, 'loss_3': -16.130229949951172, 'loss_4': 0.942664623260498, 'epoch': 17.84}
{'loss': 0.0061, 'grad_norm': 5.014342308044434, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.004474664572626352, 'loss_2': 0.0016603469848632812, 'loss_3': -16.184593200683594, 'loss_4': 0.33183902502059937, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 10:42:18,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:18,283 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:15:45<35:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:42:25,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01003580167889595, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.551, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007087107747793198, 'eval_loss_2': 0.0029486939311027527, 'eval_loss_3': -18.249746322631836, 'eval_loss_4': 0.8435927033424377, 'epoch': 17.85}
{'loss': 0.0066, 'grad_norm': 4.709772109985352, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.004100122954696417, 'loss_2': 0.0024871826171875, 'loss_3': -16.392711639404297, 'loss_4': 0.8675727248191833, 'epoch': 17.85}
{'loss': 0.0028, 'grad_norm': 4.683654308319092, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.002316863974556327, 'loss_2': 0.000499725341796875, 'loss_3': -16.321426391601562, 'loss_4': 0.7378689050674438, 'epoch': 17.86}
{'loss': 0.01, 'grad_norm': 5.34704065322876, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.005798460450023413, 'loss_2': 0.004169464111328125, 'loss_3': -16.23737335205078, 'loss_4': 1.2648130655288696, 'epoch': 17.87}
{'loss': 0.0161, 'grad_norm': 6.642368793487549, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.009794359095394611, 'loss_2': 0.006328582763671875, 'loss_3': -16.305063247680664, 'loss_4': 1.862107276916504, 'epoch': 17.87}
{'loss': 0.0119, 'grad_norm': 8.486645698547363, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.006532918196171522, 'loss_2': 0.00539398193359375, 'loss_3': -16.374141693115234, 'loss_4': 1.77384614944458, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 10:42:25,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:25,604 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:15:52<35:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:32,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01291534025222063, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.11, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008464124985039234, 'eval_loss_2': 0.0044512152671813965, 'eval_loss_3': -18.24884796142578, 'eval_loss_4': 1.2271569967269897, 'epoch': 17.88}
{'loss': 0.0244, 'grad_norm': 6.992101669311523, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.010934455320239067, 'loss_2': 0.01348114013671875, 'loss_3': -16.320960998535156, 'loss_4': 1.4062830209732056, 'epoch': 17.88}
{'loss': 0.0054, 'grad_norm': 4.92070198059082, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.004165139980614185, 'loss_2': 0.0012226104736328125, 'loss_3': -16.34760093688965, 'loss_4': 2.4503581523895264, 'epoch': 17.89}
{'loss': 0.0099, 'grad_norm': 7.540583610534668, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.008317279629409313, 'loss_2': 0.0015821456909179688, 'loss_3': -16.33026123046875, 'loss_4': 2.4051926136016846, 'epoch': 17.9}
{'loss': 0.0181, 'grad_norm': 5.181740760803223, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.006652034353464842, 'loss_2': 0.0114898681640625, 'loss_3': -16.146648406982422, 'loss_4': 2.1569559574127197, 'epoch': 17.9}
{'loss': 0.0274, 'grad_norm': 5.874875545501709, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.01458237785845995, 'loss_2': 0.0128021240234375, 'loss_3': -16.213850021362305, 'loss_4': 2.332296848297119, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 10:42:32,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:32,940 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:00<35:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:40,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014253705739974976, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.426, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.009057296440005302, 'eval_loss_2': 0.005196411162614822, 'eval_loss_3': -18.252296447753906, 'eval_loss_4': 1.381522536277771, 'epoch': 17.91}
{'loss': 0.0105, 'grad_norm': 4.459178447723389, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.0037706762086600065, 'loss_2': 0.00673675537109375, 'loss_3': -16.49391746520996, 'loss_4': 1.3753948211669922, 'epoch': 17.91}
{'loss': 0.0206, 'grad_norm': 9.522720336914062, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.011078623123466969, 'loss_2': 0.0095062255859375, 'loss_3': -16.4149169921875, 'loss_4': 1.642216682434082, 'epoch': 17.92}
{'loss': 0.0187, 'grad_norm': 10.170541763305664, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.0135873481631279, 'loss_2': 0.00507354736328125, 'loss_3': -16.267261505126953, 'loss_4': 1.9481550455093384, 'epoch': 17.92}
{'loss': 0.0061, 'grad_norm': 5.508908271789551, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.0056508309207856655, 'loss_2': 0.00039958953857421875, 'loss_3': -16.4677734375, 'loss_4': 1.8694099187850952, 'epoch': 17.93}
{'loss': 0.0071, 'grad_norm': 4.788808822631836, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.003344791941344738, 'loss_2': 0.00371551513671875, 'loss_3': -16.19717788696289, 'loss_4': 1.806502342224121, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 10:42:40,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:40,269 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:07<35:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:47,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01208308432251215, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.35, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008754285052418709, 'eval_loss_2': 0.0033288002014160156, 'eval_loss_3': -18.26795196533203, 'eval_loss_4': 1.447619080543518, 'epoch': 17.94}
{'loss': 0.0121, 'grad_norm': 7.442636013031006, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.010415748693048954, 'loss_2': 0.0016469955444335938, 'loss_3': -16.317712783813477, 'loss_4': 1.5155770778656006, 'epoch': 17.94}
{'loss': 0.01, 'grad_norm': 5.670046806335449, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.009828045964241028, 'loss_2': 0.00017499923706054688, 'loss_3': -16.30213165283203, 'loss_4': 1.6164839267730713, 'epoch': 17.95}
{'loss': 0.0069, 'grad_norm': 4.514483451843262, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.0034843492321670055, 'loss_2': 0.0034580230712890625, 'loss_3': -16.289554595947266, 'loss_4': 1.5985820293426514, 'epoch': 17.95}
{'loss': 0.0224, 'grad_norm': 9.884453773498535, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.01955156959593296, 'loss_2': 0.0028781890869140625, 'loss_3': -16.19036293029785, 'loss_4': 1.6706969738006592, 'epoch': 17.96}
{'loss': 0.0088, 'grad_norm': 5.014050006866455, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.006989817135035992, 'loss_2': 0.0018596649169921875, 'loss_3': -16.457454681396484, 'loss_4': 1.5241572856903076, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 10:42:47,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:47,597 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:14<35:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:55,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012544378638267517, 'eval_runtime': 3.9825, 'eval_samples_per_second': 257.125, 'eval_steps_per_second': 4.018, 'eval_loss_1': 0.008670704439282417, 'eval_loss_2': 0.003873676061630249, 'eval_loss_3': -18.263378143310547, 'eval_loss_4': 1.5546795129776, 'epoch': 17.97}
{'loss': 0.0148, 'grad_norm': 6.7594146728515625, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.012272195890545845, 'loss_2': 0.0025482177734375, 'loss_3': -16.269886016845703, 'loss_4': 1.9282994270324707, 'epoch': 17.97}
{'loss': 0.0137, 'grad_norm': 4.511868953704834, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.004186732228845358, 'loss_2': 0.009521484375, 'loss_3': -16.455820083618164, 'loss_4': 1.9470912218093872, 'epoch': 17.98}
{'loss': 0.0217, 'grad_norm': 5.571474075317383, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.01846250705420971, 'loss_2': 0.0032291412353515625, 'loss_3': -16.25497055053711, 'loss_4': 2.157942771911621, 'epoch': 17.98}
{'loss': 0.0068, 'grad_norm': 4.559185981750488, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.00455591781064868, 'loss_2': 0.002246856689453125, 'loss_3': -16.337242126464844, 'loss_4': 1.4621801376342773, 'epoch': 17.99}
{'loss': 0.0079, 'grad_norm': 4.609004497528076, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.005236791446805, 'loss_2': 0.002685546875, 'loss_3': -16.62062644958496, 'loss_4': 2.0371298789978027, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 10:42:55,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:55,107 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:21<34:56,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:43:02,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012232791632413864, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.891, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007981304079294205, 'eval_loss_2': 0.004251487553119659, 'eval_loss_3': -18.24486541748047, 'eval_loss_4': 1.5567536354064941, 'epoch': 17.99}
{'loss': 0.0037, 'grad_norm': 5.894953727722168, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.002749457722529769, 'loss_2': 0.0009746551513671875, 'loss_3': -16.09001350402832, 'loss_4': 1.3044250011444092, 'epoch': 18.0}
{'loss': 0.0234, 'grad_norm': 13.463178634643555, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.020536039024591446, 'loss_2': 0.00287628173828125, 'loss_3': -16.476680755615234, 'loss_4': 1.5692481994628906, 'epoch': 18.01}
{'loss': 0.0119, 'grad_norm': 4.630826473236084, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.004721755161881447, 'loss_2': 0.00722503662109375, 'loss_3': -16.31739044189453, 'loss_4': 1.9486137628555298, 'epoch': 18.01}
{'loss': 0.0065, 'grad_norm': 4.954756736755371, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.0057639991864562035, 'loss_2': 0.0007266998291015625, 'loss_3': -16.176912307739258, 'loss_4': 2.030120849609375, 'epoch': 18.02}
{'loss': 0.0069, 'grad_norm': 5.154881477355957, 'learning_rate': 1.2e-05, 'loss_1': 0.0064422572031617165, 'loss_2': 0.000507354736328125, 'loss_3': -16.200960159301758, 'loss_4': 1.6829230785369873, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 10:43:02,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:02,150 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:29<35:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:43:09,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010823732241988182, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.028, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007920038886368275, 'eval_loss_2': 0.0029036924242973328, 'eval_loss_3': -18.242870330810547, 'eval_loss_4': 1.5128158330917358, 'epoch': 18.02}
{'loss': 0.0218, 'grad_norm': 11.409131050109863, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.01452882494777441, 'loss_2': 0.00722503662109375, 'loss_3': -16.3001651763916, 'loss_4': 1.2994225025177002, 'epoch': 18.03}
{'loss': 0.0082, 'grad_norm': 5.677550792694092, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.007010500878095627, 'loss_2': 0.0012359619140625, 'loss_3': -16.506540298461914, 'loss_4': 2.197144031524658, 'epoch': 18.03}
{'loss': 0.0071, 'grad_norm': 4.622812747955322, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.00459981570020318, 'loss_2': 0.002483367919921875, 'loss_3': -16.442928314208984, 'loss_4': 1.623975396156311, 'epoch': 18.04}
{'loss': 0.0243, 'grad_norm': 12.167925834655762, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.023337149992585182, 'loss_2': 0.000957489013671875, 'loss_3': -16.341949462890625, 'loss_4': 1.7718589305877686, 'epoch': 18.05}
{'loss': 0.017, 'grad_norm': 7.066939353942871, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.011680243536829948, 'loss_2': 0.0052947998046875, 'loss_3': -16.517906188964844, 'loss_4': 1.6095023155212402, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 10:43:09,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:09,483 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:36<35:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:16,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012236161157488823, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00797466654330492, 'eval_loss_2': 0.004261493682861328, 'eval_loss_3': -18.228271484375, 'eval_loss_4': 1.436569094657898, 'epoch': 18.05}
{'loss': 0.0107, 'grad_norm': 4.815917015075684, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.004705994389951229, 'loss_2': 0.006011962890625, 'loss_3': -16.332509994506836, 'loss_4': 1.6503232717514038, 'epoch': 18.06}
{'loss': 0.012, 'grad_norm': 4.670572280883789, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.003692332189530134, 'loss_2': 0.0083160400390625, 'loss_3': -16.269935607910156, 'loss_4': 1.2468717098236084, 'epoch': 18.06}
{'loss': 0.0083, 'grad_norm': 4.809964656829834, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.007736461702734232, 'loss_2': 0.0005483627319335938, 'loss_3': -16.230697631835938, 'loss_4': 1.3099042177200317, 'epoch': 18.07}
{'loss': 0.0163, 'grad_norm': 4.982785701751709, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.006879823748022318, 'loss_2': 0.00942230224609375, 'loss_3': -16.171022415161133, 'loss_4': 1.224164366722107, 'epoch': 18.08}
{'loss': 0.0239, 'grad_norm': 9.12929916381836, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.02085147425532341, 'loss_2': 0.0030879974365234375, 'loss_3': -16.27590560913086, 'loss_4': 1.8126314878463745, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 10:43:16,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:16,829 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:43<35:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:24,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010946450755000114, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.41, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.007780489511787891, 'eval_loss_2': 0.0031659603118896484, 'eval_loss_3': -18.228343963623047, 'eval_loss_4': 1.3174259662628174, 'epoch': 18.08}
{'loss': 0.0156, 'grad_norm': 6.941929340362549, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.013528774492442608, 'loss_2': 0.002048492431640625, 'loss_3': -16.364839553833008, 'loss_4': 1.860111117362976, 'epoch': 18.09}
{'loss': 0.0036, 'grad_norm': 4.508763313293457, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.0033329061698168516, 'loss_2': 0.0003151893615722656, 'loss_3': -16.43478012084961, 'loss_4': 1.3441970348358154, 'epoch': 18.09}
{'loss': 0.0108, 'grad_norm': 6.190054893493652, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.005958699621260166, 'loss_2': 0.00479888916015625, 'loss_3': -16.522422790527344, 'loss_4': 1.147524118423462, 'epoch': 18.1}
{'loss': 0.0054, 'grad_norm': 4.807743072509766, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.004064076580107212, 'loss_2': 0.0013427734375, 'loss_3': -16.469587326049805, 'loss_4': 1.4098749160766602, 'epoch': 18.1}
{'loss': 0.0179, 'grad_norm': 9.39863395690918, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.015459355898201466, 'loss_2': 0.002422332763671875, 'loss_3': -16.34276580810547, 'loss_4': 1.4787309169769287, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 10:43:24,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:24,159 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:16:51<35:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:43:31,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012147418223321438, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.366, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008638552390038967, 'eval_loss_2': 0.0035088658332824707, 'eval_loss_3': -18.24410057067871, 'eval_loss_4': 1.1933844089508057, 'epoch': 18.11}
{'loss': 0.0178, 'grad_norm': 4.99998140335083, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.007084028795361519, 'loss_2': 0.0106964111328125, 'loss_3': -16.453996658325195, 'loss_4': 1.2099533081054688, 'epoch': 18.12}
{'loss': 0.005, 'grad_norm': 5.183199405670166, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.0041492292657494545, 'loss_2': 0.000896453857421875, 'loss_3': -16.46799087524414, 'loss_4': 1.6276417970657349, 'epoch': 18.12}
{'loss': 0.0249, 'grad_norm': 10.153005599975586, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.02225739136338234, 'loss_2': 0.002685546875, 'loss_3': -16.41985321044922, 'loss_4': 1.2893855571746826, 'epoch': 18.13}
{'loss': 0.0185, 'grad_norm': 8.295031547546387, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.01541566476225853, 'loss_2': 0.00311279296875, 'loss_3': -16.250999450683594, 'loss_4': 1.5602710247039795, 'epoch': 18.13}
{'loss': 0.0127, 'grad_norm': 6.689244747161865, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.006637224927544594, 'loss_2': 0.006072998046875, 'loss_3': -16.305648803710938, 'loss_4': 1.624429702758789, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 10:43:31,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:31,481 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:16:58<35:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:38,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013338061980903149, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.21, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009403618052601814, 'eval_loss_2': 0.00393444299697876, 'eval_loss_3': -18.25090217590332, 'eval_loss_4': 1.1565510034561157, 'epoch': 18.14}
{'loss': 0.0093, 'grad_norm': 4.606726169586182, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.005350802093744278, 'loss_2': 0.00394439697265625, 'loss_3': -16.457822799682617, 'loss_4': 1.3610975742340088, 'epoch': 18.15}
{'loss': 0.0058, 'grad_norm': 5.118218421936035, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.0045241545885801315, 'loss_2': 0.001247406005859375, 'loss_3': -16.49297332763672, 'loss_4': 0.8255642652511597, 'epoch': 18.15}
{'loss': 0.0074, 'grad_norm': 4.921228885650635, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.005723702721297741, 'loss_2': 0.001636505126953125, 'loss_3': -16.29556655883789, 'loss_4': 1.4443620443344116, 'epoch': 18.16}
{'loss': 0.0078, 'grad_norm': 5.067854881286621, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.006533108651638031, 'loss_2': 0.00127410888671875, 'loss_3': -16.47342300415039, 'loss_4': 1.4636238813400269, 'epoch': 18.16}
{'loss': 0.011, 'grad_norm': 5.649347305297852, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.007665222976356745, 'loss_2': 0.003322601318359375, 'loss_3': -16.341184616088867, 'loss_4': 0.9553501009941101, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 10:43:38,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:38,815 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:05<35:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:46,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011828605085611343, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.39, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008434477262198925, 'eval_loss_2': 0.0033941268920898438, 'eval_loss_3': -18.23049545288086, 'eval_loss_4': 1.1443108320236206, 'epoch': 18.17}
{'loss': 0.0166, 'grad_norm': 6.3195929527282715, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.01162804290652275, 'loss_2': 0.0050048828125, 'loss_3': -16.284704208374023, 'loss_4': 1.2982940673828125, 'epoch': 18.17}
{'loss': 0.0306, 'grad_norm': 14.37206745147705, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.026991862803697586, 'loss_2': 0.003650665283203125, 'loss_3': -16.39892578125, 'loss_4': 1.4233556985855103, 'epoch': 18.18}
{'loss': 0.0135, 'grad_norm': 4.66778564453125, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.00286216102540493, 'loss_2': 0.01068115234375, 'loss_3': -16.50779151916504, 'loss_4': 1.220220685005188, 'epoch': 18.19}
{'loss': 0.0132, 'grad_norm': 5.773010730743408, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.010701149702072144, 'loss_2': 0.00247955322265625, 'loss_3': -16.27419662475586, 'loss_4': 1.6051578521728516, 'epoch': 18.19}
{'loss': 0.0137, 'grad_norm': 5.078143119812012, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.007237151265144348, 'loss_2': 0.0064697265625, 'loss_3': -16.3140869140625, 'loss_4': 1.0028889179229736, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 10:43:46,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:46,141 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:13<35:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:53,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011686260811984539, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.944, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008595125749707222, 'eval_loss_2': 0.0030911341309547424, 'eval_loss_3': -18.22664451599121, 'eval_loss_4': 1.0747296810150146, 'epoch': 18.2}
{'loss': 0.0129, 'grad_norm': 4.452826023101807, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.004691805690526962, 'loss_2': 0.0082244873046875, 'loss_3': -16.337448120117188, 'loss_4': 1.5249674320220947, 'epoch': 18.2}
{'loss': 0.0132, 'grad_norm': 6.124981880187988, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.007957389578223228, 'loss_2': 0.005252838134765625, 'loss_3': -16.25319480895996, 'loss_4': 1.4683210849761963, 'epoch': 18.21}
{'loss': 0.0062, 'grad_norm': 4.59450101852417, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.004676137585192919, 'loss_2': 0.0015459060668945312, 'loss_3': -16.440990447998047, 'loss_4': 0.9750193953514099, 'epoch': 18.22}
{'loss': 0.0069, 'grad_norm': 4.966629505157471, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.006480824667960405, 'loss_2': 0.00043201446533203125, 'loss_3': -16.358673095703125, 'loss_4': 1.3832578659057617, 'epoch': 18.22}
{'loss': 0.0188, 'grad_norm': 6.118350982666016, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.012841252610087395, 'loss_2': 0.0059814453125, 'loss_3': -16.21963882446289, 'loss_4': 1.1799955368041992, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 10:43:53,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:53,482 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:20<34:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:00,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012884637340903282, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.55, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.008095046505331993, 'eval_loss_2': 0.004789590835571289, 'eval_loss_3': -18.22332763671875, 'eval_loss_4': 1.1381070613861084, 'epoch': 18.23}
{'loss': 0.0127, 'grad_norm': 5.264147758483887, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.009221485815942287, 'loss_2': 0.0034351348876953125, 'loss_3': -16.47732162475586, 'loss_4': 1.7553660869598389, 'epoch': 18.23}
{'loss': 0.0137, 'grad_norm': 5.251543998718262, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.0066975378431379795, 'loss_2': 0.006992340087890625, 'loss_3': -16.326557159423828, 'loss_4': 0.9912455677986145, 'epoch': 18.24}
{'loss': 0.0063, 'grad_norm': 4.940700531005859, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.005326001439243555, 'loss_2': 0.00095367431640625, 'loss_3': -16.235273361206055, 'loss_4': 1.6616764068603516, 'epoch': 18.24}
{'loss': 0.0135, 'grad_norm': 5.4473676681518555, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.008710838854312897, 'loss_2': 0.004741668701171875, 'loss_3': -16.402299880981445, 'loss_4': 1.1597929000854492, 'epoch': 18.25}
{'loss': 0.0077, 'grad_norm': 4.498766899108887, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.0033089753706008196, 'loss_2': 0.004425048828125, 'loss_3': -16.348896026611328, 'loss_4': 1.5884407758712769, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 10:44:00,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:00,809 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:27<34:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:08,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011791897937655449, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.491, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007601602002978325, 'eval_loss_2': 0.004190295934677124, 'eval_loss_3': -18.215721130371094, 'eval_loss_4': 1.1562120914459229, 'epoch': 18.26}
{'loss': 0.006, 'grad_norm': 5.279490947723389, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.005828368943184614, 'loss_2': 0.00021207332611083984, 'loss_3': -16.204689025878906, 'loss_4': 1.3922356367111206, 'epoch': 18.26}
{'loss': 0.0094, 'grad_norm': 5.332717418670654, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.007236822042614222, 'loss_2': 0.0021457672119140625, 'loss_3': -16.360078811645508, 'loss_4': 0.8455461263656616, 'epoch': 18.27}
{'loss': 0.0159, 'grad_norm': 7.337474822998047, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.012507298029959202, 'loss_2': 0.003414154052734375, 'loss_3': -16.394798278808594, 'loss_4': 1.8316404819488525, 'epoch': 18.27}
{'loss': 0.0121, 'grad_norm': 5.752075672149658, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.00936987716704607, 'loss_2': 0.002727508544921875, 'loss_3': -16.43417739868164, 'loss_4': 1.259160041809082, 'epoch': 18.28}
{'loss': 0.0122, 'grad_norm': 4.890472412109375, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.003964582923799753, 'loss_2': 0.00821685791015625, 'loss_3': -16.215538024902344, 'loss_4': 1.0464520454406738, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 10:44:08,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:08,134 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:35<34:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:15,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010297798551619053, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.295, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007231914438307285, 'eval_loss_2': 0.0030658841133117676, 'eval_loss_3': -18.200891494750977, 'eval_loss_4': 1.0626552104949951, 'epoch': 18.28}
{'loss': 0.0124, 'grad_norm': 7.7762298583984375, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.01130653452128172, 'loss_2': 0.0010890960693359375, 'loss_3': -16.101673126220703, 'loss_4': 1.0534948110580444, 'epoch': 18.29}
{'loss': 0.0212, 'grad_norm': 5.625847339630127, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.007079397793859243, 'loss_2': 0.0141448974609375, 'loss_3': -16.324338912963867, 'loss_4': 0.8905953168869019, 'epoch': 18.3}
{'loss': 0.0109, 'grad_norm': 5.616120338439941, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.008814530447125435, 'loss_2': 0.0021228790283203125, 'loss_3': -16.200054168701172, 'loss_4': 0.6443573236465454, 'epoch': 18.3}
{'loss': 0.0193, 'grad_norm': 6.316066741943359, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.012310340069234371, 'loss_2': 0.007015228271484375, 'loss_3': -16.22433853149414, 'loss_4': 0.7669541835784912, 'epoch': 18.31}
{'loss': 0.0125, 'grad_norm': 5.098082065582275, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.007185258902609348, 'loss_2': 0.005313873291015625, 'loss_3': -16.42208480834961, 'loss_4': 1.3644541501998901, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 10:44:15,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:15,463 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:42<34:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:22,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010165748186409473, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.104, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007443633396178484, 'eval_loss_2': 0.002722114324569702, 'eval_loss_3': -18.201004028320312, 'eval_loss_4': 0.975996732711792, 'epoch': 18.31}
{'loss': 0.0072, 'grad_norm': 5.069425106048584, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.005739669315516949, 'loss_2': 0.00141143798828125, 'loss_3': -16.407859802246094, 'loss_4': 1.0265510082244873, 'epoch': 18.32}
{'loss': 0.0055, 'grad_norm': 5.031482219696045, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.004811272025108337, 'loss_2': 0.0006804466247558594, 'loss_3': -16.331308364868164, 'loss_4': 1.1168862581253052, 'epoch': 18.33}
{'loss': 0.0112, 'grad_norm': 5.692509651184082, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.009064869955182076, 'loss_2': 0.0021381378173828125, 'loss_3': -16.483642578125, 'loss_4': 1.0673425197601318, 'epoch': 18.33}
{'loss': 0.0165, 'grad_norm': 9.131258964538574, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.01351717859506607, 'loss_2': 0.003017425537109375, 'loss_3': -16.30135726928711, 'loss_4': 1.47282075881958, 'epoch': 18.34}
{'loss': 0.0102, 'grad_norm': 5.528299808502197, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.007493482902646065, 'loss_2': 0.002727508544921875, 'loss_3': -16.285045623779297, 'loss_4': 1.0353286266326904, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 10:44:22,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:22,795 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:17:49<34:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:30,126 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010355385020375252, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.098, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007437514141201973, 'eval_loss_2': 0.002917870879173279, 'eval_loss_3': -18.17595672607422, 'eval_loss_4': 0.8546414971351624, 'epoch': 18.34}
{'loss': 0.006, 'grad_norm': 5.026602268218994, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.004037133883684874, 'loss_2': 0.001964569091796875, 'loss_3': -16.198902130126953, 'loss_4': 0.5375349521636963, 'epoch': 18.35}
{'loss': 0.0097, 'grad_norm': 4.993049621582031, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.007617680821567774, 'loss_2': 0.002109527587890625, 'loss_3': -16.466840744018555, 'loss_4': 0.760329008102417, 'epoch': 18.35}
{'loss': 0.0098, 'grad_norm': 5.542545795440674, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.004393634386360645, 'loss_2': 0.00543212890625, 'loss_3': -16.273563385009766, 'loss_4': 0.6404207944869995, 'epoch': 18.36}
{'loss': 0.01, 'grad_norm': 5.294754505157471, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.008926855400204659, 'loss_2': 0.0010814666748046875, 'loss_3': -16.47531509399414, 'loss_4': 0.6589450240135193, 'epoch': 18.37}
{'loss': 0.0092, 'grad_norm': 5.019993782043457, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.00834694318473339, 'loss_2': 0.000820159912109375, 'loss_3': -16.240129470825195, 'loss_4': 0.9107652902603149, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 10:44:30,126 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:30,126 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:17:57<34:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:37,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010283286683261395, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.096, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.007221702486276627, 'eval_loss_2': 0.0030615851283073425, 'eval_loss_3': -18.202165603637695, 'eval_loss_4': 0.8164361119270325, 'epoch': 18.37}
{'loss': 0.0301, 'grad_norm': 11.042413711547852, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.021414916962385178, 'loss_2': 0.0086517333984375, 'loss_3': -16.326974868774414, 'loss_4': 0.8336648344993591, 'epoch': 18.38}
{'loss': 0.0047, 'grad_norm': 3.988757848739624, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.0033907070755958557, 'loss_2': 0.0013141632080078125, 'loss_3': -16.116924285888672, 'loss_4': 1.14444100856781, 'epoch': 18.38}
{'loss': 0.0067, 'grad_norm': 4.984570026397705, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.0035147112794220448, 'loss_2': 0.0031871795654296875, 'loss_3': -16.3897705078125, 'loss_4': 0.9984801411628723, 'epoch': 18.39}
{'loss': 0.0119, 'grad_norm': 5.178776741027832, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.00515154842287302, 'loss_2': 0.00676727294921875, 'loss_3': -16.306032180786133, 'loss_4': 1.151848554611206, 'epoch': 18.4}
{'loss': 0.0177, 'grad_norm': 7.191786766052246, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.01273264829069376, 'loss_2': 0.00493621826171875, 'loss_3': -16.176292419433594, 'loss_4': 0.678720235824585, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 10:44:37,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:37,491 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:04<34:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:44,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012580305337905884, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.267, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007137327920645475, 'eval_loss_2': 0.005442976951599121, 'eval_loss_3': -18.194608688354492, 'eval_loss_4': 0.8801421523094177, 'epoch': 18.4}
{'loss': 0.0122, 'grad_norm': 6.7159104347229, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.006414848379790783, 'loss_2': 0.0057373046875, 'loss_3': -16.25461196899414, 'loss_4': 1.3240859508514404, 'epoch': 18.41}
{'loss': 0.006, 'grad_norm': 4.587458610534668, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.004286572802811861, 'loss_2': 0.0017156600952148438, 'loss_3': -16.255046844482422, 'loss_4': 1.117476224899292, 'epoch': 18.41}
{'loss': 0.0135, 'grad_norm': 4.660050868988037, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.005971027538180351, 'loss_2': 0.00748443603515625, 'loss_3': -16.40386199951172, 'loss_4': 0.68026202917099, 'epoch': 18.42}
{'loss': 0.008, 'grad_norm': 4.973672389984131, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.0036793970502913, 'loss_2': 0.0042877197265625, 'loss_3': -16.354755401611328, 'loss_4': 1.0822288990020752, 'epoch': 18.42}
{'loss': 0.012, 'grad_norm': 4.919341087341309, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.006216405890882015, 'loss_2': 0.00582122802734375, 'loss_3': -16.34210968017578, 'loss_4': 0.8227773904800415, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 10:44:44,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:44,820 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:11<34:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:52,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012605354189872742, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.376, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.007607385981827974, 'eval_loss_2': 0.004997968673706055, 'eval_loss_3': -18.205692291259766, 'eval_loss_4': 0.8473680019378662, 'epoch': 18.43}
{'loss': 0.0153, 'grad_norm': 6.349871635437012, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.009342098608613014, 'loss_2': 0.00595855712890625, 'loss_3': -16.31662368774414, 'loss_4': 0.5432509183883667, 'epoch': 18.44}
{'loss': 0.0088, 'grad_norm': 5.45732307434082, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.005232065450400114, 'loss_2': 0.0036106109619140625, 'loss_3': -16.386083602905273, 'loss_4': 0.8368560075759888, 'epoch': 18.44}
{'loss': 0.0127, 'grad_norm': 8.806065559387207, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.010789236053824425, 'loss_2': 0.001926422119140625, 'loss_3': -16.439329147338867, 'loss_4': 0.8082515001296997, 'epoch': 18.45}
{'loss': 0.0099, 'grad_norm': 5.575812816619873, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.009397649206221104, 'loss_2': 0.0004630088806152344, 'loss_3': -16.26584815979004, 'loss_4': 1.2562291622161865, 'epoch': 18.45}
{'loss': 0.0106, 'grad_norm': 5.992202281951904, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.008173789829015732, 'loss_2': 0.002407073974609375, 'loss_3': -16.179088592529297, 'loss_4': 0.5535238981246948, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 10:44:52,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:52,146 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:19<34:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:44:59,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011182298883795738, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.218, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007159105036407709, 'eval_loss_2': 0.004023194313049316, 'eval_loss_3': -18.213085174560547, 'eval_loss_4': 0.721052885055542, 'epoch': 18.46}
{'loss': 0.016, 'grad_norm': 8.04057502746582, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.010638921521604061, 'loss_2': 0.005374908447265625, 'loss_3': -16.369586944580078, 'loss_4': 0.7153655886650085, 'epoch': 18.47}
{'loss': 0.0189, 'grad_norm': 4.930188179016113, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.01035304181277752, 'loss_2': 0.0085601806640625, 'loss_3': -16.406150817871094, 'loss_4': 1.2677209377288818, 'epoch': 18.47}
{'loss': 0.0189, 'grad_norm': 5.069356918334961, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.007749510463327169, 'loss_2': 0.0111083984375, 'loss_3': -16.326492309570312, 'loss_4': 0.49297481775283813, 'epoch': 18.48}
{'loss': 0.021, 'grad_norm': 6.320353031158447, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.014023267664015293, 'loss_2': 0.007022857666015625, 'loss_3': -16.398757934570312, 'loss_4': 1.593480110168457, 'epoch': 18.48}
{'loss': 0.014, 'grad_norm': 5.974594593048096, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.008372101932764053, 'loss_2': 0.005588531494140625, 'loss_3': -16.30274200439453, 'loss_4': 0.37470513582229614, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 10:44:59,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:59,473 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:26<34:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:06,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012880667112767696, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.192, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007375648710876703, 'eval_loss_2': 0.005505017936229706, 'eval_loss_3': -18.21540069580078, 'eval_loss_4': 0.6489229202270508, 'epoch': 18.49}
{'loss': 0.0145, 'grad_norm': 5.846272945404053, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.008675973862409592, 'loss_2': 0.0058441162109375, 'loss_3': -16.409067153930664, 'loss_4': 1.0912917852401733, 'epoch': 18.49}
{'loss': 0.0174, 'grad_norm': 5.076180934906006, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.009265030734241009, 'loss_2': 0.0081634521484375, 'loss_3': -16.404613494873047, 'loss_4': 0.9419856667518616, 'epoch': 18.5}
{'loss': 0.0186, 'grad_norm': 11.522751808166504, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.017089277505874634, 'loss_2': 0.0015411376953125, 'loss_3': -16.34921646118164, 'loss_4': 0.9196892380714417, 'epoch': 18.51}
{'loss': 0.0097, 'grad_norm': 5.385642051696777, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.008669668808579445, 'loss_2': 0.0010166168212890625, 'loss_3': -16.18511199951172, 'loss_4': 1.001509189605713, 'epoch': 18.51}
{'loss': 0.0109, 'grad_norm': 5.424961090087891, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.00821663998067379, 'loss_2': 0.002712249755859375, 'loss_3': -16.45530891418457, 'loss_4': 1.1431314945220947, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 10:45:06,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:06,798 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:33<34:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:14,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011091480031609535, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.134, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007867256179451942, 'eval_loss_2': 0.0032242238521575928, 'eval_loss_3': -18.205219268798828, 'eval_loss_4': 0.7194804549217224, 'epoch': 18.52}
{'loss': 0.0085, 'grad_norm': 5.162885665893555, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.0033038570545613766, 'loss_2': 0.00516510009765625, 'loss_3': -16.39040184020996, 'loss_4': 0.6588245034217834, 'epoch': 18.52}
{'loss': 0.0122, 'grad_norm': 4.914951801300049, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.006185134872794151, 'loss_2': 0.0060577392578125, 'loss_3': -16.41829490661621, 'loss_4': 0.6827678680419922, 'epoch': 18.53}
{'loss': 0.0064, 'grad_norm': 4.74033784866333, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.0047968304716050625, 'loss_2': 0.0016231536865234375, 'loss_3': -16.408672332763672, 'loss_4': 0.8058422803878784, 'epoch': 18.53}
{'loss': 0.0302, 'grad_norm': 13.621355056762695, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.028070801869034767, 'loss_2': 0.0020847320556640625, 'loss_3': -16.33602523803711, 'loss_4': 1.14821195602417, 'epoch': 18.54}
{'loss': 0.0162, 'grad_norm': 5.160135269165039, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.007864445447921753, 'loss_2': 0.0083465576171875, 'loss_3': -16.426773071289062, 'loss_4': 0.6026772856712341, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 10:45:14,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:14,128 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:41<33:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:21,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012711324729025364, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.071, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00808517076075077, 'eval_loss_2': 0.004626154899597168, 'eval_loss_3': -18.19940185546875, 'eval_loss_4': 0.6920866966247559, 'epoch': 18.55}
{'loss': 0.0176, 'grad_norm': 7.489325523376465, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.010428630746901035, 'loss_2': 0.0072174072265625, 'loss_3': -16.60848617553711, 'loss_4': 0.5325472354888916, 'epoch': 18.55}
{'loss': 0.0073, 'grad_norm': 5.608004570007324, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.006069888360798359, 'loss_2': 0.001232147216796875, 'loss_3': -16.32832908630371, 'loss_4': 0.8248202800750732, 'epoch': 18.56}
{'loss': 0.0186, 'grad_norm': 8.943897247314453, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.013867298141121864, 'loss_2': 0.004756927490234375, 'loss_3': -16.330612182617188, 'loss_4': 0.4028656482696533, 'epoch': 18.56}
{'loss': 0.0102, 'grad_norm': 5.093686580657959, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.009570061229169369, 'loss_2': 0.0006198883056640625, 'loss_3': -16.40404510498047, 'loss_4': 0.8265564441680908, 'epoch': 18.57}
{'loss': 0.0114, 'grad_norm': 5.580954551696777, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.005663960240781307, 'loss_2': 0.005706787109375, 'loss_3': -16.503063201904297, 'loss_4': 1.0187981128692627, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 10:45:21,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:21,459 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:18:48<33:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:28,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013003261759877205, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.59, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.008234592154622078, 'eval_loss_2': 0.004768669605255127, 'eval_loss_3': -18.167936325073242, 'eval_loss_4': 0.5960225462913513, 'epoch': 18.58}
{'loss': 0.0171, 'grad_norm': 5.495932102203369, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.013819157145917416, 'loss_2': 0.003253936767578125, 'loss_3': -16.4132080078125, 'loss_4': 0.7924988865852356, 'epoch': 18.58}
{'loss': 0.0121, 'grad_norm': 7.865753650665283, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.011014976538717747, 'loss_2': 0.0010433197021484375, 'loss_3': -16.415287017822266, 'loss_4': 0.602768063545227, 'epoch': 18.59}
{'loss': 0.0294, 'grad_norm': 15.075658798217773, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.024353614076972008, 'loss_2': 0.00508880615234375, 'loss_3': -16.538991928100586, 'loss_4': 0.9187625646591187, 'epoch': 18.59}
{'loss': 0.0159, 'grad_norm': 5.4137420654296875, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.006700939033180475, 'loss_2': 0.00921630859375, 'loss_3': -16.20205307006836, 'loss_4': 0.6553928852081299, 'epoch': 18.6}
{'loss': 0.0105, 'grad_norm': 5.468949317932129, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.0070612127892673016, 'loss_2': 0.0034027099609375, 'loss_3': -16.31441879272461, 'loss_4': 0.4334176778793335, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 10:45:28,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:28,781 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:18:55<33:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:36,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01207982562482357, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.686, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.008478616364300251, 'eval_loss_2': 0.0036012083292007446, 'eval_loss_3': -18.15850067138672, 'eval_loss_4': 0.5050724148750305, 'epoch': 18.6}
{'loss': 0.0248, 'grad_norm': 9.407391548156738, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.022264553233981133, 'loss_2': 0.0025634765625, 'loss_3': -16.620750427246094, 'loss_4': 0.997905969619751, 'epoch': 18.61}
{'loss': 0.0113, 'grad_norm': 5.563477993011475, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.008155575022101402, 'loss_2': 0.003192901611328125, 'loss_3': -16.312767028808594, 'loss_4': 0.3718334436416626, 'epoch': 18.62}
{'loss': 0.0112, 'grad_norm': 4.837357044219971, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.006601786240935326, 'loss_2': 0.0045623779296875, 'loss_3': -16.446666717529297, 'loss_4': 0.4572446048259735, 'epoch': 18.62}
{'loss': 0.0166, 'grad_norm': 6.714573860168457, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.012769820168614388, 'loss_2': 0.003810882568359375, 'loss_3': -16.2734375, 'loss_4': 0.4560491442680359, 'epoch': 18.63}
{'loss': 0.012, 'grad_norm': 8.48022174835205, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.011096359230577946, 'loss_2': 0.0009136199951171875, 'loss_3': -16.50676155090332, 'loss_4': 0.13456034660339355, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 10:45:36,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:36,100 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:03<33:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:43,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012174084782600403, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.56, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.008501931093633175, 'eval_loss_2': 0.0036721527576446533, 'eval_loss_3': -18.142086029052734, 'eval_loss_4': 0.42774251103401184, 'epoch': 18.63}
{'loss': 0.0073, 'grad_norm': 4.839894771575928, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.005969488527625799, 'loss_2': 0.00133514404296875, 'loss_3': -16.42999267578125, 'loss_4': 0.4111631214618683, 'epoch': 18.64}
{'loss': 0.0235, 'grad_norm': 7.022432804107666, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.012124828062951565, 'loss_2': 0.0113983154296875, 'loss_3': -16.492721557617188, 'loss_4': 0.542697012424469, 'epoch': 18.65}
{'loss': 0.0151, 'grad_norm': 6.661935329437256, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.010864902287721634, 'loss_2': 0.004241943359375, 'loss_3': -16.29843521118164, 'loss_4': 0.09816816449165344, 'epoch': 18.65}
{'loss': 0.0082, 'grad_norm': 4.9925432205200195, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.00532692251726985, 'loss_2': 0.0028839111328125, 'loss_3': -16.15493392944336, 'loss_4': -0.10086359083652496, 'epoch': 18.66}
{'loss': 0.027, 'grad_norm': 13.957422256469727, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.020674729719758034, 'loss_2': 0.0063018798828125, 'loss_3': -16.362606048583984, 'loss_4': 0.10349627584218979, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 10:45:43,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:43,419 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:10<33:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:45:50,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011874936521053314, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.491, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008141481317579746, 'eval_loss_2': 0.0037334561347961426, 'eval_loss_3': -18.161155700683594, 'eval_loss_4': 0.3192644715309143, 'epoch': 18.66}
{'loss': 0.0111, 'grad_norm': 5.442067623138428, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.007673713844269514, 'loss_2': 0.0034046173095703125, 'loss_3': -16.534805297851562, 'loss_4': 0.6841590404510498, 'epoch': 18.67}
{'loss': 0.0211, 'grad_norm': 9.391016006469727, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.014820436015725136, 'loss_2': 0.006305694580078125, 'loss_3': -16.435672760009766, 'loss_4': -0.0705878809094429, 'epoch': 18.67}
{'loss': 0.0135, 'grad_norm': 5.8756608963012695, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.012363987974822521, 'loss_2': 0.00109100341796875, 'loss_3': -16.548419952392578, 'loss_4': -0.16798418760299683, 'epoch': 18.68}
{'loss': 0.021, 'grad_norm': 7.387147426605225, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.011142217554152012, 'loss_2': 0.009857177734375, 'loss_3': -16.55435562133789, 'loss_4': 0.4674692153930664, 'epoch': 18.69}
{'loss': 0.017, 'grad_norm': 6.460934638977051, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.013514573685824871, 'loss_2': 0.0034847259521484375, 'loss_3': -16.492992401123047, 'loss_4': 0.4106500744819641, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 10:45:50,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:50,739 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:17<33:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:58,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012430381029844284, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.904, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008985857479274273, 'eval_loss_2': 0.0034445226192474365, 'eval_loss_3': -18.145620346069336, 'eval_loss_4': 0.26795583963394165, 'epoch': 18.69}
{'loss': 0.0066, 'grad_norm': 5.001456260681152, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.00519984308630228, 'loss_2': 0.0013799667358398438, 'loss_3': -16.282665252685547, 'loss_4': -0.16506363451480865, 'epoch': 18.7}
{'loss': 0.0138, 'grad_norm': 6.035039901733398, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.00983831100165844, 'loss_2': 0.00399017333984375, 'loss_3': -16.306270599365234, 'loss_4': 0.35024338960647583, 'epoch': 18.7}
{'loss': 0.0129, 'grad_norm': 4.891017436981201, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.006436680443584919, 'loss_2': 0.006496429443359375, 'loss_3': -16.22227668762207, 'loss_4': -0.2607887387275696, 'epoch': 18.71}
{'loss': 0.0088, 'grad_norm': 5.273223876953125, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.006754839792847633, 'loss_2': 0.002002716064453125, 'loss_3': -16.406158447265625, 'loss_4': -0.062113694846630096, 'epoch': 18.72}
{'loss': 0.0152, 'grad_norm': 4.677074909210205, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.006408254150301218, 'loss_2': 0.0088043212890625, 'loss_3': -16.44101333618164, 'loss_4': 0.35416898131370544, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 10:45:58,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:58,075 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:25<33:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:05,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013547027483582497, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.692, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.009472395293414593, 'eval_loss_2': 0.0040746331214904785, 'eval_loss_3': -18.147079467773438, 'eval_loss_4': 0.2772648334503174, 'epoch': 18.72}
{'loss': 0.0181, 'grad_norm': 10.093213081359863, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.018018195405602455, 'loss_2': 0.00011068582534790039, 'loss_3': -16.370241165161133, 'loss_4': 0.3374025523662567, 'epoch': 18.73}
{'loss': 0.0167, 'grad_norm': 6.790907382965088, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.010717065073549747, 'loss_2': 0.005950927734375, 'loss_3': -16.33692169189453, 'loss_4': 0.409248411655426, 'epoch': 18.73}
{'loss': 0.0151, 'grad_norm': 5.553784370422363, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.00873828586190939, 'loss_2': 0.006317138671875, 'loss_3': -16.43566131591797, 'loss_4': 0.5710394978523254, 'epoch': 18.74}
{'loss': 0.0106, 'grad_norm': 5.2563557624816895, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.009465161710977554, 'loss_2': 0.00116729736328125, 'loss_3': -16.492843627929688, 'loss_4': 0.22140468657016754, 'epoch': 18.74}
{'loss': 0.0087, 'grad_norm': 6.2533063888549805, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.007108090911060572, 'loss_2': 0.0015516281127929688, 'loss_3': -16.492046356201172, 'loss_4': 0.28680941462516785, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 10:46:05,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:05,397 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:32<33:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:12,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013286033645272255, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.453, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.009527008049190044, 'eval_loss_2': 0.003759026527404785, 'eval_loss_3': -18.150373458862305, 'eval_loss_4': 0.32498741149902344, 'epoch': 18.75}
{'loss': 0.0068, 'grad_norm': 4.860225677490234, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.005399197340011597, 'loss_2': 0.001407623291015625, 'loss_3': -16.474021911621094, 'loss_4': 0.2790428102016449, 'epoch': 18.76}
{'loss': 0.0051, 'grad_norm': 5.072714328765869, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.003416843479499221, 'loss_2': 0.001705169677734375, 'loss_3': -16.333053588867188, 'loss_4': 0.37072527408599854, 'epoch': 18.76}
{'loss': 0.0058, 'grad_norm': 5.257650375366211, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.00563493836671114, 'loss_2': 0.00012683868408203125, 'loss_3': -16.219886779785156, 'loss_4': 0.14386972784996033, 'epoch': 18.77}
{'loss': 0.0093, 'grad_norm': 5.361598014831543, 'learning_rate': 1.125e-05, 'loss_1': 0.006596764549612999, 'loss_2': 0.0027008056640625, 'loss_3': -16.404705047607422, 'loss_4': 0.16666756570339203, 'epoch': 18.77}
{'loss': 0.0131, 'grad_norm': 6.451240539550781, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.012176592834293842, 'loss_2': 0.0009131431579589844, 'loss_3': -16.205455780029297, 'loss_4': 0.3460889160633087, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 10:46:12,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:12,719 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:39<33:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:20,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014384841546416283, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.524, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.010009994730353355, 'eval_loss_2': 0.004374846816062927, 'eval_loss_3': -18.145469665527344, 'eval_loss_4': 0.39509332180023193, 'epoch': 18.78}
{'loss': 0.0199, 'grad_norm': 9.278958320617676, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.018454059958457947, 'loss_2': 0.0014467239379882812, 'loss_3': -16.353622436523438, 'loss_4': 0.5105383396148682, 'epoch': 18.78}
{'loss': 0.0049, 'grad_norm': 5.553371906280518, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.00486881984397769, 'loss_2': 3.8504600524902344e-05, 'loss_3': -16.538419723510742, 'loss_4': 0.4559631943702698, 'epoch': 18.79}
{'loss': 0.0072, 'grad_norm': 5.540083885192871, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.006741080898791552, 'loss_2': 0.00046825408935546875, 'loss_3': -16.299367904663086, 'loss_4': 0.31327611207962036, 'epoch': 18.8}
{'loss': 0.01, 'grad_norm': 5.859920024871826, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.008732322603464127, 'loss_2': 0.00127410888671875, 'loss_3': -16.253751754760742, 'loss_4': 0.5818457007408142, 'epoch': 18.8}
{'loss': 0.0165, 'grad_norm': 5.592899799346924, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.00908130407333374, 'loss_2': 0.0073699951171875, 'loss_3': -16.29789924621582, 'loss_4': 0.2685946822166443, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 10:46:20,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:20,039 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:19:47<33:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:27,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013738458044826984, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.377, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008991900831460953, 'eval_loss_2': 0.004746556282043457, 'eval_loss_3': -18.151775360107422, 'eval_loss_4': 0.6198914647102356, 'epoch': 18.81}
{'loss': 0.009, 'grad_norm': 5.06019926071167, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.007690407335758209, 'loss_2': 0.0012769699096679688, 'loss_3': -16.38062286376953, 'loss_4': 0.38732609152793884, 'epoch': 18.81}
{'loss': 0.0076, 'grad_norm': 4.966944694519043, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.00319645251147449, 'loss_2': 0.00441741943359375, 'loss_3': -16.40687370300293, 'loss_4': 0.647696852684021, 'epoch': 18.82}
{'loss': 0.0076, 'grad_norm': 5.133383274078369, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.00628623878583312, 'loss_2': 0.001293182373046875, 'loss_3': -16.282901763916016, 'loss_4': 0.7022231817245483, 'epoch': 18.83}
{'loss': 0.0052, 'grad_norm': 4.614196300506592, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.004575178027153015, 'loss_2': 0.0006008148193359375, 'loss_3': -16.44185447692871, 'loss_4': 0.9034687280654907, 'epoch': 18.83}
{'loss': 0.0104, 'grad_norm': 4.715106010437012, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.004410811234265566, 'loss_2': 0.005950927734375, 'loss_3': -16.361473083496094, 'loss_4': 0.9778852462768555, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 10:46:27,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:27,360 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:19:54<33:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:34,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013263381086289883, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.402, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.009081161580979824, 'eval_loss_2': 0.004182219505310059, 'eval_loss_3': -18.161710739135742, 'eval_loss_4': 0.8751695156097412, 'epoch': 18.84}
{'loss': 0.0046, 'grad_norm': 4.4109978675842285, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.003480962011963129, 'loss_2': 0.0010690689086914062, 'loss_3': -16.617982864379883, 'loss_4': 1.00131356716156, 'epoch': 18.84}
{'loss': 0.0088, 'grad_norm': 5.88348388671875, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.006173353176563978, 'loss_2': 0.0025844573974609375, 'loss_3': -16.373706817626953, 'loss_4': 0.9183443188667297, 'epoch': 18.85}
{'loss': 0.0092, 'grad_norm': 5.431556224822998, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.005045678000897169, 'loss_2': 0.00411224365234375, 'loss_3': -16.322046279907227, 'loss_4': 1.0980193614959717, 'epoch': 18.85}
{'loss': 0.0458, 'grad_norm': 19.436670303344727, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.04477616026997566, 'loss_2': 0.0010395050048828125, 'loss_3': -16.514476776123047, 'loss_4': 1.0346877574920654, 'epoch': 18.86}
{'loss': 0.009, 'grad_norm': 5.040363311767578, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.005716596730053425, 'loss_2': 0.00324249267578125, 'loss_3': -16.355533599853516, 'loss_4': 1.0163644552230835, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 10:46:34,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:34,682 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:01<33:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:42,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010783812031149864, 'eval_runtime': 3.8193, 'eval_samples_per_second': 268.114, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.0076545230112969875, 'eval_loss_2': 0.0031292885541915894, 'eval_loss_3': -18.14134407043457, 'eval_loss_4': 1.0748212337493896, 'epoch': 18.87}
{'loss': 0.0139, 'grad_norm': 5.019247055053711, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.007387715857475996, 'loss_2': 0.0065460205078125, 'loss_3': -16.43752670288086, 'loss_4': 1.288390040397644, 'epoch': 18.87}
{'loss': 0.0201, 'grad_norm': 7.510507106781006, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.01181884203106165, 'loss_2': 0.0082855224609375, 'loss_3': -16.244094848632812, 'loss_4': 1.3588382005691528, 'epoch': 18.88}
{'loss': 0.0215, 'grad_norm': 7.449523448944092, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.017331000417470932, 'loss_2': 0.004123687744140625, 'loss_3': -16.41846466064453, 'loss_4': 1.0256284475326538, 'epoch': 18.88}
{'loss': 0.0092, 'grad_norm': 5.179953098297119, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.006275422405451536, 'loss_2': 0.00287628173828125, 'loss_3': -16.30408477783203, 'loss_4': 1.406420111656189, 'epoch': 18.89}
{'loss': 0.0112, 'grad_norm': 6.055874824523926, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.009113509207963943, 'loss_2': 0.002094268798828125, 'loss_3': -16.551027297973633, 'loss_4': 1.0284624099731445, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 10:46:42,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:42,037 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:09<32:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:46:49,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011294709518551826, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.562, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007153884042054415, 'eval_loss_2': 0.00414082407951355, 'eval_loss_3': -18.138301849365234, 'eval_loss_4': 1.1533156633377075, 'epoch': 18.9}
{'loss': 0.0123, 'grad_norm': 5.194619655609131, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.010396418161690235, 'loss_2': 0.0018930435180664062, 'loss_3': -16.459041595458984, 'loss_4': 1.4155676364898682, 'epoch': 18.9}
{'loss': 0.0136, 'grad_norm': 5.443832874298096, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.0039757355116307735, 'loss_2': 0.0096282958984375, 'loss_3': -16.441099166870117, 'loss_4': 1.2283802032470703, 'epoch': 18.91}
{'loss': 0.0163, 'grad_norm': 4.847326755523682, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.00653400644659996, 'loss_2': 0.00977325439453125, 'loss_3': -16.28586196899414, 'loss_4': 0.9774566888809204, 'epoch': 18.91}
{'loss': 0.0077, 'grad_norm': 5.13985538482666, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.005263682454824448, 'loss_2': 0.002468109130859375, 'loss_3': -16.438825607299805, 'loss_4': 0.8833319544792175, 'epoch': 18.92}
{'loss': 0.0084, 'grad_norm': 4.4518585205078125, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.005156177561730146, 'loss_2': 0.0032825469970703125, 'loss_3': -16.188186645507812, 'loss_4': 1.5232877731323242, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 10:46:49,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:49,359 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:16<32:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:56,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01159217394888401, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0071024103090167046, 'eval_loss_2': 0.00448976457118988, 'eval_loss_3': -18.145212173461914, 'eval_loss_4': 1.2532410621643066, 'epoch': 18.92}
{'loss': 0.0116, 'grad_norm': 6.316155433654785, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.008500517345964909, 'loss_2': 0.003131866455078125, 'loss_3': -16.27392578125, 'loss_4': 1.0941102504730225, 'epoch': 18.93}
{'loss': 0.0184, 'grad_norm': 7.6545209884643555, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.016282862052321434, 'loss_2': 0.002094268798828125, 'loss_3': -16.25847625732422, 'loss_4': 1.2325890064239502, 'epoch': 18.94}
{'loss': 0.0167, 'grad_norm': 5.290578365325928, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.007303793448954821, 'loss_2': 0.009368896484375, 'loss_3': -16.321269989013672, 'loss_4': 1.3408515453338623, 'epoch': 18.94}
{'loss': 0.0077, 'grad_norm': 5.060451507568359, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.004746332298964262, 'loss_2': 0.00296783447265625, 'loss_3': -16.353084564208984, 'loss_4': 0.9395924806594849, 'epoch': 18.95}
{'loss': 0.0173, 'grad_norm': 6.622630596160889, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.009909569285809994, 'loss_2': 0.00734710693359375, 'loss_3': -16.373397827148438, 'loss_4': 0.9171041250228882, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 10:46:56,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:56,684 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:23<32:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:04,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011288943700492382, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.39, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00775723485276103, 'eval_loss_2': 0.003531709313392639, 'eval_loss_3': -18.159595489501953, 'eval_loss_4': 1.2479248046875, 'epoch': 18.95}
{'loss': 0.0078, 'grad_norm': 4.326018810272217, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.005597986746579409, 'loss_2': 0.0022411346435546875, 'loss_3': -16.420757293701172, 'loss_4': 1.1059470176696777, 'epoch': 18.96}
{'loss': 0.0121, 'grad_norm': 5.647188663482666, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.01101233996450901, 'loss_2': 0.00107574462890625, 'loss_3': -16.43073272705078, 'loss_4': 1.562242031097412, 'epoch': 18.97}
{'loss': 0.0239, 'grad_norm': 6.920726299285889, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.01610904186964035, 'loss_2': 0.007793426513671875, 'loss_3': -16.352039337158203, 'loss_4': 1.3212502002716064, 'epoch': 18.97}
{'loss': 0.0135, 'grad_norm': 5.426318168640137, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.009948432445526123, 'loss_2': 0.003520965576171875, 'loss_3': -16.495525360107422, 'loss_4': 0.9545634984970093, 'epoch': 18.98}
{'loss': 0.0131, 'grad_norm': 5.2882537841796875, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.008692001923918724, 'loss_2': 0.004425048828125, 'loss_3': -16.40256118774414, 'loss_4': 0.9110480546951294, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 10:47:04,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:04,010 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:30<31:17,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 10:47:11,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010195618495345116, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.375, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006915966048836708, 'eval_loss_2': 0.0032796524465084076, 'eval_loss_3': -18.197853088378906, 'eval_loss_4': 1.250817894935608, 'epoch': 18.98}
{'loss': 0.0118, 'grad_norm': 5.158543586730957, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.0062546501867473125, 'loss_2': 0.0055084228515625, 'loss_3': -16.467199325561523, 'loss_4': 1.306095838546753, 'epoch': 18.99}
{'loss': 0.015, 'grad_norm': 4.743738651275635, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.006440372206270695, 'loss_2': 0.00856781005859375, 'loss_3': -16.322002410888672, 'loss_4': 1.3688738346099854, 'epoch': 18.99}
{'loss': 0.0129, 'grad_norm': 7.918574810028076, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.007808500435203314, 'loss_2': 0.005138397216796875, 'loss_3': -16.326108932495117, 'loss_4': 0.9589700102806091, 'epoch': 19.0}
{'loss': 0.015, 'grad_norm': 5.448945999145508, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.008990173228085041, 'loss_2': 0.005992889404296875, 'loss_3': -16.466299057006836, 'loss_4': 1.4851768016815186, 'epoch': 19.01}
{'loss': 0.0218, 'grad_norm': 5.2834272384643555, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.013192502781748772, 'loss_2': 0.008636474609375, 'loss_3': -16.303802490234375, 'loss_4': 1.5054471492767334, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 10:47:11,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:11,028 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:38<32:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:47:18,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010276613757014275, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006760424003005028, 'eval_loss_2': 0.003516189754009247, 'eval_loss_3': -18.216693878173828, 'eval_loss_4': 1.2605326175689697, 'epoch': 19.01}
{'loss': 0.0208, 'grad_norm': 8.189610481262207, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.013963212259113789, 'loss_2': 0.00684356689453125, 'loss_3': -16.384471893310547, 'loss_4': 1.1445329189300537, 'epoch': 19.02}
{'loss': 0.0101, 'grad_norm': 4.848875522613525, 'learning_rate': 1.1e-05, 'loss_1': 0.007247861009091139, 'loss_2': 0.00289154052734375, 'loss_3': -16.410709381103516, 'loss_4': 1.81686532497406, 'epoch': 19.02}
{'loss': 0.0066, 'grad_norm': 5.209441184997559, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.006460753735154867, 'loss_2': 0.00018072128295898438, 'loss_3': -16.546802520751953, 'loss_4': 1.5763208866119385, 'epoch': 19.03}
{'loss': 0.0097, 'grad_norm': 6.197474002838135, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.009673737920820713, 'loss_2': 2.562999725341797e-05, 'loss_3': -16.603656768798828, 'loss_4': 1.4878822565078735, 'epoch': 19.03}
{'loss': 0.0213, 'grad_norm': 11.761627197265625, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.021256810054183006, 'loss_2': 3.3795833587646484e-05, 'loss_3': -16.449861526489258, 'loss_4': 1.3151767253875732, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 10:47:18,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:18,363 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:20:45<32:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:47:25,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012207521125674248, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.437, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006684584077447653, 'eval_loss_2': 0.005522936582565308, 'eval_loss_3': -18.208650588989258, 'eval_loss_4': 1.2331007719039917, 'epoch': 19.04}
{'loss': 0.0142, 'grad_norm': 5.358614921569824, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.005773898679763079, 'loss_2': 0.0084228515625, 'loss_3': -16.47692108154297, 'loss_4': 1.4112169742584229, 'epoch': 19.05}
{'loss': 0.0159, 'grad_norm': 5.349389553070068, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.005485893692821264, 'loss_2': 0.01041412353515625, 'loss_3': -16.401569366455078, 'loss_4': 1.375347375869751, 'epoch': 19.05}
{'loss': 0.0266, 'grad_norm': 8.965353965759277, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.015212002210319042, 'loss_2': 0.01140594482421875, 'loss_3': -16.52419662475586, 'loss_4': 1.4140880107879639, 'epoch': 19.06}
{'loss': 0.0224, 'grad_norm': 6.76288366317749, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.01392173208296299, 'loss_2': 0.00847625732421875, 'loss_3': -16.256214141845703, 'loss_4': 1.410979986190796, 'epoch': 19.06}
{'loss': 0.0101, 'grad_norm': 5.3445281982421875, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.008138180710375309, 'loss_2': 0.0019445419311523438, 'loss_3': -16.507244110107422, 'loss_4': 1.021944284439087, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 10:47:25,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:25,684 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:20:52<32:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:33,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009595962241292, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.444, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006133998278528452, 'eval_loss_2': 0.003461964428424835, 'eval_loss_3': -18.22447967529297, 'eval_loss_4': 1.2644213438034058, 'epoch': 19.07}
{'loss': 0.011, 'grad_norm': 5.817542552947998, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.010252022184431553, 'loss_2': 0.0007028579711914062, 'loss_3': -16.39273452758789, 'loss_4': 1.0206372737884521, 'epoch': 19.08}
{'loss': 0.0074, 'grad_norm': 4.758895397186279, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.005260918755084276, 'loss_2': 0.002166748046875, 'loss_3': -16.6387996673584, 'loss_4': 1.166292667388916, 'epoch': 19.08}
{'loss': 0.0148, 'grad_norm': 6.3904290199279785, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.0068572210147976875, 'loss_2': 0.0079803466796875, 'loss_3': -16.44089698791504, 'loss_4': 1.2750446796417236, 'epoch': 19.09}
{'loss': 0.0101, 'grad_norm': 5.410615921020508, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.010093488730490208, 'loss_2': 2.8133392333984375e-05, 'loss_3': -16.390165328979492, 'loss_4': 1.5750823020935059, 'epoch': 19.09}
{'loss': 0.0121, 'grad_norm': 4.117280006408691, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.00518793985247612, 'loss_2': 0.0069580078125, 'loss_3': -16.475589752197266, 'loss_4': 1.1655597686767578, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 10:47:33,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:33,015 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:00<32:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:40,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009613238275051117, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.471, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006526030134409666, 'eval_loss_2': 0.0030872076749801636, 'eval_loss_3': -18.23859977722168, 'eval_loss_4': 1.2585874795913696, 'epoch': 19.1}
{'loss': 0.0058, 'grad_norm': 4.9230451583862305, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.004191883374005556, 'loss_2': 0.001613616943359375, 'loss_3': -16.39177703857422, 'loss_4': 1.2674360275268555, 'epoch': 19.1}
{'loss': 0.0179, 'grad_norm': 7.0711989402771, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.010781527496874332, 'loss_2': 0.007110595703125, 'loss_3': -16.384796142578125, 'loss_4': 1.508188247680664, 'epoch': 19.11}
{'loss': 0.0063, 'grad_norm': 4.771975994110107, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.004433700814843178, 'loss_2': 0.0018510818481445312, 'loss_3': -16.537357330322266, 'loss_4': 0.9970680475234985, 'epoch': 19.12}
{'loss': 0.0097, 'grad_norm': 5.47692346572876, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.006843911483883858, 'loss_2': 0.0028247833251953125, 'loss_3': -16.36963653564453, 'loss_4': 1.2391366958618164, 'epoch': 19.12}
{'loss': 0.0095, 'grad_norm': 5.222850799560547, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.008180929347872734, 'loss_2': 0.0013675689697265625, 'loss_3': -16.51738929748535, 'loss_4': 1.4665048122406006, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 10:47:40,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:40,344 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:07<32:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:47,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011466107331216335, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.497, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007120218127965927, 'eval_loss_2': 0.004345890134572983, 'eval_loss_3': -18.26055908203125, 'eval_loss_4': 1.1561634540557861, 'epoch': 19.13}
{'loss': 0.0109, 'grad_norm': 4.734084129333496, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.004060520324856043, 'loss_2': 0.00679779052734375, 'loss_3': -16.435169219970703, 'loss_4': 1.2803447246551514, 'epoch': 19.13}
{'loss': 0.0258, 'grad_norm': 10.687413215637207, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.0196995846927166, 'loss_2': 0.006145477294921875, 'loss_3': -16.371044158935547, 'loss_4': 1.486172080039978, 'epoch': 19.14}
{'loss': 0.015, 'grad_norm': 5.0311455726623535, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.007682953029870987, 'loss_2': 0.00733184814453125, 'loss_3': -16.465442657470703, 'loss_4': 1.3771549463272095, 'epoch': 19.15}
{'loss': 0.0076, 'grad_norm': 5.39611291885376, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.006101593840867281, 'loss_2': 0.0015411376953125, 'loss_3': -16.449142456054688, 'loss_4': 1.1554253101348877, 'epoch': 19.15}
{'loss': 0.0185, 'grad_norm': 6.031980514526367, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.010401783511042595, 'loss_2': 0.0081329345703125, 'loss_3': -16.40848159790039, 'loss_4': 1.2079875469207764, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 10:47:47,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:47,670 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:14<32:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:47:54,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010797884315252304, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.566, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006889325100928545, 'eval_loss_2': 0.003908559679985046, 'eval_loss_3': -18.255321502685547, 'eval_loss_4': 1.0471508502960205, 'epoch': 19.16}
{'loss': 0.0079, 'grad_norm': 4.855281829833984, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.004749438725411892, 'loss_2': 0.003177642822265625, 'loss_3': -16.40328025817871, 'loss_4': 0.6153730154037476, 'epoch': 19.16}
{'loss': 0.0269, 'grad_norm': 14.530628204345703, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.026018166914582253, 'loss_2': 0.0008525848388671875, 'loss_3': -16.308849334716797, 'loss_4': 1.1213083267211914, 'epoch': 19.17}
{'loss': 0.0199, 'grad_norm': 7.514626502990723, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.013022264465689659, 'loss_2': 0.0069122314453125, 'loss_3': -16.37442398071289, 'loss_4': 0.8957681655883789, 'epoch': 19.17}
{'loss': 0.0243, 'grad_norm': 5.704580783843994, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.010953639633953571, 'loss_2': 0.013336181640625, 'loss_3': -16.4837589263916, 'loss_4': 1.2376164197921753, 'epoch': 19.18}
{'loss': 0.0094, 'grad_norm': 4.695057392120361, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.007630037143826485, 'loss_2': 0.00177001953125, 'loss_3': -16.454084396362305, 'loss_4': 0.6628206968307495, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 10:47:54,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:54,993 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:22<32:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:02,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01030734647065401, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.582, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006687140092253685, 'eval_loss_2': 0.0036202073097229004, 'eval_loss_3': -18.260934829711914, 'eval_loss_4': 0.9840264320373535, 'epoch': 19.19}
{'loss': 0.0173, 'grad_norm': 5.292572021484375, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.004335517529398203, 'loss_2': 0.012939453125, 'loss_3': -16.599838256835938, 'loss_4': 1.691239356994629, 'epoch': 19.19}
{'loss': 0.0073, 'grad_norm': 5.231783390045166, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.0048208534717559814, 'loss_2': 0.00246429443359375, 'loss_3': -16.534587860107422, 'loss_4': 1.3960617780685425, 'epoch': 19.2}
{'loss': 0.0138, 'grad_norm': 8.45344066619873, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.013761603273451328, 'loss_2': 5.537271499633789e-05, 'loss_3': -15.996520042419434, 'loss_4': 1.228369116783142, 'epoch': 19.2}
{'loss': 0.0199, 'grad_norm': 6.625871658325195, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.01282524410635233, 'loss_2': 0.007110595703125, 'loss_3': -16.426931381225586, 'loss_4': 1.2964622974395752, 'epoch': 19.21}
{'loss': 0.0197, 'grad_norm': 6.26500129699707, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.010001217015087605, 'loss_2': 0.009735107421875, 'loss_3': -16.510513305664062, 'loss_4': 1.1943353414535522, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 10:48:02,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:02,341 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:29<31:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:09,669 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011494861915707588, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005658017471432686, 'eval_loss_2': 0.005836844444274902, 'eval_loss_3': -18.275442123413086, 'eval_loss_4': 0.941940188407898, 'epoch': 19.22}
{'loss': 0.0144, 'grad_norm': 6.0798540115356445, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.010911834426224232, 'loss_2': 0.0034580230712890625, 'loss_3': -16.434993743896484, 'loss_4': 1.0421068668365479, 'epoch': 19.22}
{'loss': 0.017, 'grad_norm': 5.940957546234131, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.00762446504086256, 'loss_2': 0.00937652587890625, 'loss_3': -16.466426849365234, 'loss_4': 1.3088427782058716, 'epoch': 19.23}
{'loss': 0.0236, 'grad_norm': 5.43652868270874, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.01152832806110382, 'loss_2': 0.01209259033203125, 'loss_3': -16.42560386657715, 'loss_4': 1.2467848062515259, 'epoch': 19.23}
{'loss': 0.0092, 'grad_norm': 4.917489528656006, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.004760680720210075, 'loss_2': 0.004421234130859375, 'loss_3': -16.331192016601562, 'loss_4': 1.0723521709442139, 'epoch': 19.24}
{'loss': 0.0126, 'grad_norm': 4.70900297164917, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.006903764791786671, 'loss_2': 0.00567626953125, 'loss_3': -16.475082397460938, 'loss_4': 1.281285047531128, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 10:48:09,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:09,669 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:36<31:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:16,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0088617829605937, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.13, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005691217258572578, 'eval_loss_2': 0.0031705647706985474, 'eval_loss_3': -18.29564094543457, 'eval_loss_4': 0.796341061592102, 'epoch': 19.24}
{'loss': 0.0247, 'grad_norm': 11.445518493652344, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.021392913535237312, 'loss_2': 0.0032958984375, 'loss_3': -16.369985580444336, 'loss_4': 1.0727741718292236, 'epoch': 19.25}
{'loss': 0.0072, 'grad_norm': 4.409062385559082, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.0033244050573557615, 'loss_2': 0.0038890838623046875, 'loss_3': -16.5340576171875, 'loss_4': 1.0151257514953613, 'epoch': 19.26}
{'loss': 0.0124, 'grad_norm': 6.14458703994751, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.009556546807289124, 'loss_2': 0.0028553009033203125, 'loss_3': -16.426410675048828, 'loss_4': 0.8096433877944946, 'epoch': 19.26}
{'loss': 0.0168, 'grad_norm': 7.2092604637146, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.01026554498821497, 'loss_2': 0.0064849853515625, 'loss_3': -16.30587387084961, 'loss_4': 1.1320185661315918, 'epoch': 19.27}
{'loss': 0.0193, 'grad_norm': 7.382831573486328, 'learning_rate': 1.075e-05, 'loss_1': 0.014651178382337093, 'loss_2': 0.00466156005859375, 'loss_3': -16.37851333618164, 'loss_4': 1.0749647617340088, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 10:48:16,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:16,999 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:44<31:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:24,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008174114860594273, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.263, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005675979889929295, 'eval_loss_2': 0.002498134970664978, 'eval_loss_3': -18.307796478271484, 'eval_loss_4': 0.7026456594467163, 'epoch': 19.27}
{'loss': 0.0103, 'grad_norm': 4.798529148101807, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.005026606842875481, 'loss_2': 0.005237579345703125, 'loss_3': -16.491641998291016, 'loss_4': 0.9240156412124634, 'epoch': 19.28}
{'loss': 0.0111, 'grad_norm': 5.391018867492676, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.007073072250932455, 'loss_2': 0.00402069091796875, 'loss_3': -16.4171142578125, 'loss_4': 1.28504478931427, 'epoch': 19.28}
{'loss': 0.0219, 'grad_norm': 7.3045573234558105, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.018376579508185387, 'loss_2': 0.0035381317138671875, 'loss_3': -16.491924285888672, 'loss_4': 0.9511793851852417, 'epoch': 19.29}
{'loss': 0.0127, 'grad_norm': 5.898857593536377, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.00789202842861414, 'loss_2': 0.00479888916015625, 'loss_3': -16.499523162841797, 'loss_4': 1.8879485130310059, 'epoch': 19.3}
{'loss': 0.0121, 'grad_norm': 5.286116600036621, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.006673478055745363, 'loss_2': 0.00540924072265625, 'loss_3': -16.371105194091797, 'loss_4': 1.29573655128479, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 10:48:24,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:24,327 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:21:51<31:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:48:31,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00861019641160965, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.52, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005712219979614019, 'eval_loss_2': 0.002897977828979492, 'eval_loss_3': -18.291959762573242, 'eval_loss_4': 0.7499524354934692, 'epoch': 19.3}
{'loss': 0.0127, 'grad_norm': 4.885212421417236, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.009628904052078724, 'loss_2': 0.00312042236328125, 'loss_3': -16.481712341308594, 'loss_4': 0.69008868932724, 'epoch': 19.31}
{'loss': 0.0098, 'grad_norm': 5.216436862945557, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.007105639204382896, 'loss_2': 0.0026950836181640625, 'loss_3': -16.47518539428711, 'loss_4': 0.6282840371131897, 'epoch': 19.31}
{'loss': 0.0096, 'grad_norm': 5.604791641235352, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.005991887301206589, 'loss_2': 0.003582000732421875, 'loss_3': -16.4140682220459, 'loss_4': 1.0133309364318848, 'epoch': 19.32}
{'loss': 0.0173, 'grad_norm': 7.2555694580078125, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.013683914206922054, 'loss_2': 0.003582000732421875, 'loss_3': -16.475040435791016, 'loss_4': 1.4738304615020752, 'epoch': 19.33}
{'loss': 0.0095, 'grad_norm': 4.857071876525879, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.00797989685088396, 'loss_2': 0.0015411376953125, 'loss_3': -16.425010681152344, 'loss_4': 0.9200963377952576, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 10:48:31,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:31,647 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:21:58<31:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:38,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011303841136395931, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.087, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.005932103376835585, 'eval_loss_2': 0.005371738225221634, 'eval_loss_3': -18.279682159423828, 'eval_loss_4': 0.7066614031791687, 'epoch': 19.33}
{'loss': 0.0179, 'grad_norm': 5.625545501708984, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.014001540839672089, 'loss_2': 0.003936767578125, 'loss_3': -16.433448791503906, 'loss_4': 1.1240055561065674, 'epoch': 19.34}
{'loss': 0.0167, 'grad_norm': 11.148741722106934, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.01636503078043461, 'loss_2': 0.0003542900085449219, 'loss_3': -16.42312240600586, 'loss_4': 0.5264252424240112, 'epoch': 19.34}
{'loss': 0.0179, 'grad_norm': 9.938217163085938, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.014551215805113316, 'loss_2': 0.003322601318359375, 'loss_3': -16.42034912109375, 'loss_4': 0.8652411699295044, 'epoch': 19.35}
{'loss': 0.027, 'grad_norm': 9.056893348693848, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.018713802099227905, 'loss_2': 0.008331298828125, 'loss_3': -16.45956039428711, 'loss_4': 1.1444365978240967, 'epoch': 19.35}
{'loss': 0.0108, 'grad_norm': 4.768022537231445, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.005506249610334635, 'loss_2': 0.005321502685546875, 'loss_3': -16.41502571105957, 'loss_4': 0.8039695024490356, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 10:48:38,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:38,979 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:06<31:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:46,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011554371565580368, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005977999418973923, 'eval_loss_2': 0.005576372146606445, 'eval_loss_3': -18.287494659423828, 'eval_loss_4': 0.5381683111190796, 'epoch': 19.36}
{'loss': 0.0346, 'grad_norm': 10.086503982543945, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.02438761666417122, 'loss_2': 0.0102386474609375, 'loss_3': -16.56610679626465, 'loss_4': 0.790115237236023, 'epoch': 19.37}
{'loss': 0.009, 'grad_norm': 4.945507049560547, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.005965924356132746, 'loss_2': 0.0030193328857421875, 'loss_3': -16.33257484436035, 'loss_4': 0.8314324617385864, 'epoch': 19.37}
{'loss': 0.0126, 'grad_norm': 5.951774597167969, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.008718874305486679, 'loss_2': 0.00392913818359375, 'loss_3': -16.267738342285156, 'loss_4': 0.5880364179611206, 'epoch': 19.38}
{'loss': 0.0107, 'grad_norm': 6.216556072235107, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.009088645689189434, 'loss_2': 0.0015954971313476562, 'loss_3': -16.490060806274414, 'loss_4': 0.7415257096290588, 'epoch': 19.38}
{'loss': 0.009, 'grad_norm': 4.761016368865967, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.006957188248634338, 'loss_2': 0.002063751220703125, 'loss_3': -16.430355072021484, 'loss_4': 0.504069447517395, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 10:48:46,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:46,321 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:13<31:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:53,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010131380520761013, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.323, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006538658868521452, 'eval_loss_2': 0.0035927221179008484, 'eval_loss_3': -18.295475006103516, 'eval_loss_4': 0.3974657952785492, 'epoch': 19.39}
{'loss': 0.0072, 'grad_norm': 4.58118200302124, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.005436216946691275, 'loss_2': 0.001811981201171875, 'loss_3': -16.584156036376953, 'loss_4': 0.6494779586791992, 'epoch': 19.4}
{'loss': 0.0132, 'grad_norm': 5.68368673324585, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.008347728289663792, 'loss_2': 0.0048675537109375, 'loss_3': -16.43547821044922, 'loss_4': 0.45813679695129395, 'epoch': 19.4}
{'loss': 0.0152, 'grad_norm': 6.857550621032715, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.01349679846316576, 'loss_2': 0.0016574859619140625, 'loss_3': -16.292160034179688, 'loss_4': 0.6340823769569397, 'epoch': 19.41}
{'loss': 0.0122, 'grad_norm': 7.936738967895508, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.011328412219882011, 'loss_2': 0.0008907318115234375, 'loss_3': -16.572999954223633, 'loss_4': 0.5758124589920044, 'epoch': 19.41}
{'loss': 0.0186, 'grad_norm': 6.664875507354736, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.012207072228193283, 'loss_2': 0.00640869140625, 'loss_3': -16.596542358398438, 'loss_4': 1.092700719833374, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 10:48:53,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:53,647 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:20<31:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:00,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00900614820420742, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006272291298955679, 'eval_loss_2': 0.002733856439590454, 'eval_loss_3': -18.303401947021484, 'eval_loss_4': 0.28661105036735535, 'epoch': 19.42}
{'loss': 0.0111, 'grad_norm': 5.078603267669678, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.008551783859729767, 'loss_2': 0.002582550048828125, 'loss_3': -16.35934066772461, 'loss_4': 0.34605908393859863, 'epoch': 19.42}
{'loss': 0.0095, 'grad_norm': 4.503522872924805, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.005738440435379744, 'loss_2': 0.0037250518798828125, 'loss_3': -16.49362564086914, 'loss_4': 0.4908073842525482, 'epoch': 19.43}
{'loss': 0.0137, 'grad_norm': 9.11176872253418, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.012567497789859772, 'loss_2': 0.0011310577392578125, 'loss_3': -16.25749969482422, 'loss_4': 0.20447519421577454, 'epoch': 19.44}
{'loss': 0.0151, 'grad_norm': 5.105861186981201, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.006853222846984863, 'loss_2': 0.0082244873046875, 'loss_3': -16.412124633789062, 'loss_4': 0.011573657393455505, 'epoch': 19.44}
{'loss': 0.0148, 'grad_norm': 6.340436935424805, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.01394117996096611, 'loss_2': 0.0008897781372070312, 'loss_3': -16.608436584472656, 'loss_4': 1.0351818799972534, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 10:49:00,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:00,962 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:28<31:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:08,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009770912118256092, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.386, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006393169518560171, 'eval_loss_2': 0.0033777430653572083, 'eval_loss_3': -18.29446792602539, 'eval_loss_4': 0.2511669397354126, 'epoch': 19.45}
{'loss': 0.0184, 'grad_norm': 7.594123363494873, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.015108954161405563, 'loss_2': 0.003269195556640625, 'loss_3': -16.29005241394043, 'loss_4': 1.0458855628967285, 'epoch': 19.45}
{'loss': 0.0131, 'grad_norm': 5.621182441711426, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.010991919785737991, 'loss_2': 0.002105712890625, 'loss_3': -16.450420379638672, 'loss_4': 1.0670350790023804, 'epoch': 19.46}
{'loss': 0.0122, 'grad_norm': 5.405372142791748, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.008487635292112827, 'loss_2': 0.0036830902099609375, 'loss_3': -16.420047760009766, 'loss_4': 0.2175617218017578, 'epoch': 19.47}
{'loss': 0.0156, 'grad_norm': 5.032224655151367, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.01029875222593546, 'loss_2': 0.00531768798828125, 'loss_3': -16.236705780029297, 'loss_4': 0.3519788980484009, 'epoch': 19.47}
{'loss': 0.0147, 'grad_norm': 6.526219367980957, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.011018317192792892, 'loss_2': 0.003696441650390625, 'loss_3': -16.423988342285156, 'loss_4': 0.4684300720691681, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 10:49:08,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:08,290 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:35<31:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:15,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010687245056033134, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.586, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006269467528909445, 'eval_loss_2': 0.004417777061462402, 'eval_loss_3': -18.274898529052734, 'eval_loss_4': 0.2508087158203125, 'epoch': 19.48}
{'loss': 0.017, 'grad_norm': 5.945596694946289, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.009873746894299984, 'loss_2': 0.00716400146484375, 'loss_3': -16.445838928222656, 'loss_4': 1.1551311016082764, 'epoch': 19.48}
{'loss': 0.0186, 'grad_norm': 10.209709167480469, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.018002070486545563, 'loss_2': 0.0006322860717773438, 'loss_3': -16.359853744506836, 'loss_4': 0.818095326423645, 'epoch': 19.49}
{'loss': 0.0109, 'grad_norm': 4.661705017089844, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.007403850089758635, 'loss_2': 0.00347137451171875, 'loss_3': -16.520416259765625, 'loss_4': 0.5184950232505798, 'epoch': 19.49}
{'loss': 0.011, 'grad_norm': 4.8232245445251465, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.006322392262518406, 'loss_2': 0.0046844482421875, 'loss_3': -16.47093963623047, 'loss_4': 0.6153855323791504, 'epoch': 19.5}
{'loss': 0.0127, 'grad_norm': 5.198585033416748, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.010030282661318779, 'loss_2': 0.002643585205078125, 'loss_3': -16.392959594726562, 'loss_4': 0.478773295879364, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 10:49:15,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:15,605 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:42<31:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:22,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008154960349202156, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.041, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0055574048310518265, 'eval_loss_2': 0.0025975555181503296, 'eval_loss_3': -18.261220932006836, 'eval_loss_4': 0.2597994804382324, 'epoch': 19.51}
{'loss': 0.0146, 'grad_norm': 6.644906044006348, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.013756665401160717, 'loss_2': 0.0008678436279296875, 'loss_3': -16.38710594177246, 'loss_4': 0.4286101758480072, 'epoch': 19.51}
{'loss': 0.0124, 'grad_norm': 5.003636360168457, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.004787381272763014, 'loss_2': 0.00763702392578125, 'loss_3': -16.54024314880371, 'loss_4': 0.08735352754592896, 'epoch': 19.52}
{'loss': 0.0127, 'grad_norm': 5.606812953948975, 'learning_rate': 1.05e-05, 'loss_1': 0.005065976642072201, 'loss_2': 0.00768280029296875, 'loss_3': -16.271198272705078, 'loss_4': 0.7112773060798645, 'epoch': 19.52}
{'loss': 0.0272, 'grad_norm': 9.968100547790527, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.012995646335184574, 'loss_2': 0.0142059326171875, 'loss_3': -16.541549682617188, 'loss_4': 0.5173417329788208, 'epoch': 19.53}
{'loss': 0.0143, 'grad_norm': 4.65950345993042, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.006463272962719202, 'loss_2': 0.00785064697265625, 'loss_3': -16.231658935546875, 'loss_4': 0.5308433771133423, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 10:49:22,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:22,939 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:22:50<30:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:30,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010296999476850033, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.471, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005875766277313232, 'eval_loss_2': 0.004421234130859375, 'eval_loss_3': -18.259511947631836, 'eval_loss_4': 0.36434459686279297, 'epoch': 19.53}
{'loss': 0.0097, 'grad_norm': 4.847407341003418, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.007085522636771202, 'loss_2': 0.00257110595703125, 'loss_3': -16.473657608032227, 'loss_4': 0.33790767192840576, 'epoch': 19.54}
{'loss': 0.0107, 'grad_norm': 4.6099629402160645, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.0028615707997232676, 'loss_2': 0.0077972412109375, 'loss_3': -16.546113967895508, 'loss_4': 0.24888786673545837, 'epoch': 19.55}
{'loss': 0.0149, 'grad_norm': 5.518307685852051, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.011007414199411869, 'loss_2': 0.0038604736328125, 'loss_3': -16.432531356811523, 'loss_4': 0.3203250467777252, 'epoch': 19.55}
{'loss': 0.0114, 'grad_norm': 5.589328765869141, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.007465813774615526, 'loss_2': 0.00389862060546875, 'loss_3': -16.573698043823242, 'loss_4': 0.4330245852470398, 'epoch': 19.56}
{'loss': 0.0081, 'grad_norm': 4.83269739151001, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.004408275242894888, 'loss_2': 0.0037212371826171875, 'loss_3': -16.39624786376953, 'loss_4': 0.029787182807922363, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 10:49:30,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:30,263 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:22:57<30:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:37,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008112398907542229, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.664, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005699490197002888, 'eval_loss_2': 0.0024129077792167664, 'eval_loss_3': -18.24385643005371, 'eval_loss_4': 0.4406402111053467, 'epoch': 19.56}
{'loss': 0.0063, 'grad_norm': 4.753942966461182, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.005036045331507921, 'loss_2': 0.0012664794921875, 'loss_3': -16.41826629638672, 'loss_4': 0.610629677772522, 'epoch': 19.57}
{'loss': 0.0048, 'grad_norm': 4.266094207763672, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.004484603647142649, 'loss_2': 0.0002803802490234375, 'loss_3': -16.46800994873047, 'loss_4': 0.8681829571723938, 'epoch': 19.58}
{'loss': 0.0166, 'grad_norm': 5.718270778656006, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.008833903819322586, 'loss_2': 0.007720947265625, 'loss_3': -16.441150665283203, 'loss_4': 0.321974515914917, 'epoch': 19.58}
{'loss': 0.0131, 'grad_norm': 5.282364368438721, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.008955071680247784, 'loss_2': 0.0041351318359375, 'loss_3': -16.448270797729492, 'loss_4': 0.7159985899925232, 'epoch': 19.59}
{'loss': 0.013, 'grad_norm': 4.840298175811768, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.005328715778887272, 'loss_2': 0.007663726806640625, 'loss_3': -16.367841720581055, 'loss_4': 0.9436858892440796, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 10:49:37,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:37,581 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:04<30:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:44,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012787764891982079, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.553, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.006044080946594477, 'eval_loss_2': 0.006743684411048889, 'eval_loss_3': -18.246583938598633, 'eval_loss_4': 0.44594162702560425, 'epoch': 19.59}
{'loss': 0.015, 'grad_norm': 4.999794006347656, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.006485479883849621, 'loss_2': 0.0084686279296875, 'loss_3': -16.19559097290039, 'loss_4': 0.9037071466445923, 'epoch': 19.6}
{'loss': 0.0076, 'grad_norm': 5.5620808601379395, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.007330129388719797, 'loss_2': 0.0002675056457519531, 'loss_3': -16.510515213012695, 'loss_4': 0.44906213879585266, 'epoch': 19.6}
{'loss': 0.02, 'grad_norm': 4.662120819091797, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.006511165294796228, 'loss_2': 0.0135040283203125, 'loss_3': -16.236831665039062, 'loss_4': 0.2804211974143982, 'epoch': 19.61}
{'loss': 0.0338, 'grad_norm': 11.886406898498535, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.021674389019608498, 'loss_2': 0.01215362548828125, 'loss_3': -16.376733779907227, 'loss_4': 0.12050193548202515, 'epoch': 19.62}
{'loss': 0.0069, 'grad_norm': 4.713006019592285, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.004552590660750866, 'loss_2': 0.0023403167724609375, 'loss_3': -16.493289947509766, 'loss_4': 0.3388446867465973, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 10:49:44,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:44,906 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:12<30:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:52,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014795658178627491, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.465, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007489141076803207, 'eval_loss_2': 0.007306516170501709, 'eval_loss_3': -18.24806785583496, 'eval_loss_4': 0.5164903402328491, 'epoch': 19.62}
{'loss': 0.0144, 'grad_norm': 6.321693420410156, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.009461110457777977, 'loss_2': 0.00493621826171875, 'loss_3': -16.593984603881836, 'loss_4': 0.2722023129463196, 'epoch': 19.63}
{'loss': 0.0264, 'grad_norm': 9.315128326416016, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.024744629859924316, 'loss_2': 0.0016498565673828125, 'loss_3': -16.54431915283203, 'loss_4': 0.8166966438293457, 'epoch': 19.63}
{'loss': 0.0083, 'grad_norm': 4.740762233734131, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.005566045176237822, 'loss_2': 0.002780914306640625, 'loss_3': -16.40597915649414, 'loss_4': 0.6527369022369385, 'epoch': 19.64}
{'loss': 0.022, 'grad_norm': 12.935976028442383, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.017423855140805244, 'loss_2': 0.00461578369140625, 'loss_3': -16.177438735961914, 'loss_4': 0.9916301965713501, 'epoch': 19.65}
{'loss': 0.0285, 'grad_norm': 10.030989646911621, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.02592872828245163, 'loss_2': 0.00260162353515625, 'loss_3': -16.161888122558594, 'loss_4': 0.408221960067749, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 10:49:52,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:52,221 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:19<30:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:59,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012163588777184486, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007709810510277748, 'eval_loss_2': 0.004453778266906738, 'eval_loss_3': -18.250091552734375, 'eval_loss_4': 0.5818609595298767, 'epoch': 19.65}
{'loss': 0.0331, 'grad_norm': 23.300073623657227, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.030182767659425735, 'loss_2': 0.0029659271240234375, 'loss_3': -16.585723876953125, 'loss_4': 0.9421748518943787, 'epoch': 19.66}
{'loss': 0.0234, 'grad_norm': 5.667642593383789, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.01380334421992302, 'loss_2': 0.009552001953125, 'loss_3': -16.445819854736328, 'loss_4': 0.253604918718338, 'epoch': 19.66}
{'loss': 0.0068, 'grad_norm': 5.042253494262695, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.005458736792206764, 'loss_2': 0.0013179779052734375, 'loss_3': -16.547515869140625, 'loss_4': 0.34764668345451355, 'epoch': 19.67}
{'loss': 0.0136, 'grad_norm': 5.053669452667236, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.008873268961906433, 'loss_2': 0.004734039306640625, 'loss_3': -16.346168518066406, 'loss_4': 0.4490787982940674, 'epoch': 19.67}
{'loss': 0.0114, 'grad_norm': 6.676193714141846, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.008820336312055588, 'loss_2': 0.002559661865234375, 'loss_3': -16.31664276123047, 'loss_4': 0.8636097311973572, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 10:49:59,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:59,551 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:26<30:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:06,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010250523686408997, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007970674894750118, 'eval_loss_2': 0.0022798478603363037, 'eval_loss_3': -18.2464542388916, 'eval_loss_4': 0.6765194535255432, 'epoch': 19.68}
{'loss': 0.0262, 'grad_norm': 13.00445556640625, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.024541225284337997, 'loss_2': 0.0016527175903320312, 'loss_3': -16.393035888671875, 'loss_4': 0.8875640630722046, 'epoch': 19.69}
{'loss': 0.0239, 'grad_norm': 9.801210403442383, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.02063155360519886, 'loss_2': 0.00325775146484375, 'loss_3': -16.30669403076172, 'loss_4': 1.2663904428482056, 'epoch': 19.69}
{'loss': 0.0096, 'grad_norm': 4.644804000854492, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.005420343019068241, 'loss_2': 0.004222869873046875, 'loss_3': -16.595869064331055, 'loss_4': 0.5766919851303101, 'epoch': 19.7}
{'loss': 0.0233, 'grad_norm': 8.45716381072998, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.015348579734563828, 'loss_2': 0.00791168212890625, 'loss_3': -16.354909896850586, 'loss_4': 0.9905593395233154, 'epoch': 19.7}
{'loss': 0.0119, 'grad_norm': 7.30269193649292, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.01167710404843092, 'loss_2': 0.00022792816162109375, 'loss_3': -16.312999725341797, 'loss_4': 1.1052594184875488, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 10:50:06,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:06,893 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:34<30:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:50:14,210 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010606009513139725, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.647, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.007686932571232319, 'eval_loss_2': 0.0029190778732299805, 'eval_loss_3': -18.271635055541992, 'eval_loss_4': 0.6920580863952637, 'epoch': 19.71}
{'loss': 0.0316, 'grad_norm': 7.12399959564209, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.025740403681993484, 'loss_2': 0.005855560302734375, 'loss_3': -16.259498596191406, 'loss_4': 0.881891131401062, 'epoch': 19.72}
{'loss': 0.0073, 'grad_norm': 5.716920852661133, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.007150256074965, 'loss_2': 0.00011163949966430664, 'loss_3': -16.519996643066406, 'loss_4': 0.2700539231300354, 'epoch': 19.72}
{'loss': 0.0053, 'grad_norm': 4.450456142425537, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.0051628896035254, 'loss_2': 0.0001316070556640625, 'loss_3': -16.423181533813477, 'loss_4': 0.8656840324401855, 'epoch': 19.73}
{'loss': 0.0214, 'grad_norm': 7.398088455200195, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.01559089869260788, 'loss_2': 0.0058441162109375, 'loss_3': -16.370704650878906, 'loss_4': 0.8372358679771423, 'epoch': 19.73}
{'loss': 0.0068, 'grad_norm': 5.383681297302246, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.004205281846225262, 'loss_2': 0.002552032470703125, 'loss_3': -16.633434295654297, 'loss_4': 0.11943313479423523, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 10:50:14,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:14,210 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:41<30:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:21,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011990749277174473, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.488, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008519511669874191, 'eval_loss_2': 0.003471236675977707, 'eval_loss_3': -18.26078987121582, 'eval_loss_4': 0.5818920731544495, 'epoch': 19.74}
{'loss': 0.0246, 'grad_norm': 10.253591537475586, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.017002331092953682, 'loss_2': 0.007640838623046875, 'loss_3': -16.493484497070312, 'loss_4': 0.4431633949279785, 'epoch': 19.74}
{'loss': 0.0188, 'grad_norm': 8.137880325317383, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.014987976290285587, 'loss_2': 0.0037822723388671875, 'loss_3': -16.499305725097656, 'loss_4': 0.5045777559280396, 'epoch': 19.75}
{'loss': 0.0125, 'grad_norm': 5.72067928314209, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.011985940858721733, 'loss_2': 0.0005445480346679688, 'loss_3': -16.435596466064453, 'loss_4': 0.6844916343688965, 'epoch': 19.76}
{'loss': 0.0081, 'grad_norm': 5.255539417266846, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.00643882667645812, 'loss_2': 0.0016717910766601562, 'loss_3': -16.208072662353516, 'loss_4': 0.624596118927002, 'epoch': 19.76}
{'loss': 0.0131, 'grad_norm': 6.250406742095947, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.011021562851965427, 'loss_2': 0.002086639404296875, 'loss_3': -16.517501831054688, 'loss_4': 0.6194641590118408, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 10:50:21,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:21,537 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:23:48<30:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:28,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011995279230177402, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.57, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.008680395781993866, 'eval_loss_2': 0.003314882516860962, 'eval_loss_3': -18.260425567626953, 'eval_loss_4': 0.4974132180213928, 'epoch': 19.77}
{'loss': 0.0082, 'grad_norm': 4.769436359405518, 'learning_rate': 1.025e-05, 'loss_1': 0.00496645225211978, 'loss_2': 0.003269195556640625, 'loss_3': -16.54924774169922, 'loss_4': 0.31334301829338074, 'epoch': 19.77}
{'loss': 0.0105, 'grad_norm': 5.007533073425293, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.00738314725458622, 'loss_2': 0.0030841827392578125, 'loss_3': -16.37529945373535, 'loss_4': 0.5492023229598999, 'epoch': 19.78}
{'loss': 0.014, 'grad_norm': 4.9505109786987305, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.0060583981685340405, 'loss_2': 0.007904052734375, 'loss_3': -16.36829948425293, 'loss_4': 0.5945174694061279, 'epoch': 19.78}
{'loss': 0.027, 'grad_norm': 15.838991165161133, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.02114890143275261, 'loss_2': 0.00583648681640625, 'loss_3': -16.233566284179688, 'loss_4': 0.018384035676717758, 'epoch': 19.79}
{'loss': 0.0056, 'grad_norm': 4.667095184326172, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.003325186436995864, 'loss_2': 0.0022735595703125, 'loss_3': -16.396940231323242, 'loss_4': 0.09183914959430695, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 10:50:28,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:28,860 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:23:55<30:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:36,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012380406260490417, 'eval_runtime': 3.7815, 'eval_samples_per_second': 270.793, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.008548615500330925, 'eval_loss_2': 0.0038317888975143433, 'eval_loss_3': -18.256656646728516, 'eval_loss_4': 0.4193055033683777, 'epoch': 19.8}
{'loss': 0.0141, 'grad_norm': 5.2854743003845215, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.011076941154897213, 'loss_2': 0.0030422210693359375, 'loss_3': -16.430042266845703, 'loss_4': 0.7016494870185852, 'epoch': 19.8}
{'loss': 0.0182, 'grad_norm': 7.381504535675049, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.012683668173849583, 'loss_2': 0.005558013916015625, 'loss_3': -16.31077003479004, 'loss_4': 0.14667095243930817, 'epoch': 19.81}
{'loss': 0.0135, 'grad_norm': 7.675052165985107, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.01161478366702795, 'loss_2': 0.0019016265869140625, 'loss_3': -16.43941879272461, 'loss_4': -0.031280092895030975, 'epoch': 19.81}
{'loss': 0.0197, 'grad_norm': 7.963171482086182, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.015156404115259647, 'loss_2': 0.0045166015625, 'loss_3': -16.513959884643555, 'loss_4': 0.5451874732971191, 'epoch': 19.82}
{'loss': 0.029, 'grad_norm': 14.44723892211914, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.028686372563242912, 'loss_2': 0.00036144256591796875, 'loss_3': -16.290863037109375, 'loss_4': 0.6164345145225525, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 10:50:36,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:36,186 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:03<30:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:43,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011655477806925774, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.015, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007894198410212994, 'eval_loss_2': 0.0037612803280353546, 'eval_loss_3': -18.234294891357422, 'eval_loss_4': 0.44595932960510254, 'epoch': 19.83}
{'loss': 0.0123, 'grad_norm': 4.84614372253418, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.011378622613847256, 'loss_2': 0.0009598731994628906, 'loss_3': -16.564558029174805, 'loss_4': 0.5024291276931763, 'epoch': 19.83}
{'loss': 0.0134, 'grad_norm': 4.808344841003418, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.008547700941562653, 'loss_2': 0.004871368408203125, 'loss_3': -16.460830688476562, 'loss_4': 0.6940290927886963, 'epoch': 19.84}
{'loss': 0.0042, 'grad_norm': 4.7477006912231445, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.0035627763718366623, 'loss_2': 0.0006132125854492188, 'loss_3': -16.470375061035156, 'loss_4': 0.2530978322029114, 'epoch': 19.84}
{'loss': 0.0095, 'grad_norm': 4.766805648803711, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.005750693846493959, 'loss_2': 0.00371551513671875, 'loss_3': -16.696063995361328, 'loss_4': -0.003786534070968628, 'epoch': 19.85}
{'loss': 0.0047, 'grad_norm': 4.4148850440979, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.004014570266008377, 'loss_2': 0.0006761550903320312, 'loss_3': -16.51211166381836, 'loss_4': 0.795427680015564, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 10:50:43,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:43,515 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:10<30:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:50:50,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01103183627128601, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.63, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.008304526098072529, 'eval_loss_2': 0.0027273111045360565, 'eval_loss_3': -18.226865768432617, 'eval_loss_4': 0.5055359601974487, 'epoch': 19.85}
{'loss': 0.009, 'grad_norm': 4.874270915985107, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.008669428527355194, 'loss_2': 0.0003299713134765625, 'loss_3': -16.219270706176758, 'loss_4': 0.6954042315483093, 'epoch': 19.86}
{'loss': 0.0068, 'grad_norm': 4.431258201599121, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.00457907747477293, 'loss_2': 0.0022430419921875, 'loss_3': -16.45982551574707, 'loss_4': 0.13263505697250366, 'epoch': 19.87}
{'loss': 0.0086, 'grad_norm': 5.480672836303711, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.005863668397068977, 'loss_2': 0.002704620361328125, 'loss_3': -16.52197265625, 'loss_4': 0.6473315954208374, 'epoch': 19.87}
{'loss': 0.0083, 'grad_norm': 5.857633113861084, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.005365860648453236, 'loss_2': 0.0029296875, 'loss_3': -16.539560317993164, 'loss_4': 0.7786319255828857, 'epoch': 19.88}
{'loss': 0.0159, 'grad_norm': 5.267026424407959, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.007892332971096039, 'loss_2': 0.0079803466796875, 'loss_3': -16.22880744934082, 'loss_4': 0.7530678510665894, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 10:50:50,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:50,835 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:17<29:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:50:58,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010917047038674355, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.465, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007816295139491558, 'eval_loss_2': 0.003100752830505371, 'eval_loss_3': -18.23982048034668, 'eval_loss_4': 0.5319600105285645, 'epoch': 19.88}
{'loss': 0.0054, 'grad_norm': 4.5692853927612305, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.005004828795790672, 'loss_2': 0.0003676414489746094, 'loss_3': -16.54709243774414, 'loss_4': 0.6734747886657715, 'epoch': 19.89}
{'loss': 0.0079, 'grad_norm': 5.40889310836792, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.007229461334645748, 'loss_2': 0.0006885528564453125, 'loss_3': -16.170730590820312, 'loss_4': 0.6980680823326111, 'epoch': 19.9}
{'loss': 0.0096, 'grad_norm': 4.695806980133057, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.007169471587985754, 'loss_2': 0.002407073974609375, 'loss_3': -16.344287872314453, 'loss_4': 0.3937796652317047, 'epoch': 19.9}
{'loss': 0.0139, 'grad_norm': 5.566911697387695, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.007055640686303377, 'loss_2': 0.00681304931640625, 'loss_3': -16.497650146484375, 'loss_4': 0.16232441365718842, 'epoch': 19.91}
{'loss': 0.016, 'grad_norm': 6.403374671936035, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.0154641754925251, 'loss_2': 0.0004911422729492188, 'loss_3': -16.287574768066406, 'loss_4': 0.5358142852783203, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 10:50:58,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:58,157 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:25<29:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:51:05,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012419382110238075, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.473, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006222734693437815, 'eval_loss_2': 0.006196647882461548, 'eval_loss_3': -18.260709762573242, 'eval_loss_4': 0.5616379380226135, 'epoch': 19.91}
{'loss': 0.009, 'grad_norm': 4.893052577972412, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.004198390990495682, 'loss_2': 0.0047607421875, 'loss_3': -16.27176284790039, 'loss_4': 0.8753973245620728, 'epoch': 19.92}
{'loss': 0.0166, 'grad_norm': 9.843055725097656, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.014011855237185955, 'loss_2': 0.00255584716796875, 'loss_3': -16.389034271240234, 'loss_4': 0.8409022092819214, 'epoch': 19.92}
{'loss': 0.0133, 'grad_norm': 5.181329250335693, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.005994461476802826, 'loss_2': 0.007293701171875, 'loss_3': -16.45318603515625, 'loss_4': 0.4886239767074585, 'epoch': 19.93}
{'loss': 0.0136, 'grad_norm': 8.99483871459961, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.012073036283254623, 'loss_2': 0.0015268325805664062, 'loss_3': -16.388484954833984, 'loss_4': 0.5458800792694092, 'epoch': 19.94}
{'loss': 0.0338, 'grad_norm': 8.871108055114746, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.02336045540869236, 'loss_2': 0.0104217529296875, 'loss_3': -16.388248443603516, 'loss_4': 0.6995531916618347, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 10:51:05,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:05,479 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:32<29:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:51:12,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010485287755727768, 'eval_runtime': 3.7823, 'eval_samples_per_second': 270.733, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005720911081880331, 'eval_loss_2': 0.004764378070831299, 'eval_loss_3': -18.26645851135254, 'eval_loss_4': 0.5614231824874878, 'epoch': 19.94}
{'loss': 0.0156, 'grad_norm': 4.627709865570068, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.005804961547255516, 'loss_2': 0.0098114013671875, 'loss_3': -16.562931060791016, 'loss_4': 0.8273189067840576, 'epoch': 19.95}
{'loss': 0.0061, 'grad_norm': 4.6233601570129395, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.005818476434797049, 'loss_2': 0.00024509429931640625, 'loss_3': -16.45462417602539, 'loss_4': 0.8326864838600159, 'epoch': 19.95}
{'loss': 0.0077, 'grad_norm': 4.451839447021484, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.004634174518287182, 'loss_2': 0.0031070709228515625, 'loss_3': -16.299495697021484, 'loss_4': 0.04324967786669731, 'epoch': 19.96}
{'loss': 0.0238, 'grad_norm': 13.586625099182129, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.022348077967762947, 'loss_2': 0.0014238357543945312, 'loss_3': -16.276569366455078, 'loss_4': 0.292326420545578, 'epoch': 19.97}
{'loss': 0.0493, 'grad_norm': 21.297006607055664, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.04632679373025894, 'loss_2': 0.002948760986328125, 'loss_3': -16.447105407714844, 'loss_4': 0.3622935116291046, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 10:51:12,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:12,791 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:39<26:39,  1.08it/s][INFO|trainer.py:4226] 2025-01-21 10:51:19,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0090667475014925, 'eval_runtime': 3.7814, 'eval_samples_per_second': 270.801, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.005941541399806738, 'eval_loss_2': 0.003125205636024475, 'eval_loss_3': -18.276058197021484, 'eval_loss_4': 0.505663275718689, 'epoch': 19.97}
{'loss': 0.0149, 'grad_norm': 4.816102981567383, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.006186007056385279, 'loss_2': 0.00867462158203125, 'loss_3': -16.45176887512207, 'loss_4': 0.30901816487312317, 'epoch': 19.98}
{'loss': 0.0176, 'grad_norm': 5.128058433532715, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.00844377838075161, 'loss_2': 0.00919342041015625, 'loss_3': -16.509870529174805, 'loss_4': 0.30573099851608276, 'epoch': 19.98}
{'loss': 0.0161, 'grad_norm': 6.519625186920166, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.010714704170823097, 'loss_2': 0.0053558349609375, 'loss_3': -16.349151611328125, 'loss_4': 0.2581806778907776, 'epoch': 19.99}
{'loss': 0.0151, 'grad_norm': 5.2319135665893555, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.007767931558191776, 'loss_2': 0.007350921630859375, 'loss_3': -16.297300338745117, 'loss_4': 0.6460105180740356, 'epoch': 19.99}
{'loss': 0.0033, 'grad_norm': 6.719047546386719, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.0013777933781966567, 'loss_2': 0.0019054412841796875, 'loss_3': -16.52323341369629, 'loss_4': 0.9030348658561707, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 10:51:19,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:19,758 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:24:46<29:09,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:51:27,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010050750337541103, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006299174390733242, 'eval_loss_2': 0.0037515759468078613, 'eval_loss_3': -18.269643783569336, 'eval_loss_4': 0.5048598051071167, 'epoch': 20.0}
{'loss': 0.0185, 'grad_norm': 7.966098308563232, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.012629643082618713, 'loss_2': 0.005870819091796875, 'loss_3': -16.49013328552246, 'loss_4': 1.1522200107574463, 'epoch': 20.01}
{'loss': 0.0109, 'grad_norm': 6.871561527252197, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.008907384239137173, 'loss_2': 0.001949310302734375, 'loss_3': -16.486177444458008, 'loss_4': 0.19375711679458618, 'epoch': 20.01}
{'loss': 0.012, 'grad_norm': 4.512012004852295, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.003382994793355465, 'loss_2': 0.0085906982421875, 'loss_3': -16.412033081054688, 'loss_4': 0.7930272817611694, 'epoch': 20.02}
{'loss': 0.0249, 'grad_norm': 9.287696838378906, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.021190442144870758, 'loss_2': 0.003726959228515625, 'loss_3': -16.334190368652344, 'loss_4': 0.7350383996963501, 'epoch': 20.02}
{'loss': 0.0107, 'grad_norm': 5.826921463012695, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.007944815792143345, 'loss_2': 0.002750396728515625, 'loss_3': -16.37458610534668, 'loss_4': 0.9389497637748718, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 10:51:27,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:27,125 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:24:54<29:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:51:34,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009245038032531738, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.641, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.00616347836330533, 'eval_loss_2': 0.0030815601348876953, 'eval_loss_3': -18.275100708007812, 'eval_loss_4': 0.542214572429657, 'epoch': 20.03}
{'loss': 0.0182, 'grad_norm': 6.826165676116943, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.010589856654405594, 'loss_2': 0.0075836181640625, 'loss_3': -16.420400619506836, 'loss_4': 0.8830406665802002, 'epoch': 20.03}
{'loss': 0.0174, 'grad_norm': 5.832311630249023, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.009567341767251492, 'loss_2': 0.0078125, 'loss_3': -16.364992141723633, 'loss_4': 0.5353986620903015, 'epoch': 20.04}
{'loss': 0.012, 'grad_norm': 5.975310802459717, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.008500587195158005, 'loss_2': 0.0035037994384765625, 'loss_3': -16.439023971557617, 'loss_4': 0.45629391074180603, 'epoch': 20.05}
{'loss': 0.0066, 'grad_norm': 4.610771179199219, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.00403346074745059, 'loss_2': 0.00255584716796875, 'loss_3': -16.358318328857422, 'loss_4': 0.8762133121490479, 'epoch': 20.05}
{'loss': 0.018, 'grad_norm': 7.480529308319092, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.017288407310843468, 'loss_2': 0.0007581710815429688, 'loss_3': -16.323440551757812, 'loss_4': 0.9657520055770874, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 10:51:34,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:34,444 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:01<29:47,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:51:41,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009109031409025192, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.714, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.006401863880455494, 'eval_loss_2': 0.002707168459892273, 'eval_loss_3': -18.277790069580078, 'eval_loss_4': 0.5601377487182617, 'epoch': 20.06}
{'loss': 0.0099, 'grad_norm': 7.995794773101807, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.00940009392797947, 'loss_2': 0.0005474090576171875, 'loss_3': -16.352298736572266, 'loss_4': 1.1156492233276367, 'epoch': 20.06}
{'loss': 0.0122, 'grad_norm': 5.800783634185791, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.007218933664262295, 'loss_2': 0.00493621826171875, 'loss_3': -16.594717025756836, 'loss_4': 1.0562422275543213, 'epoch': 20.07}
{'loss': 0.0099, 'grad_norm': 5.7427449226379395, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.006086099427193403, 'loss_2': 0.003814697265625, 'loss_3': -16.414337158203125, 'loss_4': 1.2850301265716553, 'epoch': 20.08}
{'loss': 0.0103, 'grad_norm': 5.666467666625977, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.008695641532540321, 'loss_2': 0.0015649795532226562, 'loss_3': -16.599626541137695, 'loss_4': 0.6092967391014099, 'epoch': 20.08}
{'loss': 0.0213, 'grad_norm': 7.728827476501465, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.014903796836733818, 'loss_2': 0.006389617919921875, 'loss_3': -16.47248077392578, 'loss_4': 1.1806789636611938, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 10:51:41,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:41,956 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:09<29:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:49,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009235749021172523, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.499, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.006619923748075962, 'eval_loss_2': 0.002615824341773987, 'eval_loss_3': -18.27178382873535, 'eval_loss_4': 0.5532675385475159, 'epoch': 20.09}
{'loss': 0.0258, 'grad_norm': 11.197900772094727, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.022780198603868484, 'loss_2': 0.0030117034912109375, 'loss_3': -16.335979461669922, 'loss_4': 0.9459233283996582, 'epoch': 20.09}
{'loss': 0.0142, 'grad_norm': 5.969962120056152, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.0136442631483078, 'loss_2': 0.0005598068237304688, 'loss_3': -16.31374740600586, 'loss_4': 1.397963047027588, 'epoch': 20.1}
{'loss': 0.0183, 'grad_norm': 5.002797603607178, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.008469589054584503, 'loss_2': 0.00988006591796875, 'loss_3': -16.123798370361328, 'loss_4': 0.6273165941238403, 'epoch': 20.1}
{'loss': 0.0164, 'grad_norm': 5.887508869171143, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.013776562176644802, 'loss_2': 0.0026149749755859375, 'loss_3': -16.48691177368164, 'loss_4': 0.47975143790245056, 'epoch': 20.11}
{'loss': 0.0095, 'grad_norm': 6.114072322845459, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.009108257479965687, 'loss_2': 0.00041961669921875, 'loss_3': -16.31934356689453, 'loss_4': 0.392770379781723, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 10:51:49,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:49,276 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:16<29:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:51:56,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00849773921072483, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005999574437737465, 'eval_loss_2': 0.0024981647729873657, 'eval_loss_3': -18.252925872802734, 'eval_loss_4': 0.5112105011940002, 'epoch': 20.12}
{'loss': 0.0104, 'grad_norm': 4.987953186035156, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.004758566617965698, 'loss_2': 0.0056610107421875, 'loss_3': -16.560279846191406, 'loss_4': 1.0642685890197754, 'epoch': 20.12}
{'loss': 0.0045, 'grad_norm': 4.298275470733643, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.0038878596387803555, 'loss_2': 0.0005664825439453125, 'loss_3': -16.430282592773438, 'loss_4': 0.14446279406547546, 'epoch': 20.13}
{'loss': 0.0284, 'grad_norm': 9.83613109588623, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.023642372339963913, 'loss_2': 0.0048065185546875, 'loss_3': -16.13849449157715, 'loss_4': 0.7012072801589966, 'epoch': 20.13}
{'loss': 0.0177, 'grad_norm': 7.727244853973389, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.00945955514907837, 'loss_2': 0.00827789306640625, 'loss_3': -16.52092933654785, 'loss_4': 0.5778711438179016, 'epoch': 20.14}
{'loss': 0.016, 'grad_norm': 16.107622146606445, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.01438205223530531, 'loss_2': 0.0016613006591796875, 'loss_3': -16.293546676635742, 'loss_4': 0.8267087936401367, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 10:51:56,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:56,592 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:23<29:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:03,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010696491226553917, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.316, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006651720497757196, 'eval_loss_2': 0.004044771194458008, 'eval_loss_3': -18.22970962524414, 'eval_loss_4': 0.44208064675331116, 'epoch': 20.15}
{'loss': 0.0124, 'grad_norm': 5.454184532165527, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.005477422382682562, 'loss_2': 0.00690460205078125, 'loss_3': -16.506267547607422, 'loss_4': 0.5800071358680725, 'epoch': 20.15}
{'loss': 0.0079, 'grad_norm': 5.565988540649414, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.00455504609271884, 'loss_2': 0.003307342529296875, 'loss_3': -16.451353073120117, 'loss_4': 0.3313734233379364, 'epoch': 20.16}
{'loss': 0.0072, 'grad_norm': 4.799509525299072, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.0020732046104967594, 'loss_2': 0.0051422119140625, 'loss_3': -16.533184051513672, 'loss_4': 0.5542595982551575, 'epoch': 20.16}
{'loss': 0.0161, 'grad_norm': 5.123076438903809, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.007600497920066118, 'loss_2': 0.008514404296875, 'loss_3': -16.442062377929688, 'loss_4': 0.26595625281333923, 'epoch': 20.17}
{'loss': 0.0071, 'grad_norm': 5.6123762130737305, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.00599081302061677, 'loss_2': 0.0011148452758789062, 'loss_3': -16.441526412963867, 'loss_4': 0.12307370454072952, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 10:52:03,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:03,916 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:31<29:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:11,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009873523376882076, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.893, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0060024624690413475, 'eval_loss_2': 0.0038710609078407288, 'eval_loss_3': -18.219179153442383, 'eval_loss_4': 0.4545787572860718, 'epoch': 20.17}
{'loss': 0.0084, 'grad_norm': 6.340170383453369, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.006926670204848051, 'loss_2': 0.0014247894287109375, 'loss_3': -16.49074935913086, 'loss_4': 0.301771879196167, 'epoch': 20.18}
{'loss': 0.0096, 'grad_norm': 5.095408916473389, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.006206798832863569, 'loss_2': 0.003398895263671875, 'loss_3': -16.475690841674805, 'loss_4': 0.4062831699848175, 'epoch': 20.19}
{'loss': 0.009, 'grad_norm': 5.2948431968688965, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.007106288801878691, 'loss_2': 0.0018901824951171875, 'loss_3': -16.3134765625, 'loss_4': 0.39814749360084534, 'epoch': 20.19}
{'loss': 0.0109, 'grad_norm': 5.52545690536499, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.010651928372681141, 'loss_2': 0.0001995563507080078, 'loss_3': -16.108949661254883, 'loss_4': 0.36907920241355896, 'epoch': 20.2}
{'loss': 0.0049, 'grad_norm': 4.856113910675049, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.0037197843194007874, 'loss_2': 0.0012006759643554688, 'loss_3': -16.441917419433594, 'loss_4': 0.8757870197296143, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 10:52:11,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:11,259 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:38<29:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:18,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008810454979538918, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006255204789340496, 'eval_loss_2': 0.002555251121520996, 'eval_loss_3': -18.22817039489746, 'eval_loss_4': 0.4895334243774414, 'epoch': 20.2}
{'loss': 0.0066, 'grad_norm': 5.844595432281494, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.006493244785815477, 'loss_2': 0.00014495849609375, 'loss_3': -16.400920867919922, 'loss_4': 0.5028549432754517, 'epoch': 20.21}
{'loss': 0.0087, 'grad_norm': 5.2517266273498535, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.00844330433756113, 'loss_2': 0.00024437904357910156, 'loss_3': -16.238285064697266, 'loss_4': 0.24475200474262238, 'epoch': 20.22}
{'loss': 0.0068, 'grad_norm': 4.754021167755127, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.005229322239756584, 'loss_2': 0.0016088485717773438, 'loss_3': -16.426815032958984, 'loss_4': 0.3741636276245117, 'epoch': 20.22}
{'loss': 0.0157, 'grad_norm': 5.588865756988525, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.007303707301616669, 'loss_2': 0.00836181640625, 'loss_3': -16.286718368530273, 'loss_4': 0.22085227072238922, 'epoch': 20.23}
{'loss': 0.0159, 'grad_norm': 6.0128607749938965, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.0101415254175663, 'loss_2': 0.00580596923828125, 'loss_3': -16.44062042236328, 'loss_4': 0.41657596826553345, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 10:52:18,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:18,585 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:25:45<28:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:52:25,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00935288704931736, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006515140179544687, 'eval_loss_2': 0.00283774733543396, 'eval_loss_3': -18.245689392089844, 'eval_loss_4': 0.44334548711776733, 'epoch': 20.23}
{'loss': 0.0185, 'grad_norm': 5.576491355895996, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.013515906408429146, 'loss_2': 0.00498199462890625, 'loss_3': -16.33583641052246, 'loss_4': 0.4748927354812622, 'epoch': 20.24}
{'loss': 0.0087, 'grad_norm': 4.775498867034912, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.004444899968802929, 'loss_2': 0.00421905517578125, 'loss_3': -16.52399444580078, 'loss_4': 0.38167035579681396, 'epoch': 20.24}
{'loss': 0.0193, 'grad_norm': 5.559445381164551, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.008142629638314247, 'loss_2': 0.0111236572265625, 'loss_3': -16.347352981567383, 'loss_4': 0.18940138816833496, 'epoch': 20.25}
{'loss': 0.0127, 'grad_norm': 6.4035162925720215, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.00914531946182251, 'loss_2': 0.0035858154296875, 'loss_3': -16.265958786010742, 'loss_4': 0.04276464134454727, 'epoch': 20.26}
{'loss': 0.0158, 'grad_norm': 5.602291584014893, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.007094878703355789, 'loss_2': 0.008697509765625, 'loss_3': -16.510704040527344, 'loss_4': 0.716460645198822, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 10:52:25,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:25,908 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:25:53<28:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:52:33,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009946896694600582, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.342, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0070748236030340195, 'eval_loss_2': 0.002872072160243988, 'eval_loss_3': -18.234664916992188, 'eval_loss_4': 0.4805208444595337, 'epoch': 20.26}
{'loss': 0.012, 'grad_norm': 4.582666873931885, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.00669996440410614, 'loss_2': 0.00533294677734375, 'loss_3': -16.451169967651367, 'loss_4': 0.7200661897659302, 'epoch': 20.27}
{'loss': 0.0141, 'grad_norm': 6.835521221160889, 'learning_rate': 9.75e-06, 'loss_1': 0.009944479912519455, 'loss_2': 0.00415802001953125, 'loss_3': -16.406253814697266, 'loss_4': -0.01864786446094513, 'epoch': 20.27}
{'loss': 0.0123, 'grad_norm': 5.630878925323486, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.007907712832093239, 'loss_2': 0.00437164306640625, 'loss_3': -16.600399017333984, 'loss_4': 0.5765790343284607, 'epoch': 20.28}
{'loss': 0.0215, 'grad_norm': 8.52686882019043, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.013762511312961578, 'loss_2': 0.007781982421875, 'loss_3': -16.317317962646484, 'loss_4': -0.09555753320455551, 'epoch': 20.28}
{'loss': 0.0063, 'grad_norm': 5.142927169799805, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.005866960622370243, 'loss_2': 0.0004367828369140625, 'loss_3': -16.512006759643555, 'loss_4': 0.7765607833862305, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 10:52:33,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:33,230 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:00<28:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:52:40,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009855429641902447, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.334, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0075976066291332245, 'eval_loss_2': 0.002257823944091797, 'eval_loss_3': -18.219650268554688, 'eval_loss_4': 0.5097488760948181, 'epoch': 20.29}
{'loss': 0.0098, 'grad_norm': 5.105659484863281, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.00676965806633234, 'loss_2': 0.003025054931640625, 'loss_3': -16.37314224243164, 'loss_4': 0.31457996368408203, 'epoch': 20.3}
{'loss': 0.0358, 'grad_norm': 11.487016677856445, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.03320835158228874, 'loss_2': 0.002574920654296875, 'loss_3': -16.452178955078125, 'loss_4': 0.6491315364837646, 'epoch': 20.3}
{'loss': 0.0144, 'grad_norm': 8.652297019958496, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.011727700009942055, 'loss_2': 0.002651214599609375, 'loss_3': -16.429317474365234, 'loss_4': 0.9425653219223022, 'epoch': 20.31}
{'loss': 0.015, 'grad_norm': 6.914588451385498, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.011428729631006718, 'loss_2': 0.003604888916015625, 'loss_3': -16.351333618164062, 'loss_4': 0.06381985545158386, 'epoch': 20.31}
{'loss': 0.0051, 'grad_norm': 4.9163384437561035, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.004477782640606165, 'loss_2': 0.0005779266357421875, 'loss_3': -16.425556182861328, 'loss_4': 0.5416249632835388, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 10:52:40,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:40,557 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:07<28:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:47,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011233835481107235, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.042, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007757304701954126, 'eval_loss_2': 0.0034765303134918213, 'eval_loss_3': -18.2237606048584, 'eval_loss_4': 0.641384482383728, 'epoch': 20.32}
{'loss': 0.0112, 'grad_norm': 5.280849933624268, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.00990571454167366, 'loss_2': 0.001331329345703125, 'loss_3': -16.25849151611328, 'loss_4': 0.3897775709629059, 'epoch': 20.33}
{'loss': 0.0136, 'grad_norm': 5.459325313568115, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.009047484956681728, 'loss_2': 0.004547119140625, 'loss_3': -16.5704345703125, 'loss_4': 0.7944159507751465, 'epoch': 20.33}
{'loss': 0.0117, 'grad_norm': 6.339305877685547, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.010852690786123276, 'loss_2': 0.0008959770202636719, 'loss_3': -16.549495697021484, 'loss_4': 0.5298843383789062, 'epoch': 20.34}
{'loss': 0.013, 'grad_norm': 4.918533802032471, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.008563315495848656, 'loss_2': 0.0044097900390625, 'loss_3': -16.49538803100586, 'loss_4': 0.7823126316070557, 'epoch': 20.34}
{'loss': 0.0108, 'grad_norm': 6.48122501373291, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.00987634714692831, 'loss_2': 0.0009217262268066406, 'loss_3': -16.337432861328125, 'loss_4': 0.8758467435836792, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 10:52:47,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:47,897 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:15<28:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:55,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011716954410076141, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.339, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007999262772500515, 'eval_loss_2': 0.0037176907062530518, 'eval_loss_3': -18.23279571533203, 'eval_loss_4': 0.6898530721664429, 'epoch': 20.35}
{'loss': 0.0362, 'grad_norm': 20.794384002685547, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.03223685547709465, 'loss_2': 0.003997802734375, 'loss_3': -16.34160804748535, 'loss_4': 1.0261147022247314, 'epoch': 20.35}
{'loss': 0.025, 'grad_norm': 11.110945701599121, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.023886820301413536, 'loss_2': 0.001068115234375, 'loss_3': -16.408557891845703, 'loss_4': 0.7799575328826904, 'epoch': 20.36}
{'loss': 0.008, 'grad_norm': 5.086235046386719, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.005623589735478163, 'loss_2': 0.002349853515625, 'loss_3': -16.464937210083008, 'loss_4': 0.8222610950469971, 'epoch': 20.37}
{'loss': 0.023, 'grad_norm': 7.203315734863281, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.019249919801950455, 'loss_2': 0.00377655029296875, 'loss_3': -16.643301010131836, 'loss_4': 0.6871055364608765, 'epoch': 20.37}
{'loss': 0.0128, 'grad_norm': 7.162692546844482, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.012502970173954964, 'loss_2': 0.0003123283386230469, 'loss_3': -16.315372467041016, 'loss_4': 0.8960123062133789, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 10:52:55,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:55,232 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:22<28:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:02,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009831149131059647, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.494, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006996053736656904, 'eval_loss_2': 0.002835094928741455, 'eval_loss_3': -18.24350929260254, 'eval_loss_4': 0.6578720808029175, 'epoch': 20.38}
{'loss': 0.0108, 'grad_norm': 7.635107040405273, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.00813134852796793, 'loss_2': 0.00262451171875, 'loss_3': -16.129959106445312, 'loss_4': 0.8060165643692017, 'epoch': 20.38}
{'loss': 0.0096, 'grad_norm': 5.764012813568115, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.009173673577606678, 'loss_2': 0.0004038810729980469, 'loss_3': -16.298995971679688, 'loss_4': 0.36862248182296753, 'epoch': 20.39}
{'loss': 0.0148, 'grad_norm': 5.2190423011779785, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.008853502571582794, 'loss_2': 0.0059814453125, 'loss_3': -16.478755950927734, 'loss_4': 0.5425906181335449, 'epoch': 20.4}
{'loss': 0.0125, 'grad_norm': 4.445878982543945, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.0034126504324376583, 'loss_2': 0.00908660888671875, 'loss_3': -16.61833381652832, 'loss_4': 0.9318668842315674, 'epoch': 20.4}
{'loss': 0.0111, 'grad_norm': 4.921420574188232, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.005745020229369402, 'loss_2': 0.0053558349609375, 'loss_3': -16.517698287963867, 'loss_4': 0.49066483974456787, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 10:53:02,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:02,553 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:29<28:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:09,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009700038470327854, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006883241236209869, 'eval_loss_2': 0.00281679630279541, 'eval_loss_3': -18.24311065673828, 'eval_loss_4': 0.6578423380851746, 'epoch': 20.41}
{'loss': 0.0156, 'grad_norm': 5.072583198547363, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.008414006792008877, 'loss_2': 0.0072174072265625, 'loss_3': -16.58605194091797, 'loss_4': 0.4230858087539673, 'epoch': 20.41}
{'loss': 0.0287, 'grad_norm': 15.026968002319336, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.022693675011396408, 'loss_2': 0.006011962890625, 'loss_3': -16.354459762573242, 'loss_4': 0.3487221598625183, 'epoch': 20.42}
{'loss': 0.013, 'grad_norm': 4.773575782775879, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.007541233208030462, 'loss_2': 0.00542449951171875, 'loss_3': -16.464731216430664, 'loss_4': 0.7260021567344666, 'epoch': 20.42}
{'loss': 0.009, 'grad_norm': 5.355778217315674, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.008449232205748558, 'loss_2': 0.0005397796630859375, 'loss_3': -16.44083595275879, 'loss_4': 0.3578624129295349, 'epoch': 20.43}
{'loss': 0.008, 'grad_norm': 4.932409286499023, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.0064428383484482765, 'loss_2': 0.001529693603515625, 'loss_3': -16.553695678710938, 'loss_4': 0.8400205373764038, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 10:53:09,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:09,881 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:37<28:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:17,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010373970493674278, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006769991014152765, 'eval_loss_2': 0.0036039799451828003, 'eval_loss_3': -18.25299644470215, 'eval_loss_4': 0.7781014442443848, 'epoch': 20.44}
{'loss': 0.0089, 'grad_norm': 4.70046329498291, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.007107354234904051, 'loss_2': 0.0017786026000976562, 'loss_3': -16.644197463989258, 'loss_4': 0.9675641655921936, 'epoch': 20.44}
{'loss': 0.0094, 'grad_norm': 4.552979946136475, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.0054901461116969585, 'loss_2': 0.0039520263671875, 'loss_3': -16.63743019104004, 'loss_4': 0.3437269926071167, 'epoch': 20.45}
{'loss': 0.008, 'grad_norm': 4.609095573425293, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.005069295410066843, 'loss_2': 0.002887725830078125, 'loss_3': -16.368999481201172, 'loss_4': 0.6053894758224487, 'epoch': 20.45}
{'loss': 0.0066, 'grad_norm': 4.490992069244385, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.0047436547465622425, 'loss_2': 0.0018157958984375, 'loss_3': -16.572635650634766, 'loss_4': 0.07038955390453339, 'epoch': 20.46}
{'loss': 0.0049, 'grad_norm': 4.738875389099121, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.004183223005384207, 'loss_2': 0.0006785392761230469, 'loss_3': -16.41973114013672, 'loss_4': 0.38342079520225525, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 10:53:17,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:17,214 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:26:44<28:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:24,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010541535913944244, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.247, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006651885807514191, 'eval_loss_2': 0.0038896501064300537, 'eval_loss_3': -18.24005889892578, 'eval_loss_4': 0.8273093104362488, 'epoch': 20.47}
{'loss': 0.0081, 'grad_norm': 5.5238823890686035, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.007403848692774773, 'loss_2': 0.0006871223449707031, 'loss_3': -16.239723205566406, 'loss_4': 1.177310824394226, 'epoch': 20.47}
{'loss': 0.0095, 'grad_norm': 4.445866107940674, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.005211012903600931, 'loss_2': 0.004241943359375, 'loss_3': -16.444610595703125, 'loss_4': 1.0702016353607178, 'epoch': 20.48}
{'loss': 0.0179, 'grad_norm': 9.578852653503418, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.013370215892791748, 'loss_2': 0.0045166015625, 'loss_3': -16.515100479125977, 'loss_4': 1.005477786064148, 'epoch': 20.48}
{'loss': 0.0065, 'grad_norm': 4.803530216217041, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.0049442509189248085, 'loss_2': 0.0015697479248046875, 'loss_3': -16.424856185913086, 'loss_4': 0.9580832719802856, 'epoch': 20.49}
{'loss': 0.0091, 'grad_norm': 4.8649067878723145, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.006939074955880642, 'loss_2': 0.002147674560546875, 'loss_3': -16.414276123046875, 'loss_4': 0.9728795289993286, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 10:53:24,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:24,545 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:26:51<28:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:31,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011500203981995583, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007163072470575571, 'eval_loss_2': 0.004337131977081299, 'eval_loss_3': -18.231239318847656, 'eval_loss_4': 0.8624680042266846, 'epoch': 20.49}
{'loss': 0.0211, 'grad_norm': 9.640275001525879, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.012014561332762241, 'loss_2': 0.00907135009765625, 'loss_3': -16.230518341064453, 'loss_4': 0.7745503783226013, 'epoch': 20.5}
{'loss': 0.0074, 'grad_norm': 4.6297430992126465, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.005254524759948254, 'loss_2': 0.002132415771484375, 'loss_3': -16.59868812561035, 'loss_4': 0.8467397689819336, 'epoch': 20.51}
{'loss': 0.0209, 'grad_norm': 4.9461188316345215, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.0065092891454696655, 'loss_2': 0.0144195556640625, 'loss_3': -16.354095458984375, 'loss_4': 0.6017486453056335, 'epoch': 20.51}
{'loss': 0.0125, 'grad_norm': 10.863868713378906, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.012230323627591133, 'loss_2': 0.00026535987854003906, 'loss_3': -16.371017456054688, 'loss_4': 0.47382575273513794, 'epoch': 20.52}
{'loss': 0.0353, 'grad_norm': 11.863791465759277, 'learning_rate': 9.5e-06, 'loss_1': 0.02871999330818653, 'loss_2': 0.00655364990234375, 'loss_3': -16.538379669189453, 'loss_4': 0.9295281171798706, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 10:53:31,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:31,888 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:26:59<28:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:53:39,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010820003226399422, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.452, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006666632369160652, 'eval_loss_2': 0.0041533708572387695, 'eval_loss_3': -18.247787475585938, 'eval_loss_4': 0.7784026861190796, 'epoch': 20.52}
{'loss': 0.0075, 'grad_norm': 4.8520283699035645, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.0031426993664354086, 'loss_2': 0.004364013671875, 'loss_3': -16.572956085205078, 'loss_4': 1.0165436267852783, 'epoch': 20.53}
{'loss': 0.009, 'grad_norm': 5.332941055297852, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.006654903292655945, 'loss_2': 0.002338409423828125, 'loss_3': -16.47490692138672, 'loss_4': 1.1883090734481812, 'epoch': 20.53}
{'loss': 0.0079, 'grad_norm': 4.159498691558838, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.0038179971743375063, 'loss_2': 0.00408935546875, 'loss_3': -16.64162826538086, 'loss_4': 1.150844931602478, 'epoch': 20.54}
{'loss': 0.0242, 'grad_norm': 8.76082706451416, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.021959736943244934, 'loss_2': 0.002288818359375, 'loss_3': -16.31000518798828, 'loss_4': 0.8653481006622314, 'epoch': 20.55}
{'loss': 0.016, 'grad_norm': 6.163311004638672, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.015147211961448193, 'loss_2': 0.0008716583251953125, 'loss_3': -16.362529754638672, 'loss_4': 0.5380995869636536, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 10:53:39,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:39,206 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:06<27:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:46,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010564273223280907, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.362, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.00688815675675869, 'eval_loss_2': 0.003676116466522217, 'eval_loss_3': -18.25389862060547, 'eval_loss_4': 0.6643527746200562, 'epoch': 20.55}
{'loss': 0.0119, 'grad_norm': 5.2455010414123535, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.010121080093085766, 'loss_2': 0.0017719268798828125, 'loss_3': -16.4786376953125, 'loss_4': 0.8458030223846436, 'epoch': 20.56}
{'loss': 0.0114, 'grad_norm': 5.056724548339844, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.005150534212589264, 'loss_2': 0.0062255859375, 'loss_3': -16.357624053955078, 'loss_4': 0.45662420988082886, 'epoch': 20.56}
{'loss': 0.0068, 'grad_norm': 4.759611129760742, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.00409659743309021, 'loss_2': 0.002750396728515625, 'loss_3': -16.37161636352539, 'loss_4': 0.4989553987979889, 'epoch': 20.57}
{'loss': 0.0084, 'grad_norm': 5.707075595855713, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.007677468005567789, 'loss_2': 0.0007696151733398438, 'loss_3': -16.52971649169922, 'loss_4': 0.5484527945518494, 'epoch': 20.58}
{'loss': 0.0102, 'grad_norm': 4.887480735778809, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.008559251204133034, 'loss_2': 0.0016002655029296875, 'loss_3': -16.471431732177734, 'loss_4': 0.4597930908203125, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 10:53:46,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:46,535 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:13<27:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:53:53,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0119923185557127, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.587, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007555527146905661, 'eval_loss_2': 0.004436790943145752, 'eval_loss_3': -18.2346134185791, 'eval_loss_4': 0.5954505801200867, 'epoch': 20.58}
{'loss': 0.0067, 'grad_norm': 5.18126916885376, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.004691074136644602, 'loss_2': 0.001987457275390625, 'loss_3': -16.479942321777344, 'loss_4': 0.6140509247779846, 'epoch': 20.59}
{'loss': 0.0095, 'grad_norm': 4.637746334075928, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.007260679267346859, 'loss_2': 0.002254486083984375, 'loss_3': -16.332237243652344, 'loss_4': 0.6270179152488708, 'epoch': 20.59}
{'loss': 0.0339, 'grad_norm': 11.749024391174316, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.03128964826464653, 'loss_2': 0.0026531219482421875, 'loss_3': -16.34806251525879, 'loss_4': 0.7314527034759521, 'epoch': 20.6}
{'loss': 0.0089, 'grad_norm': 4.6053972244262695, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.006009325850754976, 'loss_2': 0.002902984619140625, 'loss_3': -16.47225570678711, 'loss_4': 0.5634791851043701, 'epoch': 20.6}
{'loss': 0.0237, 'grad_norm': 14.417335510253906, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.02155420184135437, 'loss_2': 0.0021514892578125, 'loss_3': -16.634815216064453, 'loss_4': 0.9568063020706177, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 10:53:53,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:53,856 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:20<27:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:54:01,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011691565625369549, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.401, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00818499457091093, 'eval_loss_2': 0.003506571054458618, 'eval_loss_3': -18.193252563476562, 'eval_loss_4': 0.5150454044342041, 'epoch': 20.61}
{'loss': 0.0219, 'grad_norm': 6.052042484283447, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.012585208751261234, 'loss_2': 0.00933837890625, 'loss_3': -16.482690811157227, 'loss_4': 0.639080286026001, 'epoch': 20.62}
{'loss': 0.0057, 'grad_norm': 4.791555881500244, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.004882816690951586, 'loss_2': 0.00078582763671875, 'loss_3': -16.53734588623047, 'loss_4': 0.17912383377552032, 'epoch': 20.62}
{'loss': 0.0118, 'grad_norm': 4.587986469268799, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.004944033920764923, 'loss_2': 0.006900787353515625, 'loss_3': -16.362510681152344, 'loss_4': 0.292729914188385, 'epoch': 20.63}
{'loss': 0.016, 'grad_norm': 6.826034069061279, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.014149008318781853, 'loss_2': 0.001865386962890625, 'loss_3': -16.37679672241211, 'loss_4': 0.38086050748825073, 'epoch': 20.63}
{'loss': 0.0138, 'grad_norm': 6.207065105438232, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.00954124704003334, 'loss_2': 0.004241943359375, 'loss_3': -16.383621215820312, 'loss_4': 0.678239107131958, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 10:54:01,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:01,178 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:28<27:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:08,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012947937473654747, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.797, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009472941979765892, 'eval_loss_2': 0.003474995493888855, 'eval_loss_3': -18.17967987060547, 'eval_loss_4': 0.4844243824481964, 'epoch': 20.64}
{'loss': 0.0039, 'grad_norm': 4.7983527183532715, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.003738424740731716, 'loss_2': 0.00020051002502441406, 'loss_3': -16.373369216918945, 'loss_4': 0.3885571360588074, 'epoch': 20.65}
{'loss': 0.0144, 'grad_norm': 6.295059680938721, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.008666475303471088, 'loss_2': 0.005718231201171875, 'loss_3': -16.51321792602539, 'loss_4': 0.5140131115913391, 'epoch': 20.65}
{'loss': 0.0196, 'grad_norm': 9.082612991333008, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.014133043587207794, 'loss_2': 0.00542449951171875, 'loss_3': -16.622905731201172, 'loss_4': 0.10728999972343445, 'epoch': 20.66}
{'loss': 0.0158, 'grad_norm': 8.216487884521484, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.01205352135002613, 'loss_2': 0.003719329833984375, 'loss_3': -16.431673049926758, 'loss_4': 0.49980705976486206, 'epoch': 20.66}
{'loss': 0.02, 'grad_norm': 11.571632385253906, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.015309914015233517, 'loss_2': 0.004673004150390625, 'loss_3': -16.358753204345703, 'loss_4': 0.4873351752758026, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 10:54:08,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:08,515 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:35<27:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:54:15,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014421951025724411, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.511, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.010938460007309914, 'eval_loss_2': 0.003483489155769348, 'eval_loss_3': -18.17279815673828, 'eval_loss_4': 0.5688568353652954, 'epoch': 20.67}
{'loss': 0.0109, 'grad_norm': 5.059360504150391, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.008220518007874489, 'loss_2': 0.0026721954345703125, 'loss_3': -16.544456481933594, 'loss_4': 0.3082273602485657, 'epoch': 20.67}
{'loss': 0.0196, 'grad_norm': 9.169620513916016, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.01810462400317192, 'loss_2': 0.0014495849609375, 'loss_3': -16.45953369140625, 'loss_4': 0.7037234306335449, 'epoch': 20.68}
{'loss': 0.0213, 'grad_norm': 9.277663230895996, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.0153095917776227, 'loss_2': 0.005947113037109375, 'loss_3': -16.206470489501953, 'loss_4': 0.38350555300712585, 'epoch': 20.69}
{'loss': 0.0105, 'grad_norm': 5.212547779083252, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.006718232296407223, 'loss_2': 0.0038204193115234375, 'loss_3': -16.139320373535156, 'loss_4': 0.2023039013147354, 'epoch': 20.69}
{'loss': 0.0084, 'grad_norm': 4.885890007019043, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.006603235844522715, 'loss_2': 0.001781463623046875, 'loss_3': -16.607831954956055, 'loss_4': 0.19532836973667145, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 10:54:15,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:15,839 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:42<27:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:23,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015613464638590813, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.477, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.011621668934822083, 'eval_loss_2': 0.003991797566413879, 'eval_loss_3': -18.14488410949707, 'eval_loss_4': 0.6670215129852295, 'epoch': 20.7}
{'loss': 0.0093, 'grad_norm': 4.4588799476623535, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.004039634484797716, 'loss_2': 0.005306243896484375, 'loss_3': -16.428768157958984, 'loss_4': 0.15979449450969696, 'epoch': 20.7}
{'loss': 0.0168, 'grad_norm': 10.55034351348877, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.014475259929895401, 'loss_2': 0.002300262451171875, 'loss_3': -16.446928024291992, 'loss_4': 0.7558582425117493, 'epoch': 20.71}
{'loss': 0.0114, 'grad_norm': 5.422658443450928, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.011050170287489891, 'loss_2': 0.0003218650817871094, 'loss_3': -16.400867462158203, 'loss_4': 0.5997467041015625, 'epoch': 20.72}
{'loss': 0.0115, 'grad_norm': 5.739206314086914, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.00950087420642376, 'loss_2': 0.0020294189453125, 'loss_3': -16.342327117919922, 'loss_4': 0.6511849761009216, 'epoch': 20.72}
{'loss': 0.0109, 'grad_norm': 5.066138744354248, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.00967622734606266, 'loss_2': 0.0012416839599609375, 'loss_3': -16.385196685791016, 'loss_4': 0.3976469039916992, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 10:54:23,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:23,166 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:27:50<27:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:30,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016756970435380936, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.523, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.012072820216417313, 'eval_loss_2': 0.004684150218963623, 'eval_loss_3': -18.13823699951172, 'eval_loss_4': 0.706830620765686, 'epoch': 20.73}
{'loss': 0.0151, 'grad_norm': 5.4173994064331055, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.009171932935714722, 'loss_2': 0.00589752197265625, 'loss_3': -16.260234832763672, 'loss_4': 0.378445565700531, 'epoch': 20.73}
{'loss': 0.0122, 'grad_norm': 4.544483661651611, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.005914685316383839, 'loss_2': 0.0062408447265625, 'loss_3': -16.438587188720703, 'loss_4': 0.6782625913619995, 'epoch': 20.74}
{'loss': 0.0232, 'grad_norm': 8.26162338256836, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.019092584028840065, 'loss_2': 0.004070281982421875, 'loss_3': -16.125385284423828, 'loss_4': 0.620208740234375, 'epoch': 20.74}
{'loss': 0.0096, 'grad_norm': 4.783154010772705, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.0037761153653264046, 'loss_2': 0.00586700439453125, 'loss_3': -16.424758911132812, 'loss_4': 0.7099562883377075, 'epoch': 20.75}
{'loss': 0.0145, 'grad_norm': 9.576245307922363, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.013483733870089054, 'loss_2': 0.0010528564453125, 'loss_3': -16.287036895751953, 'loss_4': 0.7964417934417725, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 10:54:30,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:30,494 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:27:57<27:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:54:37,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01766539365053177, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.666, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.012207974679768085, 'eval_loss_2': 0.0054574161767959595, 'eval_loss_3': -18.15886116027832, 'eval_loss_4': 0.8118693828582764, 'epoch': 20.76}
{'loss': 0.008, 'grad_norm': 5.213102340698242, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.007804942782968283, 'loss_2': 0.0002295970916748047, 'loss_3': -16.29033088684082, 'loss_4': 0.8076862096786499, 'epoch': 20.76}
{'loss': 0.0129, 'grad_norm': 5.929610729217529, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.009880470111966133, 'loss_2': 0.0030078887939453125, 'loss_3': -16.292224884033203, 'loss_4': 0.8596083521842957, 'epoch': 20.77}
{'loss': 0.0148, 'grad_norm': 5.12328577041626, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.0045842370018363, 'loss_2': 0.01024627685546875, 'loss_3': -16.469053268432617, 'loss_4': 0.7778522372245789, 'epoch': 20.77}
{'loss': 0.0065, 'grad_norm': 4.917387962341309, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.006012459751218557, 'loss_2': 0.0004534721374511719, 'loss_3': -16.379390716552734, 'loss_4': 0.6650026440620422, 'epoch': 20.78}
{'loss': 0.0124, 'grad_norm': 5.062952995300293, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.007651733700186014, 'loss_2': 0.0047607421875, 'loss_3': -16.398231506347656, 'loss_4': 0.9467211365699768, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 10:54:37,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:37,817 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:04<27:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:54:45,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014698008075356483, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.579, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.010343052446842194, 'eval_loss_2': 0.004354953765869141, 'eval_loss_3': -18.17774772644043, 'eval_loss_4': 0.9167742133140564, 'epoch': 20.78}
{'loss': 0.0116, 'grad_norm': 4.965582847595215, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.0059906295500695705, 'loss_2': 0.0055999755859375, 'loss_3': -16.273151397705078, 'loss_4': 0.3533836007118225, 'epoch': 20.79}
{'loss': 0.0185, 'grad_norm': 7.731057167053223, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.015224317088723183, 'loss_2': 0.00327301025390625, 'loss_3': -16.48700714111328, 'loss_4': 0.9198075532913208, 'epoch': 20.8}
{'loss': 0.014, 'grad_norm': 6.340198040008545, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.011810338124632835, 'loss_2': 0.002178192138671875, 'loss_3': -16.416946411132812, 'loss_4': 0.7048375010490417, 'epoch': 20.8}
{'loss': 0.0219, 'grad_norm': 15.162250518798828, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.02133292518556118, 'loss_2': 0.0005407333374023438, 'loss_3': -16.443904876708984, 'loss_4': 0.728778600692749, 'epoch': 20.81}
{'loss': 0.0107, 'grad_norm': 5.0294060707092285, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.007477180566638708, 'loss_2': 0.0032215118408203125, 'loss_3': -16.63509750366211, 'loss_4': 1.0657367706298828, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 10:54:45,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:45,133 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:12<27:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:52,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013639343902468681, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010655922815203667, 'eval_loss_2': 0.0029834210872650146, 'eval_loss_3': -18.183692932128906, 'eval_loss_4': 1.0732905864715576, 'epoch': 20.81}
{'loss': 0.0054, 'grad_norm': 4.496428489685059, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.00527248065918684, 'loss_2': 7.784366607666016e-05, 'loss_3': -16.558143615722656, 'loss_4': 1.022486925125122, 'epoch': 20.82}
{'loss': 0.0237, 'grad_norm': 10.421488761901855, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.020161181688308716, 'loss_2': 0.0035381317138671875, 'loss_3': -16.115589141845703, 'loss_4': 1.4310499429702759, 'epoch': 20.83}
{'loss': 0.0145, 'grad_norm': 5.060293197631836, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.01043245755136013, 'loss_2': 0.004058837890625, 'loss_3': -16.358104705810547, 'loss_4': 1.0246716737747192, 'epoch': 20.83}
{'loss': 0.0167, 'grad_norm': 7.323806285858154, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.011977304704487324, 'loss_2': 0.00469970703125, 'loss_3': -16.380054473876953, 'loss_4': 0.7494232654571533, 'epoch': 20.84}
{'loss': 0.0071, 'grad_norm': 5.270979881286621, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.006604728754609823, 'loss_2': 0.0004799365997314453, 'loss_3': -16.40007209777832, 'loss_4': 0.9409703016281128, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 10:54:52,475 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:52,475 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:19<27:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:54:59,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011790146119892597, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.303, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00864279642701149, 'eval_loss_2': 0.0031473487615585327, 'eval_loss_3': -18.213409423828125, 'eval_loss_4': 1.2073434591293335, 'epoch': 20.84}
{'loss': 0.0089, 'grad_norm': 5.258173942565918, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.007012488320469856, 'loss_2': 0.0018529891967773438, 'loss_3': -16.502145767211914, 'loss_4': 1.2266887426376343, 'epoch': 20.85}
{'loss': 0.0112, 'grad_norm': 6.147799491882324, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.009915757924318314, 'loss_2': 0.0013179779052734375, 'loss_3': -16.367576599121094, 'loss_4': 1.0312955379486084, 'epoch': 20.85}
{'loss': 0.0144, 'grad_norm': 8.42769718170166, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.013325238600373268, 'loss_2': 0.0010814666748046875, 'loss_3': -16.367027282714844, 'loss_4': 1.1464242935180664, 'epoch': 20.86}
{'loss': 0.0119, 'grad_norm': 5.303424835205078, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.009181659668684006, 'loss_2': 0.002685546875, 'loss_3': -16.412155151367188, 'loss_4': 1.411625623703003, 'epoch': 20.87}
{'loss': 0.0136, 'grad_norm': 6.361163139343262, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.011852876283228397, 'loss_2': 0.00174713134765625, 'loss_3': -16.546977996826172, 'loss_4': 1.253720998764038, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 10:54:59,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:59,801 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:26<26:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:55:07,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010901190340518951, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.542, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007247545290738344, 'eval_loss_2': 0.0036536455154418945, 'eval_loss_3': -18.244096755981445, 'eval_loss_4': 1.2254160642623901, 'epoch': 20.87}
{'loss': 0.0074, 'grad_norm': 5.063493728637695, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.007329628337174654, 'loss_2': 3.731250762939453e-05, 'loss_3': -16.400531768798828, 'loss_4': 1.1793792247772217, 'epoch': 20.88}
{'loss': 0.0088, 'grad_norm': 5.499637603759766, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.007072067819535732, 'loss_2': 0.0017223358154296875, 'loss_3': -16.354999542236328, 'loss_4': 0.972008228302002, 'epoch': 20.88}
{'loss': 0.0196, 'grad_norm': 8.29623794555664, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.014573631808161736, 'loss_2': 0.005035400390625, 'loss_3': -16.508930206298828, 'loss_4': 1.2472970485687256, 'epoch': 20.89}
{'loss': 0.0131, 'grad_norm': 6.807652473449707, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.012661965563893318, 'loss_2': 0.00044417381286621094, 'loss_3': -16.35587501525879, 'loss_4': 1.371964931488037, 'epoch': 20.9}
{'loss': 0.0071, 'grad_norm': 4.63670015335083, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.005394198000431061, 'loss_2': 0.0017375946044921875, 'loss_3': -16.64845085144043, 'loss_4': 1.2553523778915405, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 10:55:07,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:07,122 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:34<26:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:14,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010807963088154793, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.426, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.007183725014328957, 'eval_loss_2': 0.003624238073825836, 'eval_loss_3': -18.27972412109375, 'eval_loss_4': 1.21254563331604, 'epoch': 20.9}
{'loss': 0.0098, 'grad_norm': 4.698510646820068, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.006761184427887201, 'loss_2': 0.00299072265625, 'loss_3': -16.57373046875, 'loss_4': 1.0448285341262817, 'epoch': 20.91}
{'loss': 0.008, 'grad_norm': 4.72859001159668, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.006513433530926704, 'loss_2': 0.0014629364013671875, 'loss_3': -16.612293243408203, 'loss_4': 1.1671780347824097, 'epoch': 20.91}
{'loss': 0.0079, 'grad_norm': 4.966283798217773, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.005705928895622492, 'loss_2': 0.002231597900390625, 'loss_3': -16.412860870361328, 'loss_4': 1.2320129871368408, 'epoch': 20.92}
{'loss': 0.0084, 'grad_norm': 4.909976959228516, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.007323068100959063, 'loss_2': 0.00107574462890625, 'loss_3': -16.382244110107422, 'loss_4': 1.5350675582885742, 'epoch': 20.92}
{'loss': 0.015, 'grad_norm': 5.225729465484619, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.009343559853732586, 'loss_2': 0.00560760498046875, 'loss_3': -16.449377059936523, 'loss_4': 1.6843458414077759, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 10:55:14,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:14,451 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:41<26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:21,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010674763470888138, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.533, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.007009405642747879, 'eval_loss_2': 0.003665357828140259, 'eval_loss_3': -18.287635803222656, 'eval_loss_4': 1.2620071172714233, 'epoch': 20.93}
{'loss': 0.0134, 'grad_norm': 5.163030624389648, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.007497504353523254, 'loss_2': 0.005886077880859375, 'loss_3': -16.45642852783203, 'loss_4': 1.2821613550186157, 'epoch': 20.94}
{'loss': 0.006, 'grad_norm': 4.531729221343994, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.0059217484667897224, 'loss_2': 9.298324584960938e-05, 'loss_3': -16.609939575195312, 'loss_4': 1.4211664199829102, 'epoch': 20.94}
{'loss': 0.0111, 'grad_norm': 4.341822624206543, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.006167507730424404, 'loss_2': 0.0048828125, 'loss_3': -16.56231117248535, 'loss_4': 1.2771731615066528, 'epoch': 20.95}
{'loss': 0.0074, 'grad_norm': 4.340691566467285, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.004830916877835989, 'loss_2': 0.0025577545166015625, 'loss_3': -16.566452026367188, 'loss_4': 1.1893450021743774, 'epoch': 20.95}
{'loss': 0.0204, 'grad_norm': 9.109914779663086, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.014819509349763393, 'loss_2': 0.005615234375, 'loss_3': -16.255094528198242, 'loss_4': 0.9721972346305847, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 10:55:21,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:21,776 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:28:48<26:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:29,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01034148596227169, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.623, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00721568800508976, 'eval_loss_2': 0.0031257979571819305, 'eval_loss_3': -18.294692993164062, 'eval_loss_4': 1.2837518453598022, 'epoch': 20.96}
{'loss': 0.0105, 'grad_norm': 4.7071428298950195, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.0066901626996695995, 'loss_2': 0.0037746429443359375, 'loss_3': -16.40094566345215, 'loss_4': 1.0837104320526123, 'epoch': 20.97}
{'loss': 0.0112, 'grad_norm': 5.094447135925293, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.010970894247293472, 'loss_2': 0.00025844573974609375, 'loss_3': -16.34696388244629, 'loss_4': 1.021816372871399, 'epoch': 20.97}
{'loss': 0.0166, 'grad_norm': 6.109731674194336, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.014017343521118164, 'loss_2': 0.002597808837890625, 'loss_3': -16.31572914123535, 'loss_4': 1.0696038007736206, 'epoch': 20.98}
{'loss': 0.0154, 'grad_norm': 4.97081995010376, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.005948178935796022, 'loss_2': 0.00948333740234375, 'loss_3': -16.410301208496094, 'loss_4': 1.5550572872161865, 'epoch': 20.98}
{'loss': 0.0129, 'grad_norm': 5.509384632110596, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.007719491608440876, 'loss_2': 0.005153656005859375, 'loss_3': -16.39653778076172, 'loss_4': 1.1977691650390625, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 10:55:29,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:29,105 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:28:55<25:52,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 10:55:36,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011048493906855583, 'eval_runtime': 3.7819, 'eval_samples_per_second': 270.761, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.00781928189098835, 'eval_loss_2': 0.0032292120158672333, 'eval_loss_3': -18.294450759887695, 'eval_loss_4': 1.2786184549331665, 'epoch': 20.99}
{'loss': 0.0117, 'grad_norm': 5.082403659820557, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.007793719414621592, 'loss_2': 0.00392913818359375, 'loss_3': -16.474321365356445, 'loss_4': 1.4912711381912231, 'epoch': 20.99}
{'loss': 0.0066, 'grad_norm': 5.834248065948486, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.0017349929548799992, 'loss_2': 0.0048370361328125, 'loss_3': -16.57635498046875, 'loss_4': 1.2793315649032593, 'epoch': 21.0}
{'loss': 0.011, 'grad_norm': 4.92416524887085, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.007320831995457411, 'loss_2': 0.0036640167236328125, 'loss_3': -16.438247680664062, 'loss_4': 1.258662223815918, 'epoch': 21.01}
{'loss': 0.0082, 'grad_norm': 4.9408278465271, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.007116090971976519, 'loss_2': 0.0010356903076171875, 'loss_3': -16.38212776184082, 'loss_4': 1.1157796382904053, 'epoch': 21.01}
{'loss': 0.0069, 'grad_norm': 4.833427429199219, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.0059608230367302895, 'loss_2': 0.0009565353393554688, 'loss_3': -16.479724884033203, 'loss_4': 1.389026165008545, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 10:55:36,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:36,110 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:03<26:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:55:43,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010572186671197414, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.343, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007395721971988678, 'eval_loss_2': 0.003176465630531311, 'eval_loss_3': -18.293472290039062, 'eval_loss_4': 1.326241374015808, 'epoch': 21.02}
{'loss': 0.0116, 'grad_norm': 5.700085639953613, 'learning_rate': 9e-06, 'loss_1': 0.009219643659889698, 'loss_2': 0.002376556396484375, 'loss_3': -16.34975242614746, 'loss_4': 1.4749512672424316, 'epoch': 21.02}
{'loss': 0.0082, 'grad_norm': 4.697580337524414, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.008081283420324326, 'loss_2': 0.00013875961303710938, 'loss_3': -16.34567642211914, 'loss_4': 1.3993090391159058, 'epoch': 21.03}
{'loss': 0.008, 'grad_norm': 4.990565776824951, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.005169140174984932, 'loss_2': 0.00283050537109375, 'loss_3': -16.417177200317383, 'loss_4': 1.3005479574203491, 'epoch': 21.03}
{'loss': 0.0076, 'grad_norm': 4.928155899047852, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.006165522150695324, 'loss_2': 0.0014801025390625, 'loss_3': -16.28065299987793, 'loss_4': 2.028399705886841, 'epoch': 21.04}
{'loss': 0.0096, 'grad_norm': 5.280019760131836, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.007263828534632921, 'loss_2': 0.0023479461669921875, 'loss_3': -16.461679458618164, 'loss_4': 1.6199145317077637, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 10:55:43,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:43,436 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:10<26:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:55:50,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01164573710411787, 'eval_runtime': 3.7822, 'eval_samples_per_second': 270.739, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.008066052570939064, 'eval_loss_2': 0.0035796836018562317, 'eval_loss_3': -18.2777156829834, 'eval_loss_4': 1.2584037780761719, 'epoch': 21.05}
{'loss': 0.0116, 'grad_norm': 5.347167015075684, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.006202710792422295, 'loss_2': 0.00542449951171875, 'loss_3': -16.327884674072266, 'loss_4': 1.3186969757080078, 'epoch': 21.05}
{'loss': 0.0091, 'grad_norm': 5.063239097595215, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.008013882674276829, 'loss_2': 0.0010833740234375, 'loss_3': -16.470054626464844, 'loss_4': 0.9991186261177063, 'epoch': 21.06}
{'loss': 0.0074, 'grad_norm': 4.652277946472168, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.005687172524631023, 'loss_2': 0.001705169677734375, 'loss_3': -16.494407653808594, 'loss_4': 1.611274242401123, 'epoch': 21.06}
{'loss': 0.0078, 'grad_norm': 4.665814399719238, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.005457447841763496, 'loss_2': 0.002346038818359375, 'loss_3': -16.516170501708984, 'loss_4': 1.1034752130508423, 'epoch': 21.07}
{'loss': 0.0081, 'grad_norm': 4.50345516204834, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.0042633237317204475, 'loss_2': 0.003864288330078125, 'loss_3': -16.520286560058594, 'loss_4': 1.3250060081481934, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 10:55:50,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:50,760 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:17<26:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:55:58,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011809156276285648, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.688, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.00822618417441845, 'eval_loss_2': 0.0035829730331897736, 'eval_loss_3': -18.27324676513672, 'eval_loss_4': 1.201886534690857, 'epoch': 21.08}
{'loss': 0.0147, 'grad_norm': 5.667251110076904, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.01155881118029356, 'loss_2': 0.003108978271484375, 'loss_3': -16.288089752197266, 'loss_4': 1.2497738599777222, 'epoch': 21.08}
{'loss': 0.0141, 'grad_norm': 4.9860639572143555, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.00871187262237072, 'loss_2': 0.0053558349609375, 'loss_3': -16.35870933532715, 'loss_4': 0.7686249613761902, 'epoch': 21.09}
{'loss': 0.0098, 'grad_norm': 4.526448726654053, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.006440883502364159, 'loss_2': 0.003360748291015625, 'loss_3': -16.346067428588867, 'loss_4': 0.9946606159210205, 'epoch': 21.09}
{'loss': 0.007, 'grad_norm': 5.061995506286621, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.0063477386720478535, 'loss_2': 0.0006656646728515625, 'loss_3': -16.50786781311035, 'loss_4': 1.365767002105713, 'epoch': 21.1}
{'loss': 0.007, 'grad_norm': 5.134693145751953, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.004879203625023365, 'loss_2': 0.0021419525146484375, 'loss_3': -16.524066925048828, 'loss_4': 0.99741530418396, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 10:55:58,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:58,077 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:25<26:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:05,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011486373841762543, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.571, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.007592522539198399, 'eval_loss_2': 0.0038938522338867188, 'eval_loss_3': -18.247217178344727, 'eval_loss_4': 1.1653625965118408, 'epoch': 21.1}
{'loss': 0.0185, 'grad_norm': 6.959823131561279, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.015326227992773056, 'loss_2': 0.0031337738037109375, 'loss_3': -16.366260528564453, 'loss_4': 1.3509186506271362, 'epoch': 21.11}
{'loss': 0.0132, 'grad_norm': 5.585245132446289, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.01171080395579338, 'loss_2': 0.0015239715576171875, 'loss_3': -16.378326416015625, 'loss_4': 1.4638311862945557, 'epoch': 21.12}
{'loss': 0.0143, 'grad_norm': 5.051292419433594, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.007170565892010927, 'loss_2': 0.00713348388671875, 'loss_3': -16.383514404296875, 'loss_4': 1.2923920154571533, 'epoch': 21.12}
{'loss': 0.014, 'grad_norm': 7.019951343536377, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.008670088835060596, 'loss_2': 0.005306243896484375, 'loss_3': -16.510608673095703, 'loss_4': 1.5441522598266602, 'epoch': 21.13}
{'loss': 0.0111, 'grad_norm': 5.086596965789795, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.004711690358817577, 'loss_2': 0.0063934326171875, 'loss_3': -16.486881256103516, 'loss_4': 1.183877944946289, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 10:56:05,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:05,404 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:32<26:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:12,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01207929290831089, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00821757409721613, 'eval_loss_2': 0.0038617178797721863, 'eval_loss_3': -18.226945877075195, 'eval_loss_4': 1.1429357528686523, 'epoch': 21.13}
{'loss': 0.0058, 'grad_norm': 4.72037410736084, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.00531731266528368, 'loss_2': 0.00048160552978515625, 'loss_3': -16.43024444580078, 'loss_4': 1.005076289176941, 'epoch': 21.14}
{'loss': 0.0046, 'grad_norm': 4.340211868286133, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.003269513137638569, 'loss_2': 0.001323699951171875, 'loss_3': -16.396350860595703, 'loss_4': 1.3546241521835327, 'epoch': 21.15}
{'loss': 0.0061, 'grad_norm': 4.7533464431762695, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.004480032715946436, 'loss_2': 0.00164031982421875, 'loss_3': -16.357303619384766, 'loss_4': 1.1583678722381592, 'epoch': 21.15}
{'loss': 0.0134, 'grad_norm': 5.0564799308776855, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.008253933861851692, 'loss_2': 0.00516510009765625, 'loss_3': -16.478195190429688, 'loss_4': 1.3082923889160156, 'epoch': 21.16}
{'loss': 0.0192, 'grad_norm': 8.204371452331543, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.01632607728242874, 'loss_2': 0.0028553009033203125, 'loss_3': -16.236299514770508, 'loss_4': 1.6141207218170166, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 10:56:12,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:12,742 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:39<26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:20,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012895612046122551, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.589, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.008268294855952263, 'eval_loss_2': 0.004627317190170288, 'eval_loss_3': -18.21741485595703, 'eval_loss_4': 1.1576032638549805, 'epoch': 21.16}
{'loss': 0.0091, 'grad_norm': 4.593316078186035, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.006566291209310293, 'loss_2': 0.0025501251220703125, 'loss_3': -16.37602996826172, 'loss_4': 1.5089187622070312, 'epoch': 21.17}
{'loss': 0.0154, 'grad_norm': 5.781862258911133, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.010806677863001823, 'loss_2': 0.00460052490234375, 'loss_3': -16.394289016723633, 'loss_4': 0.9189109206199646, 'epoch': 21.17}
{'loss': 0.008, 'grad_norm': 5.529011249542236, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.0046057370491325855, 'loss_2': 0.00342559814453125, 'loss_3': -16.46844482421875, 'loss_4': 1.1364562511444092, 'epoch': 21.18}
{'loss': 0.0107, 'grad_norm': 4.852359771728516, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.004182453267276287, 'loss_2': 0.00652313232421875, 'loss_3': -16.445653915405273, 'loss_4': 1.2624140977859497, 'epoch': 21.19}
{'loss': 0.0149, 'grad_norm': 5.552649021148682, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.01321069709956646, 'loss_2': 0.00168609619140625, 'loss_3': -16.48467254638672, 'loss_4': 1.0297569036483765, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 10:56:20,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:20,069 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:29:47<26:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:27,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012535842135548592, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.549, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.008240671828389168, 'eval_loss_2': 0.004295170307159424, 'eval_loss_3': -18.202497482299805, 'eval_loss_4': 1.1527724266052246, 'epoch': 21.19}
{'loss': 0.0128, 'grad_norm': 5.965597629547119, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.009381602518260479, 'loss_2': 0.003444671630859375, 'loss_3': -16.411537170410156, 'loss_4': 1.0705828666687012, 'epoch': 21.2}
{'loss': 0.0141, 'grad_norm': 5.034205913543701, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.009822448715567589, 'loss_2': 0.00426483154296875, 'loss_3': -16.26230812072754, 'loss_4': 0.7681102752685547, 'epoch': 21.2}
{'loss': 0.0142, 'grad_norm': 7.173175811767578, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.01313283946365118, 'loss_2': 0.0010929107666015625, 'loss_3': -16.298410415649414, 'loss_4': 1.3233054876327515, 'epoch': 21.21}
{'loss': 0.0054, 'grad_norm': 4.643082141876221, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.0026729588862508535, 'loss_2': 0.0027313232421875, 'loss_3': -16.472232818603516, 'loss_4': 1.1410284042358398, 'epoch': 21.22}
{'loss': 0.0105, 'grad_norm': 5.318328857421875, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.008799975737929344, 'loss_2': 0.0017070770263671875, 'loss_3': -16.338685989379883, 'loss_4': 1.3068100214004517, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 10:56:27,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:27,390 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:29:54<25:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:34,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013898489065468311, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.7, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.009537586942315102, 'eval_loss_2': 0.004360899329185486, 'eval_loss_3': -18.18071174621582, 'eval_loss_4': 1.1895630359649658, 'epoch': 21.22}
{'loss': 0.0049, 'grad_norm': 4.826547622680664, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.004510150291025639, 'loss_2': 0.0004067420959472656, 'loss_3': -16.36648178100586, 'loss_4': 1.102721929550171, 'epoch': 21.23}
{'loss': 0.0088, 'grad_norm': 4.563263416290283, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.006908731069415808, 'loss_2': 0.001873016357421875, 'loss_3': -16.352008819580078, 'loss_4': 1.357100009918213, 'epoch': 21.23}
{'loss': 0.0115, 'grad_norm': 4.739351749420166, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.005340851843357086, 'loss_2': 0.006145477294921875, 'loss_3': -16.424598693847656, 'loss_4': 0.9778625965118408, 'epoch': 21.24}
{'loss': 0.0149, 'grad_norm': 5.434459209442139, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.008276429027318954, 'loss_2': 0.006633758544921875, 'loss_3': -16.524456024169922, 'loss_4': 0.716238260269165, 'epoch': 21.24}
{'loss': 0.0096, 'grad_norm': 6.079176902770996, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.00813391711562872, 'loss_2': 0.0014619827270507812, 'loss_3': -16.294170379638672, 'loss_4': 1.3436229228973389, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 10:56:34,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:34,714 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:01<25:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:42,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016553379595279694, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.996, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010507664643228054, 'eval_loss_2': 0.006045714020729065, 'eval_loss_3': -18.18162727355957, 'eval_loss_4': 1.2335783243179321, 'epoch': 21.25}
{'loss': 0.009, 'grad_norm': 4.563892841339111, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.006848974619060755, 'loss_2': 0.002117156982421875, 'loss_3': -16.375083923339844, 'loss_4': 1.213608980178833, 'epoch': 21.26}
{'loss': 0.0154, 'grad_norm': 5.775017738342285, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.010549083352088928, 'loss_2': 0.00487518310546875, 'loss_3': -16.344806671142578, 'loss_4': 1.3075006008148193, 'epoch': 21.26}
{'loss': 0.0066, 'grad_norm': 4.863894939422607, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.004043261520564556, 'loss_2': 0.00251007080078125, 'loss_3': -16.490291595458984, 'loss_4': 1.0753638744354248, 'epoch': 21.27}
{'loss': 0.0182, 'grad_norm': 6.640413761138916, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.013570304028689861, 'loss_2': 0.0046539306640625, 'loss_3': -16.52975845336914, 'loss_4': 0.8274753093719482, 'epoch': 21.27}
{'loss': 0.0166, 'grad_norm': 6.05469274520874, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.008451064117252827, 'loss_2': 0.0081024169921875, 'loss_3': -16.270790100097656, 'loss_4': 0.9998950958251953, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 10:56:42,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:42,053 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:09<25:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:56:49,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015295838937163353, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.017, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010977602563798428, 'eval_loss_2': 0.0043182373046875, 'eval_loss_3': -18.18815040588379, 'eval_loss_4': 1.1896578073501587, 'epoch': 21.28}
{'loss': 0.0137, 'grad_norm': 6.575035572052002, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.010263058356940746, 'loss_2': 0.0034637451171875, 'loss_3': -16.170909881591797, 'loss_4': 0.8063832521438599, 'epoch': 21.28}
{'loss': 0.0195, 'grad_norm': 12.313614845275879, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.019423814490437508, 'loss_2': 6.967782974243164e-05, 'loss_3': -16.220260620117188, 'loss_4': 0.8892370462417603, 'epoch': 21.29}
{'loss': 0.0093, 'grad_norm': 4.685700416564941, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.00325585575774312, 'loss_2': 0.00600433349609375, 'loss_3': -16.361648559570312, 'loss_4': 1.1013487577438354, 'epoch': 21.3}
{'loss': 0.0068, 'grad_norm': 4.971195697784424, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.006545716896653175, 'loss_2': 0.00028586387634277344, 'loss_3': -16.260095596313477, 'loss_4': 0.9513305425643921, 'epoch': 21.3}
{'loss': 0.0054, 'grad_norm': 4.801234245300293, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0033930737990885973, 'loss_2': 0.0020503997802734375, 'loss_3': -16.454545974731445, 'loss_4': 1.0173903703689575, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 10:56:49,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:49,379 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:16<25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:56,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016393592581152916, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.012917435728013515, 'eval_loss_2': 0.003476157784461975, 'eval_loss_3': -18.15866470336914, 'eval_loss_4': 1.1694859266281128, 'epoch': 21.31}
{'loss': 0.017, 'grad_norm': 7.181535243988037, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.013750231824815273, 'loss_2': 0.003253936767578125, 'loss_3': -16.211551666259766, 'loss_4': 1.056699514389038, 'epoch': 21.31}
{'loss': 0.0115, 'grad_norm': 8.297565460205078, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.009186316281557083, 'loss_2': 0.002338409423828125, 'loss_3': -16.23584747314453, 'loss_4': 1.2673448324203491, 'epoch': 21.32}
{'loss': 0.0082, 'grad_norm': 4.564670085906982, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.006614344194531441, 'loss_2': 0.0016231536865234375, 'loss_3': -16.365642547607422, 'loss_4': 1.1786234378814697, 'epoch': 21.33}
{'loss': 0.0088, 'grad_norm': 5.89425802230835, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.0071451314724981785, 'loss_2': 0.00167083740234375, 'loss_3': -16.297706604003906, 'loss_4': 1.1993039846420288, 'epoch': 21.33}
{'loss': 0.0115, 'grad_norm': 4.757724761962891, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.006454803980886936, 'loss_2': 0.00501251220703125, 'loss_3': -16.164690017700195, 'loss_4': 1.152044415473938, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 10:56:56,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:56,724 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:23<25:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:04,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01902296207845211, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.744, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01623566262423992, 'eval_loss_2': 0.0027872994542121887, 'eval_loss_3': -18.124557495117188, 'eval_loss_4': 1.2909533977508545, 'epoch': 21.34}
{'loss': 0.0072, 'grad_norm': 5.4745097160339355, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.006802849471569061, 'loss_2': 0.0003523826599121094, 'loss_3': -16.464811325073242, 'loss_4': 1.184990406036377, 'epoch': 21.34}
{'loss': 0.0131, 'grad_norm': 4.959693908691406, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.005645079538226128, 'loss_2': 0.00749969482421875, 'loss_3': -16.344459533691406, 'loss_4': 1.4387112855911255, 'epoch': 21.35}
{'loss': 0.0109, 'grad_norm': 4.592008113861084, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.005377739667892456, 'loss_2': 0.00554656982421875, 'loss_3': -16.054391860961914, 'loss_4': 1.4003806114196777, 'epoch': 21.35}
{'loss': 0.0065, 'grad_norm': 4.506065368652344, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.004220276139676571, 'loss_2': 0.002307891845703125, 'loss_3': -16.303081512451172, 'loss_4': 1.170804500579834, 'epoch': 21.36}
{'loss': 0.0099, 'grad_norm': 5.843703746795654, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.008516574278473854, 'loss_2': 0.0014190673828125, 'loss_3': -16.483917236328125, 'loss_4': 1.4384377002716064, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 10:57:04,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:04,058 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:31<25:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:57:11,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024722043424844742, 'eval_runtime': 3.7802, 'eval_samples_per_second': 270.887, 'eval_steps_per_second': 4.233, 'eval_loss_1': 0.021660614758729935, 'eval_loss_2': 0.003061428666114807, 'eval_loss_3': -18.1043701171875, 'eval_loss_4': 1.3606820106506348, 'epoch': 21.37}
{'loss': 0.0129, 'grad_norm': 5.724606513977051, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.00850638560950756, 'loss_2': 0.0044403076171875, 'loss_3': -16.416460037231445, 'loss_4': 0.919607400894165, 'epoch': 21.37}
{'loss': 0.0124, 'grad_norm': 7.603542804718018, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.009622263722121716, 'loss_2': 0.00278472900390625, 'loss_3': -16.295639038085938, 'loss_4': 0.6128879189491272, 'epoch': 21.38}
{'loss': 0.0156, 'grad_norm': 8.736387252807617, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.011808238923549652, 'loss_2': 0.0037822723388671875, 'loss_3': -16.47780990600586, 'loss_4': 1.5627036094665527, 'epoch': 21.38}
{'loss': 0.0235, 'grad_norm': 8.070243835449219, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.016980038955807686, 'loss_2': 0.0065460205078125, 'loss_3': -16.033498764038086, 'loss_4': 0.8446102142333984, 'epoch': 21.39}
{'loss': 0.0222, 'grad_norm': 7.121809959411621, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.010733595117926598, 'loss_2': 0.01145172119140625, 'loss_3': -16.123008728027344, 'loss_4': 1.1895442008972168, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 10:57:11,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:11,372 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:38<25:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:18,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03310356289148331, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.984, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.029467865824699402, 'eval_loss_2': 0.003635704517364502, 'eval_loss_3': -18.068817138671875, 'eval_loss_4': 1.4040769338607788, 'epoch': 21.4}
{'loss': 0.0058, 'grad_norm': 4.591121196746826, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.004678669851273298, 'loss_2': 0.0010890960693359375, 'loss_3': -16.28750991821289, 'loss_4': 1.291666030883789, 'epoch': 21.4}
{'loss': 0.0134, 'grad_norm': 8.221151351928711, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.011755116283893585, 'loss_2': 0.0015964508056640625, 'loss_3': -16.19390106201172, 'loss_4': 1.0585005283355713, 'epoch': 21.41}
{'loss': 0.0159, 'grad_norm': 8.630098342895508, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.01430587936192751, 'loss_2': 0.001560211181640625, 'loss_3': -16.23711395263672, 'loss_4': 1.0916478633880615, 'epoch': 21.41}
{'loss': 0.0389, 'grad_norm': 13.514626502990723, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.033651795238256454, 'loss_2': 0.00527191162109375, 'loss_3': -16.348094940185547, 'loss_4': 1.6846721172332764, 'epoch': 21.42}
{'loss': 0.0456, 'grad_norm': 14.748787879943848, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.04458845406770706, 'loss_2': 0.000965118408203125, 'loss_3': -16.13582992553711, 'loss_4': 1.9068219661712646, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 10:57:18,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:18,718 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:30:45<25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:26,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03343906253576279, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.712, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.03082992136478424, 'eval_loss_2': 0.002609141170978546, 'eval_loss_3': -18.086536407470703, 'eval_loss_4': 1.465305209159851, 'epoch': 21.42}
{'loss': 0.0127, 'grad_norm': 5.4333906173706055, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.009171704761683941, 'loss_2': 0.00353240966796875, 'loss_3': -16.22707748413086, 'loss_4': 0.9616205096244812, 'epoch': 21.43}
{'loss': 0.0174, 'grad_norm': 5.2157721519470215, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.00958199892193079, 'loss_2': 0.007781982421875, 'loss_3': -16.4671688079834, 'loss_4': 1.534611463546753, 'epoch': 21.44}
{'loss': 0.0134, 'grad_norm': 4.907961368560791, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.003963494673371315, 'loss_2': 0.00945281982421875, 'loss_3': -16.4245662689209, 'loss_4': 1.178053855895996, 'epoch': 21.44}
{'loss': 0.0171, 'grad_norm': 4.4346022605896, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.006327584385871887, 'loss_2': 0.0108184814453125, 'loss_3': -16.33634376525879, 'loss_4': 1.5852129459381104, 'epoch': 21.45}
{'loss': 0.0155, 'grad_norm': 13.474730491638184, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.014008667320013046, 'loss_2': 0.001491546630859375, 'loss_3': -16.485008239746094, 'loss_4': 1.443195104598999, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 10:57:26,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:26,060 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:30:53<25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:33,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022401969879865646, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02018643356859684, 'eval_loss_2': 0.0022155381739139557, 'eval_loss_3': -18.129623413085938, 'eval_loss_4': 1.5151469707489014, 'epoch': 21.45}
{'loss': 0.0057, 'grad_norm': 4.947697162628174, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.0055422596633434296, 'loss_2': 0.00012564659118652344, 'loss_3': -16.468469619750977, 'loss_4': 1.2203691005706787, 'epoch': 21.46}
{'loss': 0.006, 'grad_norm': 5.059797286987305, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.004731401801109314, 'loss_2': 0.001224517822265625, 'loss_3': -16.53030776977539, 'loss_4': 1.22340726852417, 'epoch': 21.47}
{'loss': 0.008, 'grad_norm': 6.083549976348877, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.0065367743372917175, 'loss_2': 0.0014896392822265625, 'loss_3': -16.306081771850586, 'loss_4': 1.1700994968414307, 'epoch': 21.47}
{'loss': 0.0097, 'grad_norm': 5.6640753746032715, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.006667191628366709, 'loss_2': 0.003070831298828125, 'loss_3': -16.279085159301758, 'loss_4': 1.3837223052978516, 'epoch': 21.48}
{'loss': 0.0082, 'grad_norm': 5.721133708953857, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.006121482700109482, 'loss_2': 0.002109527587890625, 'loss_3': -16.32880973815918, 'loss_4': 1.5930328369140625, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 10:57:33,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:33,414 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:00<25:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:40,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01629924215376377, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012168580666184425, 'eval_loss_2': 0.004130661487579346, 'eval_loss_3': -18.172557830810547, 'eval_loss_4': 1.564094066619873, 'epoch': 21.48}
{'loss': 0.0147, 'grad_norm': 5.331774711608887, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.006309628952294588, 'loss_2': 0.00836944580078125, 'loss_3': -16.39673614501953, 'loss_4': 1.9709956645965576, 'epoch': 21.49}
{'loss': 0.0108, 'grad_norm': 4.74749755859375, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.005623370409011841, 'loss_2': 0.005199432373046875, 'loss_3': -16.310659408569336, 'loss_4': 1.4569131135940552, 'epoch': 21.49}
{'loss': 0.0049, 'grad_norm': 4.6100311279296875, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.003379411995410919, 'loss_2': 0.001476287841796875, 'loss_3': -16.26983642578125, 'loss_4': 1.5262999534606934, 'epoch': 21.5}
{'loss': 0.0072, 'grad_norm': 4.60260009765625, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.004486532416194677, 'loss_2': 0.00272369384765625, 'loss_3': -16.20147132873535, 'loss_4': 1.6344280242919922, 'epoch': 21.51}
{'loss': 0.0073, 'grad_norm': 5.9885406494140625, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.006088115740567446, 'loss_2': 0.0012054443359375, 'loss_3': -16.37869644165039, 'loss_4': 1.606919288635254, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 10:57:40,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:40,742 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:07<25:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:48,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01311909593641758, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009991312399506569, 'eval_loss_2': 0.0031277835369110107, 'eval_loss_3': -18.206092834472656, 'eval_loss_4': 1.578818678855896, 'epoch': 21.51}
{'loss': 0.02, 'grad_norm': 6.626119613647461, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.011951007880270481, 'loss_2': 0.00807952880859375, 'loss_3': -16.329246520996094, 'loss_4': 1.9334443807601929, 'epoch': 21.52}
{'loss': 0.0072, 'grad_norm': 5.541734218597412, 'learning_rate': 8.5e-06, 'loss_1': 0.005699897650629282, 'loss_2': 0.0015497207641601562, 'loss_3': -16.35100555419922, 'loss_4': 2.0253663063049316, 'epoch': 21.52}
{'loss': 0.0037, 'grad_norm': 4.474193572998047, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.0033671932760626078, 'loss_2': 0.00030803680419921875, 'loss_3': -16.391647338867188, 'loss_4': 1.20320725440979, 'epoch': 21.53}
{'loss': 0.0135, 'grad_norm': 4.943251132965088, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.004610072355717421, 'loss_2': 0.00885009765625, 'loss_3': -16.204208374023438, 'loss_4': 1.7238290309906006, 'epoch': 21.53}
{'loss': 0.0056, 'grad_norm': 4.378174304962158, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.005178031977266073, 'loss_2': 0.0004611015319824219, 'loss_3': -16.279653549194336, 'loss_4': 1.6610422134399414, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 10:57:48,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:48,075 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:15<25:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:55,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012461099773645401, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.518, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009367017075419426, 'eval_loss_2': 0.0030940845608711243, 'eval_loss_3': -18.234880447387695, 'eval_loss_4': 1.5449646711349487, 'epoch': 21.54}
{'loss': 0.0093, 'grad_norm': 4.414306163787842, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.002755008405074477, 'loss_2': 0.00655364990234375, 'loss_3': -16.251201629638672, 'loss_4': 1.8858596086502075, 'epoch': 21.55}
{'loss': 0.0358, 'grad_norm': 16.114572525024414, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.031040767207741737, 'loss_2': 0.00475311279296875, 'loss_3': -16.454437255859375, 'loss_4': 2.1031012535095215, 'epoch': 21.55}
{'loss': 0.007, 'grad_norm': 5.97281551361084, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.0056416853331029415, 'loss_2': 0.0013113021850585938, 'loss_3': -16.194252014160156, 'loss_4': 1.647219181060791, 'epoch': 21.56}
{'loss': 0.0062, 'grad_norm': 4.451522350311279, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.00369539693929255, 'loss_2': 0.0025348663330078125, 'loss_3': -16.344280242919922, 'loss_4': 1.3911058902740479, 'epoch': 21.56}
{'loss': 0.0086, 'grad_norm': 4.536509037017822, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.005843814928084612, 'loss_2': 0.002773284912109375, 'loss_3': -16.272212982177734, 'loss_4': 1.349151849746704, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 10:57:55,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:55,428 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:22<24:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:58:02,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012565790675580502, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.537, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.009411445818841457, 'eval_loss_2': 0.003154344856739044, 'eval_loss_3': -18.243743896484375, 'eval_loss_4': 1.596186876296997, 'epoch': 21.57}
{'loss': 0.0158, 'grad_norm': 4.410528182983398, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.00584156159311533, 'loss_2': 0.0099945068359375, 'loss_3': -16.185989379882812, 'loss_4': 2.301098108291626, 'epoch': 21.58}
{'loss': 0.0077, 'grad_norm': 4.674187183380127, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.005845861509442329, 'loss_2': 0.0018825531005859375, 'loss_3': -16.472063064575195, 'loss_4': 1.806217074394226, 'epoch': 21.58}
{'loss': 0.0121, 'grad_norm': 5.010961532592773, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.009753644466400146, 'loss_2': 0.00238800048828125, 'loss_3': -16.48387908935547, 'loss_4': 2.2157793045043945, 'epoch': 21.59}
{'loss': 0.0159, 'grad_norm': 7.813973426818848, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.010283790528774261, 'loss_2': 0.0055694580078125, 'loss_3': -16.45228385925293, 'loss_4': 2.409996509552002, 'epoch': 21.59}
{'loss': 0.0122, 'grad_norm': 5.048633098602295, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.006776327267289162, 'loss_2': 0.005420684814453125, 'loss_3': -16.356800079345703, 'loss_4': 1.630598545074463, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 10:58:02,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:02,745 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:29<24:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:58:10,074 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011845376342535019, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.87, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009103442542254925, 'eval_loss_2': 0.0027419328689575195, 'eval_loss_3': -18.255489349365234, 'eval_loss_4': 1.6810251474380493, 'epoch': 21.6}
{'loss': 0.0185, 'grad_norm': 6.613179683685303, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.018075207248330116, 'loss_2': 0.0004451274871826172, 'loss_3': -16.43215560913086, 'loss_4': 1.8888612985610962, 'epoch': 21.6}
{'loss': 0.0056, 'grad_norm': 4.404977321624756, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.004077930003404617, 'loss_2': 0.0015048980712890625, 'loss_3': -16.369617462158203, 'loss_4': 1.7903972864151, 'epoch': 21.61}
{'loss': 0.0045, 'grad_norm': 4.908457279205322, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.0030122960451990366, 'loss_2': 0.0015287399291992188, 'loss_3': -16.285093307495117, 'loss_4': 1.7314919233322144, 'epoch': 21.62}
{'loss': 0.0158, 'grad_norm': 4.976858615875244, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.0066385031677782536, 'loss_2': 0.0091552734375, 'loss_3': -16.320707321166992, 'loss_4': 1.3253662586212158, 'epoch': 21.62}
{'loss': 0.0146, 'grad_norm': 5.512645721435547, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.007949979975819588, 'loss_2': 0.006649017333984375, 'loss_3': -16.365373611450195, 'loss_4': 1.5479222536087036, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 10:58:10,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:10,074 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:37<24:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:17,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014509368687868118, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.961, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00878981500864029, 'eval_loss_2': 0.005719553679227829, 'eval_loss_3': -18.238222122192383, 'eval_loss_4': 1.7458295822143555, 'epoch': 21.63}
{'loss': 0.0145, 'grad_norm': 5.441102504730225, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.00752752972766757, 'loss_2': 0.00693511962890625, 'loss_3': -16.219749450683594, 'loss_4': 2.096510887145996, 'epoch': 21.63}
{'loss': 0.0143, 'grad_norm': 5.2356953620910645, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.008130756206810474, 'loss_2': 0.00612640380859375, 'loss_3': -16.276050567626953, 'loss_4': 1.975698471069336, 'epoch': 21.64}
{'loss': 0.0104, 'grad_norm': 4.8828125, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.005467187613248825, 'loss_2': 0.00496673583984375, 'loss_3': -16.164138793945312, 'loss_4': 1.8602075576782227, 'epoch': 21.65}
{'loss': 0.0108, 'grad_norm': 5.92289924621582, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.007285366300493479, 'loss_2': 0.0034942626953125, 'loss_3': -16.217844009399414, 'loss_4': 1.4682201147079468, 'epoch': 21.65}
{'loss': 0.0126, 'grad_norm': 5.952970504760742, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.006711648777127266, 'loss_2': 0.005870819091796875, 'loss_3': -16.184646606445312, 'loss_4': 2.131049633026123, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 10:58:17,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:17,429 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:31:44<24:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:24,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01314994040876627, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.003, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008803688921034336, 'eval_loss_2': 0.004346251487731934, 'eval_loss_3': -18.243850708007812, 'eval_loss_4': 1.6674323081970215, 'epoch': 21.66}
{'loss': 0.0276, 'grad_norm': 9.135664939880371, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.018177423626184464, 'loss_2': 0.0094146728515625, 'loss_3': -16.12955665588379, 'loss_4': 1.5928351879119873, 'epoch': 21.66}
{'loss': 0.0116, 'grad_norm': 5.114543914794922, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.009406543336808681, 'loss_2': 0.002178192138671875, 'loss_3': -16.464107513427734, 'loss_4': 1.9033312797546387, 'epoch': 21.67}
{'loss': 0.0242, 'grad_norm': 10.137727737426758, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.01821758598089218, 'loss_2': 0.0059967041015625, 'loss_3': -16.376422882080078, 'loss_4': 1.4676799774169922, 'epoch': 21.67}
{'loss': 0.0124, 'grad_norm': 4.242079734802246, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.0026351765263825655, 'loss_2': 0.00980377197265625, 'loss_3': -16.546072006225586, 'loss_4': 2.1137027740478516, 'epoch': 21.68}
{'loss': 0.0091, 'grad_norm': 5.247256278991699, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.006604163907468319, 'loss_2': 0.00249481201171875, 'loss_3': -16.246076583862305, 'loss_4': 1.6898589134216309, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 10:58:24,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:24,761 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:31:51<24:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:32,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011341014876961708, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008311853744089603, 'eval_loss_2': 0.00302916020154953, 'eval_loss_3': -18.251867294311523, 'eval_loss_4': 1.6166045665740967, 'epoch': 21.69}
{'loss': 0.0102, 'grad_norm': 4.698773384094238, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.0042790318839251995, 'loss_2': 0.00595855712890625, 'loss_3': -16.34564781188965, 'loss_4': 2.1291651725769043, 'epoch': 21.69}
{'loss': 0.0143, 'grad_norm': 8.915207862854004, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.010685086250305176, 'loss_2': 0.00363922119140625, 'loss_3': -16.332077026367188, 'loss_4': 1.567276954650879, 'epoch': 21.7}
{'loss': 0.0121, 'grad_norm': 8.342387199401855, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.00980068277567625, 'loss_2': 0.002315521240234375, 'loss_3': -16.257740020751953, 'loss_4': 1.4084506034851074, 'epoch': 21.7}
{'loss': 0.0056, 'grad_norm': 4.743491172790527, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.005404943134635687, 'loss_2': 0.00016057491302490234, 'loss_3': -16.37619972229004, 'loss_4': 1.5446062088012695, 'epoch': 21.71}
{'loss': 0.0058, 'grad_norm': 4.594268798828125, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.004475659690797329, 'loss_2': 0.001369476318359375, 'loss_3': -16.267698287963867, 'loss_4': 1.8756369352340698, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 10:58:32,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:32,109 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:31:59<24:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:39,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011331845074892044, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008041110821068287, 'eval_loss_2': 0.003290735185146332, 'eval_loss_3': -18.265737533569336, 'eval_loss_4': 1.558884620666504, 'epoch': 21.72}
{'loss': 0.0094, 'grad_norm': 5.393473148345947, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.007527707144618034, 'loss_2': 0.0018291473388671875, 'loss_3': -16.23965835571289, 'loss_4': 1.5599297285079956, 'epoch': 21.72}
{'loss': 0.0098, 'grad_norm': 6.177938938140869, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.0079830726608634, 'loss_2': 0.0018157958984375, 'loss_3': -16.183551788330078, 'loss_4': 1.7163982391357422, 'epoch': 21.73}
{'loss': 0.0067, 'grad_norm': 4.98767614364624, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.006553336046636105, 'loss_2': 0.00015413761138916016, 'loss_3': -16.29903793334961, 'loss_4': 2.0390572547912598, 'epoch': 21.73}
{'loss': 0.0165, 'grad_norm': 10.046539306640625, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.01137584913522005, 'loss_2': 0.0051422119140625, 'loss_3': -16.447887420654297, 'loss_4': 1.45283842086792, 'epoch': 21.74}
{'loss': 0.0087, 'grad_norm': 5.049500465393066, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.0038454020395874977, 'loss_2': 0.0048980712890625, 'loss_3': -16.34735107421875, 'loss_4': 1.0599524974822998, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 10:58:39,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:39,462 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:06<24:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:46,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011150055564939976, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.869, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007845917716622353, 'eval_loss_2': 0.0033041387796401978, 'eval_loss_3': -18.244495391845703, 'eval_loss_4': 1.4692836999893188, 'epoch': 21.74}
{'loss': 0.0173, 'grad_norm': 8.973397254943848, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.016301311552524567, 'loss_2': 0.0010366439819335938, 'loss_3': -16.25418472290039, 'loss_4': 1.8622262477874756, 'epoch': 21.75}
{'loss': 0.0036, 'grad_norm': 4.2616658210754395, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.0034071633126586676, 'loss_2': 0.00023221969604492188, 'loss_3': -16.418190002441406, 'loss_4': 1.7646589279174805, 'epoch': 21.76}
{'loss': 0.0085, 'grad_norm': 4.742623329162598, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.005082001443952322, 'loss_2': 0.003368377685546875, 'loss_3': -16.301942825317383, 'loss_4': 1.4519987106323242, 'epoch': 21.76}
{'loss': 0.0122, 'grad_norm': 7.191341876983643, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.00954316183924675, 'loss_2': 0.00269317626953125, 'loss_3': -16.289548873901367, 'loss_4': 1.2095844745635986, 'epoch': 21.77}
{'loss': 0.0073, 'grad_norm': 4.646468162536621, 'learning_rate': 8.25e-06, 'loss_1': 0.005646861158311367, 'loss_2': 0.0016117095947265625, 'loss_3': -16.327131271362305, 'loss_4': 1.6359069347381592, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 10:58:46,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:46,801 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:13<24:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:54,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010932725854218006, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.621, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0074757169932127, 'eval_loss_2': 0.003457009792327881, 'eval_loss_3': -18.223552703857422, 'eval_loss_4': 1.4405465126037598, 'epoch': 21.77}
{'loss': 0.0109, 'grad_norm': 5.393227577209473, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.008201759308576584, 'loss_2': 0.002655029296875, 'loss_3': -16.343212127685547, 'loss_4': 1.4215916395187378, 'epoch': 21.78}
{'loss': 0.0193, 'grad_norm': 9.864909172058105, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.0136861652135849, 'loss_2': 0.0056610107421875, 'loss_3': -16.233154296875, 'loss_4': 2.195979356765747, 'epoch': 21.78}
{'loss': 0.0139, 'grad_norm': 7.140388011932373, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.01157127134501934, 'loss_2': 0.002376556396484375, 'loss_3': -16.22503662109375, 'loss_4': 1.348187804222107, 'epoch': 21.79}
{'loss': 0.008, 'grad_norm': 4.832905292510986, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.005263541825115681, 'loss_2': 0.002716064453125, 'loss_3': -16.076274871826172, 'loss_4': 2.141054630279541, 'epoch': 21.8}
{'loss': 0.0064, 'grad_norm': 4.506112098693848, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.0055616083554923534, 'loss_2': 0.0008454322814941406, 'loss_3': -16.389482498168945, 'loss_4': 1.7227897644042969, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 10:58:54,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:54,149 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:21<24:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:01,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012033350765705109, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.895, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008073636330664158, 'eval_loss_2': 0.003959715366363525, 'eval_loss_3': -18.219696044921875, 'eval_loss_4': 1.3778882026672363, 'epoch': 21.8}
{'loss': 0.0066, 'grad_norm': 5.379149913787842, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.006024880800396204, 'loss_2': 0.000606536865234375, 'loss_3': -16.51666259765625, 'loss_4': 2.0926015377044678, 'epoch': 21.81}
{'loss': 0.0102, 'grad_norm': 4.8221869468688965, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.0038163652643561363, 'loss_2': 0.00641632080078125, 'loss_3': -16.33608627319336, 'loss_4': 1.5503475666046143, 'epoch': 21.81}
{'loss': 0.007, 'grad_norm': 4.438913822174072, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.0063260393217206, 'loss_2': 0.0007009506225585938, 'loss_3': -16.35409164428711, 'loss_4': 1.6258187294006348, 'epoch': 21.82}
{'loss': 0.0156, 'grad_norm': 6.462972164154053, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.010761359706521034, 'loss_2': 0.00484466552734375, 'loss_3': -16.19858169555664, 'loss_4': 1.689526915550232, 'epoch': 21.83}
{'loss': 0.0109, 'grad_norm': 7.291810035705566, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.008631902746856213, 'loss_2': 0.0022258758544921875, 'loss_3': -16.25748062133789, 'loss_4': 1.425856351852417, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 10:59:01,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:01,480 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:28<24:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:08,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011474935337901115, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.864, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007246342021971941, 'eval_loss_2': 0.0042285919189453125, 'eval_loss_3': -18.226852416992188, 'eval_loss_4': 1.340954303741455, 'epoch': 21.83}
{'loss': 0.0076, 'grad_norm': 4.940841197967529, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.0046578277833759785, 'loss_2': 0.002925872802734375, 'loss_3': -16.409042358398438, 'loss_4': 1.8256226778030396, 'epoch': 21.84}
{'loss': 0.008, 'grad_norm': 4.919269561767578, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.0056595406495034695, 'loss_2': 0.00231170654296875, 'loss_3': -16.411537170410156, 'loss_4': 1.3730298280715942, 'epoch': 21.84}
{'loss': 0.0129, 'grad_norm': 6.560944080352783, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.008047855459153652, 'loss_2': 0.004848480224609375, 'loss_3': -16.578718185424805, 'loss_4': 1.9853049516677856, 'epoch': 21.85}
{'loss': 0.0158, 'grad_norm': 8.096120834350586, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.014684047549962997, 'loss_2': 0.0010776519775390625, 'loss_3': -16.50792694091797, 'loss_4': 1.248807430267334, 'epoch': 21.85}
{'loss': 0.0181, 'grad_norm': 6.8807597160339355, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.013733305968344212, 'loss_2': 0.0043792724609375, 'loss_3': -16.39547348022461, 'loss_4': 1.1955280303955078, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 10:59:08,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:08,823 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:35<24:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:59:16,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010421101935207844, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.113, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.006317619699984789, 'eval_loss_2': 0.004103481769561768, 'eval_loss_3': -18.2397518157959, 'eval_loss_4': 1.2049556970596313, 'epoch': 21.86}
{'loss': 0.0232, 'grad_norm': 10.773707389831543, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.019527142867445946, 'loss_2': 0.003704071044921875, 'loss_3': -16.435909271240234, 'loss_4': 1.2493000030517578, 'epoch': 21.87}
{'loss': 0.0167, 'grad_norm': 8.588318824768066, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.01650165393948555, 'loss_2': 0.0002465248107910156, 'loss_3': -16.309186935424805, 'loss_4': 1.6164584159851074, 'epoch': 21.87}
{'loss': 0.0063, 'grad_norm': 4.597674369812012, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.0038680231664329767, 'loss_2': 0.0024471282958984375, 'loss_3': -16.419498443603516, 'loss_4': 1.495253086090088, 'epoch': 21.88}
{'loss': 0.0216, 'grad_norm': 7.8255767822265625, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.013789135031402111, 'loss_2': 0.0077972412109375, 'loss_3': -16.246910095214844, 'loss_4': 1.2968151569366455, 'epoch': 21.88}
{'loss': 0.0112, 'grad_norm': 5.12050724029541, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.004544551949948072, 'loss_2': 0.0066375732421875, 'loss_3': -16.32602310180664, 'loss_4': 1.2596704959869385, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 10:59:16,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:16,141 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:32:43<24:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:23,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009912136942148209, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0063674855045974255, 'eval_loss_2': 0.003544650971889496, 'eval_loss_3': -18.222562789916992, 'eval_loss_4': 1.093357801437378, 'epoch': 21.89}
{'loss': 0.0045, 'grad_norm': 4.527278423309326, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.0028745646122843027, 'loss_2': 0.001583099365234375, 'loss_3': -16.372926712036133, 'loss_4': 1.183168649673462, 'epoch': 21.9}
{'loss': 0.0041, 'grad_norm': 4.4792890548706055, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0032547260634601116, 'loss_2': 0.0008568763732910156, 'loss_3': -16.30731201171875, 'loss_4': 1.198740005493164, 'epoch': 21.9}
{'loss': 0.007, 'grad_norm': 4.626338958740234, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.003283495781943202, 'loss_2': 0.0037250518798828125, 'loss_3': -16.36386489868164, 'loss_4': 1.2162543535232544, 'epoch': 21.91}
{'loss': 0.0185, 'grad_norm': 9.688420295715332, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.016238464042544365, 'loss_2': 0.00225830078125, 'loss_3': -16.309574127197266, 'loss_4': 1.057396650314331, 'epoch': 21.91}
{'loss': 0.0073, 'grad_norm': 5.090799808502197, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.006059899460524321, 'loss_2': 0.0012044906616210938, 'loss_3': -16.553884506225586, 'loss_4': 1.6527149677276611, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 10:59:23,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:23,485 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:32:50<23:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:30,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00996406190097332, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006446568761020899, 'eval_loss_2': 0.0035174936056137085, 'eval_loss_3': -18.21722984313965, 'eval_loss_4': 0.9881249070167542, 'epoch': 21.92}
{'loss': 0.0174, 'grad_norm': 8.298297882080078, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.01679953746497631, 'loss_2': 0.0006103515625, 'loss_3': -16.24419593811035, 'loss_4': 0.42067134380340576, 'epoch': 21.92}
{'loss': 0.0145, 'grad_norm': 10.254669189453125, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.011696948669850826, 'loss_2': 0.002803802490234375, 'loss_3': -16.467273712158203, 'loss_4': 0.9517296552658081, 'epoch': 21.93}
{'loss': 0.0106, 'grad_norm': 7.282158374786377, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.010233616456389427, 'loss_2': 0.0003695487976074219, 'loss_3': -16.34276580810547, 'loss_4': 1.0513348579406738, 'epoch': 21.94}
{'loss': 0.0291, 'grad_norm': 10.726554870605469, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.027549955993890762, 'loss_2': 0.0015306472778320312, 'loss_3': -16.283493041992188, 'loss_4': 1.2100865840911865, 'epoch': 21.94}
{'loss': 0.0095, 'grad_norm': 5.722966194152832, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.008672187104821205, 'loss_2': 0.000823974609375, 'loss_3': -16.310598373413086, 'loss_4': 1.285202145576477, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 10:59:30,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:30,833 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:32:57<23:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:38,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010004355572164059, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.369, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006347730290144682, 'eval_loss_2': 0.003656625747680664, 'eval_loss_3': -18.219743728637695, 'eval_loss_4': 0.9442305564880371, 'epoch': 21.95}
{'loss': 0.0141, 'grad_norm': 5.864156246185303, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.009997233748435974, 'loss_2': 0.004116058349609375, 'loss_3': -16.444616317749023, 'loss_4': 0.7798142433166504, 'epoch': 21.95}
{'loss': 0.0119, 'grad_norm': 6.421754837036133, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.009249950759112835, 'loss_2': 0.0026760101318359375, 'loss_3': -16.379043579101562, 'loss_4': 0.9183813333511353, 'epoch': 21.96}
{'loss': 0.008, 'grad_norm': 5.072420120239258, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.003462917171418667, 'loss_2': 0.00458526611328125, 'loss_3': -16.371854782104492, 'loss_4': 1.611255407333374, 'epoch': 21.97}
{'loss': 0.0167, 'grad_norm': 5.00545072555542, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.011937364935874939, 'loss_2': 0.00478363037109375, 'loss_3': -16.197229385375977, 'loss_4': 1.6882987022399902, 'epoch': 21.97}
{'loss': 0.0062, 'grad_norm': 5.16235876083374, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.005329628940671682, 'loss_2': 0.0008840560913085938, 'loss_3': -16.365100860595703, 'loss_4': 0.9441896677017212, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 10:59:38,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:38,174 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:05<22:28,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:59:45,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009884247556328773, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.842, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0064696683548390865, 'eval_loss_2': 0.0034145787358283997, 'eval_loss_3': -18.22060775756836, 'eval_loss_4': 0.942811131477356, 'epoch': 21.98}
{'loss': 0.0162, 'grad_norm': 8.014616966247559, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.010589425452053547, 'loss_2': 0.00562286376953125, 'loss_3': -16.535490036010742, 'loss_4': 0.854214072227478, 'epoch': 21.98}
{'loss': 0.0069, 'grad_norm': 4.50286340713501, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.004056303296238184, 'loss_2': 0.00289154052734375, 'loss_3': -16.528030395507812, 'loss_4': 0.899056077003479, 'epoch': 21.99}
{'loss': 0.0121, 'grad_norm': 5.178885459899902, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.007868840359151363, 'loss_2': 0.00421142578125, 'loss_3': -16.366886138916016, 'loss_4': 1.231762409210205, 'epoch': 21.99}
{'loss': 0.0117, 'grad_norm': 6.4953718185424805, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.0024257341865450144, 'loss_2': 0.009246826171875, 'loss_3': -16.31248664855957, 'loss_4': 1.2616783380508423, 'epoch': 22.0}
{'loss': 0.0094, 'grad_norm': 5.178760051727295, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.0063890982419252396, 'loss_2': 0.00298309326171875, 'loss_3': -16.442413330078125, 'loss_4': 1.6909676790237427, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 10:59:45,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:45,212 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:12<23:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:59:52,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009745202958583832, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.646, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006151221692562103, 'eval_loss_2': 0.0035939812660217285, 'eval_loss_3': -18.220474243164062, 'eval_loss_4': 0.9638442397117615, 'epoch': 22.01}
{'loss': 0.0059, 'grad_norm': 5.0008463859558105, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.004839280620217323, 'loss_2': 0.0010347366333007812, 'loss_3': -16.277103424072266, 'loss_4': 0.6911922693252563, 'epoch': 22.01}
{'loss': 0.0111, 'grad_norm': 4.732170104980469, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.004048742353916168, 'loss_2': 0.0070648193359375, 'loss_3': -16.246234893798828, 'loss_4': 1.4541709423065186, 'epoch': 22.02}
{'loss': 0.0074, 'grad_norm': 5.780259609222412, 'learning_rate': 8e-06, 'loss_1': 0.0065908171236515045, 'loss_2': 0.0008053779602050781, 'loss_3': -16.47863006591797, 'loss_4': 1.0318379402160645, 'epoch': 22.02}
{'loss': 0.0079, 'grad_norm': 5.011366367340088, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.006025379523634911, 'loss_2': 0.0018558502197265625, 'loss_3': -16.311979293823242, 'loss_4': 1.7311705350875854, 'epoch': 22.03}
{'loss': 0.01, 'grad_norm': 4.859826564788818, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.005382266826927662, 'loss_2': 0.00461578369140625, 'loss_3': -16.191577911376953, 'loss_4': 0.8490908741950989, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 10:59:52,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:52,548 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:19<23:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:59:59,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009339595213532448, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.782, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0057474905624985695, 'eval_loss_2': 0.0035921037197113037, 'eval_loss_3': -18.234148025512695, 'eval_loss_4': 1.0105608701705933, 'epoch': 22.03}
{'loss': 0.0074, 'grad_norm': 6.266191482543945, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.005555515643209219, 'loss_2': 0.0018177032470703125, 'loss_3': -16.377182006835938, 'loss_4': 1.2423021793365479, 'epoch': 22.04}
{'loss': 0.0082, 'grad_norm': 4.531739711761475, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.004317048005759716, 'loss_2': 0.0038700103759765625, 'loss_3': -16.41257667541504, 'loss_4': 0.7000745534896851, 'epoch': 22.05}
{'loss': 0.0126, 'grad_norm': 5.37970495223999, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.0055919126607477665, 'loss_2': 0.0070343017578125, 'loss_3': -16.494558334350586, 'loss_4': 1.2404539585113525, 'epoch': 22.05}
{'loss': 0.0072, 'grad_norm': 4.802076816558838, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.0049013858661055565, 'loss_2': 0.00231170654296875, 'loss_3': -16.391233444213867, 'loss_4': 1.59950590133667, 'epoch': 22.06}
{'loss': 0.011, 'grad_norm': 5.331512928009033, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.00562261464074254, 'loss_2': 0.00533294677734375, 'loss_3': -16.386091232299805, 'loss_4': 1.3474829196929932, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 10:59:59,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:59,882 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:27<23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:07,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008726047351956367, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.748, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0050980462692677975, 'eval_loss_2': 0.0036280006170272827, 'eval_loss_3': -18.219635009765625, 'eval_loss_4': 1.0018668174743652, 'epoch': 22.06}
{'loss': 0.0097, 'grad_norm': 4.392349720001221, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.0037676519714295864, 'loss_2': 0.0059051513671875, 'loss_3': -16.272361755371094, 'loss_4': 1.5636324882507324, 'epoch': 22.07}
{'loss': 0.0074, 'grad_norm': 5.371148586273193, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.00587770901620388, 'loss_2': 0.001506805419921875, 'loss_3': -16.48367691040039, 'loss_4': 1.096785306930542, 'epoch': 22.08}
{'loss': 0.0036, 'grad_norm': 4.578449726104736, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.002951723523437977, 'loss_2': 0.0006923675537109375, 'loss_3': -16.356046676635742, 'loss_4': 1.3536946773529053, 'epoch': 22.08}
{'loss': 0.0066, 'grad_norm': 6.029908657073975, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.006000205874443054, 'loss_2': 0.0006275177001953125, 'loss_3': -16.144336700439453, 'loss_4': 1.0493454933166504, 'epoch': 22.09}
{'loss': 0.0244, 'grad_norm': 11.88774585723877, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.01932828314602375, 'loss_2': 0.00502777099609375, 'loss_3': -16.422853469848633, 'loss_4': 1.1771730184555054, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 11:00:07,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:07,226 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:34<23:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:14,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008827758021652699, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005257648415863514, 'eval_loss_2': 0.0035701096057891846, 'eval_loss_3': -18.2269344329834, 'eval_loss_4': 0.9070170521736145, 'epoch': 22.09}
{'loss': 0.0052, 'grad_norm': 4.424575328826904, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.003635276574641466, 'loss_2': 0.0015888214111328125, 'loss_3': -16.227947235107422, 'loss_4': 1.3848917484283447, 'epoch': 22.1}
{'loss': 0.0144, 'grad_norm': 7.0046000480651855, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.008455227129161358, 'loss_2': 0.00591278076171875, 'loss_3': -16.25440788269043, 'loss_4': 0.9568496346473694, 'epoch': 22.1}
{'loss': 0.0136, 'grad_norm': 6.099234580993652, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.009452109225094318, 'loss_2': 0.0041656494140625, 'loss_3': -16.414913177490234, 'loss_4': 0.5566402077674866, 'epoch': 22.11}
{'loss': 0.0356, 'grad_norm': 13.240263938903809, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.028412042185664177, 'loss_2': 0.007205963134765625, 'loss_3': -16.25437355041504, 'loss_4': 1.2377761602401733, 'epoch': 22.12}
{'loss': 0.0117, 'grad_norm': 5.735797882080078, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.0032743518240749836, 'loss_2': 0.008453369140625, 'loss_3': -16.43881607055664, 'loss_4': 0.9125452041625977, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 11:00:14,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:14,560 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:41<23:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:21,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009486041031777859, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.763, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006166032049804926, 'eval_loss_2': 0.0033200085163116455, 'eval_loss_3': -18.225271224975586, 'eval_loss_4': 0.796785831451416, 'epoch': 22.12}
{'loss': 0.0064, 'grad_norm': 4.892199516296387, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.00504792807623744, 'loss_2': 0.0013284683227539062, 'loss_3': -16.305809020996094, 'loss_4': 1.349995732307434, 'epoch': 22.13}
{'loss': 0.0073, 'grad_norm': 4.6185712814331055, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.0032291491515934467, 'loss_2': 0.0040740966796875, 'loss_3': -16.45288848876953, 'loss_4': 1.1352914571762085, 'epoch': 22.13}
{'loss': 0.0109, 'grad_norm': 5.031278610229492, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.004990285728126764, 'loss_2': 0.00589752197265625, 'loss_3': -16.303241729736328, 'loss_4': 0.7554992437362671, 'epoch': 22.14}
{'loss': 0.0065, 'grad_norm': 4.679217338562012, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.0027833625208586454, 'loss_2': 0.003704071044921875, 'loss_3': -16.354618072509766, 'loss_4': 0.7923575639724731, 'epoch': 22.15}
{'loss': 0.0219, 'grad_norm': 7.00996732711792, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.020968236029148102, 'loss_2': 0.0009450912475585938, 'loss_3': -16.250102996826172, 'loss_4': 0.9061516523361206, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 11:00:21,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:21,918 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:33:49<23:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:29,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009453710168600082, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005904701538383961, 'eval_loss_2': 0.0035490095615386963, 'eval_loss_3': -18.232791900634766, 'eval_loss_4': 0.6640194058418274, 'epoch': 22.15}
{'loss': 0.0137, 'grad_norm': 11.478514671325684, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.013229279778897762, 'loss_2': 0.0004868507385253906, 'loss_3': -16.34717559814453, 'loss_4': 0.4401422142982483, 'epoch': 22.16}
{'loss': 0.008, 'grad_norm': 4.905102252960205, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.004287997260689735, 'loss_2': 0.003711700439453125, 'loss_3': -16.270992279052734, 'loss_4': 0.5327325463294983, 'epoch': 22.16}
{'loss': 0.0124, 'grad_norm': 5.399996757507324, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.0066034323535859585, 'loss_2': 0.0058135986328125, 'loss_3': -16.22684097290039, 'loss_4': 0.6917359828948975, 'epoch': 22.17}
{'loss': 0.011, 'grad_norm': 4.953969955444336, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.006975402124226093, 'loss_2': 0.004058837890625, 'loss_3': -16.35345458984375, 'loss_4': 0.9743955135345459, 'epoch': 22.17}
{'loss': 0.0129, 'grad_norm': 4.712479591369629, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.004713776987046003, 'loss_2': 0.00814056396484375, 'loss_3': -16.335105895996094, 'loss_4': 0.5770735144615173, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 11:00:29,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:29,249 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:33:56<23:27,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:00:36,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009004645049571991, 'eval_runtime': 3.992, 'eval_samples_per_second': 256.514, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.005766112357378006, 'eval_loss_2': 0.003238532692193985, 'eval_loss_3': -18.242773056030273, 'eval_loss_4': 0.5582636594772339, 'epoch': 22.18}
{'loss': 0.011, 'grad_norm': 5.387947082519531, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.004723685327917337, 'loss_2': 0.00626373291015625, 'loss_3': -16.3237361907959, 'loss_4': 0.9857394695281982, 'epoch': 22.19}
{'loss': 0.0102, 'grad_norm': 7.358870029449463, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.007465250790119171, 'loss_2': 0.0027599334716796875, 'loss_3': -16.293720245361328, 'loss_4': 1.526176929473877, 'epoch': 22.19}
{'loss': 0.0066, 'grad_norm': 5.772171497344971, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.005202502943575382, 'loss_2': 0.001422882080078125, 'loss_3': -16.44472312927246, 'loss_4': 0.6492100954055786, 'epoch': 22.2}
{'loss': 0.0171, 'grad_norm': 7.846155166625977, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.008964003063738346, 'loss_2': 0.0081787109375, 'loss_3': -16.527572631835938, 'loss_4': 0.9396606683731079, 'epoch': 22.2}
{'loss': 0.0089, 'grad_norm': 4.501924991607666, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.0033388312440365553, 'loss_2': 0.0055999755859375, 'loss_3': -16.25265884399414, 'loss_4': 0.7838560342788696, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 11:00:36,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:36,782 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:03<23:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:44,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008827166631817818, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.622, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005634742323309183, 'eval_loss_2': 0.003192424774169922, 'eval_loss_3': -18.242725372314453, 'eval_loss_4': 0.5120002031326294, 'epoch': 22.21}
{'loss': 0.0031, 'grad_norm': 4.725550174713135, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.0021764945704489946, 'loss_2': 0.0009036064147949219, 'loss_3': -16.381240844726562, 'loss_4': 0.9810307621955872, 'epoch': 22.22}
{'loss': 0.012, 'grad_norm': 5.29646110534668, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.0071443961933255196, 'loss_2': 0.00489044189453125, 'loss_3': -16.444358825683594, 'loss_4': 1.230181097984314, 'epoch': 22.22}
{'loss': 0.0039, 'grad_norm': 4.948676109313965, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.0034628105349838734, 'loss_2': 0.0004730224609375, 'loss_3': -16.393497467041016, 'loss_4': 0.5388391017913818, 'epoch': 22.23}
{'loss': 0.0048, 'grad_norm': 4.814510822296143, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.003978752996772528, 'loss_2': 0.0007824897766113281, 'loss_3': -16.391754150390625, 'loss_4': 0.763838529586792, 'epoch': 22.23}
{'loss': 0.0243, 'grad_norm': 10.278155326843262, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.01834745705127716, 'loss_2': 0.0059661865234375, 'loss_3': -16.409561157226562, 'loss_4': 0.5273653864860535, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 11:00:44,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:44,106 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:11<23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:51,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008879798464477062, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.468, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0056318663991987705, 'eval_loss_2': 0.0032479315996170044, 'eval_loss_3': -18.244279861450195, 'eval_loss_4': 0.47103193402290344, 'epoch': 22.24}
{'loss': 0.0073, 'grad_norm': 4.484502792358398, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.004491121508181095, 'loss_2': 0.002826690673828125, 'loss_3': -16.511526107788086, 'loss_4': 0.9901388883590698, 'epoch': 22.24}
{'loss': 0.0087, 'grad_norm': 4.6335768699646, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.002921181032434106, 'loss_2': 0.00580596923828125, 'loss_3': -16.200698852539062, 'loss_4': 0.8483513593673706, 'epoch': 22.25}
{'loss': 0.0112, 'grad_norm': 5.478245735168457, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.005235626362264156, 'loss_2': 0.00592041015625, 'loss_3': -16.29401969909668, 'loss_4': 0.7239310145378113, 'epoch': 22.26}
{'loss': 0.0194, 'grad_norm': 7.807596683502197, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.013578933663666248, 'loss_2': 0.005828857421875, 'loss_3': -16.2530460357666, 'loss_4': 0.7708689570426941, 'epoch': 22.26}
{'loss': 0.0029, 'grad_norm': 4.833467483520508, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.002412976697087288, 'loss_2': 0.0005083084106445312, 'loss_3': -16.514753341674805, 'loss_4': 0.5835810899734497, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 11:00:51,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:51,459 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:18<22:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:58,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008640006184577942, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.239, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006127039901912212, 'eval_loss_2': 0.002512965351343155, 'eval_loss_3': -18.25747299194336, 'eval_loss_4': 0.42640817165374756, 'epoch': 22.27}
{'loss': 0.0068, 'grad_norm': 4.634851455688477, 'learning_rate': 7.75e-06, 'loss_1': 0.0023565874435007572, 'loss_2': 0.004421234130859375, 'loss_3': -16.367311477661133, 'loss_4': 0.7431323528289795, 'epoch': 22.27}
{'loss': 0.0056, 'grad_norm': 4.86637020111084, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.004131324589252472, 'loss_2': 0.00150299072265625, 'loss_3': -16.45997428894043, 'loss_4': 0.913341760635376, 'epoch': 22.28}
{'loss': 0.0123, 'grad_norm': 6.943298816680908, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.009471875615417957, 'loss_2': 0.002788543701171875, 'loss_3': -16.54589080810547, 'loss_4': 0.6637688279151917, 'epoch': 22.28}
{'loss': 0.0238, 'grad_norm': 10.507426261901855, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.02253098227083683, 'loss_2': 0.0012664794921875, 'loss_3': -16.348102569580078, 'loss_4': 0.18759533762931824, 'epoch': 22.29}
{'loss': 0.0056, 'grad_norm': 5.124508380889893, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.00349513441324234, 'loss_2': 0.0020599365234375, 'loss_3': -16.55929183959961, 'loss_4': 0.29454171657562256, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 11:00:58,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:58,797 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:25<22:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:06,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008918482810258865, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.686, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005914981476962566, 'eval_loss_2': 0.0030035004019737244, 'eval_loss_3': -18.260160446166992, 'eval_loss_4': 0.4532757103443146, 'epoch': 22.3}
{'loss': 0.0068, 'grad_norm': 5.038200855255127, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.004139774013310671, 'loss_2': 0.002666473388671875, 'loss_3': -16.407413482666016, 'loss_4': 0.35670217871665955, 'epoch': 22.3}
{'loss': 0.0063, 'grad_norm': 4.719707489013672, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.003855279413983226, 'loss_2': 0.002490997314453125, 'loss_3': -16.38488006591797, 'loss_4': 0.3295186161994934, 'epoch': 22.31}
{'loss': 0.0098, 'grad_norm': 4.515125274658203, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.0029919955413788557, 'loss_2': 0.006809234619140625, 'loss_3': -16.458253860473633, 'loss_4': 0.45692262053489685, 'epoch': 22.31}
{'loss': 0.0124, 'grad_norm': 5.347710132598877, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.00653082737699151, 'loss_2': 0.005878448486328125, 'loss_3': -16.452329635620117, 'loss_4': 0.07743017375469208, 'epoch': 22.32}
{'loss': 0.0106, 'grad_norm': 5.430959701538086, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.009726650081574917, 'loss_2': 0.000835418701171875, 'loss_3': -16.31670379638672, 'loss_4': 0.8105779886245728, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 11:01:06,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:06,153 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:33<22:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:13,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009921222925186157, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.175, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.006481037009507418, 'eval_loss_2': 0.003440186381340027, 'eval_loss_3': -18.249942779541016, 'eval_loss_4': 0.4958995580673218, 'epoch': 22.33}
{'loss': 0.0179, 'grad_norm': 9.44035530090332, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.01184975914657116, 'loss_2': 0.00605010986328125, 'loss_3': -16.40987205505371, 'loss_4': 0.8654212951660156, 'epoch': 22.33}
{'loss': 0.0079, 'grad_norm': 4.990290641784668, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.0039640371687710285, 'loss_2': 0.003902435302734375, 'loss_3': -16.242393493652344, 'loss_4': 0.3796522617340088, 'epoch': 22.34}
{'loss': 0.0114, 'grad_norm': 5.219480991363525, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.009304441511631012, 'loss_2': 0.0020503997802734375, 'loss_3': -16.41254234313965, 'loss_4': 0.38889503479003906, 'epoch': 22.34}
{'loss': 0.0074, 'grad_norm': 4.663618564605713, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.003358570160344243, 'loss_2': 0.00408172607421875, 'loss_3': -16.380901336669922, 'loss_4': 0.9703117609024048, 'epoch': 22.35}
{'loss': 0.0096, 'grad_norm': 4.41740083694458, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.003124955575913191, 'loss_2': 0.00650787353515625, 'loss_3': -16.594907760620117, 'loss_4': 0.5199170112609863, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 11:01:13,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:13,485 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:40<22:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:20,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009212355129420757, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006461369805037975, 'eval_loss_2': 0.002750985324382782, 'eval_loss_3': -18.240886688232422, 'eval_loss_4': 0.560880720615387, 'epoch': 22.35}
{'loss': 0.0128, 'grad_norm': 5.197593688964844, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.0069941142573952675, 'loss_2': 0.005828857421875, 'loss_3': -16.361984252929688, 'loss_4': 0.7303371429443359, 'epoch': 22.36}
{'loss': 0.0154, 'grad_norm': 8.93152141571045, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.012611267156898975, 'loss_2': 0.0027675628662109375, 'loss_3': -16.194738388061523, 'loss_4': 0.7755035161972046, 'epoch': 22.37}
{'loss': 0.0078, 'grad_norm': 5.255115509033203, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.003247984452173114, 'loss_2': 0.004547119140625, 'loss_3': -16.59634017944336, 'loss_4': 1.174795150756836, 'epoch': 22.37}
{'loss': 0.0049, 'grad_norm': 4.773728370666504, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.004021368455141783, 'loss_2': 0.0008878707885742188, 'loss_3': -16.30098533630371, 'loss_4': 1.030960202217102, 'epoch': 22.38}
{'loss': 0.0051, 'grad_norm': 4.93004035949707, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.0023884635884314775, 'loss_2': 0.00273895263671875, 'loss_3': -16.361230850219727, 'loss_4': 0.7650744915008545, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 11:01:20,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:20,827 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:34:47<22:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:28,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010279646143317223, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007169415708631277, 'eval_loss_2': 0.003110229969024658, 'eval_loss_3': -18.241291046142578, 'eval_loss_4': 0.6402221918106079, 'epoch': 22.38}
{'loss': 0.0067, 'grad_norm': 4.572830677032471, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.004307921510189772, 'loss_2': 0.00238037109375, 'loss_3': -16.47894287109375, 'loss_4': 0.490418016910553, 'epoch': 22.39}
{'loss': 0.0103, 'grad_norm': 5.8263959884643555, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.007552351336926222, 'loss_2': 0.0027217864990234375, 'loss_3': -16.461000442504883, 'loss_4': 0.6505284309387207, 'epoch': 22.4}
{'loss': 0.0041, 'grad_norm': 5.09657096862793, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.004097979981452227, 'loss_2': 3.719329833984375e-05, 'loss_3': -16.370101928710938, 'loss_4': 1.0156517028808594, 'epoch': 22.4}
{'loss': 0.0064, 'grad_norm': 4.312514781951904, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.002102649537846446, 'loss_2': 0.0043182373046875, 'loss_3': -16.43171501159668, 'loss_4': 0.9227359294891357, 'epoch': 22.41}
{'loss': 0.0104, 'grad_norm': 8.211498260498047, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.009970244020223618, 'loss_2': 0.00045800209045410156, 'loss_3': -16.484512329101562, 'loss_4': 0.8599337935447693, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 11:01:28,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:28,166 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:34:55<22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:35,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01137742679566145, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.817, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007491203956305981, 'eval_loss_2': 0.0038862228393554688, 'eval_loss_3': -18.22815704345703, 'eval_loss_4': 0.6784497499465942, 'epoch': 22.41}
{'loss': 0.0079, 'grad_norm': 4.853894233703613, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.006844027433544397, 'loss_2': 0.001064300537109375, 'loss_3': -16.443532943725586, 'loss_4': 1.0818064212799072, 'epoch': 22.42}
{'loss': 0.0035, 'grad_norm': 4.57205057144165, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.0022584465332329273, 'loss_2': 0.0012483596801757812, 'loss_3': -16.44835090637207, 'loss_4': 0.8432483077049255, 'epoch': 22.42}
{'loss': 0.0103, 'grad_norm': 5.297290802001953, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.00448206951841712, 'loss_2': 0.0058135986328125, 'loss_3': -16.238021850585938, 'loss_4': 0.9625913500785828, 'epoch': 22.43}
{'loss': 0.0087, 'grad_norm': 4.988675117492676, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.004800122231245041, 'loss_2': 0.00392913818359375, 'loss_3': -16.337574005126953, 'loss_4': 0.9509819746017456, 'epoch': 22.44}
{'loss': 0.0064, 'grad_norm': 4.992339611053467, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.0037861615419387817, 'loss_2': 0.002590179443359375, 'loss_3': -16.317310333251953, 'loss_4': 0.7292085886001587, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 11:01:35,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:35,495 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:02<22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:42,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011865757405757904, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00788786169141531, 'eval_loss_2': 0.0039778947830200195, 'eval_loss_3': -18.224885940551758, 'eval_loss_4': 0.5868589878082275, 'epoch': 22.44}
{'loss': 0.0084, 'grad_norm': 4.5338006019592285, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.00344732403755188, 'loss_2': 0.00496673583984375, 'loss_3': -16.390357971191406, 'loss_4': 0.8723479509353638, 'epoch': 22.45}
{'loss': 0.0141, 'grad_norm': 8.254029273986816, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.013075516559183598, 'loss_2': 0.0010519027709960938, 'loss_3': -16.342178344726562, 'loss_4': 0.44215628504753113, 'epoch': 22.45}
{'loss': 0.0061, 'grad_norm': 4.879526138305664, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.004440187010914087, 'loss_2': 0.0016307830810546875, 'loss_3': -16.533824920654297, 'loss_4': 0.5314174294471741, 'epoch': 22.46}
{'loss': 0.0079, 'grad_norm': 4.582828521728516, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.004453950561583042, 'loss_2': 0.00344085693359375, 'loss_3': -16.513442993164062, 'loss_4': 0.7484164237976074, 'epoch': 22.47}
{'loss': 0.0077, 'grad_norm': 5.210572719573975, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.005562181584537029, 'loss_2': 0.0020923614501953125, 'loss_3': -16.477445602416992, 'loss_4': 0.6727300882339478, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 11:01:42,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:42,849 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:09<22:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:50,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011972522363066673, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.689, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007655836176127195, 'eval_loss_2': 0.00431668758392334, 'eval_loss_3': -18.22568130493164, 'eval_loss_4': 0.4983118176460266, 'epoch': 22.47}
{'loss': 0.0205, 'grad_norm': 16.725482940673828, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.01988646760582924, 'loss_2': 0.0006527900695800781, 'loss_3': -16.485673904418945, 'loss_4': 0.9122435450553894, 'epoch': 22.48}
{'loss': 0.015, 'grad_norm': 4.706945419311523, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.00609241658821702, 'loss_2': 0.00894927978515625, 'loss_3': -16.447925567626953, 'loss_4': 0.3939831852912903, 'epoch': 22.48}
{'loss': 0.008, 'grad_norm': 4.9426445960998535, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.005600600969046354, 'loss_2': 0.00235748291015625, 'loss_3': -16.2093505859375, 'loss_4': 0.8734772801399231, 'epoch': 22.49}
{'loss': 0.0108, 'grad_norm': 5.313260078430176, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.00811572652310133, 'loss_2': 0.00269317626953125, 'loss_3': -16.267932891845703, 'loss_4': 0.5763229131698608, 'epoch': 22.49}
{'loss': 0.0103, 'grad_norm': 4.487823486328125, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.002437095856294036, 'loss_2': 0.0078582763671875, 'loss_3': -16.426132202148438, 'loss_4': 0.7549366354942322, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 11:01:50,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:50,180 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:17<22:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:01:57,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012738130986690521, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.67, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.009062310680747032, 'eval_loss_2': 0.00367581844329834, 'eval_loss_3': -18.225643157958984, 'eval_loss_4': 0.3883001208305359, 'epoch': 22.5}
{'loss': 0.015, 'grad_norm': 6.06350564956665, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.010496594943106174, 'loss_2': 0.00446319580078125, 'loss_3': -16.440608978271484, 'loss_4': 0.6323740482330322, 'epoch': 22.51}
{'loss': 0.0065, 'grad_norm': 4.414679050445557, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.002923511201515794, 'loss_2': 0.00354766845703125, 'loss_3': -16.475032806396484, 'loss_4': 0.3314950168132782, 'epoch': 22.51}
{'loss': 0.0107, 'grad_norm': 5.30250358581543, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.00513077387586236, 'loss_2': 0.005584716796875, 'loss_3': -16.36362075805664, 'loss_4': 0.6119836568832397, 'epoch': 22.52}
{'loss': 0.0112, 'grad_norm': 5.768076419830322, 'learning_rate': 7.5e-06, 'loss_1': 0.008571719750761986, 'loss_2': 0.0026531219482421875, 'loss_3': -16.314273834228516, 'loss_4': 0.4932459592819214, 'epoch': 22.52}
{'loss': 0.0065, 'grad_norm': 5.847330093383789, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.00516290171071887, 'loss_2': 0.0013408660888671875, 'loss_3': -16.28472900390625, 'loss_4': 0.42396652698516846, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 11:01:57,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:57,498 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:24<22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:04,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012424670159816742, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009579538367688656, 'eval_loss_2': 0.0028451308608055115, 'eval_loss_3': -18.225013732910156, 'eval_loss_4': 0.3023177683353424, 'epoch': 22.53}
{'loss': 0.0094, 'grad_norm': 5.049380302429199, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.005394795909523964, 'loss_2': 0.004016876220703125, 'loss_3': -16.478713989257812, 'loss_4': 0.7502776384353638, 'epoch': 22.53}
{'loss': 0.0062, 'grad_norm': 4.438155174255371, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.005521086044609547, 'loss_2': 0.0006666183471679688, 'loss_3': -16.33991050720215, 'loss_4': 0.3683508038520813, 'epoch': 22.54}
{'loss': 0.0135, 'grad_norm': 5.802849769592285, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.009177944622933865, 'loss_2': 0.00434112548828125, 'loss_3': -16.43569564819336, 'loss_4': 0.2805091142654419, 'epoch': 22.55}
{'loss': 0.0172, 'grad_norm': 9.515243530273438, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.01615222357213497, 'loss_2': 0.001041412353515625, 'loss_3': -16.394981384277344, 'loss_4': 0.22892659902572632, 'epoch': 22.55}
{'loss': 0.0103, 'grad_norm': 5.409735202789307, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.006030963733792305, 'loss_2': 0.004222869873046875, 'loss_3': -16.352031707763672, 'loss_4': 0.5708140730857849, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 11:02:04,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:04,846 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:31<22:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:12,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013617245480418205, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009826336987316608, 'eval_loss_2': 0.003790907561779022, 'eval_loss_3': -18.227672576904297, 'eval_loss_4': 0.24521151185035706, 'epoch': 22.56}
{'loss': 0.0128, 'grad_norm': 7.0654425621032715, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.009071200154721737, 'loss_2': 0.0037689208984375, 'loss_3': -16.33847427368164, 'loss_4': 0.25781047344207764, 'epoch': 22.56}
{'loss': 0.0108, 'grad_norm': 4.7555832862854, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.0035740432795137167, 'loss_2': 0.0072021484375, 'loss_3': -16.2625675201416, 'loss_4': -0.11115560680627823, 'epoch': 22.57}
{'loss': 0.0071, 'grad_norm': 4.571667671203613, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.002708223182708025, 'loss_2': 0.0044403076171875, 'loss_3': -16.333396911621094, 'loss_4': 0.22785472869873047, 'epoch': 22.58}
{'loss': 0.0126, 'grad_norm': 4.674868583679199, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.005140130408108234, 'loss_2': 0.007476806640625, 'loss_3': -16.31308937072754, 'loss_4': -0.27156388759613037, 'epoch': 22.58}
{'loss': 0.0044, 'grad_norm': 4.41337251663208, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.0026236330159008503, 'loss_2': 0.0017423629760742188, 'loss_3': -16.453439712524414, 'loss_4': 0.069638192653656, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 11:02:12,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:12,188 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:39<22:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:19,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013361163437366486, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009405911900103092, 'eval_loss_2': 0.003955252468585968, 'eval_loss_3': -18.228012084960938, 'eval_loss_4': 0.18617670238018036, 'epoch': 22.59}
{'loss': 0.0078, 'grad_norm': 4.632486343383789, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.002594653284177184, 'loss_2': 0.0052490234375, 'loss_3': -16.400257110595703, 'loss_4': 0.43372195959091187, 'epoch': 22.59}
{'loss': 0.0081, 'grad_norm': 5.030542373657227, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.005241573788225651, 'loss_2': 0.0028133392333984375, 'loss_3': -16.32498550415039, 'loss_4': 0.6461421251296997, 'epoch': 22.6}
{'loss': 0.0088, 'grad_norm': 5.221294403076172, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.005016916897147894, 'loss_2': 0.0037403106689453125, 'loss_3': -16.400436401367188, 'loss_4': 0.1457984745502472, 'epoch': 22.6}
{'loss': 0.0038, 'grad_norm': 4.8299760818481445, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.003657248103991151, 'loss_2': 0.00015616416931152344, 'loss_3': -16.353548049926758, 'loss_4': 0.5471794009208679, 'epoch': 22.61}
{'loss': 0.021, 'grad_norm': 7.60398006439209, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.01868184469640255, 'loss_2': 0.002307891845703125, 'loss_3': -16.466510772705078, 'loss_4': 0.36935120820999146, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 11:02:19,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:19,541 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:35:46<21:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:26,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011670256964862347, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.963, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008846234530210495, 'eval_loss_2': 0.0028240233659744263, 'eval_loss_3': -18.23006820678711, 'eval_loss_4': 0.18779918551445007, 'epoch': 22.62}
{'loss': 0.023, 'grad_norm': 7.938621997833252, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.018032226711511612, 'loss_2': 0.00496673583984375, 'loss_3': -16.33450698852539, 'loss_4': 0.7769864201545715, 'epoch': 22.62}
{'loss': 0.0056, 'grad_norm': 5.142364978790283, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.005159097723662853, 'loss_2': 0.00041103363037109375, 'loss_3': -16.588695526123047, 'loss_4': 0.28043508529663086, 'epoch': 22.63}
{'loss': 0.0075, 'grad_norm': 4.431650638580322, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.004960768856108189, 'loss_2': 0.002552032470703125, 'loss_3': -16.343883514404297, 'loss_4': 0.49423453211784363, 'epoch': 22.63}
{'loss': 0.0095, 'grad_norm': 5.349786281585693, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.004763846285641193, 'loss_2': 0.00470733642578125, 'loss_3': -16.367385864257812, 'loss_4': 0.1476391851902008, 'epoch': 22.64}
{'loss': 0.0196, 'grad_norm': 8.533467292785645, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.011730439960956573, 'loss_2': 0.00787353515625, 'loss_3': -16.396787643432617, 'loss_4': -0.031019240617752075, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 11:02:26,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:26,873 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:35:54<21:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:34,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011464515700936317, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.623, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008789489045739174, 'eval_loss_2': 0.0026750266551971436, 'eval_loss_3': -18.214447021484375, 'eval_loss_4': 0.18611042201519012, 'epoch': 22.65}
{'loss': 0.0075, 'grad_norm': 4.8565592765808105, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.005193936172872782, 'loss_2': 0.002262115478515625, 'loss_3': -16.5476016998291, 'loss_4': 0.22611099481582642, 'epoch': 22.65}
{'loss': 0.0047, 'grad_norm': 4.777441024780273, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.003893544664606452, 'loss_2': 0.000789642333984375, 'loss_3': -16.32416343688965, 'loss_4': 0.13076643645763397, 'epoch': 22.66}
{'loss': 0.0259, 'grad_norm': 7.663107395172119, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.011673509143292904, 'loss_2': 0.014190673828125, 'loss_3': -16.412853240966797, 'loss_4': 0.32845646142959595, 'epoch': 22.66}
{'loss': 0.0116, 'grad_norm': 4.912143707275391, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.006014636252075434, 'loss_2': 0.005584716796875, 'loss_3': -16.495445251464844, 'loss_4': 0.10815240442752838, 'epoch': 22.67}
{'loss': 0.021, 'grad_norm': 7.8545002937316895, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.014075757004320621, 'loss_2': 0.0069122314453125, 'loss_3': -16.2439022064209, 'loss_4': 1.0041613578796387, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 11:02:34,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:34,206 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:01<21:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:41,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012518489733338356, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008670690469443798, 'eval_loss_2': 0.0038478001952171326, 'eval_loss_3': -18.21361541748047, 'eval_loss_4': 0.15329107642173767, 'epoch': 22.67}
{'loss': 0.0056, 'grad_norm': 4.677009582519531, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.0032479194924235344, 'loss_2': 0.0023975372314453125, 'loss_3': -16.636507034301758, 'loss_4': 0.6457698345184326, 'epoch': 22.68}
{'loss': 0.0044, 'grad_norm': 4.479945182800293, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.002911579329520464, 'loss_2': 0.0014476776123046875, 'loss_3': -16.23432159423828, 'loss_4': 0.06503929197788239, 'epoch': 22.69}
{'loss': 0.0265, 'grad_norm': 19.829439163208008, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.02368682064116001, 'loss_2': 0.0027828216552734375, 'loss_3': -16.467247009277344, 'loss_4': 0.17350530624389648, 'epoch': 22.69}
{'loss': 0.0388, 'grad_norm': 15.623127937316895, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.03365764021873474, 'loss_2': 0.00510406494140625, 'loss_3': -16.509292602539062, 'loss_4': 0.0009485017508268356, 'epoch': 22.7}
{'loss': 0.0056, 'grad_norm': 4.801000118255615, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.005044601857662201, 'loss_2': 0.00055694580078125, 'loss_3': -16.320831298828125, 'loss_4': 0.3968113660812378, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 11:02:41,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:41,556 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:08<21:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:02:48,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012987334281206131, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008264021947979927, 'eval_loss_2': 0.004723310470581055, 'eval_loss_3': -18.20995330810547, 'eval_loss_4': 0.1656322479248047, 'epoch': 22.7}
{'loss': 0.0071, 'grad_norm': 4.5081787109375, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.0036249998956918716, 'loss_2': 0.0034637451171875, 'loss_3': -16.562915802001953, 'loss_4': 0.17285554111003876, 'epoch': 22.71}
{'loss': 0.0086, 'grad_norm': 5.046342372894287, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.005459415260702372, 'loss_2': 0.0031147003173828125, 'loss_3': -16.365848541259766, 'loss_4': 0.2864132821559906, 'epoch': 22.72}
{'loss': 0.0078, 'grad_norm': 5.895772457122803, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.0044327387586236, 'loss_2': 0.0033416748046875, 'loss_3': -16.499671936035156, 'loss_4': 0.057433806359767914, 'epoch': 22.72}
{'loss': 0.0095, 'grad_norm': 4.630136966705322, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.003210641909390688, 'loss_2': 0.006313323974609375, 'loss_3': -16.382858276367188, 'loss_4': -0.008521005511283875, 'epoch': 22.73}
{'loss': 0.0069, 'grad_norm': 4.730081558227539, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.004240699112415314, 'loss_2': 0.002613067626953125, 'loss_3': -16.535940170288086, 'loss_4': 0.31836751103401184, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 11:02:48,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:48,881 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:16<21:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:56,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013663452118635178, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.679, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008776756934821606, 'eval_loss_2': 0.004886694252490997, 'eval_loss_3': -18.193359375, 'eval_loss_4': 0.21126602590084076, 'epoch': 22.73}
{'loss': 0.0108, 'grad_norm': 4.748452663421631, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.004951068200170994, 'loss_2': 0.005886077880859375, 'loss_3': -16.460737228393555, 'loss_4': 0.2442934811115265, 'epoch': 22.74}
{'loss': 0.0137, 'grad_norm': 6.2870402336120605, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.010407096706330776, 'loss_2': 0.0032444000244140625, 'loss_3': -16.512802124023438, 'loss_4': 0.2735011875629425, 'epoch': 22.74}
{'loss': 0.0146, 'grad_norm': 7.617034435272217, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.010865027084946632, 'loss_2': 0.00373077392578125, 'loss_3': -16.410232543945312, 'loss_4': 0.09205037355422974, 'epoch': 22.75}
{'loss': 0.0066, 'grad_norm': 4.528195381164551, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.0053108371794223785, 'loss_2': 0.0012531280517578125, 'loss_3': -16.46280860900879, 'loss_4': 0.49017512798309326, 'epoch': 22.76}
{'loss': 0.0086, 'grad_norm': 4.970780849456787, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.007085384335368872, 'loss_2': 0.0015392303466796875, 'loss_3': -16.596227645874023, 'loss_4': 0.5022774338722229, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 11:02:56,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:56,213 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:23<21:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:03,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011910399422049522, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.13, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00833721924573183, 'eval_loss_2': 0.003573179244995117, 'eval_loss_3': -18.17495346069336, 'eval_loss_4': 0.2638760209083557, 'epoch': 22.76}
{'loss': 0.0067, 'grad_norm': 4.529284477233887, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.005402891896665096, 'loss_2': 0.001270294189453125, 'loss_3': -16.451440811157227, 'loss_4': -0.32429951429367065, 'epoch': 22.77}
{'loss': 0.0096, 'grad_norm': 5.03851842880249, 'learning_rate': 7.25e-06, 'loss_1': 0.004747784696519375, 'loss_2': 0.004833221435546875, 'loss_3': -16.65291404724121, 'loss_4': 0.49424514174461365, 'epoch': 22.77}
{'loss': 0.0098, 'grad_norm': 6.083340167999268, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.008734029717743397, 'loss_2': 0.0010509490966796875, 'loss_3': -16.483694076538086, 'loss_4': 0.1530514359474182, 'epoch': 22.78}
{'loss': 0.0086, 'grad_norm': 5.100799560546875, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.004081483464688063, 'loss_2': 0.0045318603515625, 'loss_3': -16.393051147460938, 'loss_4': 0.0981399416923523, 'epoch': 22.78}
{'loss': 0.0084, 'grad_norm': 5.335655212402344, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.006920926738530397, 'loss_2': 0.00152587890625, 'loss_3': -16.217147827148438, 'loss_4': 0.611648440361023, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 11:03:03,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:03,544 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:30<21:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:10,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011910106986761093, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.375, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008579644374549389, 'eval_loss_2': 0.0033304616808891296, 'eval_loss_3': -18.17829704284668, 'eval_loss_4': 0.31988146901130676, 'epoch': 22.79}
{'loss': 0.0122, 'grad_norm': 4.842067718505859, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.005466389004141092, 'loss_2': 0.00677490234375, 'loss_3': -16.416919708251953, 'loss_4': 0.6604858636856079, 'epoch': 22.8}
{'loss': 0.0226, 'grad_norm': 6.736863613128662, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.019459791481494904, 'loss_2': 0.003139495849609375, 'loss_3': -16.3843994140625, 'loss_4': 0.5031668543815613, 'epoch': 22.8}
{'loss': 0.0261, 'grad_norm': 12.678000450134277, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.020431553944945335, 'loss_2': 0.00569915771484375, 'loss_3': -16.264089584350586, 'loss_4': 0.5042537450790405, 'epoch': 22.81}
{'loss': 0.0108, 'grad_norm': 4.5130133628845215, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.004954985808581114, 'loss_2': 0.005840301513671875, 'loss_3': -16.506000518798828, 'loss_4': 0.3182360529899597, 'epoch': 22.81}
{'loss': 0.0079, 'grad_norm': 4.423620700836182, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.004598534666001797, 'loss_2': 0.00331878662109375, 'loss_3': -16.417943954467773, 'loss_4': 0.769986093044281, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 11:03:10,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:10,870 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:38<21:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:18,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01192041952162981, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.921, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008319375105202198, 'eval_loss_2': 0.0036010444164276123, 'eval_loss_3': -18.175281524658203, 'eval_loss_4': 0.3771357536315918, 'epoch': 22.82}
{'loss': 0.0118, 'grad_norm': 6.465259075164795, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.010678880847990513, 'loss_2': 0.0010890960693359375, 'loss_3': -16.2891788482666, 'loss_4': 0.2768697142601013, 'epoch': 22.83}
{'loss': 0.0086, 'grad_norm': 5.383290767669678, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.005540252663195133, 'loss_2': 0.003040313720703125, 'loss_3': -16.294424057006836, 'loss_4': 0.4323919415473938, 'epoch': 22.83}
{'loss': 0.0073, 'grad_norm': 4.8567047119140625, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.0037451956886798143, 'loss_2': 0.003574371337890625, 'loss_3': -16.398412704467773, 'loss_4': 0.761844277381897, 'epoch': 22.84}
{'loss': 0.0144, 'grad_norm': 4.763789653778076, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.008978567086160183, 'loss_2': 0.005462646484375, 'loss_3': -16.332826614379883, 'loss_4': 0.6609443426132202, 'epoch': 22.84}
{'loss': 0.0094, 'grad_norm': 4.956274509429932, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.003923377487808466, 'loss_2': 0.00543975830078125, 'loss_3': -16.468564987182617, 'loss_4': 0.07051917165517807, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 11:03:18,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:18,202 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:36:45<21:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:03:25,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011763504706323147, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00853829737752676, 'eval_loss_2': 0.0032252073287963867, 'eval_loss_3': -18.166091918945312, 'eval_loss_4': 0.42955154180526733, 'epoch': 22.85}
{'loss': 0.0095, 'grad_norm': 5.277223110198975, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.0053016128949820995, 'loss_2': 0.00421142578125, 'loss_3': -16.222087860107422, 'loss_4': 0.2065717577934265, 'epoch': 22.85}
{'loss': 0.0086, 'grad_norm': 4.692508220672607, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.005212088581174612, 'loss_2': 0.003429412841796875, 'loss_3': -16.365087509155273, 'loss_4': 0.4694625735282898, 'epoch': 22.86}
{'loss': 0.0141, 'grad_norm': 7.065925598144531, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.013036884367465973, 'loss_2': 0.0010461807250976562, 'loss_3': -16.22822380065918, 'loss_4': 0.38091492652893066, 'epoch': 22.87}
{'loss': 0.0162, 'grad_norm': 7.937338352203369, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.011412285268306732, 'loss_2': 0.00482177734375, 'loss_3': -16.409162521362305, 'loss_4': 0.5520786046981812, 'epoch': 22.87}
{'loss': 0.0158, 'grad_norm': 4.549502372741699, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.0035610452760010958, 'loss_2': 0.0122528076171875, 'loss_3': -16.129791259765625, 'loss_4': 0.5229933261871338, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 11:03:25,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:25,522 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:36:52<21:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:32,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011996211484074593, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.377, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0080789253115654, 'eval_loss_2': 0.003917288035154343, 'eval_loss_3': -18.17620849609375, 'eval_loss_4': 0.47861772775650024, 'epoch': 22.88}
{'loss': 0.0081, 'grad_norm': 4.529788494110107, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.004256203770637512, 'loss_2': 0.0038928985595703125, 'loss_3': -16.339401245117188, 'loss_4': 0.12705086171627045, 'epoch': 22.88}
{'loss': 0.009, 'grad_norm': 4.980123043060303, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.005390614736825228, 'loss_2': 0.0036220550537109375, 'loss_3': -16.414791107177734, 'loss_4': 0.21621182560920715, 'epoch': 22.89}
{'loss': 0.0047, 'grad_norm': 5.040596961975098, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.004096712917089462, 'loss_2': 0.0005784034729003906, 'loss_3': -16.336877822875977, 'loss_4': 0.856228768825531, 'epoch': 22.9}
{'loss': 0.009, 'grad_norm': 4.844238758087158, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.0045028431341052055, 'loss_2': 0.004505157470703125, 'loss_3': -16.34066390991211, 'loss_4': 0.48380693793296814, 'epoch': 22.9}
{'loss': 0.0217, 'grad_norm': 11.694382667541504, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.0170762799680233, 'loss_2': 0.0046234130859375, 'loss_3': -16.427261352539062, 'loss_4': 0.8009417057037354, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 11:03:32,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:32,849 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:36:59<20:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:03:40,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011786160990595818, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.147, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007892867550253868, 'eval_loss_2': 0.0038932934403419495, 'eval_loss_3': -18.18398666381836, 'eval_loss_4': 0.4836210310459137, 'epoch': 22.91}
{'loss': 0.0032, 'grad_norm': 4.629969596862793, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.0030839748214930296, 'loss_2': 7.730722427368164e-05, 'loss_3': -16.359134674072266, 'loss_4': 0.2844363749027252, 'epoch': 22.91}
{'loss': 0.0095, 'grad_norm': 5.450153350830078, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.00689705228433013, 'loss_2': 0.00257110595703125, 'loss_3': -16.46856117248535, 'loss_4': 0.30893129110336304, 'epoch': 22.92}
{'loss': 0.006, 'grad_norm': 4.776702880859375, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.003987448289990425, 'loss_2': 0.001964569091796875, 'loss_3': -16.458980560302734, 'loss_4': 0.3669750690460205, 'epoch': 22.92}
{'loss': 0.0149, 'grad_norm': 7.462421417236328, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.014080147258937359, 'loss_2': 0.00081634521484375, 'loss_3': -16.207197189331055, 'loss_4': 0.7977640628814697, 'epoch': 22.93}
{'loss': 0.01, 'grad_norm': 5.192819595336914, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.0059587424620985985, 'loss_2': 0.00400543212890625, 'loss_3': -16.37477684020996, 'loss_4': 0.5772395133972168, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 11:03:40,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:40,173 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:07<20:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:47,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01120777428150177, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.73, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007994722574949265, 'eval_loss_2': 0.0032130517065525055, 'eval_loss_3': -18.19542694091797, 'eval_loss_4': 0.5200271606445312, 'epoch': 22.94}
{'loss': 0.0112, 'grad_norm': 5.227271556854248, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.004636862780898809, 'loss_2': 0.00653076171875, 'loss_3': -16.39645767211914, 'loss_4': 0.8963807821273804, 'epoch': 22.94}
{'loss': 0.0181, 'grad_norm': 12.289632797241211, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.01754806935787201, 'loss_2': 0.0005240440368652344, 'loss_3': -16.34374237060547, 'loss_4': 0.6859286427497864, 'epoch': 22.95}
{'loss': 0.0062, 'grad_norm': 4.961906433105469, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.003482803935185075, 'loss_2': 0.00267791748046875, 'loss_3': -16.300268173217773, 'loss_4': 0.5705153346061707, 'epoch': 22.95}
{'loss': 0.0079, 'grad_norm': 4.680317401885986, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.003870983375236392, 'loss_2': 0.0040130615234375, 'loss_3': -16.43952751159668, 'loss_4': 0.47096115350723267, 'epoch': 22.96}
{'loss': 0.0056, 'grad_norm': 4.602134704589844, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.004946491215378046, 'loss_2': 0.00069427490234375, 'loss_3': -16.371212005615234, 'loss_4': 0.2927524447441101, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 11:03:47,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:47,506 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:14<20:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:03:54,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011720037087798119, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.367, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008472872897982597, 'eval_loss_2': 0.0032471641898155212, 'eval_loss_3': -18.204387664794922, 'eval_loss_4': 0.5084174275398254, 'epoch': 22.97}
{'loss': 0.0243, 'grad_norm': 8.755388259887695, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.020243477076292038, 'loss_2': 0.004009246826171875, 'loss_3': -16.5336971282959, 'loss_4': 0.4628181755542755, 'epoch': 22.97}
{'loss': 0.0138, 'grad_norm': 5.483488082885742, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.007049435283988714, 'loss_2': 0.006755828857421875, 'loss_3': -16.550058364868164, 'loss_4': 0.6091679930686951, 'epoch': 22.98}
{'loss': 0.0107, 'grad_norm': 5.020308971405029, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.0078112841583788395, 'loss_2': 0.0029144287109375, 'loss_3': -16.477588653564453, 'loss_4': 0.5083887577056885, 'epoch': 22.98}
{'loss': 0.0058, 'grad_norm': 4.437625885009766, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.004247545730322599, 'loss_2': 0.0015993118286132812, 'loss_3': -16.409730911254883, 'loss_4': 0.6241710186004639, 'epoch': 22.99}
{'loss': 0.0044, 'grad_norm': 4.373804569244385, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.003994497936218977, 'loss_2': 0.0004425048828125, 'loss_3': -16.46100616455078, 'loss_4': 0.3155669569969177, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 11:03:54,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:54,812 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:21<20:17,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 11:04:01,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012029856443405151, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.007, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008338049054145813, 'eval_loss_2': 0.0036918073892593384, 'eval_loss_3': -18.22572135925293, 'eval_loss_4': 0.4619801938533783, 'epoch': 22.99}
{'loss': 0.011, 'grad_norm': 7.697559356689453, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.00490275863558054, 'loss_2': 0.0060577392578125, 'loss_3': -16.19911766052246, 'loss_4': 0.6608866453170776, 'epoch': 23.0}
{'loss': 0.0113, 'grad_norm': 5.084774494171143, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.005780993495136499, 'loss_2': 0.00555419921875, 'loss_3': -16.4842472076416, 'loss_4': 0.01345151662826538, 'epoch': 23.01}
{'loss': 0.0156, 'grad_norm': 5.5267720222473145, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.008529417216777802, 'loss_2': 0.00705718994140625, 'loss_3': -16.41982650756836, 'loss_4': 0.6284846067428589, 'epoch': 23.01}
{'loss': 0.0169, 'grad_norm': 13.249199867248535, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.013937876559793949, 'loss_2': 0.00298309326171875, 'loss_3': -16.436155319213867, 'loss_4': 0.8043248653411865, 'epoch': 23.02}
{'loss': 0.0049, 'grad_norm': 4.410161972045898, 'learning_rate': 7e-06, 'loss_1': 0.004712396301329136, 'loss_2': 0.00021409988403320312, 'loss_3': -16.539203643798828, 'loss_4': 0.6777792572975159, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 11:04:01,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:01,848 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:28<20:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:04:09,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012477436102926731, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.352, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008066276088356972, 'eval_loss_2': 0.004411160945892334, 'eval_loss_3': -18.223773956298828, 'eval_loss_4': 0.46597886085510254, 'epoch': 23.02}
{'loss': 0.0143, 'grad_norm': 6.955770969390869, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.009686817415058613, 'loss_2': 0.00457000732421875, 'loss_3': -16.508296966552734, 'loss_4': 0.3684888184070587, 'epoch': 23.03}
{'loss': 0.0209, 'grad_norm': 6.952790260314941, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.01472514122724533, 'loss_2': 0.006195068359375, 'loss_3': -16.22643280029297, 'loss_4': 0.3193177580833435, 'epoch': 23.03}
{'loss': 0.009, 'grad_norm': 5.181910037994385, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.0072151124477386475, 'loss_2': 0.001766204833984375, 'loss_3': -16.329715728759766, 'loss_4': 0.5076739192008972, 'epoch': 23.04}
{'loss': 0.0154, 'grad_norm': 5.085172176361084, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.004980207420885563, 'loss_2': 0.01041412353515625, 'loss_3': -16.28461456298828, 'loss_4': 0.5404466986656189, 'epoch': 23.05}
{'loss': 0.0086, 'grad_norm': 4.872875213623047, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.006478373892605305, 'loss_2': 0.0021514892578125, 'loss_3': -16.33074188232422, 'loss_4': 0.21967291831970215, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 11:04:09,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:09,171 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:36<20:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:16,502 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011011701077222824, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.274, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007464629132300615, 'eval_loss_2': 0.003547072410583496, 'eval_loss_3': -18.234966278076172, 'eval_loss_4': 0.5026980638504028, 'epoch': 23.05}
{'loss': 0.0086, 'grad_norm': 4.888789176940918, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.0031955267768353224, 'loss_2': 0.00543975830078125, 'loss_3': -16.44607162475586, 'loss_4': 0.39519360661506653, 'epoch': 23.06}
{'loss': 0.0145, 'grad_norm': 5.250086784362793, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.004746549762785435, 'loss_2': 0.00970458984375, 'loss_3': -16.40467071533203, 'loss_4': -0.03695988655090332, 'epoch': 23.06}
{'loss': 0.0101, 'grad_norm': 5.212701797485352, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.0060117910616099834, 'loss_2': 0.004039764404296875, 'loss_3': -16.403167724609375, 'loss_4': 0.4636842608451843, 'epoch': 23.07}
{'loss': 0.023, 'grad_norm': 7.161050319671631, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.017683226615190506, 'loss_2': 0.005279541015625, 'loss_3': -16.36583709716797, 'loss_4': 0.8651294708251953, 'epoch': 23.08}
{'loss': 0.0093, 'grad_norm': 5.327999114990234, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.007799989078193903, 'loss_2': 0.001514434814453125, 'loss_3': -16.48570442199707, 'loss_4': 0.3380812406539917, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 11:04:16,502 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:16,502 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:37:43<20:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:23,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011553032323718071, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.065, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007745188195258379, 'eval_loss_2': 0.00380784273147583, 'eval_loss_3': -18.23116111755371, 'eval_loss_4': 0.5235911011695862, 'epoch': 23.08}
{'loss': 0.0063, 'grad_norm': 4.892158508300781, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.00260903500020504, 'loss_2': 0.0036754608154296875, 'loss_3': -16.55730438232422, 'loss_4': 0.8145562410354614, 'epoch': 23.09}
{'loss': 0.0057, 'grad_norm': 4.609711647033691, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.005636520683765411, 'loss_2': 4.649162292480469e-05, 'loss_3': -16.481218338012695, 'loss_4': 0.6342646479606628, 'epoch': 23.09}
{'loss': 0.0081, 'grad_norm': 5.115566253662109, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.007869604974985123, 'loss_2': 0.00026297569274902344, 'loss_3': -16.624980926513672, 'loss_4': 0.0716656744480133, 'epoch': 23.1}
{'loss': 0.0079, 'grad_norm': 4.487971305847168, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.003156735096126795, 'loss_2': 0.004734039306640625, 'loss_3': -16.41284942626953, 'loss_4': 0.7083543539047241, 'epoch': 23.1}
{'loss': 0.0188, 'grad_norm': 5.32021427154541, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.006898343097418547, 'loss_2': 0.0119476318359375, 'loss_3': -16.42266845703125, 'loss_4': 0.4955218434333801, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 11:04:23,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:23,848 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:37:50<20:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:31,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012732421047985554, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007952485233545303, 'eval_loss_2': 0.004779934883117676, 'eval_loss_3': -18.219890594482422, 'eval_loss_4': 0.5584613084793091, 'epoch': 23.11}
{'loss': 0.0106, 'grad_norm': 5.3850555419921875, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.00754142040386796, 'loss_2': 0.0030975341796875, 'loss_3': -16.467662811279297, 'loss_4': 0.21252459287643433, 'epoch': 23.12}
{'loss': 0.0089, 'grad_norm': 4.7811598777771, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.004522797651588917, 'loss_2': 0.00433349609375, 'loss_3': -16.800018310546875, 'loss_4': 0.8056558966636658, 'epoch': 23.12}
{'loss': 0.009, 'grad_norm': 4.80190896987915, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.003148664254695177, 'loss_2': 0.005859375, 'loss_3': -16.64769172668457, 'loss_4': 0.5138376355171204, 'epoch': 23.13}
{'loss': 0.0108, 'grad_norm': 5.454202651977539, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.009066326543688774, 'loss_2': 0.001697540283203125, 'loss_3': -16.3645076751709, 'loss_4': 0.394001305103302, 'epoch': 23.13}
{'loss': 0.0352, 'grad_norm': 16.2639102935791, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.02689865417778492, 'loss_2': 0.008270263671875, 'loss_3': -16.44603729248047, 'loss_4': 0.46136474609375, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 11:04:31,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:31,171 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:37:58<20:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:38,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013647648505866528, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.201, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007420363370329142, 'eval_loss_2': 0.006227284669876099, 'eval_loss_3': -18.223834991455078, 'eval_loss_4': 0.610318660736084, 'epoch': 23.14}
{'loss': 0.0247, 'grad_norm': 8.141120910644531, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.019821101799607277, 'loss_2': 0.00492095947265625, 'loss_3': -16.364049911499023, 'loss_4': 0.9526513814926147, 'epoch': 23.15}
{'loss': 0.0155, 'grad_norm': 4.404401779174805, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.006345195695757866, 'loss_2': 0.009124755859375, 'loss_3': -16.5740966796875, 'loss_4': 1.038621425628662, 'epoch': 23.15}
{'loss': 0.041, 'grad_norm': 17.915611267089844, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.037842292338609695, 'loss_2': 0.003204345703125, 'loss_3': -16.3007869720459, 'loss_4': 0.7472285032272339, 'epoch': 23.16}
{'loss': 0.0238, 'grad_norm': 8.054510116577148, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.009022065438330173, 'loss_2': 0.0147857666015625, 'loss_3': -16.600196838378906, 'loss_4': 0.8276200294494629, 'epoch': 23.16}
{'loss': 0.0203, 'grad_norm': 7.6075544357299805, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.011404851451516151, 'loss_2': 0.00885009765625, 'loss_3': -16.24561309814453, 'loss_4': 1.1475862264633179, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 11:04:38,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:38,500 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:05<20:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:45,823 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013557713478803635, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.34, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007377185858786106, 'eval_loss_2': 0.006180528551340103, 'eval_loss_3': -18.228694915771484, 'eval_loss_4': 0.6721779108047485, 'epoch': 23.17}
{'loss': 0.0224, 'grad_norm': 14.101073265075684, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.01962805725634098, 'loss_2': 0.002796173095703125, 'loss_3': -16.463878631591797, 'loss_4': 0.48975834250450134, 'epoch': 23.17}
{'loss': 0.0262, 'grad_norm': 8.141030311584473, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.018042808398604393, 'loss_2': 0.00817108154296875, 'loss_3': -16.367816925048828, 'loss_4': 1.0977622270584106, 'epoch': 23.18}
{'loss': 0.0097, 'grad_norm': 4.301985263824463, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.004058649763464928, 'loss_2': 0.005664825439453125, 'loss_3': -16.389001846313477, 'loss_4': 0.34500551223754883, 'epoch': 23.19}
{'loss': 0.0067, 'grad_norm': 4.649608612060547, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.0049535902217030525, 'loss_2': 0.0017757415771484375, 'loss_3': -16.417356491088867, 'loss_4': 0.8045454025268555, 'epoch': 23.19}
{'loss': 0.0066, 'grad_norm': 4.926724433898926, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.005403971299529076, 'loss_2': 0.0011577606201171875, 'loss_3': -16.54650115966797, 'loss_4': 0.7965936064720154, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 11:04:45,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:45,823 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:12<20:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:53,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012104496359825134, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.343, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0071835508570075035, 'eval_loss_2': 0.004920944571495056, 'eval_loss_3': -18.231332778930664, 'eval_loss_4': 0.6626076102256775, 'epoch': 23.2}
{'loss': 0.006, 'grad_norm': 4.360988140106201, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.0038905444089323282, 'loss_2': 0.0021209716796875, 'loss_3': -16.518035888671875, 'loss_4': 0.6712896227836609, 'epoch': 23.2}
{'loss': 0.0067, 'grad_norm': 4.926290988922119, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.005540330894291401, 'loss_2': 0.0012073516845703125, 'loss_3': -16.487430572509766, 'loss_4': 0.5631794929504395, 'epoch': 23.21}
{'loss': 0.0131, 'grad_norm': 5.630588531494141, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.008879203349351883, 'loss_2': 0.004268646240234375, 'loss_3': -16.517044067382812, 'loss_4': 0.7289665937423706, 'epoch': 23.22}
{'loss': 0.0079, 'grad_norm': 4.4254069328308105, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.0027390513569116592, 'loss_2': 0.00518035888671875, 'loss_3': -16.53597068786621, 'loss_4': 1.0003087520599365, 'epoch': 23.22}
{'loss': 0.0135, 'grad_norm': 5.932522773742676, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.008639691397547722, 'loss_2': 0.004852294921875, 'loss_3': -16.57862091064453, 'loss_4': 0.9033628702163696, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 11:04:53,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:53,153 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:20<20:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:00,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011093739420175552, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.353, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007275763433426619, 'eval_loss_2': 0.0038179755210876465, 'eval_loss_3': -18.229660034179688, 'eval_loss_4': 0.6893655061721802, 'epoch': 23.23}
{'loss': 0.0107, 'grad_norm': 4.94683313369751, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.006799712777137756, 'loss_2': 0.00388336181640625, 'loss_3': -16.375255584716797, 'loss_4': 0.770478367805481, 'epoch': 23.23}
{'loss': 0.0119, 'grad_norm': 4.918802738189697, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.005209147464483976, 'loss_2': 0.00669097900390625, 'loss_3': -16.553173065185547, 'loss_4': 0.8759697675704956, 'epoch': 23.24}
{'loss': 0.0098, 'grad_norm': 5.059175968170166, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.007876832038164139, 'loss_2': 0.0019245147705078125, 'loss_3': -16.23731231689453, 'loss_4': 0.5503731369972229, 'epoch': 23.24}
{'loss': 0.0258, 'grad_norm': 8.751935005187988, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.016748130321502686, 'loss_2': 0.009063720703125, 'loss_3': -16.437952041625977, 'loss_4': 0.5286303758621216, 'epoch': 23.25}
{'loss': 0.0053, 'grad_norm': 5.221050262451172, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.0044561512768268585, 'loss_2': 0.000850677490234375, 'loss_3': -16.462080001831055, 'loss_4': 0.6457973718643188, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 11:05:00,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:00,477 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:27<19:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:05:07,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011032326146960258, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.915, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007582259830087423, 'eval_loss_2': 0.003450065851211548, 'eval_loss_3': -18.215435028076172, 'eval_loss_4': 0.7442628741264343, 'epoch': 23.26}
{'loss': 0.015, 'grad_norm': 5.122915267944336, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.008821492083370686, 'loss_2': 0.006195068359375, 'loss_3': -16.38119125366211, 'loss_4': 0.9693121910095215, 'epoch': 23.26}
{'loss': 0.0093, 'grad_norm': 5.872177600860596, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.006185843143612146, 'loss_2': 0.003124237060546875, 'loss_3': -16.33772850036621, 'loss_4': 0.5649442672729492, 'epoch': 23.27}
{'loss': 0.0134, 'grad_norm': 4.897177696228027, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.006169167347252369, 'loss_2': 0.007274627685546875, 'loss_3': -16.356494903564453, 'loss_4': 0.7320910692214966, 'epoch': 23.27}
{'loss': 0.0084, 'grad_norm': 5.263998031616211, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.004585011396557093, 'loss_2': 0.00385284423828125, 'loss_3': -16.670921325683594, 'loss_4': 1.1954617500305176, 'epoch': 23.28}
{'loss': 0.01, 'grad_norm': 5.830981254577637, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.009511609561741352, 'loss_2': 0.0004911422729492188, 'loss_3': -16.55068016052246, 'loss_4': 0.6798611879348755, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 11:05:07,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:07,806 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:34<19:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:15,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010344868525862694, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.299, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007314568851143122, 'eval_loss_2': 0.0030303001403808594, 'eval_loss_3': -18.20706558227539, 'eval_loss_4': 0.8659051656723022, 'epoch': 23.28}
{'loss': 0.0089, 'grad_norm': 4.721722602844238, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.004629818256944418, 'loss_2': 0.00429534912109375, 'loss_3': -16.238798141479492, 'loss_4': 1.0524182319641113, 'epoch': 23.29}
{'loss': 0.0165, 'grad_norm': 7.06967306137085, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.014835236594080925, 'loss_2': 0.0016613006591796875, 'loss_3': -16.15972328186035, 'loss_4': 1.2057042121887207, 'epoch': 23.3}
{'loss': 0.0083, 'grad_norm': 6.731633186340332, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0066797565668821335, 'loss_2': 0.001636505126953125, 'loss_3': -16.383010864257812, 'loss_4': 1.0118255615234375, 'epoch': 23.3}
{'loss': 0.0073, 'grad_norm': 5.493630886077881, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.00615845387801528, 'loss_2': 0.00118255615234375, 'loss_3': -16.476228713989258, 'loss_4': 0.9304394125938416, 'epoch': 23.31}
{'loss': 0.0071, 'grad_norm': 4.166937828063965, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.003963780589401722, 'loss_2': 0.00315093994140625, 'loss_3': -16.253036499023438, 'loss_4': 1.076960563659668, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 11:05:15,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:15,129 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:42<19:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:22,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0109860859811306, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.2, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007744443602859974, 'eval_loss_2': 0.0032416433095932007, 'eval_loss_3': -18.190126419067383, 'eval_loss_4': 0.9569565057754517, 'epoch': 23.31}
{'loss': 0.0085, 'grad_norm': 4.354608535766602, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.005069783888757229, 'loss_2': 0.0034332275390625, 'loss_3': -16.475645065307617, 'loss_4': 1.3077763319015503, 'epoch': 23.32}
{'loss': 0.0127, 'grad_norm': 4.848154067993164, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.004875644110143185, 'loss_2': 0.0078277587890625, 'loss_3': -16.51907730102539, 'loss_4': 1.0318527221679688, 'epoch': 23.33}
{'loss': 0.0142, 'grad_norm': 7.553998947143555, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.011784407310187817, 'loss_2': 0.002460479736328125, 'loss_3': -16.198631286621094, 'loss_4': 1.163384199142456, 'epoch': 23.33}
{'loss': 0.0082, 'grad_norm': 4.714188098907471, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.007120607420802116, 'loss_2': 0.0010471343994140625, 'loss_3': -16.447696685791016, 'loss_4': 1.0119187831878662, 'epoch': 23.34}
{'loss': 0.0077, 'grad_norm': 5.049927711486816, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.006977553945034742, 'loss_2': 0.0007181167602539062, 'loss_3': -16.44115447998047, 'loss_4': 1.116161584854126, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 11:05:22,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:22,460 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:38:49<19:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:29,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011413762345910072, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.047, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0075566875748336315, 'eval_loss_2': 0.0038570761680603027, 'eval_loss_3': -18.16485023498535, 'eval_loss_4': 1.055168628692627, 'epoch': 23.34}
{'loss': 0.009, 'grad_norm': 4.4538798332214355, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.002238640794530511, 'loss_2': 0.0067901611328125, 'loss_3': -16.340229034423828, 'loss_4': 1.0687942504882812, 'epoch': 23.35}
{'loss': 0.0206, 'grad_norm': 9.652405738830566, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.01320224441587925, 'loss_2': 0.0074462890625, 'loss_3': -16.287912368774414, 'loss_4': 0.7072687149047852, 'epoch': 23.35}
{'loss': 0.0182, 'grad_norm': 6.3322553634643555, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.011746606789529324, 'loss_2': 0.00644683837890625, 'loss_3': -16.421863555908203, 'loss_4': 0.8928402662277222, 'epoch': 23.36}
{'loss': 0.0251, 'grad_norm': 8.387097358703613, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.01648336835205555, 'loss_2': 0.0085906982421875, 'loss_3': -16.337087631225586, 'loss_4': 1.0457611083984375, 'epoch': 23.37}
{'loss': 0.012, 'grad_norm': 4.869161605834961, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.00623320322483778, 'loss_2': 0.005809783935546875, 'loss_3': -16.493999481201172, 'loss_4': 1.1988024711608887, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 11:05:29,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:29,797 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:38:56<19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:37,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010607019066810608, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.343, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0068317800760269165, 'eval_loss_2': 0.0037752389907836914, 'eval_loss_3': -18.158607482910156, 'eval_loss_4': 1.1022237539291382, 'epoch': 23.37}
{'loss': 0.0091, 'grad_norm': 5.185332298278809, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.005900324322283268, 'loss_2': 0.003246307373046875, 'loss_3': -16.56998062133789, 'loss_4': 0.9055601358413696, 'epoch': 23.38}
{'loss': 0.0102, 'grad_norm': 5.084212303161621, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.004743873607367277, 'loss_2': 0.00548553466796875, 'loss_3': -16.333402633666992, 'loss_4': 1.5140202045440674, 'epoch': 23.38}
{'loss': 0.0086, 'grad_norm': 5.261223316192627, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.004623980261385441, 'loss_2': 0.00394439697265625, 'loss_3': -16.43623161315918, 'loss_4': 1.3242807388305664, 'epoch': 23.39}
{'loss': 0.0118, 'grad_norm': 4.73822021484375, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.007138339802622795, 'loss_2': 0.004638671875, 'loss_3': -16.292387008666992, 'loss_4': 0.7611148357391357, 'epoch': 23.4}
{'loss': 0.0083, 'grad_norm': 4.8423991203308105, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.0066041238605976105, 'loss_2': 0.0016841888427734375, 'loss_3': -16.33067512512207, 'loss_4': 0.9346986413002014, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 11:05:37,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:37,125 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:04<19:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:44,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010079707950353622, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.105, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.006912137381732464, 'eval_loss_2': 0.003167569637298584, 'eval_loss_3': -18.15576171875, 'eval_loss_4': 1.1118347644805908, 'epoch': 23.4}
{'loss': 0.0099, 'grad_norm': 7.013051986694336, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.009714805521070957, 'loss_2': 0.00018656253814697266, 'loss_3': -16.709178924560547, 'loss_4': 1.1250191926956177, 'epoch': 23.41}
{'loss': 0.021, 'grad_norm': 7.0875444412231445, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.012090422213077545, 'loss_2': 0.00893402099609375, 'loss_3': -16.544769287109375, 'loss_4': 1.6198127269744873, 'epoch': 23.41}
{'loss': 0.0047, 'grad_norm': 4.8545308113098145, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.0037898258306086063, 'loss_2': 0.0008783340454101562, 'loss_3': -16.351613998413086, 'loss_4': 1.075333595275879, 'epoch': 23.42}
{'loss': 0.0139, 'grad_norm': 5.13766622543335, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.008291925303637981, 'loss_2': 0.005649566650390625, 'loss_3': -16.44125747680664, 'loss_4': 1.382224678993225, 'epoch': 23.42}
{'loss': 0.0134, 'grad_norm': 4.4441986083984375, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.003463280387222767, 'loss_2': 0.0099029541015625, 'loss_3': -16.592880249023438, 'loss_4': 1.283534288406372, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 11:05:44,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:44,467 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:11<19:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:51,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011641088873147964, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.163, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0069730537943542, 'eval_loss_2': 0.004668034613132477, 'eval_loss_3': -18.15631675720215, 'eval_loss_4': 1.1917673349380493, 'epoch': 23.43}
{'loss': 0.0068, 'grad_norm': 4.140147686004639, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.002596078207716346, 'loss_2': 0.0041961669921875, 'loss_3': -16.535938262939453, 'loss_4': 1.2184306383132935, 'epoch': 23.44}
{'loss': 0.0076, 'grad_norm': 5.24008321762085, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.0075333453714847565, 'loss_2': 8.445978164672852e-05, 'loss_3': -16.421897888183594, 'loss_4': 1.3990212678909302, 'epoch': 23.44}
{'loss': 0.0114, 'grad_norm': 5.795862197875977, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.008288916200399399, 'loss_2': 0.0030765533447265625, 'loss_3': -16.291080474853516, 'loss_4': 1.182305097579956, 'epoch': 23.45}
{'loss': 0.0096, 'grad_norm': 5.386077880859375, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.0072254310362041, 'loss_2': 0.0023441314697265625, 'loss_3': -16.284339904785156, 'loss_4': 1.5779908895492554, 'epoch': 23.45}
{'loss': 0.0038, 'grad_norm': 4.707625389099121, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.0030846898443996906, 'loss_2': 0.0007085800170898438, 'loss_3': -16.543859481811523, 'loss_4': 1.0325146913528442, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 11:05:51,796 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:51,796 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:18<19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:59,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012816039845347404, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008311299607157707, 'eval_loss_2': 0.004504740238189697, 'eval_loss_3': -18.12512969970703, 'eval_loss_4': 1.2915732860565186, 'epoch': 23.46}
{'loss': 0.022, 'grad_norm': 6.447464942932129, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.017531517893075943, 'loss_2': 0.0045166015625, 'loss_3': -16.37925148010254, 'loss_4': 1.3071397542953491, 'epoch': 23.47}
{'loss': 0.0114, 'grad_norm': 6.440742492675781, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.0074478755705058575, 'loss_2': 0.003997802734375, 'loss_3': -16.442581176757812, 'loss_4': 1.3330533504486084, 'epoch': 23.47}
{'loss': 0.0096, 'grad_norm': 5.61126708984375, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.007331942208111286, 'loss_2': 0.00231170654296875, 'loss_3': -16.467870712280273, 'loss_4': 1.6038347482681274, 'epoch': 23.48}
{'loss': 0.0112, 'grad_norm': 6.532985687255859, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.008430342189967632, 'loss_2': 0.0028018951416015625, 'loss_3': -16.45785140991211, 'loss_4': 1.4839527606964111, 'epoch': 23.48}
{'loss': 0.0118, 'grad_norm': 5.83127498626709, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.010722761042416096, 'loss_2': 0.0010547637939453125, 'loss_3': -16.49404525756836, 'loss_4': 1.452445149421692, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 11:05:59,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:59,123 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:26<19:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:06,455 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012734757736325264, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.16, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.009173589758574963, 'eval_loss_2': 0.003561168909072876, 'eval_loss_3': -18.12263298034668, 'eval_loss_4': 1.3622634410858154, 'epoch': 23.49}
{'loss': 0.0166, 'grad_norm': 6.642958641052246, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.01106016244739294, 'loss_2': 0.005535125732421875, 'loss_3': -16.473039627075195, 'loss_4': 1.425110936164856, 'epoch': 23.49}
{'loss': 0.0142, 'grad_norm': 7.63509464263916, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.013475277461111546, 'loss_2': 0.0007686614990234375, 'loss_3': -16.224552154541016, 'loss_4': 1.202573299407959, 'epoch': 23.5}
{'loss': 0.0058, 'grad_norm': 5.348362445831299, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.005404005292803049, 'loss_2': 0.00034809112548828125, 'loss_3': -16.334224700927734, 'loss_4': 1.3654358386993408, 'epoch': 23.51}
{'loss': 0.0128, 'grad_norm': 6.3454790115356445, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.0109175406396389, 'loss_2': 0.0018529891967773438, 'loss_3': -16.408409118652344, 'loss_4': 1.6575888395309448, 'epoch': 23.51}
{'loss': 0.0153, 'grad_norm': 5.763885021209717, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.011089620180428028, 'loss_2': 0.004184722900390625, 'loss_3': -16.569677352905273, 'loss_4': 1.4062881469726562, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 11:06:06,455 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:06,455 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:33<19:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:13,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013005847111344337, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.249, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.010036046616733074, 'eval_loss_2': 0.002969801425933838, 'eval_loss_3': -18.11550521850586, 'eval_loss_4': 1.4421714544296265, 'epoch': 23.52}
{'loss': 0.0143, 'grad_norm': 4.919811248779297, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.007247362285852432, 'loss_2': 0.007080078125, 'loss_3': -16.29790687561035, 'loss_4': 1.599208116531372, 'epoch': 23.52}
{'loss': 0.0081, 'grad_norm': 4.812908172607422, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.006333090830594301, 'loss_2': 0.001766204833984375, 'loss_3': -16.419666290283203, 'loss_4': 1.8444507122039795, 'epoch': 23.53}
{'loss': 0.0103, 'grad_norm': 5.350727558135986, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.010010222904384136, 'loss_2': 0.0002932548522949219, 'loss_3': -16.464000701904297, 'loss_4': 1.0435999631881714, 'epoch': 23.53}
{'loss': 0.0112, 'grad_norm': 5.316407203674316, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.0073926751501858234, 'loss_2': 0.00382232666015625, 'loss_3': -16.449748992919922, 'loss_4': 1.5388567447662354, 'epoch': 23.54}
{'loss': 0.0144, 'grad_norm': 6.3911943435668945, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.00967985950410366, 'loss_2': 0.0047454833984375, 'loss_3': -16.35684585571289, 'loss_4': 1.459699034690857, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 11:06:13,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:13,788 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:40<19:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:21,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013589367270469666, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.506, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.010031774640083313, 'eval_loss_2': 0.0035575926303863525, 'eval_loss_3': -18.112680435180664, 'eval_loss_4': 1.463973045349121, 'epoch': 23.55}
{'loss': 0.0063, 'grad_norm': 4.556380271911621, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.005813737399876118, 'loss_2': 0.00044918060302734375, 'loss_3': -16.491958618164062, 'loss_4': 1.4050151109695435, 'epoch': 23.55}
{'loss': 0.0115, 'grad_norm': 5.114965915679932, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.005645063705742359, 'loss_2': 0.0058746337890625, 'loss_3': -16.471725463867188, 'loss_4': 1.570598840713501, 'epoch': 23.56}
{'loss': 0.0194, 'grad_norm': 18.426427841186523, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.01936580240726471, 'loss_2': 4.774332046508789e-05, 'loss_3': -16.09246826171875, 'loss_4': 1.5794644355773926, 'epoch': 23.56}
{'loss': 0.0171, 'grad_norm': 5.46073579788208, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.008109468966722488, 'loss_2': 0.009002685546875, 'loss_3': -16.39767837524414, 'loss_4': 0.9086114168167114, 'epoch': 23.57}
{'loss': 0.0133, 'grad_norm': 4.666665554046631, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.006192099303007126, 'loss_2': 0.00714874267578125, 'loss_3': -16.419681549072266, 'loss_4': 1.8265247344970703, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 11:06:21,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:21,113 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:39:48<19:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:28,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011486006900668144, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.57, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007440253160893917, 'eval_loss_2': 0.004045754671096802, 'eval_loss_3': -18.146581649780273, 'eval_loss_4': 1.4079980850219727, 'epoch': 23.58}
{'loss': 0.0203, 'grad_norm': 10.870755195617676, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.014706844463944435, 'loss_2': 0.005641937255859375, 'loss_3': -16.31369972229004, 'loss_4': 1.8221688270568848, 'epoch': 23.58}
{'loss': 0.0126, 'grad_norm': 4.942387580871582, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.006628021132200956, 'loss_2': 0.00598907470703125, 'loss_3': -16.322437286376953, 'loss_4': 1.3515665531158447, 'epoch': 23.59}
{'loss': 0.0056, 'grad_norm': 4.702827453613281, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.0035768288653343916, 'loss_2': 0.0020427703857421875, 'loss_3': -16.446563720703125, 'loss_4': 1.3502602577209473, 'epoch': 23.59}
{'loss': 0.0235, 'grad_norm': 10.273303985595703, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.017288586124777794, 'loss_2': 0.006183624267578125, 'loss_3': -16.38296127319336, 'loss_4': 1.1507822275161743, 'epoch': 23.6}
{'loss': 0.0087, 'grad_norm': 4.833154201507568, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.005605567246675491, 'loss_2': 0.003093719482421875, 'loss_3': -16.53896713256836, 'loss_4': 1.4173610210418701, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 11:06:28,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:28,460 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:39:55<18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:35,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010313548147678375, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.318, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006940043997019529, 'eval_loss_2': 0.0033735036849975586, 'eval_loss_3': -18.157594680786133, 'eval_loss_4': 1.3833026885986328, 'epoch': 23.6}
{'loss': 0.0145, 'grad_norm': 5.931334972381592, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.011863862164318562, 'loss_2': 0.0026378631591796875, 'loss_3': -16.38861656188965, 'loss_4': 1.762878656387329, 'epoch': 23.61}
{'loss': 0.0122, 'grad_norm': 6.495617389678955, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.009038831107318401, 'loss_2': 0.0031909942626953125, 'loss_3': -16.228309631347656, 'loss_4': 1.4237852096557617, 'epoch': 23.62}
{'loss': 0.016, 'grad_norm': 5.488777160644531, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.01298797968775034, 'loss_2': 0.002994537353515625, 'loss_3': -16.323619842529297, 'loss_4': 1.7648555040359497, 'epoch': 23.62}
{'loss': 0.0066, 'grad_norm': 5.340904235839844, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.005991439800709486, 'loss_2': 0.0006361007690429688, 'loss_3': -16.11648178100586, 'loss_4': 1.4507744312286377, 'epoch': 23.63}
{'loss': 0.01, 'grad_norm': 5.215177059173584, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.005197032820433378, 'loss_2': 0.00476837158203125, 'loss_3': -16.40390396118164, 'loss_4': 1.500538945198059, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 11:06:35,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:35,785 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:02<18:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:43,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009800679981708527, 'eval_runtime': 3.7827, 'eval_samples_per_second': 270.709, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.0066067809239029884, 'eval_loss_2': 0.003193899989128113, 'eval_loss_3': -18.161008834838867, 'eval_loss_4': 1.344603180885315, 'epoch': 23.63}
{'loss': 0.0209, 'grad_norm': 8.393763542175293, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.015876704826951027, 'loss_2': 0.00502777099609375, 'loss_3': -16.229368209838867, 'loss_4': 1.4569005966186523, 'epoch': 23.64}
{'loss': 0.0076, 'grad_norm': 4.464080333709717, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.004235454834997654, 'loss_2': 0.003330230712890625, 'loss_3': -16.475299835205078, 'loss_4': 1.5192290544509888, 'epoch': 23.65}
{'loss': 0.0094, 'grad_norm': 4.80602502822876, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.007174196187406778, 'loss_2': 0.002193450927734375, 'loss_3': -16.42497444152832, 'loss_4': 1.5947160720825195, 'epoch': 23.65}
{'loss': 0.01, 'grad_norm': 5.281242370605469, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.007085816469043493, 'loss_2': 0.002864837646484375, 'loss_3': -16.421466827392578, 'loss_4': 1.6695590019226074, 'epoch': 23.66}
{'loss': 0.0095, 'grad_norm': 4.481557369232178, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.004447183106094599, 'loss_2': 0.00507354736328125, 'loss_3': -16.173568725585938, 'loss_4': 1.584019660949707, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 11:06:43,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:43,106 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:10<18:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:50,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009501284919679165, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.511, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.006314582657068968, 'eval_loss_2': 0.0031867027282714844, 'eval_loss_3': -18.17131996154785, 'eval_loss_4': 1.3338810205459595, 'epoch': 23.66}
{'loss': 0.0092, 'grad_norm': 5.032063007354736, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.008233211934566498, 'loss_2': 0.0009822845458984375, 'loss_3': -16.18619155883789, 'loss_4': 1.5007901191711426, 'epoch': 23.67}
{'loss': 0.0136, 'grad_norm': 4.263148307800293, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.007859337143599987, 'loss_2': 0.005706787109375, 'loss_3': -16.29471206665039, 'loss_4': 1.6069718599319458, 'epoch': 23.67}
{'loss': 0.0158, 'grad_norm': 5.397561550140381, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.009935641661286354, 'loss_2': 0.005889892578125, 'loss_3': -16.288373947143555, 'loss_4': 1.0162404775619507, 'epoch': 23.68}
{'loss': 0.0128, 'grad_norm': 4.365069389343262, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.005512954201549292, 'loss_2': 0.0073089599609375, 'loss_3': -16.359882354736328, 'loss_4': 1.3798332214355469, 'epoch': 23.69}
{'loss': 0.0076, 'grad_norm': 5.164566516876221, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.0072593968361616135, 'loss_2': 0.0003676414489746094, 'loss_3': -16.34958267211914, 'loss_4': 1.5483307838439941, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 11:06:50,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:50,432 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:17<18:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:57,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008657848462462425, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.691, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.0056904456578195095, 'eval_loss_2': 0.0029674023389816284, 'eval_loss_3': -18.187294006347656, 'eval_loss_4': 1.3362269401550293, 'epoch': 23.69}
{'loss': 0.0068, 'grad_norm': 5.179295539855957, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.003976211883127689, 'loss_2': 0.00278472900390625, 'loss_3': -16.36009407043457, 'loss_4': 1.3387467861175537, 'epoch': 23.7}
{'loss': 0.0059, 'grad_norm': 4.285379886627197, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.0032118703238666058, 'loss_2': 0.002655029296875, 'loss_3': -16.460433959960938, 'loss_4': 1.701737642288208, 'epoch': 23.7}
{'loss': 0.0088, 'grad_norm': 4.601234436035156, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.0037631290033459663, 'loss_2': 0.00505828857421875, 'loss_3': -16.28704261779785, 'loss_4': 1.3320975303649902, 'epoch': 23.71}
{'loss': 0.0112, 'grad_norm': 8.067898750305176, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.010102270171046257, 'loss_2': 0.001132965087890625, 'loss_3': -16.311477661132812, 'loss_4': 1.331608533859253, 'epoch': 23.72}
{'loss': 0.0059, 'grad_norm': 4.500064373016357, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.004826435819268227, 'loss_2': 0.0010623931884765625, 'loss_3': -16.317554473876953, 'loss_4': 1.8367531299591064, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 11:06:57,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:57,759 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:24<18:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:07:05,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008865383453667164, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.607, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005782594438642263, 'eval_loss_2': 0.0030827894806861877, 'eval_loss_3': -18.181087493896484, 'eval_loss_4': 1.360903024673462, 'epoch': 23.72}
{'loss': 0.0092, 'grad_norm': 4.949318885803223, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.00570293515920639, 'loss_2': 0.0035247802734375, 'loss_3': -16.28801155090332, 'loss_4': 1.786983847618103, 'epoch': 23.73}
{'loss': 0.0107, 'grad_norm': 4.5227508544921875, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.006659918464720249, 'loss_2': 0.00405120849609375, 'loss_3': -16.24092674255371, 'loss_4': 1.460930347442627, 'epoch': 23.73}
{'loss': 0.0093, 'grad_norm': 5.269098281860352, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.006337353494018316, 'loss_2': 0.002933502197265625, 'loss_3': -16.30929946899414, 'loss_4': 1.4949723482131958, 'epoch': 23.74}
{'loss': 0.0107, 'grad_norm': 5.126410484313965, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.007654100656509399, 'loss_2': 0.003017425537109375, 'loss_3': -16.3116397857666, 'loss_4': 1.677058458328247, 'epoch': 23.74}
{'loss': 0.0129, 'grad_norm': 7.401254653930664, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.012282067909836769, 'loss_2': 0.0005779266357421875, 'loss_3': -16.259151458740234, 'loss_4': 1.6376628875732422, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 11:07:05,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:05,081 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:32<18:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:12,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009043961763381958, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.238, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.005470707081258297, 'eval_loss_2': 0.0035732537508010864, 'eval_loss_3': -18.2001953125, 'eval_loss_4': 1.3556878566741943, 'epoch': 23.75}
{'loss': 0.0094, 'grad_norm': 4.986093521118164, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.006970650982111692, 'loss_2': 0.0024242401123046875, 'loss_3': -16.492687225341797, 'loss_4': 1.5983917713165283, 'epoch': 23.76}
{'loss': 0.0067, 'grad_norm': 4.712256908416748, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.0043710521422326565, 'loss_2': 0.0023212432861328125, 'loss_3': -16.198333740234375, 'loss_4': 1.5458571910858154, 'epoch': 23.76}
{'loss': 0.0133, 'grad_norm': 10.8135347366333, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.011489353142678738, 'loss_2': 0.0018100738525390625, 'loss_3': -16.367233276367188, 'loss_4': 1.2093517780303955, 'epoch': 23.77}
{'loss': 0.004, 'grad_norm': 5.220339298248291, 'learning_rate': 6.25e-06, 'loss_1': 0.0025895379949361086, 'loss_2': 0.0013885498046875, 'loss_3': -16.412044525146484, 'loss_4': 1.594600796699524, 'epoch': 23.77}
{'loss': 0.0036, 'grad_norm': 4.473818302154541, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.003150500124320388, 'loss_2': 0.0004930496215820312, 'loss_3': -16.383148193359375, 'loss_4': 1.2074558734893799, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 11:07:12,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:12,407 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:39<18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:19,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009845559485256672, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.542, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005569641478359699, 'eval_loss_2': 0.004275918006896973, 'eval_loss_3': -18.21299934387207, 'eval_loss_4': 1.3298420906066895, 'epoch': 23.78}
{'loss': 0.0155, 'grad_norm': 5.884796619415283, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.011584742926061153, 'loss_2': 0.003940582275390625, 'loss_3': -16.407817840576172, 'loss_4': 1.89617919921875, 'epoch': 23.78}
{'loss': 0.004, 'grad_norm': 4.665650367736816, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.003516128286719322, 'loss_2': 0.0005321502685546875, 'loss_3': -16.260271072387695, 'loss_4': 1.1821067333221436, 'epoch': 23.79}
{'loss': 0.0103, 'grad_norm': 4.839613437652588, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.005918083246797323, 'loss_2': 0.00440216064453125, 'loss_3': -16.280292510986328, 'loss_4': 1.5836610794067383, 'epoch': 23.8}
{'loss': 0.0185, 'grad_norm': 6.983095645904541, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.009086641483008862, 'loss_2': 0.0093994140625, 'loss_3': -16.24497413635254, 'loss_4': 1.6659669876098633, 'epoch': 23.8}
{'loss': 0.0094, 'grad_norm': 4.466060638427734, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.006120618432760239, 'loss_2': 0.003265380859375, 'loss_3': -16.250469207763672, 'loss_4': 1.5610101222991943, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 11:07:19,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:19,731 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:40:46<18:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:27,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009653367102146149, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.542, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005604244768619537, 'eval_loss_2': 0.004049122333526611, 'eval_loss_3': -18.22461700439453, 'eval_loss_4': 1.2978274822235107, 'epoch': 23.81}
{'loss': 0.0167, 'grad_norm': 9.066819190979004, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.01467766985297203, 'loss_2': 0.00206756591796875, 'loss_3': -16.674964904785156, 'loss_4': 1.8471777439117432, 'epoch': 23.81}
{'loss': 0.0115, 'grad_norm': 4.696042060852051, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.011083878576755524, 'loss_2': 0.00039958953857421875, 'loss_3': -16.332794189453125, 'loss_4': 1.10576331615448, 'epoch': 23.82}
{'loss': 0.0107, 'grad_norm': 4.301532745361328, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.004168062470853329, 'loss_2': 0.006561279296875, 'loss_3': -16.399093627929688, 'loss_4': 1.6737581491470337, 'epoch': 23.83}
{'loss': 0.0155, 'grad_norm': 4.750341892242432, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.0035950273741036654, 'loss_2': 0.011871337890625, 'loss_3': -16.29526710510254, 'loss_4': 1.4362713098526, 'epoch': 23.83}
{'loss': 0.0071, 'grad_norm': 5.951822757720947, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.0070265610702335835, 'loss_2': 7.343292236328125e-05, 'loss_3': -16.294816970825195, 'loss_4': 1.917128562927246, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 11:07:27,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:27,059 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:40:54<18:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:34,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009165866300463676, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.494, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005667670629918575, 'eval_loss_2': 0.0034981966018676758, 'eval_loss_3': -18.228273391723633, 'eval_loss_4': 1.3051186800003052, 'epoch': 23.84}
{'loss': 0.0058, 'grad_norm': 5.065374851226807, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.00398658961057663, 'loss_2': 0.001861572265625, 'loss_3': -16.36091423034668, 'loss_4': 1.5884777307510376, 'epoch': 23.84}
{'loss': 0.0056, 'grad_norm': 4.640294551849365, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.003971310332417488, 'loss_2': 0.00162506103515625, 'loss_3': -16.433563232421875, 'loss_4': 1.4932324886322021, 'epoch': 23.85}
{'loss': 0.0077, 'grad_norm': 5.46465539932251, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.003931889776140451, 'loss_2': 0.00376129150390625, 'loss_3': -16.175575256347656, 'loss_4': 2.165844202041626, 'epoch': 23.85}
{'loss': 0.0051, 'grad_norm': 4.489756107330322, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.0029889133293181658, 'loss_2': 0.00208282470703125, 'loss_3': -16.300010681152344, 'loss_4': 1.026100754737854, 'epoch': 23.86}
{'loss': 0.0023, 'grad_norm': 4.787036418914795, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.002170178107917309, 'loss_2': 0.00011658668518066406, 'loss_3': -16.45758056640625, 'loss_4': 1.289048671722412, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 11:07:34,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:34,384 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:01<18:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:41,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009054345078766346, 'eval_runtime': 3.7818, 'eval_samples_per_second': 270.772, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.0059150164015591145, 'eval_loss_2': 0.003139328211545944, 'eval_loss_3': -18.227266311645508, 'eval_loss_4': 1.3018832206726074, 'epoch': 23.87}
{'loss': 0.0063, 'grad_norm': 4.3086066246032715, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.0038713773246854544, 'loss_2': 0.00244140625, 'loss_3': -16.43722915649414, 'loss_4': 0.8439717292785645, 'epoch': 23.87}
{'loss': 0.0083, 'grad_norm': 6.009538650512695, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.007913635112345219, 'loss_2': 0.00034618377685546875, 'loss_3': -16.288047790527344, 'loss_4': 1.5057592391967773, 'epoch': 23.88}
{'loss': 0.0051, 'grad_norm': 4.4312543869018555, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.0050404006615281105, 'loss_2': 5.4955482482910156e-05, 'loss_3': -16.433412551879883, 'loss_4': 0.7929141521453857, 'epoch': 23.88}
{'loss': 0.0124, 'grad_norm': 5.329254627227783, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.006932842545211315, 'loss_2': 0.0054931640625, 'loss_3': -16.343473434448242, 'loss_4': 1.49947988986969, 'epoch': 23.89}
{'loss': 0.0075, 'grad_norm': 5.238245964050293, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.0058484626933932304, 'loss_2': 0.0016021728515625, 'loss_3': -16.359182357788086, 'loss_4': 1.1150498390197754, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 11:07:41,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:41,706 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:08<18:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:49,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009623262099921703, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.286, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005985664669424295, 'eval_loss_2': 0.0036375969648361206, 'eval_loss_3': -18.240934371948242, 'eval_loss_4': 1.3204741477966309, 'epoch': 23.9}
{'loss': 0.0122, 'grad_norm': 4.3528642654418945, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.005270138382911682, 'loss_2': 0.00688934326171875, 'loss_3': -16.467397689819336, 'loss_4': 1.3766212463378906, 'epoch': 23.9}
{'loss': 0.0078, 'grad_norm': 5.256876468658447, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.00760555500164628, 'loss_2': 0.00017571449279785156, 'loss_3': -16.240510940551758, 'loss_4': 1.2854747772216797, 'epoch': 23.91}
{'loss': 0.0082, 'grad_norm': 4.47509241104126, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.003280032891780138, 'loss_2': 0.00487518310546875, 'loss_3': -16.13742446899414, 'loss_4': 1.3963515758514404, 'epoch': 23.91}
{'loss': 0.0115, 'grad_norm': 5.011872291564941, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.0076021854765713215, 'loss_2': 0.0039215087890625, 'loss_3': -16.468015670776367, 'loss_4': 1.6474075317382812, 'epoch': 23.92}
{'loss': 0.0355, 'grad_norm': 11.064971923828125, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.029294893145561218, 'loss_2': 0.0062255859375, 'loss_3': -16.37638282775879, 'loss_4': 1.0660855770111084, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 11:07:49,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:49,036 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:16<17:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:56,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00851273164153099, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.582, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005768578499555588, 'eval_loss_2': 0.002744153141975403, 'eval_loss_3': -18.249326705932617, 'eval_loss_4': 1.3691978454589844, 'epoch': 23.92}
{'loss': 0.0064, 'grad_norm': 4.941565036773682, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.003221533726900816, 'loss_2': 0.003204345703125, 'loss_3': -16.302743911743164, 'loss_4': 1.0439770221710205, 'epoch': 23.93}
{'loss': 0.0173, 'grad_norm': 8.303391456604004, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.011143319308757782, 'loss_2': 0.00617218017578125, 'loss_3': -16.522174835205078, 'loss_4': 1.2349536418914795, 'epoch': 23.94}
{'loss': 0.0134, 'grad_norm': 6.89369010925293, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.012650547549128532, 'loss_2': 0.0007162094116210938, 'loss_3': -16.18393325805664, 'loss_4': 1.8617547750473022, 'epoch': 23.94}
{'loss': 0.0047, 'grad_norm': 4.644830226898193, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.003512635128572583, 'loss_2': 0.00115966796875, 'loss_3': -16.276336669921875, 'loss_4': 1.8415110111236572, 'epoch': 23.95}
{'loss': 0.0089, 'grad_norm': 5.359492301940918, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.004310040734708309, 'loss_2': 0.00460052490234375, 'loss_3': -16.26161766052246, 'loss_4': 1.391860842704773, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 11:07:56,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:56,362 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:23<17:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:03,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0090596042573452, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.401, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00588735518977046, 'eval_loss_2': 0.003172248601913452, 'eval_loss_3': -18.222700119018555, 'eval_loss_4': 1.3735542297363281, 'epoch': 23.95}
{'loss': 0.0152, 'grad_norm': 5.346159934997559, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.007991199381649494, 'loss_2': 0.007175445556640625, 'loss_3': -16.230876922607422, 'loss_4': 1.9196949005126953, 'epoch': 23.96}
{'loss': 0.0106, 'grad_norm': 4.944887638092041, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.008327704854309559, 'loss_2': 0.002262115478515625, 'loss_3': -16.19272232055664, 'loss_4': 2.0924124717712402, 'epoch': 23.97}
{'loss': 0.0084, 'grad_norm': 4.901644706726074, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.005740083754062653, 'loss_2': 0.0026760101318359375, 'loss_3': -16.26199722290039, 'loss_4': 1.9627995491027832, 'epoch': 23.97}
{'loss': 0.0303, 'grad_norm': 16.60174560546875, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.02712407149374485, 'loss_2': 0.003162384033203125, 'loss_3': -16.43593406677246, 'loss_4': 1.5878562927246094, 'epoch': 23.98}
{'loss': 0.0033, 'grad_norm': 4.374115467071533, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.0027875227387994528, 'loss_2': 0.00047779083251953125, 'loss_3': -16.257444381713867, 'loss_4': 1.2298911809921265, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 11:08:03,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:03,690 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:30<17:01,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 11:08:10,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008883138187229633, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.477, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005997349973767996, 'eval_loss_2': 0.002885788679122925, 'eval_loss_3': -18.211082458496094, 'eval_loss_4': 1.3014142513275146, 'epoch': 23.98}
{'loss': 0.0054, 'grad_norm': 4.568222999572754, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.004847449716180563, 'loss_2': 0.00051116943359375, 'loss_3': -16.289884567260742, 'loss_4': 1.8014943599700928, 'epoch': 23.99}
{'loss': 0.0082, 'grad_norm': 4.599133014678955, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.005466022994369268, 'loss_2': 0.0027217864990234375, 'loss_3': -16.42462730407715, 'loss_4': 1.9614243507385254, 'epoch': 23.99}
{'loss': 0.0023, 'grad_norm': 6.199514865875244, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.0014718208694830537, 'loss_2': 0.0007810592651367188, 'loss_3': -16.155906677246094, 'loss_4': 1.5498507022857666, 'epoch': 24.0}
{'loss': 0.0045, 'grad_norm': 4.725793361663818, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.0033927825279533863, 'loss_2': 0.001125335693359375, 'loss_3': -16.20675277709961, 'loss_4': 1.455003261566162, 'epoch': 24.01}
{'loss': 0.0094, 'grad_norm': 4.772115230560303, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.004207507707178593, 'loss_2': 0.005229949951171875, 'loss_3': -16.32171058654785, 'loss_4': 1.7744741439819336, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 11:08:10,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:10,697 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:37<17:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:08:18,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009067917242646217, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.203, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0060554323717951775, 'eval_loss_2': 0.0030124858021736145, 'eval_loss_3': -18.210145950317383, 'eval_loss_4': 1.2453267574310303, 'epoch': 24.01}
{'loss': 0.0123, 'grad_norm': 5.153095722198486, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.007132586557418108, 'loss_2': 0.005123138427734375, 'loss_3': -16.468055725097656, 'loss_4': 1.3945684432983398, 'epoch': 24.02}
{'loss': 0.0179, 'grad_norm': 11.281453132629395, 'learning_rate': 6e-06, 'loss_1': 0.01453522127121687, 'loss_2': 0.003345489501953125, 'loss_3': -16.27602767944336, 'loss_4': 1.6184989213943481, 'epoch': 24.02}
{'loss': 0.0109, 'grad_norm': 5.119882583618164, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.007637674920260906, 'loss_2': 0.00324249267578125, 'loss_3': -16.29474639892578, 'loss_4': 1.0973374843597412, 'epoch': 24.03}
{'loss': 0.0318, 'grad_norm': 17.069320678710938, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.028393413871526718, 'loss_2': 0.00335693359375, 'loss_3': -16.384151458740234, 'loss_4': 1.1958681344985962, 'epoch': 24.03}
{'loss': 0.0105, 'grad_norm': 5.555464267730713, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.009690600447356701, 'loss_2': 0.0008502006530761719, 'loss_3': -16.339797973632812, 'loss_4': 0.8747945427894592, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 11:08:18,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:18,031 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:41:45<17:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:08:25,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008734125643968582, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0058869896456599236, 'eval_loss_2': 0.002847135066986084, 'eval_loss_3': -18.20844078063965, 'eval_loss_4': 1.170721411705017, 'epoch': 24.04}
{'loss': 0.0074, 'grad_norm': 5.5584025382995605, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.005104648880660534, 'loss_2': 0.002277374267578125, 'loss_3': -16.369720458984375, 'loss_4': 0.8445333242416382, 'epoch': 24.05}
{'loss': 0.0219, 'grad_norm': 9.818788528442383, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.01777529902756214, 'loss_2': 0.004150390625, 'loss_3': -16.34847640991211, 'loss_4': 1.4425160884857178, 'epoch': 24.05}
{'loss': 0.0054, 'grad_norm': 4.903014659881592, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.004921154119074345, 'loss_2': 0.0004820823669433594, 'loss_3': -16.342018127441406, 'loss_4': 1.4330589771270752, 'epoch': 24.06}
{'loss': 0.0113, 'grad_norm': 5.4610114097595215, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.010382776148617268, 'loss_2': 0.0008974075317382812, 'loss_3': -16.20767593383789, 'loss_4': 1.1434602737426758, 'epoch': 24.06}
{'loss': 0.0117, 'grad_norm': 5.5275068283081055, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.00829611998051405, 'loss_2': 0.003360748291015625, 'loss_3': -16.168140411376953, 'loss_4': 1.6900187730789185, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 11:08:25,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:25,357 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:41:52<17:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:32,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008585577830672264, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005582556128501892, 'eval_loss_2': 0.0030030235648155212, 'eval_loss_3': -18.208574295043945, 'eval_loss_4': 1.096099615097046, 'epoch': 24.07}
{'loss': 0.014, 'grad_norm': 7.078342914581299, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.00926604587584734, 'loss_2': 0.004695892333984375, 'loss_3': -16.2018985748291, 'loss_4': 1.805514931678772, 'epoch': 24.08}
{'loss': 0.0075, 'grad_norm': 4.818731307983398, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.005451099947094917, 'loss_2': 0.0020160675048828125, 'loss_3': -16.274761199951172, 'loss_4': 0.9106304049491882, 'epoch': 24.08}
{'loss': 0.0123, 'grad_norm': 4.507190704345703, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.0048017860390245914, 'loss_2': 0.00749969482421875, 'loss_3': -16.40157127380371, 'loss_4': 1.0299797058105469, 'epoch': 24.09}
{'loss': 0.0057, 'grad_norm': 6.31557559967041, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.005492207128554583, 'loss_2': 0.00023829936981201172, 'loss_3': -16.414382934570312, 'loss_4': 1.1453734636306763, 'epoch': 24.09}
{'loss': 0.0081, 'grad_norm': 5.427639007568359, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.004628713708370924, 'loss_2': 0.003459930419921875, 'loss_3': -16.365867614746094, 'loss_4': 0.7327933311462402, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 11:08:32,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:32,693 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:41:59<17:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:40,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00878113228827715, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.397, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005538964178413153, 'eval_loss_2': 0.003242168575525284, 'eval_loss_3': -18.21139144897461, 'eval_loss_4': 0.9922299385070801, 'epoch': 24.1}
{'loss': 0.0119, 'grad_norm': 5.8663129806518555, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.00957694835960865, 'loss_2': 0.002353668212890625, 'loss_3': -16.293649673461914, 'loss_4': 1.0662996768951416, 'epoch': 24.1}
{'loss': 0.0246, 'grad_norm': 8.106940269470215, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.01753898710012436, 'loss_2': 0.00707244873046875, 'loss_3': -16.486186981201172, 'loss_4': 1.4949653148651123, 'epoch': 24.11}
{'loss': 0.012, 'grad_norm': 5.068723201751709, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.005004133563488722, 'loss_2': 0.007022857666015625, 'loss_3': -16.21868133544922, 'loss_4': 1.1187548637390137, 'epoch': 24.12}
{'loss': 0.0089, 'grad_norm': 5.860531806945801, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.007656837347894907, 'loss_2': 0.0011997222900390625, 'loss_3': -16.409133911132812, 'loss_4': 1.3574714660644531, 'epoch': 24.12}
{'loss': 0.013, 'grad_norm': 6.283880710601807, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.008092180825769901, 'loss_2': 0.004913330078125, 'loss_3': -16.505735397338867, 'loss_4': 0.883944034576416, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 11:08:40,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:40,017 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:07<17:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:47,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009140681475400925, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005663413088768721, 'eval_loss_2': 0.0034772679209709167, 'eval_loss_3': -18.202871322631836, 'eval_loss_4': 0.9309532046318054, 'epoch': 24.13}
{'loss': 0.0143, 'grad_norm': 4.951591968536377, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.003489196300506592, 'loss_2': 0.010772705078125, 'loss_3': -16.41275978088379, 'loss_4': 1.2317806482315063, 'epoch': 24.13}
{'loss': 0.0079, 'grad_norm': 4.743673324584961, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.0044387164525687695, 'loss_2': 0.0034942626953125, 'loss_3': -16.213603973388672, 'loss_4': 0.7451735734939575, 'epoch': 24.14}
{'loss': 0.0157, 'grad_norm': 6.77305269241333, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.011488959193229675, 'loss_2': 0.00418853759765625, 'loss_3': -16.400691986083984, 'loss_4': 0.6477377414703369, 'epoch': 24.15}
{'loss': 0.008, 'grad_norm': 4.61013650894165, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.0036149972584098577, 'loss_2': 0.00435638427734375, 'loss_3': -16.234683990478516, 'loss_4': 1.3857004642486572, 'epoch': 24.15}
{'loss': 0.0067, 'grad_norm': 4.656927585601807, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.004961379803717136, 'loss_2': 0.0017118453979492188, 'loss_3': -16.321855545043945, 'loss_4': 1.2159456014633179, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 11:08:47,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:47,349 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:14<17:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:54,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008996006101369858, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.262, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00556847034022212, 'eval_loss_2': 0.00342753529548645, 'eval_loss_3': -18.214962005615234, 'eval_loss_4': 0.8624303340911865, 'epoch': 24.16}
{'loss': 0.01, 'grad_norm': 7.441779613494873, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.007367270067334175, 'loss_2': 0.0026760101318359375, 'loss_3': -16.221416473388672, 'loss_4': 1.079138159751892, 'epoch': 24.16}
{'loss': 0.017, 'grad_norm': 5.6962409019470215, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.007762098219245672, 'loss_2': 0.0092010498046875, 'loss_3': -16.353763580322266, 'loss_4': 1.7618701457977295, 'epoch': 24.17}
{'loss': 0.0153, 'grad_norm': 5.7933573722839355, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.011556345038115978, 'loss_2': 0.0037384033203125, 'loss_3': -16.300737380981445, 'loss_4': 0.8548876643180847, 'epoch': 24.17}
{'loss': 0.0085, 'grad_norm': 4.843530178070068, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.0038760125171393156, 'loss_2': 0.00461578369140625, 'loss_3': -16.26111602783203, 'loss_4': 0.7238596677780151, 'epoch': 24.18}
{'loss': 0.0106, 'grad_norm': 5.143283843994141, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.008039372973144054, 'loss_2': 0.00260162353515625, 'loss_3': -16.262306213378906, 'loss_4': 1.0173187255859375, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 11:08:54,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:54,682 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:21<17:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:02,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009505601599812508, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.655, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005826862528920174, 'eval_loss_2': 0.003678739070892334, 'eval_loss_3': -18.227874755859375, 'eval_loss_4': 0.7920325994491577, 'epoch': 24.19}
{'loss': 0.0061, 'grad_norm': 4.324230670928955, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.002014035824686289, 'loss_2': 0.0040740966796875, 'loss_3': -16.52007484436035, 'loss_4': 0.9944546818733215, 'epoch': 24.19}
{'loss': 0.0121, 'grad_norm': 7.21915864944458, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.012014474719762802, 'loss_2': 9.739398956298828e-05, 'loss_3': -16.33866310119629, 'loss_4': 1.1562516689300537, 'epoch': 24.2}
{'loss': 0.0121, 'grad_norm': 7.515108108520508, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.00859289150685072, 'loss_2': 0.003490447998046875, 'loss_3': -16.359962463378906, 'loss_4': 0.609269380569458, 'epoch': 24.2}
{'loss': 0.0092, 'grad_norm': 5.3464179039001465, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.006860528606921434, 'loss_2': 0.0023784637451171875, 'loss_3': -16.205360412597656, 'loss_4': 1.1017400026321411, 'epoch': 24.21}
{'loss': 0.0064, 'grad_norm': 4.559000015258789, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.004757437855005264, 'loss_2': 0.001667022705078125, 'loss_3': -16.353504180908203, 'loss_4': 0.925643801689148, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 11:09:02,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:02,003 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:29<17:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:09,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009459132328629494, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005806550849229097, 'eval_loss_2': 0.0036525800824165344, 'eval_loss_3': -18.228816986083984, 'eval_loss_4': 0.7649638056755066, 'epoch': 24.22}
{'loss': 0.0047, 'grad_norm': 4.483039379119873, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.003771488554775715, 'loss_2': 0.0008821487426757812, 'loss_3': -16.3321590423584, 'loss_4': 0.964800238609314, 'epoch': 24.22}
{'loss': 0.0089, 'grad_norm': 5.3541579246521, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.006194393150508404, 'loss_2': 0.002712249755859375, 'loss_3': -16.455366134643555, 'loss_4': 0.8011008501052856, 'epoch': 24.23}
{'loss': 0.0055, 'grad_norm': 4.1072564125061035, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.002770165214315057, 'loss_2': 0.002758026123046875, 'loss_3': -16.485393524169922, 'loss_4': 1.0774126052856445, 'epoch': 24.23}
{'loss': 0.0114, 'grad_norm': 4.614407539367676, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.006040432024747133, 'loss_2': 0.005313873291015625, 'loss_3': -16.284622192382812, 'loss_4': 0.8563871383666992, 'epoch': 24.24}
{'loss': 0.0411, 'grad_norm': 20.0546932220459, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.03999702259898186, 'loss_2': 0.0010814666748046875, 'loss_3': -16.423255920410156, 'loss_4': 0.7125582695007324, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 11:09:09,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:09,349 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:36<17:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:16,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009754689410328865, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.044, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0058423602022230625, 'eval_loss_2': 0.00391232967376709, 'eval_loss_3': -18.219768524169922, 'eval_loss_4': 0.8209477066993713, 'epoch': 24.24}
{'loss': 0.0101, 'grad_norm': 5.342462539672852, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.005777672864496708, 'loss_2': 0.00437164306640625, 'loss_3': -16.32038116455078, 'loss_4': 0.9195299744606018, 'epoch': 24.25}
{'loss': 0.0104, 'grad_norm': 4.588318347930908, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.0023287099320441484, 'loss_2': 0.0081024169921875, 'loss_3': -16.408607482910156, 'loss_4': 0.86341392993927, 'epoch': 24.26}
{'loss': 0.0055, 'grad_norm': 4.903628826141357, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.004624094348400831, 'loss_2': 0.00083160400390625, 'loss_3': -16.444637298583984, 'loss_4': 0.7100417017936707, 'epoch': 24.26}
{'loss': 0.013, 'grad_norm': 7.164097309112549, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.01021571271121502, 'loss_2': 0.0028076171875, 'loss_3': -16.380123138427734, 'loss_4': 1.7769131660461426, 'epoch': 24.27}
{'loss': 0.004, 'grad_norm': 4.3764777183532715, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.0028634497430175543, 'loss_2': 0.0011348724365234375, 'loss_3': -16.29941177368164, 'loss_4': 0.7408849596977234, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 11:09:16,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:16,679 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:42:43<16:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:09:23,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009249728173017502, 'eval_runtime': 3.7825, 'eval_samples_per_second': 270.718, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005922973621636629, 'eval_loss_2': 0.00332675501704216, 'eval_loss_3': -18.204017639160156, 'eval_loss_4': 0.8547340631484985, 'epoch': 24.27}
{'loss': 0.0071, 'grad_norm': 4.371057510375977, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.003949364181607962, 'loss_2': 0.0031890869140625, 'loss_3': -16.37723731994629, 'loss_4': 0.67784184217453, 'epoch': 24.28}
{'loss': 0.0068, 'grad_norm': 4.579350471496582, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.0048509943298995495, 'loss_2': 0.001983642578125, 'loss_3': -16.2049617767334, 'loss_4': 0.7949820160865784, 'epoch': 24.28}
{'loss': 0.008, 'grad_norm': 5.000071048736572, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.003882942022755742, 'loss_2': 0.004123687744140625, 'loss_3': -16.288909912109375, 'loss_4': 1.4297364950180054, 'epoch': 24.29}
{'loss': 0.0135, 'grad_norm': 4.447056293487549, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.007675327826291323, 'loss_2': 0.0057830810546875, 'loss_3': -16.30545425415039, 'loss_4': 1.2284244298934937, 'epoch': 24.3}
{'loss': 0.0115, 'grad_norm': 4.774722099304199, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.009497862309217453, 'loss_2': 0.0020351409912109375, 'loss_3': -16.19866180419922, 'loss_4': 1.240631341934204, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 11:09:23,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:23,999 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:42:51<17:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:09:31,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009442085400223732, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.463, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006761581636965275, 'eval_loss_2': 0.0026805028319358826, 'eval_loss_3': -18.206470489501953, 'eval_loss_4': 0.9573236107826233, 'epoch': 24.3}
{'loss': 0.0051, 'grad_norm': 5.050657272338867, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.004500528797507286, 'loss_2': 0.0006265640258789062, 'loss_3': -16.376953125, 'loss_4': 1.7376763820648193, 'epoch': 24.31}
{'loss': 0.0037, 'grad_norm': 4.803131580352783, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.0034993872977793217, 'loss_2': 0.00021028518676757812, 'loss_3': -16.574254989624023, 'loss_4': 1.0329010486602783, 'epoch': 24.31}
{'loss': 0.0089, 'grad_norm': 4.840853691101074, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.005517986137419939, 'loss_2': 0.0034275054931640625, 'loss_3': -16.2508602142334, 'loss_4': 0.8074820637702942, 'epoch': 24.32}
{'loss': 0.0117, 'grad_norm': 4.459958553314209, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.004625652451068163, 'loss_2': 0.00711822509765625, 'loss_3': -16.225736618041992, 'loss_4': 0.8771392107009888, 'epoch': 24.33}
{'loss': 0.0162, 'grad_norm': 5.323334217071533, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.007220580708235502, 'loss_2': 0.00897979736328125, 'loss_3': -16.30674171447754, 'loss_4': 1.223292350769043, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 11:09:31,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:31,509 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:42:58<16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:38,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010093053802847862, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006572595331817865, 'eval_loss_2': 0.003520458936691284, 'eval_loss_3': -18.213773727416992, 'eval_loss_4': 1.0388871431350708, 'epoch': 24.33}
{'loss': 0.0167, 'grad_norm': 7.381831169128418, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.008892449550330639, 'loss_2': 0.0077667236328125, 'loss_3': -16.502344131469727, 'loss_4': 1.6546151638031006, 'epoch': 24.34}
{'loss': 0.0135, 'grad_norm': 5.59327507019043, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.00776251032948494, 'loss_2': 0.00574493408203125, 'loss_3': -16.31878662109375, 'loss_4': 1.2786285877227783, 'epoch': 24.34}
{'loss': 0.0112, 'grad_norm': 6.422696113586426, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.00931838620454073, 'loss_2': 0.00183868408203125, 'loss_3': -16.37050437927246, 'loss_4': 0.8956639766693115, 'epoch': 24.35}
{'loss': 0.0124, 'grad_norm': 4.122607231140137, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.0030946743208914995, 'loss_2': 0.009307861328125, 'loss_3': -16.183265686035156, 'loss_4': 1.1324622631072998, 'epoch': 24.35}
{'loss': 0.0271, 'grad_norm': 9.154585838317871, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.018501777201890945, 'loss_2': 0.00858306884765625, 'loss_3': -16.451828002929688, 'loss_4': 1.2377159595489502, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 11:09:38,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:38,841 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:05<16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:46,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010828137397766113, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.27, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006812602281570435, 'eval_loss_2': 0.004015535116195679, 'eval_loss_3': -18.214012145996094, 'eval_loss_4': 1.0260608196258545, 'epoch': 24.36}
{'loss': 0.0075, 'grad_norm': 4.528252601623535, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.004667158238589764, 'loss_2': 0.00279998779296875, 'loss_3': -16.208555221557617, 'loss_4': 1.2694108486175537, 'epoch': 24.37}
{'loss': 0.0051, 'grad_norm': 4.915936470031738, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.0038646801840513945, 'loss_2': 0.0012760162353515625, 'loss_3': -16.27832794189453, 'loss_4': 1.3811532258987427, 'epoch': 24.37}
{'loss': 0.0131, 'grad_norm': 5.584712028503418, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.009951458312571049, 'loss_2': 0.0031719207763671875, 'loss_3': -16.38491439819336, 'loss_4': 1.248724102973938, 'epoch': 24.38}
{'loss': 0.0271, 'grad_norm': 12.202730178833008, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.01829002983868122, 'loss_2': 0.00878143310546875, 'loss_3': -16.398883819580078, 'loss_4': 1.6159403324127197, 'epoch': 24.38}
{'loss': 0.0113, 'grad_norm': 7.074961185455322, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.00816911831498146, 'loss_2': 0.003170013427734375, 'loss_3': -16.22314453125, 'loss_4': 1.1392509937286377, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 11:09:46,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:46,171 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:13<16:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:53,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01054893434047699, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006928741931915283, 'eval_loss_2': 0.0036201924085617065, 'eval_loss_3': -18.21933937072754, 'eval_loss_4': 0.9554941654205322, 'epoch': 24.39}
{'loss': 0.006, 'grad_norm': 4.232545852661133, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0038725414779037237, 'loss_2': 0.00213623046875, 'loss_3': -16.355396270751953, 'loss_4': 1.28562593460083, 'epoch': 24.4}
{'loss': 0.0152, 'grad_norm': 5.447281360626221, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.0049825916066765785, 'loss_2': 0.01019287109375, 'loss_3': -16.402400970458984, 'loss_4': 1.4336249828338623, 'epoch': 24.4}
{'loss': 0.0075, 'grad_norm': 4.675741672515869, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.0036069131456315517, 'loss_2': 0.003879547119140625, 'loss_3': -16.464828491210938, 'loss_4': 0.7383102178573608, 'epoch': 24.41}
{'loss': 0.0054, 'grad_norm': 4.426990509033203, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.003253149800002575, 'loss_2': 0.00217437744140625, 'loss_3': -16.49497413635254, 'loss_4': 1.0026881694793701, 'epoch': 24.41}
{'loss': 0.0107, 'grad_norm': 5.337997913360596, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.009571154601871967, 'loss_2': 0.001094818115234375, 'loss_3': -16.291561126708984, 'loss_4': 1.1217554807662964, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 11:09:53,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:53,524 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:20<16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:00,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010122419334948063, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.103, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007038981653749943, 'eval_loss_2': 0.00308343768119812, 'eval_loss_3': -18.216825485229492, 'eval_loss_4': 0.8995774984359741, 'epoch': 24.42}
{'loss': 0.0127, 'grad_norm': 6.320028781890869, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.011099513620138168, 'loss_2': 0.0016326904296875, 'loss_3': -16.33911895751953, 'loss_4': 1.6567424535751343, 'epoch': 24.42}
{'loss': 0.0106, 'grad_norm': 7.456283092498779, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.0090269660577178, 'loss_2': 0.0015316009521484375, 'loss_3': -16.512332916259766, 'loss_4': 0.9620182514190674, 'epoch': 24.43}
{'loss': 0.0159, 'grad_norm': 4.817708492279053, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.008364049717783928, 'loss_2': 0.00753021240234375, 'loss_3': -16.031715393066406, 'loss_4': 0.5149457454681396, 'epoch': 24.44}
{'loss': 0.0051, 'grad_norm': 4.884958267211914, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.0043278890661895275, 'loss_2': 0.000762939453125, 'loss_3': -16.32927131652832, 'loss_4': 1.0297430753707886, 'epoch': 24.44}
{'loss': 0.0086, 'grad_norm': 4.612893581390381, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.007705822121351957, 'loss_2': 0.0008745193481445312, 'loss_3': -16.399911880493164, 'loss_4': 0.7125958800315857, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 11:10:00,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:00,852 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:27<16:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:08,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01090068370103836, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.292, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00751628540456295, 'eval_loss_2': 0.0033843964338302612, 'eval_loss_3': -18.211545944213867, 'eval_loss_4': 0.941696286201477, 'epoch': 24.45}
{'loss': 0.0232, 'grad_norm': 7.434412002563477, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.015543745830655098, 'loss_2': 0.00768280029296875, 'loss_3': -16.41851806640625, 'loss_4': 1.2899854183197021, 'epoch': 24.45}
{'loss': 0.0096, 'grad_norm': 5.245577812194824, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.006707460153847933, 'loss_2': 0.002910614013671875, 'loss_3': -16.270782470703125, 'loss_4': 0.9415715336799622, 'epoch': 24.46}
{'loss': 0.0118, 'grad_norm': 5.913843154907227, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.011753952130675316, 'loss_2': 6.860494613647461e-05, 'loss_3': -16.343067169189453, 'loss_4': 0.6871845722198486, 'epoch': 24.47}
{'loss': 0.0133, 'grad_norm': 5.244147777557373, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.009714880026876926, 'loss_2': 0.0035953521728515625, 'loss_3': -16.526639938354492, 'loss_4': 1.0236849784851074, 'epoch': 24.47}
{'loss': 0.0097, 'grad_norm': 5.398955345153809, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.007926776073873043, 'loss_2': 0.00177764892578125, 'loss_3': -16.250732421875, 'loss_4': 1.114182710647583, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 11:10:08,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:08,191 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:35<16:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:15,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01130053959786892, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007857611402869225, 'eval_loss_2': 0.003442928194999695, 'eval_loss_3': -18.200334548950195, 'eval_loss_4': 1.0373327732086182, 'epoch': 24.48}
{'loss': 0.0187, 'grad_norm': 5.733402252197266, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.013833876699209213, 'loss_2': 0.004878997802734375, 'loss_3': -16.57163429260254, 'loss_4': 1.4269740581512451, 'epoch': 24.48}
{'loss': 0.012, 'grad_norm': 4.937187671661377, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.0051105935126543045, 'loss_2': 0.0069122314453125, 'loss_3': -16.38630485534668, 'loss_4': 0.9291567802429199, 'epoch': 24.49}
{'loss': 0.0129, 'grad_norm': 4.277378082275391, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.004462039098143578, 'loss_2': 0.0084228515625, 'loss_3': -16.34684944152832, 'loss_4': 1.4105916023254395, 'epoch': 24.49}
{'loss': 0.0101, 'grad_norm': 5.82269811630249, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.009376388974487782, 'loss_2': 0.000713348388671875, 'loss_3': -16.083354949951172, 'loss_4': 1.186084508895874, 'epoch': 24.5}
{'loss': 0.0084, 'grad_norm': 4.738185405731201, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.0039376369677484035, 'loss_2': 0.004486083984375, 'loss_3': -16.354869842529297, 'loss_4': 1.038970708847046, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 11:10:15,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:15,537 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:43:42<16:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:22,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00970881525427103, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.324, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.00738211814314127, 'eval_loss_2': 0.0023266971111297607, 'eval_loss_3': -18.184141159057617, 'eval_loss_4': 1.1192630529403687, 'epoch': 24.51}
{'loss': 0.0097, 'grad_norm': 4.349064826965332, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.004936267621815205, 'loss_2': 0.004795074462890625, 'loss_3': -16.336578369140625, 'loss_4': 0.8520543575286865, 'epoch': 24.51}
{'loss': 0.0136, 'grad_norm': 5.696792125701904, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.012840300798416138, 'loss_2': 0.0007200241088867188, 'loss_3': -16.33222007751465, 'loss_4': 0.7484183311462402, 'epoch': 24.52}
{'loss': 0.0137, 'grad_norm': 5.565883159637451, 'learning_rate': 5.5e-06, 'loss_1': 0.010693222284317017, 'loss_2': 0.0029888153076171875, 'loss_3': -16.414928436279297, 'loss_4': 1.3218417167663574, 'epoch': 24.52}
{'loss': 0.0086, 'grad_norm': 7.01434850692749, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.0075697884894907475, 'loss_2': 0.001071929931640625, 'loss_3': -16.247272491455078, 'loss_4': 1.053975224494934, 'epoch': 24.53}
{'loss': 0.0106, 'grad_norm': 8.166755676269531, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.008912361226975918, 'loss_2': 0.0016994476318359375, 'loss_3': -16.333984375, 'loss_4': 1.3323934078216553, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 11:10:22,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:22,869 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:43:50<16:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:30,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009867300279438496, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007787150330841541, 'eval_loss_2': 0.0020801499485969543, 'eval_loss_3': -18.175861358642578, 'eval_loss_4': 1.1875853538513184, 'epoch': 24.53}
{'loss': 0.0103, 'grad_norm': 4.793074131011963, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.005631624720990658, 'loss_2': 0.0046844482421875, 'loss_3': -16.298316955566406, 'loss_4': 1.194498062133789, 'epoch': 24.54}
{'loss': 0.0118, 'grad_norm': 6.526900291442871, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.011095897294580936, 'loss_2': 0.000743865966796875, 'loss_3': -16.454452514648438, 'loss_4': 1.1771011352539062, 'epoch': 24.55}
{'loss': 0.0097, 'grad_norm': 4.652820110321045, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.009718065150082111, 'loss_2': 1.6450881958007812e-05, 'loss_3': -16.296361923217773, 'loss_4': 1.537068486213684, 'epoch': 24.55}
{'loss': 0.0074, 'grad_norm': 5.037586688995361, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.005539091303944588, 'loss_2': 0.0019092559814453125, 'loss_3': -16.35996437072754, 'loss_4': 0.7458599209785461, 'epoch': 24.56}
{'loss': 0.0071, 'grad_norm': 4.521677017211914, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.005759045016020536, 'loss_2': 0.00136566162109375, 'loss_3': -16.306148529052734, 'loss_4': 0.9700062274932861, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 11:10:30,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:30,206 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:43:57<16:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:37,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010973080061376095, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.857, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008452622219920158, 'eval_loss_2': 0.002520456910133362, 'eval_loss_3': -18.17273712158203, 'eval_loss_4': 1.2794378995895386, 'epoch': 24.56}
{'loss': 0.0103, 'grad_norm': 5.50364875793457, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.008458757773041725, 'loss_2': 0.001800537109375, 'loss_3': -16.17221450805664, 'loss_4': 1.27767014503479, 'epoch': 24.57}
{'loss': 0.0121, 'grad_norm': 6.644288539886475, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.009645586833357811, 'loss_2': 0.0024356842041015625, 'loss_3': -16.264976501464844, 'loss_4': 1.2015564441680908, 'epoch': 24.58}
{'loss': 0.0148, 'grad_norm': 5.546637535095215, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.00830899178981781, 'loss_2': 0.00653076171875, 'loss_3': -16.410919189453125, 'loss_4': 1.2165601253509521, 'epoch': 24.58}
{'loss': 0.0062, 'grad_norm': 4.925609111785889, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.004744234029203653, 'loss_2': 0.001483917236328125, 'loss_3': -16.230850219726562, 'loss_4': 1.272536039352417, 'epoch': 24.59}
{'loss': 0.0105, 'grad_norm': 4.599721431732178, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.003937988076359034, 'loss_2': 0.006549835205078125, 'loss_3': -16.223308563232422, 'loss_4': 1.2668204307556152, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 11:10:37,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:37,537 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:04<15:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:44,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011897756718099117, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.384, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0092953871935606, 'eval_loss_2': 0.0026023685932159424, 'eval_loss_3': -18.15161895751953, 'eval_loss_4': 1.3524059057235718, 'epoch': 24.59}
{'loss': 0.0078, 'grad_norm': 4.378073692321777, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.0061504412442445755, 'loss_2': 0.001605987548828125, 'loss_3': -16.36844825744629, 'loss_4': 1.5960140228271484, 'epoch': 24.6}
{'loss': 0.0093, 'grad_norm': 4.635910511016846, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.005269103217869997, 'loss_2': 0.004055023193359375, 'loss_3': -16.10441017150879, 'loss_4': 1.3963310718536377, 'epoch': 24.6}
{'loss': 0.0128, 'grad_norm': 8.29054069519043, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.009484256617724895, 'loss_2': 0.003284454345703125, 'loss_3': -16.402748107910156, 'loss_4': 1.1299595832824707, 'epoch': 24.61}
{'loss': 0.0065, 'grad_norm': 4.865898609161377, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.005950226914137602, 'loss_2': 0.0005750656127929688, 'loss_3': -16.161169052124023, 'loss_4': 1.6249597072601318, 'epoch': 24.62}
{'loss': 0.0067, 'grad_norm': 4.643901348114014, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.004559320863336325, 'loss_2': 0.002109527587890625, 'loss_3': -16.400501251220703, 'loss_4': 1.4199734926223755, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 11:10:44,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:44,866 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:11<15:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:52,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01271754503250122, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.621, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.009804160334169865, 'eval_loss_2': 0.0029133856296539307, 'eval_loss_3': -18.147314071655273, 'eval_loss_4': 1.3873200416564941, 'epoch': 24.62}
{'loss': 0.0278, 'grad_norm': 14.23369312286377, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.0265873484313488, 'loss_2': 0.0012054443359375, 'loss_3': -16.02167320251465, 'loss_4': 1.4711215496063232, 'epoch': 24.63}
{'loss': 0.0063, 'grad_norm': 4.63852071762085, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.005674910731613636, 'loss_2': 0.000621795654296875, 'loss_3': -16.47037124633789, 'loss_4': 1.2482354640960693, 'epoch': 24.63}
{'loss': 0.0101, 'grad_norm': 4.663359642028809, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.006178691983222961, 'loss_2': 0.0038738250732421875, 'loss_3': -16.332517623901367, 'loss_4': 1.8125967979431152, 'epoch': 24.64}
{'loss': 0.0355, 'grad_norm': 13.259895324707031, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.03484013304114342, 'loss_2': 0.00070953369140625, 'loss_3': -16.357166290283203, 'loss_4': 1.523046851158142, 'epoch': 24.65}
{'loss': 0.0119, 'grad_norm': 5.8313751220703125, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.01042119786143303, 'loss_2': 0.0014705657958984375, 'loss_3': -16.304351806640625, 'loss_4': 1.7181978225708008, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 11:10:52,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:52,192 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:19<15:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:59,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013870051130652428, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.509, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.010654730722308159, 'eval_loss_2': 0.003215320408344269, 'eval_loss_3': -18.14553451538086, 'eval_loss_4': 1.3744685649871826, 'epoch': 24.65}
{'loss': 0.0109, 'grad_norm': 5.060064315795898, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.008937626145780087, 'loss_2': 0.00200653076171875, 'loss_3': -16.312618255615234, 'loss_4': 1.2535948753356934, 'epoch': 24.66}
{'loss': 0.0122, 'grad_norm': 5.386896133422852, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.009815957397222519, 'loss_2': 0.002349853515625, 'loss_3': -16.238433837890625, 'loss_4': 1.250648021697998, 'epoch': 24.66}
{'loss': 0.0103, 'grad_norm': 6.135994911193848, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.00875405129045248, 'loss_2': 0.0015316009521484375, 'loss_3': -16.111217498779297, 'loss_4': 1.590094804763794, 'epoch': 24.67}
{'loss': 0.0057, 'grad_norm': 5.011229515075684, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.00561119569465518, 'loss_2': 4.8995018005371094e-05, 'loss_3': -16.410263061523438, 'loss_4': 1.0956352949142456, 'epoch': 24.67}
{'loss': 0.0105, 'grad_norm': 4.290530681610107, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.0041230348870158195, 'loss_2': 0.0063934326171875, 'loss_3': -16.392349243164062, 'loss_4': 0.9739362001419067, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 11:10:59,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:59,516 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:26<15:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:11:06,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01434151828289032, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.694, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.011115580797195435, 'eval_loss_2': 0.0032259374856948853, 'eval_loss_3': -18.137861251831055, 'eval_loss_4': 1.360520839691162, 'epoch': 24.68}
{'loss': 0.0165, 'grad_norm': 7.691736221313477, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.015145624056458473, 'loss_2': 0.0013971328735351562, 'loss_3': -16.367692947387695, 'loss_4': 1.3761839866638184, 'epoch': 24.69}
{'loss': 0.0131, 'grad_norm': 5.994312286376953, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.009518845938146114, 'loss_2': 0.0036106109619140625, 'loss_3': -16.303712844848633, 'loss_4': 1.0967838764190674, 'epoch': 24.69}
{'loss': 0.0105, 'grad_norm': 5.459488868713379, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.007681746035814285, 'loss_2': 0.002788543701171875, 'loss_3': -16.23908233642578, 'loss_4': 1.4422048330307007, 'epoch': 24.7}
{'loss': 0.0169, 'grad_norm': 7.387448310852051, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.014693613164126873, 'loss_2': 0.002193450927734375, 'loss_3': -15.931680679321289, 'loss_4': 1.0578501224517822, 'epoch': 24.7}
{'loss': 0.0145, 'grad_norm': 5.824741840362549, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.007773807272315025, 'loss_2': 0.006725311279296875, 'loss_3': -16.27980613708496, 'loss_4': 1.3802900314331055, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 11:11:06,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:06,836 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:34<15:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:14,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01510334201157093, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011668864637613297, 'eval_loss_2': 0.003434479236602783, 'eval_loss_3': -18.123125076293945, 'eval_loss_4': 1.3481346368789673, 'epoch': 24.71}
{'loss': 0.011, 'grad_norm': 5.333970069885254, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.009320469573140144, 'loss_2': 0.0016613006591796875, 'loss_3': -16.108211517333984, 'loss_4': 1.0279183387756348, 'epoch': 24.72}
{'loss': 0.0113, 'grad_norm': 5.077005386352539, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.008414791896939278, 'loss_2': 0.0028839111328125, 'loss_3': -16.280555725097656, 'loss_4': 1.4178143739700317, 'epoch': 24.72}
{'loss': 0.0154, 'grad_norm': 4.9234089851379395, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.008153348229825497, 'loss_2': 0.0072479248046875, 'loss_3': -16.165685653686523, 'loss_4': 1.1661162376403809, 'epoch': 24.73}
{'loss': 0.0093, 'grad_norm': 5.208373546600342, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.005539897363632917, 'loss_2': 0.0037975311279296875, 'loss_3': -16.416000366210938, 'loss_4': 1.5856249332427979, 'epoch': 24.73}
{'loss': 0.0163, 'grad_norm': 8.637051582336426, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.01505153439939022, 'loss_2': 0.0012569427490234375, 'loss_3': -16.329805374145508, 'loss_4': 1.4965392351150513, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 11:11:14,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:14,195 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:41<15:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:21,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015233003534376621, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.629, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.011874370276927948, 'eval_loss_2': 0.0033586323261260986, 'eval_loss_3': -18.12348747253418, 'eval_loss_4': 1.3214998245239258, 'epoch': 24.74}
{'loss': 0.0124, 'grad_norm': 9.133377075195312, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.008830664679408073, 'loss_2': 0.003528594970703125, 'loss_3': -16.47219467163086, 'loss_4': 1.3090602159500122, 'epoch': 24.74}
{'loss': 0.0059, 'grad_norm': 5.722151756286621, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.005546262953430414, 'loss_2': 0.000354766845703125, 'loss_3': -16.17563247680664, 'loss_4': 0.950678825378418, 'epoch': 24.75}
{'loss': 0.008, 'grad_norm': 4.636167526245117, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.0044719148427248, 'loss_2': 0.0035686492919921875, 'loss_3': -16.278406143188477, 'loss_4': 1.3678414821624756, 'epoch': 24.76}
{'loss': 0.0067, 'grad_norm': 4.8170647621154785, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.0038794521242380142, 'loss_2': 0.0028438568115234375, 'loss_3': -16.337669372558594, 'loss_4': 1.3506609201431274, 'epoch': 24.76}
{'loss': 0.0203, 'grad_norm': 7.642898082733154, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.010968225076794624, 'loss_2': 0.009368896484375, 'loss_3': -16.184280395507812, 'loss_4': 1.342460036277771, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 11:11:21,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:21,519 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:44:48<15:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:28,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011449724435806274, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.277, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.008077830076217651, 'eval_loss_2': 0.003371894359588623, 'eval_loss_3': -18.15313720703125, 'eval_loss_4': 1.2217843532562256, 'epoch': 24.77}
{'loss': 0.0216, 'grad_norm': 10.550518989562988, 'learning_rate': 5.25e-06, 'loss_1': 0.017413806170225143, 'loss_2': 0.0041656494140625, 'loss_3': -16.132919311523438, 'loss_4': 1.572338581085205, 'epoch': 24.77}
{'loss': 0.0146, 'grad_norm': 4.9739508628845215, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.012089041993021965, 'loss_2': 0.002483367919921875, 'loss_3': -16.166704177856445, 'loss_4': 1.1498932838439941, 'epoch': 24.78}
{'loss': 0.0083, 'grad_norm': 4.418682098388672, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.004335159435868263, 'loss_2': 0.0039825439453125, 'loss_3': -16.45867919921875, 'loss_4': 1.3689138889312744, 'epoch': 24.78}
{'loss': 0.0084, 'grad_norm': 4.915332794189453, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.004694069270044565, 'loss_2': 0.003749847412109375, 'loss_3': -16.236984252929688, 'loss_4': 1.3706238269805908, 'epoch': 24.79}
{'loss': 0.0128, 'grad_norm': 4.859620094299316, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.007492187432944775, 'loss_2': 0.005336761474609375, 'loss_3': -16.38909339904785, 'loss_4': 1.3678760528564453, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 11:11:28,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:28,847 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:44:55<15:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:36,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009788516908884048, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.236, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006640378851443529, 'eval_loss_2': 0.0031481385231018066, 'eval_loss_3': -18.157333374023438, 'eval_loss_4': 1.1581233739852905, 'epoch': 24.8}
{'loss': 0.0113, 'grad_norm': 5.789744853973389, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.006158602889627218, 'loss_2': 0.00511932373046875, 'loss_3': -16.444482803344727, 'loss_4': 1.4132089614868164, 'epoch': 24.8}
{'loss': 0.0072, 'grad_norm': 5.0691375732421875, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.004521674942225218, 'loss_2': 0.002727508544921875, 'loss_3': -16.440227508544922, 'loss_4': 1.0260415077209473, 'epoch': 24.81}
{'loss': 0.0075, 'grad_norm': 4.407196998596191, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.005521257407963276, 'loss_2': 0.00200653076171875, 'loss_3': -16.46566390991211, 'loss_4': 1.1897642612457275, 'epoch': 24.81}
{'loss': 0.0142, 'grad_norm': 5.759364128112793, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.00919958297163248, 'loss_2': 0.005001068115234375, 'loss_3': -16.32659339904785, 'loss_4': 1.1281378269195557, 'epoch': 24.82}
{'loss': 0.0141, 'grad_norm': 5.774353981018066, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.008420076221227646, 'loss_2': 0.00569915771484375, 'loss_3': -16.310237884521484, 'loss_4': 1.3005077838897705, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 11:11:36,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:36,181 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:03<15:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:43,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009438743814826012, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.238, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006278222892433405, 'eval_loss_2': 0.003160521388053894, 'eval_loss_3': -18.168357849121094, 'eval_loss_4': 1.1604925394058228, 'epoch': 24.83}
{'loss': 0.0053, 'grad_norm': 4.659812927246094, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0021422363352030516, 'loss_2': 0.003177642822265625, 'loss_3': -16.380666732788086, 'loss_4': 1.3843226432800293, 'epoch': 24.83}
{'loss': 0.0215, 'grad_norm': 14.111186027526855, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.018991386517882347, 'loss_2': 0.002552032470703125, 'loss_3': -16.278871536254883, 'loss_4': 1.6127052307128906, 'epoch': 24.84}
{'loss': 0.0112, 'grad_norm': 4.853076934814453, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.011107605881989002, 'loss_2': 8.159875869750977e-05, 'loss_3': -16.304550170898438, 'loss_4': 1.121016263961792, 'epoch': 24.84}
{'loss': 0.006, 'grad_norm': 4.295128345489502, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.0038921907544136047, 'loss_2': 0.002094268798828125, 'loss_3': -16.399843215942383, 'loss_4': 1.5836963653564453, 'epoch': 24.85}
{'loss': 0.0194, 'grad_norm': 9.108650207519531, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.01856648549437523, 'loss_2': 0.0008716583251953125, 'loss_3': -16.219335556030273, 'loss_4': 1.6866267919540405, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 11:11:43,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:43,518 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:10<15:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:50,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008942925371229649, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006053556222468615, 'eval_loss_2': 0.0028893686830997467, 'eval_loss_3': -18.18006134033203, 'eval_loss_4': 1.1867185831069946, 'epoch': 24.85}
{'loss': 0.0105, 'grad_norm': 4.293201446533203, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.004786901641637087, 'loss_2': 0.005718231201171875, 'loss_3': -16.47689437866211, 'loss_4': 1.2039079666137695, 'epoch': 24.86}
{'loss': 0.0053, 'grad_norm': 4.5531487464904785, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.004479297436773777, 'loss_2': 0.0008368492126464844, 'loss_3': -16.016990661621094, 'loss_4': 1.0263656377792358, 'epoch': 24.87}
{'loss': 0.0088, 'grad_norm': 4.701000690460205, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.005410309880971909, 'loss_2': 0.003345489501953125, 'loss_3': -16.252830505371094, 'loss_4': 1.4012072086334229, 'epoch': 24.87}
{'loss': 0.0096, 'grad_norm': 5.106734752655029, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.0033791863825172186, 'loss_2': 0.0062103271484375, 'loss_3': -16.214523315429688, 'loss_4': 0.9721749424934387, 'epoch': 24.88}
{'loss': 0.0178, 'grad_norm': 7.059101104736328, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.009473792277276516, 'loss_2': 0.0082855224609375, 'loss_3': -16.274747848510742, 'loss_4': 1.5282247066497803, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 11:11:50,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:50,860 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:17<15:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:58,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008845782838761806, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.372, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0057458421215415, 'eval_loss_2': 0.0030999407172203064, 'eval_loss_3': -18.197311401367188, 'eval_loss_4': 1.2140849828720093, 'epoch': 24.88}
{'loss': 0.0142, 'grad_norm': 4.547373294830322, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.004420098848640919, 'loss_2': 0.00974273681640625, 'loss_3': -16.471670150756836, 'loss_4': 1.7538565397262573, 'epoch': 24.89}
{'loss': 0.0075, 'grad_norm': 5.170650005340576, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.006830956321209669, 'loss_2': 0.000629425048828125, 'loss_3': -16.250524520874023, 'loss_4': 1.4690117835998535, 'epoch': 24.9}
{'loss': 0.0183, 'grad_norm': 5.605395793914795, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.011087704449892044, 'loss_2': 0.00719451904296875, 'loss_3': -16.38695526123047, 'loss_4': 1.6759607791900635, 'epoch': 24.9}
{'loss': 0.0043, 'grad_norm': 4.387274742126465, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.0026694554835557938, 'loss_2': 0.0016498565673828125, 'loss_3': -16.57543182373047, 'loss_4': 1.5609874725341797, 'epoch': 24.91}
{'loss': 0.0097, 'grad_norm': 5.190480709075928, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.00792661402374506, 'loss_2': 0.0018110275268554688, 'loss_3': -16.434310913085938, 'loss_4': 1.698526382446289, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 11:11:58,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:58,188 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:25<15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:05,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009179770946502686, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.454, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005667984485626221, 'eval_loss_2': 0.003511786460876465, 'eval_loss_3': -18.195491790771484, 'eval_loss_4': 1.237026333808899, 'epoch': 24.91}
{'loss': 0.0088, 'grad_norm': 5.607387542724609, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.007223373744636774, 'loss_2': 0.00153350830078125, 'loss_3': -16.48722267150879, 'loss_4': 1.2036466598510742, 'epoch': 24.92}
{'loss': 0.0095, 'grad_norm': 5.681585788726807, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.005906493403017521, 'loss_2': 0.0036029815673828125, 'loss_3': -16.344444274902344, 'loss_4': 1.0660359859466553, 'epoch': 24.92}
{'loss': 0.0145, 'grad_norm': 5.903750419616699, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.011143618263304234, 'loss_2': 0.0033740997314453125, 'loss_3': -16.305702209472656, 'loss_4': 1.2340749502182007, 'epoch': 24.93}
{'loss': 0.0085, 'grad_norm': 4.966759204864502, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.007435897830873728, 'loss_2': 0.001049041748046875, 'loss_3': -16.427471160888672, 'loss_4': 1.1737351417541504, 'epoch': 24.94}
{'loss': 0.0093, 'grad_norm': 5.896396636962891, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.007725008297711611, 'loss_2': 0.001621246337890625, 'loss_3': -16.36252784729004, 'loss_4': 1.4739080667495728, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 11:12:05,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:05,513 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:32<14:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:12,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009785565547645092, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.317, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.005879554431885481, 'eval_loss_2': 0.0039060115814208984, 'eval_loss_3': -18.20663833618164, 'eval_loss_4': 1.2402772903442383, 'epoch': 24.94}
{'loss': 0.0073, 'grad_norm': 4.348811626434326, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.004519835114479065, 'loss_2': 0.002742767333984375, 'loss_3': -16.40640640258789, 'loss_4': 1.5959138870239258, 'epoch': 24.95}
{'loss': 0.0166, 'grad_norm': 7.02426290512085, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.012128527276217937, 'loss_2': 0.004497528076171875, 'loss_3': -16.09803009033203, 'loss_4': 1.2903108596801758, 'epoch': 24.95}
{'loss': 0.0081, 'grad_norm': 4.531803607940674, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.004280424676835537, 'loss_2': 0.0038623809814453125, 'loss_3': -16.14620590209961, 'loss_4': 1.2845690250396729, 'epoch': 24.96}
{'loss': 0.0108, 'grad_norm': 5.524757385253906, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.0059806592762470245, 'loss_2': 0.0048065185546875, 'loss_3': -16.20001220703125, 'loss_4': 1.3987600803375244, 'epoch': 24.97}
{'loss': 0.0062, 'grad_norm': 4.521758556365967, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.005966816563159227, 'loss_2': 0.0002651214599609375, 'loss_3': -16.07940673828125, 'loss_4': 1.2307188510894775, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 11:12:12,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:12,838 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:39<13:20,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:12:19,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0092126140370965, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006016315892338753, 'eval_loss_2': 0.0031962990760803223, 'eval_loss_3': -18.2106876373291, 'eval_loss_4': 1.214651346206665, 'epoch': 24.97}
{'loss': 0.015, 'grad_norm': 5.196778297424316, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.01167847029864788, 'loss_2': 0.003284454345703125, 'loss_3': -16.594331741333008, 'loss_4': 1.1383781433105469, 'epoch': 24.98}
{'loss': 0.0072, 'grad_norm': 5.126550674438477, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.007077672053128481, 'loss_2': 0.00014472007751464844, 'loss_3': -16.256267547607422, 'loss_4': 1.2539143562316895, 'epoch': 24.98}
{'loss': 0.013, 'grad_norm': 4.949856281280518, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.004336242564022541, 'loss_2': 0.0086822509765625, 'loss_3': -16.356243133544922, 'loss_4': 1.566361665725708, 'epoch': 24.99}
{'loss': 0.0068, 'grad_norm': 4.93165397644043, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.004479747731238604, 'loss_2': 0.0023040771484375, 'loss_3': -16.50316619873047, 'loss_4': 1.402941107749939, 'epoch': 24.99}
{'loss': 0.0045, 'grad_norm': 5.701735019683838, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0011468888260424137, 'loss_2': 0.0033550262451171875, 'loss_3': -16.39360809326172, 'loss_4': 1.3845083713531494, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 11:12:19,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:19,811 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:45:46<14:33,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:12:27,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009045269340276718, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006084516644477844, 'eval_loss_2': 0.002960752695798874, 'eval_loss_3': -18.215368270874023, 'eval_loss_4': 1.183229923248291, 'epoch': 25.0}
{'loss': 0.0053, 'grad_norm': 5.104804992675781, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.0049125743098556995, 'loss_2': 0.0004334449768066406, 'loss_3': -16.323944091796875, 'loss_4': 1.2711576223373413, 'epoch': 25.01}
{'loss': 0.0072, 'grad_norm': 4.922636032104492, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.003742084838449955, 'loss_2': 0.00341033935546875, 'loss_3': -16.270320892333984, 'loss_4': 1.3502883911132812, 'epoch': 25.01}
{'loss': 0.004, 'grad_norm': 4.696898460388184, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.003231628565117717, 'loss_2': 0.0007772445678710938, 'loss_3': -16.330875396728516, 'loss_4': 1.6875884532928467, 'epoch': 25.02}
{'loss': 0.0059, 'grad_norm': 4.878777503967285, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.0037762699648737907, 'loss_2': 0.00212860107421875, 'loss_3': -16.585603713989258, 'loss_4': 1.4619439840316772, 'epoch': 25.02}
{'loss': 0.0067, 'grad_norm': 4.742976188659668, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.0048132725059986115, 'loss_2': 0.0018463134765625, 'loss_3': -16.261009216308594, 'loss_4': 1.1836254596710205, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 11:12:27,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:27,191 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:45:54<14:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:12:34,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008900190703570843, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.947, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.0060769934207201, 'eval_loss_2': 0.0028231963515281677, 'eval_loss_3': -18.203269958496094, 'eval_loss_4': 1.1360737085342407, 'epoch': 25.03}
{'loss': 0.0143, 'grad_norm': 6.250024318695068, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.010797114111483097, 'loss_2': 0.0034847259521484375, 'loss_3': -16.283180236816406, 'loss_4': 1.182086706161499, 'epoch': 25.03}
{'loss': 0.011, 'grad_norm': 4.807272911071777, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.00575454905629158, 'loss_2': 0.0052337646484375, 'loss_3': -16.536954879760742, 'loss_4': 1.3598928451538086, 'epoch': 25.04}
{'loss': 0.0119, 'grad_norm': 4.806224822998047, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.006036547012627125, 'loss_2': 0.005859375, 'loss_3': -16.353397369384766, 'loss_4': 1.0068520307540894, 'epoch': 25.05}
{'loss': 0.0085, 'grad_norm': 5.200852870941162, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.007140332367271185, 'loss_2': 0.0013484954833984375, 'loss_3': -16.268577575683594, 'loss_4': 1.3175607919692993, 'epoch': 25.05}
{'loss': 0.0068, 'grad_norm': 4.315214157104492, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.0033378987573087215, 'loss_2': 0.0034351348876953125, 'loss_3': -16.386978149414062, 'loss_4': 0.9712848663330078, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 11:12:34,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:34,524 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:01<14:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:41,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009021478705108166, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.166, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005875114351511002, 'eval_loss_2': 0.0031463652849197388, 'eval_loss_3': -18.199302673339844, 'eval_loss_4': 1.0597503185272217, 'epoch': 25.06}
{'loss': 0.0135, 'grad_norm': 5.789459705352783, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.008774209767580032, 'loss_2': 0.00469970703125, 'loss_3': -16.433456420898438, 'loss_4': 1.0293865203857422, 'epoch': 25.06}
{'loss': 0.0067, 'grad_norm': 4.729795932769775, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.004082335624843836, 'loss_2': 0.00266265869140625, 'loss_3': -16.3409366607666, 'loss_4': 1.3671058416366577, 'epoch': 25.07}
{'loss': 0.0135, 'grad_norm': 9.158522605895996, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.009183067828416824, 'loss_2': 0.00432586669921875, 'loss_3': -16.35918617248535, 'loss_4': 1.4436249732971191, 'epoch': 25.08}
{'loss': 0.0052, 'grad_norm': 4.4475321769714355, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.0017517689848318696, 'loss_2': 0.003475189208984375, 'loss_3': -16.55455207824707, 'loss_4': 0.9902767539024353, 'epoch': 25.08}
{'loss': 0.0098, 'grad_norm': 4.707861423492432, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.006670346483588219, 'loss_2': 0.003147125244140625, 'loss_3': -16.49635887145996, 'loss_4': 1.2792975902557373, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 11:12:41,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:41,859 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:08<14:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:49,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00895424373447895, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.431, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006073005497455597, 'eval_loss_2': 0.0028812363743782043, 'eval_loss_3': -18.193504333496094, 'eval_loss_4': 0.9850452542304993, 'epoch': 25.09}
{'loss': 0.0093, 'grad_norm': 4.928290367126465, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.007756873033940792, 'loss_2': 0.001522064208984375, 'loss_3': -16.398120880126953, 'loss_4': 1.455019474029541, 'epoch': 25.09}
{'loss': 0.0054, 'grad_norm': 4.373326778411865, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.0038178761024028063, 'loss_2': 0.001613616943359375, 'loss_3': -16.28089714050293, 'loss_4': 1.4096181392669678, 'epoch': 25.1}
{'loss': 0.0194, 'grad_norm': 5.805228233337402, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.008280027657747269, 'loss_2': 0.01111602783203125, 'loss_3': -16.520633697509766, 'loss_4': 0.9725932478904724, 'epoch': 25.1}
{'loss': 0.0086, 'grad_norm': 5.312689781188965, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.005258367396891117, 'loss_2': 0.003337860107421875, 'loss_3': -16.43170166015625, 'loss_4': 1.1423001289367676, 'epoch': 25.11}
{'loss': 0.009, 'grad_norm': 4.964982986450195, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.003988543525338173, 'loss_2': 0.004962921142578125, 'loss_3': -16.294071197509766, 'loss_4': 1.133442997932434, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 11:12:49,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:49,190 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:16<14:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:56,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009086651727557182, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.693, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.0065870266407728195, 'eval_loss_2': 0.002499625086784363, 'eval_loss_3': -18.18606948852539, 'eval_loss_4': 0.9328893423080444, 'epoch': 25.12}
{'loss': 0.0097, 'grad_norm': 4.844647407531738, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.004877384752035141, 'loss_2': 0.004791259765625, 'loss_3': -16.42833709716797, 'loss_4': 0.7621262073516846, 'epoch': 25.12}
{'loss': 0.0063, 'grad_norm': 4.468047618865967, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.0019294878002256155, 'loss_2': 0.004329681396484375, 'loss_3': -16.43613052368164, 'loss_4': 0.8525608777999878, 'epoch': 25.13}
{'loss': 0.0102, 'grad_norm': 5.846072673797607, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.009142905473709106, 'loss_2': 0.0010461807250976562, 'loss_3': -16.354183197021484, 'loss_4': 1.2249996662139893, 'epoch': 25.13}
{'loss': 0.0266, 'grad_norm': 17.59899139404297, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.02467353641986847, 'loss_2': 0.0019159317016601562, 'loss_3': -16.275604248046875, 'loss_4': 1.1037578582763672, 'epoch': 25.14}
{'loss': 0.0055, 'grad_norm': 5.539689540863037, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.005179279483854771, 'loss_2': 0.00029087066650390625, 'loss_3': -16.428176879882812, 'loss_4': 1.0914721488952637, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 11:12:56,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:56,521 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:23<14:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:03,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009145034477114677, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.314, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.006393315736204386, 'eval_loss_2': 0.002751719206571579, 'eval_loss_3': -18.178382873535156, 'eval_loss_4': 0.8893623948097229, 'epoch': 25.15}
{'loss': 0.0106, 'grad_norm': 5.272042274475098, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.0050682732835412025, 'loss_2': 0.00554656982421875, 'loss_3': -16.41558074951172, 'loss_4': 0.8326688408851624, 'epoch': 25.15}
{'loss': 0.0077, 'grad_norm': 4.715004920959473, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.0035622133873403072, 'loss_2': 0.004177093505859375, 'loss_3': -16.349885940551758, 'loss_4': 1.2908209562301636, 'epoch': 25.16}
{'loss': 0.0107, 'grad_norm': 4.680225849151611, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.004879798740148544, 'loss_2': 0.00579833984375, 'loss_3': -16.237293243408203, 'loss_4': 0.7633484601974487, 'epoch': 25.16}
{'loss': 0.0048, 'grad_norm': 4.399794101715088, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.0022372298408299685, 'loss_2': 0.0025348663330078125, 'loss_3': -16.566007614135742, 'loss_4': 0.8805729150772095, 'epoch': 25.17}
{'loss': 0.0105, 'grad_norm': 4.486933708190918, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.004498694092035294, 'loss_2': 0.0059814453125, 'loss_3': -16.277259826660156, 'loss_4': 0.9338908791542053, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 11:13:03,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:03,856 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:30<14:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:11,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009945069439709187, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.491, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006684225983917713, 'eval_loss_2': 0.0032608434557914734, 'eval_loss_3': -18.181455612182617, 'eval_loss_4': 0.8648593425750732, 'epoch': 25.17}
{'loss': 0.0086, 'grad_norm': 4.277694225311279, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.005376576911658049, 'loss_2': 0.0031795501708984375, 'loss_3': -16.294368743896484, 'loss_4': 0.940603494644165, 'epoch': 25.18}
{'loss': 0.0123, 'grad_norm': 5.402224540710449, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.0077371736988425255, 'loss_2': 0.00457000732421875, 'loss_3': -16.354595184326172, 'loss_4': 1.467782974243164, 'epoch': 25.19}
{'loss': 0.0081, 'grad_norm': 4.884671688079834, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.0061751171015203, 'loss_2': 0.0019006729125976562, 'loss_3': -16.287723541259766, 'loss_4': 0.9605622291564941, 'epoch': 25.19}
{'loss': 0.0095, 'grad_norm': 5.327304363250732, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.009397895075380802, 'loss_2': 5.626678466796875e-05, 'loss_3': -16.264385223388672, 'loss_4': 0.7867462038993835, 'epoch': 25.2}
{'loss': 0.0129, 'grad_norm': 4.53776741027832, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.0050202361308038235, 'loss_2': 0.00791168212890625, 'loss_3': -16.512775421142578, 'loss_4': 0.9653841257095337, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 11:13:11,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:11,186 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:38<14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:18,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009419974870979786, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.756, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006509733386337757, 'eval_loss_2': 0.002910241484642029, 'eval_loss_3': -18.189407348632812, 'eval_loss_4': 0.840424656867981, 'epoch': 25.2}
{'loss': 0.0034, 'grad_norm': 4.665853500366211, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.0033186001237481833, 'loss_2': 0.00010037422180175781, 'loss_3': -16.349384307861328, 'loss_4': 1.0813661813735962, 'epoch': 25.21}
{'loss': 0.0103, 'grad_norm': 4.561282157897949, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.002750612795352936, 'loss_2': 0.007518768310546875, 'loss_3': -16.386520385742188, 'loss_4': 0.9531412124633789, 'epoch': 25.22}
{'loss': 0.0165, 'grad_norm': 7.304149627685547, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.013302907347679138, 'loss_2': 0.0032138824462890625, 'loss_3': -16.333799362182617, 'loss_4': 0.9953209757804871, 'epoch': 25.22}
{'loss': 0.0038, 'grad_norm': 4.211419105529785, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.002547543728724122, 'loss_2': 0.0012226104736328125, 'loss_3': -16.148460388183594, 'loss_4': 0.8431535363197327, 'epoch': 25.23}
{'loss': 0.0063, 'grad_norm': 5.616777420043945, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.004978051874786615, 'loss_2': 0.0012874603271484375, 'loss_3': -16.33448028564453, 'loss_4': 1.3516738414764404, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 11:13:18,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:18,539 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:46:45<14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:25,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008663345128297806, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.471, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006383512634783983, 'eval_loss_2': 0.00227983295917511, 'eval_loss_3': -18.189374923706055, 'eval_loss_4': 0.8073325753211975, 'epoch': 25.23}
{'loss': 0.0112, 'grad_norm': 6.939750671386719, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.010906273499131203, 'loss_2': 0.0002651214599609375, 'loss_3': -16.235464096069336, 'loss_4': 0.38601577281951904, 'epoch': 25.24}
{'loss': 0.0088, 'grad_norm': 4.484367847442627, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.0027059658896178007, 'loss_2': 0.006061553955078125, 'loss_3': -16.42885971069336, 'loss_4': 1.0616607666015625, 'epoch': 25.24}
{'loss': 0.0209, 'grad_norm': 16.1016788482666, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.01719759777188301, 'loss_2': 0.00371551513671875, 'loss_3': -16.397274017333984, 'loss_4': 0.5895907282829285, 'epoch': 25.25}
{'loss': 0.0089, 'grad_norm': 5.080474376678467, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.006022315006703138, 'loss_2': 0.00284576416015625, 'loss_3': -16.39632797241211, 'loss_4': 0.6688988208770752, 'epoch': 25.26}
{'loss': 0.0052, 'grad_norm': 5.062917232513428, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.004215646535158157, 'loss_2': 0.0009446144104003906, 'loss_3': -16.298160552978516, 'loss_4': 1.15971040725708, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 11:13:25,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:25,873 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:46:53<13:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:33,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008946715854108334, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.606, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006232632324099541, 'eval_loss_2': 0.0027140825986862183, 'eval_loss_3': -18.192033767700195, 'eval_loss_4': 0.7441992163658142, 'epoch': 25.26}
{'loss': 0.0125, 'grad_norm': 9.07551097869873, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.00937255285680294, 'loss_2': 0.00315093994140625, 'loss_3': -16.245731353759766, 'loss_4': 0.4719074070453644, 'epoch': 25.27}
{'loss': 0.0101, 'grad_norm': 5.2665605545043945, 'learning_rate': 4.75e-06, 'loss_1': 0.006789097096771002, 'loss_2': 0.003353118896484375, 'loss_3': -16.333908081054688, 'loss_4': 0.8334267735481262, 'epoch': 25.27}
{'loss': 0.0094, 'grad_norm': 5.037708282470703, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.005735868588089943, 'loss_2': 0.0036602020263671875, 'loss_3': -16.359909057617188, 'loss_4': 0.6229614019393921, 'epoch': 25.28}
{'loss': 0.003, 'grad_norm': 4.51050329208374, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.0022888595703989267, 'loss_2': 0.000743865966796875, 'loss_3': -16.27393341064453, 'loss_4': 0.9045413732528687, 'epoch': 25.28}
{'loss': 0.0203, 'grad_norm': 8.232349395751953, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.0179360993206501, 'loss_2': 0.0023670196533203125, 'loss_3': -16.33565902709961, 'loss_4': 1.4367923736572266, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 11:13:33,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:33,195 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:00<13:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:40,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008664491586387157, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.604, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005834655836224556, 'eval_loss_2': 0.002829834818840027, 'eval_loss_3': -18.19828224182129, 'eval_loss_4': 0.7348921895027161, 'epoch': 25.29}
{'loss': 0.0082, 'grad_norm': 5.276797294616699, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.006628117058426142, 'loss_2': 0.00159454345703125, 'loss_3': -16.402591705322266, 'loss_4': 0.5162578821182251, 'epoch': 25.3}
{'loss': 0.0105, 'grad_norm': 6.818194389343262, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.007783691398799419, 'loss_2': 0.0027141571044921875, 'loss_3': -16.317228317260742, 'loss_4': 0.7298091053962708, 'epoch': 25.3}
{'loss': 0.0077, 'grad_norm': 6.051417350769043, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.0067754266783595085, 'loss_2': 0.0009150505065917969, 'loss_3': -16.41271209716797, 'loss_4': 0.6374781131744385, 'epoch': 25.31}
{'loss': 0.0281, 'grad_norm': 14.26804256439209, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.027765842154622078, 'loss_2': 0.0003001689910888672, 'loss_3': -16.233829498291016, 'loss_4': 0.9405952095985413, 'epoch': 25.31}
{'loss': 0.0113, 'grad_norm': 5.073840618133545, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.009154131636023521, 'loss_2': 0.00213623046875, 'loss_3': -16.316219329833984, 'loss_4': 0.9701886177062988, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 11:13:40,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:40,525 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:07<13:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:13:47,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008382603526115417, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.583, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005665838252753019, 'eval_loss_2': 0.002716764807701111, 'eval_loss_3': -18.212364196777344, 'eval_loss_4': 0.7744123339653015, 'epoch': 25.32}
{'loss': 0.0081, 'grad_norm': 4.559175491333008, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.003022285643965006, 'loss_2': 0.005100250244140625, 'loss_3': -16.358966827392578, 'loss_4': 0.7038349509239197, 'epoch': 25.33}
{'loss': 0.0052, 'grad_norm': 4.859417915344238, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.004358705133199692, 'loss_2': 0.0008373260498046875, 'loss_3': -16.389976501464844, 'loss_4': 0.8153910636901855, 'epoch': 25.33}
{'loss': 0.0048, 'grad_norm': 4.647845268249512, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.00206571607850492, 'loss_2': 0.00270843505859375, 'loss_3': -16.471080780029297, 'loss_4': 1.0557410717010498, 'epoch': 25.34}
{'loss': 0.0039, 'grad_norm': 4.303896427154541, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.0021975066047161818, 'loss_2': 0.0017080307006835938, 'loss_3': -16.2544002532959, 'loss_4': 0.652125358581543, 'epoch': 25.34}
{'loss': 0.0092, 'grad_norm': 4.8713297843933105, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.0044843475334346294, 'loss_2': 0.0047607421875, 'loss_3': -16.47878646850586, 'loss_4': 1.0896786451339722, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 11:13:47,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:47,843 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:14<13:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:13:55,167 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008175388909876347, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.375, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005447299685329199, 'eval_loss_2': 0.002728089690208435, 'eval_loss_3': -18.214948654174805, 'eval_loss_4': 0.8199669718742371, 'epoch': 25.35}
{'loss': 0.0087, 'grad_norm': 4.402438640594482, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.002480362541973591, 'loss_2': 0.00624847412109375, 'loss_3': -16.132192611694336, 'loss_4': 1.1533122062683105, 'epoch': 25.35}
{'loss': 0.0095, 'grad_norm': 5.3275675773620605, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.007375197950750589, 'loss_2': 0.002166748046875, 'loss_3': -16.260154724121094, 'loss_4': 1.189548134803772, 'epoch': 25.36}
{'loss': 0.0047, 'grad_norm': 4.935211658477783, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.0038601846899837255, 'loss_2': 0.0008869171142578125, 'loss_3': -16.45380401611328, 'loss_4': 1.0482844114303589, 'epoch': 25.37}
{'loss': 0.0221, 'grad_norm': 9.503667831420898, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.020270006731152534, 'loss_2': 0.0017957687377929688, 'loss_3': -16.337671279907227, 'loss_4': 1.122351050376892, 'epoch': 25.37}
{'loss': 0.0062, 'grad_norm': 4.7005228996276855, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.0023631397634744644, 'loss_2': 0.003849029541015625, 'loss_3': -16.28907012939453, 'loss_4': 0.6658307909965515, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 11:13:55,167 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:55,167 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:22<13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:02,494 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008335767313838005, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005398449953645468, 'eval_loss_2': 0.00293731689453125, 'eval_loss_3': -18.21017837524414, 'eval_loss_4': 0.850074291229248, 'epoch': 25.38}
{'loss': 0.0141, 'grad_norm': 7.304201126098633, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.008318876847624779, 'loss_2': 0.005767822265625, 'loss_3': -16.38602638244629, 'loss_4': 0.95111083984375, 'epoch': 25.38}
{'loss': 0.0111, 'grad_norm': 5.226413249969482, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.005122508853673935, 'loss_2': 0.0059814453125, 'loss_3': -16.36029815673828, 'loss_4': 1.1717700958251953, 'epoch': 25.39}
{'loss': 0.005, 'grad_norm': 5.145304203033447, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.003248939523473382, 'loss_2': 0.0017862319946289062, 'loss_3': -16.236560821533203, 'loss_4': 0.8730694055557251, 'epoch': 25.4}
{'loss': 0.006, 'grad_norm': 4.687870025634766, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.0021655671298503876, 'loss_2': 0.0038433074951171875, 'loss_3': -16.35360336303711, 'loss_4': 1.2715691328048706, 'epoch': 25.4}
{'loss': 0.0073, 'grad_norm': 4.51832389831543, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.002647090470418334, 'loss_2': 0.004627227783203125, 'loss_3': -16.47733497619629, 'loss_4': 1.0406080484390259, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 11:14:02,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:02,495 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:29<13:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:09,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00821855291724205, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.65, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005043801385909319, 'eval_loss_2': 0.0031747519969940186, 'eval_loss_3': -18.21170425415039, 'eval_loss_4': 0.9064805507659912, 'epoch': 25.41}
{'loss': 0.0088, 'grad_norm': 4.557557582855225, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.0055044363252818584, 'loss_2': 0.003326416015625, 'loss_3': -16.18801498413086, 'loss_4': 1.3463027477264404, 'epoch': 25.41}
{'loss': 0.0041, 'grad_norm': 4.506647109985352, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.0024328979197889566, 'loss_2': 0.0016632080078125, 'loss_3': -16.40473175048828, 'loss_4': 1.3225746154785156, 'epoch': 25.42}
{'loss': 0.0051, 'grad_norm': 5.187819004058838, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.004306488670408726, 'loss_2': 0.0007443428039550781, 'loss_3': -16.464534759521484, 'loss_4': 0.9142611622810364, 'epoch': 25.42}
{'loss': 0.0086, 'grad_norm': 5.035341739654541, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.007080969400703907, 'loss_2': 0.0015010833740234375, 'loss_3': -16.094234466552734, 'loss_4': 1.2737644910812378, 'epoch': 25.43}
{'loss': 0.0457, 'grad_norm': 20.44807243347168, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.04485249146819115, 'loss_2': 0.0008120536804199219, 'loss_3': -16.404560089111328, 'loss_4': 1.0638052225112915, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 11:14:09,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:09,821 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:33<13:33,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 11:14:13,608 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375
[INFO|configuration_utils.py:420] 2025-01-21 11:14:13,609 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375/config.json                                                                             
{'eval_loss': 0.00786731019616127, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.563, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.0050880201160907745, 'eval_loss_2': 0.0027792900800704956, 'eval_loss_3': -18.196165084838867, 'eval_loss_4': 0.941798985004425, 'epoch': 25.44}
[INFO|modeling_utils.py:2988] 2025-01-21 11:14:14,111 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:14:14,112 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:14:14,112 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 11:14:15,065 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-2430] due to args.save_total_limit
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:38<14:54,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 11:14:18,698 >>
{'loss': 0.0112, 'grad_norm': 8.00459098815918, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.010152814909815788, 'loss_2': 0.00106048583984375, 'loss_3': -16.3653507232666, 'loss_4': 1.3601562976837158, 'epoch': 25.44}
{'loss': 0.014, 'grad_norm': 8.55817699432373, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.013666121289134026, 'loss_2': 0.00031948089599609375, 'loss_3': -16.33913803100586, 'loss_4': 1.1031606197357178, 'epoch': 25.45}
{'loss': 0.0074, 'grad_norm': 4.669414520263672, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.004141379147768021, 'loss_2': 0.00321197509765625, 'loss_3': -16.562976837158203, 'loss_4': 1.615791916847229, 'epoch': 25.45}
{'loss': 0.0054, 'grad_norm': 4.776026248931885, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.0036682316567748785, 'loss_2': 0.0016956329345703125, 'loss_3': -16.309833526611328, 'loss_4': 0.79901123046875, 'epoch': 25.46}
{'loss': 0.0083, 'grad_norm': 4.820849418640137, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.0024954951368272305, 'loss_2': 0.005767822265625, 'loss_3': -16.46677017211914, 'loss_4': 1.300480604171753, 'epoch': 25.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:14:18,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:18,698 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:42<14:54,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 11:14:22,491 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380
[INFO|configuration_utils.py:420] 2025-01-21 11:14:22,492 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380/config.json                                                                             
{'eval_loss': 0.007509466260671616, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.075, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.005115915555506945, 'eval_loss_2': 0.0023935511708259583, 'eval_loss_3': -18.18351936340332, 'eval_loss_4': 0.930396556854248, 'epoch': 25.47}
[INFO|modeling_utils.py:2988] 2025-01-21 11:14:22,985 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:14:22,986 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:14:22,987 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 11:14:23,937 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4375] due to args.save_total_limit
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:47:47<15:03,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 11:14:27,559 >>
{'loss': 0.0081, 'grad_norm': 4.628454685211182, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.0017763543874025345, 'loss_2': 0.006351470947265625, 'loss_3': -16.413930892944336, 'loss_4': 0.9040858745574951, 'epoch': 25.47}
{'loss': 0.0057, 'grad_norm': 4.093060493469238, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.002453799592331052, 'loss_2': 0.00325775146484375, 'loss_3': -16.476839065551758, 'loss_4': 1.1362929344177246, 'epoch': 25.48}
{'loss': 0.0123, 'grad_norm': 7.824763774871826, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.011649333871901035, 'loss_2': 0.0006551742553710938, 'loss_3': -16.39601707458496, 'loss_4': 1.1679767370224, 'epoch': 25.48}
{'loss': 0.0047, 'grad_norm': 4.589627265930176, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.0031969361007213593, 'loss_2': 0.00152587890625, 'loss_3': -16.225990295410156, 'loss_4': 1.613612413406372, 'epoch': 25.49}
{'loss': 0.0042, 'grad_norm': 4.55089807510376, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.002736883470788598, 'loss_2': 0.001453399658203125, 'loss_3': -16.275054931640625, 'loss_4': 1.5100631713867188, 'epoch': 25.49}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:14:27,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:27,559 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:47:54<13:33,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 11:14:34,881 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00826176442205906, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005886455997824669, 'eval_loss_2': 0.0023753084242343903, 'eval_loss_3': -18.176443099975586, 'eval_loss_4': 0.9185887575149536, 'epoch': 25.49}
{'loss': 0.0056, 'grad_norm': 4.8725690841674805, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.0020446397829800844, 'loss_2': 0.003597259521484375, 'loss_3': -16.25763702392578, 'loss_4': 0.8564376831054688, 'epoch': 25.5}
{'loss': 0.0113, 'grad_norm': 4.409674644470215, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.005919415969401598, 'loss_2': 0.00542449951171875, 'loss_3': -16.376880645751953, 'loss_4': 1.1391716003417969, 'epoch': 25.51}
{'loss': 0.0047, 'grad_norm': 4.348945617675781, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.004430932924151421, 'loss_2': 0.00024700164794921875, 'loss_3': -16.111286163330078, 'loss_4': 0.9519874453544617, 'epoch': 25.51}
{'loss': 0.0087, 'grad_norm': 4.734965801239014, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.006043426692485809, 'loss_2': 0.002685546875, 'loss_3': -16.3299617767334, 'loss_4': 1.1165351867675781, 'epoch': 25.52}
{'loss': 0.0193, 'grad_norm': 15.565342903137207, 'learning_rate': 4.5e-06, 'loss_1': 0.014415579847991467, 'loss_2': 0.004852294921875, 'loss_3': -16.39069175720215, 'loss_4': 0.8007025718688965, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 11:14:34,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:34,882 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:02<13:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:42,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00847951415926218, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.972, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.005795308388769627, 'eval_loss_2': 0.0026842057704925537, 'eval_loss_3': -18.184608459472656, 'eval_loss_4': 0.928376317024231, 'epoch': 25.52}
{'loss': 0.0181, 'grad_norm': 9.263107299804688, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.014491952955722809, 'loss_2': 0.00359344482421875, 'loss_3': -16.075117111206055, 'loss_4': 1.0989103317260742, 'epoch': 25.53}
{'loss': 0.014, 'grad_norm': 4.709636688232422, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.00463533541187644, 'loss_2': 0.0093994140625, 'loss_3': -16.415395736694336, 'loss_4': 0.9738709926605225, 'epoch': 25.53}
{'loss': 0.0055, 'grad_norm': 4.549097061157227, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.0018806909210979939, 'loss_2': 0.0036678314208984375, 'loss_3': -16.464149475097656, 'loss_4': 1.2305259704589844, 'epoch': 25.54}
{'loss': 0.0071, 'grad_norm': 4.395986557006836, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.0023683973122388124, 'loss_2': 0.0047607421875, 'loss_3': -16.2315616607666, 'loss_4': 1.0605287551879883, 'epoch': 25.55}
{'loss': 0.0096, 'grad_norm': 4.419003009796143, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.0032535961363464594, 'loss_2': 0.0063934326171875, 'loss_3': -16.233003616333008, 'loss_4': 1.257279634475708, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 11:14:42,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:42,220 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:09<13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:49,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008611437864601612, 'eval_runtime': 3.7819, 'eval_samples_per_second': 270.76, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.005955156870186329, 'eval_loss_2': 0.002656280994415283, 'eval_loss_3': -18.187503814697266, 'eval_loss_4': 0.9550942778587341, 'epoch': 25.55}
{'loss': 0.0154, 'grad_norm': 4.86195707321167, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.00702831894159317, 'loss_2': 0.00833892822265625, 'loss_3': -16.41229820251465, 'loss_4': 1.2096978425979614, 'epoch': 25.56}
{'loss': 0.0061, 'grad_norm': 5.5435638427734375, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.005225378088653088, 'loss_2': 0.0008592605590820312, 'loss_3': -16.209209442138672, 'loss_4': 0.6559891700744629, 'epoch': 25.56}
{'loss': 0.023, 'grad_norm': 9.256621360778809, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.021343039348721504, 'loss_2': 0.0016460418701171875, 'loss_3': -16.256479263305664, 'loss_4': 0.8803584575653076, 'epoch': 25.57}
{'loss': 0.0093, 'grad_norm': 5.049838066101074, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.0031218810472637415, 'loss_2': 0.006145477294921875, 'loss_3': -16.24730682373047, 'loss_4': 0.7850794792175293, 'epoch': 25.58}
{'loss': 0.005, 'grad_norm': 4.653127193450928, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.0026340659242123365, 'loss_2': 0.002330780029296875, 'loss_3': -16.494688034057617, 'loss_4': 1.412980079650879, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 11:14:49,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:49,542 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:16<13:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:14:56,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008996255695819855, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.239, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006379172205924988, 'eval_loss_2': 0.002617083489894867, 'eval_loss_3': -18.190336227416992, 'eval_loss_4': 1.0039961338043213, 'epoch': 25.58}
{'loss': 0.0225, 'grad_norm': 7.696430683135986, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.017629172652959824, 'loss_2': 0.004833221435546875, 'loss_3': -16.26398277282715, 'loss_4': 1.0195624828338623, 'epoch': 25.59}
{'loss': 0.0118, 'grad_norm': 8.726428985595703, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.01045527495443821, 'loss_2': 0.0013589859008789062, 'loss_3': -16.322349548339844, 'loss_4': 1.0180599689483643, 'epoch': 25.59}
{'loss': 0.0178, 'grad_norm': 7.058071613311768, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.01301808562129736, 'loss_2': 0.00473785400390625, 'loss_3': -16.398895263671875, 'loss_4': 1.216110110282898, 'epoch': 25.6}
{'loss': 0.011, 'grad_norm': 5.172698974609375, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.009468702599406242, 'loss_2': 0.0015201568603515625, 'loss_3': -16.173095703125, 'loss_4': 1.3140580654144287, 'epoch': 25.6}
{'loss': 0.0125, 'grad_norm': 6.259978771209717, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.009164282120764256, 'loss_2': 0.0033664703369140625, 'loss_3': -16.23821258544922, 'loss_4': 1.4263898134231567, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 11:14:56,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:56,865 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:24<12:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:04,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009278833866119385, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.666, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.006479292642325163, 'eval_loss_2': 0.0027995407581329346, 'eval_loss_3': -18.186676025390625, 'eval_loss_4': 1.0602233409881592, 'epoch': 25.61}
{'loss': 0.0106, 'grad_norm': 4.590732097625732, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.004825411830097437, 'loss_2': 0.00580596923828125, 'loss_3': -16.3830623626709, 'loss_4': 1.3654885292053223, 'epoch': 25.62}
{'loss': 0.0045, 'grad_norm': 4.448127269744873, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.002605777233839035, 'loss_2': 0.001903533935546875, 'loss_3': -16.403112411499023, 'loss_4': 1.1709132194519043, 'epoch': 25.62}
{'loss': 0.0146, 'grad_norm': 5.512427806854248, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.009337724186480045, 'loss_2': 0.00531005859375, 'loss_3': -16.28078842163086, 'loss_4': 1.081137776374817, 'epoch': 25.63}
{'loss': 0.008, 'grad_norm': 4.8537917137146, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.006445162929594517, 'loss_2': 0.0016021728515625, 'loss_3': -16.330923080444336, 'loss_4': 1.1702191829681396, 'epoch': 25.63}
{'loss': 0.0086, 'grad_norm': 5.971904277801514, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.006419323850423098, 'loss_2': 0.002201080322265625, 'loss_3': -16.303115844726562, 'loss_4': 0.7807144522666931, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 11:15:04,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:04,199 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:31<12:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:11,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009246132336556911, 'eval_runtime': 3.7819, 'eval_samples_per_second': 270.763, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.006514041218906641, 'eval_loss_2': 0.002732090651988983, 'eval_loss_3': -18.188814163208008, 'eval_loss_4': 1.1299841403961182, 'epoch': 25.64}
{'loss': 0.0173, 'grad_norm': 5.250128269195557, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.007316232658922672, 'loss_2': 0.00994110107421875, 'loss_3': -16.247783660888672, 'loss_4': 1.4738423824310303, 'epoch': 25.65}
{'loss': 0.0074, 'grad_norm': 5.390829086303711, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.005769677460193634, 'loss_2': 0.001651763916015625, 'loss_3': -16.257965087890625, 'loss_4': 0.9533644318580627, 'epoch': 25.65}
{'loss': 0.02, 'grad_norm': 5.5913591384887695, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.008151417598128319, 'loss_2': 0.01186370849609375, 'loss_3': -16.120067596435547, 'loss_4': 1.6531147956848145, 'epoch': 25.66}
{'loss': 0.0153, 'grad_norm': 5.750524520874023, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.01233327854424715, 'loss_2': 0.0029697418212890625, 'loss_3': -16.300312042236328, 'loss_4': 1.446573257446289, 'epoch': 25.66}
{'loss': 0.0085, 'grad_norm': 4.509194850921631, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.0033555792178958654, 'loss_2': 0.005096435546875, 'loss_3': -16.3333740234375, 'loss_4': 1.856196403503418, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 11:15:11,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:11,525 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:38<12:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:15:18,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009277982637286186, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.91, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006181625649333, 'eval_loss_2': 0.003096356987953186, 'eval_loss_3': -18.195486068725586, 'eval_loss_4': 1.1573554277420044, 'epoch': 25.67}
{'loss': 0.0043, 'grad_norm': 4.817570209503174, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.0030988138169050217, 'loss_2': 0.0011749267578125, 'loss_3': -16.584007263183594, 'loss_4': 1.342362403869629, 'epoch': 25.67}
{'loss': 0.0132, 'grad_norm': 4.621414661407471, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.004824446514248848, 'loss_2': 0.0083465576171875, 'loss_3': -16.178951263427734, 'loss_4': 1.2782418727874756, 'epoch': 25.68}
{'loss': 0.0086, 'grad_norm': 5.0948591232299805, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.0036411709152162075, 'loss_2': 0.00494384765625, 'loss_3': -16.368648529052734, 'loss_4': 1.48018217086792, 'epoch': 25.69}
{'loss': 0.0091, 'grad_norm': 5.235451698303223, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.0063703833147883415, 'loss_2': 0.00270843505859375, 'loss_3': -16.158702850341797, 'loss_4': 1.0656864643096924, 'epoch': 25.69}
{'loss': 0.0078, 'grad_norm': 4.809972286224365, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.0070861224085092545, 'loss_2': 0.000713348388671875, 'loss_3': -16.473953247070312, 'loss_4': 1.3288521766662598, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 11:15:18,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:18,850 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:48:45<12:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:26,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008854484185576439, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.607, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005825778469443321, 'eval_loss_2': 0.0030287057161331177, 'eval_loss_3': -18.198841094970703, 'eval_loss_4': 1.172803521156311, 'epoch': 25.7}
{'loss': 0.0142, 'grad_norm': 5.887794494628906, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.011693906970322132, 'loss_2': 0.002483367919921875, 'loss_3': -16.4515438079834, 'loss_4': 1.3264825344085693, 'epoch': 25.7}
{'loss': 0.0136, 'grad_norm': 5.791754245758057, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.006947951391339302, 'loss_2': 0.006683349609375, 'loss_3': -16.290424346923828, 'loss_4': 1.1550655364990234, 'epoch': 25.71}
{'loss': 0.0017, 'grad_norm': 4.701672554016113, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.001209760899655521, 'loss_2': 0.0005168914794921875, 'loss_3': -16.5112361907959, 'loss_4': 1.399707555770874, 'epoch': 25.72}
{'loss': 0.0052, 'grad_norm': 4.7151408195495605, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.0033375879283994436, 'loss_2': 0.001834869384765625, 'loss_3': -16.259418487548828, 'loss_4': 1.321720004081726, 'epoch': 25.72}
{'loss': 0.0066, 'grad_norm': 4.607025146484375, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.004764987621456385, 'loss_2': 0.001827239990234375, 'loss_3': -16.348236083984375, 'loss_4': 1.0329227447509766, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 11:15:26,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:26,184 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:48:53<12:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:33,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009330143220722675, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.282, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006049242801964283, 'eval_loss_2': 0.0032809004187583923, 'eval_loss_3': -18.1944580078125, 'eval_loss_4': 1.1495132446289062, 'epoch': 25.73}
{'loss': 0.0082, 'grad_norm': 5.171525955200195, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.006420799531042576, 'loss_2': 0.0017604827880859375, 'loss_3': -16.278608322143555, 'loss_4': 1.4936177730560303, 'epoch': 25.73}
{'loss': 0.0084, 'grad_norm': 5.192887783050537, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.005163395311683416, 'loss_2': 0.0032367706298828125, 'loss_3': -16.26491928100586, 'loss_4': 1.332158088684082, 'epoch': 25.74}
{'loss': 0.0096, 'grad_norm': 4.620913505554199, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.003436875529587269, 'loss_2': 0.0061492919921875, 'loss_3': -16.388690948486328, 'loss_4': 1.1811825037002563, 'epoch': 25.74}
{'loss': 0.0075, 'grad_norm': 5.7053446769714355, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.005988564342260361, 'loss_2': 0.0015201568603515625, 'loss_3': -16.345272064208984, 'loss_4': 1.3957509994506836, 'epoch': 25.75}
{'loss': 0.0091, 'grad_norm': 4.9681501388549805, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.003652512328699231, 'loss_2': 0.00545501708984375, 'loss_3': -16.30289077758789, 'loss_4': 1.2337589263916016, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 11:15:33,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:33,522 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:00<12:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:40,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008910114876925945, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.801, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0058717611245810986, 'eval_loss_2': 0.003038354218006134, 'eval_loss_3': -18.189538955688477, 'eval_loss_4': 1.1715937852859497, 'epoch': 25.76}
{'loss': 0.0093, 'grad_norm': 4.214641094207764, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.003655517939478159, 'loss_2': 0.005657196044921875, 'loss_3': -16.39642333984375, 'loss_4': 1.5085736513137817, 'epoch': 25.76}
{'loss': 0.0087, 'grad_norm': 4.127872467041016, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.004579911008477211, 'loss_2': 0.004161834716796875, 'loss_3': -16.44363784790039, 'loss_4': 0.8586790561676025, 'epoch': 25.77}
{'loss': 0.0082, 'grad_norm': 5.940140724182129, 'learning_rate': 4.25e-06, 'loss_1': 0.0055559552274644375, 'loss_2': 0.00260162353515625, 'loss_3': -16.310089111328125, 'loss_4': 0.9706053733825684, 'epoch': 25.77}
{'loss': 0.0093, 'grad_norm': 4.7823028564453125, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.005062795244157314, 'loss_2': 0.004245758056640625, 'loss_3': -16.306467056274414, 'loss_4': 1.3701300621032715, 'epoch': 25.78}
{'loss': 0.0068, 'grad_norm': 4.683793067932129, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.002430616645142436, 'loss_2': 0.004364013671875, 'loss_3': -16.315771102905273, 'loss_4': 1.011149287223816, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 11:15:40,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:40,879 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:08<12:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:48,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008362436667084694, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.673, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005537795834243298, 'eval_loss_2': 0.002824641764163971, 'eval_loss_3': -18.180133819580078, 'eval_loss_4': 1.1631903648376465, 'epoch': 25.78}
{'loss': 0.0125, 'grad_norm': 4.876351833343506, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.0066231596283614635, 'loss_2': 0.005859375, 'loss_3': -16.29483413696289, 'loss_4': 1.9713186025619507, 'epoch': 25.79}
{'loss': 0.0091, 'grad_norm': 5.398127555847168, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.0068124765530228615, 'loss_2': 0.002323150634765625, 'loss_3': -16.191394805908203, 'loss_4': 1.144824743270874, 'epoch': 25.8}
{'loss': 0.0035, 'grad_norm': 4.599062919616699, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.002735031535848975, 'loss_2': 0.0008039474487304688, 'loss_3': -16.33914566040039, 'loss_4': 1.0899728536605835, 'epoch': 25.8}
{'loss': 0.0055, 'grad_norm': 5.037374496459961, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.00490627670660615, 'loss_2': 0.0005559921264648438, 'loss_3': -16.31425666809082, 'loss_4': 1.4289989471435547, 'epoch': 25.81}
{'loss': 0.008, 'grad_norm': 4.699062824249268, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.0028474247083067894, 'loss_2': 0.00514984130859375, 'loss_3': -16.310001373291016, 'loss_4': 1.0633327960968018, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 11:15:48,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:48,207 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:15<12:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:55,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00847911648452282, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.546, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0055669448338449, 'eval_loss_2': 0.002912171185016632, 'eval_loss_3': -18.16956901550293, 'eval_loss_4': 1.1094272136688232, 'epoch': 25.81}
{'loss': 0.0057, 'grad_norm': 4.906910419464111, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.004650644492357969, 'loss_2': 0.001068115234375, 'loss_3': -16.45139503479004, 'loss_4': 1.1212952136993408, 'epoch': 25.82}
{'loss': 0.0053, 'grad_norm': 4.697331428527832, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.005165252834558487, 'loss_2': 0.0001392364501953125, 'loss_3': -16.3420352935791, 'loss_4': 0.8877202272415161, 'epoch': 25.83}
{'loss': 0.0244, 'grad_norm': 7.329807758331299, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.018157990649342537, 'loss_2': 0.006256103515625, 'loss_3': -16.431434631347656, 'loss_4': 0.8889750242233276, 'epoch': 25.83}
{'loss': 0.0049, 'grad_norm': 4.456031322479248, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.0027351155877113342, 'loss_2': 0.00213623046875, 'loss_3': -16.252201080322266, 'loss_4': 1.127335786819458, 'epoch': 25.84}
{'loss': 0.0131, 'grad_norm': 8.264496803283691, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.011389609426259995, 'loss_2': 0.0017042160034179688, 'loss_3': -16.318986892700195, 'loss_4': 1.3556498289108276, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 11:15:55,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:55,541 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:22<12:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:02,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008794774301350117, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00548457121476531, 'eval_loss_2': 0.0033102035522460938, 'eval_loss_3': -18.169326782226562, 'eval_loss_4': 1.0649563074111938, 'epoch': 25.84}
{'loss': 0.0131, 'grad_norm': 6.328298568725586, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.011335223913192749, 'loss_2': 0.00176239013671875, 'loss_3': -16.293136596679688, 'loss_4': 1.67246675491333, 'epoch': 25.85}
{'loss': 0.0088, 'grad_norm': 5.807147026062012, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.00795258954167366, 'loss_2': 0.0008473396301269531, 'loss_3': -16.265640258789062, 'loss_4': 1.137291669845581, 'epoch': 25.85}
{'loss': 0.0098, 'grad_norm': 4.313253879547119, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.0033618381712585688, 'loss_2': 0.00644683837890625, 'loss_3': -16.34707260131836, 'loss_4': 1.188597321510315, 'epoch': 25.86}
{'loss': 0.0045, 'grad_norm': 4.532819747924805, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.003204726381227374, 'loss_2': 0.0013408660888671875, 'loss_3': -16.34027862548828, 'loss_4': 0.9591726064682007, 'epoch': 25.87}
{'loss': 0.0099, 'grad_norm': 7.276163578033447, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.009694889187812805, 'loss_2': 0.000217437744140625, 'loss_3': -16.417098999023438, 'loss_4': 1.3115154504776, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 11:16:02,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:02,888 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:30<12:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:10,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009129172191023827, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.372, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00558192003518343, 'eval_loss_2': 0.0035472512245178223, 'eval_loss_3': -18.169233322143555, 'eval_loss_4': 1.0287493467330933, 'epoch': 25.87}
{'loss': 0.0147, 'grad_norm': 7.590005874633789, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.009469166398048401, 'loss_2': 0.005222320556640625, 'loss_3': -16.22221565246582, 'loss_4': 1.054314374923706, 'epoch': 25.88}
{'loss': 0.0055, 'grad_norm': 4.71287727355957, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.0041023241356015205, 'loss_2': 0.001369476318359375, 'loss_3': -16.273283004760742, 'loss_4': 0.8251787424087524, 'epoch': 25.88}
{'loss': 0.0155, 'grad_norm': 5.793018817901611, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.006860575173050165, 'loss_2': 0.0086212158203125, 'loss_3': -16.352338790893555, 'loss_4': 1.4595426321029663, 'epoch': 25.89}
{'loss': 0.0112, 'grad_norm': 4.954255104064941, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.004375210497528315, 'loss_2': 0.006793975830078125, 'loss_3': -16.23965072631836, 'loss_4': 0.9207803010940552, 'epoch': 25.9}
{'loss': 0.0082, 'grad_norm': 4.8642754554748535, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.0031687819864600897, 'loss_2': 0.005077362060546875, 'loss_3': -16.25082015991211, 'loss_4': 1.1736199855804443, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 11:16:10,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:10,226 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:49:37<12:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:17,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009680135175585747, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.334, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.005421115551143885, 'eval_loss_2': 0.004259020090103149, 'eval_loss_3': -18.166833877563477, 'eval_loss_4': 0.9852237701416016, 'epoch': 25.9}
{'loss': 0.0133, 'grad_norm': 5.169119358062744, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.004109812434762716, 'loss_2': 0.0092010498046875, 'loss_3': -16.399322509765625, 'loss_4': 1.1050986051559448, 'epoch': 25.91}
{'loss': 0.01, 'grad_norm': 5.074300289154053, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.006533920299261808, 'loss_2': 0.003459930419921875, 'loss_3': -16.35772705078125, 'loss_4': 1.0989439487457275, 'epoch': 25.91}
{'loss': 0.0182, 'grad_norm': 7.3141770362854, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.009993772953748703, 'loss_2': 0.008209228515625, 'loss_3': -16.111953735351562, 'loss_4': 1.6264233589172363, 'epoch': 25.92}
{'loss': 0.0092, 'grad_norm': 5.748010635375977, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.00642685079947114, 'loss_2': 0.002758026123046875, 'loss_3': -16.307903289794922, 'loss_4': 1.2038347721099854, 'epoch': 25.92}
{'loss': 0.008, 'grad_norm': 4.859341621398926, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.00370555161498487, 'loss_2': 0.004245758056640625, 'loss_3': -16.317453384399414, 'loss_4': 0.6716525554656982, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 11:16:17,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:17,555 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:49:44<11:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:24,883 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009718670509755611, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.155, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005507929716259241, 'eval_loss_2': 0.004210740327835083, 'eval_loss_3': -18.161020278930664, 'eval_loss_4': 0.9675630927085876, 'epoch': 25.93}
{'loss': 0.0055, 'grad_norm': 4.771052837371826, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.004990095272660255, 'loss_2': 0.0005092620849609375, 'loss_3': -16.172868728637695, 'loss_4': 0.7091124057769775, 'epoch': 25.94}
{'loss': 0.0099, 'grad_norm': 4.4859700202941895, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.002506906632333994, 'loss_2': 0.00739288330078125, 'loss_3': -16.207557678222656, 'loss_4': 0.7658971548080444, 'epoch': 25.94}
{'loss': 0.0078, 'grad_norm': 4.584524631500244, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.0045547946356236935, 'loss_2': 0.003265380859375, 'loss_3': -16.440256118774414, 'loss_4': 1.4528160095214844, 'epoch': 25.95}
{'loss': 0.0066, 'grad_norm': 4.706660270690918, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.002522426890209317, 'loss_2': 0.0040740966796875, 'loss_3': -16.295774459838867, 'loss_4': 0.8033060431480408, 'epoch': 25.95}
{'loss': 0.0129, 'grad_norm': 6.3705220222473145, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.009635800495743752, 'loss_2': 0.00324249267578125, 'loss_3': -16.24483871459961, 'loss_4': 1.0973199605941772, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 11:16:24,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:24,884 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:49:52<11:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:32,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008723238483071327, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.588, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.0056181056424975395, 'eval_loss_2': 0.0031051337718963623, 'eval_loss_3': -18.148555755615234, 'eval_loss_4': 0.9619814157485962, 'epoch': 25.96}
{'loss': 0.0117, 'grad_norm': 5.558982849121094, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.006020325236022472, 'loss_2': 0.00568389892578125, 'loss_3': -16.310962677001953, 'loss_4': 0.989829421043396, 'epoch': 25.97}
{'loss': 0.0124, 'grad_norm': 6.169430732727051, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.012005683034658432, 'loss_2': 0.0004248619079589844, 'loss_3': -16.305187225341797, 'loss_4': 0.9242352247238159, 'epoch': 25.97}
{'loss': 0.0064, 'grad_norm': 4.3605780601501465, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.001739206607453525, 'loss_2': 0.00470733642578125, 'loss_3': -16.197711944580078, 'loss_4': 1.2025877237319946, 'epoch': 25.98}
{'loss': 0.0098, 'grad_norm': 4.533030986785889, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.005610884632915258, 'loss_2': 0.004207611083984375, 'loss_3': -16.158716201782227, 'loss_4': 1.1810933351516724, 'epoch': 25.98}
{'loss': 0.0143, 'grad_norm': 5.418520927429199, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.01161294337362051, 'loss_2': 0.0027179718017578125, 'loss_3': -16.477767944335938, 'loss_4': 0.7640801668167114, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 11:16:32,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:32,209 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:49:59<11:30,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 11:16:39,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008100992999970913, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.136, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0053223734721541405, 'eval_loss_2': 0.0027786195278167725, 'eval_loss_3': -18.14316177368164, 'eval_loss_4': 0.966090202331543, 'epoch': 25.99}
{'loss': 0.0046, 'grad_norm': 4.690131187438965, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.002511288272216916, 'loss_2': 0.0020732879638671875, 'loss_3': -16.28093147277832, 'loss_4': 0.9258372187614441, 'epoch': 25.99}
{'loss': 0.0035, 'grad_norm': 5.286696434020996, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.0011960965348407626, 'loss_2': 0.0023250579833984375, 'loss_3': -16.231597900390625, 'loss_4': 0.9842482209205627, 'epoch': 26.0}
{'loss': 0.0057, 'grad_norm': 4.752795696258545, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.004032573662698269, 'loss_2': 0.0016880035400390625, 'loss_3': -16.34265899658203, 'loss_4': 1.1145555973052979, 'epoch': 26.01}
{'loss': 0.0138, 'grad_norm': 8.66833209991455, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.011301158927381039, 'loss_2': 0.002506256103515625, 'loss_3': -16.413650512695312, 'loss_4': 0.8901698589324951, 'epoch': 26.01}
{'loss': 0.0061, 'grad_norm': 4.507448196411133, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.004351941403001547, 'loss_2': 0.0017604827880859375, 'loss_3': -16.365680694580078, 'loss_4': 0.8468856811523438, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 11:16:39,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:39,236 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:06<11:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:16:46,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008144678547978401, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.152, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.004922004416584969, 'eval_loss_2': 0.0032226741313934326, 'eval_loss_3': -18.142261505126953, 'eval_loss_4': 0.994562029838562, 'epoch': 26.02}
{'loss': 0.0139, 'grad_norm': 7.2547101974487305, 'learning_rate': 4e-06, 'loss_1': 0.011449525132775307, 'loss_2': 0.0024433135986328125, 'loss_3': -16.28600311279297, 'loss_4': 0.39939892292022705, 'epoch': 26.02}
{'loss': 0.0102, 'grad_norm': 4.95247220993042, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.007547795306891203, 'loss_2': 0.002685546875, 'loss_3': -16.28310203552246, 'loss_4': 1.4338550567626953, 'epoch': 26.03}
{'loss': 0.0075, 'grad_norm': 5.430076599121094, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.002685173647478223, 'loss_2': 0.0048065185546875, 'loss_3': -16.336997985839844, 'loss_4': 0.7199416160583496, 'epoch': 26.03}
{'loss': 0.0053, 'grad_norm': 4.411589622497559, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.002710913773626089, 'loss_2': 0.0026340484619140625, 'loss_3': -16.548656463623047, 'loss_4': 1.5013535022735596, 'epoch': 26.04}
{'loss': 0.0099, 'grad_norm': 5.0933027267456055, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.0036456722300499678, 'loss_2': 0.006221771240234375, 'loss_3': -16.11587905883789, 'loss_4': 1.0066691637039185, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 11:16:46,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:46,575 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:13<11:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:53,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007759420201182365, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.582, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00486394576728344, 'eval_loss_2': 0.0028954744338989258, 'eval_loss_3': -18.141952514648438, 'eval_loss_4': 1.0382424592971802, 'epoch': 26.05}
{'loss': 0.0093, 'grad_norm': 5.088871955871582, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.007025622762739658, 'loss_2': 0.002307891845703125, 'loss_3': -16.284059524536133, 'loss_4': 0.7305343747138977, 'epoch': 26.05}
{'loss': 0.0151, 'grad_norm': 9.430060386657715, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.013155452907085419, 'loss_2': 0.0019435882568359375, 'loss_3': -16.308382034301758, 'loss_4': 1.6774442195892334, 'epoch': 26.06}
{'loss': 0.0071, 'grad_norm': 5.391171932220459, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.0059514460153877735, 'loss_2': 0.001110076904296875, 'loss_3': -16.37329864501953, 'loss_4': 1.3831452131271362, 'epoch': 26.06}
{'loss': 0.0157, 'grad_norm': 4.634622573852539, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.0024331468157470226, 'loss_2': 0.013275146484375, 'loss_3': -16.326404571533203, 'loss_4': 0.45860016345977783, 'epoch': 26.07}
{'loss': 0.0043, 'grad_norm': 5.112725257873535, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.004089055582880974, 'loss_2': 0.00018668174743652344, 'loss_3': -16.26066017150879, 'loss_4': 1.043879747390747, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 11:16:53,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:53,903 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:21<11:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:01,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007849348708987236, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.383, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00501219742000103, 'eval_loss_2': 0.002837151288986206, 'eval_loss_3': -18.132858276367188, 'eval_loss_4': 1.028764247894287, 'epoch': 26.08}
{'loss': 0.0034, 'grad_norm': 4.797678470611572, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.0019663977436721325, 'loss_2': 0.0014362335205078125, 'loss_3': -16.359867095947266, 'loss_4': 0.8914488554000854, 'epoch': 26.08}
{'loss': 0.0126, 'grad_norm': 5.505812644958496, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.007982968352735043, 'loss_2': 0.004665374755859375, 'loss_3': -16.281986236572266, 'loss_4': 1.0827946662902832, 'epoch': 26.09}
{'loss': 0.0136, 'grad_norm': 5.6517534255981445, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.00877794623374939, 'loss_2': 0.00478363037109375, 'loss_3': -16.33354377746582, 'loss_4': 1.0607000589370728, 'epoch': 26.09}
{'loss': 0.0114, 'grad_norm': 5.1568169593811035, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.006357778329402208, 'loss_2': 0.005035400390625, 'loss_3': -16.162134170532227, 'loss_4': 0.875891923904419, 'epoch': 26.1}
{'loss': 0.0106, 'grad_norm': 4.032898902893066, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.0037941306363791227, 'loss_2': 0.00677490234375, 'loss_3': -16.49507713317871, 'loss_4': 1.1152222156524658, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 11:17:01,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:01,241 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:28<11:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:08,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008483071811497211, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.249, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005548824556171894, 'eval_loss_2': 0.0029342472553253174, 'eval_loss_3': -18.13089942932129, 'eval_loss_4': 0.9708788990974426, 'epoch': 26.1}
{'loss': 0.007, 'grad_norm': 6.071775913238525, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.00532052805647254, 'loss_2': 0.001678466796875, 'loss_3': -16.344724655151367, 'loss_4': 0.7042912244796753, 'epoch': 26.11}
{'loss': 0.0108, 'grad_norm': 5.141844749450684, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.005757410079240799, 'loss_2': 0.00499725341796875, 'loss_3': -16.09653091430664, 'loss_4': 1.2955902814865112, 'epoch': 26.12}
{'loss': 0.0055, 'grad_norm': 4.904633522033691, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.0026453807950019836, 'loss_2': 0.0028629302978515625, 'loss_3': -16.438575744628906, 'loss_4': 0.7252601385116577, 'epoch': 26.12}
{'loss': 0.0042, 'grad_norm': 4.143013000488281, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.004158729687333107, 'loss_2': 5.8531761169433594e-05, 'loss_3': -16.209470748901367, 'loss_4': 0.8006236553192139, 'epoch': 26.13}
{'loss': 0.0088, 'grad_norm': 4.926687717437744, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.00348181021399796, 'loss_2': 0.005352020263671875, 'loss_3': -16.376911163330078, 'loss_4': 1.1796784400939941, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 11:17:08,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:08,581 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:35<11:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:15,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008502980694174767, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.507, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005761532578617334, 'eval_loss_2': 0.0027414485812187195, 'eval_loss_3': -18.125951766967773, 'eval_loss_4': 0.9099568128585815, 'epoch': 26.13}
{'loss': 0.0124, 'grad_norm': 5.372051239013672, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.009120158851146698, 'loss_2': 0.0033111572265625, 'loss_3': -16.26518440246582, 'loss_4': 1.0372874736785889, 'epoch': 26.14}
{'loss': 0.0083, 'grad_norm': 4.982355117797852, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.005702689755707979, 'loss_2': 0.00258636474609375, 'loss_3': -16.29833221435547, 'loss_4': 0.7184773683547974, 'epoch': 26.15}
{'loss': 0.018, 'grad_norm': 6.263821601867676, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.01075789611786604, 'loss_2': 0.007205963134765625, 'loss_3': -16.264366149902344, 'loss_4': 0.6021012663841248, 'epoch': 26.15}
{'loss': 0.0052, 'grad_norm': 4.544597148895264, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.00425087520852685, 'loss_2': 0.0009436607360839844, 'loss_3': -16.59256362915039, 'loss_4': 1.005144476890564, 'epoch': 26.16}
{'loss': 0.0068, 'grad_norm': 5.570652961730957, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.005715802311897278, 'loss_2': 0.00109100341796875, 'loss_3': -16.357559204101562, 'loss_4': 0.6929374933242798, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 11:17:15,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:15,909 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:50:43<11:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:23,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008979346603155136, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.046, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.006252903491258621, 'eval_loss_2': 0.002726443111896515, 'eval_loss_3': -18.120956420898438, 'eval_loss_4': 0.9011310338973999, 'epoch': 26.16}
{'loss': 0.0074, 'grad_norm': 5.299520969390869, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.006243084091693163, 'loss_2': 0.0011615753173828125, 'loss_3': -16.29256248474121, 'loss_4': 0.4126783013343811, 'epoch': 26.17}
{'loss': 0.0191, 'grad_norm': 7.415929794311523, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.013932952657341957, 'loss_2': 0.005126953125, 'loss_3': -16.253419876098633, 'loss_4': 0.8384038805961609, 'epoch': 26.17}
{'loss': 0.0065, 'grad_norm': 4.695794105529785, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.00493213115260005, 'loss_2': 0.00153350830078125, 'loss_3': -16.272903442382812, 'loss_4': 0.7896836400032043, 'epoch': 26.18}
{'loss': 0.0106, 'grad_norm': 6.481976509094238, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.009250487200915813, 'loss_2': 0.001384735107421875, 'loss_3': -16.478622436523438, 'loss_4': 1.201615333557129, 'epoch': 26.19}
{'loss': 0.0087, 'grad_norm': 4.705371379852295, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.004639304708689451, 'loss_2': 0.00408935546875, 'loss_3': -16.276752471923828, 'loss_4': 0.5200692415237427, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 11:17:23,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:23,254 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:50:50<11:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:30,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009190192446112633, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.613, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006714662071317434, 'eval_loss_2': 0.002475529909133911, 'eval_loss_3': -18.119277954101562, 'eval_loss_4': 0.8762652277946472, 'epoch': 26.19}
{'loss': 0.0063, 'grad_norm': 4.670736789703369, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.003271354828029871, 'loss_2': 0.003002166748046875, 'loss_3': -16.42377471923828, 'loss_4': 0.9035471677780151, 'epoch': 26.2}
{'loss': 0.0048, 'grad_norm': 4.489975452423096, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.0031747741159051657, 'loss_2': 0.001674652099609375, 'loss_3': -16.37105941772461, 'loss_4': 1.2894999980926514, 'epoch': 26.2}
{'loss': 0.0076, 'grad_norm': 5.202184200286865, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.004115032497793436, 'loss_2': 0.0034427642822265625, 'loss_3': -16.370052337646484, 'loss_4': 0.5196442008018494, 'epoch': 26.21}
{'loss': 0.0183, 'grad_norm': 5.515562057495117, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.012889771722257137, 'loss_2': 0.00545501708984375, 'loss_3': -16.48202896118164, 'loss_4': 0.8726692199707031, 'epoch': 26.22}
{'loss': 0.017, 'grad_norm': 9.280431747436523, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.011072658002376556, 'loss_2': 0.00592041015625, 'loss_3': -16.211610794067383, 'loss_4': 0.8832062482833862, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 11:17:30,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:30,581 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:50:57<11:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:37,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008879787288606167, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.262, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006411752663552761, 'eval_loss_2': 0.0024680346250534058, 'eval_loss_3': -18.120346069335938, 'eval_loss_4': 0.846776008605957, 'epoch': 26.22}
{'loss': 0.0139, 'grad_norm': 6.325507164001465, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.01119309663772583, 'loss_2': 0.002735137939453125, 'loss_3': -16.159324645996094, 'loss_4': 1.5143967866897583, 'epoch': 26.23}
{'loss': 0.0092, 'grad_norm': 5.612048149108887, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.005334645975381136, 'loss_2': 0.003864288330078125, 'loss_3': -16.298912048339844, 'loss_4': 0.5651391744613647, 'epoch': 26.23}
{'loss': 0.0094, 'grad_norm': 5.783060550689697, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.008263463154435158, 'loss_2': 0.001140594482421875, 'loss_3': -16.334606170654297, 'loss_4': 0.6607295274734497, 'epoch': 26.24}
{'loss': 0.0043, 'grad_norm': 5.004032135009766, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.002858411520719528, 'loss_2': 0.001430511474609375, 'loss_3': -16.345703125, 'loss_4': 0.8504429459571838, 'epoch': 26.24}
{'loss': 0.0082, 'grad_norm': 4.295005798339844, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.002572049852460623, 'loss_2': 0.005596160888671875, 'loss_3': -16.366451263427734, 'loss_4': 0.566098690032959, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 11:17:37,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:37,914 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:05<11:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:45,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008514074608683586, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.376, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005865721497684717, 'eval_loss_2': 0.0026483535766601562, 'eval_loss_3': -18.119577407836914, 'eval_loss_4': 0.823013424873352, 'epoch': 26.25}
{'loss': 0.0081, 'grad_norm': 4.585155487060547, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.0052775428630411625, 'loss_2': 0.00281524658203125, 'loss_3': -16.3525390625, 'loss_4': 0.9693607091903687, 'epoch': 26.26}
{'loss': 0.0129, 'grad_norm': 6.508095741271973, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.010664288885891438, 'loss_2': 0.00223541259765625, 'loss_3': -16.35335922241211, 'loss_4': 1.1618081331253052, 'epoch': 26.26}
{'loss': 0.0217, 'grad_norm': 8.156521797180176, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.014538193121552467, 'loss_2': 0.00714874267578125, 'loss_3': -16.236572265625, 'loss_4': 1.0831334590911865, 'epoch': 26.27}
{'loss': 0.0046, 'grad_norm': 5.348660945892334, 'learning_rate': 3.75e-06, 'loss_1': 0.0044582197442650795, 'loss_2': 0.00011563301086425781, 'loss_3': -16.408599853515625, 'loss_4': 0.5650671720504761, 'epoch': 26.27}
{'loss': 0.0075, 'grad_norm': 5.162360191345215, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.0032040623482316732, 'loss_2': 0.00433349609375, 'loss_3': -16.245071411132812, 'loss_4': 0.5133089423179626, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 11:17:45,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:45,244 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:12<10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:52,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008615314960479736, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.505, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0059165204875171185, 'eval_loss_2': 0.0026987940073013306, 'eval_loss_3': -18.103134155273438, 'eval_loss_4': 0.7954191565513611, 'epoch': 26.28}
{'loss': 0.0173, 'grad_norm': 8.738818168640137, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.011773577891290188, 'loss_2': 0.005523681640625, 'loss_3': -16.439743041992188, 'loss_4': 0.5942191481590271, 'epoch': 26.28}
{'loss': 0.0142, 'grad_norm': 8.688591003417969, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.009331992827355862, 'loss_2': 0.00487518310546875, 'loss_3': -16.126314163208008, 'loss_4': 0.2426237314939499, 'epoch': 26.29}
{'loss': 0.0164, 'grad_norm': 6.642496109008789, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.01262911967933178, 'loss_2': 0.003814697265625, 'loss_3': -16.325164794921875, 'loss_4': 0.9824832677841187, 'epoch': 26.3}
{'loss': 0.0105, 'grad_norm': 4.5229973793029785, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.003849729895591736, 'loss_2': 0.00662994384765625, 'loss_3': -16.182069778442383, 'loss_4': 1.143477439880371, 'epoch': 26.3}
{'loss': 0.0045, 'grad_norm': 4.8156657218933105, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.004358705133199692, 'loss_2': 0.00015497207641601562, 'loss_3': -16.391263961791992, 'loss_4': 1.0189859867095947, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 11:17:52,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:52,575 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:19<10:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:59,912 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00892273336648941, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.204, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006133355665951967, 'eval_loss_2': 0.0027893781661987305, 'eval_loss_3': -18.109722137451172, 'eval_loss_4': 0.7472550868988037, 'epoch': 26.31}
{'loss': 0.0065, 'grad_norm': 4.910523414611816, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.0052491952665150166, 'loss_2': 0.0012073516845703125, 'loss_3': -16.43617820739746, 'loss_4': 0.4661747217178345, 'epoch': 26.31}
{'loss': 0.0165, 'grad_norm': 7.104101657867432, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.015413928776979446, 'loss_2': 0.0010576248168945312, 'loss_3': -16.346111297607422, 'loss_4': 1.4553594589233398, 'epoch': 26.32}
{'loss': 0.0042, 'grad_norm': 4.5345306396484375, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.0022169507574290037, 'loss_2': 0.0020236968994140625, 'loss_3': -16.619037628173828, 'loss_4': 0.6228254437446594, 'epoch': 26.33}
{'loss': 0.0125, 'grad_norm': 5.392489910125732, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.004334718454629183, 'loss_2': 0.00817108154296875, 'loss_3': -16.15374183654785, 'loss_4': 0.48650693893432617, 'epoch': 26.33}
{'loss': 0.006, 'grad_norm': 4.591959476470947, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.004659036640077829, 'loss_2': 0.00138092041015625, 'loss_3': -16.21861457824707, 'loss_4': 1.0950591564178467, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 11:17:59,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:59,912 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:27<10:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:07,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00831906870007515, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0057232272811234, 'eval_loss_2': 0.002595841884613037, 'eval_loss_3': -18.114152908325195, 'eval_loss_4': 0.7053580284118652, 'epoch': 26.34}
{'loss': 0.0066, 'grad_norm': 4.6005682945251465, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0031860684975981712, 'loss_2': 0.00337982177734375, 'loss_3': -16.417255401611328, 'loss_4': 0.7527135610580444, 'epoch': 26.34}
{'loss': 0.0046, 'grad_norm': 4.477102279663086, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.0021179555915296078, 'loss_2': 0.0024509429931640625, 'loss_3': -16.266498565673828, 'loss_4': 0.830642580986023, 'epoch': 26.35}
{'loss': 0.0142, 'grad_norm': 5.469295978546143, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.0111671919003129, 'loss_2': 0.0030517578125, 'loss_3': -16.4265079498291, 'loss_4': 1.0571504831314087, 'epoch': 26.35}
{'loss': 0.0097, 'grad_norm': 5.016518592834473, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.006562415044754744, 'loss_2': 0.0031757354736328125, 'loss_3': -16.314132690429688, 'loss_4': 1.010202407836914, 'epoch': 26.36}
{'loss': 0.0073, 'grad_norm': 5.21933126449585, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.006339299958199263, 'loss_2': 0.0009374618530273438, 'loss_3': -16.385723114013672, 'loss_4': 0.154750257730484, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 11:18:07,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:07,259 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:34<10:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:14,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009175434708595276, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.438, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0062865763902664185, 'eval_loss_2': 0.0028888583183288574, 'eval_loss_3': -18.124980926513672, 'eval_loss_4': 0.6742214560508728, 'epoch': 26.37}
{'loss': 0.006, 'grad_norm': 4.211623191833496, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.005619480740278959, 'loss_2': 0.0004239082336425781, 'loss_3': -16.24639129638672, 'loss_4': 0.7267568707466125, 'epoch': 26.37}
{'loss': 0.0055, 'grad_norm': 4.489990711212158, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.003943943418562412, 'loss_2': 0.0015497207641601562, 'loss_3': -16.565698623657227, 'loss_4': 0.574939489364624, 'epoch': 26.38}
{'loss': 0.0124, 'grad_norm': 5.924394130706787, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.006244818679988384, 'loss_2': 0.0061798095703125, 'loss_3': -16.2836971282959, 'loss_4': 0.5115673542022705, 'epoch': 26.38}
{'loss': 0.0105, 'grad_norm': 4.952587604522705, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.008050503209233284, 'loss_2': 0.002437591552734375, 'loss_3': -16.357013702392578, 'loss_4': 0.7350114583969116, 'epoch': 26.39}
{'loss': 0.0119, 'grad_norm': 4.579138278961182, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.006348955444991589, 'loss_2': 0.005542755126953125, 'loss_3': -16.345762252807617, 'loss_4': 0.32962220907211304, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 11:18:14,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:14,592 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:51:41<10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:21,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008334343321621418, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0060623036697506905, 'eval_loss_2': 0.0022720396518707275, 'eval_loss_3': -18.133577346801758, 'eval_loss_4': 0.6515012383460999, 'epoch': 26.4}
{'loss': 0.0042, 'grad_norm': 4.183030128479004, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.0020682085305452347, 'loss_2': 0.002162933349609375, 'loss_3': -16.519184112548828, 'loss_4': 0.6637663841247559, 'epoch': 26.4}
{'loss': 0.0057, 'grad_norm': 4.729674339294434, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.002844308502972126, 'loss_2': 0.002811431884765625, 'loss_3': -16.364879608154297, 'loss_4': 0.8864257335662842, 'epoch': 26.41}
{'loss': 0.0146, 'grad_norm': 4.708131790161133, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.004594641737639904, 'loss_2': 0.0099945068359375, 'loss_3': -16.320465087890625, 'loss_4': 1.0891530513763428, 'epoch': 26.41}
{'loss': 0.0084, 'grad_norm': 5.619195461273193, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.006826024502515793, 'loss_2': 0.001575469970703125, 'loss_3': -16.25373649597168, 'loss_4': 0.553226113319397, 'epoch': 26.42}
{'loss': 0.0079, 'grad_norm': 5.156474590301514, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0026106699369847775, 'loss_2': 0.00527191162109375, 'loss_3': -16.189729690551758, 'loss_4': 0.6313891410827637, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 11:18:21,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:21,935 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:51:49<10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:29,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008163551799952984, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.208, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.005783613305538893, 'eval_loss_2': 0.0023799389600753784, 'eval_loss_3': -18.130334854125977, 'eval_loss_4': 0.6357054710388184, 'epoch': 26.42}
{'loss': 0.0071, 'grad_norm': 4.727924823760986, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.003110306803137064, 'loss_2': 0.00399017333984375, 'loss_3': -16.30731964111328, 'loss_4': 0.5453993082046509, 'epoch': 26.43}
{'loss': 0.012, 'grad_norm': 4.49166202545166, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.00256265327334404, 'loss_2': 0.0093994140625, 'loss_3': -16.359333038330078, 'loss_4': 0.893150269985199, 'epoch': 26.44}
{'loss': 0.0102, 'grad_norm': 4.667128562927246, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.008018003776669502, 'loss_2': 0.002155303955078125, 'loss_3': -16.429733276367188, 'loss_4': 0.5201517939567566, 'epoch': 26.44}
{'loss': 0.0036, 'grad_norm': 4.805064678192139, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.0035893262829631567, 'loss_2': 4.482269287109375e-05, 'loss_3': -16.33207130432129, 'loss_4': 0.7289721965789795, 'epoch': 26.45}
{'loss': 0.0038, 'grad_norm': 4.128042697906494, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.0033310966100543737, 'loss_2': 0.00043320655822753906, 'loss_3': -16.2474422454834, 'loss_4': 0.9579175710678101, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 11:18:29,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:29,272 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:51:56<10:36,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:18:36,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008245954290032387, 'eval_runtime': 3.9959, 'eval_samples_per_second': 256.262, 'eval_steps_per_second': 4.004, 'eval_loss_1': 0.005294914357364178, 'eval_loss_2': 0.0029510408639907837, 'eval_loss_3': -18.136600494384766, 'eval_loss_4': 0.6372283101081848, 'epoch': 26.45}
{'loss': 0.0096, 'grad_norm': 5.450214862823486, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.00809654500335455, 'loss_2': 0.0014896392822265625, 'loss_3': -16.471939086914062, 'loss_4': 0.46291810274124146, 'epoch': 26.46}
{'loss': 0.0079, 'grad_norm': 5.321905612945557, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0037319466937333345, 'loss_2': 0.0041351318359375, 'loss_3': -16.21417999267578, 'loss_4': 0.21420305967330933, 'epoch': 26.47}
{'loss': 0.0093, 'grad_norm': 4.545326232910156, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.004089496098458767, 'loss_2': 0.00518798828125, 'loss_3': -16.186691284179688, 'loss_4': 0.4629020094871521, 'epoch': 26.47}
{'loss': 0.0105, 'grad_norm': 5.68587589263916, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.009594812989234924, 'loss_2': 0.0008754730224609375, 'loss_3': -16.34406280517578, 'loss_4': 0.8195714354515076, 'epoch': 26.48}
{'loss': 0.0076, 'grad_norm': 4.696559906005859, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.0015707092825323343, 'loss_2': 0.00606536865234375, 'loss_3': -16.266536712646484, 'loss_4': 0.8958528637886047, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 11:18:36,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:36,813 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:03<10:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:44,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008324675261974335, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.795, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0054404581896960735, 'eval_loss_2': 0.002884216606616974, 'eval_loss_3': -18.14372444152832, 'eval_loss_4': 0.625334620475769, 'epoch': 26.48}
{'loss': 0.0035, 'grad_norm': 4.333144664764404, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.003127236384898424, 'loss_2': 0.0003972053527832031, 'loss_3': -16.454906463623047, 'loss_4': 0.8281197547912598, 'epoch': 26.49}
{'loss': 0.0132, 'grad_norm': 7.438069820404053, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.009045352227985859, 'loss_2': 0.0041961669921875, 'loss_3': -16.280010223388672, 'loss_4': 1.0417659282684326, 'epoch': 26.49}
{'loss': 0.0162, 'grad_norm': 7.317924499511719, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.010737034492194653, 'loss_2': 0.0055084228515625, 'loss_3': -16.44629669189453, 'loss_4': 0.7225098013877869, 'epoch': 26.5}
{'loss': 0.0142, 'grad_norm': 8.223546981811523, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.011483615264296532, 'loss_2': 0.0026702880859375, 'loss_3': -16.307144165039062, 'loss_4': 1.063714861869812, 'epoch': 26.51}
{'loss': 0.0053, 'grad_norm': 4.573103427886963, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.0033873962238430977, 'loss_2': 0.00189971923828125, 'loss_3': -16.315942764282227, 'loss_4': 1.0562775135040283, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 11:18:44,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:44,150 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:11<10:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:51,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008333844132721424, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.321, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0055645303800702095, 'eval_loss_2': 0.0027693137526512146, 'eval_loss_3': -18.148813247680664, 'eval_loss_4': 0.6235129833221436, 'epoch': 26.51}
{'loss': 0.0152, 'grad_norm': 5.838562488555908, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.005966439377516508, 'loss_2': 0.0092010498046875, 'loss_3': -16.189006805419922, 'loss_4': 0.5836844444274902, 'epoch': 26.52}
{'loss': 0.0105, 'grad_norm': 5.2942938804626465, 'learning_rate': 3.5e-06, 'loss_1': 0.005267735570669174, 'loss_2': 0.00524139404296875, 'loss_3': -16.3194580078125, 'loss_4': 0.9630464315414429, 'epoch': 26.52}
{'loss': 0.0068, 'grad_norm': 4.645572662353516, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.003257417120039463, 'loss_2': 0.003520965576171875, 'loss_3': -16.328155517578125, 'loss_4': 0.7837612628936768, 'epoch': 26.53}
{'loss': 0.005, 'grad_norm': 4.9890522956848145, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.004879760090261698, 'loss_2': 9.02414321899414e-05, 'loss_3': -16.408573150634766, 'loss_4': 1.0510389804840088, 'epoch': 26.53}
{'loss': 0.0111, 'grad_norm': 5.923868179321289, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.009418384172022343, 'loss_2': 0.0017309188842773438, 'loss_3': -16.43090057373047, 'loss_4': 0.5374853014945984, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 11:18:51,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:51,487 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:18<10:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:58,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008484076708555222, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.012, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0058379885740578175, 'eval_loss_2': 0.0026460886001586914, 'eval_loss_3': -18.13388442993164, 'eval_loss_4': 0.6267463564872742, 'epoch': 26.54}
{'loss': 0.0094, 'grad_norm': 3.8161966800689697, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.00364784081466496, 'loss_2': 0.00572967529296875, 'loss_3': -16.2933406829834, 'loss_4': 0.15035513043403625, 'epoch': 26.55}
{'loss': 0.0055, 'grad_norm': 4.870444297790527, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.004469776060432196, 'loss_2': 0.001018524169921875, 'loss_3': -16.429113388061523, 'loss_4': 0.5594891905784607, 'epoch': 26.55}
{'loss': 0.011, 'grad_norm': 6.944194316864014, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.00889633409678936, 'loss_2': 0.002147674560546875, 'loss_3': -16.248645782470703, 'loss_4': 0.5011003613471985, 'epoch': 26.56}
{'loss': 0.0089, 'grad_norm': 4.623748779296875, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.002603983273729682, 'loss_2': 0.00628662109375, 'loss_3': -16.323598861694336, 'loss_4': 1.0505268573760986, 'epoch': 26.56}
{'loss': 0.0047, 'grad_norm': 4.632467746734619, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.004336418118327856, 'loss_2': 0.00040531158447265625, 'loss_3': -16.206144332885742, 'loss_4': 0.36909112334251404, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 11:18:58,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:58,824 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:25<10:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:06,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00838770903646946, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.26, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005869234446436167, 'eval_loss_2': 0.00251847505569458, 'eval_loss_3': -18.11967658996582, 'eval_loss_4': 0.6550589799880981, 'epoch': 26.57}
{'loss': 0.0046, 'grad_norm': 5.107535362243652, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.004169199150055647, 'loss_2': 0.0004315376281738281, 'loss_3': -16.319154739379883, 'loss_4': 0.8027243614196777, 'epoch': 26.58}
{'loss': 0.0164, 'grad_norm': 7.788529396057129, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.013368210755288601, 'loss_2': 0.003078460693359375, 'loss_3': -16.410913467407227, 'loss_4': 0.770814061164856, 'epoch': 26.58}
{'loss': 0.0046, 'grad_norm': 4.66042423248291, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.002415277296677232, 'loss_2': 0.0021514892578125, 'loss_3': -16.418420791625977, 'loss_4': 0.8156667947769165, 'epoch': 26.59}
{'loss': 0.008, 'grad_norm': 5.06313419342041, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.004883176647126675, 'loss_2': 0.003124237060546875, 'loss_3': -16.101654052734375, 'loss_4': 0.5319051146507263, 'epoch': 26.59}
{'loss': 0.0113, 'grad_norm': 5.887517929077148, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.006573151797056198, 'loss_2': 0.0047760009765625, 'loss_3': -16.113927841186523, 'loss_4': 0.43341055512428284, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 11:19:06,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:06,156 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:33<10:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:13,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008048606105148792, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005633991211652756, 'eval_loss_2': 0.002414613962173462, 'eval_loss_3': -18.114295959472656, 'eval_loss_4': 0.6966454982757568, 'epoch': 26.6}
{'loss': 0.0072, 'grad_norm': 5.280344486236572, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.005013240501284599, 'loss_2': 0.0021800994873046875, 'loss_3': -16.1937198638916, 'loss_4': 0.4238317608833313, 'epoch': 26.6}
{'loss': 0.0065, 'grad_norm': 4.936607360839844, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.0036130754742771387, 'loss_2': 0.002849578857421875, 'loss_3': -16.247478485107422, 'loss_4': 1.2011207342147827, 'epoch': 26.61}
{'loss': 0.0129, 'grad_norm': 5.15242862701416, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.00538551714271307, 'loss_2': 0.00756072998046875, 'loss_3': -16.28264045715332, 'loss_4': 0.7694849371910095, 'epoch': 26.62}
{'loss': 0.0132, 'grad_norm': 5.138943672180176, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.00913653988391161, 'loss_2': 0.00405120849609375, 'loss_3': -16.396541595458984, 'loss_4': 0.9082581400871277, 'epoch': 26.62}
{'loss': 0.0101, 'grad_norm': 4.673549652099609, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.00455495435744524, 'loss_2': 0.00550079345703125, 'loss_3': -16.070959091186523, 'loss_4': 0.7618205547332764, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 11:19:13,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:13,483 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:52:40<09:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:20,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00781500618904829, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.373, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00562688335776329, 'eval_loss_2': 0.0021881237626075745, 'eval_loss_3': -18.113195419311523, 'eval_loss_4': 0.7226366996765137, 'epoch': 26.63}
{'loss': 0.0057, 'grad_norm': 4.74428129196167, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.0037304176948964596, 'loss_2': 0.0019245147705078125, 'loss_3': -16.142786026000977, 'loss_4': 0.8548122644424438, 'epoch': 26.63}
{'loss': 0.0041, 'grad_norm': 4.665290355682373, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.003262904239818454, 'loss_2': 0.0008258819580078125, 'loss_3': -16.38237762451172, 'loss_4': 0.684886634349823, 'epoch': 26.64}
{'loss': 0.034, 'grad_norm': 15.276032447814941, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.03187721222639084, 'loss_2': 0.002109527587890625, 'loss_3': -16.20919418334961, 'loss_4': 0.470237135887146, 'epoch': 26.65}
{'loss': 0.0056, 'grad_norm': 4.285239219665527, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.0021863821893930435, 'loss_2': 0.0034580230712890625, 'loss_3': -16.371606826782227, 'loss_4': 0.40881842374801636, 'epoch': 26.65}
{'loss': 0.0158, 'grad_norm': 10.04670524597168, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.01454935409128666, 'loss_2': 0.001209259033203125, 'loss_3': -16.333740234375, 'loss_4': 0.5845822095870972, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 11:19:20,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:20,810 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:52:47<09:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:28,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0077082496136426926, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0055665429681539536, 'eval_loss_2': 0.002141706645488739, 'eval_loss_3': -18.11374282836914, 'eval_loss_4': 0.7343986630439758, 'epoch': 26.66}
{'loss': 0.0036, 'grad_norm': 4.999745845794678, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.0032194771338254213, 'loss_2': 0.0003514289855957031, 'loss_3': -16.50521469116211, 'loss_4': 0.5785942673683167, 'epoch': 26.66}
{'loss': 0.0125, 'grad_norm': 7.288171768188477, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.009333478286862373, 'loss_2': 0.003116607666015625, 'loss_3': -16.26128387451172, 'loss_4': 0.7005598545074463, 'epoch': 26.67}
{'loss': 0.0098, 'grad_norm': 5.065891265869141, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.002561878180131316, 'loss_2': 0.00728607177734375, 'loss_3': -16.452638626098633, 'loss_4': 0.6683072447776794, 'epoch': 26.67}
{'loss': 0.0029, 'grad_norm': 4.686981678009033, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.0020557898096740246, 'loss_2': 0.0008535385131835938, 'loss_3': -16.501663208007812, 'loss_4': 0.3459703326225281, 'epoch': 26.68}
{'loss': 0.0092, 'grad_norm': 5.104094982147217, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.004192585591226816, 'loss_2': 0.00501251220703125, 'loss_3': -16.353811264038086, 'loss_4': 0.8357789516448975, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 11:19:28,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:28,154 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:52:55<09:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:35,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008122224360704422, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.596, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00568138062953949, 'eval_loss_2': 0.0024408437311649323, 'eval_loss_3': -18.111343383789062, 'eval_loss_4': 0.7412120699882507, 'epoch': 26.69}
{'loss': 0.0178, 'grad_norm': 7.943842887878418, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.014261490665376186, 'loss_2': 0.003543853759765625, 'loss_3': -16.080902099609375, 'loss_4': 0.3977853059768677, 'epoch': 26.69}
{'loss': 0.0058, 'grad_norm': 4.402990341186523, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0030885282903909683, 'loss_2': 0.00267791748046875, 'loss_3': -16.64244270324707, 'loss_4': 0.34464412927627563, 'epoch': 26.7}
{'loss': 0.0178, 'grad_norm': 4.922538757324219, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.010078366845846176, 'loss_2': 0.007720947265625, 'loss_3': -16.130634307861328, 'loss_4': 0.9949382543563843, 'epoch': 26.7}
{'loss': 0.0086, 'grad_norm': 5.507172107696533, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.005230894777923822, 'loss_2': 0.0033721923828125, 'loss_3': -16.476348876953125, 'loss_4': 0.5492371320724487, 'epoch': 26.71}
{'loss': 0.0164, 'grad_norm': 7.220882892608643, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.009704167023301125, 'loss_2': 0.00667572021484375, 'loss_3': -16.252239227294922, 'loss_4': 0.7684619426727295, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 11:19:35,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:35,488 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:02<09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:42,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008596185594797134, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.195, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.005439777858555317, 'eval_loss_2': 0.003156408667564392, 'eval_loss_3': -18.109716415405273, 'eval_loss_4': 0.7602081298828125, 'epoch': 26.72}
{'loss': 0.0076, 'grad_norm': 5.395785808563232, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.003550660563632846, 'loss_2': 0.00400543212890625, 'loss_3': -16.474546432495117, 'loss_4': 0.9024704694747925, 'epoch': 26.72}
{'loss': 0.0062, 'grad_norm': 4.743139266967773, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.004562718328088522, 'loss_2': 0.00165557861328125, 'loss_3': -16.1159725189209, 'loss_4': 0.5741652250289917, 'epoch': 26.73}
{'loss': 0.0078, 'grad_norm': 4.431581020355225, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.004090938717126846, 'loss_2': 0.0036602020263671875, 'loss_3': -16.407875061035156, 'loss_4': 0.8833069801330566, 'epoch': 26.73}
{'loss': 0.003, 'grad_norm': 4.9170823097229, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.0028073538560420275, 'loss_2': 0.0001976490020751953, 'loss_3': -16.2723445892334, 'loss_4': 0.6518033742904663, 'epoch': 26.74}
{'loss': 0.0104, 'grad_norm': 7.351041793823242, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.009932702407240868, 'loss_2': 0.0005092620849609375, 'loss_3': -16.234540939331055, 'loss_4': 1.0126323699951172, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 11:19:42,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:42,826 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:09<09:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:50,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008793163113296032, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.486, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005626853089779615, 'eval_loss_2': 0.003166310489177704, 'eval_loss_3': -18.0982666015625, 'eval_loss_4': 0.7396071553230286, 'epoch': 26.74}
{'loss': 0.008, 'grad_norm': 4.664092540740967, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.0044406321831047535, 'loss_2': 0.003543853759765625, 'loss_3': -16.429683685302734, 'loss_4': 1.3042855262756348, 'epoch': 26.75}
{'loss': 0.0039, 'grad_norm': 4.700844764709473, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.002799851354211569, 'loss_2': 0.0010652542114257812, 'loss_3': -16.482942581176758, 'loss_4': 1.140685796737671, 'epoch': 26.76}
{'loss': 0.0102, 'grad_norm': 4.765575408935547, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.00526157021522522, 'loss_2': 0.00489044189453125, 'loss_3': -16.261367797851562, 'loss_4': 0.890576958656311, 'epoch': 26.76}
{'loss': 0.0133, 'grad_norm': 4.725534439086914, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.003936840686947107, 'loss_2': 0.00936126708984375, 'loss_3': -16.197309494018555, 'loss_4': 1.1703262329101562, 'epoch': 26.77}
{'loss': 0.0063, 'grad_norm': 4.907150745391846, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.003498016856610775, 'loss_2': 0.002780914306640625, 'loss_3': -16.405437469482422, 'loss_4': 0.6684094667434692, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 11:19:50,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:50,156 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:17<09:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:57,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008272267878055573, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.231, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.004967206157743931, 'eval_loss_2': 0.0033050626516342163, 'eval_loss_3': -18.101219177246094, 'eval_loss_4': 0.7236945629119873, 'epoch': 26.77}
{'loss': 0.0047, 'grad_norm': 4.623115062713623, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.003448139876127243, 'loss_2': 0.0012683868408203125, 'loss_3': -16.144927978515625, 'loss_4': 0.7006713151931763, 'epoch': 26.78}
{'loss': 0.0028, 'grad_norm': 4.454684734344482, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.002065008506178856, 'loss_2': 0.0007038116455078125, 'loss_3': -16.32843017578125, 'loss_4': 0.9220855832099915, 'epoch': 26.78}
{'loss': 0.0123, 'grad_norm': 7.644151210784912, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.010064362548291683, 'loss_2': 0.00228118896484375, 'loss_3': -16.32394790649414, 'loss_4': 0.9427840709686279, 'epoch': 26.79}
{'loss': 0.0057, 'grad_norm': 4.552705764770508, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.003613832173869014, 'loss_2': 0.002105712890625, 'loss_3': -16.460580825805664, 'loss_4': 0.8646405935287476, 'epoch': 26.8}
{'loss': 0.0096, 'grad_norm': 4.890536308288574, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.0064996592700481415, 'loss_2': 0.0030574798583984375, 'loss_3': -16.16522979736328, 'loss_4': 0.7322566509246826, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 11:19:57,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:57,492 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:24<09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:04,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007762431167066097, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.005, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.004671681206673384, 'eval_loss_2': 0.003090750426054001, 'eval_loss_3': -18.116792678833008, 'eval_loss_4': 0.7366461753845215, 'epoch': 26.8}
{'loss': 0.011, 'grad_norm': 5.811202526092529, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.009707624092698097, 'loss_2': 0.00125885009765625, 'loss_3': -16.263118743896484, 'loss_4': 0.25815337896347046, 'epoch': 26.81}
{'loss': 0.0095, 'grad_norm': 5.08523416519165, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.006192703265696764, 'loss_2': 0.00335693359375, 'loss_3': -16.073984146118164, 'loss_4': 0.41973403096199036, 'epoch': 26.81}
{'loss': 0.0039, 'grad_norm': 4.534008026123047, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.0022144881077110767, 'loss_2': 0.0016536712646484375, 'loss_3': -16.255563735961914, 'loss_4': 0.1928693801164627, 'epoch': 26.82}
{'loss': 0.0079, 'grad_norm': 5.326167583465576, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.007826371118426323, 'loss_2': 6.67572021484375e-05, 'loss_3': -16.355052947998047, 'loss_4': 0.6698803305625916, 'epoch': 26.83}
{'loss': 0.0056, 'grad_norm': 4.477602005004883, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.0025841095484793186, 'loss_2': 0.0029964447021484375, 'loss_3': -16.399728775024414, 'loss_4': 0.2838880717754364, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 11:20:04,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:04,828 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:31<09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:12,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008273333311080933, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.315, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.004960480611771345, 'eval_loss_2': 0.0033128522336483, 'eval_loss_3': -18.127107620239258, 'eval_loss_4': 0.7383789420127869, 'epoch': 26.83}
{'loss': 0.0062, 'grad_norm': 4.813313961029053, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.003996538929641247, 'loss_2': 0.002216339111328125, 'loss_3': -16.28847312927246, 'loss_4': 0.6223664283752441, 'epoch': 26.84}
{'loss': 0.0057, 'grad_norm': 4.627233505249023, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.004459137097001076, 'loss_2': 0.0012807846069335938, 'loss_3': -16.226604461669922, 'loss_4': 1.1579277515411377, 'epoch': 26.84}
{'loss': 0.0051, 'grad_norm': 4.757041931152344, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.004886435344815254, 'loss_2': 0.00018858909606933594, 'loss_3': -16.130069732666016, 'loss_4': 0.5421066284179688, 'epoch': 26.85}
{'loss': 0.0064, 'grad_norm': 5.126603603363037, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.0031177117489278316, 'loss_2': 0.003265380859375, 'loss_3': -16.29137420654297, 'loss_4': 0.4499862492084503, 'epoch': 26.85}
{'loss': 0.0108, 'grad_norm': 6.799170017242432, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.009210361167788506, 'loss_2': 0.0015821456909179688, 'loss_3': -16.29599952697754, 'loss_4': 0.7627005577087402, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 11:20:12,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:12,159 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:53:39<09:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:19,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008072305470705032, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.004752915818244219, 'eval_loss_2': 0.003319390118122101, 'eval_loss_3': -18.13471031188965, 'eval_loss_4': 0.7903027534484863, 'epoch': 26.86}
{'loss': 0.0139, 'grad_norm': 4.664870262145996, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.007513508200645447, 'loss_2': 0.006366729736328125, 'loss_3': -16.326526641845703, 'loss_4': 1.105182409286499, 'epoch': 26.87}
{'loss': 0.0112, 'grad_norm': 4.718261241912842, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.00487587321549654, 'loss_2': 0.00630950927734375, 'loss_3': -16.388530731201172, 'loss_4': 0.9008080363273621, 'epoch': 26.87}
{'loss': 0.0048, 'grad_norm': 7.75699520111084, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.0024947901256382465, 'loss_2': 0.002288818359375, 'loss_3': -16.256032943725586, 'loss_4': 0.9383684992790222, 'epoch': 26.88}
{'loss': 0.0085, 'grad_norm': 4.5731682777404785, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.0026932985056191683, 'loss_2': 0.00582122802734375, 'loss_3': -16.391386032104492, 'loss_4': 0.8822610378265381, 'epoch': 26.88}
{'loss': 0.0227, 'grad_norm': 8.062822341918945, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.0181923545897007, 'loss_2': 0.0045166015625, 'loss_3': -16.508535385131836, 'loss_4': 0.8733952045440674, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 11:20:19,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:19,499 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:53:46<09:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:26,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007781244348734617, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.586, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.004411614965647459, 'eval_loss_2': 0.003369629383087158, 'eval_loss_3': -18.141109466552734, 'eval_loss_4': 0.8377261757850647, 'epoch': 26.89}
{'loss': 0.0062, 'grad_norm': 4.748270034790039, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.004866001196205616, 'loss_2': 0.00130462646484375, 'loss_3': -16.290781021118164, 'loss_4': 1.04136323928833, 'epoch': 26.9}
{'loss': 0.0086, 'grad_norm': 4.610166549682617, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.006301581859588623, 'loss_2': 0.0022830963134765625, 'loss_3': -16.28586196899414, 'loss_4': 0.8241082429885864, 'epoch': 26.9}
{'loss': 0.0073, 'grad_norm': 5.274172782897949, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.003678092500194907, 'loss_2': 0.0036163330078125, 'loss_3': -16.29115104675293, 'loss_4': 0.67750084400177, 'epoch': 26.91}
{'loss': 0.0066, 'grad_norm': 5.142016410827637, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.006006807088851929, 'loss_2': 0.0005550384521484375, 'loss_3': -16.199726104736328, 'loss_4': 0.8929476141929626, 'epoch': 26.91}
{'loss': 0.0026, 'grad_norm': 4.444636821746826, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.002504230011254549, 'loss_2': 6.270408630371094e-05, 'loss_3': -16.490699768066406, 'loss_4': 0.8156207799911499, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 11:20:26,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:26,826 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:53:53<09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:34,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007572676986455917, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.004385079722851515, 'eval_loss_2': 0.0031875967979431152, 'eval_loss_3': -18.139007568359375, 'eval_loss_4': 0.8574705123901367, 'epoch': 26.92}
{'loss': 0.0056, 'grad_norm': 4.540055274963379, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.002784050302579999, 'loss_2': 0.002857208251953125, 'loss_3': -16.09136199951172, 'loss_4': 0.701938271522522, 'epoch': 26.92}
{'loss': 0.0088, 'grad_norm': 4.295531749725342, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.004047846887260675, 'loss_2': 0.0047454833984375, 'loss_3': -16.308330535888672, 'loss_4': 0.7494059801101685, 'epoch': 26.93}
{'loss': 0.0056, 'grad_norm': 5.000997543334961, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.0055006276816129684, 'loss_2': 0.0001232624053955078, 'loss_3': -16.17108726501465, 'loss_4': 0.740811824798584, 'epoch': 26.94}
{'loss': 0.0049, 'grad_norm': 4.88379430770874, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.0025364626199007034, 'loss_2': 0.0023403167724609375, 'loss_3': -16.479881286621094, 'loss_4': 0.6975206136703491, 'epoch': 26.94}
{'loss': 0.0205, 'grad_norm': 8.09537124633789, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.011374975554645061, 'loss_2': 0.0090789794921875, 'loss_3': -16.25348663330078, 'loss_4': 0.8105766177177429, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 11:20:34,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:34,162 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:53:57<09:04,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 11:20:37,953 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635
[INFO|configuration_utils.py:420] 2025-01-21 11:20:37,954 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635/config.json                                                                             
{'eval_loss': 0.007151917088776827, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.256, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.004368484485894442, 'eval_loss_2': 0.0027834326028823853, 'eval_loss_3': -18.132905960083008, 'eval_loss_4': 0.8670235276222229, 'epoch': 26.95}
[INFO|modeling_utils.py:2988] 2025-01-21 11:20:38,459 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:20:38,461 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:20:38,461 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 11:20:39,439 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4380] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:02<09:58,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 11:20:43,072 >>
{'loss': 0.012, 'grad_norm': 5.752853870391846, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.007641242817044258, 'loss_2': 0.0043792724609375, 'loss_3': -16.154808044433594, 'loss_4': 0.7111373543739319, 'epoch': 26.95}
{'loss': 0.0098, 'grad_norm': 5.185685634613037, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.005146740470081568, 'loss_2': 0.00469970703125, 'loss_3': -16.186450958251953, 'loss_4': 1.1445696353912354, 'epoch': 26.96}
{'loss': 0.0072, 'grad_norm': 4.412131309509277, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.0037102883215993643, 'loss_2': 0.003444671630859375, 'loss_3': -16.179515838623047, 'loss_4': 0.8463785648345947, 'epoch': 26.97}
{'loss': 0.0235, 'grad_norm': 10.32470417022705, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.0180105809122324, 'loss_2': 0.00545501708984375, 'loss_3': -16.250288009643555, 'loss_4': 0.9924301505088806, 'epoch': 26.97}
{'loss': 0.0093, 'grad_norm': 4.623103141784668, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.00303071946837008, 'loss_2': 0.00626373291015625, 'loss_3': -16.232120513916016, 'loss_4': 0.5203766226768494, 'epoch': 26.98}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:20:43,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:43,072 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:06<09:58,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 11:20:46,879 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640
[INFO|configuration_utils.py:420] 2025-01-21 11:20:46,881 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640/config.json                                                                             
{'eval_loss': 0.006847674027085304, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.02, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004284875467419624, 'eval_loss_2': 0.00256279855966568, 'eval_loss_3': -18.12482452392578, 'eval_loss_4': 0.8499071598052979, 'epoch': 26.98}
[INFO|modeling_utils.py:2988] 2025-01-21 11:20:47,382 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:20:47,384 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:20:47,384 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 11:20:48,354 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4635] due to args.save_total_limit
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:11<09:29,  1.11s/it][INFO|trainer.py:4226] 2025-01-21 11:20:51,659 >>
{'loss': 0.0087, 'grad_norm': 6.885685443878174, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.007469233125448227, 'loss_2': 0.0012760162353515625, 'loss_3': -16.38494300842285, 'loss_4': 0.7236000299453735, 'epoch': 26.98}
{'loss': 0.0138, 'grad_norm': 7.478418827056885, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.010711484588682652, 'loss_2': 0.003055572509765625, 'loss_3': -16.140270233154297, 'loss_4': 0.6810675859451294, 'epoch': 26.99}
{'loss': 0.0075, 'grad_norm': 5.258632183074951, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.00662972591817379, 'loss_2': 0.0009145736694335938, 'loss_3': -16.535253524780273, 'loss_4': 1.543805718421936, 'epoch': 26.99}
{'loss': 0.0121, 'grad_norm': 11.576909065246582, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.007012083660811186, 'loss_2': 0.00504302978515625, 'loss_3': -16.269826889038086, 'loss_4': 1.409847378730774, 'epoch': 27.0}
{'loss': 0.0099, 'grad_norm': 4.332712173461914, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.004738555755466223, 'loss_2': 0.005176544189453125, 'loss_3': -16.197071075439453, 'loss_4': 0.6367748975753784, 'epoch': 27.01}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:20:51,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:51,659 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:18<08:54,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:20:58,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0072491951286792755, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.457, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.00459404569119215, 'eval_loss_2': 0.0026551485061645508, 'eval_loss_3': -18.119579315185547, 'eval_loss_4': 0.8602072596549988, 'epoch': 27.01}
{'loss': 0.0053, 'grad_norm': 4.435770034790039, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.0026778881438076496, 'loss_2': 0.00266265869140625, 'loss_3': -16.240978240966797, 'loss_4': 0.7775049805641174, 'epoch': 27.01}
{'loss': 0.0113, 'grad_norm': 5.384047985076904, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.006156537681818008, 'loss_2': 0.005126953125, 'loss_3': -16.345653533935547, 'loss_4': 0.5996401309967041, 'epoch': 27.02}
{'loss': 0.0104, 'grad_norm': 4.642237663269043, 'learning_rate': 3e-06, 'loss_1': 0.004884439520537853, 'loss_2': 0.005527496337890625, 'loss_3': -16.283992767333984, 'loss_4': 1.0174767971038818, 'epoch': 27.02}
{'loss': 0.0143, 'grad_norm': 4.815672397613525, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.008831905201077461, 'loss_2': 0.0054931640625, 'loss_3': -16.31597900390625, 'loss_4': 0.6265968680381775, 'epoch': 27.03}
{'loss': 0.0066, 'grad_norm': 4.417242050170898, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.004452468361705542, 'loss_2': 0.002140045166015625, 'loss_3': -16.288127899169922, 'loss_4': 0.8642172813415527, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 11:20:58,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:58,986 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:26<08:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:06,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007165911607444286, 'eval_runtime': 3.7806, 'eval_samples_per_second': 270.854, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.004519391339272261, 'eval_loss_2': 0.002646520733833313, 'eval_loss_3': -18.118183135986328, 'eval_loss_4': 0.8641542196273804, 'epoch': 27.03}
{'loss': 0.0096, 'grad_norm': 4.483369827270508, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.004605772905051708, 'loss_2': 0.005035400390625, 'loss_3': -16.4056453704834, 'loss_4': 1.014540433883667, 'epoch': 27.04}
{'loss': 0.0042, 'grad_norm': 4.5143256187438965, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.002686925698071718, 'loss_2': 0.0014677047729492188, 'loss_3': -16.207748413085938, 'loss_4': 0.6373509168624878, 'epoch': 27.05}
{'loss': 0.0169, 'grad_norm': 8.877278327941895, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.016542961820960045, 'loss_2': 0.0003769397735595703, 'loss_3': -16.340133666992188, 'loss_4': 0.8785668611526489, 'epoch': 27.05}
{'loss': 0.0162, 'grad_norm': 4.679220199584961, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.0051863729022443295, 'loss_2': 0.011016845703125, 'loss_3': -16.253124237060547, 'loss_4': 0.5628657341003418, 'epoch': 27.06}
{'loss': 0.0097, 'grad_norm': 4.876077651977539, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.003876781091094017, 'loss_2': 0.0058135986328125, 'loss_3': -16.289657592773438, 'loss_4': 0.6794204711914062, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 11:21:06,314 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:06,314 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:33<08:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:13,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007242935243993998, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.604, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.004488307982683182, 'eval_loss_2': 0.0027546286582946777, 'eval_loss_3': -18.112621307373047, 'eval_loss_4': 0.8736333847045898, 'epoch': 27.06}
{'loss': 0.0068, 'grad_norm': 4.866631984710693, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.006221633870154619, 'loss_2': 0.0005617141723632812, 'loss_3': -16.271480560302734, 'loss_4': 0.9526423215866089, 'epoch': 27.07}
{'loss': 0.0037, 'grad_norm': 4.27841329574585, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.002840012079104781, 'loss_2': 0.000812530517578125, 'loss_3': -16.384506225585938, 'loss_4': 1.086139440536499, 'epoch': 27.08}
{'loss': 0.0034, 'grad_norm': 4.584784984588623, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.002619437174871564, 'loss_2': 0.0007953643798828125, 'loss_3': -16.402313232421875, 'loss_4': 0.8915185928344727, 'epoch': 27.08}
{'loss': 0.0046, 'grad_norm': 4.195728302001953, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.0036682356148958206, 'loss_2': 0.0009403228759765625, 'loss_3': -16.42202377319336, 'loss_4': 0.8754849433898926, 'epoch': 27.09}
{'loss': 0.0098, 'grad_norm': 4.9631171226501465, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.004258343484252691, 'loss_2': 0.00550079345703125, 'loss_3': -16.210224151611328, 'loss_4': 0.7972432374954224, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 11:21:13,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:13,634 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:54:40<08:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:21:20,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007428654469549656, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.431, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.004544415976852179, 'eval_loss_2': 0.0028842389583587646, 'eval_loss_3': -18.105728149414062, 'eval_loss_4': 0.8738153576850891, 'epoch': 27.09}
{'loss': 0.0091, 'grad_norm': 4.620051383972168, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.004151054657995701, 'loss_2': 0.00499725341796875, 'loss_3': -16.457962036132812, 'loss_4': 0.8788875341415405, 'epoch': 27.1}
{'loss': 0.0085, 'grad_norm': 4.752912998199463, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.0041147456504404545, 'loss_2': 0.004352569580078125, 'loss_3': -16.19403648376465, 'loss_4': 0.6628345251083374, 'epoch': 27.1}
{'loss': 0.0099, 'grad_norm': 6.02230167388916, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.009790456853806973, 'loss_2': 9.02414321899414e-05, 'loss_3': -16.450767517089844, 'loss_4': 1.0302499532699585, 'epoch': 27.11}
{'loss': 0.0082, 'grad_norm': 5.489312648773193, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.006427766289561987, 'loss_2': 0.0017375946044921875, 'loss_3': -16.276277542114258, 'loss_4': 1.0460081100463867, 'epoch': 27.12}
{'loss': 0.0111, 'grad_norm': 6.307461738586426, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.00656121177598834, 'loss_2': 0.004528045654296875, 'loss_3': -16.450714111328125, 'loss_4': 0.8084982633590698, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 11:21:20,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:20,954 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:54:48<08:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:28,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0072899251244962215, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.523, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.004573897458612919, 'eval_loss_2': 0.0027160272002220154, 'eval_loss_3': -18.10663414001465, 'eval_loss_4': 0.8616364598274231, 'epoch': 27.12}
{'loss': 0.0109, 'grad_norm': 5.349338531494141, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.006505028810352087, 'loss_2': 0.004375457763671875, 'loss_3': -16.265010833740234, 'loss_4': 0.5497725605964661, 'epoch': 27.13}
{'loss': 0.0064, 'grad_norm': 4.7852559089660645, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.00296108890324831, 'loss_2': 0.0034351348876953125, 'loss_3': -16.321155548095703, 'loss_4': 1.2257001399993896, 'epoch': 27.13}
{'loss': 0.0067, 'grad_norm': 5.157867908477783, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.0045562805607914925, 'loss_2': 0.0021343231201171875, 'loss_3': -16.365543365478516, 'loss_4': 0.7720918655395508, 'epoch': 27.14}
{'loss': 0.0055, 'grad_norm': 4.668938159942627, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.002779934322461486, 'loss_2': 0.00269317626953125, 'loss_3': -16.23771095275879, 'loss_4': 0.7546628713607788, 'epoch': 27.15}
{'loss': 0.0343, 'grad_norm': 14.023932456970215, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.031122993677854538, 'loss_2': 0.003185272216796875, 'loss_3': -16.187808990478516, 'loss_4': 0.9970022439956665, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 11:21:28,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:28,290 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:54:55<08:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:35,611 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007210972253233194, 'eval_runtime': 3.7817, 'eval_samples_per_second': 270.775, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.004416080191731453, 'eval_loss_2': 0.002794891595840454, 'eval_loss_3': -18.106658935546875, 'eval_loss_4': 0.8593618273735046, 'epoch': 27.15}
{'loss': 0.0098, 'grad_norm': 5.426477432250977, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.008133629336953163, 'loss_2': 0.00170135498046875, 'loss_3': -16.490936279296875, 'loss_4': 1.4394017457962036, 'epoch': 27.16}
{'loss': 0.0077, 'grad_norm': 4.82441520690918, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.005129206459969282, 'loss_2': 0.002574920654296875, 'loss_3': -16.407623291015625, 'loss_4': 0.7662003040313721, 'epoch': 27.16}
{'loss': 0.005, 'grad_norm': 5.093912601470947, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.0035322464536875486, 'loss_2': 0.0014696121215820312, 'loss_3': -16.273075103759766, 'loss_4': 0.7037511467933655, 'epoch': 27.17}
{'loss': 0.0055, 'grad_norm': 4.680332183837891, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.005187653470784426, 'loss_2': 0.0003371238708496094, 'loss_3': -16.225006103515625, 'loss_4': 0.7440195083618164, 'epoch': 27.17}
{'loss': 0.0066, 'grad_norm': 4.565319061279297, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.00286825536750257, 'loss_2': 0.0037403106689453125, 'loss_3': -16.222787857055664, 'loss_4': 0.781643271446228, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 11:21:35,611 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:35,611 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:02<08:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:42,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00746408523991704, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.515, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.004434820730239153, 'eval_loss_2': 0.003029264509677887, 'eval_loss_3': -18.112104415893555, 'eval_loss_4': 0.8459705114364624, 'epoch': 27.18}
{'loss': 0.0084, 'grad_norm': 4.845986843109131, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.0034364983439445496, 'loss_2': 0.004947662353515625, 'loss_3': -16.337158203125, 'loss_4': 1.1462512016296387, 'epoch': 27.19}
{'loss': 0.0083, 'grad_norm': 4.954296112060547, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.0027272594161331654, 'loss_2': 0.005573272705078125, 'loss_3': -16.303001403808594, 'loss_4': 0.7947202920913696, 'epoch': 27.19}
{'loss': 0.0068, 'grad_norm': 5.17620325088501, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.0036713092122226954, 'loss_2': 0.0030803680419921875, 'loss_3': -16.399524688720703, 'loss_4': 0.8278623223304749, 'epoch': 27.2}
{'loss': 0.0153, 'grad_norm': 5.667367935180664, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.008040870539844036, 'loss_2': 0.007293701171875, 'loss_3': -16.285236358642578, 'loss_4': 0.9484897255897522, 'epoch': 27.2}
{'loss': 0.0056, 'grad_norm': 4.782075881958008, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.0024261425714939833, 'loss_2': 0.003154754638671875, 'loss_3': -16.437698364257812, 'loss_4': 1.2470113039016724, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 11:21:42,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:42,940 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:10<08:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:50,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007668328937143087, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.565, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.004611318465322256, 'eval_loss_2': 0.0030570104718208313, 'eval_loss_3': -18.1187801361084, 'eval_loss_4': 0.8215957880020142, 'epoch': 27.21}
{'loss': 0.0077, 'grad_norm': 4.955780506134033, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.005233291070908308, 'loss_2': 0.0024871826171875, 'loss_3': -16.34423828125, 'loss_4': 1.0108717679977417, 'epoch': 27.22}
{'loss': 0.0067, 'grad_norm': 6.7601542472839355, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.006466624792665243, 'loss_2': 0.0002713203430175781, 'loss_3': -16.330896377563477, 'loss_4': 0.7510578632354736, 'epoch': 27.22}
{'loss': 0.0112, 'grad_norm': 4.717050552368164, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.006330385338515043, 'loss_2': 0.004863739013671875, 'loss_3': -16.24456024169922, 'loss_4': 1.1201391220092773, 'epoch': 27.23}
{'loss': 0.0045, 'grad_norm': 4.467212677001953, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.001747154165059328, 'loss_2': 0.0027141571044921875, 'loss_3': -16.370283126831055, 'loss_4': 0.5951637029647827, 'epoch': 27.23}
{'loss': 0.0065, 'grad_norm': 4.544155120849609, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.003885239129886031, 'loss_2': 0.002590179443359375, 'loss_3': -16.456371307373047, 'loss_4': 0.9446579217910767, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 11:21:50,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:50,271 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:17<08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:57,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008138453587889671, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.499, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0050091613084077835, 'eval_loss_2': 0.003129292279481888, 'eval_loss_3': -18.122034072875977, 'eval_loss_4': 0.8256595730781555, 'epoch': 27.24}
{'loss': 0.0096, 'grad_norm': 4.588615417480469, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.002656340366229415, 'loss_2': 0.00691986083984375, 'loss_3': -16.36121368408203, 'loss_4': 0.7513400316238403, 'epoch': 27.24}
{'loss': 0.0038, 'grad_norm': 4.548562049865723, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.003460827749222517, 'loss_2': 0.00032329559326171875, 'loss_3': -16.255504608154297, 'loss_4': 0.5750723481178284, 'epoch': 27.25}
{'loss': 0.0089, 'grad_norm': 6.481128692626953, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.00745463976636529, 'loss_2': 0.0014019012451171875, 'loss_3': -16.25293731689453, 'loss_4': 0.7332746982574463, 'epoch': 27.26}
{'loss': 0.0085, 'grad_norm': 6.346714973449707, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.007852999493479729, 'loss_2': 0.0006093978881835938, 'loss_3': -16.279624938964844, 'loss_4': 0.08777059614658356, 'epoch': 27.26}
{'loss': 0.0051, 'grad_norm': 4.526780605316162, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.0029591748025268316, 'loss_2': 0.002109527587890625, 'loss_3': -16.318702697753906, 'loss_4': 1.0247831344604492, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 11:21:57,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:57,604 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:24<08:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:22:04,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00833624042570591, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.6, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005067373160272837, 'eval_loss_2': 0.0032688677310943604, 'eval_loss_3': -18.125507354736328, 'eval_loss_4': 0.8443849682807922, 'epoch': 27.27}
{'loss': 0.0097, 'grad_norm': 5.963724613189697, 'learning_rate': 2.75e-06, 'loss_1': 0.008069680072367191, 'loss_2': 0.0015811920166015625, 'loss_3': -16.192777633666992, 'loss_4': 0.6897075772285461, 'epoch': 27.27}
{'loss': 0.018, 'grad_norm': 6.649782180786133, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.014460648410022259, 'loss_2': 0.0035858154296875, 'loss_3': -16.514537811279297, 'loss_4': 0.6318197250366211, 'epoch': 27.28}
{'loss': 0.0049, 'grad_norm': 4.779794216156006, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.0034606840927153826, 'loss_2': 0.001476287841796875, 'loss_3': -16.018604278564453, 'loss_4': 1.276792287826538, 'epoch': 27.28}
{'loss': 0.0103, 'grad_norm': 7.22897481918335, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.008897783234715462, 'loss_2': 0.0013875961303710938, 'loss_3': -16.304584503173828, 'loss_4': 1.2281367778778076, 'epoch': 27.29}
{'loss': 0.0137, 'grad_norm': 6.849399566650391, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.009579305537045002, 'loss_2': 0.00412750244140625, 'loss_3': -16.35787582397461, 'loss_4': 0.957578182220459, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 11:22:04,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:04,922 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:32<07:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:12,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008638926781713963, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.669, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.004954987205564976, 'eval_loss_2': 0.003683939576148987, 'eval_loss_3': -18.12746238708496, 'eval_loss_4': 0.890592098236084, 'epoch': 27.3}
{'loss': 0.006, 'grad_norm': 5.003817081451416, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.005721052642911673, 'loss_2': 0.0003147125244140625, 'loss_3': -16.291128158569336, 'loss_4': 1.4204585552215576, 'epoch': 27.3}
{'loss': 0.0116, 'grad_norm': 5.178887844085693, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.0065255057998001575, 'loss_2': 0.00502777099609375, 'loss_3': -16.383541107177734, 'loss_4': 1.1949021816253662, 'epoch': 27.31}
{'loss': 0.0071, 'grad_norm': 4.427557945251465, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.004149226937443018, 'loss_2': 0.002971649169921875, 'loss_3': -16.43115234375, 'loss_4': 0.9630386829376221, 'epoch': 27.31}
{'loss': 0.0247, 'grad_norm': 11.518898963928223, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.01260919775813818, 'loss_2': 0.01213836669921875, 'loss_3': -16.38324546813965, 'loss_4': 0.9013718366622925, 'epoch': 27.32}
{'loss': 0.0144, 'grad_norm': 4.677066802978516, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.0045213825069367886, 'loss_2': 0.0098724365234375, 'loss_3': -16.259950637817383, 'loss_4': 0.9137488603591919, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 11:22:12,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:12,248 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:55:39<07:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:19,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008706347085535526, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.004921892657876015, 'eval_loss_2': 0.003784455358982086, 'eval_loss_3': -18.13498878479004, 'eval_loss_4': 0.9344236254692078, 'epoch': 27.33}
{'loss': 0.0125, 'grad_norm': 5.587576389312744, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.0077295731753110886, 'loss_2': 0.00475311279296875, 'loss_3': -16.357418060302734, 'loss_4': 0.8354214429855347, 'epoch': 27.33}
{'loss': 0.0029, 'grad_norm': 4.449406623840332, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.002595319412648678, 'loss_2': 0.0002655982971191406, 'loss_3': -16.386634826660156, 'loss_4': 0.5554894208908081, 'epoch': 27.34}
{'loss': 0.0198, 'grad_norm': 11.389579772949219, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.013692916370928288, 'loss_2': 0.00615692138671875, 'loss_3': -16.265369415283203, 'loss_4': 0.822171688079834, 'epoch': 27.34}
{'loss': 0.0197, 'grad_norm': 5.365660190582275, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.006842308212071657, 'loss_2': 0.01280975341796875, 'loss_3': -16.29781723022461, 'loss_4': 1.0602703094482422, 'epoch': 27.35}
{'loss': 0.0143, 'grad_norm': 9.578078269958496, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.01303032971918583, 'loss_2': 0.0012969970703125, 'loss_3': -16.323928833007812, 'loss_4': 1.0513108968734741, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 11:22:19,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:19,584 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:55:46<07:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:26,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00866284966468811, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.539, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005141987930983305, 'eval_loss_2': 0.003520861268043518, 'eval_loss_3': -18.13669204711914, 'eval_loss_4': 0.9652698636054993, 'epoch': 27.35}
{'loss': 0.0143, 'grad_norm': 4.9879350662231445, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.004966911394149065, 'loss_2': 0.00934600830078125, 'loss_3': -16.2470703125, 'loss_4': 0.8584341406822205, 'epoch': 27.36}
{'loss': 0.0096, 'grad_norm': 5.405570983886719, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.006668965797871351, 'loss_2': 0.0028839111328125, 'loss_3': -16.52762222290039, 'loss_4': 1.0250914096832275, 'epoch': 27.37}
{'loss': 0.0042, 'grad_norm': 4.45432710647583, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.0030627972446382046, 'loss_2': 0.0011758804321289062, 'loss_3': -16.39751625061035, 'loss_4': 0.6353733539581299, 'epoch': 27.37}
{'loss': 0.0081, 'grad_norm': 4.110966205596924, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.005901649594306946, 'loss_2': 0.0021610260009765625, 'loss_3': -16.46308135986328, 'loss_4': 0.6521774530410767, 'epoch': 27.38}
{'loss': 0.0132, 'grad_norm': 4.570241928100586, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.0036237009335309267, 'loss_2': 0.00955963134765625, 'loss_3': -16.074077606201172, 'loss_4': 0.917320728302002, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 11:22:26,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:26,915 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:55:54<07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:34,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008101752027869225, 'eval_runtime': 3.7824, 'eval_samples_per_second': 270.73, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005294969771057367, 'eval_loss_2': 0.0028067827224731445, 'eval_loss_3': -18.131031036376953, 'eval_loss_4': 0.9858225584030151, 'epoch': 27.38}
{'loss': 0.0162, 'grad_norm': 5.612780570983887, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.0060415747575461864, 'loss_2': 0.01010894775390625, 'loss_3': -16.354976654052734, 'loss_4': 0.8558090329170227, 'epoch': 27.39}
{'loss': 0.0241, 'grad_norm': 12.656733512878418, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.02157919853925705, 'loss_2': 0.002559661865234375, 'loss_3': -16.30830955505371, 'loss_4': 1.2234642505645752, 'epoch': 27.4}
{'loss': 0.0201, 'grad_norm': 6.322586536407471, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.018819542601704597, 'loss_2': 0.0013265609741210938, 'loss_3': -16.304161071777344, 'loss_4': 1.1652750968933105, 'epoch': 27.4}
{'loss': 0.0068, 'grad_norm': 5.1624369621276855, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.0046295542269945145, 'loss_2': 0.002216339111328125, 'loss_3': -16.127012252807617, 'loss_4': 1.1640232801437378, 'epoch': 27.41}
{'loss': 0.0073, 'grad_norm': 5.032168865203857, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.00552480248734355, 'loss_2': 0.00179290771484375, 'loss_3': -16.000959396362305, 'loss_4': 0.5697224140167236, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 11:22:34,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:34,247 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:01<07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:41,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008195231668651104, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.625, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005618581548333168, 'eval_loss_2': 0.0025766491889953613, 'eval_loss_3': -18.1425838470459, 'eval_loss_4': 0.9953324794769287, 'epoch': 27.41}
{'loss': 0.0072, 'grad_norm': 4.082610607147217, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.003053670981898904, 'loss_2': 0.004123687744140625, 'loss_3': -16.24997329711914, 'loss_4': 1.3061223030090332, 'epoch': 27.42}
{'loss': 0.0207, 'grad_norm': 8.658541679382324, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.01731875166296959, 'loss_2': 0.0033721923828125, 'loss_3': -16.386838912963867, 'loss_4': 1.0367685556411743, 'epoch': 27.42}
{'loss': 0.0071, 'grad_norm': 4.78254508972168, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.004998653661459684, 'loss_2': 0.002132415771484375, 'loss_3': -16.300907135009766, 'loss_4': 1.0311321020126343, 'epoch': 27.43}
{'loss': 0.0134, 'grad_norm': 5.2143354415893555, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.008491728454828262, 'loss_2': 0.00485992431640625, 'loss_3': -16.257177352905273, 'loss_4': 0.9732114672660828, 'epoch': 27.44}
{'loss': 0.0064, 'grad_norm': 4.896892547607422, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.004060611594468355, 'loss_2': 0.0023097991943359375, 'loss_3': -16.192028045654297, 'loss_4': 1.3858866691589355, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 11:22:41,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:41,573 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:08<07:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:48,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008817488327622414, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.559, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.006001091096550226, 'eval_loss_2': 0.0028163976967334747, 'eval_loss_3': -18.137937545776367, 'eval_loss_4': 1.0056970119476318, 'epoch': 27.44}
{'loss': 0.0052, 'grad_norm': 4.481784820556641, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.003593259956687689, 'loss_2': 0.0016078948974609375, 'loss_3': -16.399188995361328, 'loss_4': 1.07364821434021, 'epoch': 27.45}
{'loss': 0.0106, 'grad_norm': 5.510191440582275, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.007822193205356598, 'loss_2': 0.00279998779296875, 'loss_3': -16.286638259887695, 'loss_4': 1.0220117568969727, 'epoch': 27.45}
{'loss': 0.0075, 'grad_norm': 4.976198196411133, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.0045059542171657085, 'loss_2': 0.0029659271240234375, 'loss_3': -16.21963882446289, 'loss_4': 0.9205776453018188, 'epoch': 27.46}
{'loss': 0.0099, 'grad_norm': 4.37687873840332, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.0038726944476366043, 'loss_2': 0.006011962890625, 'loss_3': -16.429248809814453, 'loss_4': 0.9632182121276855, 'epoch': 27.47}
{'loss': 0.0062, 'grad_norm': 4.604773998260498, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.0034492085687816143, 'loss_2': 0.00270843505859375, 'loss_3': -16.20982551574707, 'loss_4': 1.1560630798339844, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 11:22:48,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:48,902 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:16<07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:56,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009017862379550934, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.58, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.0061100199818611145, 'eval_loss_2': 0.0029078423976898193, 'eval_loss_3': -18.14396095275879, 'eval_loss_4': 1.019039273262024, 'epoch': 27.47}
{'loss': 0.0108, 'grad_norm': 5.3038716316223145, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.006849678233265877, 'loss_2': 0.00391387939453125, 'loss_3': -16.073732376098633, 'loss_4': 1.120632290840149, 'epoch': 27.48}
{'loss': 0.0103, 'grad_norm': 5.448288440704346, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.006353309378027916, 'loss_2': 0.00394439697265625, 'loss_3': -15.980717658996582, 'loss_4': 0.9962993860244751, 'epoch': 27.48}
{'loss': 0.0054, 'grad_norm': 4.6462507247924805, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.003667467273771763, 'loss_2': 0.0017595291137695312, 'loss_3': -16.114097595214844, 'loss_4': 1.3153505325317383, 'epoch': 27.49}
{'loss': 0.0158, 'grad_norm': 6.298520088195801, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.00830165110528469, 'loss_2': 0.00746917724609375, 'loss_3': -16.36502456665039, 'loss_4': 0.92920982837677, 'epoch': 27.49}
{'loss': 0.0025, 'grad_norm': 4.57871675491333, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.002012000884860754, 'loss_2': 0.0005245208740234375, 'loss_3': -16.225059509277344, 'loss_4': 1.2943036556243896, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 11:22:56,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:56,241 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:23<07:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:03,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009052110835909843, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.681, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005951220169663429, 'eval_loss_2': 0.003100890666246414, 'eval_loss_3': -18.146093368530273, 'eval_loss_4': 1.0482372045516968, 'epoch': 27.5}
{'loss': 0.0144, 'grad_norm': 5.6024675369262695, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.00806482508778572, 'loss_2': 0.0063629150390625, 'loss_3': -16.381420135498047, 'loss_4': 1.4116837978363037, 'epoch': 27.51}
{'loss': 0.0059, 'grad_norm': 4.318484783172607, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0024500424042344093, 'loss_2': 0.003467559814453125, 'loss_3': -16.324588775634766, 'loss_4': 0.9974913001060486, 'epoch': 27.51}
{'loss': 0.0074, 'grad_norm': 4.620299339294434, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.004944024607539177, 'loss_2': 0.0024929046630859375, 'loss_3': -16.385494232177734, 'loss_4': 1.7602708339691162, 'epoch': 27.52}
{'loss': 0.0084, 'grad_norm': 5.126256942749023, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.006782230455428362, 'loss_2': 0.001605987548828125, 'loss_3': -16.356006622314453, 'loss_4': 1.211613655090332, 'epoch': 27.52}
{'loss': 0.0185, 'grad_norm': 6.388968467712402, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.011459492146968842, 'loss_2': 0.00705718994140625, 'loss_3': -16.287952423095703, 'loss_4': 0.8255388736724854, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 11:23:03,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:03,573 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:30<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:10,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008862504735589027, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.67, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005815606098622084, 'eval_loss_2': 0.0030469000339508057, 'eval_loss_3': -18.152908325195312, 'eval_loss_4': 1.0627174377441406, 'epoch': 27.53}
{'loss': 0.007, 'grad_norm': 5.160386085510254, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.006566239520907402, 'loss_2': 0.0004658699035644531, 'loss_3': -16.128986358642578, 'loss_4': 1.2568403482437134, 'epoch': 27.53}
{'loss': 0.0095, 'grad_norm': 4.402593612670898, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.005046716891229153, 'loss_2': 0.00443267822265625, 'loss_3': -16.181289672851562, 'loss_4': 0.996285617351532, 'epoch': 27.54}
{'loss': 0.0072, 'grad_norm': 4.427345275878906, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.004429688211530447, 'loss_2': 0.002735137939453125, 'loss_3': -16.278606414794922, 'loss_4': 1.0150063037872314, 'epoch': 27.55}
{'loss': 0.0091, 'grad_norm': 4.8740105628967285, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.005746264010667801, 'loss_2': 0.003360748291015625, 'loss_3': -16.505245208740234, 'loss_4': 1.251298427581787, 'epoch': 27.55}
{'loss': 0.0085, 'grad_norm': 4.70277738571167, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.002415540860965848, 'loss_2': 0.0060882568359375, 'loss_3': -16.390911102294922, 'loss_4': 1.1574066877365112, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 11:23:10,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:10,913 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:38<07:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:18,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009001032449305058, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.532, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005880364682525396, 'eval_loss_2': 0.0031206682324409485, 'eval_loss_3': -18.154693603515625, 'eval_loss_4': 1.047864556312561, 'epoch': 27.56}
{'loss': 0.0057, 'grad_norm': 4.662440299987793, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.0034078576136380434, 'loss_2': 0.0022792816162109375, 'loss_3': -16.445995330810547, 'loss_4': 0.994609534740448, 'epoch': 27.56}
{'loss': 0.005, 'grad_norm': 4.678106307983398, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.0030925662722438574, 'loss_2': 0.0019283294677734375, 'loss_3': -16.251216888427734, 'loss_4': 0.6903812885284424, 'epoch': 27.57}
{'loss': 0.0066, 'grad_norm': 4.472626209259033, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.0049296473152935505, 'loss_2': 0.001644134521484375, 'loss_3': -16.452655792236328, 'loss_4': 1.2143551111221313, 'epoch': 27.58}
{'loss': 0.0139, 'grad_norm': 5.710874080657959, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.0092011708766222, 'loss_2': 0.004711151123046875, 'loss_3': -16.494274139404297, 'loss_4': 1.1550633907318115, 'epoch': 27.58}
{'loss': 0.0045, 'grad_norm': 4.8270111083984375, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.0025781504809856415, 'loss_2': 0.0018939971923828125, 'loss_3': -16.350305557250977, 'loss_4': 0.5786766409873962, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 11:23:18,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:18,253 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:56:45<07:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:25,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009091679006814957, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.698, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005965885240584612, 'eval_loss_2': 0.003125794231891632, 'eval_loss_3': -18.154037475585938, 'eval_loss_4': 1.0352332592010498, 'epoch': 27.59}
{'loss': 0.0057, 'grad_norm': 4.6192731857299805, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.0051979259587824345, 'loss_2': 0.0004940032958984375, 'loss_3': -16.169448852539062, 'loss_4': 0.8652574419975281, 'epoch': 27.59}
{'loss': 0.0071, 'grad_norm': 5.0382843017578125, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.003670057514682412, 'loss_2': 0.0034236907958984375, 'loss_3': -16.255165100097656, 'loss_4': 0.6989657878875732, 'epoch': 27.6}
{'loss': 0.0077, 'grad_norm': 4.735445499420166, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.0046678101643919945, 'loss_2': 0.003017425537109375, 'loss_3': -16.141071319580078, 'loss_4': 1.203319787979126, 'epoch': 27.6}
{'loss': 0.0077, 'grad_norm': 5.285405158996582, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.007102716248482466, 'loss_2': 0.0005974769592285156, 'loss_3': -16.146297454833984, 'loss_4': 1.0933769941329956, 'epoch': 27.61}
{'loss': 0.0057, 'grad_norm': 4.707447528839111, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.004132486414164305, 'loss_2': 0.0015287399291992188, 'loss_3': -16.138391494750977, 'loss_4': 1.1347712278366089, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 11:23:25,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:25,580 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:56:52<07:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:32,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00887024961411953, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.45, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00594726437702775, 'eval_loss_2': 0.002922985702753067, 'eval_loss_3': -18.152103424072266, 'eval_loss_4': 1.0367481708526611, 'epoch': 27.62}
{'loss': 0.0079, 'grad_norm': 5.262004375457764, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.007262849248945713, 'loss_2': 0.0006208419799804688, 'loss_3': -16.144128799438477, 'loss_4': 0.9106267690658569, 'epoch': 27.62}
{'loss': 0.0108, 'grad_norm': 5.169918060302734, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.005380750633776188, 'loss_2': 0.0054473876953125, 'loss_3': -16.280620574951172, 'loss_4': 0.9418882131576538, 'epoch': 27.63}
{'loss': 0.0074, 'grad_norm': 5.4188408851623535, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.0046532549895346165, 'loss_2': 0.0027008056640625, 'loss_3': -16.189559936523438, 'loss_4': 1.1118619441986084, 'epoch': 27.63}
{'loss': 0.011, 'grad_norm': 6.17343282699585, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.007682160008698702, 'loss_2': 0.003314971923828125, 'loss_3': -16.222349166870117, 'loss_4': 0.8546340465545654, 'epoch': 27.64}
{'loss': 0.0115, 'grad_norm': 5.523564338684082, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.004157421179115772, 'loss_2': 0.007293701171875, 'loss_3': -16.10260772705078, 'loss_4': 0.830573558807373, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 11:23:32,943 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:32,943 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:00<06:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:40,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008961087092757225, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.688, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.00580329354852438, 'eval_loss_2': 0.00315779447555542, 'eval_loss_3': -18.156177520751953, 'eval_loss_4': 1.048926591873169, 'epoch': 27.65}
{'loss': 0.0056, 'grad_norm': 5.413982391357422, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.0014143011067062616, 'loss_2': 0.00421905517578125, 'loss_3': -16.456127166748047, 'loss_4': 0.9124536514282227, 'epoch': 27.65}
{'loss': 0.011, 'grad_norm': 4.910908222198486, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.004723812453448772, 'loss_2': 0.0062408447265625, 'loss_3': -16.25137710571289, 'loss_4': 1.175930380821228, 'epoch': 27.66}
{'loss': 0.0136, 'grad_norm': 5.561975955963135, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.005440905690193176, 'loss_2': 0.00812530517578125, 'loss_3': -16.230552673339844, 'loss_4': 1.2601436376571655, 'epoch': 27.66}
{'loss': 0.0122, 'grad_norm': 4.633909702301025, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.003429555334150791, 'loss_2': 0.0087738037109375, 'loss_3': -16.37783432006836, 'loss_4': 1.1309819221496582, 'epoch': 27.67}
{'loss': 0.0087, 'grad_norm': 5.726478099822998, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.00575243541970849, 'loss_2': 0.002994537353515625, 'loss_3': -16.403255462646484, 'loss_4': 1.1433205604553223, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 11:23:40,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:40,277 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:07<06:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:47,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009046136401593685, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.654, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.0059861596673727036, 'eval_loss_2': 0.003059975802898407, 'eval_loss_3': -18.15591049194336, 'eval_loss_4': 1.0621447563171387, 'epoch': 27.67}
{'loss': 0.0124, 'grad_norm': 6.464990615844727, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.0064859893172979355, 'loss_2': 0.00595855712890625, 'loss_3': -16.353425979614258, 'loss_4': 1.4310942888259888, 'epoch': 27.68}
{'loss': 0.0055, 'grad_norm': 4.93148946762085, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.005188008304685354, 'loss_2': 0.0003490447998046875, 'loss_3': -16.32530975341797, 'loss_4': 1.7434511184692383, 'epoch': 27.69}
{'loss': 0.0161, 'grad_norm': 6.076225757598877, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.011996138840913773, 'loss_2': 0.004058837890625, 'loss_3': -16.287872314453125, 'loss_4': 0.749302327632904, 'epoch': 27.69}
{'loss': 0.0108, 'grad_norm': 4.759335994720459, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.008273850195109844, 'loss_2': 0.0024871826171875, 'loss_3': -16.21883201599121, 'loss_4': 1.1929905414581299, 'epoch': 27.7}
{'loss': 0.0057, 'grad_norm': 4.096009254455566, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.004316197242587805, 'loss_2': 0.0013647079467773438, 'loss_3': -16.443471908569336, 'loss_4': 0.9311989545822144, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 11:23:47,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:47,608 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:14<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:54,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00873484741896391, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.658, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005719194188714027, 'eval_loss_2': 0.003015652298927307, 'eval_loss_3': -18.15627098083496, 'eval_loss_4': 1.0580179691314697, 'epoch': 27.7}
{'loss': 0.0093, 'grad_norm': 4.851383209228516, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.0026230167131870985, 'loss_2': 0.00672149658203125, 'loss_3': -16.392135620117188, 'loss_4': 1.0212631225585938, 'epoch': 27.71}
{'loss': 0.0046, 'grad_norm': 4.45234489440918, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.0020191327203065157, 'loss_2': 0.00254058837890625, 'loss_3': -16.2093563079834, 'loss_4': 0.9030107259750366, 'epoch': 27.72}
{'loss': 0.0035, 'grad_norm': 4.35451078414917, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.0021093469113111496, 'loss_2': 0.0014238357543945312, 'loss_3': -16.530244827270508, 'loss_4': 1.3681402206420898, 'epoch': 27.72}
{'loss': 0.0028, 'grad_norm': 4.510265827178955, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0026096205692738295, 'loss_2': 0.0001423358917236328, 'loss_3': -16.33159637451172, 'loss_4': 0.9152145385742188, 'epoch': 27.73}
{'loss': 0.0087, 'grad_norm': 5.227677822113037, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.005238333251327276, 'loss_2': 0.003444671630859375, 'loss_3': -16.181241989135742, 'loss_4': 0.699403703212738, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 11:23:54,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:54,941 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:22<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:02,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008291352540254593, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.666, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005483766086399555, 'eval_loss_2': 0.0028075873851776123, 'eval_loss_3': -18.159687042236328, 'eval_loss_4': 1.0664703845977783, 'epoch': 27.73}
{'loss': 0.0067, 'grad_norm': 5.056188583374023, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.0059457761235535145, 'loss_2': 0.00070953369140625, 'loss_3': -16.346477508544922, 'loss_4': 1.4988441467285156, 'epoch': 27.74}
{'loss': 0.0077, 'grad_norm': 4.462944030761719, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.00254508457146585, 'loss_2': 0.00519561767578125, 'loss_3': -16.38850212097168, 'loss_4': 1.6470394134521484, 'epoch': 27.74}
{'loss': 0.0111, 'grad_norm': 6.4534502029418945, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.008879832923412323, 'loss_2': 0.0022296905517578125, 'loss_3': -16.230300903320312, 'loss_4': 1.2158236503601074, 'epoch': 27.75}
{'loss': 0.0076, 'grad_norm': 4.728829383850098, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.007195543963462114, 'loss_2': 0.000431060791015625, 'loss_3': -16.284610748291016, 'loss_4': 1.2733298540115356, 'epoch': 27.76}
{'loss': 0.0073, 'grad_norm': 4.996659278869629, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.004753431770950556, 'loss_2': 0.0025787353515625, 'loss_3': -16.32763671875, 'loss_4': 1.7153465747833252, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 11:24:02,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:02,271 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:29<06:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:09,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008524606004357338, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.77, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005697882268577814, 'eval_loss_2': 0.002826724201440811, 'eval_loss_3': -18.1538143157959, 'eval_loss_4': 1.0643413066864014, 'epoch': 27.76}
{'loss': 0.0075, 'grad_norm': 4.746882915496826, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.0041253697127103806, 'loss_2': 0.0033512115478515625, 'loss_3': -16.443435668945312, 'loss_4': 0.8890542984008789, 'epoch': 27.77}
{'loss': 0.0047, 'grad_norm': 4.9054365158081055, 'learning_rate': 2.25e-06, 'loss_1': 0.0034595627803355455, 'loss_2': 0.0012569427490234375, 'loss_3': -16.270980834960938, 'loss_4': 0.8892228007316589, 'epoch': 27.77}
{'loss': 0.007, 'grad_norm': 4.979270935058594, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.0036019000690430403, 'loss_2': 0.00341033935546875, 'loss_3': -16.439271926879883, 'loss_4': 0.925380527973175, 'epoch': 27.78}
{'loss': 0.0085, 'grad_norm': 5.326672077178955, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.007981874980032444, 'loss_2': 0.0005426406860351562, 'loss_3': -16.4251708984375, 'loss_4': 1.741112232208252, 'epoch': 27.78}
{'loss': 0.0053, 'grad_norm': 4.325389862060547, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.0028869558591395617, 'loss_2': 0.00238800048828125, 'loss_3': -16.251689910888672, 'loss_4': 1.0986891984939575, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 11:24:09,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:09,626 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:36<06:28,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:24:16,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008679525926709175, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.664, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005825208034366369, 'eval_loss_2': 0.0028543174266815186, 'eval_loss_3': -18.16086196899414, 'eval_loss_4': 1.0569649934768677, 'epoch': 27.79}
{'loss': 0.0067, 'grad_norm': 4.893852710723877, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.0022503789514303207, 'loss_2': 0.004482269287109375, 'loss_3': -16.47861099243164, 'loss_4': 1.3072865009307861, 'epoch': 27.8}
{'loss': 0.0059, 'grad_norm': 4.586535453796387, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.0037144485395401716, 'loss_2': 0.002231597900390625, 'loss_3': -16.25952911376953, 'loss_4': 1.059638500213623, 'epoch': 27.8}
{'loss': 0.0093, 'grad_norm': 5.032497406005859, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.007726835552603006, 'loss_2': 0.0015878677368164062, 'loss_3': -16.375560760498047, 'loss_4': 1.2199045419692993, 'epoch': 27.81}
{'loss': 0.0042, 'grad_norm': 4.599795341491699, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.0038826570380479097, 'loss_2': 0.00029015541076660156, 'loss_3': -16.473054885864258, 'loss_4': 1.134551763534546, 'epoch': 27.81}
{'loss': 0.0077, 'grad_norm': 4.832056999206543, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.004152386449277401, 'loss_2': 0.003551483154296875, 'loss_3': -16.33537483215332, 'loss_4': 1.1199042797088623, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 11:24:16,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:16,941 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:57:44<06:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:24:24,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008489727042615414, 'eval_runtime': 3.7816, 'eval_samples_per_second': 270.784, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.0057121203280985355, 'eval_loss_2': 0.002777606248855591, 'eval_loss_3': -18.166744232177734, 'eval_loss_4': 1.055903434753418, 'epoch': 27.82}
{'loss': 0.0064, 'grad_norm': 5.586559772491455, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.004549944307655096, 'loss_2': 0.0018062591552734375, 'loss_3': -16.507068634033203, 'loss_4': 1.1859525442123413, 'epoch': 27.83}
{'loss': 0.0175, 'grad_norm': 8.243064880371094, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.011934175156056881, 'loss_2': 0.00551605224609375, 'loss_3': -16.152551651000977, 'loss_4': 1.0458048582077026, 'epoch': 27.83}
{'loss': 0.011, 'grad_norm': 5.452862739562988, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.00600267993286252, 'loss_2': 0.00498199462890625, 'loss_3': -16.396507263183594, 'loss_4': 1.1799070835113525, 'epoch': 27.84}
{'loss': 0.0161, 'grad_norm': 8.201117515563965, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.01258841436356306, 'loss_2': 0.003559112548828125, 'loss_3': -16.489704132080078, 'loss_4': 1.0565944910049438, 'epoch': 27.84}
{'loss': 0.011, 'grad_norm': 7.6231465339660645, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.010348508134484291, 'loss_2': 0.0006265640258789062, 'loss_3': -16.391172409057617, 'loss_4': 1.5745253562927246, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 11:24:24,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:24,262 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:57:51<06:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:24:31,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00828688032925129, 'eval_runtime': 3.7808, 'eval_samples_per_second': 270.841, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.005658821202814579, 'eval_loss_2': 0.0026280581951141357, 'eval_loss_3': -18.167652130126953, 'eval_loss_4': 1.0629973411560059, 'epoch': 27.85}
{'loss': 0.0051, 'grad_norm': 4.788469314575195, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.004617867060005665, 'loss_2': 0.0005197525024414062, 'loss_3': -16.28830909729004, 'loss_4': 1.2393134832382202, 'epoch': 27.85}
{'loss': 0.0087, 'grad_norm': 5.884127616882324, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.007568312343209982, 'loss_2': 0.00113677978515625, 'loss_3': -16.373292922973633, 'loss_4': 0.9752538800239563, 'epoch': 27.86}
{'loss': 0.0101, 'grad_norm': 6.052292346954346, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.006145217921584845, 'loss_2': 0.003948211669921875, 'loss_3': -16.24624252319336, 'loss_4': 1.407416820526123, 'epoch': 27.87}
{'loss': 0.0127, 'grad_norm': 5.512178897857666, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.006854413542896509, 'loss_2': 0.00580596923828125, 'loss_3': -16.121562957763672, 'loss_4': 0.9335753321647644, 'epoch': 27.87}
{'loss': 0.0066, 'grad_norm': 4.704087734222412, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.003696301719173789, 'loss_2': 0.0029144287109375, 'loss_3': -16.30469512939453, 'loss_4': 1.1742455959320068, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 11:24:31,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:31,580 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:57:58<06:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:38,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008090466260910034, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.586, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005535930395126343, 'eval_loss_2': 0.0025545358657836914, 'eval_loss_3': -18.168088912963867, 'eval_loss_4': 1.071320652961731, 'epoch': 27.88}
{'loss': 0.0059, 'grad_norm': 4.772999286651611, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.0025616821367293596, 'loss_2': 0.00333404541015625, 'loss_3': -16.375728607177734, 'loss_4': 1.1742061376571655, 'epoch': 27.88}
{'loss': 0.0126, 'grad_norm': 4.8302154541015625, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.0064053828828036785, 'loss_2': 0.00617218017578125, 'loss_3': -16.282169342041016, 'loss_4': 1.4433064460754395, 'epoch': 27.89}
{'loss': 0.0098, 'grad_norm': 4.310948848724365, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.002203362062573433, 'loss_2': 0.007602691650390625, 'loss_3': -16.467281341552734, 'loss_4': 1.5729538202285767, 'epoch': 27.9}
{'loss': 0.0044, 'grad_norm': 4.908987998962402, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.0036463881842792034, 'loss_2': 0.0007390975952148438, 'loss_3': -16.337574005126953, 'loss_4': 1.1169769763946533, 'epoch': 27.9}
{'loss': 0.0115, 'grad_norm': 5.493193626403809, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.004949084483087063, 'loss_2': 0.00652313232421875, 'loss_3': -16.48741912841797, 'loss_4': 0.5462327003479004, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 11:24:38,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:38,901 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:06<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:46,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008279277943074703, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.418, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005822611972689629, 'eval_loss_2': 0.0024566650390625, 'eval_loss_3': -18.165918350219727, 'eval_loss_4': 1.0780352354049683, 'epoch': 27.91}
{'loss': 0.0052, 'grad_norm': 4.4383625984191895, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.0035229497589170933, 'loss_2': 0.0016326904296875, 'loss_3': -16.325502395629883, 'loss_4': 0.8503620624542236, 'epoch': 27.91}
{'loss': 0.0095, 'grad_norm': 4.967071533203125, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.004091809969395399, 'loss_2': 0.00542449951171875, 'loss_3': -16.2043399810791, 'loss_4': 1.4585399627685547, 'epoch': 27.92}
{'loss': 0.0098, 'grad_norm': 4.871105194091797, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.0036789653822779655, 'loss_2': 0.006099700927734375, 'loss_3': -16.40366554260254, 'loss_4': 1.075148105621338, 'epoch': 27.92}
{'loss': 0.0109, 'grad_norm': 4.607428073883057, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.009639257565140724, 'loss_2': 0.0012664794921875, 'loss_3': -16.214920043945312, 'loss_4': 1.3025224208831787, 'epoch': 27.93}
{'loss': 0.007, 'grad_norm': 4.5282816886901855, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.0033091427758336067, 'loss_2': 0.003696441650390625, 'loss_3': -16.4374942779541, 'loss_4': 0.894802451133728, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 11:24:46,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:46,236 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:13<06:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:53,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008578211069107056, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0061275954358279705, 'eval_loss_2': 0.002450615167617798, 'eval_loss_3': -18.164039611816406, 'eval_loss_4': 1.0843329429626465, 'epoch': 27.94}
{'loss': 0.0024, 'grad_norm': 4.7342529296875, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.002225383184850216, 'loss_2': 0.00017690658569335938, 'loss_3': -16.332324981689453, 'loss_4': 0.8535282015800476, 'epoch': 27.94}
{'loss': 0.0083, 'grad_norm': 4.568347454071045, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.005489147733896971, 'loss_2': 0.00276947021484375, 'loss_3': -16.26388168334961, 'loss_4': 1.064579963684082, 'epoch': 27.95}
{'loss': 0.0134, 'grad_norm': 4.8686981201171875, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.002887740731239319, 'loss_2': 0.0104827880859375, 'loss_3': -16.318191528320312, 'loss_4': 1.3639377355575562, 'epoch': 27.95}
{'loss': 0.004, 'grad_norm': 4.1603779792785645, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.002073457930237055, 'loss_2': 0.00194549560546875, 'loss_3': -16.513641357421875, 'loss_4': 1.031395435333252, 'epoch': 27.96}
{'loss': 0.0158, 'grad_norm': 9.229452133178711, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.01475021243095398, 'loss_2': 0.0010528564453125, 'loss_3': -16.31371307373047, 'loss_4': 1.188773512840271, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 11:24:53,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:53,567 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:20<05:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:00,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008655409328639507, 'eval_runtime': 3.7825, 'eval_samples_per_second': 270.722, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.006229395978152752, 'eval_loss_2': 0.0024260133504867554, 'eval_loss_3': -18.155380249023438, 'eval_loss_4': 1.1009048223495483, 'epoch': 27.97}
{'loss': 0.0097, 'grad_norm': 4.4941020011901855, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.006281484849750996, 'loss_2': 0.003376007080078125, 'loss_3': -16.26393699645996, 'loss_4': 1.0981817245483398, 'epoch': 27.97}
{'loss': 0.0043, 'grad_norm': 4.843765735626221, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.0029384964145720005, 'loss_2': 0.0013599395751953125, 'loss_3': -16.47794532775879, 'loss_4': 1.1451475620269775, 'epoch': 27.98}
{'loss': 0.0114, 'grad_norm': 4.453062057495117, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.00512990728020668, 'loss_2': 0.006256103515625, 'loss_3': -16.072246551513672, 'loss_4': 1.0979923009872437, 'epoch': 27.98}
{'loss': 0.0081, 'grad_norm': 4.5975117683410645, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.004892369266599417, 'loss_2': 0.003253936767578125, 'loss_3': -16.201282501220703, 'loss_4': 1.2224652767181396, 'epoch': 27.99}
{'loss': 0.0075, 'grad_norm': 5.2601189613342285, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.004948712885379791, 'loss_2': 0.002590179443359375, 'loss_3': -16.49114227294922, 'loss_4': 1.2101380825042725, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 11:25:00,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:00,871 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:27<05:44,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 11:25:07,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008575152605772018, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.441, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.006197917275130749, 'eval_loss_2': 0.002377234399318695, 'eval_loss_3': -18.1496524810791, 'eval_loss_4': 1.102164387702942, 'epoch': 27.99}
{'loss': 0.0056, 'grad_norm': 5.691636085510254, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0019902463536709547, 'loss_2': 0.00359344482421875, 'loss_3': -16.45136833190918, 'loss_4': 1.7583404779434204, 'epoch': 28.0}
{'loss': 0.0197, 'grad_norm': 7.680589199066162, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.014705806970596313, 'loss_2': 0.00495147705078125, 'loss_3': -16.215524673461914, 'loss_4': 1.1893199682235718, 'epoch': 28.01}
{'loss': 0.0039, 'grad_norm': 4.386831760406494, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.002453738125041127, 'loss_2': 0.0014219284057617188, 'loss_3': -16.276456832885742, 'loss_4': 1.6264698505401611, 'epoch': 28.01}
{'loss': 0.0172, 'grad_norm': 7.164370059967041, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.007486189715564251, 'loss_2': 0.0096893310546875, 'loss_3': -16.263704299926758, 'loss_4': 1.6312034130096436, 'epoch': 28.02}
{'loss': 0.0056, 'grad_norm': 4.77178430557251, 'learning_rate': 2e-06, 'loss_1': 0.005508665926754475, 'loss_2': 8.285045623779297e-05, 'loss_3': -16.29476547241211, 'loss_4': 1.298478126525879, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 11:25:07,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:07,901 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:35<05:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:15,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008393512107431889, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.427, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006056108511984348, 'eval_loss_2': 0.0023374035954475403, 'eval_loss_3': -18.146909713745117, 'eval_loss_4': 1.102731466293335, 'epoch': 28.02}
{'loss': 0.0108, 'grad_norm': 6.399310111999512, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.006423060316592455, 'loss_2': 0.004352569580078125, 'loss_3': -16.21600914001465, 'loss_4': 1.9431114196777344, 'epoch': 28.03}
{'loss': 0.0071, 'grad_norm': 4.632204532623291, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.0025951883289963007, 'loss_2': 0.00455474853515625, 'loss_3': -16.36562728881836, 'loss_4': 1.0379607677459717, 'epoch': 28.03}
{'loss': 0.0034, 'grad_norm': 4.827417850494385, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.002124829450622201, 'loss_2': 0.0012941360473632812, 'loss_3': -16.410236358642578, 'loss_4': 1.1735377311706543, 'epoch': 28.04}
{'loss': 0.0032, 'grad_norm': 4.847171306610107, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.0029149632900953293, 'loss_2': 0.00033020973205566406, 'loss_3': -16.368587493896484, 'loss_4': 1.3107762336730957, 'epoch': 28.05}
{'loss': 0.0167, 'grad_norm': 5.99883508682251, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.015159607864916325, 'loss_2': 0.0015687942504882812, 'loss_3': -16.26581382751465, 'loss_4': 1.7114654779434204, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 11:25:15,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:15,229 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:58:42<05:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:22,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008268493227660656, 'eval_runtime': 3.7812, 'eval_samples_per_second': 270.813, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.00595362763851881, 'eval_loss_2': 0.0023148655891418457, 'eval_loss_3': -18.1448974609375, 'eval_loss_4': 1.0930906534194946, 'epoch': 28.05}
{'loss': 0.0049, 'grad_norm': 4.698619365692139, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.003871360793709755, 'loss_2': 0.0009918212890625, 'loss_3': -16.470956802368164, 'loss_4': 0.8303296566009521, 'epoch': 28.06}
{'loss': 0.0077, 'grad_norm': 4.396040916442871, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.004126504994928837, 'loss_2': 0.003566741943359375, 'loss_3': -16.259292602539062, 'loss_4': 1.0663821697235107, 'epoch': 28.06}
{'loss': 0.0047, 'grad_norm': 4.698169708251953, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.0028838503640145063, 'loss_2': 0.001861572265625, 'loss_3': -16.156312942504883, 'loss_4': 0.9877188801765442, 'epoch': 28.07}
{'loss': 0.0143, 'grad_norm': 7.56312894821167, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.009547599591314793, 'loss_2': 0.00478363037109375, 'loss_3': -16.24428939819336, 'loss_4': 1.256217122077942, 'epoch': 28.08}
{'loss': 0.0072, 'grad_norm': 4.826257228851318, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0037443393375724554, 'loss_2': 0.0034637451171875, 'loss_3': -16.350868225097656, 'loss_4': 0.9896532297134399, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 11:25:22,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:22,550 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:58:49<05:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:29,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008225521072745323, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.64, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005843822378665209, 'eval_loss_2': 0.0023816972970962524, 'eval_loss_3': -18.14787483215332, 'eval_loss_4': 1.0817986726760864, 'epoch': 28.08}
{'loss': 0.0069, 'grad_norm': 4.639195919036865, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.002318969927728176, 'loss_2': 0.00453948974609375, 'loss_3': -16.411548614501953, 'loss_4': 1.3148162364959717, 'epoch': 28.09}
{'loss': 0.0053, 'grad_norm': 4.642423629760742, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.002810433506965637, 'loss_2': 0.002529144287109375, 'loss_3': -16.327789306640625, 'loss_4': 1.5671112537384033, 'epoch': 28.09}
{'loss': 0.0101, 'grad_norm': 4.557208061218262, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0037814280949532986, 'loss_2': 0.0063018798828125, 'loss_3': -16.30944061279297, 'loss_4': 0.9361429810523987, 'epoch': 28.1}
{'loss': 0.0054, 'grad_norm': 4.385897636413574, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.003154064528644085, 'loss_2': 0.0022754669189453125, 'loss_3': -16.514392852783203, 'loss_4': 0.7903794050216675, 'epoch': 28.1}
{'loss': 0.0054, 'grad_norm': 4.663025379180908, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.003422800451517105, 'loss_2': 0.001979827880859375, 'loss_3': -16.24654197692871, 'loss_4': 1.1643389463424683, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 11:25:29,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:29,879 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:58:57<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:37,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008144713938236237, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005822122562676668, 'eval_loss_2': 0.0023225918412208557, 'eval_loss_3': -18.147415161132812, 'eval_loss_4': 1.0775549411773682, 'epoch': 28.11}
{'loss': 0.0112, 'grad_norm': 8.336627006530762, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.009303787723183632, 'loss_2': 0.001857757568359375, 'loss_3': -16.132558822631836, 'loss_4': 0.7717528939247131, 'epoch': 28.12}
{'loss': 0.0117, 'grad_norm': 4.863263130187988, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.006038471590727568, 'loss_2': 0.00563812255859375, 'loss_3': -16.2286319732666, 'loss_4': 1.075552225112915, 'epoch': 28.12}
{'loss': 0.0052, 'grad_norm': 5.0247673988342285, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0047308821231126785, 'loss_2': 0.00047969818115234375, 'loss_3': -16.38776969909668, 'loss_4': 1.1906075477600098, 'epoch': 28.13}
{'loss': 0.0239, 'grad_norm': 5.961338996887207, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.019553910940885544, 'loss_2': 0.00431060791015625, 'loss_3': -16.496074676513672, 'loss_4': 0.6561605930328369, 'epoch': 28.13}
{'loss': 0.0051, 'grad_norm': 4.4434356689453125, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.0034625243861228228, 'loss_2': 0.0016183853149414062, 'loss_3': -16.33816146850586, 'loss_4': 1.2677090167999268, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 11:25:37,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:37,230 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:04<05:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:44,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00795370526611805, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.506, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005646127741783857, 'eval_loss_2': 0.002307578921318054, 'eval_loss_3': -18.14772605895996, 'eval_loss_4': 1.0783662796020508, 'epoch': 28.14}
{'loss': 0.0091, 'grad_norm': 4.503602981567383, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.0028485737275332212, 'loss_2': 0.0062255859375, 'loss_3': -16.333364486694336, 'loss_4': 1.2501842975616455, 'epoch': 28.15}
{'loss': 0.0056, 'grad_norm': 4.646805763244629, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.004588279873132706, 'loss_2': 0.0010223388671875, 'loss_3': -16.286972045898438, 'loss_4': 0.9929958581924438, 'epoch': 28.15}
{'loss': 0.0074, 'grad_norm': 4.773570537567139, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.0027445354498922825, 'loss_2': 0.004669189453125, 'loss_3': -16.34295082092285, 'loss_4': 1.3405299186706543, 'epoch': 28.16}
{'loss': 0.0225, 'grad_norm': 11.074899673461914, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.02164939045906067, 'loss_2': 0.000888824462890625, 'loss_3': -16.48841667175293, 'loss_4': 1.9409496784210205, 'epoch': 28.16}
{'loss': 0.0098, 'grad_norm': 4.55441951751709, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.0028863507322967052, 'loss_2': 0.006885528564453125, 'loss_3': -16.341690063476562, 'loss_4': 1.0067566633224487, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 11:25:44,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:44,548 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:11<05:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:51,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007538017351180315, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.7, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005387309938669205, 'eval_loss_2': 0.002150706946849823, 'eval_loss_3': -18.149145126342773, 'eval_loss_4': 1.063496470451355, 'epoch': 28.17}
{'loss': 0.0071, 'grad_norm': 4.491292476654053, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.003618457354605198, 'loss_2': 0.00347900390625, 'loss_3': -16.3262939453125, 'loss_4': 1.3426125049591064, 'epoch': 28.17}
{'loss': 0.0068, 'grad_norm': 5.147954940795898, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.004972930531948805, 'loss_2': 0.001861572265625, 'loss_3': -16.3931884765625, 'loss_4': 1.0950324535369873, 'epoch': 28.18}
{'loss': 0.0179, 'grad_norm': 6.858709335327148, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.012614225037395954, 'loss_2': 0.005279541015625, 'loss_3': -16.298351287841797, 'loss_4': 0.9721401929855347, 'epoch': 28.19}
{'loss': 0.0077, 'grad_norm': 4.428440570831299, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.0037302291020751, 'loss_2': 0.00396728515625, 'loss_3': -16.367692947387695, 'loss_4': 1.0949503183364868, 'epoch': 28.19}
{'loss': 0.0076, 'grad_norm': 4.98396110534668, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.00315403682179749, 'loss_2': 0.004467010498046875, 'loss_3': -16.18195343017578, 'loss_4': 1.1846373081207275, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 11:25:51,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:51,865 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:18<05:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:25:59,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007719960995018482, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.624, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00550727266818285, 'eval_loss_2': 0.0022126883268356323, 'eval_loss_3': -18.150604248046875, 'eval_loss_4': 1.0523755550384521, 'epoch': 28.2}
{'loss': 0.0072, 'grad_norm': 4.591220855712891, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.004091741982847452, 'loss_2': 0.0031414031982421875, 'loss_3': -16.02994728088379, 'loss_4': 0.6183485984802246, 'epoch': 28.2}
{'loss': 0.004, 'grad_norm': 4.528613567352295, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.0027193324640393257, 'loss_2': 0.001312255859375, 'loss_3': -16.288103103637695, 'loss_4': 1.0782824754714966, 'epoch': 28.21}
{'loss': 0.0086, 'grad_norm': 5.368925094604492, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.006448633037507534, 'loss_2': 0.002201080322265625, 'loss_3': -16.24477767944336, 'loss_4': 1.6147334575653076, 'epoch': 28.22}
{'loss': 0.0056, 'grad_norm': 5.8766913414001465, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.0046194191090762615, 'loss_2': 0.0009918212890625, 'loss_3': -16.275711059570312, 'loss_4': 1.2541706562042236, 'epoch': 28.22}
{'loss': 0.0107, 'grad_norm': 6.88508415222168, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.00725692929700017, 'loss_2': 0.0034732818603515625, 'loss_3': -16.33928680419922, 'loss_4': 0.5532817244529724, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 11:25:59,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:59,185 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:26<05:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:06,514 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008032836019992828, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.45, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005615629255771637, 'eval_loss_2': 0.0024172067642211914, 'eval_loss_3': -18.15358543395996, 'eval_loss_4': 1.030387282371521, 'epoch': 28.23}
{'loss': 0.0101, 'grad_norm': 4.398271560668945, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.00279430253431201, 'loss_2': 0.0073394775390625, 'loss_3': -16.444643020629883, 'loss_4': 1.1392619609832764, 'epoch': 28.23}
{'loss': 0.0082, 'grad_norm': 4.790983200073242, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.0033987259957939386, 'loss_2': 0.00482177734375, 'loss_3': -16.425016403198242, 'loss_4': 0.4819447994232178, 'epoch': 28.24}
{'loss': 0.0106, 'grad_norm': 5.32600212097168, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.007909699343144894, 'loss_2': 0.0027027130126953125, 'loss_3': -16.2553768157959, 'loss_4': 0.6814650297164917, 'epoch': 28.24}
{'loss': 0.0062, 'grad_norm': 4.758837699890137, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.0058187092654407024, 'loss_2': 0.0003705024719238281, 'loss_3': -16.502349853515625, 'loss_4': 0.9876939058303833, 'epoch': 28.25}
{'loss': 0.0078, 'grad_norm': 4.729438304901123, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.003259297227486968, 'loss_2': 0.00450897216796875, 'loss_3': -16.358558654785156, 'loss_4': 0.9419338703155518, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 11:26:06,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:06,514 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:33<05:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:13,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007762238383293152, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.524, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005505185574293137, 'eval_loss_2': 0.0022570528090000153, 'eval_loss_3': -18.153900146484375, 'eval_loss_4': 1.0036251544952393, 'epoch': 28.26}
{'loss': 0.0057, 'grad_norm': 5.248957633972168, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.0051175979897379875, 'loss_2': 0.0005617141723632812, 'loss_3': -16.44170570373535, 'loss_4': 1.4729527235031128, 'epoch': 28.26}
{'loss': 0.01, 'grad_norm': 4.031038761138916, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.0017439075745642185, 'loss_2': 0.0082550048828125, 'loss_3': -16.2933292388916, 'loss_4': 0.898301362991333, 'epoch': 28.27}
{'loss': 0.0077, 'grad_norm': 5.165417194366455, 'learning_rate': 1.75e-06, 'loss_1': 0.00560018653050065, 'loss_2': 0.002117156982421875, 'loss_3': -16.32373809814453, 'loss_4': 0.9102374315261841, 'epoch': 28.27}
{'loss': 0.0129, 'grad_norm': 7.537795066833496, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.005593715701252222, 'loss_2': 0.0072784423828125, 'loss_3': -16.23670196533203, 'loss_4': 0.9605335593223572, 'epoch': 28.28}
{'loss': 0.0058, 'grad_norm': 5.085440635681152, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.003891965840011835, 'loss_2': 0.0019378662109375, 'loss_3': -16.283658981323242, 'loss_4': 1.0092806816101074, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 11:26:13,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:13,853 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [1:59:40<05:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:26:21,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0077415406703948975, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.596, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.005580381024628878, 'eval_loss_2': 0.002161160111427307, 'eval_loss_3': -18.15627098083496, 'eval_loss_4': 0.9825372099876404, 'epoch': 28.28}
{'loss': 0.0381, 'grad_norm': 13.506113052368164, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.03395666182041168, 'loss_2': 0.00412750244140625, 'loss_3': -16.288230895996094, 'loss_4': 1.5758520364761353, 'epoch': 28.29}
{'loss': 0.0099, 'grad_norm': 6.130297660827637, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.008529044687747955, 'loss_2': 0.0014019012451171875, 'loss_3': -16.369579315185547, 'loss_4': 0.9104923009872437, 'epoch': 28.3}
{'loss': 0.008, 'grad_norm': 5.251877307891846, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.005909026600420475, 'loss_2': 0.00208282470703125, 'loss_3': -16.323814392089844, 'loss_4': 0.9251800775527954, 'epoch': 28.3}
{'loss': 0.0045, 'grad_norm': 4.668382167816162, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.004038092214614153, 'loss_2': 0.000415802001953125, 'loss_3': -16.30011558532715, 'loss_4': 0.5907526612281799, 'epoch': 28.31}
{'loss': 0.0074, 'grad_norm': 4.577515602111816, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.0026916079223155975, 'loss_2': 0.004688262939453125, 'loss_3': -16.449024200439453, 'loss_4': 0.5669622421264648, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 11:26:21,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:21,172 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [1:59:48<04:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:26:28,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007912908680737019, 'eval_runtime': 3.7821, 'eval_samples_per_second': 270.751, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005679434631019831, 'eval_loss_2': 0.00223347544670105, 'eval_loss_3': -18.16213035583496, 'eval_loss_4': 0.9735190272331238, 'epoch': 28.31}
{'loss': 0.0111, 'grad_norm': 5.295439720153809, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.005727393086999655, 'loss_2': 0.0054168701171875, 'loss_3': -16.273466110229492, 'loss_4': 0.7119385004043579, 'epoch': 28.32}
{'loss': 0.0251, 'grad_norm': 9.820914268493652, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.019723152741789818, 'loss_2': 0.00540924072265625, 'loss_3': -16.187076568603516, 'loss_4': 1.3353028297424316, 'epoch': 28.33}
{'loss': 0.0091, 'grad_norm': 6.520061492919922, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.0077674854546785355, 'loss_2': 0.0012912750244140625, 'loss_3': -16.250568389892578, 'loss_4': 0.5050966739654541, 'epoch': 28.33}
{'loss': 0.0035, 'grad_norm': 4.840884685516357, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0029693515971302986, 'loss_2': 0.000553131103515625, 'loss_3': -16.404706954956055, 'loss_4': 1.0284205675125122, 'epoch': 28.34}
{'loss': 0.0127, 'grad_norm': 4.923328399658203, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0035641647409647703, 'loss_2': 0.00913238525390625, 'loss_3': -16.426918029785156, 'loss_4': 1.0422842502593994, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 11:26:28,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:28,488 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [1:59:55<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:35,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008195878006517887, 'eval_runtime': 3.7806, 'eval_samples_per_second': 270.855, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.005893786437809467, 'eval_loss_2': 0.00230209156870842, 'eval_loss_3': -18.165420532226562, 'eval_loss_4': 0.9692871570587158, 'epoch': 28.34}
{'loss': 0.007, 'grad_norm': 4.8657355308532715, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.005484496708959341, 'loss_2': 0.00152587890625, 'loss_3': -16.23609733581543, 'loss_4': 1.6935300827026367, 'epoch': 28.35}
{'loss': 0.0235, 'grad_norm': 9.801355361938477, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.013484431430697441, 'loss_2': 0.0099945068359375, 'loss_3': -16.408397674560547, 'loss_4': 1.2292375564575195, 'epoch': 28.35}
{'loss': 0.0149, 'grad_norm': 4.878512859344482, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.00413480494171381, 'loss_2': 0.0107574462890625, 'loss_3': -16.283226013183594, 'loss_4': 1.500408411026001, 'epoch': 28.36}
{'loss': 0.0077, 'grad_norm': 4.9433417320251465, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.003641736228018999, 'loss_2': 0.004058837890625, 'loss_3': -16.407669067382812, 'loss_4': 1.2797011137008667, 'epoch': 28.37}
{'loss': 0.0092, 'grad_norm': 7.456216812133789, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.0074688103049993515, 'loss_2': 0.0017147064208984375, 'loss_3': -16.365907669067383, 'loss_4': 0.6468605995178223, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 11:26:35,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:35,814 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:02<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:43,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008602957241237164, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006084373686462641, 'eval_loss_2': 0.0025185830891132355, 'eval_loss_3': -18.166213989257812, 'eval_loss_4': 0.9516322612762451, 'epoch': 28.37}
{'loss': 0.0027, 'grad_norm': 4.682921409606934, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.002635172801092267, 'loss_2': 9.09566879272461e-05, 'loss_3': -16.472103118896484, 'loss_4': 0.9057725667953491, 'epoch': 28.38}
{'loss': 0.0023, 'grad_norm': 4.949366569519043, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0016395441489294171, 'loss_2': 0.0006880760192871094, 'loss_3': -16.246318817138672, 'loss_4': 1.1713154315948486, 'epoch': 28.38}
{'loss': 0.0105, 'grad_norm': 5.175374507904053, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.0035525381099432707, 'loss_2': 0.006908416748046875, 'loss_3': -16.12127685546875, 'loss_4': 1.474400281906128, 'epoch': 28.39}
{'loss': 0.0072, 'grad_norm': 4.5322585105896, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.002987505402415991, 'loss_2': 0.004241943359375, 'loss_3': -16.429607391357422, 'loss_4': 1.0593209266662598, 'epoch': 28.4}
{'loss': 0.0074, 'grad_norm': 5.099524974822998, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.006811920553445816, 'loss_2': 0.0005488395690917969, 'loss_3': -16.298198699951172, 'loss_4': 1.5150716304779053, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 11:26:43,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:43,150 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:10<04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:50,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008755721151828766, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.193, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006070309318602085, 'eval_loss_2': 0.0026854127645492554, 'eval_loss_3': -18.16619873046875, 'eval_loss_4': 0.9350073933601379, 'epoch': 28.4}
{'loss': 0.0138, 'grad_norm': 6.920663356781006, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.010505540296435356, 'loss_2': 0.00328826904296875, 'loss_3': -16.36613655090332, 'loss_4': 0.6361632347106934, 'epoch': 28.41}
{'loss': 0.004, 'grad_norm': 5.022231101989746, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.0035410874988883734, 'loss_2': 0.0004153251647949219, 'loss_3': -16.107961654663086, 'loss_4': 0.8007939457893372, 'epoch': 28.41}
{'loss': 0.016, 'grad_norm': 6.585902214050293, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.012462741695344448, 'loss_2': 0.003509521484375, 'loss_3': -16.17386245727539, 'loss_4': 1.4709280729293823, 'epoch': 28.42}
{'loss': 0.0035, 'grad_norm': 4.70119571685791, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.003327339654788375, 'loss_2': 0.00021278858184814453, 'loss_3': -16.26641082763672, 'loss_4': 1.2395960092544556, 'epoch': 28.42}
{'loss': 0.0121, 'grad_norm': 5.672507286071777, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.007101879920810461, 'loss_2': 0.005035400390625, 'loss_3': -16.540210723876953, 'loss_4': 0.7524521350860596, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 11:26:50,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:50,490 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:17<04:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:26:57,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008799978531897068, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006034941412508488, 'eval_loss_2': 0.0027650371193885803, 'eval_loss_3': -18.166011810302734, 'eval_loss_4': 0.9172917604446411, 'epoch': 28.43}
{'loss': 0.0071, 'grad_norm': 5.2107672691345215, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.005031147506088018, 'loss_2': 0.002063751220703125, 'loss_3': -16.292184829711914, 'loss_4': 1.1391099691390991, 'epoch': 28.44}
{'loss': 0.0047, 'grad_norm': 5.093391418457031, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.0024148242082446814, 'loss_2': 0.0022640228271484375, 'loss_3': -16.140228271484375, 'loss_4': 0.8184276223182678, 'epoch': 28.44}
{'loss': 0.0136, 'grad_norm': 6.115456581115723, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.008899365551769733, 'loss_2': 0.00467681884765625, 'loss_3': -16.235153198242188, 'loss_4': 1.5656954050064087, 'epoch': 28.45}
{'loss': 0.007, 'grad_norm': 4.7042555809021, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.004402500577270985, 'loss_2': 0.0026378631591796875, 'loss_3': -16.28515625, 'loss_4': 1.2231836318969727, 'epoch': 28.45}
{'loss': 0.0151, 'grad_norm': 6.237618923187256, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.009760933928191662, 'loss_2': 0.005340576171875, 'loss_3': -16.222585678100586, 'loss_4': 0.7522118091583252, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 11:26:57,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:57,815 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:24<04:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:05,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009101726114749908, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.56, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0061172922141849995, 'eval_loss_2': 0.0029844343662261963, 'eval_loss_3': -18.16648292541504, 'eval_loss_4': 0.9016135334968567, 'epoch': 28.46}
{'loss': 0.0051, 'grad_norm': 4.852695465087891, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.0020672734826803207, 'loss_2': 0.003025054931640625, 'loss_3': -16.397489547729492, 'loss_4': 0.48165804147720337, 'epoch': 28.47}
{'loss': 0.0084, 'grad_norm': 4.977661609649658, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.0041281683370471, 'loss_2': 0.00423431396484375, 'loss_3': -16.257287979125977, 'loss_4': 0.8874036073684692, 'epoch': 28.47}
{'loss': 0.0461, 'grad_norm': 26.10395622253418, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.04070298746228218, 'loss_2': 0.00539398193359375, 'loss_3': -15.99553108215332, 'loss_4': 1.1603766679763794, 'epoch': 28.48}
{'loss': 0.0084, 'grad_norm': 5.449193000793457, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.006383320316672325, 'loss_2': 0.001972198486328125, 'loss_3': -15.979753494262695, 'loss_4': 0.8179500102996826, 'epoch': 28.48}
{'loss': 0.0116, 'grad_norm': 7.264554500579834, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.010219629853963852, 'loss_2': 0.0013637542724609375, 'loss_3': -16.237590789794922, 'loss_4': 1.2241976261138916, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 11:27:05,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:05,137 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:32<04:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:27:12,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008955011144280434, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.533, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.006201865151524544, 'eval_loss_2': 0.00275314599275589, 'eval_loss_3': -18.167774200439453, 'eval_loss_4': 0.8976524472236633, 'epoch': 28.49}
{'loss': 0.0139, 'grad_norm': 7.105526924133301, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.009273977018892765, 'loss_2': 0.004642486572265625, 'loss_3': -16.33542823791504, 'loss_4': 1.199270486831665, 'epoch': 28.49}
{'loss': 0.0065, 'grad_norm': 4.811502456665039, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0024037216790020466, 'loss_2': 0.004062652587890625, 'loss_3': -16.33818817138672, 'loss_4': 0.5887050628662109, 'epoch': 28.5}
{'loss': 0.0068, 'grad_norm': 4.561202049255371, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.003618288552388549, 'loss_2': 0.0031833648681640625, 'loss_3': -16.31396484375, 'loss_4': 0.5699219703674316, 'epoch': 28.51}
{'loss': 0.005, 'grad_norm': 5.020089626312256, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0036703620571643114, 'loss_2': 0.00131988525390625, 'loss_3': -16.31618881225586, 'loss_4': 1.1714990139007568, 'epoch': 28.51}
{'loss': 0.0143, 'grad_norm': 5.256855010986328, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.0061668637208640575, 'loss_2': 0.0081787109375, 'loss_3': -16.3671875, 'loss_4': 1.0669173002243042, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 11:27:12,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:12,457 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:00:39<04:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:19,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008673175238072872, 'eval_runtime': 3.7821, 'eval_samples_per_second': 270.75, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.006163573823869228, 'eval_loss_2': 0.002509601414203644, 'eval_loss_3': -18.16874885559082, 'eval_loss_4': 0.8910360336303711, 'epoch': 28.52}
{'loss': 0.0048, 'grad_norm': 4.71480655670166, 'learning_rate': 1.5e-06, 'loss_1': 0.002477095928043127, 'loss_2': 0.002292633056640625, 'loss_3': -16.255298614501953, 'loss_4': 0.918953537940979, 'epoch': 28.52}
{'loss': 0.0036, 'grad_norm': 4.678502082824707, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.003610843326896429, 'loss_2': 1.0132789611816406e-05, 'loss_3': -16.30044937133789, 'loss_4': 1.1981370449066162, 'epoch': 28.53}
{'loss': 0.0104, 'grad_norm': 4.649492263793945, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.003425928298383951, 'loss_2': 0.00701904296875, 'loss_3': -16.309436798095703, 'loss_4': 0.6557362079620361, 'epoch': 28.53}
{'loss': 0.005, 'grad_norm': 4.521957874298096, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.004443148151040077, 'loss_2': 0.0005702972412109375, 'loss_3': -16.299816131591797, 'loss_4': 0.7707231044769287, 'epoch': 28.54}
{'loss': 0.0127, 'grad_norm': 7.3103718757629395, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.008930720388889313, 'loss_2': 0.003734588623046875, 'loss_3': -16.325361251831055, 'loss_4': 0.9065454006195068, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 11:27:19,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:19,782 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:00:46<04:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:27:27,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00864388793706894, 'eval_runtime': 3.7825, 'eval_samples_per_second': 270.717, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.006196103990077972, 'eval_loss_2': 0.002447783946990967, 'eval_loss_3': -18.171594619750977, 'eval_loss_4': 0.8857687711715698, 'epoch': 28.55}
{'loss': 0.0064, 'grad_norm': 4.836132526397705, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.004416349343955517, 'loss_2': 0.001987457275390625, 'loss_3': -16.127296447753906, 'loss_4': 1.239689826965332, 'epoch': 28.55}
{'loss': 0.0083, 'grad_norm': 4.252059459686279, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0015663817757740617, 'loss_2': 0.006725311279296875, 'loss_3': -16.173486709594727, 'loss_4': 0.9550155401229858, 'epoch': 28.56}
{'loss': 0.0126, 'grad_norm': 5.192977428436279, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.005693745333701372, 'loss_2': 0.00693511962890625, 'loss_3': -16.193077087402344, 'loss_4': 0.7554393410682678, 'epoch': 28.56}
{'loss': 0.0085, 'grad_norm': 4.965908527374268, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.005286406725645065, 'loss_2': 0.003185272216796875, 'loss_3': -16.291196823120117, 'loss_4': 1.453557014465332, 'epoch': 28.57}
{'loss': 0.0142, 'grad_norm': 10.706841468811035, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.012745529413223267, 'loss_2': 0.0014934539794921875, 'loss_3': -16.4388484954834, 'loss_4': 1.05484938621521, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 11:27:27,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:27,099 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:00:54<04:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:27:34,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008866503834724426, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.275, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.006304963957518339, 'eval_loss_2': 0.0025615394115448, 'eval_loss_3': -18.170486450195312, 'eval_loss_4': 0.8908786177635193, 'epoch': 28.58}
{'loss': 0.0054, 'grad_norm': 4.250851154327393, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.002032484160736203, 'loss_2': 0.00337982177734375, 'loss_3': -16.28875732421875, 'loss_4': 0.535835325717926, 'epoch': 28.58}
{'loss': 0.0116, 'grad_norm': 6.675423622131348, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.007322301622480154, 'loss_2': 0.00426483154296875, 'loss_3': -16.177799224853516, 'loss_4': 0.8279873132705688, 'epoch': 28.59}
{'loss': 0.0083, 'grad_norm': 4.350401401519775, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.004421457648277283, 'loss_2': 0.003910064697265625, 'loss_3': -16.190114974975586, 'loss_4': 1.278566598892212, 'epoch': 28.59}
{'loss': 0.0108, 'grad_norm': 5.4254469871521, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.005768714472651482, 'loss_2': 0.00501251220703125, 'loss_3': -16.457616806030273, 'loss_4': 0.6521679162979126, 'epoch': 28.6}
{'loss': 0.0047, 'grad_norm': 4.3271284103393555, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.0033860772382467985, 'loss_2': 0.00128173828125, 'loss_3': -16.347747802734375, 'loss_4': 1.1151591539382935, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 11:27:34,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:34,624 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:01<04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:41,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00896123144775629, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006377336569130421, 'eval_loss_2': 0.0025838948786258698, 'eval_loss_3': -18.1739501953125, 'eval_loss_4': 0.8939787745475769, 'epoch': 28.6}
{'loss': 0.0035, 'grad_norm': 4.829588890075684, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0032342432532459497, 'loss_2': 0.0003032684326171875, 'loss_3': -16.16373062133789, 'loss_4': 0.7987357378005981, 'epoch': 28.61}
{'loss': 0.0129, 'grad_norm': 5.65676212310791, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.007516737096011639, 'loss_2': 0.005401611328125, 'loss_3': -16.345909118652344, 'loss_4': 0.9658140540122986, 'epoch': 28.62}
{'loss': 0.0133, 'grad_norm': 7.667731761932373, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.010160461999475956, 'loss_2': 0.0031147003173828125, 'loss_3': -16.375415802001953, 'loss_4': 1.1766939163208008, 'epoch': 28.62}
{'loss': 0.0082, 'grad_norm': 5.106815338134766, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.006186197977513075, 'loss_2': 0.0020275115966796875, 'loss_3': -16.296825408935547, 'loss_4': 1.0237098932266235, 'epoch': 28.63}
{'loss': 0.0103, 'grad_norm': 4.5203962326049805, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.002392687601968646, 'loss_2': 0.00788116455078125, 'loss_3': -16.400127410888672, 'loss_4': 1.0938200950622559, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 11:27:41,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:41,955 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:09<03:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:49,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008911394514143467, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.391, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.006302901543676853, 'eval_loss_2': 0.0026084929704666138, 'eval_loss_3': -18.17789649963379, 'eval_loss_4': 0.8900737166404724, 'epoch': 28.63}
{'loss': 0.0095, 'grad_norm': 4.917440891265869, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.004276532679796219, 'loss_2': 0.00527191162109375, 'loss_3': -16.468334197998047, 'loss_4': 1.2335573434829712, 'epoch': 28.64}
{'loss': 0.0045, 'grad_norm': 4.745512008666992, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.004113328643143177, 'loss_2': 0.0004181861877441406, 'loss_3': -16.304468154907227, 'loss_4': 0.9008525013923645, 'epoch': 28.65}
{'loss': 0.0037, 'grad_norm': 4.361627578735352, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.003159847343340516, 'loss_2': 0.0004949569702148438, 'loss_3': -16.14224624633789, 'loss_4': 0.6447416543960571, 'epoch': 28.65}
{'loss': 0.0064, 'grad_norm': 5.296993255615234, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.0040648942813277245, 'loss_2': 0.0023345947265625, 'loss_3': -16.226280212402344, 'loss_4': 1.3296165466308594, 'epoch': 28.66}
{'loss': 0.0046, 'grad_norm': 4.603048801422119, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.004179369192570448, 'loss_2': 0.00042247772216796875, 'loss_3': -16.427125930786133, 'loss_4': 1.3292641639709473, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 11:27:49,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:49,285 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:16<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:56,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008595248684287071, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.24, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0059435125440359116, 'eval_loss_2': 0.0026517361402511597, 'eval_loss_3': -18.18069076538086, 'eval_loss_4': 0.8883144855499268, 'epoch': 28.66}
{'loss': 0.0096, 'grad_norm': 5.475018501281738, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.005199739243835211, 'loss_2': 0.004425048828125, 'loss_3': -16.405302047729492, 'loss_4': 1.1730148792266846, 'epoch': 28.67}
{'loss': 0.0087, 'grad_norm': 4.884761333465576, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.003763282671570778, 'loss_2': 0.00494384765625, 'loss_3': -16.388004302978516, 'loss_4': 1.1616771221160889, 'epoch': 28.67}
{'loss': 0.0214, 'grad_norm': 8.752873420715332, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.018994176760315895, 'loss_2': 0.002368927001953125, 'loss_3': -16.26906967163086, 'loss_4': 1.236389398574829, 'epoch': 28.68}
{'loss': 0.0049, 'grad_norm': 4.762606143951416, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.0021670241840183735, 'loss_2': 0.002689361572265625, 'loss_3': -16.440628051757812, 'loss_4': 0.8892134428024292, 'epoch': 28.69}
{'loss': 0.0056, 'grad_norm': 4.603982925415039, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.004438456613570452, 'loss_2': 0.0012073516845703125, 'loss_3': -16.189910888671875, 'loss_4': 0.6866081357002258, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 11:27:56,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:56,621 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:23<03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:03,951 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008404159918427467, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.29, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.005802982486784458, 'eval_loss_2': 0.0026011765003204346, 'eval_loss_3': -18.183208465576172, 'eval_loss_4': 0.8910959959030151, 'epoch': 28.69}
{'loss': 0.0047, 'grad_norm': 4.676296710968018, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.0019072755239903927, 'loss_2': 0.00276947021484375, 'loss_3': -16.300853729248047, 'loss_4': 0.5208278894424438, 'epoch': 28.7}
{'loss': 0.0079, 'grad_norm': 4.719357013702393, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.003144863760098815, 'loss_2': 0.00479888916015625, 'loss_3': -16.325042724609375, 'loss_4': 0.9574635624885559, 'epoch': 28.7}
{'loss': 0.0065, 'grad_norm': 5.365835189819336, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.006055003497749567, 'loss_2': 0.0004127025604248047, 'loss_3': -16.393224716186523, 'loss_4': 0.8609734773635864, 'epoch': 28.71}
{'loss': 0.0067, 'grad_norm': 4.945835113525391, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.00412954343482852, 'loss_2': 0.002597808837890625, 'loss_3': -16.34174919128418, 'loss_4': 0.5089090466499329, 'epoch': 28.72}
{'loss': 0.0036, 'grad_norm': 5.27385139465332, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.00310865743085742, 'loss_2': 0.00047135353088378906, 'loss_3': -16.276226043701172, 'loss_4': 0.6777799725532532, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 11:28:03,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:03,951 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:31<03:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:11,278 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008387638255953789, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.668, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005773609504103661, 'eval_loss_2': 0.002614028751850128, 'eval_loss_3': -18.1870174407959, 'eval_loss_4': 0.8914167881011963, 'epoch': 28.72}
{'loss': 0.0113, 'grad_norm': 5.45405912399292, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.008196589536964893, 'loss_2': 0.003063201904296875, 'loss_3': -16.31505584716797, 'loss_4': 0.7830747365951538, 'epoch': 28.73}
{'loss': 0.0038, 'grad_norm': 4.3831987380981445, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.001998674124479294, 'loss_2': 0.0017681121826171875, 'loss_3': -16.409177780151367, 'loss_4': 1.1211533546447754, 'epoch': 28.73}
{'loss': 0.0069, 'grad_norm': 5.105526447296143, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.005368377082049847, 'loss_2': 0.0015048980712890625, 'loss_3': -16.20477294921875, 'loss_4': 1.319108009338379, 'epoch': 28.74}
{'loss': 0.0047, 'grad_norm': 4.5360918045043945, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.0023047623690217733, 'loss_2': 0.0024433135986328125, 'loss_3': -16.201976776123047, 'loss_4': 0.5691407918930054, 'epoch': 28.74}
{'loss': 0.0087, 'grad_norm': 5.278870582580566, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.005255776923149824, 'loss_2': 0.003406524658203125, 'loss_3': -16.237825393676758, 'loss_4': 1.3435838222503662, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 11:28:11,278 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:11,278 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:01:38<03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:18,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008505281060934067, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.808, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.005879330914467573, 'eval_loss_2': 0.0026259496808052063, 'eval_loss_3': -18.1870059967041, 'eval_loss_4': 0.8853824734687805, 'epoch': 28.75}
{'loss': 0.014, 'grad_norm': 5.1899094581604, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.01058544497936964, 'loss_2': 0.0033721923828125, 'loss_3': -16.331012725830078, 'loss_4': 0.8433164954185486, 'epoch': 28.76}
{'loss': 0.0103, 'grad_norm': 5.630889892578125, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.006708092056214809, 'loss_2': 0.0036163330078125, 'loss_3': -16.37305450439453, 'loss_4': 0.9233740568161011, 'epoch': 28.76}
{'loss': 0.0248, 'grad_norm': 8.358927726745605, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.022670969367027283, 'loss_2': 0.002117156982421875, 'loss_3': -16.458887100219727, 'loss_4': 0.667240560054779, 'epoch': 28.77}
{'loss': 0.0059, 'grad_norm': 5.082499980926514, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.005044594407081604, 'loss_2': 0.0008401870727539062, 'loss_3': -16.24302864074707, 'loss_4': 0.8648303747177124, 'epoch': 28.77}
{'loss': 0.0108, 'grad_norm': 5.170860767364502, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.0039285290986299515, 'loss_2': 0.006847381591796875, 'loss_3': -16.161022186279297, 'loss_4': 1.4682223796844482, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 11:28:18,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:18,614 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:01:45<03:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:28:25,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00843819323927164, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.631, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005883293226361275, 'eval_loss_2': 0.0025549009442329407, 'eval_loss_3': -18.184213638305664, 'eval_loss_4': 0.8818573951721191, 'epoch': 28.78}
{'loss': 0.0149, 'grad_norm': 15.327468872070312, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.014114010147750378, 'loss_2': 0.0007867813110351562, 'loss_3': -16.360809326171875, 'loss_4': 1.2920140027999878, 'epoch': 28.78}
{'loss': 0.0109, 'grad_norm': 6.573436737060547, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.007713085040450096, 'loss_2': 0.0032329559326171875, 'loss_3': -16.409757614135742, 'loss_4': 1.4221885204315186, 'epoch': 28.79}
{'loss': 0.0083, 'grad_norm': 5.198692321777344, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.005401169415563345, 'loss_2': 0.00287628173828125, 'loss_3': -16.31822967529297, 'loss_4': 0.9835456609725952, 'epoch': 28.8}
{'loss': 0.0087, 'grad_norm': 6.68757438659668, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.007901711389422417, 'loss_2': 0.0008440017700195312, 'loss_3': -16.396556854248047, 'loss_4': 0.7100776433944702, 'epoch': 28.8}
{'loss': 0.026, 'grad_norm': 11.073447227478027, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.021078404039144516, 'loss_2': 0.00493621826171875, 'loss_3': -16.337562561035156, 'loss_4': 1.1560499668121338, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 11:28:25,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:25,937 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:01:53<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:33,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008504528552293777, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.398, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0059177083894610405, 'eval_loss_2': 0.0025868192315101624, 'eval_loss_3': -18.179462432861328, 'eval_loss_4': 0.8748558163642883, 'epoch': 28.81}
{'loss': 0.0044, 'grad_norm': 4.506540298461914, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.0031421869061887264, 'loss_2': 0.0012187957763671875, 'loss_3': -16.429622650146484, 'loss_4': 0.9287431240081787, 'epoch': 28.81}
{'loss': 0.0071, 'grad_norm': 4.452417373657227, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.004254048690199852, 'loss_2': 0.00286865234375, 'loss_3': -16.157329559326172, 'loss_4': 0.6218916177749634, 'epoch': 28.82}
{'loss': 0.0034, 'grad_norm': 4.5299882888793945, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.0030000892002135515, 'loss_2': 0.00043201446533203125, 'loss_3': -16.245906829833984, 'loss_4': 0.6981015205383301, 'epoch': 28.83}
{'loss': 0.0071, 'grad_norm': 4.773629665374756, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.005467511247843504, 'loss_2': 0.0016012191772460938, 'loss_3': -16.33426284790039, 'loss_4': 0.6392440795898438, 'epoch': 28.83}
{'loss': 0.0057, 'grad_norm': 4.345200061798096, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.0033772403839975595, 'loss_2': 0.002315521240234375, 'loss_3': -16.3021240234375, 'loss_4': 0.8829505443572998, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 11:28:33,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:33,272 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:00<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:40,596 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008356863632798195, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.662, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005885684862732887, 'eval_loss_2': 0.0024711787700653076, 'eval_loss_3': -18.178592681884766, 'eval_loss_4': 0.8623730540275574, 'epoch': 28.84}
{'loss': 0.0058, 'grad_norm': 5.5876383781433105, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.005216821096837521, 'loss_2': 0.0005702972412109375, 'loss_3': -16.455032348632812, 'loss_4': 0.48804497718811035, 'epoch': 28.84}
{'loss': 0.0083, 'grad_norm': 4.744575500488281, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.005754607263952494, 'loss_2': 0.002544403076171875, 'loss_3': -16.312206268310547, 'loss_4': 0.6745866537094116, 'epoch': 28.85}
{'loss': 0.0087, 'grad_norm': 4.980522155761719, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.006059776525944471, 'loss_2': 0.002635955810546875, 'loss_3': -16.283124923706055, 'loss_4': 0.7719030976295471, 'epoch': 28.85}
{'loss': 0.0144, 'grad_norm': 6.395689964294434, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.009005771949887276, 'loss_2': 0.00539398193359375, 'loss_3': -16.32508087158203, 'loss_4': 0.6800053715705872, 'epoch': 28.86}
{'loss': 0.0082, 'grad_norm': 5.440651893615723, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.0054045384749770164, 'loss_2': 0.00279998779296875, 'loss_3': -16.307680130004883, 'loss_4': 0.623940110206604, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 11:28:40,596 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:40,596 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:07<03:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:47,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008359980769455433, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.367, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.005934272427111864, 'eval_loss_2': 0.0024257078766822815, 'eval_loss_3': -18.17571258544922, 'eval_loss_4': 0.8574323654174805, 'epoch': 28.87}
{'loss': 0.0161, 'grad_norm': 6.858983993530273, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.0068427640944719315, 'loss_2': 0.00925445556640625, 'loss_3': -16.334951400756836, 'loss_4': 0.733576774597168, 'epoch': 28.87}
{'loss': 0.0071, 'grad_norm': 5.211872577667236, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.003915531560778618, 'loss_2': 0.0032196044921875, 'loss_3': -16.2874813079834, 'loss_4': 1.0944396257400513, 'epoch': 28.88}
{'loss': 0.0127, 'grad_norm': 6.522948741912842, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.007550414651632309, 'loss_2': 0.0051116943359375, 'loss_3': -16.22271156311035, 'loss_4': 1.2756766080856323, 'epoch': 28.88}
{'loss': 0.0055, 'grad_norm': 5.357898712158203, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.005110981874167919, 'loss_2': 0.000431060791015625, 'loss_3': -16.175973892211914, 'loss_4': 0.7527680397033691, 'epoch': 28.89}
{'loss': 0.0122, 'grad_norm': 8.48367691040039, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.01088617742061615, 'loss_2': 0.0013265609741210938, 'loss_3': -16.198463439941406, 'loss_4': 0.6980805397033691, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 11:28:47,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:47,921 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:15<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:55,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008470609784126282, 'eval_runtime': 3.7825, 'eval_samples_per_second': 270.723, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.005973324179649353, 'eval_loss_2': 0.0024972856044769287, 'eval_loss_3': -18.178237915039062, 'eval_loss_4': 0.8594983220100403, 'epoch': 28.9}
{'loss': 0.0241, 'grad_norm': 13.93952751159668, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.01812192052602768, 'loss_2': 0.0059967041015625, 'loss_3': -16.343719482421875, 'loss_4': 1.0303897857666016, 'epoch': 28.9}
{'loss': 0.0175, 'grad_norm': 7.93715763092041, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.012177926488220692, 'loss_2': 0.0053253173828125, 'loss_3': -16.37535858154297, 'loss_4': 0.7556585669517517, 'epoch': 28.91}
{'loss': 0.0082, 'grad_norm': 4.739968299865723, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.005173241253942251, 'loss_2': 0.0029773712158203125, 'loss_3': -16.351699829101562, 'loss_4': 0.8048802614212036, 'epoch': 28.91}
{'loss': 0.0098, 'grad_norm': 4.810275077819824, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.003908104263246059, 'loss_2': 0.005859375, 'loss_3': -16.349994659423828, 'loss_4': 1.2535197734832764, 'epoch': 28.92}
{'loss': 0.0031, 'grad_norm': 4.8742475509643555, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.0030707218684256077, 'loss_2': 2.6226043701171875e-05, 'loss_3': -16.372920989990234, 'loss_4': 1.2058489322662354, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 11:28:55,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:55,253 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:22<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:02,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008534102700650692, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.492, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0059584216214716434, 'eval_loss_2': 0.0025756806135177612, 'eval_loss_3': -18.181167602539062, 'eval_loss_4': 0.8663681745529175, 'epoch': 28.92}
{'loss': 0.0077, 'grad_norm': 4.673890113830566, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.004369334317743778, 'loss_2': 0.003353118896484375, 'loss_3': -16.134981155395508, 'loss_4': 0.6902788877487183, 'epoch': 28.93}
{'loss': 0.0086, 'grad_norm': 4.803829669952393, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.003144608112052083, 'loss_2': 0.00547027587890625, 'loss_3': -16.17998504638672, 'loss_4': 0.974113941192627, 'epoch': 28.94}
{'loss': 0.006, 'grad_norm': 4.775242328643799, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.004036840051412582, 'loss_2': 0.0019550323486328125, 'loss_3': -16.239044189453125, 'loss_4': 0.6914219856262207, 'epoch': 28.94}
{'loss': 0.0055, 'grad_norm': 4.3753228187561035, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.003051716135814786, 'loss_2': 0.0024089813232421875, 'loss_3': -16.375320434570312, 'loss_4': 0.7507938146591187, 'epoch': 28.95}
{'loss': 0.0115, 'grad_norm': 5.52311897277832, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.006409619003534317, 'loss_2': 0.0050506591796875, 'loss_3': -16.418262481689453, 'loss_4': 0.49489325284957886, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 11:29:02,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:02,602 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:29<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:09,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008522341027855873, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.682, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005955778528004885, 'eval_loss_2': 0.0025665611028671265, 'eval_loss_3': -18.17862892150879, 'eval_loss_4': 0.8818562626838684, 'epoch': 28.95}
{'loss': 0.027, 'grad_norm': 8.381632804870605, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.023650702089071274, 'loss_2': 0.00334930419921875, 'loss_3': -16.339738845825195, 'loss_4': 0.542100191116333, 'epoch': 28.96}
{'loss': 0.0098, 'grad_norm': 5.000790119171143, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.004890101961791515, 'loss_2': 0.0049285888671875, 'loss_3': -16.387937545776367, 'loss_4': 0.6059615612030029, 'epoch': 28.97}
{'loss': 0.0094, 'grad_norm': 4.676706314086914, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0033449206966906786, 'loss_2': 0.00601959228515625, 'loss_3': -16.345449447631836, 'loss_4': 1.289858341217041, 'epoch': 28.97}
{'loss': 0.0049, 'grad_norm': 4.810024738311768, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0018048119964078069, 'loss_2': 0.003124237060546875, 'loss_3': -16.41535186767578, 'loss_4': 0.8819429278373718, 'epoch': 28.98}
{'loss': 0.0078, 'grad_norm': 4.401115894317627, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0027706860564649105, 'loss_2': 0.005039215087890625, 'loss_3': -16.511438369750977, 'loss_4': 0.6505628228187561, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 11:29:09,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:09,926 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:36<02:48,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 11:29:16,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008456002920866013, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.522, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.005910111125558615, 'eval_loss_2': 0.0025458931922912598, 'eval_loss_3': -18.177053451538086, 'eval_loss_4': 0.895416259765625, 'epoch': 28.98}
{'loss': 0.0148, 'grad_norm': 6.997386455535889, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.010923751629889011, 'loss_2': 0.0038623809814453125, 'loss_3': -16.27765655517578, 'loss_4': 0.8406960368156433, 'epoch': 28.99}
{'loss': 0.0051, 'grad_norm': 4.643495082855225, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.001747284783050418, 'loss_2': 0.0033245086669921875, 'loss_3': -16.335742950439453, 'loss_4': 1.053753137588501, 'epoch': 28.99}
{'loss': 0.006, 'grad_norm': 6.421948432922363, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.00440375879406929, 'loss_2': 0.001583099365234375, 'loss_3': -16.401044845581055, 'loss_4': 1.2885664701461792, 'epoch': 29.0}
{'loss': 0.0067, 'grad_norm': 4.61862325668335, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.004244188312441111, 'loss_2': 0.0024871826171875, 'loss_3': -16.325210571289062, 'loss_4': 0.948677659034729, 'epoch': 29.01}
{'loss': 0.0131, 'grad_norm': 5.589178562164307, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.00971018522977829, 'loss_2': 0.003368377685546875, 'loss_3': -16.188785552978516, 'loss_4': 0.912314236164093, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 11:29:16,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:16,935 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:02:44<02:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:29:24,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008357580751180649, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.08, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0058973245322704315, 'eval_loss_2': 0.0024602562189102173, 'eval_loss_3': -18.17487907409668, 'eval_loss_4': 0.9052562117576599, 'epoch': 29.01}
{'loss': 0.0052, 'grad_norm': 4.911392688751221, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.004919576924294233, 'loss_2': 0.00023412704467773438, 'loss_3': -16.23921775817871, 'loss_4': 0.7846455574035645, 'epoch': 29.02}
{'loss': 0.0062, 'grad_norm': 4.8552656173706055, 'learning_rate': 1e-06, 'loss_1': 0.0035920836962759495, 'loss_2': 0.002613067626953125, 'loss_3': -16.28731918334961, 'loss_4': 1.1870125532150269, 'epoch': 29.02}
{'loss': 0.0048, 'grad_norm': 4.6461052894592285, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.003506155451759696, 'loss_2': 0.0012950897216796875, 'loss_3': -16.369766235351562, 'loss_4': 1.3192391395568848, 'epoch': 29.03}
{'loss': 0.0108, 'grad_norm': 5.295103073120117, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.007696035783737898, 'loss_2': 0.00311279296875, 'loss_3': -16.265586853027344, 'loss_4': 1.053891658782959, 'epoch': 29.03}
{'loss': 0.0049, 'grad_norm': 4.647711753845215, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.0030662494245916605, 'loss_2': 0.001804351806640625, 'loss_3': -16.311687469482422, 'loss_4': 0.7091294527053833, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 11:29:24,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:24,268 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:02:51<02:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:29:31,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008469345048069954, 'eval_runtime': 3.7824, 'eval_samples_per_second': 270.731, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.006040604785084724, 'eval_loss_2': 0.0024287402629852295, 'eval_loss_3': -18.175968170166016, 'eval_loss_4': 0.9121741056442261, 'epoch': 29.04}
{'loss': 0.0095, 'grad_norm': 4.679581642150879, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.004431246779859066, 'loss_2': 0.005035400390625, 'loss_3': -16.306333541870117, 'loss_4': 0.983002245426178, 'epoch': 29.05}
{'loss': 0.0084, 'grad_norm': 5.986677646636963, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.007097587455064058, 'loss_2': 0.0013322830200195312, 'loss_3': -16.25469398498535, 'loss_4': 1.0653607845306396, 'epoch': 29.05}
{'loss': 0.0081, 'grad_norm': 4.448825836181641, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.0038843373768031597, 'loss_2': 0.0042572021484375, 'loss_3': -16.43520736694336, 'loss_4': 0.8290917873382568, 'epoch': 29.06}
{'loss': 0.0195, 'grad_norm': 6.87094259262085, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.014137298800051212, 'loss_2': 0.00536346435546875, 'loss_3': -16.24329948425293, 'loss_4': 0.9610100984573364, 'epoch': 29.06}
{'loss': 0.0089, 'grad_norm': 5.724728107452393, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0054245744831860065, 'loss_2': 0.00345611572265625, 'loss_3': -16.368301391601562, 'loss_4': 0.5367009043693542, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 11:29:31,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:31,589 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:02:58<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:38,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008489871397614479, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.561, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.006099279038608074, 'eval_loss_2': 0.0023905932903289795, 'eval_loss_3': -18.176931381225586, 'eval_loss_4': 0.9206012487411499, 'epoch': 29.07}
{'loss': 0.0098, 'grad_norm': 5.220744609832764, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.007086018566042185, 'loss_2': 0.002712249755859375, 'loss_3': -16.300033569335938, 'loss_4': 0.9529608488082886, 'epoch': 29.08}
{'loss': 0.0032, 'grad_norm': 4.489105701446533, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.0026906353887170553, 'loss_2': 0.000461578369140625, 'loss_3': -16.38595199584961, 'loss_4': 0.803976833820343, 'epoch': 29.08}
{'loss': 0.0071, 'grad_norm': 4.534914493560791, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.002545068273320794, 'loss_2': 0.00455474853515625, 'loss_3': -16.285886764526367, 'loss_4': 1.1467242240905762, 'epoch': 29.09}
{'loss': 0.023, 'grad_norm': 7.9140238761901855, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.022371390834450722, 'loss_2': 0.0006499290466308594, 'loss_3': -16.529052734375, 'loss_4': 1.1496167182922363, 'epoch': 29.09}
{'loss': 0.015, 'grad_norm': 5.425070285797119, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.009028974920511246, 'loss_2': 0.00595855712890625, 'loss_3': -16.275806427001953, 'loss_4': 1.459707260131836, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 11:29:38,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:38,921 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:06<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:46,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008373698219656944, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.67, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005955358035862446, 'eval_loss_2': 0.002418339252471924, 'eval_loss_3': -18.174388885498047, 'eval_loss_4': 0.9249469041824341, 'epoch': 29.1}
{'loss': 0.0092, 'grad_norm': 4.829091548919678, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.003399505512788892, 'loss_2': 0.00583648681640625, 'loss_3': -16.40214729309082, 'loss_4': 1.2232428789138794, 'epoch': 29.1}
{'loss': 0.0067, 'grad_norm': 5.528514862060547, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.0050612809136509895, 'loss_2': 0.00159454345703125, 'loss_3': -16.35174560546875, 'loss_4': 1.2007789611816406, 'epoch': 29.11}
{'loss': 0.0072, 'grad_norm': 4.580211162567139, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.0060402750968933105, 'loss_2': 0.0011119842529296875, 'loss_3': -16.421384811401367, 'loss_4': 1.428564429283142, 'epoch': 29.12}
{'loss': 0.017, 'grad_norm': 12.129507064819336, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.01156626921147108, 'loss_2': 0.00543975830078125, 'loss_3': -16.31157112121582, 'loss_4': 0.9045343399047852, 'epoch': 29.12}
{'loss': 0.0034, 'grad_norm': 4.631810665130615, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.0033000954426825047, 'loss_2': 8.046627044677734e-05, 'loss_3': -16.390321731567383, 'loss_4': 1.2103222608566284, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 11:29:46,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:46,248 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:13<02:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:29:53,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008291399106383324, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.664, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.005921205505728722, 'eval_loss_2': 0.002370193600654602, 'eval_loss_3': -18.174209594726562, 'eval_loss_4': 0.9247941374778748, 'epoch': 29.13}
{'loss': 0.0081, 'grad_norm': 4.758816242218018, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.006781772710382938, 'loss_2': 0.0012807846069335938, 'loss_3': -16.143535614013672, 'loss_4': 0.7714720964431763, 'epoch': 29.13}
{'loss': 0.0111, 'grad_norm': 4.66228723526001, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.005252946633845568, 'loss_2': 0.00586700439453125, 'loss_3': -16.42474937438965, 'loss_4': 1.5605518817901611, 'epoch': 29.14}
{'loss': 0.0051, 'grad_norm': 5.1631951332092285, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.003919221460819244, 'loss_2': 0.0011806488037109375, 'loss_3': -16.170608520507812, 'loss_4': 0.7331305146217346, 'epoch': 29.15}
{'loss': 0.0088, 'grad_norm': 5.7920026779174805, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.003935711923986673, 'loss_2': 0.00482940673828125, 'loss_3': -16.441335678100586, 'loss_4': 1.0248212814331055, 'epoch': 29.15}
{'loss': 0.0051, 'grad_norm': 4.729642868041992, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0031703764107078314, 'loss_2': 0.0018863677978515625, 'loss_3': -16.284053802490234, 'loss_4': 0.8220764994621277, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 11:29:53,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:53,566 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:20<02:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:00,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008216316811740398, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.376, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005938912276178598, 'eval_loss_2': 0.0022774040699005127, 'eval_loss_3': -18.174348831176758, 'eval_loss_4': 0.9268834590911865, 'epoch': 29.16}
{'loss': 0.0073, 'grad_norm': 4.648698806762695, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.005266763735562563, 'loss_2': 0.0020542144775390625, 'loss_3': -16.137794494628906, 'loss_4': 1.4445295333862305, 'epoch': 29.16}
{'loss': 0.0151, 'grad_norm': 6.1200785636901855, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.008825940079987049, 'loss_2': 0.00628662109375, 'loss_3': -16.29996109008789, 'loss_4': 0.5867202877998352, 'epoch': 29.17}
{'loss': 0.0079, 'grad_norm': 4.615184783935547, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.004070555791258812, 'loss_2': 0.003849029541015625, 'loss_3': -16.259048461914062, 'loss_4': 0.8663101196289062, 'epoch': 29.17}
{'loss': 0.0088, 'grad_norm': 5.054783344268799, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.004795539658516645, 'loss_2': 0.00405120849609375, 'loss_3': -16.30349349975586, 'loss_4': 0.9142948389053345, 'epoch': 29.18}
{'loss': 0.0086, 'grad_norm': 4.592774868011475, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.004151885863393545, 'loss_2': 0.004451751708984375, 'loss_3': -16.195796966552734, 'loss_4': 1.1668179035186768, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 11:30:00,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:00,891 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:28<02:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:08,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00815693661570549, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.005926080513745546, 'eval_loss_2': 0.002230856567621231, 'eval_loss_3': -18.176361083984375, 'eval_loss_4': 0.925581693649292, 'epoch': 29.19}
{'loss': 0.0132, 'grad_norm': 5.001060962677002, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.0074603804387152195, 'loss_2': 0.00569915771484375, 'loss_3': -16.411842346191406, 'loss_4': 0.9878320693969727, 'epoch': 29.19}
{'loss': 0.0057, 'grad_norm': 4.903107643127441, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0023739838507026434, 'loss_2': 0.003353118896484375, 'loss_3': -16.485965728759766, 'loss_4': 1.1249926090240479, 'epoch': 29.2}
{'loss': 0.0093, 'grad_norm': 4.272577285766602, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.003581784665584564, 'loss_2': 0.0057525634765625, 'loss_3': -16.475332260131836, 'loss_4': 1.2131835222244263, 'epoch': 29.2}
{'loss': 0.0092, 'grad_norm': 6.438521862030029, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.008933965116739273, 'loss_2': 0.00028228759765625, 'loss_3': -16.297195434570312, 'loss_4': 0.7683415412902832, 'epoch': 29.21}
{'loss': 0.0119, 'grad_norm': 6.197808742523193, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.009971150197088718, 'loss_2': 0.0019283294677734375, 'loss_3': -16.355175018310547, 'loss_4': 0.3522728681564331, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 11:30:08,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:08,220 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:35<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:15,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008071251213550568, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.542, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005855937022715807, 'eval_loss_2': 0.002215314656496048, 'eval_loss_3': -18.18027687072754, 'eval_loss_4': 0.9225175976753235, 'epoch': 29.22}
{'loss': 0.0086, 'grad_norm': 4.956035137176514, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.005098018795251846, 'loss_2': 0.00347137451171875, 'loss_3': -16.1446475982666, 'loss_4': 1.2365381717681885, 'epoch': 29.22}
{'loss': 0.0063, 'grad_norm': 4.9629225730896, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.003963659051805735, 'loss_2': 0.002307891845703125, 'loss_3': -16.09537124633789, 'loss_4': 1.2569034099578857, 'epoch': 29.23}
{'loss': 0.0073, 'grad_norm': 4.1617431640625, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.0026735791470855474, 'loss_2': 0.00457763671875, 'loss_3': -16.571250915527344, 'loss_4': 0.9793674349784851, 'epoch': 29.23}
{'loss': 0.0077, 'grad_norm': 5.073673725128174, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.005092978943139315, 'loss_2': 0.002635955810546875, 'loss_3': -16.177356719970703, 'loss_4': 1.573256015777588, 'epoch': 29.24}
{'loss': 0.0109, 'grad_norm': 4.169530391693115, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.003954078070819378, 'loss_2': 0.00691986083984375, 'loss_3': -16.42983627319336, 'loss_4': 0.6613658666610718, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 11:30:15,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:15,559 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:03:42<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:22,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008037345483899117, 'eval_runtime': 3.8187, 'eval_samples_per_second': 268.155, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005828565917909145, 'eval_loss_2': 0.0022087804973125458, 'eval_loss_3': -18.181167602539062, 'eval_loss_4': 0.9222246408462524, 'epoch': 29.24}
{'loss': 0.0199, 'grad_norm': 11.229244232177734, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.018786819651722908, 'loss_2': 0.0011425018310546875, 'loss_3': -16.341642379760742, 'loss_4': 0.8289235830307007, 'epoch': 29.25}
{'loss': 0.0236, 'grad_norm': 7.3392744064331055, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.014716210775077343, 'loss_2': 0.0089263916015625, 'loss_3': -16.495946884155273, 'loss_4': 0.6425496339797974, 'epoch': 29.26}
{'loss': 0.0114, 'grad_norm': 4.604949951171875, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.006105971988290548, 'loss_2': 0.005279541015625, 'loss_3': -16.520227432250977, 'loss_4': 0.8425718545913696, 'epoch': 29.26}
{'loss': 0.0142, 'grad_norm': 7.900662899017334, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.011348899453878403, 'loss_2': 0.0028209686279296875, 'loss_3': -16.246597290039062, 'loss_4': 1.1577016115188599, 'epoch': 29.27}
{'loss': 0.01, 'grad_norm': 8.436762809753418, 'learning_rate': 7.5e-07, 'loss_1': 0.00924160797148943, 'loss_2': 0.000762939453125, 'loss_3': -16.395389556884766, 'loss_4': 0.5243381261825562, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 11:30:22,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:22,918 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:03:50<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:30,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008036770857870579, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.493, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.00583538506180048, 'eval_loss_2': 0.002201385796070099, 'eval_loss_3': -18.180810928344727, 'eval_loss_4': 0.9227216243743896, 'epoch': 29.27}
{'loss': 0.0128, 'grad_norm': 7.260708332061768, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.010757257230579853, 'loss_2': 0.00203704833984375, 'loss_3': -16.335399627685547, 'loss_4': 1.2271313667297363, 'epoch': 29.28}
{'loss': 0.005, 'grad_norm': 4.482712268829346, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0030446331948041916, 'loss_2': 0.0019969940185546875, 'loss_3': -16.28092384338379, 'loss_4': 0.6156595349311829, 'epoch': 29.28}
{'loss': 0.005, 'grad_norm': 4.373531341552734, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.0036573747638612986, 'loss_2': 0.0013751983642578125, 'loss_3': -16.332284927368164, 'loss_4': 1.1964261531829834, 'epoch': 29.29}
{'loss': 0.0053, 'grad_norm': 4.923504829406738, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.0034318550024181604, 'loss_2': 0.0018224716186523438, 'loss_3': -16.414031982421875, 'loss_4': 0.7745476961135864, 'epoch': 29.3}
{'loss': 0.0041, 'grad_norm': 4.706295967102051, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.0027503822930157185, 'loss_2': 0.0013265609741210938, 'loss_3': -16.2437686920166, 'loss_4': 1.2558667659759521, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 11:30:30,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:30,244 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:03:57<01:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:30:37,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00816001370549202, 'eval_runtime': 3.7816, 'eval_samples_per_second': 270.782, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.005883924197405577, 'eval_loss_2': 0.0022760890424251556, 'eval_loss_3': -18.180578231811523, 'eval_loss_4': 0.9204067587852478, 'epoch': 29.3}
{'loss': 0.0054, 'grad_norm': 4.283708095550537, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.0022683385759592056, 'loss_2': 0.003170013427734375, 'loss_3': -16.37384033203125, 'loss_4': 1.1252014636993408, 'epoch': 29.31}
{'loss': 0.0042, 'grad_norm': 4.6546454429626465, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.0015810452168807387, 'loss_2': 0.00257110595703125, 'loss_3': -16.385448455810547, 'loss_4': 0.7831196784973145, 'epoch': 29.31}
{'loss': 0.0095, 'grad_norm': 6.659160614013672, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.00824317242950201, 'loss_2': 0.0012359619140625, 'loss_3': -16.14824104309082, 'loss_4': 1.5256967544555664, 'epoch': 29.32}
{'loss': 0.0078, 'grad_norm': 4.442836284637451, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.004417102783918381, 'loss_2': 0.0033416748046875, 'loss_3': -16.298877716064453, 'loss_4': 1.1731994152069092, 'epoch': 29.33}
{'loss': 0.0063, 'grad_norm': 5.094980716705322, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.005128819029778242, 'loss_2': 0.0011444091796875, 'loss_3': -16.387832641601562, 'loss_4': 0.820629358291626, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 11:30:37,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:37,565 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:04<01:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:30:44,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008113119751214981, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.651, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.0058870743960142136, 'eval_loss_2': 0.0022260472178459167, 'eval_loss_3': -18.181114196777344, 'eval_loss_4': 0.9165581464767456, 'epoch': 29.33}
{'loss': 0.0015, 'grad_norm': 4.301456928253174, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.001530243898741901, 'loss_2': 8.940696716308594e-06, 'loss_3': -16.326202392578125, 'loss_4': 0.6522128582000732, 'epoch': 29.34}
{'loss': 0.0088, 'grad_norm': 4.684698581695557, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.002962730824947357, 'loss_2': 0.0058441162109375, 'loss_3': -16.147815704345703, 'loss_4': 0.9021109938621521, 'epoch': 29.34}
{'loss': 0.0084, 'grad_norm': 5.174727439880371, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.003445208305492997, 'loss_2': 0.004940032958984375, 'loss_3': -16.280038833618164, 'loss_4': 0.752927839756012, 'epoch': 29.35}
{'loss': 0.0093, 'grad_norm': 5.212826728820801, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.004056917503476143, 'loss_2': 0.005199432373046875, 'loss_3': -16.381229400634766, 'loss_4': 1.1941888332366943, 'epoch': 29.35}
{'loss': 0.0059, 'grad_norm': 4.978065013885498, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.005392429884523153, 'loss_2': 0.0005106925964355469, 'loss_3': -16.282020568847656, 'loss_4': 1.2919241189956665, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 11:30:44,887 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:44,887 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:12<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:52,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008158356882631779, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.452, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.005927376914769411, 'eval_loss_2': 0.0022309795022010803, 'eval_loss_3': -18.180038452148438, 'eval_loss_4': 0.9122533202171326, 'epoch': 29.36}
{'loss': 0.0198, 'grad_norm': 10.806947708129883, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.013263022527098656, 'loss_2': 0.006526947021484375, 'loss_3': -16.353219985961914, 'loss_4': 1.5102453231811523, 'epoch': 29.37}
{'loss': 0.0081, 'grad_norm': 5.252382278442383, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.003541955491527915, 'loss_2': 0.00450897216796875, 'loss_3': -16.066959381103516, 'loss_4': 1.3215675354003906, 'epoch': 29.37}
{'loss': 0.0049, 'grad_norm': 4.389138221740723, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.002771383849903941, 'loss_2': 0.00214385986328125, 'loss_3': -16.35101890563965, 'loss_4': 1.0720539093017578, 'epoch': 29.38}
{'loss': 0.0055, 'grad_norm': 5.3324198722839355, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.004622555337846279, 'loss_2': 0.0008687973022460938, 'loss_3': -16.385831832885742, 'loss_4': 0.8800011277198792, 'epoch': 29.38}
{'loss': 0.0095, 'grad_norm': 6.4704132080078125, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.008751257322728634, 'loss_2': 0.0007944107055664062, 'loss_3': -16.221515655517578, 'loss_4': 0.72199547290802, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 11:30:52,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:52,218 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:19<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:59,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008204573765397072, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.005950454156845808, 'eval_loss_2': 0.0022541210055351257, 'eval_loss_3': -18.18000602722168, 'eval_loss_4': 0.9078371524810791, 'epoch': 29.39}
{'loss': 0.0075, 'grad_norm': 5.3527326583862305, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0064626759849488735, 'loss_2': 0.0010280609130859375, 'loss_3': -16.405216217041016, 'loss_4': 0.6838886737823486, 'epoch': 29.4}
{'loss': 0.0094, 'grad_norm': 4.342418670654297, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.005413714796304703, 'loss_2': 0.00394439697265625, 'loss_3': -16.282222747802734, 'loss_4': 1.0177265405654907, 'epoch': 29.4}
{'loss': 0.0145, 'grad_norm': 5.99711799621582, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.011848804540932178, 'loss_2': 0.002681732177734375, 'loss_3': -16.308189392089844, 'loss_4': 1.3467319011688232, 'epoch': 29.41}
{'loss': 0.0059, 'grad_norm': 4.930041313171387, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.004964096006006002, 'loss_2': 0.0009245872497558594, 'loss_3': -16.120372772216797, 'loss_4': 1.2572522163391113, 'epoch': 29.41}
{'loss': 0.009, 'grad_norm': 5.166159629821777, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.0034979141782969236, 'loss_2': 0.005550384521484375, 'loss_3': -16.394412994384766, 'loss_4': 1.0363900661468506, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 11:30:59,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:59,550 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:26<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:31:06,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008163806051015854, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.568, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.00589898694306612, 'eval_loss_2': 0.0022648200392723083, 'eval_loss_3': -18.182111740112305, 'eval_loss_4': 0.9064979553222656, 'epoch': 29.42}
{'loss': 0.0052, 'grad_norm': 4.5236358642578125, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0034808311611413956, 'loss_2': 0.0017566680908203125, 'loss_3': -16.43265724182129, 'loss_4': 1.2716197967529297, 'epoch': 29.42}
{'loss': 0.0108, 'grad_norm': 6.256077289581299, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.008419644087553024, 'loss_2': 0.002338409423828125, 'loss_3': -16.107891082763672, 'loss_4': 0.7848403453826904, 'epoch': 29.43}
{'loss': 0.0095, 'grad_norm': 4.990044116973877, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.005511599592864513, 'loss_2': 0.003993988037109375, 'loss_3': -16.289867401123047, 'loss_4': 1.0511177778244019, 'epoch': 29.44}
{'loss': 0.0069, 'grad_norm': 4.672634124755859, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.006183878984302282, 'loss_2': 0.0007390975952148438, 'loss_3': -16.198945999145508, 'loss_4': 0.6205270290374756, 'epoch': 29.44}
{'loss': 0.0072, 'grad_norm': 5.103488922119141, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.0060607315972447395, 'loss_2': 0.0011749267578125, 'loss_3': -16.289642333984375, 'loss_4': 0.6572343111038208, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 11:31:06,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:06,874 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:34<01:34,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:31:14,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008102428168058395, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.529, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005837358999997377, 'eval_loss_2': 0.0022650696337223053, 'eval_loss_3': -18.181224822998047, 'eval_loss_4': 0.9069923162460327, 'epoch': 29.45}
{'loss': 0.0059, 'grad_norm': 4.548939228057861, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.002399986842647195, 'loss_2': 0.003509521484375, 'loss_3': -16.47736358642578, 'loss_4': 0.9482115507125854, 'epoch': 29.45}
{'loss': 0.0082, 'grad_norm': 6.552484512329102, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.007952272891998291, 'loss_2': 0.0002562999725341797, 'loss_3': -16.10405921936035, 'loss_4': 0.5305196046829224, 'epoch': 29.46}
{'loss': 0.0079, 'grad_norm': 5.609776496887207, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.006040901876986027, 'loss_2': 0.0018863677978515625, 'loss_3': -16.29932975769043, 'loss_4': 1.0935752391815186, 'epoch': 29.47}
{'loss': 0.0083, 'grad_norm': 4.488239765167236, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.0020206391345709562, 'loss_2': 0.006237030029296875, 'loss_3': -16.161924362182617, 'loss_4': 1.26896071434021, 'epoch': 29.47}
{'loss': 0.0114, 'grad_norm': 5.335179805755615, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.00807445403188467, 'loss_2': 0.0033054351806640625, 'loss_3': -16.46291160583496, 'loss_4': 0.9082764387130737, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 11:31:14,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:14,275 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:04:41<01:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:31:21,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008024799637496471, 'eval_runtime': 3.9461, 'eval_samples_per_second': 259.498, 'eval_steps_per_second': 4.055, 'eval_loss_1': 0.00572937959805131, 'eval_loss_2': 0.0022954195737838745, 'eval_loss_3': -18.180538177490234, 'eval_loss_4': 0.9059322476387024, 'epoch': 29.48}
{'loss': 0.0051, 'grad_norm': 5.133982181549072, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.002867642091587186, 'loss_2': 0.002216339111328125, 'loss_3': -16.28044891357422, 'loss_4': 1.148844838142395, 'epoch': 29.48}
{'loss': 0.0075, 'grad_norm': 5.06028938293457, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.003566815983504057, 'loss_2': 0.00396728515625, 'loss_3': -16.00257110595703, 'loss_4': 0.9787541627883911, 'epoch': 29.49}
{'loss': 0.0041, 'grad_norm': 4.391576766967773, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.003804992651566863, 'loss_2': 0.0002837181091308594, 'loss_3': -16.298782348632812, 'loss_4': 0.8332009315490723, 'epoch': 29.49}
{'loss': 0.0043, 'grad_norm': 4.174397945404053, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.002582490211352706, 'loss_2': 0.001689910888671875, 'loss_3': -16.305784225463867, 'loss_4': 1.1170779466629028, 'epoch': 29.5}
{'loss': 0.0096, 'grad_norm': 5.236336708068848, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.0071026841178536415, 'loss_2': 0.0025463104248046875, 'loss_3': -16.341604232788086, 'loss_4': 0.5702136158943176, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 11:31:21,794 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:21,794 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:04:48<01:23,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:31:29,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008018200285732746, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00568911898881197, 'eval_loss_2': 0.0023290812969207764, 'eval_loss_3': -18.17917823791504, 'eval_loss_4': 0.9075067043304443, 'epoch': 29.51}
{'loss': 0.0061, 'grad_norm': 4.78262186050415, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.0034677351359277964, 'loss_2': 0.002593994140625, 'loss_3': -16.348955154418945, 'loss_4': 1.0910124778747559, 'epoch': 29.51}
{'loss': 0.0061, 'grad_norm': 4.630866050720215, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0027875443920493126, 'loss_2': 0.0032978057861328125, 'loss_3': -16.30548858642578, 'loss_4': 0.5102766752243042, 'epoch': 29.52}
{'loss': 0.0029, 'grad_norm': 4.426155090332031, 'learning_rate': 5e-07, 'loss_1': 0.0025752135552465916, 'loss_2': 0.0003170967102050781, 'loss_3': -16.355552673339844, 'loss_4': 0.3981516361236572, 'epoch': 29.52}
{'loss': 0.0033, 'grad_norm': 4.632112503051758, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.003195915836840868, 'loss_2': 0.00011754035949707031, 'loss_3': -16.216381072998047, 'loss_4': 1.4606250524520874, 'epoch': 29.53}
{'loss': 0.0066, 'grad_norm': 4.30205774307251, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0029125779401510954, 'loss_2': 0.00370025634765625, 'loss_3': -16.392593383789062, 'loss_4': 1.0499241352081299, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 11:31:29,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:29,183 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:04:56<01:18,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:31:36,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007940080016851425, 'eval_runtime': 3.9769, 'eval_samples_per_second': 257.49, 'eval_steps_per_second': 4.023, 'eval_loss_1': 0.005603204946964979, 'eval_loss_2': 0.0023368746042251587, 'eval_loss_3': -18.17949676513672, 'eval_loss_4': 0.9092022180557251, 'epoch': 29.53}
{'loss': 0.0106, 'grad_norm': 4.688693523406982, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.004837615415453911, 'loss_2': 0.00571441650390625, 'loss_3': -16.466018676757812, 'loss_4': 0.8076778650283813, 'epoch': 29.54}
{'loss': 0.008, 'grad_norm': 6.116668701171875, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.0068273842334747314, 'loss_2': 0.00119781494140625, 'loss_3': -16.42166519165039, 'loss_4': 0.9594395160675049, 'epoch': 29.55}
{'loss': 0.005, 'grad_norm': 4.975945472717285, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.004795942455530167, 'loss_2': 0.00023412704467773438, 'loss_3': -16.3817081451416, 'loss_4': 1.494964838027954, 'epoch': 29.55}
{'loss': 0.007, 'grad_norm': 4.932114601135254, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0022593734320253134, 'loss_2': 0.00473785400390625, 'loss_3': -16.192249298095703, 'loss_4': 0.8498087525367737, 'epoch': 29.56}
{'loss': 0.0071, 'grad_norm': 4.7970733642578125, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.002992065157741308, 'loss_2': 0.0040740966796875, 'loss_3': -16.499473571777344, 'loss_4': 0.38874244689941406, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 11:31:36,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:36,720 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:03<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:31:44,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007986480370163918, 'eval_runtime': 3.8194, 'eval_samples_per_second': 268.107, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.005617471411824226, 'eval_loss_2': 0.002369008958339691, 'eval_loss_3': -18.177759170532227, 'eval_loss_4': 0.9079259037971497, 'epoch': 29.56}
{'loss': 0.0032, 'grad_norm': 4.479039669036865, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0027929884381592274, 'loss_2': 0.0004520416259765625, 'loss_3': -16.38610076904297, 'loss_4': 1.0877125263214111, 'epoch': 29.57}
{'loss': 0.004, 'grad_norm': 4.813908100128174, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.0016181437531486154, 'loss_2': 0.0023345947265625, 'loss_3': -16.308231353759766, 'loss_4': 1.106997013092041, 'epoch': 29.58}
{'loss': 0.004, 'grad_norm': 4.500565528869629, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.003685143543407321, 'loss_2': 0.00030040740966796875, 'loss_3': -16.3720703125, 'loss_4': 0.8467346429824829, 'epoch': 29.58}
{'loss': 0.0167, 'grad_norm': 5.399569988250732, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.00817175768315792, 'loss_2': 0.008544921875, 'loss_3': -16.273162841796875, 'loss_4': 1.0095592737197876, 'epoch': 29.59}
{'loss': 0.0033, 'grad_norm': 4.280440807342529, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.0020729985553771257, 'loss_2': 0.0012340545654296875, 'loss_3': -16.291982650756836, 'loss_4': 0.5484021902084351, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 11:31:44,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:44,083 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:11<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:31:51,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007977912202477455, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.564, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005662390496581793, 'eval_loss_2': 0.002315521240234375, 'eval_loss_3': -18.176969528198242, 'eval_loss_4': 0.9097655415534973, 'epoch': 29.59}
{'loss': 0.0085, 'grad_norm': 5.018144130706787, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.006219038274139166, 'loss_2': 0.00228118896484375, 'loss_3': -16.375059127807617, 'loss_4': 0.9747614860534668, 'epoch': 29.6}
{'loss': 0.0074, 'grad_norm': 4.747879981994629, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.004851950332522392, 'loss_2': 0.0025653839111328125, 'loss_3': -16.30961799621582, 'loss_4': 0.7792996168136597, 'epoch': 29.6}
{'loss': 0.0045, 'grad_norm': 4.587017059326172, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0025669236201792955, 'loss_2': 0.00197601318359375, 'loss_3': -16.254072189331055, 'loss_4': 0.9333252310752869, 'epoch': 29.61}
{'loss': 0.0083, 'grad_norm': 5.0106120109558105, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.005219117272645235, 'loss_2': 0.003040313720703125, 'loss_3': -16.267240524291992, 'loss_4': 1.012985348701477, 'epoch': 29.62}
{'loss': 0.0035, 'grad_norm': 4.4879255294799805, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.0030088697094470263, 'loss_2': 0.0005235671997070312, 'loss_3': -16.23802947998047, 'loss_4': 1.028524398803711, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 11:31:51,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:51,435 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:18<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:31:58,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008037017658352852, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0057493397034704685, 'eval_loss_2': 0.0022876784205436707, 'eval_loss_3': -18.175508499145508, 'eval_loss_4': 0.9112367033958435, 'epoch': 29.62}
{'loss': 0.0081, 'grad_norm': 5.178831100463867, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.005816983990371227, 'loss_2': 0.00225067138671875, 'loss_3': -16.186138153076172, 'loss_4': 0.8894542455673218, 'epoch': 29.63}
{'loss': 0.0059, 'grad_norm': 4.568447589874268, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.003266802988946438, 'loss_2': 0.0026302337646484375, 'loss_3': -16.27460479736328, 'loss_4': 0.9745068550109863, 'epoch': 29.63}
{'loss': 0.0066, 'grad_norm': 4.473527431488037, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.0028792647644877434, 'loss_2': 0.00376129150390625, 'loss_3': -16.494638442993164, 'loss_4': 1.169151782989502, 'epoch': 29.64}
{'loss': 0.01, 'grad_norm': 5.801487922668457, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.008354389108717442, 'loss_2': 0.0016536712646484375, 'loss_3': -16.260969161987305, 'loss_4': 1.6010220050811768, 'epoch': 29.65}
{'loss': 0.0084, 'grad_norm': 5.634068012237549, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.005388566292822361, 'loss_2': 0.002964019775390625, 'loss_3': -16.218860626220703, 'loss_4': 0.9891437888145447, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 11:31:58,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:31:58,788 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:25<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:06,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008060406893491745, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005781807936728001, 'eval_loss_2': 0.002278599888086319, 'eval_loss_3': -18.174497604370117, 'eval_loss_4': 0.9121206998825073, 'epoch': 29.65}
{'loss': 0.0137, 'grad_norm': 5.152021884918213, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.0106623824685812, 'loss_2': 0.003021240234375, 'loss_3': -16.299165725708008, 'loss_4': 0.8777386546134949, 'epoch': 29.66}
{'loss': 0.0066, 'grad_norm': 4.900913238525391, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.0045129950158298016, 'loss_2': 0.00213623046875, 'loss_3': -16.100059509277344, 'loss_4': 1.4846556186676025, 'epoch': 29.66}
{'loss': 0.0062, 'grad_norm': 5.325158596038818, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.006116941571235657, 'loss_2': 5.4955482482910156e-05, 'loss_3': -16.222049713134766, 'loss_4': 0.8418771624565125, 'epoch': 29.67}
{'loss': 0.006, 'grad_norm': 4.594172477722168, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.0029494662303477526, 'loss_2': 0.003070831298828125, 'loss_3': -16.33011245727539, 'loss_4': 0.942008912563324, 'epoch': 29.67}
{'loss': 0.0083, 'grad_norm': 4.538030624389648, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.0027754916809499264, 'loss_2': 0.005527496337890625, 'loss_3': -16.392852783203125, 'loss_4': 0.8857280015945435, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 11:32:06,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:06,145 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:33<00:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:13,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008099847473204136, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005823352839797735, 'eval_loss_2': 0.002276495099067688, 'eval_loss_3': -18.17382049560547, 'eval_loss_4': 0.9166556000709534, 'epoch': 29.68}
{'loss': 0.0074, 'grad_norm': 4.981163501739502, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.005478983744978905, 'loss_2': 0.001941680908203125, 'loss_3': -16.101694107055664, 'loss_4': 1.1291284561157227, 'epoch': 29.69}
{'loss': 0.0074, 'grad_norm': 4.567417621612549, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.0030475277453660965, 'loss_2': 0.0043792724609375, 'loss_3': -16.31475067138672, 'loss_4': 0.4280524253845215, 'epoch': 29.69}
{'loss': 0.0115, 'grad_norm': 5.737492561340332, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.008378665894269943, 'loss_2': 0.0031032562255859375, 'loss_3': -16.3299560546875, 'loss_4': 0.9987524151802063, 'epoch': 29.7}
{'loss': 0.0068, 'grad_norm': 4.861356735229492, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.0035711186937987804, 'loss_2': 0.003192901611328125, 'loss_3': -16.339412689208984, 'loss_4': 0.5874997973442078, 'epoch': 29.7}
{'loss': 0.0119, 'grad_norm': 6.577413558959961, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.010718991979956627, 'loss_2': 0.00122833251953125, 'loss_3': -16.33590316772461, 'loss_4': 0.9921594858169556, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 11:32:13,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:13,518 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:05:40<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:20,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008119016885757446, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.275, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005870025604963303, 'eval_loss_2': 0.0022489912807941437, 'eval_loss_3': -18.17333984375, 'eval_loss_4': 0.9193071126937866, 'epoch': 29.71}
{'loss': 0.0196, 'grad_norm': 11.592583656311035, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.015070930123329163, 'loss_2': 0.0045318603515625, 'loss_3': -16.51952362060547, 'loss_4': 0.785527229309082, 'epoch': 29.72}
{'loss': 0.0118, 'grad_norm': 5.851052761077881, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.008587339892983437, 'loss_2': 0.003261566162109375, 'loss_3': -16.300899505615234, 'loss_4': 0.985572874546051, 'epoch': 29.72}
{'loss': 0.0079, 'grad_norm': 4.601322650909424, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.0028194400947541, 'loss_2': 0.005046844482421875, 'loss_3': -16.42429542541504, 'loss_4': 1.0365424156188965, 'epoch': 29.73}
{'loss': 0.0186, 'grad_norm': 16.30508804321289, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.018485166132450104, 'loss_2': 0.00013136863708496094, 'loss_3': -16.29671287536621, 'loss_4': 1.2061350345611572, 'epoch': 29.73}
{'loss': 0.0141, 'grad_norm': 11.330771446228027, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.011479642242193222, 'loss_2': 0.002582550048828125, 'loss_3': -16.36050796508789, 'loss_4': 1.2562248706817627, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 11:32:20,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:20,884 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:05:48<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:28,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008157268166542053, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005925432778894901, 'eval_loss_2': 0.0022318363189697266, 'eval_loss_3': -18.173391342163086, 'eval_loss_4': 0.920067310333252, 'epoch': 29.74}
{'loss': 0.0092, 'grad_norm': 5.119908332824707, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.0037599396891891956, 'loss_2': 0.005466461181640625, 'loss_3': -16.21381187438965, 'loss_4': 0.9209874868392944, 'epoch': 29.74}
{'loss': 0.0095, 'grad_norm': 5.723924160003662, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.008954526856541634, 'loss_2': 0.0005283355712890625, 'loss_3': -16.316789627075195, 'loss_4': 1.4896045923233032, 'epoch': 29.75}
{'loss': 0.0112, 'grad_norm': 5.068141937255859, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.004892522934824228, 'loss_2': 0.0063323974609375, 'loss_3': -16.492748260498047, 'loss_4': 1.0047688484191895, 'epoch': 29.76}
{'loss': 0.0052, 'grad_norm': 4.995908260345459, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.004325309302657843, 'loss_2': 0.0009107589721679688, 'loss_3': -16.335092544555664, 'loss_4': 0.9874899983406067, 'epoch': 29.76}
{'loss': 0.0042, 'grad_norm': 4.808435440063477, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.0028004201594740152, 'loss_2': 0.0013580322265625, 'loss_3': -16.37630844116211, 'loss_4': 1.0661828517913818, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 11:32:28,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:28,249 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:05:55<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:35,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008156465366482735, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.866, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.005938368383795023, 'eval_loss_2': 0.002218097448348999, 'eval_loss_3': -18.173643112182617, 'eval_loss_4': 0.9193360805511475, 'epoch': 29.77}
{'loss': 0.0082, 'grad_norm': 4.751214504241943, 'learning_rate': 2.5e-07, 'loss_1': 0.005487136077135801, 'loss_2': 0.00269317626953125, 'loss_3': -16.168807983398438, 'loss_4': 0.7903677225112915, 'epoch': 29.77}
{'loss': 0.0045, 'grad_norm': 4.801127910614014, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.004191101994365454, 'loss_2': 0.0002722740173339844, 'loss_3': -16.28754997253418, 'loss_4': 0.7675880789756775, 'epoch': 29.78}
{'loss': 0.0052, 'grad_norm': 4.552680969238281, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.004023081623017788, 'loss_2': 0.0011806488037109375, 'loss_3': -16.340068817138672, 'loss_4': 1.0062448978424072, 'epoch': 29.78}
{'loss': 0.0052, 'grad_norm': 4.771683692932129, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.003753789933398366, 'loss_2': 0.0014848709106445312, 'loss_3': -16.31429100036621, 'loss_4': 1.108905553817749, 'epoch': 29.79}
{'loss': 0.0113, 'grad_norm': 5.364221572875977, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.008726450614631176, 'loss_2': 0.0025634765625, 'loss_3': -16.16901397705078, 'loss_4': 1.073807716369629, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 11:32:35,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:35,593 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:02<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:42,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008214663714170456, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005961667746305466, 'eval_loss_2': 0.0022529959678649902, 'eval_loss_3': -18.173370361328125, 'eval_loss_4': 0.9168453812599182, 'epoch': 29.8}
{'loss': 0.0086, 'grad_norm': 4.704313278198242, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.0046689738519489765, 'loss_2': 0.0039043426513671875, 'loss_3': -16.236251831054688, 'loss_4': 1.2664374113082886, 'epoch': 29.8}
{'loss': 0.0055, 'grad_norm': 5.323541641235352, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.0048560481518507, 'loss_2': 0.00060272216796875, 'loss_3': -16.439699172973633, 'loss_4': 1.3374292850494385, 'epoch': 29.81}
{'loss': 0.0083, 'grad_norm': 4.674413681030273, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.0030696839094161987, 'loss_2': 0.005218505859375, 'loss_3': -16.26871681213379, 'loss_4': 0.6888332962989807, 'epoch': 29.81}
{'loss': 0.0032, 'grad_norm': 4.6545023918151855, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0022621406242251396, 'loss_2': 0.0008945465087890625, 'loss_3': -16.1036376953125, 'loss_4': 0.9249392747879028, 'epoch': 29.82}
{'loss': 0.0135, 'grad_norm': 5.433870792388916, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.006322373170405626, 'loss_2': 0.00722503662109375, 'loss_3': -16.339719772338867, 'loss_4': 1.2047526836395264, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 11:32:42,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:42,962 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:10<00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:50,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008214429952204227, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.771, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005950265564024448, 'eval_loss_2': 0.002264164388179779, 'eval_loss_3': -18.17377471923828, 'eval_loss_4': 0.9159730672836304, 'epoch': 29.83}
{'loss': 0.0052, 'grad_norm': 4.898336887359619, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.004449821542948484, 'loss_2': 0.0007944107055664062, 'loss_3': -16.126216888427734, 'loss_4': 0.6671069860458374, 'epoch': 29.83}
{'loss': 0.0063, 'grad_norm': 4.525444030761719, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.005319179035723209, 'loss_2': 0.0010280609130859375, 'loss_3': -16.3559513092041, 'loss_4': 0.9473741054534912, 'epoch': 29.84}
{'loss': 0.0107, 'grad_norm': 7.632204532623291, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.006874562706798315, 'loss_2': 0.0038204193115234375, 'loss_3': -16.553157806396484, 'loss_4': 0.6151742935180664, 'epoch': 29.84}
{'loss': 0.0112, 'grad_norm': 4.609393119812012, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.00559595413506031, 'loss_2': 0.00557708740234375, 'loss_3': -16.449865341186523, 'loss_4': 1.0069173574447632, 'epoch': 29.85}
{'loss': 0.0036, 'grad_norm': 4.2143168449401855, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.0030853222124278545, 'loss_2': 0.0004901885986328125, 'loss_3': -16.139999389648438, 'loss_4': 0.7338411808013916, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 11:32:50,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:50,313 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:17<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:32:57,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008228655904531479, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005955089349299669, 'eval_loss_2': 0.002273567020893097, 'eval_loss_3': -18.174936294555664, 'eval_loss_4': 0.916524350643158, 'epoch': 29.85}
{'loss': 0.0178, 'grad_norm': 6.475841045379639, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.013947571627795696, 'loss_2': 0.00384521484375, 'loss_3': -16.337135314941406, 'loss_4': 0.5588153004646301, 'epoch': 29.86}
{'loss': 0.0243, 'grad_norm': 13.187191009521484, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.022418804466724396, 'loss_2': 0.0018758773803710938, 'loss_3': -16.18738555908203, 'loss_4': 1.5300853252410889, 'epoch': 29.87}
{'loss': 0.0153, 'grad_norm': 5.398359298706055, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.006648227106779814, 'loss_2': 0.00865936279296875, 'loss_3': -16.202438354492188, 'loss_4': 0.9008898138999939, 'epoch': 29.87}
{'loss': 0.0148, 'grad_norm': 6.855040073394775, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.007148999720811844, 'loss_2': 0.00766754150390625, 'loss_3': -16.253883361816406, 'loss_4': 1.094245195388794, 'epoch': 29.88}
{'loss': 0.0067, 'grad_norm': 4.870369911193848, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.004820988047868013, 'loss_2': 0.0019216537475585938, 'loss_3': -16.376420974731445, 'loss_4': 1.0661725997924805, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 11:32:57,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:32:57,682 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:24<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:33:05,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008213002234697342, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005955663044005632, 'eval_loss_2': 0.002257339656352997, 'eval_loss_3': -18.174781799316406, 'eval_loss_4': 0.9165096282958984, 'epoch': 29.88}
{'loss': 0.0251, 'grad_norm': 11.051359176635742, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.020311182364821434, 'loss_2': 0.0047454833984375, 'loss_3': -16.37126922607422, 'loss_4': 1.437945008277893, 'epoch': 29.89}
{'loss': 0.0144, 'grad_norm': 8.565145492553711, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.012349599972367287, 'loss_2': 0.0020904541015625, 'loss_3': -16.28331756591797, 'loss_4': 0.6485546231269836, 'epoch': 29.9}
{'loss': 0.0165, 'grad_norm': 7.155571460723877, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.015119976364076138, 'loss_2': 0.0013837814331054688, 'loss_3': -16.24401092529297, 'loss_4': 0.8023548126220703, 'epoch': 29.9}
{'loss': 0.0059, 'grad_norm': 4.815709114074707, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.0025686845183372498, 'loss_2': 0.00335693359375, 'loss_3': -16.32931900024414, 'loss_4': 1.2507407665252686, 'epoch': 29.91}
{'loss': 0.0035, 'grad_norm': 4.628579616546631, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.002218725858256221, 'loss_2': 0.0012655258178710938, 'loss_3': -16.21104621887207, 'loss_4': 0.9159582853317261, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 11:33:05,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:33:05,028 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:32<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:33:12,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008219609037041664, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005949387326836586, 'eval_loss_2': 0.002270221710205078, 'eval_loss_3': -18.1754207611084, 'eval_loss_4': 0.9165636897087097, 'epoch': 29.91}
{'loss': 0.0096, 'grad_norm': 4.528756618499756, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.003654471831396222, 'loss_2': 0.00594329833984375, 'loss_3': -16.374412536621094, 'loss_4': 1.3409065008163452, 'epoch': 29.92}
{'loss': 0.0071, 'grad_norm': 7.99358606338501, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.006751901004463434, 'loss_2': 0.0003082752227783203, 'loss_3': -16.159770965576172, 'loss_4': 0.5633838176727295, 'epoch': 29.92}
{'loss': 0.0052, 'grad_norm': 4.7879204750061035, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.003273509442806244, 'loss_2': 0.001903533935546875, 'loss_3': -16.235946655273438, 'loss_4': 0.9278372526168823, 'epoch': 29.93}
{'loss': 0.0123, 'grad_norm': 5.194242477416992, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.010508461855351925, 'loss_2': 0.00174713134765625, 'loss_3': -16.239242553710938, 'loss_4': 1.149293303489685, 'epoch': 29.94}
{'loss': 0.0045, 'grad_norm': 4.835623741149902, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.003755811369046569, 'loss_2': 0.0007171630859375, 'loss_3': -16.546161651611328, 'loss_4': 0.8583995699882507, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 11:33:12,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:33:12,383 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:06:39<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:33:19,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00821961835026741, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.463, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00595757644623518, 'eval_loss_2': 0.0022620409727096558, 'eval_loss_3': -18.1752872467041, 'eval_loss_4': 0.9161970019340515, 'epoch': 29.94}
{'loss': 0.0053, 'grad_norm': 4.53998327255249, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.002584123285487294, 'loss_2': 0.002681732177734375, 'loss_3': -16.574607849121094, 'loss_4': 1.1021952629089355, 'epoch': 29.95}
{'loss': 0.0068, 'grad_norm': 4.91749382019043, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.006282505579292774, 'loss_2': 0.0005130767822265625, 'loss_3': -16.353679656982422, 'loss_4': 0.9275929927825928, 'epoch': 29.95}
{'loss': 0.0098, 'grad_norm': 4.693482875823975, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.005028847139328718, 'loss_2': 0.00478363037109375, 'loss_3': -16.291534423828125, 'loss_4': 1.0106724500656128, 'epoch': 29.96}
{'loss': 0.004, 'grad_norm': 4.490179061889648, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.00330032198689878, 'loss_2': 0.0006647109985351562, 'loss_3': -16.34392738342285, 'loss_4': 0.7431350946426392, 'epoch': 29.97}
{'loss': 0.0079, 'grad_norm': 4.938075542449951, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.005417154170572758, 'loss_2': 0.00243377685546875, 'loss_3': -16.232948303222656, 'loss_4': 0.46884119510650635, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 11:33:19,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:33:19,745 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:46<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:33:26,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008238662034273148, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005948659963905811, 'eval_loss_2': 0.002290003001689911, 'eval_loss_3': -18.17531967163086, 'eval_loss_4': 0.91619873046875, 'epoch': 29.97}
{'loss': 0.0066, 'grad_norm': 4.581892490386963, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.004114080686122179, 'loss_2': 0.002468109130859375, 'loss_3': -16.28093719482422, 'loss_4': 0.8663721680641174, 'epoch': 29.98}
{'loss': 0.0163, 'grad_norm': 7.217251300811768, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.008967316709458828, 'loss_2': 0.0073089599609375, 'loss_3': -16.271747589111328, 'loss_4': 1.312089443206787, 'epoch': 29.98}
{'loss': 0.0104, 'grad_norm': 5.801048755645752, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.008374079130589962, 'loss_2': 0.002071380615234375, 'loss_3': -16.092227935791016, 'loss_4': 1.111588478088379, 'epoch': 29.99}
{'loss': 0.0062, 'grad_norm': 4.505188941955566, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.002900026272982359, 'loss_2': 0.003337860107421875, 'loss_3': -16.22769546508789, 'loss_4': 1.3688912391662598, 'epoch': 29.99}
{'loss': 0.0054, 'grad_norm': 6.401891231536865, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.0023678147699683905, 'loss_2': 0.00299072265625, 'loss_3': -16.40816307067871, 'loss_4': 0.5696883797645569, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 11:33:26,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:33:26,737 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:50<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 11:33:30,563 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.008254941552877426, 'eval_runtime': 3.8254, 'eval_samples_per_second': 267.683, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.005957689601927996, 'eval_loss_2': 0.0022972524166107178, 'eval_loss_3': -18.17548179626465, 'eval_loss_4': 0.9158905744552612, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 11:33:30,563 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/checkpoint-4640 (score: 0.006847674027085304).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:50<00:00,  1.47s/it]
{'train_runtime': 7611.3332, 'train_samples_per_second': 43.27, 'train_steps_per_second': 0.678, 'train_loss': 0.034439180305276366, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 11:33:30,649 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1
[INFO|configuration_utils.py:420] 2025-01-21 11:33:30,650 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 11:33:31,138 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:33:31,140 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:33:31,140 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg1/special_tokens_map.json
01/21/2025 11:33:31 - INFO - __main__ -   ***** Train results *****
01/21/2025 11:33:31 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:33:31 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 11:33:31 - INFO - __main__ -     train_loss = 0.034439180305276366
01/21/2025 11:33:31 - INFO - __main__ -     train_runtime = 7611.3332
01/21/2025 11:33:31 - INFO - __main__ -     train_samples_per_second = 43.27
01/21/2025 11:33:31 - INFO - __main__ -     train_steps_per_second = 0.678
01/21/2025 11:33:31 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 11:33:31,369 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:33:31,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:33:31,370 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.54it/s]
01/21/2025 11:33:35 - INFO - __main__ -   ***** Eval results *****
01/21/2025 11:33:35 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:33:35 - INFO - __main__ -     eval_loss = 0.006847674027085304
01/21/2025 11:33:35 - INFO - __main__ -     eval_loss_1 = 0.004284875467419624
01/21/2025 11:33:35 - INFO - __main__ -     eval_loss_2 = 0.00256279855966568
01/21/2025 11:33:35 - INFO - __main__ -     eval_loss_3 = -18.12482452392578
01/21/2025 11:33:35 - INFO - __main__ -     eval_loss_4 = 0.8499071598052979
01/21/2025 11:33:35 - INFO - __main__ -     eval_runtime = 3.8045
01/21/2025 11:33:35 - INFO - __main__ -     eval_samples_per_second = 269.155
01/21/2025 11:33:35 - INFO - __main__ -     eval_steps_per_second = 4.206
