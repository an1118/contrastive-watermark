  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 09:23:52,812 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:04:50,  1.32it/s][INFO|trainer.py:4226] 2025-01-21 09:23:56,906 >>
{'loss': 3.378, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.3011770248413086, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.7285, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.6451480388641357, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.7025, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.6336617469787598, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.2987, 'grad_norm': 129.12339782714844, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.232093334197998, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 3.652, 'grad_norm': 129.78456115722656, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.577155590057373, 'loss_2': 0.07489013671875, 'loss_3': -13.560209274291992, 'loss_4': 9.704458236694336, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:23:56,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:23:56,906 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:04:50,  1.32it/s][INFO|trainer.py:3910] 2025-01-21 09:24:00,689 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 09:24:00,691 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5/config.json                                                                                
{'eval_loss': 1.9082963466644287, 'eval_runtime': 3.7816, 'eval_samples_per_second': 270.786, 'eval_steps_per_second': 4.231, 'eval_loss_1': 1.8545072078704834, 'eval_loss_2': 0.05378913879394531, 'eval_loss_3': -18.017303466796875, 'eval_loss_4': 9.612262725830078, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:01,162 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:01,163 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:01,163 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:02,076 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10] due to args.save_total_limit
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:34:13,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 09:24:05,670 >>
{'loss': 3.4184, 'grad_norm': 126.85662078857422, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.365654945373535, 'loss_2': 0.052734375, 'loss_3': -14.302324295043945, 'loss_4': 10.264667510986328, 'epoch': 0.03}
{'loss': 3.0576, 'grad_norm': inf, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 2.9937705993652344, 'loss_2': 0.0638427734375, 'loss_3': -14.740663528442383, 'loss_4': 10.636629104614258, 'epoch': 0.04}
{'loss': 3.3646, 'grad_norm': 123.3438491821289, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.29644775390625, 'loss_2': 0.068115234375, 'loss_3': -14.596713066101074, 'loss_4': 10.244926452636719, 'epoch': 0.05}
{'loss': 3.0052, 'grad_norm': 127.38987731933594, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.936936378479004, 'loss_2': 0.06829833984375, 'loss_3': -14.911401748657227, 'loss_4': 10.224996566772461, 'epoch': 0.05}
{'loss': 2.7572, 'grad_norm': 128.53073120117188, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.705965042114258, 'loss_2': 0.051239013671875, 'loss_3': -15.002355575561523, 'loss_4': 10.394906997680664, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:05,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:05,670 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:34:13,  1.10s/it][INFO|trainer.py:3910] 2025-01-21 09:24:09,468 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 09:24:09,470 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10/config.json                                                                               
{'eval_loss': 1.2415575981140137, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 1.1936888694763184, 'eval_loss_2': 0.04786872863769531, 'eval_loss_3': -18.12565040588379, 'eval_loss_4': 9.346756935119629, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:09,957 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:09,959 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:09,959 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:10,844 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:24,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:24:14,437 >>
{'loss': 2.3401, 'grad_norm': 103.9306869506836, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.287198305130005, 'loss_2': 0.0528564453125, 'loss_3': -15.142072677612305, 'loss_4': 10.198959350585938, 'epoch': 0.06}
{'loss': 2.2048, 'grad_norm': 120.51155090332031, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.158036231994629, 'loss_2': 0.046783447265625, 'loss_3': -15.11359977722168, 'loss_4': 9.875909805297852, 'epoch': 0.07}
{'loss': 2.0264, 'grad_norm': 118.842041015625, 'learning_rate': 2.994767441860465e-05, 'loss_1': 1.9772506952285767, 'loss_2': 0.04913330078125, 'loss_3': -15.107490539550781, 'loss_4': 10.423160552978516, 'epoch': 0.08}
{'loss': 1.9782, 'grad_norm': 106.96827697753906, 'learning_rate': 2.994186046511628e-05, 'loss_1': 1.9274022579193115, 'loss_2': 0.05084228515625, 'loss_3': -15.264047622680664, 'loss_4': 10.004598617553711, 'epoch': 0.08}
{'loss': 1.6126, 'grad_norm': 110.10200500488281, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.5619986057281494, 'loss_2': 0.05059814453125, 'loss_3': -15.443215370178223, 'loss_4': 10.904817581176758, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:14,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:14,437 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:24,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:24:18,207 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 09:24:18,208 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15/config.json                                                                               
{'eval_loss': 0.5668260455131531, 'eval_runtime': 3.7684, 'eval_samples_per_second': 271.736, 'eval_steps_per_second': 4.246, 'eval_loss_1': 0.5141394138336182, 'eval_loss_2': 0.05268669128417969, 'eval_loss_3': -18.139501571655273, 'eval_loss_4': 10.697002410888672, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:18,656 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:18,657 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:18,657 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:19,486 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:38:24,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:24:23,103 >>
{'loss': 1.6772, 'grad_norm': 126.5543212890625, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.6189427375793457, 'loss_2': 0.05828857421875, 'loss_3': -15.282983779907227, 'loss_4': 10.77716064453125, 'epoch': 0.09}
{'loss': 1.7851, 'grad_norm': 119.526123046875, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.7351319789886475, 'loss_2': 0.04998779296875, 'loss_3': -15.044435501098633, 'loss_4': 11.241596221923828, 'epoch': 0.1}
{'loss': 1.5007, 'grad_norm': 110.57063293457031, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.4450669288635254, 'loss_2': 0.055633544921875, 'loss_3': -15.083189010620117, 'loss_4': 11.25296688079834, 'epoch': 0.1}
{'loss': 1.303, 'grad_norm': 102.44921112060547, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.2633273601531982, 'loss_2': 0.039703369140625, 'loss_3': -15.005127906799316, 'loss_4': 10.3289155960083, 'epoch': 0.11}
{'loss': 0.9329, 'grad_norm': 99.11864471435547, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 0.8838775157928467, 'loss_2': 0.04901123046875, 'loss_3': -15.27391242980957, 'loss_4': 10.205668449401855, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:23,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:23,104 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:38:24,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:24:26,878 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 09:24:26,879 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20/config.json                                                                               
{'eval_loss': 0.246698260307312, 'eval_runtime': 3.773, 'eval_samples_per_second': 271.406, 'eval_steps_per_second': 4.241, 'eval_loss_1': 0.2026003748178482, 'eval_loss_2': 0.044097900390625, 'eval_loss_3': -18.144624710083008, 'eval_loss_4': 10.763459205627441, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:27,318 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:27,319 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:27,320 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:28,193 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:38:34,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:24:31,801 >>
{'loss': 0.7817, 'grad_norm': 90.48993682861328, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 0.7332488298416138, 'loss_2': 0.0484619140625, 'loss_3': -15.018789291381836, 'loss_4': 10.02407169342041, 'epoch': 0.12}
{'loss': 0.8069, 'grad_norm': 87.13743591308594, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 0.7635306119918823, 'loss_2': 0.0433349609375, 'loss_3': -14.75692081451416, 'loss_4': 10.482934951782227, 'epoch': 0.13}
{'loss': 0.4885, 'grad_norm': 64.37090301513672, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.45417457818984985, 'loss_2': 0.0343017578125, 'loss_3': -15.042473793029785, 'loss_4': 9.9366455078125, 'epoch': 0.13}
{'loss': 0.5699, 'grad_norm': 68.1122817993164, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.5456994771957397, 'loss_2': 0.0242156982421875, 'loss_3': -14.866522789001465, 'loss_4': 10.214408874511719, 'epoch': 0.14}
{'loss': 0.4725, 'grad_norm': 69.45096588134766, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.44326162338256836, 'loss_2': 0.029266357421875, 'loss_3': -14.967238426208496, 'loss_4': 10.304285049438477, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:31,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:31,801 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:42<1:38:34,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:24:35,576 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 09:24:35,578 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25/config.json                                                                               
{'eval_loss': 0.12170545011758804, 'eval_runtime': 3.7745, 'eval_samples_per_second': 271.293, 'eval_steps_per_second': 4.239, 'eval_loss_1': 0.0969480648636818, 'eval_loss_2': 0.02475738525390625, 'eval_loss_3': -18.156044006347656, 'eval_loss_4': 10.717419624328613, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:36,045 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:36,046 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:36,047 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:36,937 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:38:53,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:24:40,550 >>
{'loss': 0.4581, 'grad_norm': 64.7083969116211, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.4278160035610199, 'loss_2': 0.0302734375, 'loss_3': -14.920637130737305, 'loss_4': 10.597723007202148, 'epoch': 0.15}
{'loss': 0.5044, 'grad_norm': 68.13748168945312, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.48675572872161865, 'loss_2': 0.017608642578125, 'loss_3': -14.683067321777344, 'loss_4': 10.368936538696289, 'epoch': 0.16}
{'loss': 0.3664, 'grad_norm': 52.87605285644531, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.3521146774291992, 'loss_2': 0.014312744140625, 'loss_3': -14.696325302124023, 'loss_4': 9.27304744720459, 'epoch': 0.16}
{'loss': 0.4232, 'grad_norm': 59.459625244140625, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.4093794524669647, 'loss_2': 0.0138397216796875, 'loss_3': -14.855476379394531, 'loss_4': 9.976125717163086, 'epoch': 0.17}
{'loss': 0.357, 'grad_norm': 58.93872833251953, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.34537774324417114, 'loss_2': 0.011627197265625, 'loss_3': -14.796941757202148, 'loss_4': 10.626465797424316, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:40,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:40,550 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:51<1:38:53,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 09:24:44,341 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 09:24:44,342 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30/config.json                                                                               
{'eval_loss': 0.08431068807840347, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.215, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.07485775649547577, 'eval_loss_2': 0.0094529390335083, 'eval_loss_3': -18.198488235473633, 'eval_loss_4': 11.182608604431152, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:44,798 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:44,799 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:44,799 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:45,630 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:56<1:38:27,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:24:49,241 >>
{'loss': 0.4893, 'grad_norm': 75.05548095703125, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.48773378133773804, 'loss_2': 0.00153350830078125, 'loss_3': -14.519877433776855, 'loss_4': 11.149439811706543, 'epoch': 0.18}
{'loss': 0.3708, 'grad_norm': 59.55872344970703, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.35502856969833374, 'loss_2': 0.015777587890625, 'loss_3': -14.625619888305664, 'loss_4': 10.33344841003418, 'epoch': 0.19}
{'loss': 0.4151, 'grad_norm': 59.65693664550781, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.39967942237854004, 'loss_2': 0.01538848876953125, 'loss_3': -14.87908935546875, 'loss_4': 11.230271339416504, 'epoch': 0.19}
{'loss': 0.2619, 'grad_norm': 53.81998825073242, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.2506037950515747, 'loss_2': 0.01129150390625, 'loss_3': -14.797183990478516, 'loss_4': 10.140043258666992, 'epoch': 0.2}
{'loss': 0.4139, 'grad_norm': 63.8877067565918, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.41014933586120605, 'loss_2': 0.00372314453125, 'loss_3': -14.552809715270996, 'loss_4': 10.066102981567383, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:49,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:49,242 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [01:00<1:38:27,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:24:53,022 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 09:24:53,023 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35/config.json                                                                               
{'eval_loss': 0.056567780673503876, 'eval_runtime': 3.779, 'eval_samples_per_second': 270.974, 'eval_steps_per_second': 4.234, 'eval_loss_1': 0.051655013114213943, 'eval_loss_2': 0.004912763833999634, 'eval_loss_3': -18.200679779052734, 'eval_loss_4': 9.77253532409668, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 09:24:53,488 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:24:53,489 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:24:53,490 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:24:54,350 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:05<1:38:28,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:24:57,961 >>
{'loss': 0.3545, 'grad_norm': 57.97339630126953, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.3451986014842987, 'loss_2': 0.00928497314453125, 'loss_3': -14.676074028015137, 'loss_4': 9.807854652404785, 'epoch': 0.21}
{'loss': 0.2595, 'grad_norm': 47.03554153442383, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.25709599256515503, 'loss_2': 0.002399444580078125, 'loss_3': -14.748773574829102, 'loss_4': 9.058307647705078, 'epoch': 0.22}
{'loss': 0.2154, 'grad_norm': 39.62717056274414, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.2095279097557068, 'loss_2': 0.00583648681640625, 'loss_3': -14.58880615234375, 'loss_4': 8.827125549316406, 'epoch': 0.22}
{'loss': 0.2231, 'grad_norm': 37.112857818603516, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.2200588583946228, 'loss_2': 0.003025054931640625, 'loss_3': -14.66777229309082, 'loss_4': 6.961215972900391, 'epoch': 0.23}
{'loss': 0.2935, 'grad_norm': 51.724769592285156, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.29205596446990967, 'loss_2': 0.0014772415161132812, 'loss_3': -14.672749519348145, 'loss_4': 7.517678260803223, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:24:57,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:24:57,962 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:12<1:29:36,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:25:05,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06186595931649208, 'eval_runtime': 3.7709, 'eval_samples_per_second': 271.556, 'eval_steps_per_second': 4.243, 'eval_loss_1': 0.05677453428506851, 'eval_loss_2': 0.005091428756713867, 'eval_loss_3': -18.023223876953125, 'eval_loss_4': 7.106073379516602, 'epoch': 0.23}
{'loss': 0.2592, 'grad_norm': 47.05378341674805, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.25776156783103943, 'loss_2': 0.0013914108276367188, 'loss_3': -14.62077522277832, 'loss_4': 6.956138610839844, 'epoch': 0.24}
{'loss': 0.241, 'grad_norm': 38.66752243041992, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.23346595466136932, 'loss_2': 0.00754547119140625, 'loss_3': -14.614142417907715, 'loss_4': 5.943268775939941, 'epoch': 0.24}
{'loss': 0.289, 'grad_norm': 52.4703254699707, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.2878359854221344, 'loss_2': 0.0011806488037109375, 'loss_3': -14.430564880371094, 'loss_4': 5.804604530334473, 'epoch': 0.25}
{'loss': 0.3797, 'grad_norm': 42.50879669189453, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.37828996777534485, 'loss_2': 0.0014476776123046875, 'loss_3': -14.530969619750977, 'loss_4': 6.571638107299805, 'epoch': 0.26}
{'loss': 0.2458, 'grad_norm': 40.328895568847656, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.2346079796552658, 'loss_2': 0.0111541748046875, 'loss_3': -14.406539916992188, 'loss_4': 6.494807243347168, 'epoch': 0.26}
[INFO|trainer.py:4228] 2025-01-21 09:25:05,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:05,252 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:16<1:29:36,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 09:25:09,038 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 09:25:09,039 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45/config.json                                                                               
{'eval_loss': 0.04889782518148422, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.573, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.04319443181157112, 'eval_loss_2': 0.005703389644622803, 'eval_loss_3': -18.04854965209961, 'eval_loss_4': 6.975347518920898, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:09,530 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:09,532 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:09,532 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:10,409 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-35] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:21<1:37:09,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:25:14,028 >>
{'loss': 0.165, 'grad_norm': 33.13883972167969, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.15646293759346008, 'loss_2': 0.0085601806640625, 'loss_3': -14.844030380249023, 'loss_4': 6.877708435058594, 'epoch': 0.27}
{'loss': 0.1204, 'grad_norm': 21.27886962890625, 'learning_rate': 2.975e-05, 'loss_1': 0.10774124413728714, 'loss_2': 0.01264190673828125, 'loss_3': -14.59219741821289, 'loss_4': 5.731141090393066, 'epoch': 0.27}
{'loss': 0.2902, 'grad_norm': 49.020469665527344, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.28255969285964966, 'loss_2': 0.00768280029296875, 'loss_3': -14.678696632385254, 'loss_4': 6.675072193145752, 'epoch': 0.28}
{'loss': 0.1602, 'grad_norm': 27.16230583190918, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.1578601896762848, 'loss_2': 0.0023193359375, 'loss_3': -14.704987525939941, 'loss_4': 6.766358852386475, 'epoch': 0.28}
{'loss': 0.1717, 'grad_norm': 34.46825408935547, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.16334614157676697, 'loss_2': 0.0083770751953125, 'loss_3': -14.688777923583984, 'loss_4': 6.783307075500488, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:14,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:14,028 >>   Batch size = 64
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:25<1:37:09,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:25:17,826 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50
[INFO|configuration_utils.py:420] 2025-01-21 09:25:17,827 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50/config.json                                                                               
{'eval_loss': 0.039922747761011124, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.758, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.035282935947179794, 'eval_loss_2': 0.004639811813831329, 'eval_loss_3': -18.136489868164062, 'eval_loss_4': 7.351378440856934, 'epoch': 0.29}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:18,306 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:18,308 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:18,308 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:19,178 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-45] due to args.save_total_limit
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:30<1:38:19,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:25:22,790 >>
{'loss': 0.2215, 'grad_norm': 32.90370559692383, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.21825498342514038, 'loss_2': 0.003238677978515625, 'loss_3': -14.766336441040039, 'loss_4': 7.263132572174072, 'epoch': 0.3}
{'loss': 0.2216, 'grad_norm': 41.92571258544922, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.2197902500629425, 'loss_2': 0.0017709732055664062, 'loss_3': -14.60805892944336, 'loss_4': 7.302988052368164, 'epoch': 0.3}
{'loss': 0.1468, 'grad_norm': 30.12297248840332, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.14568151533603668, 'loss_2': 0.00116729736328125, 'loss_3': -14.798852920532227, 'loss_4': 7.203221797943115, 'epoch': 0.31}
{'loss': 0.1744, 'grad_norm': 30.23459815979004, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.16578726470470428, 'loss_2': 0.00864410400390625, 'loss_3': -14.541558265686035, 'loss_4': 6.9949951171875, 'epoch': 0.31}
{'loss': 0.2371, 'grad_norm': 37.68388366699219, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.2170117199420929, 'loss_2': 0.020111083984375, 'loss_3': -14.592721939086914, 'loss_4': 6.859740257263184, 'epoch': 0.32}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:22,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:22,790 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:37<1:29:42,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:25:30,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04308682680130005, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.004, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.029574215412139893, 'eval_loss_2': 0.013512611389160156, 'eval_loss_3': -18.13298797607422, 'eval_loss_4': 7.570971965789795, 'epoch': 0.32}
{'loss': 0.1568, 'grad_norm': 36.34852981567383, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.14811785519123077, 'loss_2': 0.0087127685546875, 'loss_3': -14.763933181762695, 'loss_4': 6.777474403381348, 'epoch': 0.33}
{'loss': 0.2362, 'grad_norm': 46.42679214477539, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.21856804192066193, 'loss_2': 0.0176544189453125, 'loss_3': -14.77077865600586, 'loss_4': 7.620060920715332, 'epoch': 0.33}
{'loss': 0.1418, 'grad_norm': 27.641830444335938, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.1283593475818634, 'loss_2': 0.0134735107421875, 'loss_3': -14.637076377868652, 'loss_4': 7.395505905151367, 'epoch': 0.34}
{'loss': 0.1693, 'grad_norm': 31.632240295410156, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.16568298637866974, 'loss_2': 0.003597259521484375, 'loss_3': -14.59101676940918, 'loss_4': 7.443161487579346, 'epoch': 0.34}
{'loss': 0.1058, 'grad_norm': 26.54877471923828, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.10134585201740265, 'loss_2': 0.00449371337890625, 'loss_3': -14.715282440185547, 'loss_4': 7.1701226234436035, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 09:25:30,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:30,118 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:41<1:29:42,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 09:25:33,913 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 09:25:33,915 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60/config.json                                                                               
{'eval_loss': 0.03187485411763191, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.933, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.027060944586992264, 'eval_loss_2': 0.0048139095306396484, 'eval_loss_3': -18.153108596801758, 'eval_loss_4': 8.050931930541992, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:34,401 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:34,402 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:34,403 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:35,264 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-50] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:46<1:37:11,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:25:38,903 >>
{'loss': 0.1983, 'grad_norm': 41.86025619506836, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.1935095340013504, 'loss_2': 0.00482177734375, 'loss_3': -14.481895446777344, 'loss_4': 7.561942100524902, 'epoch': 0.35}
{'loss': 0.1759, 'grad_norm': 37.900665283203125, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.17483504116535187, 'loss_2': 0.0010852813720703125, 'loss_3': -14.561687469482422, 'loss_4': 7.63393497467041, 'epoch': 0.36}
{'loss': 0.1407, 'grad_norm': 30.51584815979004, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.13716420531272888, 'loss_2': 0.0035152435302734375, 'loss_3': -14.616168975830078, 'loss_4': 7.118436813354492, 'epoch': 0.37}
{'loss': 0.1375, 'grad_norm': 36.553077697753906, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.13645988702774048, 'loss_2': 0.001007080078125, 'loss_3': -14.583622932434082, 'loss_4': 7.365008354187012, 'epoch': 0.37}
{'loss': 0.1369, 'grad_norm': 31.10097885131836, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.13497255742549896, 'loss_2': 0.0019245147705078125, 'loss_3': -14.392169952392578, 'loss_4': 7.234429359436035, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:38,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:38,903 >>   Batch size = 64
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:49<1:37:11,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:25:42,701 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65
[INFO|configuration_utils.py:420] 2025-01-21 09:25:42,702 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65/config.json                                                                               
{'eval_loss': 0.026757288724184036, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.757, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.022829391062259674, 'eval_loss_2': 0.003927893936634064, 'eval_loss_3': -18.123960494995117, 'eval_loss_4': 7.424991130828857, 'epoch': 0.38}
[INFO|modeling_utils.py:2988] 2025-01-21 09:25:43,195 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:25:43,196 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:25:43,196 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:25:44,117 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-60] due to args.save_total_limit
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:54<1:38:40,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:25:47,752 >>
{'loss': 0.1012, 'grad_norm': 24.948637008666992, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.09672588109970093, 'loss_2': 0.00445556640625, 'loss_3': -14.641483306884766, 'loss_4': 7.187828540802002, 'epoch': 0.38}
{'loss': 0.1104, 'grad_norm': 28.027671813964844, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.10502123832702637, 'loss_2': 0.00539398193359375, 'loss_3': -14.751934051513672, 'loss_4': 7.043661117553711, 'epoch': 0.39}
{'loss': 0.2074, 'grad_norm': 35.254371643066406, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.20432817935943604, 'loss_2': 0.003040313720703125, 'loss_3': -14.531867980957031, 'loss_4': 6.673075199127197, 'epoch': 0.4}
{'loss': 0.0797, 'grad_norm': 35.64836502075195, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.07918212562799454, 'loss_2': 0.0005192756652832031, 'loss_3': -14.595056533813477, 'loss_4': 7.062833309173584, 'epoch': 0.4}
{'loss': 0.1022, 'grad_norm': 19.8377685546875, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.09337461739778519, 'loss_2': 0.00885009765625, 'loss_3': -14.665160179138184, 'loss_4': 4.970572471618652, 'epoch': 0.41}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:25:47,752 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:47,752 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:02<1:29:49,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:25:55,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031171932816505432, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.534, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.023481445387005806, 'eval_loss_2': 0.007690489292144775, 'eval_loss_3': -18.058055877685547, 'eval_loss_4': 5.783637046813965, 'epoch': 0.41}
{'loss': 0.1072, 'grad_norm': 28.147199630737305, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.10461356490850449, 'loss_2': 0.0025959014892578125, 'loss_3': -14.555732727050781, 'loss_4': 5.24052619934082, 'epoch': 0.41}
{'loss': 0.1177, 'grad_norm': 34.92208480834961, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.11620911955833435, 'loss_2': 0.0014705657958984375, 'loss_3': -14.566802978515625, 'loss_4': 5.658632278442383, 'epoch': 0.42}
{'loss': 0.1159, 'grad_norm': 21.87392234802246, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.11170949786901474, 'loss_2': 0.0042266845703125, 'loss_3': -14.853757858276367, 'loss_4': 6.416443824768066, 'epoch': 0.42}
{'loss': 0.0973, 'grad_norm': 20.48349380493164, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.0932762548327446, 'loss_2': 0.004024505615234375, 'loss_3': -14.746898651123047, 'loss_4': 4.417482376098633, 'epoch': 0.43}
{'loss': 0.0941, 'grad_norm': 22.54853057861328, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.09064635634422302, 'loss_2': 0.00347137451171875, 'loss_3': -14.858003616333008, 'loss_4': 4.921509742736816, 'epoch': 0.44}
[INFO|trainer.py:4228] 2025-01-21 09:25:55,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:25:55,105 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:28:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:02,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0395682193338871, 'eval_runtime': 3.8243, 'eval_samples_per_second': 267.763, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.03487001359462738, 'eval_loss_2': 0.004698202013969421, 'eval_loss_3': -18.001113891601562, 'eval_loss_4': 5.128297328948975, 'epoch': 0.44}
{'loss': 0.0931, 'grad_norm': 18.95436668395996, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.09138265997171402, 'loss_2': 0.0017528533935546875, 'loss_3': -14.776256561279297, 'loss_4': 6.048242568969727, 'epoch': 0.44}
{'loss': 0.1173, 'grad_norm': 25.47669219970703, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.11582101881504059, 'loss_2': 0.0014934539794921875, 'loss_3': -14.503351211547852, 'loss_4': 3.849285125732422, 'epoch': 0.45}
{'loss': 0.1306, 'grad_norm': 31.91535186767578, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.12300076335668564, 'loss_2': 0.007617950439453125, 'loss_3': -14.73446273803711, 'loss_4': 4.814667701721191, 'epoch': 0.45}
{'loss': 0.1688, 'grad_norm': 34.35564422607422, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.16666939854621887, 'loss_2': 0.00212860107421875, 'loss_3': -14.923030853271484, 'loss_4': 5.530073165893555, 'epoch': 0.46}
{'loss': 0.0971, 'grad_norm': 24.592884063720703, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.09526418894529343, 'loss_2': 0.001880645751953125, 'loss_3': -14.66285514831543, 'loss_4': 4.60056209564209, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 09:26:02,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:02,477 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:17<1:28:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:09,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05377298593521118, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.272, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.04651838168501854, 'eval_loss_2': 0.007254600524902344, 'eval_loss_3': -17.938945770263672, 'eval_loss_4': 5.241002082824707, 'epoch': 0.47}
{'loss': 0.1347, 'grad_norm': 26.778175354003906, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.12814298272132874, 'loss_2': 0.0065155029296875, 'loss_3': -14.796870231628418, 'loss_4': 5.332355976104736, 'epoch': 0.47}
{'loss': 0.1573, 'grad_norm': 39.18419647216797, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.15600667893886566, 'loss_2': 0.0012760162353515625, 'loss_3': -14.531305313110352, 'loss_4': 5.335111141204834, 'epoch': 0.48}
{'loss': 0.1561, 'grad_norm': 25.15848159790039, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.15354007482528687, 'loss_2': 0.0025177001953125, 'loss_3': -14.91096019744873, 'loss_4': 5.580111503601074, 'epoch': 0.48}
{'loss': 0.1463, 'grad_norm': 29.917715072631836, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.1423381268978119, 'loss_2': 0.00400543212890625, 'loss_3': -14.922736167907715, 'loss_4': 5.8151655197143555, 'epoch': 0.49}
{'loss': 0.162, 'grad_norm': 52.862525939941406, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.1576486974954605, 'loss_2': 0.0043792724609375, 'loss_3': -14.990278244018555, 'loss_4': 6.907611846923828, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 09:26:09,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:09,843 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:27:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:17,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06399565935134888, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.05541509389877319, 'eval_loss_2': 0.008580565452575684, 'eval_loss_3': -17.88408851623535, 'eval_loss_4': 6.470579147338867, 'epoch': 0.49}
{'loss': 0.2812, 'grad_norm': 53.773658752441406, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.27803996205329895, 'loss_2': 0.003131866455078125, 'loss_3': -14.621552467346191, 'loss_4': 7.002803802490234, 'epoch': 0.5}
{'loss': 0.1596, 'grad_norm': 35.71406936645508, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.1477746218442917, 'loss_2': 0.0118255615234375, 'loss_3': -14.87640380859375, 'loss_4': 6.541876792907715, 'epoch': 0.51}
{'loss': 0.1103, 'grad_norm': 20.476057052612305, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.09186562895774841, 'loss_2': 0.0183868408203125, 'loss_3': -14.803890228271484, 'loss_4': 5.9490966796875, 'epoch': 0.51}
{'loss': 0.1334, 'grad_norm': 35.049407958984375, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.13092899322509766, 'loss_2': 0.00246429443359375, 'loss_3': -15.005243301391602, 'loss_4': 6.790637016296387, 'epoch': 0.52}
{'loss': 0.0656, 'grad_norm': 21.3243465423584, 'learning_rate': 2.95e-05, 'loss_1': 0.05753612145781517, 'loss_2': 0.0081024169921875, 'loss_3': -14.913605690002441, 'loss_4': 6.119030475616455, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 09:26:17,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:17,194 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:31<1:27:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:24,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033922623842954636, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.030270298942923546, 'eval_loss_2': 0.003652334213256836, 'eval_loss_3': -18.038379669189453, 'eval_loss_4': 6.300774097442627, 'epoch': 0.52}
{'loss': 0.1032, 'grad_norm': 27.129154205322266, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.10174929350614548, 'loss_2': 0.0014896392822265625, 'loss_3': -14.996929168701172, 'loss_4': 6.326706886291504, 'epoch': 0.53}
{'loss': 0.1175, 'grad_norm': 26.01639747619629, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.11286616325378418, 'loss_2': 0.004642486572265625, 'loss_3': -14.916065216064453, 'loss_4': 6.843541145324707, 'epoch': 0.53}
{'loss': 0.0934, 'grad_norm': 25.49152374267578, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.08799193054437637, 'loss_2': 0.00537872314453125, 'loss_3': -15.10076904296875, 'loss_4': 6.190737724304199, 'epoch': 0.54}
{'loss': 0.067, 'grad_norm': 18.15706443786621, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.06643564254045486, 'loss_2': 0.0005540847778320312, 'loss_3': -14.95348834991455, 'loss_4': 5.832269191741943, 'epoch': 0.55}
{'loss': 0.0971, 'grad_norm': 27.297683715820312, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.08223297446966171, 'loss_2': 0.0148468017578125, 'loss_3': -14.82130241394043, 'loss_4': 5.976656913757324, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 09:26:24,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:24,557 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:35<1:27:46,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:26:28,391 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95
[INFO|configuration_utils.py:420] 2025-01-21 09:26:28,392 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95/config.json                                                                               
{'eval_loss': 0.02460338920354843, 'eval_runtime': 3.8327, 'eval_samples_per_second': 267.176, 'eval_steps_per_second': 4.175, 'eval_loss_1': 0.01950438693165779, 'eval_loss_2': 0.005098998546600342, 'eval_loss_3': -18.113197326660156, 'eval_loss_4': 6.180642127990723, 'epoch': 0.55}
[INFO|modeling_utils.py:2988] 2025-01-21 09:26:28,862 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:26:28,863 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:26:28,863 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:26:29,769 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-65] due to args.save_total_limit
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:40<1:36:41,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:26:33,400 >>
{'loss': 0.0961, 'grad_norm': 24.601221084594727, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.08692620694637299, 'loss_2': 0.00919342041015625, 'loss_3': -14.774803161621094, 'loss_4': 5.5769548416137695, 'epoch': 0.56}
{'loss': 0.1288, 'grad_norm': 29.856143951416016, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.12285509705543518, 'loss_2': 0.00589752197265625, 'loss_3': -14.761268615722656, 'loss_4': 5.757668495178223, 'epoch': 0.56}
{'loss': 0.0953, 'grad_norm': 21.606801986694336, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.09284015744924545, 'loss_2': 0.0024662017822265625, 'loss_3': -14.864866256713867, 'loss_4': 5.913132190704346, 'epoch': 0.57}
{'loss': 0.1283, 'grad_norm': 33.79927444458008, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.11733686178922653, 'loss_2': 0.01099395751953125, 'loss_3': -14.668018341064453, 'loss_4': 6.333576679229736, 'epoch': 0.58}
{'loss': 0.1119, 'grad_norm': 21.360437393188477, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.09563574939966202, 'loss_2': 0.016265869140625, 'loss_3': -15.041027069091797, 'loss_4': 6.691295146942139, 'epoch': 0.58}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:26:33,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:33,400 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:44<1:36:41,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 09:26:37,236 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100
[INFO|configuration_utils.py:420] 2025-01-21 09:26:37,237 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100/config.json                                                                              
{'eval_loss': 0.023198051378130913, 'eval_runtime': 3.8347, 'eval_samples_per_second': 267.038, 'eval_steps_per_second': 4.172, 'eval_loss_1': 0.0175657719373703, 'eval_loss_2': 0.005632281303405762, 'eval_loss_3': -18.141164779663086, 'eval_loss_4': 6.191554069519043, 'epoch': 0.58}
[INFO|modeling_utils.py:2988] 2025-01-21 09:26:37,698 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:26:37,699 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:26:37,699 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:26:38,564 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-95] due to args.save_total_limit
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:49<1:38:02,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 09:26:42,218 >>
{'loss': 0.0993, 'grad_norm': 23.3079833984375, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.09527131170034409, 'loss_2': 0.003997802734375, 'loss_3': -15.006038665771484, 'loss_4': 6.7982707023620605, 'epoch': 0.59}
{'loss': 0.1337, 'grad_norm': 23.845539093017578, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.12527883052825928, 'loss_2': 0.00838470458984375, 'loss_3': -14.918824195861816, 'loss_4': 6.524956703186035, 'epoch': 0.59}
{'loss': 0.121, 'grad_norm': 25.958499908447266, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.10986139625310898, 'loss_2': 0.0111541748046875, 'loss_3': -14.987302780151367, 'loss_4': 7.381865501403809, 'epoch': 0.6}
{'loss': 0.0924, 'grad_norm': 20.62729263305664, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.08767847716808319, 'loss_2': 0.004680633544921875, 'loss_3': -15.065850257873535, 'loss_4': 7.001558780670166, 'epoch': 0.6}
{'loss': 0.1266, 'grad_norm': 35.3056640625, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.12123409658670425, 'loss_2': 0.00536346435546875, 'loss_3': -14.951560974121094, 'loss_4': 6.910093784332275, 'epoch': 0.61}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:26:42,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:42,218 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:56<1:29:19,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:26:49,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02705303207039833, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.403, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.017300516366958618, 'eval_loss_2': 0.009752511978149414, 'eval_loss_3': -18.14616584777832, 'eval_loss_4': 6.0271148681640625, 'epoch': 0.61}
{'loss': 0.0865, 'grad_norm': 21.949655532836914, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.07940638065338135, 'loss_2': 0.007110595703125, 'loss_3': -15.04171371459961, 'loss_4': 6.269379615783691, 'epoch': 0.62}
{'loss': 0.1106, 'grad_norm': 23.919681549072266, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.10167104750871658, 'loss_2': 0.0088958740234375, 'loss_3': -14.895709991455078, 'loss_4': 6.350762844085693, 'epoch': 0.62}
{'loss': 0.1582, 'grad_norm': 41.40062713623047, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.1518290638923645, 'loss_2': 0.00640106201171875, 'loss_3': -15.088229179382324, 'loss_4': 6.878505706787109, 'epoch': 0.63}
{'loss': 0.0993, 'grad_norm': 22.93925666809082, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.09544496983289719, 'loss_2': 0.003826141357421875, 'loss_3': -15.291267395019531, 'loss_4': 5.986776828765869, 'epoch': 0.63}
{'loss': 0.0925, 'grad_norm': 16.78119468688965, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.0796450600028038, 'loss_2': 0.0128936767578125, 'loss_3': -14.991060256958008, 'loss_4': 5.7343902587890625, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 09:26:49,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:49,585 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:04<1:27:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:26:56,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027813050895929337, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.021997544914484024, 'eval_loss_2': 0.0058155059814453125, 'eval_loss_3': -18.078563690185547, 'eval_loss_4': 5.571684837341309, 'epoch': 0.64}
{'loss': 0.1423, 'grad_norm': 39.802677154541016, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.14191563427448273, 'loss_2': 0.0003571510314941406, 'loss_3': -14.949941635131836, 'loss_4': 5.906801223754883, 'epoch': 0.65}
{'loss': 0.1355, 'grad_norm': 36.499717712402344, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.13523633778095245, 'loss_2': 0.000247955322265625, 'loss_3': -15.068203926086426, 'loss_4': 6.161923408508301, 'epoch': 0.65}
{'loss': 0.1224, 'grad_norm': 32.0413932800293, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.10637375712394714, 'loss_2': 0.016021728515625, 'loss_3': -14.969953536987305, 'loss_4': 5.404261589050293, 'epoch': 0.66}
{'loss': 0.0712, 'grad_norm': 15.685754776000977, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.0668591558933258, 'loss_2': 0.0043792724609375, 'loss_3': -15.104079246520996, 'loss_4': 5.6554274559021, 'epoch': 0.66}
{'loss': 0.1173, 'grad_norm': 34.67578125, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.10751886665821075, 'loss_2': 0.00978851318359375, 'loss_3': -14.957109451293945, 'loss_4': 5.406927108764648, 'epoch': 0.67}
[INFO|trainer.py:4228] 2025-01-21 09:26:56,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:26:56,945 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:11<1:27:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:04,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0319218635559082, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.391, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.022652149200439453, 'eval_loss_2': 0.00926971435546875, 'eval_loss_3': -18.093887329101562, 'eval_loss_4': 5.99643087387085, 'epoch': 0.67}
{'loss': 0.1058, 'grad_norm': 27.69710922241211, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.08979672938585281, 'loss_2': 0.016021728515625, 'loss_3': -15.08549690246582, 'loss_4': 6.56082820892334, 'epoch': 0.67}
{'loss': 0.0857, 'grad_norm': 14.453542709350586, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.06718075275421143, 'loss_2': 0.0185089111328125, 'loss_3': -15.170434951782227, 'loss_4': 6.06932258605957, 'epoch': 0.68}
{'loss': 0.0975, 'grad_norm': 20.913949966430664, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.08541476726531982, 'loss_2': 0.0120697021484375, 'loss_3': -15.008927345275879, 'loss_4': 6.308900356292725, 'epoch': 0.69}
{'loss': 0.1196, 'grad_norm': 24.6198787689209, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.11205744743347168, 'loss_2': 0.00759124755859375, 'loss_3': -14.866912841796875, 'loss_4': 6.87408971786499, 'epoch': 0.69}
{'loss': 0.0963, 'grad_norm': 22.321449279785156, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.08827963471412659, 'loss_2': 0.0080413818359375, 'loss_3': -15.172945022583008, 'loss_4': 6.326427936553955, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 09:27:04,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:04,306 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:18<1:27:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:11,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02480217069387436, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02037890814244747, 'eval_loss_2': 0.004423260688781738, 'eval_loss_3': -18.133289337158203, 'eval_loss_4': 6.4872941970825195, 'epoch': 0.7}
{'loss': 0.1167, 'grad_norm': 26.338497161865234, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.1122412458062172, 'loss_2': 0.0044097900390625, 'loss_3': -15.08131217956543, 'loss_4': 6.3340349197387695, 'epoch': 0.7}
{'loss': 0.1498, 'grad_norm': 26.401960372924805, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.14726728200912476, 'loss_2': 0.0024890899658203125, 'loss_3': -14.956903457641602, 'loss_4': 6.6809844970703125, 'epoch': 0.71}
{'loss': 0.0794, 'grad_norm': 14.616118431091309, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.07788457721471786, 'loss_2': 0.0015010833740234375, 'loss_3': -14.920389175415039, 'loss_4': 6.386772632598877, 'epoch': 0.72}
{'loss': 0.0877, 'grad_norm': 23.80103874206543, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.0811552107334137, 'loss_2': 0.00652313232421875, 'loss_3': -15.141165733337402, 'loss_4': 5.6094489097595215, 'epoch': 0.72}
{'loss': 0.0928, 'grad_norm': 15.277444839477539, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.07493770122528076, 'loss_2': 0.017852783203125, 'loss_3': -15.072507858276367, 'loss_4': 5.711501598358154, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 09:27:11,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:11,660 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:26<1:26:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:19,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04405396059155464, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.019878316670656204, 'eval_loss_2': 0.024175643920898438, 'eval_loss_3': -18.079708099365234, 'eval_loss_4': 5.813414096832275, 'epoch': 0.73}
{'loss': 0.0807, 'grad_norm': 14.584657669067383, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.057758230715990067, 'loss_2': 0.0229644775390625, 'loss_3': -15.07414436340332, 'loss_4': 5.616762161254883, 'epoch': 0.73}
{'loss': 0.1118, 'grad_norm': 18.63863754272461, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.09437748044729233, 'loss_2': 0.0174560546875, 'loss_3': -14.940256118774414, 'loss_4': 5.543797016143799, 'epoch': 0.74}
{'loss': 0.1083, 'grad_norm': 23.472797393798828, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.09647760540246964, 'loss_2': 0.01177978515625, 'loss_3': -14.981117248535156, 'loss_4': 5.232785701751709, 'epoch': 0.74}
{'loss': 0.0904, 'grad_norm': 17.03516960144043, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.06625679135322571, 'loss_2': 0.0241851806640625, 'loss_3': -15.123565673828125, 'loss_4': 5.435585975646973, 'epoch': 0.75}
{'loss': 0.0663, 'grad_norm': 16.842864990234375, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.06169332191348076, 'loss_2': 0.0046539306640625, 'loss_3': -14.908451080322266, 'loss_4': 4.492367744445801, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 09:27:19,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:19,007 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:33<1:26:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:26,354 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02938130311667919, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.076, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.023772982880473137, 'eval_loss_2': 0.005608320236206055, 'eval_loss_3': -18.00274658203125, 'eval_loss_4': 5.055681228637695, 'epoch': 0.76}
{'loss': 0.0544, 'grad_norm': 18.438180923461914, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.053441282361745834, 'loss_2': 0.001007080078125, 'loss_3': -15.03686237335205, 'loss_4': 4.925809860229492, 'epoch': 0.76}
{'loss': 0.0439, 'grad_norm': 10.997162818908691, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.039044469594955444, 'loss_2': 0.00482940673828125, 'loss_3': -15.0433349609375, 'loss_4': 4.377626419067383, 'epoch': 0.77}
{'loss': 0.0882, 'grad_norm': 25.87593650817871, 'learning_rate': 2.925e-05, 'loss_1': 0.08729776740074158, 'loss_2': 0.00093841552734375, 'loss_3': -14.918901443481445, 'loss_4': 4.354245185852051, 'epoch': 0.77}
{'loss': 0.0713, 'grad_norm': 16.113874435424805, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.05351632833480835, 'loss_2': 0.017791748046875, 'loss_3': -15.015241622924805, 'loss_4': 4.930730819702148, 'epoch': 0.78}
{'loss': 0.0689, 'grad_norm': 15.412898063659668, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.0597766675055027, 'loss_2': 0.00911712646484375, 'loss_3': -15.179153442382812, 'loss_4': 4.864500999450684, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 09:27:26,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:26,354 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:40<1:26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:33,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037611134350299835, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.538, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.02604866772890091, 'eval_loss_2': 0.011562466621398926, 'eval_loss_3': -17.969188690185547, 'eval_loss_4': 4.6885762214660645, 'epoch': 0.78}
{'loss': 0.0604, 'grad_norm': 14.179261207580566, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.05286039039492607, 'loss_2': 0.007541656494140625, 'loss_3': -15.172870635986328, 'loss_4': 4.8288774490356445, 'epoch': 0.79}
{'loss': 0.1072, 'grad_norm': 26.229177474975586, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.0880827009677887, 'loss_2': 0.01910400390625, 'loss_3': -15.123549461364746, 'loss_4': 4.430291652679443, 'epoch': 0.8}
{'loss': 0.0743, 'grad_norm': 15.18109130859375, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.05954243615269661, 'loss_2': 0.01473236083984375, 'loss_3': -15.200410842895508, 'loss_4': 4.80961799621582, 'epoch': 0.8}
{'loss': 0.0758, 'grad_norm': 27.731674194335938, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.0643719732761383, 'loss_2': 0.01146697998046875, 'loss_3': -15.211488723754883, 'loss_4': 3.8244481086730957, 'epoch': 0.81}
{'loss': 0.0731, 'grad_norm': 19.396583557128906, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.06594327837228775, 'loss_2': 0.00711822509765625, 'loss_3': -14.736786842346191, 'loss_4': 3.983644962310791, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 09:27:33,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:33,711 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:48<1:26:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:41,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04275599867105484, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.948, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03681100904941559, 'eval_loss_2': 0.005944989621639252, 'eval_loss_3': -17.900705337524414, 'eval_loss_4': 4.429271221160889, 'epoch': 0.81}
{'loss': 0.0472, 'grad_norm': 10.678478240966797, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.04271535202860832, 'loss_2': 0.00450897216796875, 'loss_3': -15.000981330871582, 'loss_4': 3.873213768005371, 'epoch': 0.82}
{'loss': 0.1051, 'grad_norm': 25.865528106689453, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.10401345789432526, 'loss_2': 0.001132965087890625, 'loss_3': -15.103395462036133, 'loss_4': 4.933141231536865, 'epoch': 0.83}
{'loss': 0.0753, 'grad_norm': 22.07110023498535, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.07224277406930923, 'loss_2': 0.003082275390625, 'loss_3': -14.914148330688477, 'loss_4': 4.009500980377197, 'epoch': 0.83}
{'loss': 0.1001, 'grad_norm': 28.32743263244629, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.09672567993402481, 'loss_2': 0.00335693359375, 'loss_3': -14.880373001098633, 'loss_4': 3.941899299621582, 'epoch': 0.84}
{'loss': 0.083, 'grad_norm': 22.858144760131836, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.07950681447982788, 'loss_2': 0.003444671630859375, 'loss_3': -15.0042724609375, 'loss_4': 4.478128433227539, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 09:27:41,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:41,068 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:55<1:26:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:27:48,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028820954263210297, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.748, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0236956849694252, 'eval_loss_2': 0.005125269293785095, 'eval_loss_3': -17.989656448364258, 'eval_loss_4': 4.325456142425537, 'epoch': 0.84}
{'loss': 0.1005, 'grad_norm': 23.778120040893555, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.09758011251688004, 'loss_2': 0.002918243408203125, 'loss_3': -15.1922607421875, 'loss_4': 4.432167053222656, 'epoch': 0.85}
{'loss': 0.1081, 'grad_norm': 26.146577835083008, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.1060529351234436, 'loss_2': 0.00206756591796875, 'loss_3': -14.910786628723145, 'loss_4': 5.081837177276611, 'epoch': 0.85}
{'loss': 0.0752, 'grad_norm': 25.014177322387695, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.07129111886024475, 'loss_2': 0.0039520263671875, 'loss_3': -15.181840896606445, 'loss_4': 4.664233684539795, 'epoch': 0.86}
{'loss': 0.0659, 'grad_norm': 17.921674728393555, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.05905148386955261, 'loss_2': 0.006866455078125, 'loss_3': -15.308959007263184, 'loss_4': 4.801766872406006, 'epoch': 0.87}
{'loss': 0.0532, 'grad_norm': 13.35567569732666, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.04884180426597595, 'loss_2': 0.00434112548828125, 'loss_3': -15.112114906311035, 'loss_4': 4.674984455108643, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 09:27:48,422 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:48,422 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:59<1:26:42,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:27:52,238 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150
[INFO|configuration_utils.py:420] 2025-01-21 09:27:52,239 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150/config.json                                                                              
{'eval_loss': 0.017466599121689796, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.457, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.013051211833953857, 'eval_loss_2': 0.004415389150381088, 'eval_loss_3': -18.14122772216797, 'eval_loss_4': 4.799105644226074, 'epoch': 0.87}
[INFO|modeling_utils.py:2988] 2025-01-21 09:27:52,732 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:27:52,733 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:27:52,734 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:27:53,616 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-100] due to args.save_total_limit
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:04<1:35:14,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:27:57,224 >>
{'loss': 0.065, 'grad_norm': 15.487542152404785, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.05521822348237038, 'loss_2': 0.00975799560546875, 'loss_3': -15.480735778808594, 'loss_4': 5.217223167419434, 'epoch': 0.88}
{'loss': 0.1281, 'grad_norm': 31.082366943359375, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.12434247136116028, 'loss_2': 0.00373077392578125, 'loss_3': -15.038962364196777, 'loss_4': 4.746396541595459, 'epoch': 0.88}
{'loss': 0.1514, 'grad_norm': 23.77992820739746, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.14905907213687897, 'loss_2': 0.00238037109375, 'loss_3': -15.07709789276123, 'loss_4': 4.345483779907227, 'epoch': 0.89}
{'loss': 0.1129, 'grad_norm': 25.670190811157227, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.10857092589139938, 'loss_2': 0.00432586669921875, 'loss_3': -15.010075569152832, 'loss_4': 6.071596622467041, 'epoch': 0.9}
{'loss': 0.0778, 'grad_norm': 32.286582946777344, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.06720428168773651, 'loss_2': 0.01059722900390625, 'loss_3': -15.161334991455078, 'loss_4': 6.295537948608398, 'epoch': 0.9}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:27:57,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:27:57,224 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:11<1:28:05,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:28:04,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018404828384518623, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.736, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013402686454355717, 'eval_loss_2': 0.005002140998840332, 'eval_loss_3': -18.250673294067383, 'eval_loss_4': 5.926694393157959, 'epoch': 0.9}
{'loss': 0.072, 'grad_norm': 20.51542854309082, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.07172273099422455, 'loss_2': 0.0003113746643066406, 'loss_3': -15.361291885375977, 'loss_4': 5.611525535583496, 'epoch': 0.91}
{'loss': 0.1286, 'grad_norm': 32.18825912475586, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.12180493772029877, 'loss_2': 0.006832122802734375, 'loss_3': -15.140876770019531, 'loss_4': 7.161782264709473, 'epoch': 0.91}
{'loss': 0.0748, 'grad_norm': 20.07978057861328, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.07133183628320694, 'loss_2': 0.003452301025390625, 'loss_3': -15.332085609436035, 'loss_4': 7.469071388244629, 'epoch': 0.92}
{'loss': 0.1356, 'grad_norm': 28.48765754699707, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.11996421217918396, 'loss_2': 0.0156402587890625, 'loss_3': -15.286296844482422, 'loss_4': 7.793763637542725, 'epoch': 0.92}
{'loss': 0.0922, 'grad_norm': 21.436492919921875, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.08957848697900772, 'loss_2': 0.002605438232421875, 'loss_3': -15.218981742858887, 'loss_4': 6.793309211730957, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 09:28:04,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:04,584 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:19<1:26:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:11,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023652035742998123, 'eval_runtime': 3.8225, 'eval_samples_per_second': 267.891, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.01565362885594368, 'eval_loss_2': 0.007998406887054443, 'eval_loss_3': -18.30729866027832, 'eval_loss_4': 6.508820533752441, 'epoch': 0.93}
{'loss': 0.1075, 'grad_norm': 23.46360206604004, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.09787172079086304, 'loss_2': 0.0095977783203125, 'loss_3': -15.190186500549316, 'loss_4': 6.394091606140137, 'epoch': 0.94}
{'loss': 0.0762, 'grad_norm': 21.052249908447266, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.07223239541053772, 'loss_2': 0.003978729248046875, 'loss_3': -15.281482696533203, 'loss_4': 7.37437629699707, 'epoch': 0.94}
{'loss': 0.0902, 'grad_norm': 29.011653900146484, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.08776499330997467, 'loss_2': 0.0024547576904296875, 'loss_3': -15.19196891784668, 'loss_4': 6.657507419586182, 'epoch': 0.95}
{'loss': 0.0591, 'grad_norm': 17.0600643157959, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.05779777839779854, 'loss_2': 0.0012969970703125, 'loss_3': -15.39646053314209, 'loss_4': 6.082590103149414, 'epoch': 0.95}
{'loss': 0.0597, 'grad_norm': 16.975698471069336, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.05922809615731239, 'loss_2': 0.00043582916259765625, 'loss_3': -15.287493705749512, 'loss_4': 5.525259494781494, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 09:28:11,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:11,963 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:22<1:26:58,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:28:15,782 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165
[INFO|configuration_utils.py:420] 2025-01-21 09:28:15,784 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165/config.json                                                                              
{'eval_loss': 0.016724087297916412, 'eval_runtime': 3.8173, 'eval_samples_per_second': 268.255, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.011821487918496132, 'eval_loss_2': 0.00490260124206543, 'eval_loss_3': -18.266599655151367, 'eval_loss_4': 5.148691177368164, 'epoch': 0.96}
[INFO|modeling_utils.py:2988] 2025-01-21 09:28:16,252 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:28:16,254 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:28:16,254 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:28:17,120 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-150] due to args.save_total_limit
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:27<1:35:02,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:28:20,751 >>
{'loss': 0.0713, 'grad_norm': 16.353670120239258, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.06747004389762878, 'loss_2': 0.00383758544921875, 'loss_3': -15.238969802856445, 'loss_4': 5.842155456542969, 'epoch': 0.97}
{'loss': 0.0935, 'grad_norm': 16.135719299316406, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.07813387364149094, 'loss_2': 0.01531982421875, 'loss_3': -15.202006340026855, 'loss_4': 5.528722763061523, 'epoch': 0.97}
{'loss': 0.0617, 'grad_norm': 13.846899032592773, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.05153729021549225, 'loss_2': 0.0101165771484375, 'loss_3': -15.343489646911621, 'loss_4': 5.626265525817871, 'epoch': 0.98}
{'loss': 0.1312, 'grad_norm': 51.9589729309082, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.13042619824409485, 'loss_2': 0.0008001327514648438, 'loss_3': -15.141138076782227, 'loss_4': 4.261567115783691, 'epoch': 0.98}
{'loss': 0.107, 'grad_norm': 27.250165939331055, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.10567834228277206, 'loss_2': 0.0012912750244140625, 'loss_3': -15.142340660095215, 'loss_4': 5.45823335647583, 'epoch': 0.99}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:28:20,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:20,751 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:35<1:25:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:28:27,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01774047501385212, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012030811049044132, 'eval_loss_2': 0.005709663033485413, 'eval_loss_3': -18.214120864868164, 'eval_loss_4': 4.677562713623047, 'epoch': 0.99}
{'loss': 0.0485, 'grad_norm': 12.730387687683105, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.046123206615448, 'loss_2': 0.002376556396484375, 'loss_3': -15.011951446533203, 'loss_4': 3.9872076511383057, 'epoch': 0.99}
{'loss': 0.0911, 'grad_norm': 44.19285583496094, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.07776669412851334, 'loss_2': 0.01332855224609375, 'loss_3': -15.309008598327637, 'loss_4': 5.274088382720947, 'epoch': 1.0}
{'loss': 0.0678, 'grad_norm': 16.553800582885742, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.05864158645272255, 'loss_2': 0.0091400146484375, 'loss_3': -15.32817268371582, 'loss_4': 4.929842948913574, 'epoch': 1.01}
{'loss': 0.0696, 'grad_norm': 16.61911964416504, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.06594099849462509, 'loss_2': 0.003696441650390625, 'loss_3': -15.302218437194824, 'loss_4': 5.186909198760986, 'epoch': 1.01}
{'loss': 0.0667, 'grad_norm': 19.154691696166992, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.06080740690231323, 'loss_2': 0.0059051513671875, 'loss_3': -15.322989463806152, 'loss_4': 4.725099563598633, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 09:28:27,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:27,788 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:42<1:26:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:35,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028309248387813568, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013348005712032318, 'eval_loss_2': 0.01496124267578125, 'eval_loss_3': -18.186485290527344, 'eval_loss_4': 4.82620906829834, 'epoch': 1.02}
{'loss': 0.0947, 'grad_norm': 24.933521270751953, 'learning_rate': 2.9e-05, 'loss_1': 0.08806785196065903, 'loss_2': 0.006595611572265625, 'loss_3': -15.331562042236328, 'loss_4': 5.457669734954834, 'epoch': 1.02}
{'loss': 0.057, 'grad_norm': 14.494564056396484, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.04561623930931091, 'loss_2': 0.0113677978515625, 'loss_3': -15.377301216125488, 'loss_4': 4.665136337280273, 'epoch': 1.03}
{'loss': 0.1027, 'grad_norm': 23.59189224243164, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.09703297168016434, 'loss_2': 0.0056610107421875, 'loss_3': -15.124533653259277, 'loss_4': 4.99946928024292, 'epoch': 1.03}
{'loss': 0.119, 'grad_norm': 25.319063186645508, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.11865818500518799, 'loss_2': 0.0003032684326171875, 'loss_3': -15.188480377197266, 'loss_4': 4.293013095855713, 'epoch': 1.04}
{'loss': 0.1144, 'grad_norm': 25.742483139038086, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.11286938935518265, 'loss_2': 0.0014972686767578125, 'loss_3': -15.182595252990723, 'loss_4': 4.897430419921875, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 09:28:35,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:35,140 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:49<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:42,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01814662665128708, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.014225222170352936, 'eval_loss_2': 0.003921404480934143, 'eval_loss_3': -18.1511287689209, 'eval_loss_4': 5.341974258422852, 'epoch': 1.05}
{'loss': 0.0497, 'grad_norm': 10.910362243652344, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.04734829440712929, 'loss_2': 0.002353668212890625, 'loss_3': -15.263850212097168, 'loss_4': 5.328008651733398, 'epoch': 1.05}
{'loss': 0.0464, 'grad_norm': 11.97398567199707, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.04371270537376404, 'loss_2': 0.002666473388671875, 'loss_3': -15.345499038696289, 'loss_4': 5.596341609954834, 'epoch': 1.06}
{'loss': 0.0484, 'grad_norm': 11.658417701721191, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.04561839997768402, 'loss_2': 0.002796173095703125, 'loss_3': -15.318429946899414, 'loss_4': 5.759214401245117, 'epoch': 1.06}
{'loss': 0.0569, 'grad_norm': 16.12250328063965, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.04476974904537201, 'loss_2': 0.0120849609375, 'loss_3': -15.05235481262207, 'loss_4': 5.502796649932861, 'epoch': 1.07}
{'loss': 0.051, 'grad_norm': 34.714054107666016, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.05016074329614639, 'loss_2': 0.0008616447448730469, 'loss_3': -15.126222610473633, 'loss_4': 5.303954124450684, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 09:28:42,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:42,497 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:57<1:26:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:49,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01881830394268036, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.136, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.012240869924426079, 'eval_loss_2': 0.006577432155609131, 'eval_loss_3': -18.207908630371094, 'eval_loss_4': 5.3227033615112305, 'epoch': 1.08}
{'loss': 0.0533, 'grad_norm': 17.504104614257812, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.04944306239485741, 'loss_2': 0.0038890838623046875, 'loss_3': -15.282414436340332, 'loss_4': 5.400630474090576, 'epoch': 1.08}
{'loss': 0.0403, 'grad_norm': 8.413274765014648, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.033517688512802124, 'loss_2': 0.00679779052734375, 'loss_3': -15.108842849731445, 'loss_4': 5.029804229736328, 'epoch': 1.09}
{'loss': 0.0523, 'grad_norm': 13.861236572265625, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.04827890545129776, 'loss_2': 0.0040283203125, 'loss_3': -15.081963539123535, 'loss_4': 4.916986465454102, 'epoch': 1.09}
{'loss': 0.068, 'grad_norm': 26.71223258972168, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.06669145822525024, 'loss_2': 0.0013494491577148438, 'loss_3': -14.966448783874512, 'loss_4': 5.205890655517578, 'epoch': 1.1}
{'loss': 0.0331, 'grad_norm': 11.036490440368652, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.0307779498398304, 'loss_2': 0.002330780029296875, 'loss_3': -15.350069046020508, 'loss_4': 5.424332141876221, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 09:28:49,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:49,866 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:04<1:25:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:28:57,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02657853439450264, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012340417131781578, 'eval_loss_2': 0.014238119125366211, 'eval_loss_3': -18.241992950439453, 'eval_loss_4': 5.620901584625244, 'epoch': 1.1}
{'loss': 0.0665, 'grad_norm': 19.954723358154297, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.059896647930145264, 'loss_2': 0.0065765380859375, 'loss_3': -15.121774673461914, 'loss_4': 5.757526397705078, 'epoch': 1.11}
{'loss': 0.0721, 'grad_norm': 17.54863929748535, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.055322736501693726, 'loss_2': 0.0167999267578125, 'loss_3': -15.147233963012695, 'loss_4': 6.345113754272461, 'epoch': 1.12}
{'loss': 0.0906, 'grad_norm': 19.10297393798828, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.06946569681167603, 'loss_2': 0.0211334228515625, 'loss_3': -15.409663200378418, 'loss_4': 6.1588640213012695, 'epoch': 1.12}
{'loss': 0.089, 'grad_norm': 15.540364265441895, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.058280397206544876, 'loss_2': 0.030670166015625, 'loss_3': -15.219375610351562, 'loss_4': 6.235002517700195, 'epoch': 1.13}
{'loss': 0.0809, 'grad_norm': 14.939021110534668, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.05230364203453064, 'loss_2': 0.0285491943359375, 'loss_3': -15.060783386230469, 'loss_4': 6.56398344039917, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 09:28:57,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:28:57,224 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:11<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:04,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03272336721420288, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.934, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012309012934565544, 'eval_loss_2': 0.020414352416992188, 'eval_loss_3': -18.282140731811523, 'eval_loss_4': 6.530065536499023, 'epoch': 1.13}
{'loss': 0.088, 'grad_norm': 18.548439025878906, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.0687897726893425, 'loss_2': 0.0192108154296875, 'loss_3': -15.289228439331055, 'loss_4': 6.28812837600708, 'epoch': 1.14}
{'loss': 0.1198, 'grad_norm': 29.483980178833008, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.09747271984815598, 'loss_2': 0.0223541259765625, 'loss_3': -15.265572547912598, 'loss_4': 6.8051557540893555, 'epoch': 1.15}
{'loss': 0.1039, 'grad_norm': 20.497215270996094, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.08888412266969681, 'loss_2': 0.0150299072265625, 'loss_3': -15.489500045776367, 'loss_4': 7.148681640625, 'epoch': 1.15}
{'loss': 0.054, 'grad_norm': 12.49783992767334, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.04608234390616417, 'loss_2': 0.0079345703125, 'loss_3': -15.347151756286621, 'loss_4': 6.3166913986206055, 'epoch': 1.16}
{'loss': 0.0592, 'grad_norm': 16.150360107421875, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.049397557973861694, 'loss_2': 0.00980377197265625, 'loss_3': -15.481979370117188, 'loss_4': 7.3338212966918945, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 09:29:04,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:04,573 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:19<1:25:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:11,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018591085448861122, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011580470018088818, 'eval_loss_2': 0.007010616362094879, 'eval_loss_3': -18.3039608001709, 'eval_loss_4': 6.725841045379639, 'epoch': 1.16}
{'loss': 0.0352, 'grad_norm': 8.791181564331055, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.03309791907668114, 'loss_2': 0.0020542144775390625, 'loss_3': -15.414653778076172, 'loss_4': 7.16474723815918, 'epoch': 1.17}
{'loss': 0.0701, 'grad_norm': 21.09964942932129, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.06330303102731705, 'loss_2': 0.0068359375, 'loss_3': -15.279912948608398, 'loss_4': 7.385072708129883, 'epoch': 1.17}
{'loss': 0.0555, 'grad_norm': 12.794631004333496, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.048535335808992386, 'loss_2': 0.006992340087890625, 'loss_3': -15.387016296386719, 'loss_4': 7.041841506958008, 'epoch': 1.18}
{'loss': 0.1365, 'grad_norm': 38.89749526977539, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.12612751126289368, 'loss_2': 0.010345458984375, 'loss_3': -15.41001033782959, 'loss_4': 6.905406951904297, 'epoch': 1.19}
{'loss': 0.0918, 'grad_norm': 16.803077697753906, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.07431022077798843, 'loss_2': 0.0174407958984375, 'loss_3': -15.236656188964844, 'loss_4': 6.248228549957275, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 09:29:11,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:11,927 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:26<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:19,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028218021616339684, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01166700292378664, 'eval_loss_2': 0.01655101776123047, 'eval_loss_3': -18.284465789794922, 'eval_loss_4': 6.086864471435547, 'epoch': 1.19}
{'loss': 0.0779, 'grad_norm': 19.503150939941406, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.061799727380275726, 'loss_2': 0.016143798828125, 'loss_3': -15.14460563659668, 'loss_4': 6.277243137359619, 'epoch': 1.2}
{'loss': 0.0942, 'grad_norm': 31.76542854309082, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.08178036659955978, 'loss_2': 0.012451171875, 'loss_3': -15.354070663452148, 'loss_4': 6.217493057250977, 'epoch': 1.2}
{'loss': 0.0872, 'grad_norm': 21.675439834594727, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.07248955219984055, 'loss_2': 0.01474761962890625, 'loss_3': -15.286178588867188, 'loss_4': 5.812790870666504, 'epoch': 1.21}
{'loss': 0.068, 'grad_norm': 19.179136276245117, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.054536156356334686, 'loss_2': 0.013427734375, 'loss_3': -15.51009464263916, 'loss_4': 5.541158199310303, 'epoch': 1.22}
{'loss': 0.2174, 'grad_norm': 25.488832473754883, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.212263286113739, 'loss_2': 0.00514984130859375, 'loss_3': -15.067705154418945, 'loss_4': 5.840098857879639, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 09:29:19,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:19,284 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:33<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:26,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01873384416103363, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.288, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.01402120292186737, 'eval_loss_2': 0.00471264123916626, 'eval_loss_3': -18.24803924560547, 'eval_loss_4': 5.132909774780273, 'epoch': 1.22}
{'loss': 0.0635, 'grad_norm': 15.02515983581543, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.06305116415023804, 'loss_2': 0.0004940032958984375, 'loss_3': -15.52364730834961, 'loss_4': 5.391213417053223, 'epoch': 1.23}
{'loss': 0.104, 'grad_norm': 24.539533615112305, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.09090155363082886, 'loss_2': 0.01309967041015625, 'loss_3': -15.325989723205566, 'loss_4': 5.1212897300720215, 'epoch': 1.23}
{'loss': 0.0414, 'grad_norm': 11.503806114196777, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.03610610216856003, 'loss_2': 0.00531005859375, 'loss_3': -15.338159561157227, 'loss_4': 5.004676342010498, 'epoch': 1.24}
{'loss': 0.1192, 'grad_norm': 23.776662826538086, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.10322622209787369, 'loss_2': 0.0159454345703125, 'loss_3': -15.626571655273438, 'loss_4': 4.821087837219238, 'epoch': 1.24}
{'loss': 0.049, 'grad_norm': 8.41878890991211, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.02798405848443508, 'loss_2': 0.02105712890625, 'loss_3': -15.324462890625, 'loss_4': 5.263670921325684, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 09:29:26,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:26,651 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:41<1:25:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:34,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026635870337486267, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.642, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.017941730096936226, 'eval_loss_2': 0.00869414210319519, 'eval_loss_3': -18.250226974487305, 'eval_loss_4': 5.24282693862915, 'epoch': 1.25}
{'loss': 0.0649, 'grad_norm': 12.43978214263916, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.052889224141836166, 'loss_2': 0.011993408203125, 'loss_3': -15.456920623779297, 'loss_4': 4.502559661865234, 'epoch': 1.26}
{'loss': 0.048, 'grad_norm': 11.202430725097656, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.04178275167942047, 'loss_2': 0.006214141845703125, 'loss_3': -15.559097290039062, 'loss_4': 6.06318473815918, 'epoch': 1.26}
{'loss': 0.0794, 'grad_norm': 24.159252166748047, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.07588016986846924, 'loss_2': 0.00351715087890625, 'loss_3': -15.407133102416992, 'loss_4': 5.427927494049072, 'epoch': 1.27}
{'loss': 0.037, 'grad_norm': 14.535948753356934, 'learning_rate': 2.875e-05, 'loss_1': 0.033273518085479736, 'loss_2': 0.0037403106689453125, 'loss_3': -15.436206817626953, 'loss_4': 5.720405578613281, 'epoch': 1.27}
{'loss': 0.0425, 'grad_norm': 11.080310821533203, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.03292109817266464, 'loss_2': 0.00959014892578125, 'loss_3': -15.352119445800781, 'loss_4': 4.914212226867676, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 09:29:34,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:34,010 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:48<1:25:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:41,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03009079210460186, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.018485765904188156, 'eval_loss_2': 0.011605024337768555, 'eval_loss_3': -18.25433349609375, 'eval_loss_4': 4.814249038696289, 'epoch': 1.28}
{'loss': 0.0636, 'grad_norm': 12.439458847045898, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.052849989384412766, 'loss_2': 0.01078033447265625, 'loss_3': -15.581256866455078, 'loss_4': 4.778925895690918, 'epoch': 1.28}
{'loss': 0.0792, 'grad_norm': 18.268230438232422, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.06925881654024124, 'loss_2': 0.00992584228515625, 'loss_3': -15.414884567260742, 'loss_4': 5.08600378036499, 'epoch': 1.29}
{'loss': 0.0625, 'grad_norm': 15.590982437133789, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.0616917610168457, 'loss_2': 0.0007710456848144531, 'loss_3': -15.49443244934082, 'loss_4': 4.602788925170898, 'epoch': 1.3}
{'loss': 0.044, 'grad_norm': 11.451736450195312, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.03157626837491989, 'loss_2': 0.0123748779296875, 'loss_3': -15.491442680358887, 'loss_4': 4.51578950881958, 'epoch': 1.3}
{'loss': 0.0707, 'grad_norm': 18.29069709777832, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.06683870404958725, 'loss_2': 0.003826141357421875, 'loss_3': -15.558324813842773, 'loss_4': 4.294926166534424, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 09:29:41,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:41,358 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [05:55<1:25:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:48,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02373644709587097, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.02021603100001812, 'eval_loss_2': 0.0035204142332077026, 'eval_loss_3': -18.211536407470703, 'eval_loss_4': 4.424705505371094, 'epoch': 1.31}
{'loss': 0.0193, 'grad_norm': 7.846467018127441, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.018748069182038307, 'loss_2': 0.0005125999450683594, 'loss_3': -15.490131378173828, 'loss_4': 4.32455587387085, 'epoch': 1.31}
{'loss': 0.1124, 'grad_norm': 32.04595947265625, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.10307294130325317, 'loss_2': 0.0093536376953125, 'loss_3': -15.447509765625, 'loss_4': 4.05330228805542, 'epoch': 1.32}
{'loss': 0.056, 'grad_norm': 14.97017765045166, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.045625269412994385, 'loss_2': 0.0103302001953125, 'loss_3': -15.354896545410156, 'loss_4': 4.107417583465576, 'epoch': 1.33}
{'loss': 0.043, 'grad_norm': 12.63054370880127, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.04090062528848648, 'loss_2': 0.0020999908447265625, 'loss_3': -15.429983139038086, 'loss_4': 4.345878601074219, 'epoch': 1.33}
{'loss': 0.0569, 'grad_norm': 15.927082061767578, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.05382348597049713, 'loss_2': 0.00308990478515625, 'loss_3': -15.377256393432617, 'loss_4': 4.040901184082031, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 09:29:48,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:48,713 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:03<1:25:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:29:56,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022400040179491043, 'eval_runtime': 3.8208, 'eval_samples_per_second': 268.006, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01750703528523445, 'eval_loss_2': 0.004893004894256592, 'eval_loss_3': -18.135236740112305, 'eval_loss_4': 3.84291410446167, 'epoch': 1.34}
{'loss': 0.0398, 'grad_norm': 10.857383728027344, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.03439434990286827, 'loss_2': 0.005359649658203125, 'loss_3': -15.416616439819336, 'loss_4': 4.085054874420166, 'epoch': 1.34}
{'loss': 0.1729, 'grad_norm': 22.740795135498047, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.16749998927116394, 'loss_2': 0.0053558349609375, 'loss_3': -15.226099014282227, 'loss_4': 3.454578161239624, 'epoch': 1.35}
{'loss': 0.0886, 'grad_norm': 24.18244743347168, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.08406157791614532, 'loss_2': 0.00457763671875, 'loss_3': -15.075155258178711, 'loss_4': 3.8414697647094727, 'epoch': 1.35}
{'loss': 0.0452, 'grad_norm': 13.979223251342773, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.043509285897016525, 'loss_2': 0.0017032623291015625, 'loss_3': -15.23569107055664, 'loss_4': 4.175022125244141, 'epoch': 1.36}
{'loss': 0.043, 'grad_norm': 11.55146312713623, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.03856274485588074, 'loss_2': 0.0044097900390625, 'loss_3': -15.039718627929688, 'loss_4': 4.238901138305664, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 09:29:56,078 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:29:56,078 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:10<1:25:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:03,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021891703829169273, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.672, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.017557967454195023, 'eval_loss_2': 0.0043337345123291016, 'eval_loss_3': -18.147653579711914, 'eval_loss_4': 4.005260467529297, 'epoch': 1.37}
{'loss': 0.079, 'grad_norm': 25.164344787597656, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.07333722710609436, 'loss_2': 0.005615234375, 'loss_3': -15.062615394592285, 'loss_4': 4.315727710723877, 'epoch': 1.37}
{'loss': 0.0628, 'grad_norm': 17.49761390686035, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.06217489764094353, 'loss_2': 0.0006003379821777344, 'loss_3': -15.165329933166504, 'loss_4': 4.501465797424316, 'epoch': 1.38}
{'loss': 0.0467, 'grad_norm': 11.592761039733887, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.042142949998378754, 'loss_2': 0.0045166015625, 'loss_3': -15.208873748779297, 'loss_4': 5.033980369567871, 'epoch': 1.38}
{'loss': 0.0489, 'grad_norm': 15.095283508300781, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.0455348864197731, 'loss_2': 0.0033397674560546875, 'loss_3': -15.18734073638916, 'loss_4': 4.562259197235107, 'epoch': 1.39}
{'loss': 0.0708, 'grad_norm': 20.790613174438477, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.06208775192499161, 'loss_2': 0.0087432861328125, 'loss_3': -15.47822380065918, 'loss_4': 5.358602523803711, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 09:30:03,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:03,441 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:18<1:25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:10,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02934892475605011, 'eval_runtime': 3.8218, 'eval_samples_per_second': 267.934, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.024324923753738403, 'eval_loss_2': 0.0050240010023117065, 'eval_loss_3': -18.145774841308594, 'eval_loss_4': 5.174921035766602, 'epoch': 1.4}
{'loss': 0.0554, 'grad_norm': 14.740190505981445, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.054226119071245193, 'loss_2': 0.001201629638671875, 'loss_3': -15.528624534606934, 'loss_4': 5.362576484680176, 'epoch': 1.4}
{'loss': 0.0367, 'grad_norm': 9.729107856750488, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.03518255054950714, 'loss_2': 0.0015316009521484375, 'loss_3': -15.326898574829102, 'loss_4': 5.060790061950684, 'epoch': 1.41}
{'loss': 0.0735, 'grad_norm': 18.712488174438477, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.07297826558351517, 'loss_2': 0.0005254745483398438, 'loss_3': -15.482208251953125, 'loss_4': 5.894408226013184, 'epoch': 1.41}
{'loss': 0.0619, 'grad_norm': 18.386444091796875, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.05876897647976875, 'loss_2': 0.003082275390625, 'loss_3': -15.239484786987305, 'loss_4': 5.430832862854004, 'epoch': 1.42}
{'loss': 0.0869, 'grad_norm': 23.651044845581055, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.0841478556394577, 'loss_2': 0.0027313232421875, 'loss_3': -15.073343276977539, 'loss_4': 5.477484703063965, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 09:30:10,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:10,812 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:25<1:25:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:18,167 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023288477212190628, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.017225462943315506, 'eval_loss_2': 0.006063014268875122, 'eval_loss_3': -18.173744201660156, 'eval_loss_4': 5.814570903778076, 'epoch': 1.42}
{'loss': 0.06, 'grad_norm': 13.237009048461914, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.05607070028781891, 'loss_2': 0.00396728515625, 'loss_3': -15.157974243164062, 'loss_4': 5.87307071685791, 'epoch': 1.43}
{'loss': 0.0895, 'grad_norm': 20.875019073486328, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.08819691836833954, 'loss_2': 0.00128173828125, 'loss_3': -15.275171279907227, 'loss_4': 6.189903259277344, 'epoch': 1.44}
{'loss': 0.1538, 'grad_norm': 33.9431037902832, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.14076833426952362, 'loss_2': 0.01306915283203125, 'loss_3': -14.905305862426758, 'loss_4': 6.211399078369141, 'epoch': 1.44}
{'loss': 0.0525, 'grad_norm': 13.98318862915039, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.0487285777926445, 'loss_2': 0.0037994384765625, 'loss_3': -15.2501859664917, 'loss_4': 6.360544681549072, 'epoch': 1.45}
{'loss': 0.0693, 'grad_norm': 17.236730575561523, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.06485012173652649, 'loss_2': 0.00449371337890625, 'loss_3': -15.372648239135742, 'loss_4': 6.190925598144531, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 09:30:18,167 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:18,167 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:32<1:25:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:25,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017136521637439728, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012568718753755093, 'eval_loss_2': 0.0045678019523620605, 'eval_loss_3': -18.21497344970703, 'eval_loss_4': 6.104603290557861, 'epoch': 1.45}
{'loss': 0.0709, 'grad_norm': 15.572831153869629, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.06375724077224731, 'loss_2': 0.007171630859375, 'loss_3': -15.143306732177734, 'loss_4': 6.912056922912598, 'epoch': 1.46}
{'loss': 0.0702, 'grad_norm': 22.76297950744629, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.06261339783668518, 'loss_2': 0.007625579833984375, 'loss_3': -15.221592903137207, 'loss_4': 6.088500499725342, 'epoch': 1.47}
{'loss': 0.0746, 'grad_norm': 17.220191955566406, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.06836465001106262, 'loss_2': 0.00626373291015625, 'loss_3': -15.221989631652832, 'loss_4': 6.64470100402832, 'epoch': 1.47}
{'loss': 0.0897, 'grad_norm': 30.975086212158203, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.08423053473234177, 'loss_2': 0.00548553466796875, 'loss_3': -15.096700668334961, 'loss_4': 7.275312423706055, 'epoch': 1.48}
{'loss': 0.0427, 'grad_norm': 15.029467582702637, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.04035719484090805, 'loss_2': 0.0023555755615234375, 'loss_3': -15.218996047973633, 'loss_4': 6.1603803634643555, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 09:30:25,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:25,522 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:40<1:24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:32,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02062269300222397, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.763, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.014152133837342262, 'eval_loss_2': 0.0064705610275268555, 'eval_loss_3': -18.249187469482422, 'eval_loss_4': 6.32044792175293, 'epoch': 1.48}
{'loss': 0.0439, 'grad_norm': 11.939745903015137, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.04083153232932091, 'loss_2': 0.003021240234375, 'loss_3': -15.382063865661621, 'loss_4': 6.63619327545166, 'epoch': 1.49}
{'loss': 0.0705, 'grad_norm': 21.203969955444336, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.06456878781318665, 'loss_2': 0.00597381591796875, 'loss_3': -15.265053749084473, 'loss_4': 7.030972480773926, 'epoch': 1.49}
{'loss': 0.0586, 'grad_norm': 17.430850982666016, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.05776359885931015, 'loss_2': 0.0008087158203125, 'loss_3': -15.155899047851562, 'loss_4': 6.555118083953857, 'epoch': 1.5}
{'loss': 0.103, 'grad_norm': 25.96255874633789, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.1002790555357933, 'loss_2': 0.0026721954345703125, 'loss_3': -14.975549697875977, 'loss_4': 6.763557434082031, 'epoch': 1.51}
{'loss': 0.0731, 'grad_norm': 26.28523063659668, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.06977412104606628, 'loss_2': 0.0033397674560546875, 'loss_3': -15.0396728515625, 'loss_4': 5.674912452697754, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 09:30:32,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:32,885 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:47<1:24:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:30:40,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01805221289396286, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.689, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012872078455984592, 'eval_loss_2': 0.005180135369300842, 'eval_loss_3': -18.27645492553711, 'eval_loss_4': 5.342032432556152, 'epoch': 1.51}
{'loss': 0.0685, 'grad_norm': 20.196640014648438, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.05385636165738106, 'loss_2': 0.0146026611328125, 'loss_3': -15.019380569458008, 'loss_4': 5.771669387817383, 'epoch': 1.52}
{'loss': 0.0452, 'grad_norm': 12.688706398010254, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.036301419138908386, 'loss_2': 0.0089263916015625, 'loss_3': -15.145679473876953, 'loss_4': 5.531515121459961, 'epoch': 1.52}
{'loss': 0.0922, 'grad_norm': 24.33009147644043, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.0910278856754303, 'loss_2': 0.0011262893676757812, 'loss_3': -15.20875358581543, 'loss_4': 5.385770797729492, 'epoch': 1.53}
{'loss': 0.0763, 'grad_norm': 21.909015655517578, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.06994131207466125, 'loss_2': 0.00632476806640625, 'loss_3': -14.859350204467773, 'loss_4': 4.277588844299316, 'epoch': 1.53}
{'loss': 0.0321, 'grad_norm': 8.50891399383545, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.02616814523935318, 'loss_2': 0.0059661865234375, 'loss_3': -15.375280380249023, 'loss_4': 4.316339492797852, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 09:30:40,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:40,242 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:51<1:24:44,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:30:44,069 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265
[INFO|configuration_utils.py:420] 2025-01-21 09:30:44,071 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265/config.json                                                                              
{'eval_loss': 0.015280568972229958, 'eval_runtime': 3.8259, 'eval_samples_per_second': 267.649, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.011564726009964943, 'eval_loss_2': 0.0037158429622650146, 'eval_loss_3': -18.297693252563477, 'eval_loss_4': 4.143363952636719, 'epoch': 1.54}
[INFO|modeling_utils.py:2988] 2025-01-21 09:30:44,618 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:30:44,619 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:30:44,620 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:30:45,541 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-165] due to args.save_total_limit
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [06:56<1:33:50,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:30:49,161 >>
{'loss': 0.0918, 'grad_norm': 21.98059844970703, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.07745488733053207, 'loss_2': 0.0143280029296875, 'loss_3': -15.201549530029297, 'loss_4': 5.264101982116699, 'epoch': 1.55}
{'loss': 0.0916, 'grad_norm': 25.472667694091797, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.08860736340284348, 'loss_2': 0.00301361083984375, 'loss_3': -15.01205062866211, 'loss_4': 4.621870040893555, 'epoch': 1.55}
{'loss': 0.0582, 'grad_norm': 12.95726490020752, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.04884914308786392, 'loss_2': 0.009307861328125, 'loss_3': -15.365679740905762, 'loss_4': 4.187288761138916, 'epoch': 1.56}
{'loss': 0.0571, 'grad_norm': 21.32963752746582, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.047461338341236115, 'loss_2': 0.009613037109375, 'loss_3': -15.215009689331055, 'loss_4': 4.050948143005371, 'epoch': 1.56}
{'loss': 0.0391, 'grad_norm': 10.85573959350586, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.034513797610998154, 'loss_2': 0.00453948974609375, 'loss_3': -15.360733032226562, 'loss_4': 3.3839964866638184, 'epoch': 1.57}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:30:49,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:49,161 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:03<1:25:55,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:30:56,503 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015285376459360123, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012468406930565834, 'eval_loss_2': 0.0028169676661491394, 'eval_loss_3': -18.305789947509766, 'eval_loss_4': 2.9323678016662598, 'epoch': 1.57}
{'loss': 0.0533, 'grad_norm': 17.202821731567383, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.052881870418787, 'loss_2': 0.0003991127014160156, 'loss_3': -15.231895446777344, 'loss_4': 2.9841809272766113, 'epoch': 1.58}
{'loss': 0.0482, 'grad_norm': 17.70670509338379, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.04690226912498474, 'loss_2': 0.001331329345703125, 'loss_3': -15.526802062988281, 'loss_4': 2.6231212615966797, 'epoch': 1.58}
{'loss': 0.0736, 'grad_norm': 15.448987007141113, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.060253918170928955, 'loss_2': 0.01332855224609375, 'loss_3': -15.403054237365723, 'loss_4': 3.243802309036255, 'epoch': 1.59}
{'loss': 0.0682, 'grad_norm': 13.235189437866211, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.05351846665143967, 'loss_2': 0.01470184326171875, 'loss_3': -15.395751953125, 'loss_4': 2.561096668243408, 'epoch': 1.59}
{'loss': 0.1045, 'grad_norm': 23.70486068725586, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.09789683669805527, 'loss_2': 0.00656890869140625, 'loss_3': -15.06313419342041, 'loss_4': 2.536386013031006, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 09:30:56,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:30:56,504 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:11<1:24:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:03,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023881003260612488, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.064, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01708441972732544, 'eval_loss_2': 0.006796583533287048, 'eval_loss_3': -18.27582550048828, 'eval_loss_4': 2.1600801944732666, 'epoch': 1.6}
{'loss': 0.0427, 'grad_norm': 12.366358757019043, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.03730272129178047, 'loss_2': 0.00536346435546875, 'loss_3': -15.31934928894043, 'loss_4': 2.623440742492676, 'epoch': 1.6}
{'loss': 0.0791, 'grad_norm': 20.939573287963867, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.0732845887541771, 'loss_2': 0.005771636962890625, 'loss_3': -15.427745819091797, 'loss_4': 2.232785224914551, 'epoch': 1.61}
{'loss': 0.0738, 'grad_norm': 15.071202278137207, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.06238783523440361, 'loss_2': 0.0114593505859375, 'loss_3': -15.369789123535156, 'loss_4': 2.372314929962158, 'epoch': 1.62}
{'loss': 0.0599, 'grad_norm': 15.480599403381348, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.05267185717821121, 'loss_2': 0.007190704345703125, 'loss_3': -15.206829071044922, 'loss_4': 2.5043816566467285, 'epoch': 1.62}
{'loss': 0.0921, 'grad_norm': 18.240489959716797, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.071501724421978, 'loss_2': 0.0205535888671875, 'loss_3': -15.246772766113281, 'loss_4': 1.7668026685714722, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 09:31:03,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:03,851 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:18<1:24:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:11,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042732883244752884, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.027166057378053665, 'eval_loss_2': 0.015566825866699219, 'eval_loss_3': -18.183414459228516, 'eval_loss_4': 2.221217393875122, 'epoch': 1.63}
{'loss': 0.0605, 'grad_norm': 16.838397979736328, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.04529010131955147, 'loss_2': 0.015228271484375, 'loss_3': -15.195709228515625, 'loss_4': 1.7998217344284058, 'epoch': 1.63}
{'loss': 0.0483, 'grad_norm': 8.334906578063965, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.030660342425107956, 'loss_2': 0.017608642578125, 'loss_3': -15.366661071777344, 'loss_4': 1.925945520401001, 'epoch': 1.64}
{'loss': 0.1364, 'grad_norm': 25.069799423217773, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.12100820988416672, 'loss_2': 0.015411376953125, 'loss_3': -15.118083953857422, 'loss_4': 1.8558075428009033, 'epoch': 1.65}
{'loss': 0.0816, 'grad_norm': 18.136268615722656, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.06720579415559769, 'loss_2': 0.014404296875, 'loss_3': -15.37738037109375, 'loss_4': 2.6917519569396973, 'epoch': 1.65}
{'loss': 0.1101, 'grad_norm': 24.632417678833008, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.09810677915811539, 'loss_2': 0.01202392578125, 'loss_3': -15.293550491333008, 'loss_4': 2.796508312225342, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 09:31:11,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:11,190 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:25<1:24:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:18,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03222478926181793, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.023323312401771545, 'eval_loss_2': 0.008901476860046387, 'eval_loss_3': -18.1904296875, 'eval_loss_4': 2.8728086948394775, 'epoch': 1.66}
{'loss': 0.0488, 'grad_norm': 10.955098152160645, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.034607548266649246, 'loss_2': 0.01421356201171875, 'loss_3': -15.226541519165039, 'loss_4': 3.2573323249816895, 'epoch': 1.66}
{'loss': 0.0615, 'grad_norm': 22.454023361206055, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.06108201667666435, 'loss_2': 0.0003840923309326172, 'loss_3': -15.396119117736816, 'loss_4': 2.945810317993164, 'epoch': 1.67}
{'loss': 0.0915, 'grad_norm': 26.941837310791016, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.08741769194602966, 'loss_2': 0.004123687744140625, 'loss_3': -15.28584098815918, 'loss_4': 3.0842509269714355, 'epoch': 1.67}
{'loss': 0.0389, 'grad_norm': 17.520978927612305, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.03846916928887367, 'loss_2': 0.0003867149353027344, 'loss_3': -15.167706489562988, 'loss_4': 4.098847389221191, 'epoch': 1.68}
{'loss': 0.0569, 'grad_norm': 14.95361042022705, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.048663392663002014, 'loss_2': 0.0082244873046875, 'loss_3': -15.218362808227539, 'loss_4': 3.4699134826660156, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 09:31:18,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:18,537 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:33<1:24:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:25,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022995049133896828, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.018035706132650375, 'eval_loss_2': 0.0049593448638916016, 'eval_loss_3': -18.23019027709961, 'eval_loss_4': 3.3895390033721924, 'epoch': 1.69}
{'loss': 0.0807, 'grad_norm': 28.128131866455078, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.07833471149206161, 'loss_2': 0.0023345947265625, 'loss_3': -15.540852546691895, 'loss_4': 4.163119792938232, 'epoch': 1.69}
{'loss': 0.036, 'grad_norm': 10.373067855834961, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.030818449333310127, 'loss_2': 0.00518035888671875, 'loss_3': -15.263251304626465, 'loss_4': 3.6779332160949707, 'epoch': 1.7}
{'loss': 0.0709, 'grad_norm': 16.279781341552734, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.0682804137468338, 'loss_2': 0.002655029296875, 'loss_3': -15.383489608764648, 'loss_4': 3.3136682510375977, 'epoch': 1.7}
{'loss': 0.0806, 'grad_norm': 25.305339813232422, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.07630248367786407, 'loss_2': 0.00434112548828125, 'loss_3': -15.349072456359863, 'loss_4': 3.890493869781494, 'epoch': 1.71}
{'loss': 0.0473, 'grad_norm': 17.233421325683594, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.04394945129752159, 'loss_2': 0.003326416015625, 'loss_3': -15.50084114074707, 'loss_4': 3.5114152431488037, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 09:31:25,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:25,885 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:40<1:24:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:33,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024175435304641724, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.326, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.017423542216420174, 'eval_loss_2': 0.006751894950866699, 'eval_loss_3': -18.22567367553711, 'eval_loss_4': 3.8499937057495117, 'epoch': 1.72}
{'loss': 0.0527, 'grad_norm': 22.46889877319336, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.04793517291545868, 'loss_2': 0.00476837158203125, 'loss_3': -15.120834350585938, 'loss_4': 3.863910436630249, 'epoch': 1.72}
{'loss': 0.068, 'grad_norm': 20.75589370727539, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.06265323609113693, 'loss_2': 0.00537872314453125, 'loss_3': -15.18088150024414, 'loss_4': 4.073192119598389, 'epoch': 1.73}
{'loss': 0.0295, 'grad_norm': 8.242823600769043, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.02672423981130123, 'loss_2': 0.002819061279296875, 'loss_3': -15.279220581054688, 'loss_4': 4.356019020080566, 'epoch': 1.73}
{'loss': 0.0461, 'grad_norm': 9.401203155517578, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.0346505381166935, 'loss_2': 0.0114288330078125, 'loss_3': -15.16694164276123, 'loss_4': 4.637950897216797, 'epoch': 1.74}
{'loss': 0.0696, 'grad_norm': 13.148602485656738, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.04558785632252693, 'loss_2': 0.02398681640625, 'loss_3': -15.39918327331543, 'loss_4': 4.149701118469238, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 09:31:33,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:33,248 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:47<1:25:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:31:40,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03155086562037468, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.948, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017522793263196945, 'eval_loss_2': 0.014028072357177734, 'eval_loss_3': -18.207855224609375, 'eval_loss_4': 4.315035820007324, 'epoch': 1.74}
{'loss': 0.0722, 'grad_norm': 16.826705932617188, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.06630875915288925, 'loss_2': 0.005859375, 'loss_3': -15.364435195922852, 'loss_4': 4.572538375854492, 'epoch': 1.75}
{'loss': 0.0312, 'grad_norm': 7.886032581329346, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.025749294087290764, 'loss_2': 0.005462646484375, 'loss_3': -15.487510681152344, 'loss_4': 4.968526840209961, 'epoch': 1.76}
{'loss': 0.0243, 'grad_norm': 7.886648178100586, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.023701824247837067, 'loss_2': 0.0005593299865722656, 'loss_3': -15.219722747802734, 'loss_4': 4.608802795410156, 'epoch': 1.76}
{'loss': 0.0636, 'grad_norm': 13.325611114501953, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.05352472513914108, 'loss_2': 0.01004791259765625, 'loss_3': -15.186616897583008, 'loss_4': 4.879087924957275, 'epoch': 1.77}
{'loss': 0.0886, 'grad_norm': 23.46965980529785, 'learning_rate': 2.825e-05, 'loss_1': 0.07554160803556442, 'loss_2': 0.01308441162109375, 'loss_3': -15.32059097290039, 'loss_4': 4.684782028198242, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 09:31:40,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:40,776 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [07:55<1:24:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:48,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0369272418320179, 'eval_runtime': 3.8202, 'eval_samples_per_second': 268.048, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01908399537205696, 'eval_loss_2': 0.017843246459960938, 'eval_loss_3': -18.176464080810547, 'eval_loss_4': 4.828468322753906, 'epoch': 1.77}
{'loss': 0.1117, 'grad_norm': 33.335975646972656, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.1009710356593132, 'loss_2': 0.01068878173828125, 'loss_3': -15.197473526000977, 'loss_4': 4.526371955871582, 'epoch': 1.78}
{'loss': 0.1541, 'grad_norm': 37.13323974609375, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.1393774300813675, 'loss_2': 0.0147247314453125, 'loss_3': -14.974849700927734, 'loss_4': 5.014408111572266, 'epoch': 1.78}
{'loss': 0.0837, 'grad_norm': 19.022865295410156, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.06864167749881744, 'loss_2': 0.01509857177734375, 'loss_3': -15.402584075927734, 'loss_4': 5.049429893493652, 'epoch': 1.79}
{'loss': 0.0643, 'grad_norm': 15.353263854980469, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.05086655169725418, 'loss_2': 0.0134735107421875, 'loss_3': -15.362127304077148, 'loss_4': 4.714901924133301, 'epoch': 1.8}
{'loss': 0.0579, 'grad_norm': 16.94586181640625, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.05182298645377159, 'loss_2': 0.006103515625, 'loss_3': -15.43133544921875, 'loss_4': 4.253586769104004, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 09:31:48,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:48,152 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:02<1:24:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:31:55,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02944815903902054, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.817, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.020579703152179718, 'eval_loss_2': 0.00886845588684082, 'eval_loss_3': -18.216930389404297, 'eval_loss_4': 5.353003025054932, 'epoch': 1.8}
{'loss': 0.037, 'grad_norm': 11.438504219055176, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.03688957169651985, 'loss_2': 0.00010442733764648438, 'loss_3': -15.504732131958008, 'loss_4': 5.014769554138184, 'epoch': 1.81}
{'loss': 0.0271, 'grad_norm': 7.547938823699951, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.024105191230773926, 'loss_2': 0.003032684326171875, 'loss_3': -15.469949722290039, 'loss_4': 5.269200325012207, 'epoch': 1.81}
{'loss': 0.1123, 'grad_norm': 27.39287567138672, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.10955429077148438, 'loss_2': 0.002719879150390625, 'loss_3': -15.184455871582031, 'loss_4': 5.646093368530273, 'epoch': 1.82}
{'loss': 0.0658, 'grad_norm': 18.167844772338867, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.05926551669836044, 'loss_2': 0.006561279296875, 'loss_3': -15.515653610229492, 'loss_4': 5.665826320648193, 'epoch': 1.83}
{'loss': 0.0978, 'grad_norm': 24.415403366088867, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.09140875190496445, 'loss_2': 0.006427764892578125, 'loss_3': -15.58692455291748, 'loss_4': 5.763016700744629, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 09:31:55,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:31:55,523 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:10<1:23:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:02,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029784608632326126, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.021612096577882767, 'eval_loss_2': 0.00817251205444336, 'eval_loss_3': -18.195697784423828, 'eval_loss_4': 5.589163780212402, 'epoch': 1.83}
{'loss': 0.0597, 'grad_norm': 11.844374656677246, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.05297388881444931, 'loss_2': 0.00676727294921875, 'loss_3': -15.50492000579834, 'loss_4': 5.756447792053223, 'epoch': 1.84}
{'loss': 0.0787, 'grad_norm': 14.025501251220703, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.06468483805656433, 'loss_2': 0.0140228271484375, 'loss_3': -15.36679458618164, 'loss_4': 5.954129695892334, 'epoch': 1.84}
{'loss': 0.0614, 'grad_norm': 13.930399894714355, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.049935705959796906, 'loss_2': 0.011474609375, 'loss_3': -15.287339210510254, 'loss_4': 5.437080383300781, 'epoch': 1.85}
{'loss': 0.0623, 'grad_norm': 16.923091888427734, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.06115614250302315, 'loss_2': 0.0011501312255859375, 'loss_3': -15.508804321289062, 'loss_4': 6.354743957519531, 'epoch': 1.85}
{'loss': 0.141, 'grad_norm': 38.58319091796875, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.13656938076019287, 'loss_2': 0.00447845458984375, 'loss_3': -15.326580047607422, 'loss_4': 5.412240028381348, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 09:32:02,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:02,880 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:17<1:24:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:10,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02649836614727974, 'eval_runtime': 3.8554, 'eval_samples_per_second': 265.6, 'eval_steps_per_second': 4.15, 'eval_loss_1': 0.02276310883462429, 'eval_loss_2': 0.003735259175300598, 'eval_loss_3': -18.202239990234375, 'eval_loss_4': 5.410493850708008, 'epoch': 1.86}
{'loss': 0.078, 'grad_norm': 23.467758178710938, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.07586032152175903, 'loss_2': 0.002117156982421875, 'loss_3': -15.286961555480957, 'loss_4': 5.036137580871582, 'epoch': 1.87}
{'loss': 0.0612, 'grad_norm': 18.294635772705078, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.0583282932639122, 'loss_2': 0.00283050537109375, 'loss_3': -15.352075576782227, 'loss_4': 4.742822170257568, 'epoch': 1.87}
{'loss': 0.0802, 'grad_norm': 20.27936363220215, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.07305316627025604, 'loss_2': 0.0071868896484375, 'loss_3': -15.649974822998047, 'loss_4': 4.891019344329834, 'epoch': 1.88}
{'loss': 0.1314, 'grad_norm': 28.208946228027344, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.13100789487361908, 'loss_2': 0.0004353523254394531, 'loss_3': -15.286938667297363, 'loss_4': 5.243897438049316, 'epoch': 1.88}
{'loss': 0.0688, 'grad_norm': 14.759041786193848, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.054582659155130386, 'loss_2': 0.01422119140625, 'loss_3': -15.32945442199707, 'loss_4': 4.928857326507568, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 09:32:10,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:10,289 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:24<1:23:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:17,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028011342510581017, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01833607815206051, 'eval_loss_2': 0.009675264358520508, 'eval_loss_3': -18.275047302246094, 'eval_loss_4': 4.805386066436768, 'epoch': 1.89}
{'loss': 0.0593, 'grad_norm': 24.364727020263672, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.05826716497540474, 'loss_2': 0.001033782958984375, 'loss_3': -15.569914817810059, 'loss_4': 5.68513298034668, 'epoch': 1.9}
{'loss': 0.0458, 'grad_norm': 9.811166763305664, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.03967757523059845, 'loss_2': 0.006099700927734375, 'loss_3': -15.656250953674316, 'loss_4': 4.746876239776611, 'epoch': 1.9}
{'loss': 0.0607, 'grad_norm': 14.421658515930176, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.05082090571522713, 'loss_2': 0.00989532470703125, 'loss_3': -15.450936317443848, 'loss_4': 4.863844871520996, 'epoch': 1.91}
{'loss': 0.048, 'grad_norm': 11.278902053833008, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.04397932440042496, 'loss_2': 0.00406646728515625, 'loss_3': -15.491172790527344, 'loss_4': 4.384733200073242, 'epoch': 1.91}
{'loss': 0.0376, 'grad_norm': 10.718842506408691, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.03691617399454117, 'loss_2': 0.0006380081176757812, 'loss_3': -15.606036186218262, 'loss_4': 4.994776725769043, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 09:32:17,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:17,649 >>   Batch size = 64
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:32<1:23:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:24,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021423764526844025, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017720289528369904, 'eval_loss_2': 0.003703474998474121, 'eval_loss_3': -18.289100646972656, 'eval_loss_4': 4.443109035491943, 'epoch': 1.92}
{'loss': 0.0381, 'grad_norm': 11.50981330871582, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.03725001588463783, 'loss_2': 0.0008492469787597656, 'loss_3': -15.563942909240723, 'loss_4': 4.844483852386475, 'epoch': 1.92}
{'loss': 0.0441, 'grad_norm': 11.213929176330566, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.04394516721367836, 'loss_2': 0.00019025802612304688, 'loss_3': -15.45638370513916, 'loss_4': 4.2140607833862305, 'epoch': 1.93}
{'loss': 0.1768, 'grad_norm': 22.81422233581543, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.17529217898845673, 'loss_2': 0.001514434814453125, 'loss_3': -15.365735054016113, 'loss_4': 4.54316520690918, 'epoch': 1.94}
{'loss': 0.0442, 'grad_norm': 10.156363487243652, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.03965865820646286, 'loss_2': 0.00452423095703125, 'loss_3': -15.376160621643066, 'loss_4': 4.6263580322265625, 'epoch': 1.94}
{'loss': 0.0458, 'grad_norm': 11.532334327697754, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.04444705322384834, 'loss_2': 0.0013256072998046875, 'loss_3': -15.469988822937012, 'loss_4': 4.115975856781006, 'epoch': 1.95}
[INFO|trainer.py:4228] 2025-01-21 09:32:24,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:24,996 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:39<1:23:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:32,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0254938006401062, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.023, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015199006535112858, 'eval_loss_2': 0.010294795036315918, 'eval_loss_3': -18.256038665771484, 'eval_loss_4': 4.052006244659424, 'epoch': 1.95}
{'loss': 0.0831, 'grad_norm': 14.948929786682129, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.0745270624756813, 'loss_2': 0.00860595703125, 'loss_3': -15.607076644897461, 'loss_4': 4.203126430511475, 'epoch': 1.95}
{'loss': 0.0898, 'grad_norm': 27.118833541870117, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.08786311000585556, 'loss_2': 0.0018978118896484375, 'loss_3': -15.406126976013184, 'loss_4': 3.8887815475463867, 'epoch': 1.96}
{'loss': 0.0672, 'grad_norm': 13.180022239685059, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.056368637830019, 'loss_2': 0.01081085205078125, 'loss_3': -15.288562774658203, 'loss_4': 4.345076084136963, 'epoch': 1.97}
{'loss': 0.0713, 'grad_norm': 12.722848892211914, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.05627384036779404, 'loss_2': 0.015045166015625, 'loss_3': -15.544259071350098, 'loss_4': 4.250616550445557, 'epoch': 1.97}
{'loss': 0.0514, 'grad_norm': 13.629130363464355, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.04794596508145332, 'loss_2': 0.003437042236328125, 'loss_3': -15.529279708862305, 'loss_4': 4.567072868347168, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 09:32:32,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:32,348 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:46<1:18:30,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:32:39,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03307146206498146, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.649, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01837081089615822, 'eval_loss_2': 0.014700651168823242, 'eval_loss_3': -18.236234664916992, 'eval_loss_4': 3.859649658203125, 'epoch': 1.98}
{'loss': 0.0491, 'grad_norm': 11.802273750305176, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.03451022133231163, 'loss_2': 0.01458740234375, 'loss_3': -15.666216850280762, 'loss_4': 3.9128804206848145, 'epoch': 1.98}
{'loss': 0.0547, 'grad_norm': 18.001068115234375, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.052296873182058334, 'loss_2': 0.002429962158203125, 'loss_3': -15.510436058044434, 'loss_4': 3.7504305839538574, 'epoch': 1.99}
{'loss': 0.0552, 'grad_norm': 11.015522956848145, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.04852268472313881, 'loss_2': 0.006633758544921875, 'loss_3': -15.433782577514648, 'loss_4': 4.1054511070251465, 'epoch': 1.99}
{'loss': 0.0533, 'grad_norm': 22.070558547973633, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.04428265616297722, 'loss_2': 0.0089874267578125, 'loss_3': -15.28844928741455, 'loss_4': 4.165042400360107, 'epoch': 2.0}
{'loss': 0.0647, 'grad_norm': 12.722587585449219, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.054205916821956635, 'loss_2': 0.010528564453125, 'loss_3': -15.443652153015137, 'loss_4': 3.4573888778686523, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 09:32:39,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:39,396 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [08:53<1:22:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:32:46,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02970234677195549, 'eval_runtime': 3.816, 'eval_samples_per_second': 268.345, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.025535760447382927, 'eval_loss_2': 0.004166588187217712, 'eval_loss_3': -18.167348861694336, 'eval_loss_4': 3.5765910148620605, 'epoch': 2.01}
{'loss': 0.062, 'grad_norm': 16.583087921142578, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.0526641421020031, 'loss_2': 0.00930023193359375, 'loss_3': -15.443208694458008, 'loss_4': 3.806502103805542, 'epoch': 2.01}
{'loss': 0.0758, 'grad_norm': 15.944607734680176, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.061333175748586655, 'loss_2': 0.0144805908203125, 'loss_3': -15.488016128540039, 'loss_4': 3.5513792037963867, 'epoch': 2.02}
{'loss': 0.0672, 'grad_norm': 18.137836456298828, 'learning_rate': 2.8e-05, 'loss_1': 0.058615148067474365, 'loss_2': 0.00860595703125, 'loss_3': -15.470803260803223, 'loss_4': 3.518726110458374, 'epoch': 2.02}
{'loss': 0.0392, 'grad_norm': 9.7996244430542, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.029704121872782707, 'loss_2': 0.0095062255859375, 'loss_3': -15.474039077758789, 'loss_4': 3.2581663131713867, 'epoch': 2.03}
{'loss': 0.0646, 'grad_norm': 13.5200834274292, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.053750962018966675, 'loss_2': 0.0108795166015625, 'loss_3': -15.5985107421875, 'loss_4': 3.221796989440918, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 09:32:46,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:46,755 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:01<1:23:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:32:54,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0369633287191391, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.011, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.02747945860028267, 'eval_loss_2': 0.009483873844146729, 'eval_loss_3': -18.120393753051758, 'eval_loss_4': 3.717656373977661, 'epoch': 2.03}
{'loss': 0.0747, 'grad_norm': 24.176856994628906, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.0696544349193573, 'loss_2': 0.00502777099609375, 'loss_3': -15.483659744262695, 'loss_4': 4.004200458526611, 'epoch': 2.04}
{'loss': 0.1434, 'grad_norm': 21.53664207458496, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.14186708629131317, 'loss_2': 0.0015392303466796875, 'loss_3': -15.397200584411621, 'loss_4': 4.382185935974121, 'epoch': 2.05}
{'loss': 0.04, 'grad_norm': 13.629735946655273, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.03645060956478119, 'loss_2': 0.0035457611083984375, 'loss_3': -15.310596466064453, 'loss_4': 3.085679054260254, 'epoch': 2.05}
{'loss': 0.0499, 'grad_norm': 17.183502197265625, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.049526046961545944, 'loss_2': 0.000408172607421875, 'loss_3': -15.552942276000977, 'loss_4': 3.3433852195739746, 'epoch': 2.06}
{'loss': 0.0327, 'grad_norm': 8.84056282043457, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.02807820960879326, 'loss_2': 0.00463104248046875, 'loss_3': -15.500022888183594, 'loss_4': 4.066673278808594, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 09:32:54,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:32:54,118 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:08<1:23:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:01,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018601858988404274, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013170208781957626, 'eval_loss_2': 0.005431652069091797, 'eval_loss_3': -18.178617477416992, 'eval_loss_4': 3.7719039916992188, 'epoch': 2.06}
{'loss': 0.0643, 'grad_norm': 17.65220832824707, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.06332391500473022, 'loss_2': 0.000980377197265625, 'loss_3': -15.518746376037598, 'loss_4': 4.147753715515137, 'epoch': 2.07}
{'loss': 0.0704, 'grad_norm': 15.806642532348633, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.06637821346521378, 'loss_2': 0.00397491455078125, 'loss_3': -15.522958755493164, 'loss_4': 3.6360960006713867, 'epoch': 2.08}
{'loss': 0.0336, 'grad_norm': 11.964973449707031, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.03138326108455658, 'loss_2': 0.002227783203125, 'loss_3': -15.73287582397461, 'loss_4': 4.179718017578125, 'epoch': 2.08}
{'loss': 0.0379, 'grad_norm': 10.433001518249512, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.029843401163816452, 'loss_2': 0.00801849365234375, 'loss_3': -15.282510757446289, 'loss_4': 4.639465808868408, 'epoch': 2.09}
{'loss': 0.04, 'grad_norm': 9.775639533996582, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.031807489693164825, 'loss_2': 0.0082244873046875, 'loss_3': -15.2632417678833, 'loss_4': 4.550034523010254, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 09:33:01,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:01,471 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:16<1:23:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:08,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019374143332242966, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.267, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.012018452398478985, 'eval_loss_2': 0.007355690002441406, 'eval_loss_3': -18.22808074951172, 'eval_loss_4': 3.979620933532715, 'epoch': 2.09}
{'loss': 0.046, 'grad_norm': 11.662247657775879, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.035993024706840515, 'loss_2': 0.010009765625, 'loss_3': -15.33657169342041, 'loss_4': 4.298352241516113, 'epoch': 2.1}
{'loss': 0.0336, 'grad_norm': 7.965864181518555, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.025179915130138397, 'loss_2': 0.008392333984375, 'loss_3': -15.612506866455078, 'loss_4': 4.478860855102539, 'epoch': 2.1}
{'loss': 0.0279, 'grad_norm': 8.626652717590332, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.02555817924439907, 'loss_2': 0.002368927001953125, 'loss_3': -15.388690948486328, 'loss_4': 4.125802040100098, 'epoch': 2.11}
{'loss': 0.0469, 'grad_norm': 13.723572731018066, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.045991674065589905, 'loss_2': 0.000881195068359375, 'loss_3': -15.442821502685547, 'loss_4': 4.245990753173828, 'epoch': 2.12}
{'loss': 0.0572, 'grad_norm': 19.103134155273438, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.05615020543336868, 'loss_2': 0.0010919570922851562, 'loss_3': -15.196605682373047, 'loss_4': 3.8432276248931885, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 09:33:08,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:08,835 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:23<1:22:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:16,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019312329590320587, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.799, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012492339126765728, 'eval_loss_2': 0.006819993257522583, 'eval_loss_3': -18.21694564819336, 'eval_loss_4': 3.786365032196045, 'epoch': 2.12}
{'loss': 0.0451, 'grad_norm': 13.563910484313965, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.03758436441421509, 'loss_2': 0.00753021240234375, 'loss_3': -15.331120491027832, 'loss_4': 4.156595706939697, 'epoch': 2.13}
{'loss': 0.0512, 'grad_norm': 12.685283660888672, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.04486900940537453, 'loss_2': 0.006343841552734375, 'loss_3': -15.225404739379883, 'loss_4': 3.752544403076172, 'epoch': 2.13}
{'loss': 0.0612, 'grad_norm': 19.48967742919922, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.06086989492177963, 'loss_2': 0.0003571510314941406, 'loss_3': -15.277056694030762, 'loss_4': 3.988676071166992, 'epoch': 2.14}
{'loss': 0.0385, 'grad_norm': 10.595809936523438, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.03502557426691055, 'loss_2': 0.00351715087890625, 'loss_3': -15.216070175170898, 'loss_4': 4.296384334564209, 'epoch': 2.15}
{'loss': 0.042, 'grad_norm': 10.357030868530273, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.041236940771341324, 'loss_2': 0.0008001327514648438, 'loss_3': -15.383337020874023, 'loss_4': 4.216860294342041, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 09:33:16,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:16,192 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:30<1:22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:23,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017043307423591614, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.673, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012644365429878235, 'eval_loss_2': 0.004398941993713379, 'eval_loss_3': -18.21695327758789, 'eval_loss_4': 3.7183098793029785, 'epoch': 2.15}
{'loss': 0.0275, 'grad_norm': 6.275502681732178, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.02026963233947754, 'loss_2': 0.0071868896484375, 'loss_3': -15.550597190856934, 'loss_4': 3.3868653774261475, 'epoch': 2.16}
{'loss': 0.2074, 'grad_norm': 32.34049606323242, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.20667295157909393, 'loss_2': 0.0007276535034179688, 'loss_3': -15.440421104431152, 'loss_4': 3.5712366104125977, 'epoch': 2.16}
{'loss': 0.0523, 'grad_norm': 14.779770851135254, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.04593845084309578, 'loss_2': 0.006378173828125, 'loss_3': -15.360631942749023, 'loss_4': 4.292257308959961, 'epoch': 2.17}
{'loss': 0.0449, 'grad_norm': 10.424219131469727, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.03951582685112953, 'loss_2': 0.005352020263671875, 'loss_3': -15.322163581848145, 'loss_4': 4.434337139129639, 'epoch': 2.17}
{'loss': 0.0527, 'grad_norm': 13.046734809875488, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.03882632404565811, 'loss_2': 0.0138702392578125, 'loss_3': -15.226524353027344, 'loss_4': 4.094210624694824, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 09:33:23,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:23,550 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:38<1:22:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:30,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021157322451472282, 'eval_runtime': 3.8234, 'eval_samples_per_second': 267.824, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.012874539941549301, 'eval_loss_2': 0.008282780647277832, 'eval_loss_3': -18.203903198242188, 'eval_loss_4': 3.893413543701172, 'epoch': 2.18}
{'loss': 0.0335, 'grad_norm': 9.448380470275879, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.033095721155405045, 'loss_2': 0.0004031658172607422, 'loss_3': -15.279090881347656, 'loss_4': 3.9170398712158203, 'epoch': 2.19}
{'loss': 0.03, 'grad_norm': 7.082931041717529, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.024324869737029076, 'loss_2': 0.00565338134765625, 'loss_3': -15.378314971923828, 'loss_4': 4.409050941467285, 'epoch': 2.19}
{'loss': 0.0491, 'grad_norm': 16.732275009155273, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.04072289168834686, 'loss_2': 0.008392333984375, 'loss_3': -15.444082260131836, 'loss_4': 4.14350700378418, 'epoch': 2.2}
{'loss': 0.0318, 'grad_norm': 9.323429107666016, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.02805304154753685, 'loss_2': 0.0037059783935546875, 'loss_3': -15.46822452545166, 'loss_4': 3.942782402038574, 'epoch': 2.2}
{'loss': 0.0504, 'grad_norm': 12.915510177612305, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.041099805384874344, 'loss_2': 0.00927734375, 'loss_3': -15.377309799194336, 'loss_4': 4.223348140716553, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 09:33:30,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:30,923 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:45<1:22:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:38,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01937444508075714, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014445019885897636, 'eval_loss_2': 0.0049294233322143555, 'eval_loss_3': -18.186138153076172, 'eval_loss_4': 3.790620803833008, 'epoch': 2.21}
{'loss': 0.0417, 'grad_norm': 10.757608413696289, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.03046824038028717, 'loss_2': 0.0112152099609375, 'loss_3': -15.362525939941406, 'loss_4': 4.027114391326904, 'epoch': 2.22}
{'loss': 0.0422, 'grad_norm': 12.595626831054688, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.03242143243551254, 'loss_2': 0.0097808837890625, 'loss_3': -15.161795616149902, 'loss_4': 3.670902729034424, 'epoch': 2.22}
{'loss': 0.0731, 'grad_norm': 19.52214241027832, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.07080090045928955, 'loss_2': 0.002323150634765625, 'loss_3': -15.329626083374023, 'loss_4': 3.931814670562744, 'epoch': 2.23}
{'loss': 0.046, 'grad_norm': 12.835589408874512, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.04445083439350128, 'loss_2': 0.0015926361083984375, 'loss_3': -15.344247817993164, 'loss_4': 4.2708845138549805, 'epoch': 2.23}
{'loss': 0.0396, 'grad_norm': 13.521291732788086, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.03388317674398422, 'loss_2': 0.005680084228515625, 'loss_3': -15.462387084960938, 'loss_4': 3.6199488639831543, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 09:33:38,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:38,278 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:52<1:22:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:45,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01721607893705368, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.905, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.014062903821468353, 'eval_loss_2': 0.003153175115585327, 'eval_loss_3': -18.165433883666992, 'eval_loss_4': 3.7950522899627686, 'epoch': 2.24}
{'loss': 0.0405, 'grad_norm': 12.889437675476074, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.03642275556921959, 'loss_2': 0.0040740966796875, 'loss_3': -15.261547088623047, 'loss_4': 3.367440938949585, 'epoch': 2.24}
{'loss': 0.0466, 'grad_norm': 15.037654876708984, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.03991261124610901, 'loss_2': 0.00670623779296875, 'loss_3': -15.394057273864746, 'loss_4': 3.920681953430176, 'epoch': 2.25}
{'loss': 0.0723, 'grad_norm': 20.613842010498047, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.06665784865617752, 'loss_2': 0.00562286376953125, 'loss_3': -15.473004341125488, 'loss_4': 4.373729228973389, 'epoch': 2.26}
{'loss': 0.0296, 'grad_norm': 9.66114330291748, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.021443771198391914, 'loss_2': 0.0081634521484375, 'loss_3': -15.397444725036621, 'loss_4': 4.569526672363281, 'epoch': 2.26}
{'loss': 0.0411, 'grad_norm': 10.932106018066406, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.03271425887942314, 'loss_2': 0.00843048095703125, 'loss_3': -15.40921688079834, 'loss_4': 4.455913543701172, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 09:33:45,638 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:45,638 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:00<1:22:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:33:52,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017191484570503235, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.863, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011999323032796383, 'eval_loss_2': 0.005192160606384277, 'eval_loss_3': -18.23440933227539, 'eval_loss_4': 3.9142446517944336, 'epoch': 2.27}
{'loss': 0.0386, 'grad_norm': 11.004284858703613, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.03702227398753166, 'loss_2': 0.001560211181640625, 'loss_3': -15.492337226867676, 'loss_4': 3.925511598587036, 'epoch': 2.27}
{'loss': 0.0351, 'grad_norm': 12.098652839660645, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.030367882922291756, 'loss_2': 0.0047149658203125, 'loss_3': -15.368099212646484, 'loss_4': 4.454150199890137, 'epoch': 2.28}
{'loss': 0.053, 'grad_norm': 15.445687294006348, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.04031272232532501, 'loss_2': 0.0127105712890625, 'loss_3': -15.643717765808105, 'loss_4': 4.022479057312012, 'epoch': 2.28}
{'loss': 0.0374, 'grad_norm': 18.250057220458984, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.03515472635626793, 'loss_2': 0.0022525787353515625, 'loss_3': -15.71259880065918, 'loss_4': 5.071633338928223, 'epoch': 2.29}
{'loss': 0.0281, 'grad_norm': 14.23171615600586, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.0263245590031147, 'loss_2': 0.00180816650390625, 'loss_3': -15.420509338378906, 'loss_4': 4.615407943725586, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 09:33:52,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:33:52,991 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:04<1:22:27,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:33:56,803 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395
[INFO|configuration_utils.py:420] 2025-01-21 09:33:56,804 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395/config.json                                                                              
{'eval_loss': 0.013450272381305695, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.724, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010446535423398018, 'eval_loss_2': 0.003003738820552826, 'eval_loss_3': -18.321537017822266, 'eval_loss_4': 4.138518333435059, 'epoch': 2.3}
[INFO|modeling_utils.py:2988] 2025-01-21 09:33:57,284 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:33:57,285 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:33:57,285 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:33:58,171 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-265] due to args.save_total_limit
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:09<1:30:44,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:34:01,806 >>
{'loss': 0.0536, 'grad_norm': 16.243724822998047, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.05060509964823723, 'loss_2': 0.00302886962890625, 'loss_3': -15.129841804504395, 'loss_4': 4.258484840393066, 'epoch': 2.3}
{'loss': 0.0328, 'grad_norm': 8.762174606323242, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.024454860016703606, 'loss_2': 0.0083160400390625, 'loss_3': -15.331380844116211, 'loss_4': 4.592686653137207, 'epoch': 2.31}
{'loss': 0.0294, 'grad_norm': 8.827427864074707, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.024878323078155518, 'loss_2': 0.004482269287109375, 'loss_3': -15.531048774719238, 'loss_4': 4.806297302246094, 'epoch': 2.31}
{'loss': 0.0657, 'grad_norm': 20.120954513549805, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.06225539371371269, 'loss_2': 0.00344085693359375, 'loss_3': -15.2282075881958, 'loss_4': 5.202473163604736, 'epoch': 2.32}
{'loss': 0.0587, 'grad_norm': 18.97403907775879, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.04908233880996704, 'loss_2': 0.00965118408203125, 'loss_3': -15.293588638305664, 'loss_4': 5.371974945068359, 'epoch': 2.33}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:34:01,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:01,807 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:12<1:30:44,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 09:34:05,615 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400
[INFO|configuration_utils.py:420] 2025-01-21 09:34:05,616 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400/config.json                                                                              
{'eval_loss': 0.012599797919392586, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009019033052027225, 'eval_loss_2': 0.0035807639360427856, 'eval_loss_3': -18.310962677001953, 'eval_loss_4': 4.504270553588867, 'epoch': 2.33}
[INFO|modeling_utils.py:2988] 2025-01-21 09:34:06,166 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:34:06,168 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:34:06,168 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:34:07,106 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-395] due to args.save_total_limit
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:17<1:32:41,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 09:34:10,739 >>
{'loss': 0.0604, 'grad_norm': 13.46273422241211, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.04913393408060074, 'loss_2': 0.01126861572265625, 'loss_3': -15.308284759521484, 'loss_4': 5.060268402099609, 'epoch': 2.33}
{'loss': 0.0734, 'grad_norm': 21.050350189208984, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.06843981891870499, 'loss_2': 0.0049285888671875, 'loss_3': -15.256746292114258, 'loss_4': 4.882472038269043, 'epoch': 2.34}
{'loss': 0.0408, 'grad_norm': 17.129779815673828, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.030702296644449234, 'loss_2': 0.0100555419921875, 'loss_3': -15.416335105895996, 'loss_4': 4.8770222663879395, 'epoch': 2.34}
{'loss': 0.0701, 'grad_norm': 14.353517532348633, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.05121404305100441, 'loss_2': 0.0189208984375, 'loss_3': -15.331287384033203, 'loss_4': 5.528367042541504, 'epoch': 2.35}
{'loss': 0.0372, 'grad_norm': 10.039177894592285, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.02877279743552208, 'loss_2': 0.008453369140625, 'loss_3': -15.231462478637695, 'loss_4': 4.693243503570557, 'epoch': 2.35}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:34:10,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:10,740 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:25<1:23:44,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:34:18,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023460643365979195, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010365740396082401, 'eval_loss_2': 0.013094902038574219, 'eval_loss_3': -18.305770874023438, 'eval_loss_4': 3.866941452026367, 'epoch': 2.35}
{'loss': 0.0489, 'grad_norm': 15.023300170898438, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.03440059348940849, 'loss_2': 0.01446533203125, 'loss_3': -15.38587760925293, 'loss_4': 5.5816240310668945, 'epoch': 2.36}
{'loss': 0.0547, 'grad_norm': 15.624154090881348, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.041475992649793625, 'loss_2': 0.01320648193359375, 'loss_3': -15.424760818481445, 'loss_4': 3.983680009841919, 'epoch': 2.37}
{'loss': 0.0446, 'grad_norm': 13.061925888061523, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.04248511791229248, 'loss_2': 0.002079010009765625, 'loss_3': -15.209033966064453, 'loss_4': 4.190195560455322, 'epoch': 2.37}
{'loss': 0.0354, 'grad_norm': 8.593979835510254, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.027030305936932564, 'loss_2': 0.008331298828125, 'loss_3': -15.243585586547852, 'loss_4': 4.187326431274414, 'epoch': 2.38}
{'loss': 0.0601, 'grad_norm': 16.024372100830078, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.05083120986819267, 'loss_2': 0.00931549072265625, 'loss_3': -15.330432891845703, 'loss_4': 4.543814659118652, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 09:34:18,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:18,077 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:32<1:22:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:25,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015354040078818798, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010829214006662369, 'eval_loss_2': 0.004524827003479004, 'eval_loss_3': -18.28977394104004, 'eval_loss_4': 2.7954108715057373, 'epoch': 2.38}
{'loss': 0.0665, 'grad_norm': 17.575725555419922, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.06565751135349274, 'loss_2': 0.0008325576782226562, 'loss_3': -15.198074340820312, 'loss_4': 4.29212760925293, 'epoch': 2.39}
{'loss': 0.0446, 'grad_norm': 19.121091842651367, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.04166250675916672, 'loss_2': 0.00296783447265625, 'loss_3': -15.327569007873535, 'loss_4': 3.5581107139587402, 'epoch': 2.4}
{'loss': 0.0257, 'grad_norm': 10.875323295593262, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.025213725864887238, 'loss_2': 0.000453948974609375, 'loss_3': -15.471979141235352, 'loss_4': 3.222320795059204, 'epoch': 2.4}
{'loss': 0.0401, 'grad_norm': 10.70913028717041, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.029095128178596497, 'loss_2': 0.0110015869140625, 'loss_3': -15.23791790008545, 'loss_4': 2.2609925270080566, 'epoch': 2.41}
{'loss': 0.0757, 'grad_norm': 21.96308708190918, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.06576894968748093, 'loss_2': 0.0098876953125, 'loss_3': -15.088761329650879, 'loss_4': 2.4764480590820312, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 09:34:25,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:25,416 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:39<1:22:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:32,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013164669275283813, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008976750075817108, 'eval_loss_2': 0.004187919199466705, 'eval_loss_3': -18.2413330078125, 'eval_loss_4': 1.8910073041915894, 'epoch': 2.41}
{'loss': 0.0386, 'grad_norm': 11.100808143615723, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.023866897448897362, 'loss_2': 0.0146942138671875, 'loss_3': -15.181283950805664, 'loss_4': 1.805243968963623, 'epoch': 2.42}
{'loss': 0.0362, 'grad_norm': 13.691422462463379, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.025937065482139587, 'loss_2': 0.01025390625, 'loss_3': -15.390501976013184, 'loss_4': 2.3884873390197754, 'epoch': 2.42}
{'loss': 0.0146, 'grad_norm': 5.456366539001465, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.00794992782175541, 'loss_2': 0.00667572021484375, 'loss_3': -15.435335159301758, 'loss_4': 2.5823886394500732, 'epoch': 2.43}
{'loss': 0.0342, 'grad_norm': 10.90673828125, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.028044288977980614, 'loss_2': 0.00611114501953125, 'loss_3': -15.363378524780273, 'loss_4': 2.6149563789367676, 'epoch': 2.44}
{'loss': 0.0459, 'grad_norm': 23.30043601989746, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.03898550197482109, 'loss_2': 0.00693511962890625, 'loss_3': -15.252067565917969, 'loss_4': 1.6353545188903809, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 09:34:32,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:32,771 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:43<1:22:05,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:34:36,578 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420
[INFO|configuration_utils.py:420] 2025-01-21 09:34:36,579 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420/config.json                                                                              
{'eval_loss': 0.010627076029777527, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.08, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007807609159499407, 'eval_loss_2': 0.0028194673359394073, 'eval_loss_3': -18.193378448486328, 'eval_loss_4': 1.7473536729812622, 'epoch': 2.44}
[INFO|modeling_utils.py:2988] 2025-01-21 09:34:37,067 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:34:37,068 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:34:37,069 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:34:37,955 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-400] due to args.save_total_limit
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:48<1:30:09,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:34:41,577 >>
{'loss': 0.0303, 'grad_norm': 12.97403621673584, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.02684008702635765, 'loss_2': 0.003490447998046875, 'loss_3': -15.256315231323242, 'loss_4': 2.2924981117248535, 'epoch': 2.45}
{'loss': 0.0187, 'grad_norm': 8.318550109863281, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.018485886976122856, 'loss_2': 0.00022459030151367188, 'loss_3': -15.28991413116455, 'loss_4': 1.896575689315796, 'epoch': 2.45}
{'loss': 0.0247, 'grad_norm': 6.633481979370117, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.019018614664673805, 'loss_2': 0.0056610107421875, 'loss_3': -15.489648818969727, 'loss_4': 2.314467430114746, 'epoch': 2.46}
{'loss': 0.0569, 'grad_norm': 23.281932830810547, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.055041491985321045, 'loss_2': 0.0018901824951171875, 'loss_3': -15.013195991516113, 'loss_4': 2.788344383239746, 'epoch': 2.47}
{'loss': 0.0229, 'grad_norm': 7.485203266143799, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.019424106925725937, 'loss_2': 0.003520965576171875, 'loss_3': -15.210137367248535, 'loss_4': 2.286980152130127, 'epoch': 2.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:34:41,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:41,577 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:56<1:23:04,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:34:48,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013216577470302582, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.74, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009772412478923798, 'eval_loss_2': 0.003444164991378784, 'eval_loss_3': -18.171527862548828, 'eval_loss_4': 1.5456397533416748, 'epoch': 2.47}
{'loss': 0.0415, 'grad_norm': 13.303815841674805, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.036319609731435776, 'loss_2': 0.0051422119140625, 'loss_3': -15.22339916229248, 'loss_4': 2.1744544506073, 'epoch': 2.48}
{'loss': 0.0298, 'grad_norm': 12.478226661682129, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.023209361359477043, 'loss_2': 0.00662994384765625, 'loss_3': -15.126543045043945, 'loss_4': 1.9083096981048584, 'epoch': 2.48}
{'loss': 0.0268, 'grad_norm': 8.17912769317627, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.019069159403443336, 'loss_2': 0.00771331787109375, 'loss_3': -15.227619171142578, 'loss_4': 1.2356019020080566, 'epoch': 2.49}
{'loss': 0.0318, 'grad_norm': 10.813833236694336, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.028056658804416656, 'loss_2': 0.0037517547607421875, 'loss_3': -15.235505104064941, 'loss_4': 1.5500469207763672, 'epoch': 2.49}
{'loss': 0.0909, 'grad_norm': 23.504196166992188, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.08801940828561783, 'loss_2': 0.0028362274169921875, 'loss_3': -15.23768424987793, 'loss_4': 2.042264938354492, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 09:34:48,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:48,922 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:03<1:21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:34:56,269 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015014177188277245, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011416337452828884, 'eval_loss_2': 0.003597840666770935, 'eval_loss_3': -18.156597137451172, 'eval_loss_4': 1.332163691520691, 'epoch': 2.5}
{'loss': 0.0575, 'grad_norm': 15.195159912109375, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.05301934853196144, 'loss_2': 0.0045013427734375, 'loss_3': -15.360630989074707, 'loss_4': 2.663877010345459, 'epoch': 2.51}
{'loss': 0.0494, 'grad_norm': 16.019058227539062, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.04867100715637207, 'loss_2': 0.0006990432739257812, 'loss_3': -15.330347061157227, 'loss_4': 2.125728130340576, 'epoch': 2.51}
{'loss': 0.0346, 'grad_norm': 13.015445709228516, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.032179009169340134, 'loss_2': 0.002391815185546875, 'loss_3': -15.301959037780762, 'loss_4': 1.378548502922058, 'epoch': 2.52}
{'loss': 0.0515, 'grad_norm': 16.10921859741211, 'learning_rate': 2.75e-05, 'loss_1': 0.04927237704396248, 'loss_2': 0.002269744873046875, 'loss_3': -15.13968276977539, 'loss_4': 1.869420051574707, 'epoch': 2.52}
{'loss': 0.0384, 'grad_norm': 22.895780563354492, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.033704109489917755, 'loss_2': 0.004730224609375, 'loss_3': -15.368558883666992, 'loss_4': 0.7928658723831177, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 09:34:56,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:34:56,269 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:10<1:21:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:03,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014377845451235771, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010580848902463913, 'eval_loss_2': 0.003796994686126709, 'eval_loss_3': -18.12659454345703, 'eval_loss_4': 1.0295238494873047, 'epoch': 2.53}
{'loss': 0.0548, 'grad_norm': 23.76764678955078, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.05258331820368767, 'loss_2': 0.0022449493408203125, 'loss_3': -15.20641040802002, 'loss_4': 1.568821907043457, 'epoch': 2.53}
{'loss': 0.0288, 'grad_norm': 6.85883903503418, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.0180119127035141, 'loss_2': 0.0108184814453125, 'loss_3': -15.531881332397461, 'loss_4': 1.617817759513855, 'epoch': 2.54}
{'loss': 0.0497, 'grad_norm': 14.199134826660156, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.0457502156496048, 'loss_2': 0.00399017333984375, 'loss_3': -15.54958724975586, 'loss_4': 1.8257105350494385, 'epoch': 2.55}
{'loss': 0.0633, 'grad_norm': 23.49941062927246, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.05901467800140381, 'loss_2': 0.004291534423828125, 'loss_3': -15.397908210754395, 'loss_4': 1.580047845840454, 'epoch': 2.55}
{'loss': 0.069, 'grad_norm': 18.600431442260742, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.052415117621421814, 'loss_2': 0.0166168212890625, 'loss_3': -15.284992218017578, 'loss_4': 1.0129890441894531, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 09:35:03,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:03,612 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:18<1:21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:10,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022102095186710358, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014751531183719635, 'eval_loss_2': 0.007350564002990723, 'eval_loss_3': -18.113710403442383, 'eval_loss_4': 1.068302869796753, 'epoch': 2.56}
{'loss': 0.0485, 'grad_norm': 12.519086837768555, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.03600116819143295, 'loss_2': 0.012542724609375, 'loss_3': -15.275710105895996, 'loss_4': 1.5717380046844482, 'epoch': 2.56}
{'loss': 0.0331, 'grad_norm': 8.149625778198242, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.026248550042510033, 'loss_2': 0.00687408447265625, 'loss_3': -15.267478942871094, 'loss_4': 1.044621467590332, 'epoch': 2.57}
{'loss': 0.0586, 'grad_norm': 17.114452362060547, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.05844547599554062, 'loss_2': 0.0001766681671142578, 'loss_3': -15.43753433227539, 'loss_4': 1.3919676542282104, 'epoch': 2.58}
{'loss': 0.0407, 'grad_norm': 16.00205421447754, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.03906218335032463, 'loss_2': 0.0015926361083984375, 'loss_3': -15.422637939453125, 'loss_4': 1.933827519416809, 'epoch': 2.58}
{'loss': 0.112, 'grad_norm': 31.838212966918945, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.1091059073805809, 'loss_2': 0.002902984619140625, 'loss_3': -15.435304641723633, 'loss_4': 1.3278381824493408, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 09:35:10,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:10,962 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:25<1:21:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:18,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02383793145418167, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.017095033079385757, 'eval_loss_2': 0.006742894649505615, 'eval_loss_3': -18.144943237304688, 'eval_loss_4': 1.2990050315856934, 'epoch': 2.59}
{'loss': 0.0552, 'grad_norm': 17.428682327270508, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.04907621443271637, 'loss_2': 0.006153106689453125, 'loss_3': -15.418900489807129, 'loss_4': 1.2252851724624634, 'epoch': 2.59}
{'loss': 0.0289, 'grad_norm': 10.508284568786621, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.026256145909428596, 'loss_2': 0.00266265869140625, 'loss_3': -15.421771049499512, 'loss_4': 1.82359778881073, 'epoch': 2.6}
{'loss': 0.033, 'grad_norm': 12.374281883239746, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.02928737923502922, 'loss_2': 0.0037384033203125, 'loss_3': -15.375452995300293, 'loss_4': 2.1392321586608887, 'epoch': 2.6}
{'loss': 0.0537, 'grad_norm': 9.850171089172363, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.03753187507390976, 'loss_2': 0.016204833984375, 'loss_3': -15.474477767944336, 'loss_4': 1.5966994762420654, 'epoch': 2.61}
{'loss': 0.0308, 'grad_norm': 8.000053405761719, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.02953212335705757, 'loss_2': 0.0012416839599609375, 'loss_3': -15.470635414123535, 'loss_4': 1.947459101676941, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 09:35:18,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:18,315 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:32<1:21:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:25,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01700633019208908, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.545, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.013089515268802643, 'eval_loss_2': 0.003916814923286438, 'eval_loss_3': -18.173229217529297, 'eval_loss_4': 1.8223299980163574, 'epoch': 2.62}
{'loss': 0.0539, 'grad_norm': 14.48641300201416, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.0478280708193779, 'loss_2': 0.00604248046875, 'loss_3': -15.571638107299805, 'loss_4': 2.7207822799682617, 'epoch': 2.62}
{'loss': 0.0581, 'grad_norm': 14.62475299835205, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.05269131809473038, 'loss_2': 0.005367279052734375, 'loss_3': -15.65698528289795, 'loss_4': 3.2545852661132812, 'epoch': 2.63}
{'loss': 0.0614, 'grad_norm': 15.58990478515625, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.056455254554748535, 'loss_2': 0.0049591064453125, 'loss_3': -15.563873291015625, 'loss_4': 2.8423476219177246, 'epoch': 2.63}
{'loss': 0.0401, 'grad_norm': 12.899262428283691, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.03847084194421768, 'loss_2': 0.0015926361083984375, 'loss_3': -15.383545875549316, 'loss_4': 2.6788153648376465, 'epoch': 2.64}
{'loss': 0.0509, 'grad_norm': 11.306504249572754, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.04633502662181854, 'loss_2': 0.0045166015625, 'loss_3': -15.330886840820312, 'loss_4': 2.76780366897583, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 09:35:25,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:25,678 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:40<1:21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:33,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014702891930937767, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.637, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010924256406724453, 'eval_loss_2': 0.0037786364555358887, 'eval_loss_3': -18.261335372924805, 'eval_loss_4': 2.40805721282959, 'epoch': 2.65}
{'loss': 0.0367, 'grad_norm': 8.19499397277832, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.031182771548628807, 'loss_2': 0.00556182861328125, 'loss_3': -15.53121566772461, 'loss_4': 2.153211832046509, 'epoch': 2.65}
{'loss': 0.0602, 'grad_norm': 21.338085174560547, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.05790319666266441, 'loss_2': 0.002330780029296875, 'loss_3': -15.563652038574219, 'loss_4': 2.9974780082702637, 'epoch': 2.66}
{'loss': 0.0448, 'grad_norm': 18.68995475769043, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.04415914788842201, 'loss_2': 0.0006036758422851562, 'loss_3': -15.635799407958984, 'loss_4': 3.360934257507324, 'epoch': 2.66}
{'loss': 0.0442, 'grad_norm': 9.040933609008789, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.03136586770415306, 'loss_2': 0.0128021240234375, 'loss_3': -15.65412425994873, 'loss_4': 3.190253257751465, 'epoch': 2.67}
{'loss': 0.0714, 'grad_norm': 18.24656105041504, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.06226309388875961, 'loss_2': 0.00916290283203125, 'loss_3': -15.866047859191895, 'loss_4': 3.38852858543396, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 09:35:33,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:33,033 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:47<1:21:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:40,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018027279525995255, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.871, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012512755580246449, 'eval_loss_2': 0.005514524877071381, 'eval_loss_3': -18.28509521484375, 'eval_loss_4': 2.8253278732299805, 'epoch': 2.67}
{'loss': 0.0603, 'grad_norm': 12.343973159790039, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.054294489324092865, 'loss_2': 0.006015777587890625, 'loss_3': -15.610118865966797, 'loss_4': 3.1779463291168213, 'epoch': 2.68}
{'loss': 0.0477, 'grad_norm': 12.810330390930176, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.045918457210063934, 'loss_2': 0.00182342529296875, 'loss_3': -15.726970672607422, 'loss_4': 3.339021682739258, 'epoch': 2.69}
{'loss': 0.0484, 'grad_norm': 12.252156257629395, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.045767951756715775, 'loss_2': 0.0026149749755859375, 'loss_3': -15.868040084838867, 'loss_4': 3.4368503093719482, 'epoch': 2.69}
{'loss': 0.0398, 'grad_norm': 13.132838249206543, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.03246532008051872, 'loss_2': 0.00736236572265625, 'loss_3': -15.771679878234863, 'loss_4': 3.3426618576049805, 'epoch': 2.7}
{'loss': 0.0806, 'grad_norm': 16.260772705078125, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.06801993399858475, 'loss_2': 0.0125732421875, 'loss_3': -15.711771011352539, 'loss_4': 3.2875566482543945, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 09:35:40,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:40,396 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:54<1:21:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:47,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020488958805799484, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.854, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011020135134458542, 'eval_loss_2': 0.009468823671340942, 'eval_loss_3': -18.303058624267578, 'eval_loss_4': 2.9513516426086426, 'epoch': 2.7}
{'loss': 0.0374, 'grad_norm': 8.383100509643555, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.026839081197977066, 'loss_2': 0.0105743408203125, 'loss_3': -15.884096145629883, 'loss_4': 3.1466376781463623, 'epoch': 2.71}
{'loss': 0.0387, 'grad_norm': 8.99644660949707, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.028964560478925705, 'loss_2': 0.009765625, 'loss_3': -15.765254020690918, 'loss_4': 3.5136356353759766, 'epoch': 2.72}
{'loss': 0.0512, 'grad_norm': 10.7847900390625, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.04248783737421036, 'loss_2': 0.0086669921875, 'loss_3': -15.82269287109375, 'loss_4': 2.930079936981201, 'epoch': 2.72}
{'loss': 0.0489, 'grad_norm': 12.07567024230957, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.04540001228451729, 'loss_2': 0.0034637451171875, 'loss_3': -15.642975807189941, 'loss_4': 2.7613587379455566, 'epoch': 2.73}
{'loss': 0.0453, 'grad_norm': 16.167455673217773, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.04479295015335083, 'loss_2': 0.0005331039428710938, 'loss_3': -15.720247268676758, 'loss_4': 2.8795061111450195, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 09:35:47,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:47,746 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:02<1:21:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:35:55,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013522684574127197, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008964508771896362, 'eval_loss_2': 0.004558175802230835, 'eval_loss_3': -18.243343353271484, 'eval_loss_4': 2.9236438274383545, 'epoch': 2.73}
{'loss': 0.1137, 'grad_norm': 22.389116287231445, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.11158918589353561, 'loss_2': 0.00208282470703125, 'loss_3': -15.523653984069824, 'loss_4': 3.7901949882507324, 'epoch': 2.74}
{'loss': 0.038, 'grad_norm': 11.870482444763184, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.03679265081882477, 'loss_2': 0.0012264251708984375, 'loss_3': -15.603797912597656, 'loss_4': 3.6365761756896973, 'epoch': 2.74}
{'loss': 0.032, 'grad_norm': 11.309454917907715, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.02928239479660988, 'loss_2': 0.002765655517578125, 'loss_3': -15.669028282165527, 'loss_4': 3.3799185752868652, 'epoch': 2.75}
{'loss': 0.0327, 'grad_norm': 7.9573588371276855, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.026818085461854935, 'loss_2': 0.0058746337890625, 'loss_3': -15.446239471435547, 'loss_4': 2.7385590076446533, 'epoch': 2.76}
{'loss': 0.0774, 'grad_norm': 23.272764205932617, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.07127973437309265, 'loss_2': 0.006122589111328125, 'loss_3': -15.596075057983398, 'loss_4': 3.3086447715759277, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 09:35:55,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:35:55,095 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:09<1:21:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:02,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013979105278849602, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.91, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010177677497267723, 'eval_loss_2': 0.0038014277815818787, 'eval_loss_3': -18.167699813842773, 'eval_loss_4': 3.0578958988189697, 'epoch': 2.76}
{'loss': 0.0436, 'grad_norm': 11.024410247802734, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.038368791341781616, 'loss_2': 0.00527191162109375, 'loss_3': -15.700868606567383, 'loss_4': 3.4688925743103027, 'epoch': 2.77}
{'loss': 0.0378, 'grad_norm': 11.053107261657715, 'learning_rate': 2.725e-05, 'loss_1': 0.034317512065172195, 'loss_2': 0.00347900390625, 'loss_3': -15.60925579071045, 'loss_4': 3.8583621978759766, 'epoch': 2.77}
{'loss': 0.0788, 'grad_norm': 17.4227294921875, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.0732012614607811, 'loss_2': 0.005584716796875, 'loss_3': -15.529495239257812, 'loss_4': 3.915465831756592, 'epoch': 2.78}
{'loss': 0.0263, 'grad_norm': 6.862003803253174, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.02025798335671425, 'loss_2': 0.00603485107421875, 'loss_3': -15.62630558013916, 'loss_4': 3.4434189796447754, 'epoch': 2.78}
{'loss': 0.0298, 'grad_norm': 11.042941093444824, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.029459703713655472, 'loss_2': 0.0003261566162109375, 'loss_3': -15.497724533081055, 'loss_4': 3.126004934310913, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 09:36:02,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:02,454 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:17<1:20:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:09,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015848923474550247, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.015, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007446279749274254, 'eval_loss_2': 0.008402645587921143, 'eval_loss_3': -18.16808319091797, 'eval_loss_4': 3.100464105606079, 'epoch': 2.79}
{'loss': 0.027, 'grad_norm': 7.361246585845947, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.020020613446831703, 'loss_2': 0.007007598876953125, 'loss_3': -15.389647483825684, 'loss_4': 3.4088566303253174, 'epoch': 2.8}
{'loss': 0.0356, 'grad_norm': 8.342450141906738, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.019226420670747757, 'loss_2': 0.016326904296875, 'loss_3': -15.362333297729492, 'loss_4': 3.569323778152466, 'epoch': 2.8}
{'loss': 0.0491, 'grad_norm': 14.921435356140137, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.03664449229836464, 'loss_2': 0.01241302490234375, 'loss_3': -15.515766143798828, 'loss_4': 3.262967824935913, 'epoch': 2.81}
{'loss': 0.0567, 'grad_norm': 14.115120887756348, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.055068619549274445, 'loss_2': 0.0016431808471679688, 'loss_3': -15.600019454956055, 'loss_4': 3.7619104385375977, 'epoch': 2.81}
{'loss': 0.0396, 'grad_norm': 14.695054054260254, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.03767244517803192, 'loss_2': 0.00193023681640625, 'loss_3': -15.333694458007812, 'loss_4': 3.039639711380005, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 09:36:09,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:09,815 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:24<1:20:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:17,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011455724947154522, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.79, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007569771260023117, 'eval_loss_2': 0.0038859546184539795, 'eval_loss_3': -18.159744262695312, 'eval_loss_4': 2.9509899616241455, 'epoch': 2.82}
{'loss': 0.0443, 'grad_norm': 21.585128784179688, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.041175100952386856, 'loss_2': 0.00311279296875, 'loss_3': -15.52630615234375, 'loss_4': 3.5406672954559326, 'epoch': 2.83}
{'loss': 0.0434, 'grad_norm': 21.3298282623291, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.04235881194472313, 'loss_2': 0.0010814666748046875, 'loss_3': -15.412508964538574, 'loss_4': 2.8747482299804688, 'epoch': 2.83}
{'loss': 0.0339, 'grad_norm': 11.366047859191895, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.030017103999853134, 'loss_2': 0.003879547119140625, 'loss_3': -15.506361961364746, 'loss_4': 3.2667770385742188, 'epoch': 2.84}
{'loss': 0.0269, 'grad_norm': 8.224794387817383, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.025986937806010246, 'loss_2': 0.0009489059448242188, 'loss_3': -15.55724811553955, 'loss_4': 2.607707977294922, 'epoch': 2.84}
{'loss': 0.0256, 'grad_norm': 8.822712898254395, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.022721057757735252, 'loss_2': 0.002887725830078125, 'loss_3': -15.814960479736328, 'loss_4': 3.40078067779541, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 09:36:17,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:17,171 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:28<1:20:51,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:36:20,980 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490
[INFO|configuration_utils.py:420] 2025-01-21 09:36:20,981 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490/config.json                                                                              
{'eval_loss': 0.010376347228884697, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007067336235195398, 'eval_loss_2': 0.003309011459350586, 'eval_loss_3': -18.201309204101562, 'eval_loss_4': 3.094176769256592, 'epoch': 2.85}
[INFO|modeling_utils.py:2988] 2025-01-21 09:36:21,471 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:36:21,473 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:36:21,473 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:36:22,389 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-420] due to args.save_total_limit
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:33<1:29:02,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:36:26,012 >>
{'loss': 0.0184, 'grad_norm': 6.491292476654053, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.012526794336736202, 'loss_2': 0.0059051513671875, 'loss_3': -15.718160629272461, 'loss_4': 2.5795860290527344, 'epoch': 2.85}
{'loss': 0.0314, 'grad_norm': 9.815069198608398, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.027608197182416916, 'loss_2': 0.003753662109375, 'loss_3': -15.796875, 'loss_4': 3.278205156326294, 'epoch': 2.86}
{'loss': 0.0449, 'grad_norm': 14.931196212768555, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.04166782647371292, 'loss_2': 0.003200531005859375, 'loss_3': -15.623488426208496, 'loss_4': 4.32547664642334, 'epoch': 2.87}
{'loss': 0.0479, 'grad_norm': 13.056674003601074, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.043145474046468735, 'loss_2': 0.00478363037109375, 'loss_3': -15.498625755310059, 'loss_4': 3.615676164627075, 'epoch': 2.87}
{'loss': 0.0561, 'grad_norm': 16.93935203552246, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.05128515139222145, 'loss_2': 0.00482940673828125, 'loss_3': -15.530495643615723, 'loss_4': 3.5303380489349365, 'epoch': 2.88}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:36:26,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:26,013 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:40<1:22:02,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:36:33,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011593611910939217, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.218, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007812277413904667, 'eval_loss_2': 0.003781333565711975, 'eval_loss_3': -18.29660415649414, 'eval_loss_4': 3.588027000427246, 'epoch': 2.88}
{'loss': 0.0765, 'grad_norm': 19.101978302001953, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.07490070909261703, 'loss_2': 0.0016202926635742188, 'loss_3': -15.544349670410156, 'loss_4': 4.294144153594971, 'epoch': 2.88}
{'loss': 0.0513, 'grad_norm': 12.634805679321289, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.04760182648897171, 'loss_2': 0.003673553466796875, 'loss_3': -15.841114044189453, 'loss_4': 4.961111068725586, 'epoch': 2.89}
{'loss': 0.0272, 'grad_norm': 8.041631698608398, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.023959143087267876, 'loss_2': 0.003204345703125, 'loss_3': -15.77115535736084, 'loss_4': 4.571775913238525, 'epoch': 2.9}
{'loss': 0.0437, 'grad_norm': 14.151041030883789, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.04321965575218201, 'loss_2': 0.00047850608825683594, 'loss_3': -15.794175148010254, 'loss_4': 4.748365879058838, 'epoch': 2.9}
{'loss': 0.033, 'grad_norm': 10.02247428894043, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.02860400453209877, 'loss_2': 0.00441741943359375, 'loss_3': -15.828267097473145, 'loss_4': 4.769619941711426, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 09:36:33,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:33,363 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:47<1:20:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:40,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011823244392871857, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007895342074334621, 'eval_loss_2': 0.003927901387214661, 'eval_loss_3': -18.316322326660156, 'eval_loss_4': 3.6483418941497803, 'epoch': 2.91}
{'loss': 0.0328, 'grad_norm': 7.539638519287109, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.026656579226255417, 'loss_2': 0.00616455078125, 'loss_3': -15.706682205200195, 'loss_4': 4.295720100402832, 'epoch': 2.91}
{'loss': 0.0439, 'grad_norm': 11.354844093322754, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.04316827654838562, 'loss_2': 0.0006914138793945312, 'loss_3': -15.67782211303711, 'loss_4': 3.899961471557617, 'epoch': 2.92}
{'loss': 0.0314, 'grad_norm': 8.108315467834473, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.027437791228294373, 'loss_2': 0.00396728515625, 'loss_3': -15.687976837158203, 'loss_4': 3.915255069732666, 'epoch': 2.92}
{'loss': 0.0291, 'grad_norm': 10.04427433013916, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.02411244809627533, 'loss_2': 0.005035400390625, 'loss_3': -15.529879570007324, 'loss_4': 2.817081928253174, 'epoch': 2.93}
{'loss': 0.0199, 'grad_norm': 6.704380989074707, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.016293466091156006, 'loss_2': 0.00357818603515625, 'loss_3': -15.583473205566406, 'loss_4': 3.419684886932373, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 09:36:40,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:40,707 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [12:55<1:20:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:36:48,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010950691066682339, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.325, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007593005429953337, 'eval_loss_2': 0.0033576861023902893, 'eval_loss_3': -18.288902282714844, 'eval_loss_4': 2.7191965579986572, 'epoch': 2.94}
{'loss': 0.0313, 'grad_norm': 7.43251895904541, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.022954219952225685, 'loss_2': 0.00830078125, 'loss_3': -15.686544418334961, 'loss_4': 3.1875147819519043, 'epoch': 2.94}
{'loss': 0.0352, 'grad_norm': 10.813743591308594, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.02758665196597576, 'loss_2': 0.00757598876953125, 'loss_3': -15.569311141967773, 'loss_4': 2.6475510597229004, 'epoch': 2.95}
{'loss': 0.0294, 'grad_norm': 8.599814414978027, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.022660398855805397, 'loss_2': 0.00670623779296875, 'loss_3': -15.652585983276367, 'loss_4': 3.04331636428833, 'epoch': 2.95}
{'loss': 0.0283, 'grad_norm': 8.103019714355469, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.027803869917988777, 'loss_2': 0.0004901885986328125, 'loss_3': -15.65591049194336, 'loss_4': 2.0248734951019287, 'epoch': 2.96}
{'loss': 0.0583, 'grad_norm': 17.746788024902344, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.05804860591888428, 'loss_2': 0.0002586841583251953, 'loss_3': -15.444314002990723, 'loss_4': 2.9027633666992188, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 09:36:48,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:48,064 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:02<1:19:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:36:55,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011836903169751167, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007595912553369999, 'eval_loss_2': 0.004240989685058594, 'eval_loss_3': -18.249061584472656, 'eval_loss_4': 1.8818787336349487, 'epoch': 2.97}
{'loss': 0.023, 'grad_norm': 8.173625946044922, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.02146240882575512, 'loss_2': 0.00156402587890625, 'loss_3': -15.753568649291992, 'loss_4': 2.0612287521362305, 'epoch': 2.97}
{'loss': 0.0219, 'grad_norm': 8.442978858947754, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.019826890900731087, 'loss_2': 0.002109527587890625, 'loss_3': -15.714439392089844, 'loss_4': 2.133591413497925, 'epoch': 2.98}
{'loss': 0.0407, 'grad_norm': 13.775489807128906, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.03604286164045334, 'loss_2': 0.0046539306640625, 'loss_3': -15.723321914672852, 'loss_4': 2.6289143562316895, 'epoch': 2.98}
{'loss': 0.0324, 'grad_norm': 8.301460266113281, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.026731641963124275, 'loss_2': 0.00569915771484375, 'loss_3': -15.569344520568848, 'loss_4': 1.725564956665039, 'epoch': 2.99}
{'loss': 0.0416, 'grad_norm': 13.337900161743164, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.031179040670394897, 'loss_2': 0.0103759765625, 'loss_3': -15.637571334838867, 'loss_4': 1.3174275159835815, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 09:36:55,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:36:55,383 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:09<1:18:30,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:37:02,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013165746815502644, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007750307209789753, 'eval_loss_2': 0.005415439605712891, 'eval_loss_3': -18.2137508392334, 'eval_loss_4': 1.1491634845733643, 'epoch': 2.99}
{'loss': 0.0288, 'grad_norm': 8.48124885559082, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.013812427408993244, 'loss_2': 0.0150146484375, 'loss_3': -15.66956615447998, 'loss_4': 1.6958856582641602, 'epoch': 3.0}
{'loss': 0.0264, 'grad_norm': 6.267487049102783, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.016004951670765877, 'loss_2': 0.0103607177734375, 'loss_3': -15.829999923706055, 'loss_4': 1.0804145336151123, 'epoch': 3.01}
{'loss': 0.0587, 'grad_norm': 28.07752799987793, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.054792433977127075, 'loss_2': 0.0038967132568359375, 'loss_3': -15.553850173950195, 'loss_4': 1.8183571100234985, 'epoch': 3.01}
{'loss': 0.0303, 'grad_norm': 8.955562591552734, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.029202479869127274, 'loss_2': 0.0010766983032226562, 'loss_3': -15.634381294250488, 'loss_4': 0.6118046045303345, 'epoch': 3.02}
{'loss': 0.0927, 'grad_norm': 25.50872802734375, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.08614802360534668, 'loss_2': 0.00659942626953125, 'loss_3': -15.6075439453125, 'loss_4': 1.2258291244506836, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 09:37:02,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:02,434 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:17<1:19:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:37:09,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017187751829624176, 'eval_runtime': 3.8336, 'eval_samples_per_second': 267.115, 'eval_steps_per_second': 4.174, 'eval_loss_1': 0.00901512149721384, 'eval_loss_2': 0.00817263126373291, 'eval_loss_3': -18.171432495117188, 'eval_loss_4': 0.9181982278823853, 'epoch': 3.02}
{'loss': 0.0594, 'grad_norm': 13.436752319335938, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.051604028791189194, 'loss_2': 0.0078277587890625, 'loss_3': -15.62070369720459, 'loss_4': 0.8917694687843323, 'epoch': 3.03}
{'loss': 0.0446, 'grad_norm': 12.03603458404541, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.04128760099411011, 'loss_2': 0.003330230712890625, 'loss_3': -15.47359848022461, 'loss_4': 0.9745231866836548, 'epoch': 3.03}
{'loss': 0.0332, 'grad_norm': 8.857220649719238, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.02632792480289936, 'loss_2': 0.006866455078125, 'loss_3': -15.86370849609375, 'loss_4': 0.7607082724571228, 'epoch': 3.04}
{'loss': 0.0245, 'grad_norm': 6.894322872161865, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.020877394825220108, 'loss_2': 0.0036468505859375, 'loss_3': -15.766755104064941, 'loss_4': 1.5818181037902832, 'epoch': 3.05}
{'loss': 0.0699, 'grad_norm': 17.06087875366211, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.061782289296388626, 'loss_2': 0.0081634521484375, 'loss_3': -15.717184066772461, 'loss_4': 1.078272819519043, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 09:37:09,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:09,801 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:24<1:20:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:17,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012739057652652264, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009973506443202496, 'eval_loss_2': 0.002765551209449768, 'eval_loss_3': -18.153705596923828, 'eval_loss_4': 1.0829602479934692, 'epoch': 3.05}
{'loss': 0.0776, 'grad_norm': 23.763166427612305, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.07685231417417526, 'loss_2': 0.0007581710815429688, 'loss_3': -15.57179069519043, 'loss_4': 2.0543785095214844, 'epoch': 3.06}
{'loss': 0.0465, 'grad_norm': 22.696531295776367, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.04646027833223343, 'loss_2': 7.200241088867188e-05, 'loss_3': -15.575557708740234, 'loss_4': 1.5598454475402832, 'epoch': 3.06}
{'loss': 0.0522, 'grad_norm': 16.027423858642578, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.04732164368033409, 'loss_2': 0.0048828125, 'loss_3': -15.699687957763672, 'loss_4': 1.9336600303649902, 'epoch': 3.07}
{'loss': 0.0501, 'grad_norm': 9.864604949951172, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.042182810604572296, 'loss_2': 0.0079345703125, 'loss_3': -15.626287460327148, 'loss_4': 0.9417397975921631, 'epoch': 3.08}
{'loss': 0.041, 'grad_norm': 9.579246520996094, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.035907745361328125, 'loss_2': 0.00508880615234375, 'loss_3': -15.726122856140137, 'loss_4': 1.9171142578125, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 09:37:17,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:17,157 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:28<1:20:06,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:37:20,971 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530
[INFO|configuration_utils.py:420] 2025-01-21 09:37:20,972 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530/config.json                                                                              
{'eval_loss': 0.010303996503353119, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007943704724311829, 'eval_loss_2': 0.0023602917790412903, 'eval_loss_3': -18.219865798950195, 'eval_loss_4': 1.2769896984100342, 'epoch': 3.08}
[INFO|modeling_utils.py:2988] 2025-01-21 09:37:21,488 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:37:21,489 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:37:21,489 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:37:22,415 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-490] due to args.save_total_limit
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:33<1:28:23,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:37:26,030 >>
{'loss': 0.0451, 'grad_norm': 14.33098030090332, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.044609636068344116, 'loss_2': 0.0004782676696777344, 'loss_3': -15.710899353027344, 'loss_4': 1.6184240579605103, 'epoch': 3.09}
{'loss': 0.0341, 'grad_norm': 10.973801612854004, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.031471677124500275, 'loss_2': 0.0026397705078125, 'loss_3': -15.708395004272461, 'loss_4': 1.712721824645996, 'epoch': 3.09}
{'loss': 0.0422, 'grad_norm': 9.410162925720215, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.03053996153175831, 'loss_2': 0.01165771484375, 'loss_3': -15.843636512756348, 'loss_4': 1.4246554374694824, 'epoch': 3.1}
{'loss': 0.0383, 'grad_norm': 8.667701721191406, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.03317270800471306, 'loss_2': 0.005096435546875, 'loss_3': -15.847177505493164, 'loss_4': 1.5154863595962524, 'epoch': 3.1}
{'loss': 0.0498, 'grad_norm': 17.109920501708984, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.04499609023332596, 'loss_2': 0.00484466552734375, 'loss_3': -15.698773384094238, 'loss_4': 1.399577260017395, 'epoch': 3.11}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:37:26,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:26,031 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:40<1:21:19,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:37:33,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0104133989661932, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.443, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007363459561020136, 'eval_loss_2': 0.0030499398708343506, 'eval_loss_3': -18.192590713500977, 'eval_loss_4': 1.3216125965118408, 'epoch': 3.11}
{'loss': 0.0253, 'grad_norm': 8.292150497436523, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.024174204096198082, 'loss_2': 0.0011205673217773438, 'loss_3': -15.590360641479492, 'loss_4': 1.8800822496414185, 'epoch': 3.12}
{'loss': 0.0272, 'grad_norm': 10.221490859985352, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.02586272917687893, 'loss_2': 0.0012979507446289062, 'loss_3': -15.837053298950195, 'loss_4': 1.578010082244873, 'epoch': 3.12}
{'loss': 0.0309, 'grad_norm': 10.919334411621094, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.029874173924326897, 'loss_2': 0.0009918212890625, 'loss_3': -15.660493850708008, 'loss_4': 1.732344388961792, 'epoch': 3.13}
{'loss': 0.0513, 'grad_norm': 22.358539581298828, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.04956260696053505, 'loss_2': 0.00176239013671875, 'loss_3': -15.574150085449219, 'loss_4': 1.2553415298461914, 'epoch': 3.13}
{'loss': 0.0308, 'grad_norm': 9.442715644836426, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.024759437888860703, 'loss_2': 0.006008148193359375, 'loss_3': -15.691213607788086, 'loss_4': 1.9793165922164917, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 09:37:33,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:33,384 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:44<1:21:19,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 09:37:37,192 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540
[INFO|configuration_utils.py:420] 2025-01-21 09:37:37,193 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540/config.json                                                                              
{'eval_loss': 0.010103845037519932, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006810836493968964, 'eval_loss_2': 0.0032930076122283936, 'eval_loss_3': -18.2194881439209, 'eval_loss_4': 1.35426664352417, 'epoch': 3.14}
[INFO|modeling_utils.py:2988] 2025-01-21 09:37:37,653 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:37:37,654 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:37:37,654 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:37:38,608 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-530] due to args.save_total_limit
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:49<1:28:27,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:37:42,257 >>
{'loss': 0.0316, 'grad_norm': 14.709615707397461, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.02751883491873741, 'loss_2': 0.004085540771484375, 'loss_3': -15.507823944091797, 'loss_4': 1.5084798336029053, 'epoch': 3.15}
{'loss': 0.0204, 'grad_norm': 7.3472394943237305, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.018554432317614555, 'loss_2': 0.0018444061279296875, 'loss_3': -15.541179656982422, 'loss_4': 2.1070261001586914, 'epoch': 3.15}
{'loss': 0.0431, 'grad_norm': 12.692438125610352, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.04101437330245972, 'loss_2': 0.0021114349365234375, 'loss_3': -15.737375259399414, 'loss_4': 2.400630235671997, 'epoch': 3.16}
{'loss': 0.0228, 'grad_norm': 5.93753719329834, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.014010382816195488, 'loss_2': 0.0088043212890625, 'loss_3': -15.630943298339844, 'loss_4': 1.8955332040786743, 'epoch': 3.16}
{'loss': 0.0302, 'grad_norm': 13.28471851348877, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.029962385073304176, 'loss_2': 0.0002536773681640625, 'loss_3': -15.663305282592773, 'loss_4': 1.3591892719268799, 'epoch': 3.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:37:42,257 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:42,257 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:56<1:21:13,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:37:49,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012919253669679165, 'eval_runtime': 3.8225, 'eval_samples_per_second': 267.888, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.008402712643146515, 'eval_loss_2': 0.004516541957855225, 'eval_loss_3': -18.201499938964844, 'eval_loss_4': 1.1943976879119873, 'epoch': 3.17}
{'loss': 0.0248, 'grad_norm': 8.85916519165039, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.024750778451561928, 'loss_2': 5.626678466796875e-05, 'loss_3': -15.787654876708984, 'loss_4': 1.3340771198272705, 'epoch': 3.17}
{'loss': 0.0413, 'grad_norm': 13.844293594360352, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.03658725693821907, 'loss_2': 0.0047454833984375, 'loss_3': -15.776191711425781, 'loss_4': 1.050218105316162, 'epoch': 3.18}
{'loss': 0.0213, 'grad_norm': 8.441927909851074, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.020901059731841087, 'loss_2': 0.0004062652587890625, 'loss_3': -15.593560218811035, 'loss_4': 1.0371373891830444, 'epoch': 3.19}
{'loss': 0.032, 'grad_norm': 8.804095268249512, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.02349073253571987, 'loss_2': 0.00855255126953125, 'loss_3': -15.636550903320312, 'loss_4': 1.0744593143463135, 'epoch': 3.19}
{'loss': 0.0163, 'grad_norm': 5.988305568695068, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.014300762675702572, 'loss_2': 0.0019931793212890625, 'loss_3': -15.744169235229492, 'loss_4': 1.45560622215271, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 09:37:49,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:49,618 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:04<1:19:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:37:56,971 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016195140779018402, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.321, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.00920387264341116, 'eval_loss_2': 0.006991267204284668, 'eval_loss_3': -18.17160987854004, 'eval_loss_4': 1.1310796737670898, 'epoch': 3.2}
{'loss': 0.0263, 'grad_norm': 10.190410614013672, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.025361081585288048, 'loss_2': 0.0009288787841796875, 'loss_3': -15.577445983886719, 'loss_4': 2.2269539833068848, 'epoch': 3.2}
{'loss': 0.0255, 'grad_norm': 7.862393856048584, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.0185868963599205, 'loss_2': 0.006927490234375, 'loss_3': -15.509393692016602, 'loss_4': 2.052720069885254, 'epoch': 3.21}
{'loss': 0.0278, 'grad_norm': 8.51312255859375, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.025311866775155067, 'loss_2': 0.002471923828125, 'loss_3': -15.53661060333252, 'loss_4': 1.0644344091415405, 'epoch': 3.22}
{'loss': 0.0356, 'grad_norm': 12.121745109558105, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.03232754021883011, 'loss_2': 0.0033168792724609375, 'loss_3': -15.65542221069336, 'loss_4': 1.6878682374954224, 'epoch': 3.22}
{'loss': 0.0376, 'grad_norm': 10.701920509338379, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.03446892276406288, 'loss_2': 0.00311279296875, 'loss_3': -15.782761573791504, 'loss_4': 1.6214492321014404, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 09:37:56,971 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:37:56,971 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:11<1:19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:04,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01793541945517063, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.912, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008639122359454632, 'eval_loss_2': 0.009296298027038574, 'eval_loss_3': -18.144062042236328, 'eval_loss_4': 1.6566953659057617, 'epoch': 3.23}
{'loss': 0.029, 'grad_norm': 5.7104411125183105, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.01654791459441185, 'loss_2': 0.01244354248046875, 'loss_3': -15.595283508300781, 'loss_4': 2.1367244720458984, 'epoch': 3.23}
{'loss': 0.048, 'grad_norm': 10.737222671508789, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.04152844846248627, 'loss_2': 0.0065155029296875, 'loss_3': -15.455370903015137, 'loss_4': 2.305678367614746, 'epoch': 3.24}
{'loss': 0.0295, 'grad_norm': 7.5579915046691895, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.01762497052550316, 'loss_2': 0.0118865966796875, 'loss_3': -15.612480163574219, 'loss_4': 2.409332275390625, 'epoch': 3.24}
{'loss': 0.0342, 'grad_norm': 10.469454765319824, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.03170125558972359, 'loss_2': 0.002490997314453125, 'loss_3': -15.285478591918945, 'loss_4': 2.189110279083252, 'epoch': 3.25}
{'loss': 0.0065, 'grad_norm': 4.960625648498535, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.005209389142692089, 'loss_2': 0.0013208389282226562, 'loss_3': -15.670610427856445, 'loss_4': 2.3568713665008545, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 09:38:04,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:04,321 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:18<1:19:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:11,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01539117842912674, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008419639430940151, 'eval_loss_2': 0.006971538066864014, 'eval_loss_3': -18.100921630859375, 'eval_loss_4': 2.2477338314056396, 'epoch': 3.26}
{'loss': 0.0194, 'grad_norm': 7.151788711547852, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.01603454351425171, 'loss_2': 0.003330230712890625, 'loss_3': -15.435730934143066, 'loss_4': 3.1301002502441406, 'epoch': 3.26}
{'loss': 0.0337, 'grad_norm': 12.12546157836914, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.02190222591161728, 'loss_2': 0.011749267578125, 'loss_3': -15.476476669311523, 'loss_4': 2.469619035720825, 'epoch': 3.27}
{'loss': 0.1, 'grad_norm': 25.03647232055664, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.08494671434164047, 'loss_2': 0.0150146484375, 'loss_3': -15.469625473022461, 'loss_4': 2.6290979385375977, 'epoch': 3.27}
{'loss': 0.0508, 'grad_norm': 10.664970397949219, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.02597701922059059, 'loss_2': 0.024810791015625, 'loss_3': -15.463791847229004, 'loss_4': 2.5550453662872314, 'epoch': 3.28}
{'loss': 0.0526, 'grad_norm': 11.502213478088379, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.02517438307404518, 'loss_2': 0.0274658203125, 'loss_3': -15.416540145874023, 'loss_4': 2.522275447845459, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 09:38:11,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:11,671 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:26<1:19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:19,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038937296718358994, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009272304363548756, 'eval_loss_2': 0.029664993286132812, 'eval_loss_3': -18.104812622070312, 'eval_loss_4': 2.2670583724975586, 'epoch': 3.28}
{'loss': 0.0431, 'grad_norm': 9.941434860229492, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.018984241411089897, 'loss_2': 0.0241241455078125, 'loss_3': -15.682629585266113, 'loss_4': 2.3920130729675293, 'epoch': 3.29}
{'loss': 0.1474, 'grad_norm': 29.35982894897461, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.12269950658082962, 'loss_2': 0.0247039794921875, 'loss_3': -15.46019458770752, 'loss_4': 2.212282180786133, 'epoch': 3.3}
{'loss': 0.0421, 'grad_norm': 15.350236892700195, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.019693225622177124, 'loss_2': 0.0224151611328125, 'loss_3': -15.62610912322998, 'loss_4': 2.75699520111084, 'epoch': 3.3}
{'loss': 0.038, 'grad_norm': 7.700168609619141, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.021442893892526627, 'loss_2': 0.0165863037109375, 'loss_3': -15.620183944702148, 'loss_4': 1.947099208831787, 'epoch': 3.31}
{'loss': 0.0427, 'grad_norm': 9.115288734436035, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.021853186190128326, 'loss_2': 0.02081298828125, 'loss_3': -15.387722969055176, 'loss_4': 2.1876442432403564, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 09:38:19,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:19,012 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:33<1:19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:26,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03273973613977432, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012868978083133698, 'eval_loss_2': 0.019870758056640625, 'eval_loss_3': -18.05527114868164, 'eval_loss_4': 1.831115484237671, 'epoch': 3.31}
{'loss': 0.0958, 'grad_norm': 19.029375076293945, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.0758448913693428, 'loss_2': 0.019989013671875, 'loss_3': -15.394750595092773, 'loss_4': 2.1398158073425293, 'epoch': 3.32}
{'loss': 0.041, 'grad_norm': 7.538654327392578, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.02072923816740513, 'loss_2': 0.0203094482421875, 'loss_3': -15.335439682006836, 'loss_4': 2.0000972747802734, 'epoch': 3.33}
{'loss': 0.0374, 'grad_norm': 7.676876068115234, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.02034418098628521, 'loss_2': 0.01708984375, 'loss_3': -15.666390419006348, 'loss_4': 1.5801432132720947, 'epoch': 3.33}
{'loss': 0.1217, 'grad_norm': 27.170942306518555, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.11735056340694427, 'loss_2': 0.00435638427734375, 'loss_3': -15.245061874389648, 'loss_4': 1.8415056467056274, 'epoch': 3.34}
{'loss': 0.0434, 'grad_norm': 16.718002319335938, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.04127347096800804, 'loss_2': 0.00211334228515625, 'loss_3': -15.551177024841309, 'loss_4': 2.485151767730713, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 09:38:26,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:26,359 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:40<1:19:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:33,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017996568232774734, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.421, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01268132496625185, 'eval_loss_2': 0.005315244197845459, 'eval_loss_3': -18.07626724243164, 'eval_loss_4': 1.804513931274414, 'epoch': 3.34}
{'loss': 0.051, 'grad_norm': 13.551807403564453, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.04207088053226471, 'loss_2': 0.00891876220703125, 'loss_3': -15.648853302001953, 'loss_4': 2.7214198112487793, 'epoch': 3.35}
{'loss': 0.0556, 'grad_norm': 9.961416244506836, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.0389619804918766, 'loss_2': 0.0166473388671875, 'loss_3': -15.318055152893066, 'loss_4': 2.049736976623535, 'epoch': 3.35}
{'loss': 0.0227, 'grad_norm': 7.269957542419434, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.016073720529675484, 'loss_2': 0.0066375732421875, 'loss_3': -15.731825828552246, 'loss_4': 2.1260037422180176, 'epoch': 3.36}
{'loss': 0.0608, 'grad_norm': 12.92139720916748, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.044314805418252945, 'loss_2': 0.0165252685546875, 'loss_3': -15.465015411376953, 'loss_4': 2.1877689361572266, 'epoch': 3.37}
{'loss': 0.0369, 'grad_norm': 7.783949851989746, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.02559945359826088, 'loss_2': 0.011322021484375, 'loss_3': -15.41018295288086, 'loss_4': 3.0121865272521973, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 09:38:33,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:33,714 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:48<1:19:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:41,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017698632553219795, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008707866072654724, 'eval_loss_2': 0.008990764617919922, 'eval_loss_3': -18.203624725341797, 'eval_loss_4': 2.6989669799804688, 'epoch': 3.37}
{'loss': 0.0879, 'grad_norm': 29.18787384033203, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.07903073728084564, 'loss_2': 0.008819580078125, 'loss_3': -15.771055221557617, 'loss_4': 3.299499034881592, 'epoch': 3.38}
{'loss': 0.0714, 'grad_norm': 33.042991638183594, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.0671364814043045, 'loss_2': 0.004241943359375, 'loss_3': -15.780479431152344, 'loss_4': 3.601686477661133, 'epoch': 3.38}
{'loss': 0.0636, 'grad_norm': 15.89238166809082, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.05444735288619995, 'loss_2': 0.009124755859375, 'loss_3': -15.789918899536133, 'loss_4': 3.897817611694336, 'epoch': 3.39}
{'loss': 0.0221, 'grad_norm': 5.884243965148926, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.013610398396849632, 'loss_2': 0.00844573974609375, 'loss_3': -15.80300521850586, 'loss_4': 4.2236223220825195, 'epoch': 3.4}
{'loss': 0.0324, 'grad_norm': 10.67285442352295, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.027894729748368263, 'loss_2': 0.00445556640625, 'loss_3': -15.85013198852539, 'loss_4': 4.267554759979248, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 09:38:41,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:41,066 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:55<1:19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:48,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01899961195886135, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.909, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011298691853880882, 'eval_loss_2': 0.007700920104980469, 'eval_loss_3': -18.284393310546875, 'eval_loss_4': 4.2376251220703125, 'epoch': 3.4}
{'loss': 0.0388, 'grad_norm': 8.401358604431152, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.03315390646457672, 'loss_2': 0.00566864013671875, 'loss_3': -15.847945213317871, 'loss_4': 4.718186855316162, 'epoch': 3.41}
{'loss': 0.0301, 'grad_norm': 7.749475479125977, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.02295263111591339, 'loss_2': 0.00717926025390625, 'loss_3': -15.956144332885742, 'loss_4': 5.25396203994751, 'epoch': 3.41}
{'loss': 0.0667, 'grad_norm': 20.372968673706055, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.05688164755702019, 'loss_2': 0.0097808837890625, 'loss_3': -15.811956405639648, 'loss_4': 5.034860610961914, 'epoch': 3.42}
{'loss': 0.1282, 'grad_norm': 31.75188636779785, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.11079351603984833, 'loss_2': 0.017425537109375, 'loss_3': -15.754049301147461, 'loss_4': 6.129316329956055, 'epoch': 3.42}
{'loss': 0.0561, 'grad_norm': 12.829388618469238, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.043372634798288345, 'loss_2': 0.0127716064453125, 'loss_3': -15.813952445983887, 'loss_4': 5.956443786621094, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 09:38:48,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:48,430 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:03<1:19:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:38:55,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022484013810753822, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.587, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012302110902965069, 'eval_loss_2': 0.010181903839111328, 'eval_loss_3': -18.29480743408203, 'eval_loss_4': 4.9699506759643555, 'epoch': 3.43}
{'loss': 0.0839, 'grad_norm': 25.22639274597168, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.07169269025325775, 'loss_2': 0.012176513671875, 'loss_3': -16.111738204956055, 'loss_4': 6.241838455200195, 'epoch': 3.44}
{'loss': 0.0574, 'grad_norm': 13.725979804992676, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.047631531953811646, 'loss_2': 0.0098114013671875, 'loss_3': -16.02947235107422, 'loss_4': 6.030190944671631, 'epoch': 3.44}
{'loss': 0.0319, 'grad_norm': 9.558424949645996, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.029095027595758438, 'loss_2': 0.00284576416015625, 'loss_3': -15.914543151855469, 'loss_4': 5.945852756500244, 'epoch': 3.45}
{'loss': 0.0268, 'grad_norm': 9.76445198059082, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.02588994801044464, 'loss_2': 0.0008955001831054688, 'loss_3': -15.89921760559082, 'loss_4': 5.37598180770874, 'epoch': 3.45}
{'loss': 0.0426, 'grad_norm': 10.20472526550293, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.032037194818258286, 'loss_2': 0.01059722900390625, 'loss_3': -15.955347061157227, 'loss_4': 6.756115436553955, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 09:38:55,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:38:55,795 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:10<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:03,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02026418037712574, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.012869060970842838, 'eval_loss_2': 0.007395118474960327, 'eval_loss_3': -18.28000831604004, 'eval_loss_4': 4.574807643890381, 'epoch': 3.46}
{'loss': 0.0642, 'grad_norm': 16.049022674560547, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.04949618875980377, 'loss_2': 0.014739990234375, 'loss_3': -15.861729621887207, 'loss_4': 5.403073310852051, 'epoch': 3.47}
{'loss': 0.0376, 'grad_norm': 11.151310920715332, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.02712525986135006, 'loss_2': 0.010498046875, 'loss_3': -15.747692108154297, 'loss_4': 5.547667980194092, 'epoch': 3.47}
{'loss': 0.0559, 'grad_norm': 14.570438385009766, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.04148701950907707, 'loss_2': 0.01445770263671875, 'loss_3': -15.906124114990234, 'loss_4': 5.534546852111816, 'epoch': 3.48}
{'loss': 0.0606, 'grad_norm': 12.171479225158691, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.04861799627542496, 'loss_2': 0.0120086669921875, 'loss_3': -16.01144027709961, 'loss_4': 4.114192008972168, 'epoch': 3.48}
{'loss': 0.0307, 'grad_norm': 9.58572006225586, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.027369366958737373, 'loss_2': 0.003337860107421875, 'loss_3': -15.876914978027344, 'loss_4': 4.084382057189941, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 09:39:03,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:03,152 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:17<1:19:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:10,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019924720749258995, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012037357315421104, 'eval_loss_2': 0.00788736343383789, 'eval_loss_3': -18.22270393371582, 'eval_loss_4': 3.3273367881774902, 'epoch': 3.49}
{'loss': 0.0438, 'grad_norm': 8.699223518371582, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.0252439733594656, 'loss_2': 0.018524169921875, 'loss_3': -16.148174285888672, 'loss_4': 3.750039577484131, 'epoch': 3.49}
{'loss': 0.0259, 'grad_norm': 7.387855529785156, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.017730340361595154, 'loss_2': 0.0081787109375, 'loss_3': -16.176788330078125, 'loss_4': 3.6453895568847656, 'epoch': 3.5}
{'loss': 0.031, 'grad_norm': 9.344660758972168, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.025023411959409714, 'loss_2': 0.00598907470703125, 'loss_3': -15.990165710449219, 'loss_4': 2.8017070293426514, 'epoch': 3.51}
{'loss': 0.0328, 'grad_norm': 10.094809532165527, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.027103271335363388, 'loss_2': 0.00566864013671875, 'loss_3': -15.728231430053711, 'loss_4': 2.867609977722168, 'epoch': 3.51}
{'loss': 0.0299, 'grad_norm': 6.846935272216797, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.017733490094542503, 'loss_2': 0.01218414306640625, 'loss_3': -15.793975830078125, 'loss_4': 3.30751371383667, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 09:39:10,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:10,518 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:25<1:18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:17,881 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02396264299750328, 'eval_runtime': 3.8231, 'eval_samples_per_second': 267.848, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.013102203607559204, 'eval_loss_2': 0.010860443115234375, 'eval_loss_3': -18.106857299804688, 'eval_loss_4': 2.8409500122070312, 'epoch': 3.52}
{'loss': 0.0303, 'grad_norm': 8.235147476196289, 'learning_rate': 2.65e-05, 'loss_1': 0.02314833737909794, 'loss_2': 0.00711822509765625, 'loss_3': -15.766471862792969, 'loss_4': 2.990927219390869, 'epoch': 3.52}
{'loss': 0.0443, 'grad_norm': 12.794093132019043, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.035789500921964645, 'loss_2': 0.00848388671875, 'loss_3': -15.711013793945312, 'loss_4': 2.573258876800537, 'epoch': 3.53}
{'loss': 0.0334, 'grad_norm': 8.298242568969727, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.026546519249677658, 'loss_2': 0.0068359375, 'loss_3': -15.607370376586914, 'loss_4': 2.3522348403930664, 'epoch': 3.53}
{'loss': 0.0706, 'grad_norm': 27.8081111907959, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.06998777389526367, 'loss_2': 0.0006566047668457031, 'loss_3': -15.55225944519043, 'loss_4': 3.139066219329834, 'epoch': 3.54}
{'loss': 0.1313, 'grad_norm': 16.48098373413086, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.1273031383752823, 'loss_2': 0.0039825439453125, 'loss_3': -15.434831619262695, 'loss_4': 1.972480058670044, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 09:39:17,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:17,881 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:32<1:18:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:25,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014853788539767265, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01146482490003109, 'eval_loss_2': 0.0033889636397361755, 'eval_loss_3': -18.095853805541992, 'eval_loss_4': 2.3167715072631836, 'epoch': 3.55}
{'loss': 0.025, 'grad_norm': 10.74748420715332, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.023184966295957565, 'loss_2': 0.0018186569213867188, 'loss_3': -15.925309181213379, 'loss_4': 2.7531580924987793, 'epoch': 3.55}
{'loss': 0.0459, 'grad_norm': 15.687040328979492, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.041924431920051575, 'loss_2': 0.003932952880859375, 'loss_3': -15.654115676879883, 'loss_4': 2.9100308418273926, 'epoch': 3.56}
{'loss': 0.0314, 'grad_norm': 7.652742385864258, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.019810983911156654, 'loss_2': 0.0115509033203125, 'loss_3': -15.47380256652832, 'loss_4': 2.2542428970336914, 'epoch': 3.56}
{'loss': 0.0254, 'grad_norm': 8.702116012573242, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.019001975655555725, 'loss_2': 0.00640869140625, 'loss_3': -15.45570182800293, 'loss_4': 2.1129767894744873, 'epoch': 3.57}
{'loss': 0.0345, 'grad_norm': 12.705042839050293, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.02749674767255783, 'loss_2': 0.00698089599609375, 'loss_3': -15.63143539428711, 'loss_4': 2.8529932498931885, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 09:39:25,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:25,229 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:39<1:18:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:32,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023484045639634132, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.778, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017440374940633774, 'eval_loss_2': 0.006043672561645508, 'eval_loss_3': -18.020973205566406, 'eval_loss_4': 2.29752779006958, 'epoch': 3.58}
{'loss': 0.0346, 'grad_norm': 9.054344177246094, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.02451697736978531, 'loss_2': 0.010040283203125, 'loss_3': -15.708394050598145, 'loss_4': 1.933985710144043, 'epoch': 3.58}
{'loss': 0.0246, 'grad_norm': 8.421422958374023, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.020073246210813522, 'loss_2': 0.0045166015625, 'loss_3': -15.799620628356934, 'loss_4': 2.286294937133789, 'epoch': 3.59}
{'loss': 0.0618, 'grad_norm': 18.441741943359375, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.059785813093185425, 'loss_2': 0.0019989013671875, 'loss_3': -15.371286392211914, 'loss_4': 2.6233723163604736, 'epoch': 3.59}
{'loss': 0.0471, 'grad_norm': 15.31528091430664, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.0395483523607254, 'loss_2': 0.00753021240234375, 'loss_3': -15.601993560791016, 'loss_4': 2.4132027626037598, 'epoch': 3.6}
{'loss': 0.0123, 'grad_norm': 7.710434913635254, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.012147845700383186, 'loss_2': 0.0001379251480102539, 'loss_3': -15.421266555786133, 'loss_4': 2.1118860244750977, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 09:39:32,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:32,579 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:47<1:18:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:39,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029705528169870377, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.381, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.020323876291513443, 'eval_loss_2': 0.009381651878356934, 'eval_loss_3': -17.97270393371582, 'eval_loss_4': 2.5683586597442627, 'epoch': 3.6}
{'loss': 0.0211, 'grad_norm': 8.417438507080078, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.01297302171587944, 'loss_2': 0.00815582275390625, 'loss_3': -15.483748435974121, 'loss_4': 2.3372597694396973, 'epoch': 3.61}
{'loss': 0.056, 'grad_norm': 25.07419204711914, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.045191649347543716, 'loss_2': 0.0107879638671875, 'loss_3': -15.518026351928711, 'loss_4': 2.9673566818237305, 'epoch': 3.62}
{'loss': 0.0337, 'grad_norm': 6.55005407333374, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.014177371747791767, 'loss_2': 0.0194854736328125, 'loss_3': -15.628019332885742, 'loss_4': 2.71048903465271, 'epoch': 3.62}
{'loss': 0.0443, 'grad_norm': 12.895661354064941, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.03592124581336975, 'loss_2': 0.00833892822265625, 'loss_3': -15.424631118774414, 'loss_4': 1.9901148080825806, 'epoch': 3.63}
{'loss': 0.1655, 'grad_norm': 29.75624656677246, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.15391285717487335, 'loss_2': 0.01157379150390625, 'loss_3': -15.436783790588379, 'loss_4': 2.6207873821258545, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 09:39:39,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:39,939 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:54<1:18:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:47,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030872182920575142, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.617, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.019024211913347244, 'eval_loss_2': 0.011847972869873047, 'eval_loss_3': -18.012088775634766, 'eval_loss_4': 2.2812447547912598, 'epoch': 3.63}
{'loss': 0.0508, 'grad_norm': 18.298070907592773, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.0429086871445179, 'loss_2': 0.007843017578125, 'loss_3': -15.54217529296875, 'loss_4': 2.093842029571533, 'epoch': 3.64}
{'loss': 0.041, 'grad_norm': 13.12303352355957, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.033690378069877625, 'loss_2': 0.0073394775390625, 'loss_3': -15.5366849899292, 'loss_4': 2.450284481048584, 'epoch': 3.65}
{'loss': 0.0431, 'grad_norm': 11.553845405578613, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.033398568630218506, 'loss_2': 0.0097198486328125, 'loss_3': -15.67342758178711, 'loss_4': 2.2113265991210938, 'epoch': 3.65}
{'loss': 0.0614, 'grad_norm': 22.147558212280273, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.05142778903245926, 'loss_2': 0.009979248046875, 'loss_3': -15.601571083068848, 'loss_4': 2.4333529472351074, 'epoch': 3.66}
{'loss': 0.0226, 'grad_norm': 6.572170257568359, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.021591681987047195, 'loss_2': 0.0010576248168945312, 'loss_3': -15.521772384643555, 'loss_4': 2.39323091506958, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 09:39:47,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:47,296 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:01<1:18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:39:54,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021813681349158287, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.015, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.018187034875154495, 'eval_loss_2': 0.0036266446113586426, 'eval_loss_3': -18.002294540405273, 'eval_loss_4': 1.8960708379745483, 'epoch': 3.66}
{'loss': 0.0429, 'grad_norm': 17.188398361206055, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.03663133829832077, 'loss_2': 0.00626373291015625, 'loss_3': -15.385660171508789, 'loss_4': 2.52803111076355, 'epoch': 3.67}
{'loss': 0.0288, 'grad_norm': 8.239997863769531, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.025899413973093033, 'loss_2': 0.002857208251953125, 'loss_3': -15.642135620117188, 'loss_4': 2.0767970085144043, 'epoch': 3.67}
{'loss': 0.0615, 'grad_norm': 18.651092529296875, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.05536160618066788, 'loss_2': 0.00616455078125, 'loss_3': -15.494146347045898, 'loss_4': 2.7287588119506836, 'epoch': 3.68}
{'loss': 0.0442, 'grad_norm': 19.641132354736328, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.04012877121567726, 'loss_2': 0.004077911376953125, 'loss_3': -15.69008731842041, 'loss_4': 1.969081997871399, 'epoch': 3.69}
{'loss': 0.0347, 'grad_norm': 11.195636749267578, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.029119111597537994, 'loss_2': 0.00555419921875, 'loss_3': -15.735634803771973, 'loss_4': 2.2461347579956055, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 09:39:54,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:39:54,660 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:09<1:19:15,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:40:02,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01892649382352829, 'eval_runtime': 4.0091, 'eval_samples_per_second': 255.417, 'eval_steps_per_second': 3.991, 'eval_loss_1': 0.01294516958296299, 'eval_loss_2': 0.005981326103210449, 'eval_loss_3': -18.138126373291016, 'eval_loss_4': 1.9033030271530151, 'epoch': 3.69}
{'loss': 0.041, 'grad_norm': 14.227682113647461, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.038947977125644684, 'loss_2': 0.0020999908447265625, 'loss_3': -15.51140022277832, 'loss_4': 2.8875458240509033, 'epoch': 3.7}
{'loss': 0.0178, 'grad_norm': 6.352930068969727, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.015547324903309345, 'loss_2': 0.00225067138671875, 'loss_3': -15.50143814086914, 'loss_4': 3.0150227546691895, 'epoch': 3.7}
{'loss': 0.1531, 'grad_norm': 21.149620056152344, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.1517339050769806, 'loss_2': 0.0014019012451171875, 'loss_3': -15.206562042236328, 'loss_4': 2.271986484527588, 'epoch': 3.71}
{'loss': 0.0324, 'grad_norm': 11.785490989685059, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.03021850250661373, 'loss_2': 0.00214385986328125, 'loss_3': -15.85589599609375, 'loss_4': 2.6021456718444824, 'epoch': 3.72}
{'loss': 0.0326, 'grad_norm': 10.175145149230957, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.029113879427313805, 'loss_2': 0.0034427642822265625, 'loss_3': -15.8045654296875, 'loss_4': 2.988067150115967, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 09:40:02,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:02,211 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:16<1:18:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:09,571 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015826061367988586, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.544, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012719197198748589, 'eval_loss_2': 0.0031068623065948486, 'eval_loss_3': -18.239484786987305, 'eval_loss_4': 2.480745792388916, 'epoch': 3.72}
{'loss': 0.0348, 'grad_norm': 8.897313117980957, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.032687701284885406, 'loss_2': 0.0020923614501953125, 'loss_3': -15.880363464355469, 'loss_4': 3.172968864440918, 'epoch': 3.73}
{'loss': 0.0247, 'grad_norm': 9.669275283813477, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.024224305525422096, 'loss_2': 0.0004968643188476562, 'loss_3': -15.931384086608887, 'loss_4': 3.684046983718872, 'epoch': 3.73}
{'loss': 0.0492, 'grad_norm': 14.545324325561523, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.048516251146793365, 'loss_2': 0.0006494522094726562, 'loss_3': -15.734583854675293, 'loss_4': 3.2140231132507324, 'epoch': 3.74}
{'loss': 0.0373, 'grad_norm': 15.627551078796387, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.032883815467357635, 'loss_2': 0.00446319580078125, 'loss_3': -15.960346221923828, 'loss_4': 4.1501288414001465, 'epoch': 3.74}
{'loss': 0.0578, 'grad_norm': 14.19272232055664, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.045400895178318024, 'loss_2': 0.01238250732421875, 'loss_3': -15.751859664916992, 'loss_4': 4.710040092468262, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 09:40:09,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:09,572 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:24<1:18:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:16,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029523121193051338, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.669, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015305745415389538, 'eval_loss_2': 0.014217376708984375, 'eval_loss_3': -18.286245346069336, 'eval_loss_4': 3.7173852920532227, 'epoch': 3.75}
{'loss': 0.0756, 'grad_norm': 16.47113609313965, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.050774358212947845, 'loss_2': 0.0247955322265625, 'loss_3': -15.700117111206055, 'loss_4': 4.043314456939697, 'epoch': 3.76}
{'loss': 0.0267, 'grad_norm': 5.948597431182861, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.015723200514912605, 'loss_2': 0.011016845703125, 'loss_3': -15.837297439575195, 'loss_4': 4.847562313079834, 'epoch': 3.76}
{'loss': 0.0988, 'grad_norm': 25.045839309692383, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.0883917510509491, 'loss_2': 0.0104217529296875, 'loss_3': -15.653032302856445, 'loss_4': 4.163947105407715, 'epoch': 3.77}
{'loss': 0.0441, 'grad_norm': 15.137720108032227, 'learning_rate': 2.625e-05, 'loss_1': 0.03764230012893677, 'loss_2': 0.0064849853515625, 'loss_3': -15.640226364135742, 'loss_4': 5.016783237457275, 'epoch': 3.77}
{'loss': 0.0706, 'grad_norm': 28.83791160583496, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.06721079349517822, 'loss_2': 0.003368377685546875, 'loss_3': -15.625948905944824, 'loss_4': 4.214784622192383, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 09:40:16,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:16,928 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:31<1:18:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:24,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021125253289937973, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.3, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.015446286648511887, 'eval_loss_2': 0.005678966641426086, 'eval_loss_3': -18.246479034423828, 'eval_loss_4': 3.5765273571014404, 'epoch': 3.78}
{'loss': 0.0582, 'grad_norm': 11.7017240524292, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.054348256438970566, 'loss_2': 0.0038661956787109375, 'loss_3': -15.702567100524902, 'loss_4': 4.0815629959106445, 'epoch': 3.78}
{'loss': 0.0459, 'grad_norm': 15.278196334838867, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.04243581369519234, 'loss_2': 0.00345611572265625, 'loss_3': -15.877775192260742, 'loss_4': 3.6454110145568848, 'epoch': 3.79}
{'loss': 0.0326, 'grad_norm': 9.75025463104248, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.02536945231258869, 'loss_2': 0.00720977783203125, 'loss_3': -15.822587966918945, 'loss_4': 4.549952983856201, 'epoch': 3.8}
{'loss': 0.0432, 'grad_norm': 14.508160591125488, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.04011397063732147, 'loss_2': 0.00307464599609375, 'loss_3': -15.751913070678711, 'loss_4': 3.7450413703918457, 'epoch': 3.8}
{'loss': 0.0183, 'grad_norm': 7.006797790527344, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.017314480617642403, 'loss_2': 0.0009713172912597656, 'loss_3': -15.599420547485352, 'loss_4': 3.4630038738250732, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 09:40:24,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:24,292 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:38<1:17:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:31,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016925612464547157, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.351, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.013962654396891594, 'eval_loss_2': 0.0029629580676555634, 'eval_loss_3': -18.259876251220703, 'eval_loss_4': 2.8193252086639404, 'epoch': 3.81}
{'loss': 0.0314, 'grad_norm': 10.132438659667969, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.028345312923192978, 'loss_2': 0.0030498504638671875, 'loss_3': -15.792821884155273, 'loss_4': 3.4954676628112793, 'epoch': 3.81}
{'loss': 0.0268, 'grad_norm': 8.536970138549805, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.021608997136354446, 'loss_2': 0.005218505859375, 'loss_3': -15.520444869995117, 'loss_4': 2.983870029449463, 'epoch': 3.82}
{'loss': 0.0547, 'grad_norm': 17.128385543823242, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.05228911712765694, 'loss_2': 0.0024261474609375, 'loss_3': -15.825484275817871, 'loss_4': 2.314906597137451, 'epoch': 3.83}
{'loss': 0.0334, 'grad_norm': 8.933968544006348, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.026587361469864845, 'loss_2': 0.00678253173828125, 'loss_3': -15.569148063659668, 'loss_4': 3.0856359004974365, 'epoch': 3.83}
{'loss': 0.0408, 'grad_norm': 11.252735137939453, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.03452292084693909, 'loss_2': 0.0062713623046875, 'loss_3': -15.829586029052734, 'loss_4': 2.243511199951172, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 09:40:31,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:31,653 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:46<1:17:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:39,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016547678038477898, 'eval_runtime': 3.8218, 'eval_samples_per_second': 267.935, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.013245049864053726, 'eval_loss_2': 0.003302626311779022, 'eval_loss_3': -18.243961334228516, 'eval_loss_4': 1.901153564453125, 'epoch': 3.84}
{'loss': 0.0323, 'grad_norm': 10.851998329162598, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.0287554319947958, 'loss_2': 0.0035800933837890625, 'loss_3': -15.680535316467285, 'loss_4': 1.7343618869781494, 'epoch': 3.84}
{'loss': 0.0409, 'grad_norm': 10.121243476867676, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.037193670868873596, 'loss_2': 0.0036773681640625, 'loss_3': -15.758872032165527, 'loss_4': 2.273548126220703, 'epoch': 3.85}
{'loss': 0.0439, 'grad_norm': 12.90769100189209, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.037864699959754944, 'loss_2': 0.006031036376953125, 'loss_3': -15.772619247436523, 'loss_4': 2.295499801635742, 'epoch': 3.85}
{'loss': 0.035, 'grad_norm': 10.328008651733398, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.033929113298654556, 'loss_2': 0.0010318756103515625, 'loss_3': -15.77902603149414, 'loss_4': 1.7937321662902832, 'epoch': 3.86}
{'loss': 0.0604, 'grad_norm': 16.7470703125, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.058430761098861694, 'loss_2': 0.001995086669921875, 'loss_3': -15.689948081970215, 'loss_4': 1.7482328414916992, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 09:40:39,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:39,020 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:53<1:17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:46,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02642131596803665, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.697, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012052306905388832, 'eval_loss_2': 0.014369010925292969, 'eval_loss_3': -18.210186004638672, 'eval_loss_4': 1.6329429149627686, 'epoch': 3.87}
{'loss': 0.048, 'grad_norm': 14.068085670471191, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.03690600395202637, 'loss_2': 0.0111083984375, 'loss_3': -15.743674278259277, 'loss_4': 1.875430703163147, 'epoch': 3.87}
{'loss': 0.0416, 'grad_norm': 8.694817543029785, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.021809333935379982, 'loss_2': 0.0197601318359375, 'loss_3': -15.760076522827148, 'loss_4': 1.8265236616134644, 'epoch': 3.88}
{'loss': 0.0729, 'grad_norm': 14.450028419494629, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.05019562318921089, 'loss_2': 0.022705078125, 'loss_3': -15.843059539794922, 'loss_4': 2.112710475921631, 'epoch': 3.88}
{'loss': 0.0502, 'grad_norm': 9.202116966247559, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.027686607092618942, 'loss_2': 0.0225067138671875, 'loss_3': -15.96365737915039, 'loss_4': 2.0570144653320312, 'epoch': 3.89}
{'loss': 0.0603, 'grad_norm': 11.94173526763916, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.043644748628139496, 'loss_2': 0.01666259765625, 'loss_3': -15.733406066894531, 'loss_4': 2.2740821838378906, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 09:40:46,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:46,369 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:00<1:17:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:40:53,720 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02990451455116272, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.381, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0118123609572649, 'eval_loss_2': 0.01809215545654297, 'eval_loss_3': -18.20753288269043, 'eval_loss_4': 1.8222548961639404, 'epoch': 3.9}
{'loss': 0.0399, 'grad_norm': 6.530142784118652, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.01804017461836338, 'loss_2': 0.021820068359375, 'loss_3': -15.872178077697754, 'loss_4': 1.8290921449661255, 'epoch': 3.9}
{'loss': 0.0622, 'grad_norm': 13.32438850402832, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.043713971972465515, 'loss_2': 0.018524169921875, 'loss_3': -15.762506484985352, 'loss_4': 1.8312785625457764, 'epoch': 3.91}
{'loss': 0.0467, 'grad_norm': 10.490200996398926, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.037212617695331573, 'loss_2': 0.00946044921875, 'loss_3': -15.817474365234375, 'loss_4': 1.9023933410644531, 'epoch': 3.91}
{'loss': 0.0348, 'grad_norm': 11.62099838256836, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.02626911737024784, 'loss_2': 0.00848388671875, 'loss_3': -15.644186973571777, 'loss_4': 1.9651269912719727, 'epoch': 3.92}
{'loss': 0.0291, 'grad_norm': 6.546302795410156, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.02047993615269661, 'loss_2': 0.00860595703125, 'loss_3': -15.731231689453125, 'loss_4': 1.2772921323776245, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 09:40:53,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:40:53,721 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:08<1:17:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:01,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013691606931388378, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.726, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009326104074716568, 'eval_loss_2': 0.004365503787994385, 'eval_loss_3': -18.229076385498047, 'eval_loss_4': 1.6738120317459106, 'epoch': 3.92}
{'loss': 0.0315, 'grad_norm': 14.667631149291992, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.022641226649284363, 'loss_2': 0.008880615234375, 'loss_3': -15.80080509185791, 'loss_4': 1.8008694648742676, 'epoch': 3.93}
{'loss': 0.052, 'grad_norm': 10.107723236083984, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.038781698793172836, 'loss_2': 0.0132293701171875, 'loss_3': -15.623207092285156, 'loss_4': 1.273709774017334, 'epoch': 3.94}
{'loss': 0.0287, 'grad_norm': 9.467710494995117, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.02761218138039112, 'loss_2': 0.0011196136474609375, 'loss_3': -15.787206649780273, 'loss_4': 2.2446494102478027, 'epoch': 3.94}
{'loss': 0.0569, 'grad_norm': 16.212791442871094, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.043197039514780045, 'loss_2': 0.013702392578125, 'loss_3': -15.58842945098877, 'loss_4': 1.999965786933899, 'epoch': 3.95}
{'loss': 0.0437, 'grad_norm': 9.95007038116455, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.022193601354956627, 'loss_2': 0.021484375, 'loss_3': -15.707357406616211, 'loss_4': 2.676784038543701, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 09:41:01,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:01,070 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:15<1:17:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:08,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02463669516146183, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.601, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007346340920776129, 'eval_loss_2': 0.017290353775024414, 'eval_loss_3': -18.187103271484375, 'eval_loss_4': 1.841673493385315, 'epoch': 3.95}
{'loss': 0.0503, 'grad_norm': 9.378082275390625, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.029214920476078987, 'loss_2': 0.0210723876953125, 'loss_3': -15.747679710388184, 'loss_4': 1.5287023782730103, 'epoch': 3.96}
{'loss': 0.0402, 'grad_norm': 6.919983863830566, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.020204590633511543, 'loss_2': 0.0199737548828125, 'loss_3': -15.605620384216309, 'loss_4': 2.1363072395324707, 'epoch': 3.97}
{'loss': 0.0406, 'grad_norm': 10.412023544311523, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.02024606056511402, 'loss_2': 0.0203399658203125, 'loss_3': -15.875214576721191, 'loss_4': 1.8724243640899658, 'epoch': 3.97}
{'loss': 0.036, 'grad_norm': 8.1810884475708, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.024285776540637016, 'loss_2': 0.01168060302734375, 'loss_3': -15.668477058410645, 'loss_4': 1.9346930980682373, 'epoch': 3.98}
{'loss': 0.0281, 'grad_norm': 9.854430198669434, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.016187800094485283, 'loss_2': 0.01187896728515625, 'loss_3': -15.618748664855957, 'loss_4': 1.9714429378509521, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 09:41:08,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:08,424 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:22<1:14:14,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 09:41:15,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013613700866699219, 'eval_runtime': 3.8288, 'eval_samples_per_second': 267.447, 'eval_steps_per_second': 4.179, 'eval_loss_1': 0.0072393412701785564, 'eval_loss_2': 0.006374359130859375, 'eval_loss_3': -18.14678955078125, 'eval_loss_4': 1.6058651208877563, 'epoch': 3.98}
{'loss': 0.0263, 'grad_norm': 9.583026885986328, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.0231939647346735, 'loss_2': 0.003063201904296875, 'loss_3': -15.773937225341797, 'loss_4': 1.75299870967865, 'epoch': 3.99}
{'loss': 0.0293, 'grad_norm': 12.706927299499512, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.028794854879379272, 'loss_2': 0.00054168701171875, 'loss_3': -15.761457443237305, 'loss_4': 2.1038126945495605, 'epoch': 3.99}
{'loss': 0.0184, 'grad_norm': 7.263453006744385, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.010515579953789711, 'loss_2': 0.007904052734375, 'loss_3': -15.426323890686035, 'loss_4': 1.6475369930267334, 'epoch': 4.0}
{'loss': 0.0203, 'grad_norm': 7.233065605163574, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.01632934994995594, 'loss_2': 0.00399017333984375, 'loss_3': -15.570001602172852, 'loss_4': 1.674529790878296, 'epoch': 4.01}
{'loss': 0.0531, 'grad_norm': 14.55286979675293, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.05191081762313843, 'loss_2': 0.0011425018310546875, 'loss_3': -15.793024063110352, 'loss_4': 0.868972897529602, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 09:41:15,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:15,479 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:30<1:16:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:41:22,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015188662335276604, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.454, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00850608665496111, 'eval_loss_2': 0.00668257474899292, 'eval_loss_3': -18.156349182128906, 'eval_loss_4': 1.1076546907424927, 'epoch': 4.01}
{'loss': 0.045, 'grad_norm': 11.232821464538574, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.03806702420115471, 'loss_2': 0.0069580078125, 'loss_3': -15.669267654418945, 'loss_4': 0.8020031452178955, 'epoch': 4.02}
{'loss': 0.0358, 'grad_norm': 11.724189758300781, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.034846410155296326, 'loss_2': 0.0009222030639648438, 'loss_3': -15.713573455810547, 'loss_4': 1.619837760925293, 'epoch': 4.02}
{'loss': 0.033, 'grad_norm': 7.358314037322998, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.023139921948313713, 'loss_2': 0.0098724365234375, 'loss_3': -15.827573776245117, 'loss_4': 0.6780246496200562, 'epoch': 4.03}
{'loss': 0.0418, 'grad_norm': 12.323545455932617, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.03489977493882179, 'loss_2': 0.006923675537109375, 'loss_3': -15.813045501708984, 'loss_4': 0.9481984376907349, 'epoch': 4.03}
{'loss': 0.056, 'grad_norm': 13.474719047546387, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.048554833978414536, 'loss_2': 0.007476806640625, 'loss_3': -15.791556358337402, 'loss_4': 1.102262258529663, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 09:41:22,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:22,831 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:37<1:17:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:30,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012242274358868599, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.873, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008718254044651985, 'eval_loss_2': 0.0035240203142166138, 'eval_loss_3': -18.16143798828125, 'eval_loss_4': 1.1378976106643677, 'epoch': 4.04}
{'loss': 0.0284, 'grad_norm': 9.0742769241333, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.028032513335347176, 'loss_2': 0.0003523826599121094, 'loss_3': -15.705798149108887, 'loss_4': 1.4932197332382202, 'epoch': 4.05}
{'loss': 0.0413, 'grad_norm': 13.00638484954834, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.04123680666089058, 'loss_2': 6.699562072753906e-05, 'loss_3': -15.716769218444824, 'loss_4': 1.437880277633667, 'epoch': 4.05}
{'loss': 0.0287, 'grad_norm': 6.927708148956299, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.02311498299241066, 'loss_2': 0.0056304931640625, 'loss_3': -15.74966812133789, 'loss_4': 0.9405382871627808, 'epoch': 4.06}
{'loss': 0.0373, 'grad_norm': 11.987617492675781, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.03709414228796959, 'loss_2': 0.00020766258239746094, 'loss_3': -15.959944725036621, 'loss_4': 1.4845199584960938, 'epoch': 4.06}
{'loss': 0.0272, 'grad_norm': 6.858077526092529, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.02503322996199131, 'loss_2': 0.00213623046875, 'loss_3': -15.672640800476074, 'loss_4': 1.0104289054870605, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 09:41:30,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:30,179 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:41<1:17:03,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:41:33,988 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700
[INFO|configuration_utils.py:420] 2025-01-21 09:41:33,989 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700/config.json                                                                              
{'eval_loss': 0.009819092229008675, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.961, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0065888529643416405, 'eval_loss_2': 0.0032302401959896088, 'eval_loss_3': -18.1375675201416, 'eval_loss_4': 1.3781158924102783, 'epoch': 4.07}
[INFO|modeling_utils.py:2988] 2025-01-21 09:41:34,506 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:41:34,507 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:41:34,508 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:41:35,451 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-540] due to args.save_total_limit
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:46<1:25:17,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:41:39,073 >>
{'loss': 0.024, 'grad_norm': 10.10107135772705, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.01893499866127968, 'loss_2': 0.00506591796875, 'loss_3': -15.78541374206543, 'loss_4': 1.9257071018218994, 'epoch': 4.08}
{'loss': 0.0159, 'grad_norm': 6.427526473999023, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.013950039632618427, 'loss_2': 0.0019283294677734375, 'loss_3': -15.657443046569824, 'loss_4': 1.737511396408081, 'epoch': 4.08}
{'loss': 0.0227, 'grad_norm': 8.401050567626953, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.021935585886240005, 'loss_2': 0.0007810592651367188, 'loss_3': -15.784367561340332, 'loss_4': 1.6902902126312256, 'epoch': 4.09}
{'loss': 0.0343, 'grad_norm': 12.400288581848145, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.0337773859500885, 'loss_2': 0.0005159378051757812, 'loss_3': -15.775033950805664, 'loss_4': 1.619699239730835, 'epoch': 4.09}
{'loss': 0.0175, 'grad_norm': 5.706242561340332, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.012864116579294205, 'loss_2': 0.0046844482421875, 'loss_3': -15.778916358947754, 'loss_4': 1.270279049873352, 'epoch': 4.1}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:41:39,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:39,073 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:53<1:18:16,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 09:41:46,421 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01116819866001606, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.613, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006558137014508247, 'eval_loss_2': 0.0046100616455078125, 'eval_loss_3': -18.10581398010254, 'eval_loss_4': 1.7944777011871338, 'epoch': 4.1}
{'loss': 0.0211, 'grad_norm': 8.086355209350586, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.01966184191405773, 'loss_2': 0.00142669677734375, 'loss_3': -15.583643913269043, 'loss_4': 1.7414658069610596, 'epoch': 4.1}
{'loss': 0.0208, 'grad_norm': 7.446585178375244, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.017873648554086685, 'loss_2': 0.0029754638671875, 'loss_3': -15.764433860778809, 'loss_4': 2.170956611633301, 'epoch': 4.11}
{'loss': 0.0212, 'grad_norm': 7.808974742889404, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.019422180950641632, 'loss_2': 0.0017757415771484375, 'loss_3': -15.703572273254395, 'loss_4': 2.783031463623047, 'epoch': 4.12}
{'loss': 0.026, 'grad_norm': 6.8473992347717285, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.017348434776067734, 'loss_2': 0.00861358642578125, 'loss_3': -15.78728199005127, 'loss_4': 1.8038018941879272, 'epoch': 4.12}
{'loss': 0.0124, 'grad_norm': 6.522805213928223, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.010997763834893703, 'loss_2': 0.0013637542724609375, 'loss_3': -15.638362884521484, 'loss_4': 2.3767166137695312, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 09:41:46,421 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:46,421 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:00<1:17:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:41:53,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01076282374560833, 'eval_runtime': 3.8206, 'eval_samples_per_second': 268.018, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007052076049149036, 'eval_loss_2': 0.0037107467651367188, 'eval_loss_3': -18.090322494506836, 'eval_loss_4': 2.071000814437866, 'epoch': 4.13}
{'loss': 0.0189, 'grad_norm': 6.885753154754639, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.018466880545020103, 'loss_2': 0.00044035911560058594, 'loss_3': -15.770421028137207, 'loss_4': 2.3106467723846436, 'epoch': 4.13}
{'loss': 0.0316, 'grad_norm': 10.765368461608887, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.030677514150738716, 'loss_2': 0.0009174346923828125, 'loss_3': -15.706685066223145, 'loss_4': 2.313380241394043, 'epoch': 4.14}
{'loss': 0.0192, 'grad_norm': 8.338018417358398, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.019011080265045166, 'loss_2': 0.00021350383758544922, 'loss_3': -15.568939208984375, 'loss_4': 2.3101677894592285, 'epoch': 4.15}
{'loss': 0.0271, 'grad_norm': 12.987496376037598, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.026081589981913567, 'loss_2': 0.0009784698486328125, 'loss_3': -15.700981140136719, 'loss_4': 2.5678253173828125, 'epoch': 4.15}
{'loss': 0.0151, 'grad_norm': 4.64569616317749, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.007328424137085676, 'loss_2': 0.0077972412109375, 'loss_3': -15.88380241394043, 'loss_4': 1.8605875968933105, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 09:41:53,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:41:53,784 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:08<1:16:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:01,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010275209322571754, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.509, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006147780921310186, 'eval_loss_2': 0.004127427935600281, 'eval_loss_3': -18.07622718811035, 'eval_loss_4': 1.9922256469726562, 'epoch': 4.16}
{'loss': 0.0189, 'grad_norm': 8.387988090515137, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.01558932289481163, 'loss_2': 0.0033473968505859375, 'loss_3': -15.919087409973145, 'loss_4': 2.325580596923828, 'epoch': 4.16}
{'loss': 0.0071, 'grad_norm': 5.379422187805176, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.006886056624352932, 'loss_2': 0.0001989603042602539, 'loss_3': -15.86916732788086, 'loss_4': 1.8720111846923828, 'epoch': 4.17}
{'loss': 0.0261, 'grad_norm': 6.426455497741699, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.008301256224513054, 'loss_2': 0.01776123046875, 'loss_3': -15.706808090209961, 'loss_4': 1.902225136756897, 'epoch': 4.17}
{'loss': 0.0274, 'grad_norm': 6.016562461853027, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.014257609844207764, 'loss_2': 0.01313018798828125, 'loss_3': -15.78178882598877, 'loss_4': 1.9350355863571167, 'epoch': 4.18}
{'loss': 0.0219, 'grad_norm': 5.676007270812988, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.009701956063508987, 'loss_2': 0.012176513671875, 'loss_3': -15.833213806152344, 'loss_4': 1.6260039806365967, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 09:42:01,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:01,137 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:15<1:16:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:08,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014638052321970463, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.698, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006248579826205969, 'eval_loss_2': 0.008389472961425781, 'eval_loss_3': -18.04807472229004, 'eval_loss_4': 1.6880605220794678, 'epoch': 4.19}
{'loss': 0.0266, 'grad_norm': 7.095076084136963, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.01930207945406437, 'loss_2': 0.007289886474609375, 'loss_3': -15.633933067321777, 'loss_4': 1.3860636949539185, 'epoch': 4.19}
{'loss': 0.0266, 'grad_norm': 7.04848575592041, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.015197984874248505, 'loss_2': 0.01145172119140625, 'loss_3': -15.70771598815918, 'loss_4': 1.7068578004837036, 'epoch': 4.2}
{'loss': 0.0121, 'grad_norm': 5.017092227935791, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.006324509624391794, 'loss_2': 0.00582122802734375, 'loss_3': -15.781576156616211, 'loss_4': 1.5557090044021606, 'epoch': 4.2}
{'loss': 0.0514, 'grad_norm': 17.86007308959961, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.05076548084616661, 'loss_2': 0.0005965232849121094, 'loss_3': -15.874469757080078, 'loss_4': 2.0392675399780273, 'epoch': 4.21}
{'loss': 0.0092, 'grad_norm': 5.117076396942139, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.009164674207568169, 'loss_2': 5.710124969482422e-05, 'loss_3': -15.713842391967773, 'loss_4': 1.9189038276672363, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 09:42:08,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:08,488 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:23<1:16:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:15,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017199289053678513, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006632679607719183, 'eval_loss_2': 0.010566610842943192, 'eval_loss_3': -18.106367111206055, 'eval_loss_4': 1.5782049894332886, 'epoch': 4.22}
{'loss': 0.0187, 'grad_norm': 5.874339580535889, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.0151619091629982, 'loss_2': 0.0034942626953125, 'loss_3': -15.925246238708496, 'loss_4': 1.8944402933120728, 'epoch': 4.22}
{'loss': 0.0279, 'grad_norm': 9.48412036895752, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.019350869581103325, 'loss_2': 0.008575439453125, 'loss_3': -15.571300506591797, 'loss_4': 1.7144191265106201, 'epoch': 4.23}
{'loss': 0.0296, 'grad_norm': 7.407999515533447, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.015349219553172588, 'loss_2': 0.01422119140625, 'loss_3': -15.728288650512695, 'loss_4': 1.756408452987671, 'epoch': 4.23}
{'loss': 0.0416, 'grad_norm': 9.927681922912598, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.03074333444237709, 'loss_2': 0.0108795166015625, 'loss_3': -15.709254264831543, 'loss_4': 2.2302889823913574, 'epoch': 4.24}
{'loss': 0.0343, 'grad_norm': 7.61963415145874, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.01740918681025505, 'loss_2': 0.0168914794921875, 'loss_3': -15.61213493347168, 'loss_4': 1.4804978370666504, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 09:42:15,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:15,833 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:30<1:16:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:23,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018614009022712708, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006250813603401184, 'eval_loss_2': 0.012363195419311523, 'eval_loss_3': -18.100980758666992, 'eval_loss_4': 1.502883791923523, 'epoch': 4.24}
{'loss': 0.0224, 'grad_norm': 6.070390224456787, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.014375658705830574, 'loss_2': 0.0080108642578125, 'loss_3': -15.73892593383789, 'loss_4': 1.8522181510925293, 'epoch': 4.25}
{'loss': 0.0223, 'grad_norm': 9.766128540039062, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.02182888798415661, 'loss_2': 0.0004429817199707031, 'loss_3': -15.677529335021973, 'loss_4': 1.2696728706359863, 'epoch': 4.26}
{'loss': 0.0169, 'grad_norm': 4.971039295196533, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.010166370309889317, 'loss_2': 0.006725311279296875, 'loss_3': -15.79888916015625, 'loss_4': 1.2191660404205322, 'epoch': 4.26}
{'loss': 0.0248, 'grad_norm': 7.791591167449951, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.021318558603525162, 'loss_2': 0.0034503936767578125, 'loss_3': -15.80029296875, 'loss_4': 1.2242419719696045, 'epoch': 4.27}
{'loss': 0.031, 'grad_norm': 19.740962982177734, 'learning_rate': 2.575e-05, 'loss_1': 0.02784368395805359, 'loss_2': 0.0031890869140625, 'loss_3': -15.666666030883789, 'loss_4': 1.6321067810058594, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 09:42:23,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:23,178 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:37<1:16:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:30,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010823373682796955, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.572, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0068609388545155525, 'eval_loss_2': 0.003962434828281403, 'eval_loss_3': -18.087209701538086, 'eval_loss_4': 1.6986284255981445, 'epoch': 4.27}
{'loss': 0.0517, 'grad_norm': 19.490570068359375, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.04387146979570389, 'loss_2': 0.0078125, 'loss_3': -15.979832649230957, 'loss_4': 1.7899683713912964, 'epoch': 4.28}
{'loss': 0.0275, 'grad_norm': 11.293780326843262, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.02085012011229992, 'loss_2': 0.006683349609375, 'loss_3': -15.61785888671875, 'loss_4': 2.4417452812194824, 'epoch': 4.28}
{'loss': 0.036, 'grad_norm': 7.975069046020508, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.02060154639184475, 'loss_2': 0.0154266357421875, 'loss_3': -15.799764633178711, 'loss_4': 2.1206274032592773, 'epoch': 4.29}
{'loss': 0.0656, 'grad_norm': 22.4217529296875, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.05852292478084564, 'loss_2': 0.007045745849609375, 'loss_3': -15.722464561462402, 'loss_4': 1.9779248237609863, 'epoch': 4.3}
{'loss': 0.03, 'grad_norm': 7.479053497314453, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.019109368324279785, 'loss_2': 0.0109100341796875, 'loss_3': -15.92729377746582, 'loss_4': 2.038999557495117, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 09:42:30,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:30,532 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:45<1:16:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:37,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012107282876968384, 'eval_runtime': 3.8442, 'eval_samples_per_second': 266.375, 'eval_steps_per_second': 4.162, 'eval_loss_1': 0.007145070005208254, 'eval_loss_2': 0.004962213337421417, 'eval_loss_3': -18.075607299804688, 'eval_loss_4': 2.029374837875366, 'epoch': 4.3}
{'loss': 0.0241, 'grad_norm': 9.09200668334961, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.017360003665089607, 'loss_2': 0.0066986083984375, 'loss_3': -15.882479667663574, 'loss_4': 2.4862937927246094, 'epoch': 4.31}
{'loss': 0.019, 'grad_norm': 7.674922466278076, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.016801055520772934, 'loss_2': 0.0021820068359375, 'loss_3': -15.82644271850586, 'loss_4': 2.4467058181762695, 'epoch': 4.31}
{'loss': 0.0348, 'grad_norm': 14.906774520874023, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.03194938600063324, 'loss_2': 0.00281524658203125, 'loss_3': -15.740880966186523, 'loss_4': 1.5647709369659424, 'epoch': 4.32}
{'loss': 0.0372, 'grad_norm': 10.195213317871094, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.02681082673370838, 'loss_2': 0.0103607177734375, 'loss_3': -15.883722305297852, 'loss_4': 2.194312810897827, 'epoch': 4.33}
{'loss': 0.0219, 'grad_norm': 6.4647216796875, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.014444585889577866, 'loss_2': 0.00742340087890625, 'loss_3': -15.688222885131836, 'loss_4': 1.7002224922180176, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 09:42:37,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:37,908 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:52<1:16:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:45,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014897258952260017, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.181, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.009383948519825935, 'eval_loss_2': 0.005513310432434082, 'eval_loss_3': -18.081743240356445, 'eval_loss_4': 1.9714528322219849, 'epoch': 4.33}
{'loss': 0.0215, 'grad_norm': 7.390986442565918, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.017807288095355034, 'loss_2': 0.003726959228515625, 'loss_3': -15.802610397338867, 'loss_4': 2.1492202281951904, 'epoch': 4.34}
{'loss': 0.0406, 'grad_norm': 14.011067390441895, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.037532106041908264, 'loss_2': 0.0030384063720703125, 'loss_3': -15.775585174560547, 'loss_4': 2.04561710357666, 'epoch': 4.34}
{'loss': 0.047, 'grad_norm': 18.31770133972168, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.04645903408527374, 'loss_2': 0.0005779266357421875, 'loss_3': -15.934439659118652, 'loss_4': 2.5033154487609863, 'epoch': 4.35}
{'loss': 0.0624, 'grad_norm': 19.50536346435547, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.056212544441223145, 'loss_2': 0.00616455078125, 'loss_3': -15.655272483825684, 'loss_4': 2.130558490753174, 'epoch': 4.35}
{'loss': 0.0381, 'grad_norm': 12.638840675354004, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.03650397062301636, 'loss_2': 0.0016040802001953125, 'loss_3': -15.594202995300293, 'loss_4': 1.9647034406661987, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 09:42:45,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:45,267 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [18:59<1:16:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:52,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011383390054106712, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.544, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008463299833238125, 'eval_loss_2': 0.002920091152191162, 'eval_loss_3': -18.118545532226562, 'eval_loss_4': 1.9600359201431274, 'epoch': 4.36}
{'loss': 0.0249, 'grad_norm': 8.409067153930664, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.020388906821608543, 'loss_2': 0.00446319580078125, 'loss_3': -16.03875732421875, 'loss_4': 2.3259997367858887, 'epoch': 4.37}
{'loss': 0.0205, 'grad_norm': 6.928124904632568, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.01591063290834427, 'loss_2': 0.0045928955078125, 'loss_3': -15.96318244934082, 'loss_4': 1.7373154163360596, 'epoch': 4.37}
{'loss': 0.0206, 'grad_norm': 7.1338605880737305, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.018944939598441124, 'loss_2': 0.00160980224609375, 'loss_3': -15.952300071716309, 'loss_4': 2.0892653465270996, 'epoch': 4.38}
{'loss': 0.0294, 'grad_norm': 9.811389923095703, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.019817885011434555, 'loss_2': 0.0096282958984375, 'loss_3': -15.915753364562988, 'loss_4': 1.9397363662719727, 'epoch': 4.38}
{'loss': 0.0294, 'grad_norm': 9.126863479614258, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.024147888645529747, 'loss_2': 0.00527191162109375, 'loss_3': -15.871103286743164, 'loss_4': 1.871099829673767, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 09:42:52,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:52,614 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:07<1:16:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:42:59,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011773139238357544, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.813, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007291853427886963, 'eval_loss_2': 0.004481285810470581, 'eval_loss_3': -18.15590476989746, 'eval_loss_4': 2.1907994747161865, 'epoch': 4.39}
{'loss': 0.0236, 'grad_norm': 5.876903057098389, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.01393436174839735, 'loss_2': 0.00970458984375, 'loss_3': -15.87267780303955, 'loss_4': 1.6095528602600098, 'epoch': 4.4}
{'loss': 0.0294, 'grad_norm': 9.101791381835938, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.023098863661289215, 'loss_2': 0.00628662109375, 'loss_3': -15.999841690063477, 'loss_4': 2.518960475921631, 'epoch': 4.4}
{'loss': 0.0251, 'grad_norm': 7.8375773429870605, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.02011707052588463, 'loss_2': 0.00493621826171875, 'loss_3': -15.962952613830566, 'loss_4': 2.655637264251709, 'epoch': 4.41}
{'loss': 0.0121, 'grad_norm': 5.127737998962402, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.010606199502944946, 'loss_2': 0.00150299072265625, 'loss_3': -15.77901840209961, 'loss_4': 2.2616324424743652, 'epoch': 4.41}
{'loss': 0.0293, 'grad_norm': 9.686877250671387, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.028132017701864243, 'loss_2': 0.00115203857421875, 'loss_3': -15.949883460998535, 'loss_4': 3.1783127784729004, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 09:42:59,966 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:42:59,966 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:14<1:16:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:07,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016362927854061127, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.414, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006855449639260769, 'eval_loss_2': 0.009507477283477783, 'eval_loss_3': -18.186586380004883, 'eval_loss_4': 2.6804511547088623, 'epoch': 4.42}
{'loss': 0.0192, 'grad_norm': 5.570852279663086, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.011662953533232212, 'loss_2': 0.007568359375, 'loss_3': -16.08413314819336, 'loss_4': 2.6140904426574707, 'epoch': 4.42}
{'loss': 0.0492, 'grad_norm': 13.823263168334961, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.03667864575982094, 'loss_2': 0.012542724609375, 'loss_3': -15.94135856628418, 'loss_4': 3.887869119644165, 'epoch': 4.43}
{'loss': 0.0425, 'grad_norm': 9.12875747680664, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.028137212619185448, 'loss_2': 0.01436614990234375, 'loss_3': -15.897087097167969, 'loss_4': 3.5638837814331055, 'epoch': 4.44}
{'loss': 0.0444, 'grad_norm': 12.698503494262695, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.033797863870859146, 'loss_2': 0.0106201171875, 'loss_3': -15.929061889648438, 'loss_4': 3.2703475952148438, 'epoch': 4.44}
{'loss': 0.024, 'grad_norm': 8.559948921203613, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.016236189752817154, 'loss_2': 0.00775909423828125, 'loss_3': -15.649884223937988, 'loss_4': 3.4715843200683594, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 09:43:07,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:07,327 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:21<1:16:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:14,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015532688237726688, 'eval_runtime': 3.8202, 'eval_samples_per_second': 268.048, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007144489791244268, 'eval_loss_2': 0.008388198912143707, 'eval_loss_3': -18.160228729248047, 'eval_loss_4': 2.6485562324523926, 'epoch': 4.45}
{'loss': 0.0226, 'grad_norm': 8.620469093322754, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.01804501935839653, 'loss_2': 0.00453948974609375, 'loss_3': -15.78398323059082, 'loss_4': 3.5787878036499023, 'epoch': 4.45}
{'loss': 0.0331, 'grad_norm': 9.131197929382324, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.026886962354183197, 'loss_2': 0.0062103271484375, 'loss_3': -16.00335121154785, 'loss_4': 2.302262783050537, 'epoch': 4.46}
{'loss': 0.0238, 'grad_norm': 8.669657707214355, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.020989418029785156, 'loss_2': 0.0027923583984375, 'loss_3': -15.828100204467773, 'loss_4': 2.4761579036712646, 'epoch': 4.47}
{'loss': 0.0294, 'grad_norm': 7.390820503234863, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.019351722672581673, 'loss_2': 0.0100555419921875, 'loss_3': -15.797975540161133, 'loss_4': 3.131727457046509, 'epoch': 4.47}
{'loss': 0.0261, 'grad_norm': 8.300275802612305, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.02450595423579216, 'loss_2': 0.0015697479248046875, 'loss_3': -15.97303581237793, 'loss_4': 3.785501003265381, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 09:43:14,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:14,696 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:29<1:15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:22,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011925764381885529, 'eval_runtime': 3.8261, 'eval_samples_per_second': 267.636, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.007684194482862949, 'eval_loss_2': 0.004241570830345154, 'eval_loss_3': -18.108457565307617, 'eval_loss_4': 2.807878255844116, 'epoch': 4.48}
{'loss': 0.0145, 'grad_norm': 6.542269229888916, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.012541546486318111, 'loss_2': 0.0019388198852539062, 'loss_3': -15.80095100402832, 'loss_4': 2.895331382751465, 'epoch': 4.48}
{'loss': 0.0334, 'grad_norm': 11.758613586425781, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.027983179315924644, 'loss_2': 0.0053863525390625, 'loss_3': -16.047012329101562, 'loss_4': 3.3796730041503906, 'epoch': 4.49}
{'loss': 0.025, 'grad_norm': 6.692092418670654, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.01735280267894268, 'loss_2': 0.0076446533203125, 'loss_3': -15.835749626159668, 'loss_4': 3.165351390838623, 'epoch': 4.49}
{'loss': 0.0334, 'grad_norm': 7.6275739669799805, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.025733038783073425, 'loss_2': 0.00762176513671875, 'loss_3': -15.526786804199219, 'loss_4': 3.392819404602051, 'epoch': 4.5}
{'loss': 0.0306, 'grad_norm': 10.744231224060059, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.02571694366633892, 'loss_2': 0.00484466552734375, 'loss_3': -15.991443634033203, 'loss_4': 3.145688056945801, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 09:43:22,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:22,062 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:36<1:15:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:29,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010453896597027779, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.764, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0071764299646019936, 'eval_loss_2': 0.0032774657011032104, 'eval_loss_3': -18.124935150146484, 'eval_loss_4': 3.0453832149505615, 'epoch': 4.51}
{'loss': 0.0249, 'grad_norm': 7.4604058265686035, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.01798402890563011, 'loss_2': 0.00688934326171875, 'loss_3': -16.016103744506836, 'loss_4': 3.272843837738037, 'epoch': 4.51}
{'loss': 0.0142, 'grad_norm': 6.083657264709473, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.013825695030391216, 'loss_2': 0.00034999847412109375, 'loss_3': -15.966949462890625, 'loss_4': 3.8799118995666504, 'epoch': 4.52}
{'loss': 0.0178, 'grad_norm': 7.406360626220703, 'learning_rate': 2.55e-05, 'loss_1': 0.016264958307147026, 'loss_2': 0.0014896392822265625, 'loss_3': -15.802448272705078, 'loss_4': 3.422104835510254, 'epoch': 4.52}
{'loss': 0.1476, 'grad_norm': 24.584936141967773, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.1392761766910553, 'loss_2': 0.00830078125, 'loss_3': -15.701534271240234, 'loss_4': 3.3073792457580566, 'epoch': 4.53}
{'loss': 0.0494, 'grad_norm': 15.696036338806152, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.048432521522045135, 'loss_2': 0.0009431838989257812, 'loss_3': -15.884119033813477, 'loss_4': 3.769577980041504, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 09:43:29,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:29,416 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:43<1:15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:36,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013599063269793987, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.743, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007764557376503944, 'eval_loss_2': 0.005834504961967468, 'eval_loss_3': -18.150352478027344, 'eval_loss_4': 3.1184325218200684, 'epoch': 4.53}
{'loss': 0.0822, 'grad_norm': 24.70386505126953, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.07904052734375, 'loss_2': 0.0031795501708984375, 'loss_3': -15.916993141174316, 'loss_4': 3.6629834175109863, 'epoch': 4.54}
{'loss': 0.0566, 'grad_norm': 14.57736587524414, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.04762330651283264, 'loss_2': 0.00902557373046875, 'loss_3': -15.64908218383789, 'loss_4': 3.7666308879852295, 'epoch': 4.55}
{'loss': 0.0224, 'grad_norm': 9.671220779418945, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.019323963671922684, 'loss_2': 0.0030517578125, 'loss_3': -15.710705757141113, 'loss_4': 3.721365451812744, 'epoch': 4.55}
{'loss': 0.0533, 'grad_norm': 16.96169662475586, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.04709606245160103, 'loss_2': 0.0061798095703125, 'loss_3': -15.844072341918945, 'loss_4': 3.3094077110290527, 'epoch': 4.56}
{'loss': 0.0398, 'grad_norm': 11.017967224121094, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.028212888166308403, 'loss_2': 0.0115814208984375, 'loss_3': -15.683267593383789, 'loss_4': 3.8760857582092285, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 09:43:36,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:36,770 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:51<1:15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:44,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01231507770717144, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.83, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00808713398873806, 'eval_loss_2': 0.00422794371843338, 'eval_loss_3': -18.14635467529297, 'eval_loss_4': 3.2561306953430176, 'epoch': 4.56}
{'loss': 0.0108, 'grad_norm': 5.79481840133667, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.008107281289994717, 'loss_2': 0.0027256011962890625, 'loss_3': -16.04252815246582, 'loss_4': 3.8225619792938232, 'epoch': 4.57}
{'loss': 0.0134, 'grad_norm': 5.262118816375732, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.008846688084304333, 'loss_2': 0.00458526611328125, 'loss_3': -15.914148330688477, 'loss_4': 3.281033754348755, 'epoch': 4.58}
{'loss': 0.0607, 'grad_norm': 18.025009155273438, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.056942109018564224, 'loss_2': 0.0038051605224609375, 'loss_3': -15.916141510009766, 'loss_4': 3.3974454402923584, 'epoch': 4.58}
{'loss': 0.0521, 'grad_norm': 18.13089942932129, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.050338197499513626, 'loss_2': 0.001739501953125, 'loss_3': -15.795112609863281, 'loss_4': 3.3801369667053223, 'epoch': 4.59}
{'loss': 0.0585, 'grad_norm': 16.79903221130371, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.0477135144174099, 'loss_2': 0.0107574462890625, 'loss_3': -15.899402618408203, 'loss_4': 3.2194974422454834, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 09:43:44,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:44,121 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [19:58<1:15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:51,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011848969385027885, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.786, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008903281763195992, 'eval_loss_2': 0.002945687621831894, 'eval_loss_3': -18.122468948364258, 'eval_loss_4': 2.8142054080963135, 'epoch': 4.59}
{'loss': 0.0366, 'grad_norm': 10.873448371887207, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.027951372787356377, 'loss_2': 0.00865936279296875, 'loss_3': -15.773059844970703, 'loss_4': 3.452770948410034, 'epoch': 4.6}
{'loss': 0.0369, 'grad_norm': 12.095165252685547, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.03373201563954353, 'loss_2': 0.003200531005859375, 'loss_3': -15.936990737915039, 'loss_4': 2.850032329559326, 'epoch': 4.6}
{'loss': 0.0368, 'grad_norm': 9.299613952636719, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.03077809140086174, 'loss_2': 0.00598907470703125, 'loss_3': -15.856532096862793, 'loss_4': 2.6667087078094482, 'epoch': 4.61}
{'loss': 0.0237, 'grad_norm': 6.941292762756348, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.01656227745115757, 'loss_2': 0.00717926025390625, 'loss_3': -15.853652000427246, 'loss_4': 3.267648220062256, 'epoch': 4.62}
{'loss': 0.0165, 'grad_norm': 5.679915428161621, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.009122001938521862, 'loss_2': 0.007415771484375, 'loss_3': -16.026262283325195, 'loss_4': 4.298563480377197, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 09:43:51,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:51,479 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:06<1:15:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:43:58,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012434113770723343, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.101, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.008122909814119339, 'eval_loss_2': 0.004311203956604004, 'eval_loss_3': -18.159523010253906, 'eval_loss_4': 3.1364612579345703, 'epoch': 4.62}
{'loss': 0.0234, 'grad_norm': 6.906239032745361, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.02101309224963188, 'loss_2': 0.0024356842041015625, 'loss_3': -16.071533203125, 'loss_4': 3.494668483734131, 'epoch': 4.63}
{'loss': 0.0143, 'grad_norm': 5.994741916656494, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.01348703633993864, 'loss_2': 0.0008487701416015625, 'loss_3': -15.916934967041016, 'loss_4': 3.4281373023986816, 'epoch': 4.63}
{'loss': 0.0357, 'grad_norm': 16.276020050048828, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.0341792106628418, 'loss_2': 0.001506805419921875, 'loss_3': -15.963427543640137, 'loss_4': 3.948712110519409, 'epoch': 4.64}
{'loss': 0.043, 'grad_norm': 12.477130889892578, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.034753065556287766, 'loss_2': 0.0082550048828125, 'loss_3': -16.12822914123535, 'loss_4': 3.704522132873535, 'epoch': 4.65}
{'loss': 0.0292, 'grad_norm': 6.788187026977539, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.018151504918932915, 'loss_2': 0.0110015869140625, 'loss_3': -15.887580871582031, 'loss_4': 3.75095796585083, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 09:43:58,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:43:58,846 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:13<1:15:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:06,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016318706795573235, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008392837829887867, 'eval_loss_2': 0.007925868034362793, 'eval_loss_3': -18.17049789428711, 'eval_loss_4': 3.383108615875244, 'epoch': 4.65}
{'loss': 0.0424, 'grad_norm': 8.880512237548828, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.02893076464533806, 'loss_2': 0.01348876953125, 'loss_3': -15.815743446350098, 'loss_4': 3.4892497062683105, 'epoch': 4.66}
{'loss': 0.0752, 'grad_norm': 27.134859085083008, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.06754270195960999, 'loss_2': 0.007633209228515625, 'loss_3': -16.169143676757812, 'loss_4': 4.075761795043945, 'epoch': 4.66}
{'loss': 0.0266, 'grad_norm': 9.530281066894531, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.019172579050064087, 'loss_2': 0.00739288330078125, 'loss_3': -16.03793716430664, 'loss_4': 3.4828429222106934, 'epoch': 4.67}
{'loss': 0.0447, 'grad_norm': 15.059697151184082, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.04024151712656021, 'loss_2': 0.0044708251953125, 'loss_3': -15.945180892944336, 'loss_4': 3.0533413887023926, 'epoch': 4.67}
{'loss': 0.0291, 'grad_norm': 10.303009033203125, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.027020826935768127, 'loss_2': 0.0021209716796875, 'loss_3': -15.83736801147461, 'loss_4': 4.09954309463501, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 09:44:06,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:06,213 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:20<1:15:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:13,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011895290575921535, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.715, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008557072840631008, 'eval_loss_2': 0.0033382177352905273, 'eval_loss_3': -18.189329147338867, 'eval_loss_4': 2.9492456912994385, 'epoch': 4.68}
{'loss': 0.0294, 'grad_norm': 9.463834762573242, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.027540812268853188, 'loss_2': 0.0018405914306640625, 'loss_3': -15.93345832824707, 'loss_4': 3.956374406814575, 'epoch': 4.69}
{'loss': 0.033, 'grad_norm': 9.364968299865723, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.025514310225844383, 'loss_2': 0.00746917724609375, 'loss_3': -15.855691909790039, 'loss_4': 2.710651159286499, 'epoch': 4.69}
{'loss': 0.0283, 'grad_norm': 7.143562316894531, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.018187595531344414, 'loss_2': 0.0101318359375, 'loss_3': -15.777139663696289, 'loss_4': 2.9841580390930176, 'epoch': 4.7}
{'loss': 0.0372, 'grad_norm': 14.72665023803711, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.03477585315704346, 'loss_2': 0.002460479736328125, 'loss_3': -15.794194221496582, 'loss_4': 3.308661460876465, 'epoch': 4.7}
{'loss': 0.0238, 'grad_norm': 7.797430992126465, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.017826704308390617, 'loss_2': 0.00595855712890625, 'loss_3': -15.966279029846191, 'loss_4': 2.06968355178833, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 09:44:13,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:13,568 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:28<1:15:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:20,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012930182740092278, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.511, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008374331519007683, 'eval_loss_2': 0.004555851221084595, 'eval_loss_3': -18.161479949951172, 'eval_loss_4': 2.439985752105713, 'epoch': 4.71}
{'loss': 0.0268, 'grad_norm': 7.669755458831787, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.01855672337114811, 'loss_2': 0.0082244873046875, 'loss_3': -15.987805366516113, 'loss_4': 2.526346206665039, 'epoch': 4.72}
{'loss': 0.0288, 'grad_norm': 9.597561836242676, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.023814009502530098, 'loss_2': 0.0049896240234375, 'loss_3': -16.052547454833984, 'loss_4': 2.9091153144836426, 'epoch': 4.72}
{'loss': 0.0191, 'grad_norm': 7.479742527008057, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.017543809488415718, 'loss_2': 0.001556396484375, 'loss_3': -15.944459915161133, 'loss_4': 2.4386887550354004, 'epoch': 4.73}
{'loss': 0.0317, 'grad_norm': 10.036094665527344, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.02226765640079975, 'loss_2': 0.009429931640625, 'loss_3': -15.956578254699707, 'loss_4': 2.6211178302764893, 'epoch': 4.73}
{'loss': 0.0253, 'grad_norm': 6.912264823913574, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.016139429062604904, 'loss_2': 0.0091400146484375, 'loss_3': -15.986519813537598, 'loss_4': 1.8769242763519287, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 09:44:20,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:20,925 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:35<1:15:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:28,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014664225280284882, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.172, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.007766224909573793, 'eval_loss_2': 0.0068980008363723755, 'eval_loss_3': -18.126554489135742, 'eval_loss_4': 2.2353310585021973, 'epoch': 4.74}
{'loss': 0.029, 'grad_norm': 9.467079162597656, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.018120523542165756, 'loss_2': 0.01091766357421875, 'loss_3': -15.846055030822754, 'loss_4': 2.749042510986328, 'epoch': 4.74}
{'loss': 0.0538, 'grad_norm': 12.786752700805664, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.039754077792167664, 'loss_2': 0.014007568359375, 'loss_3': -15.645727157592773, 'loss_4': 1.846315860748291, 'epoch': 4.75}
{'loss': 0.0451, 'grad_norm': 15.282520294189453, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.033922553062438965, 'loss_2': 0.011199951171875, 'loss_3': -15.875993728637695, 'loss_4': 2.482863664627075, 'epoch': 4.76}
{'loss': 0.0324, 'grad_norm': 9.086771965026855, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.0236414335668087, 'loss_2': 0.0087432861328125, 'loss_3': -15.9976806640625, 'loss_4': 2.0546510219573975, 'epoch': 4.76}
{'loss': 0.0301, 'grad_norm': 8.673907279968262, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.02260664664208889, 'loss_2': 0.00751495361328125, 'loss_3': -15.747886657714844, 'loss_4': 2.5473716259002686, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 09:44:28,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:28,288 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:42<1:15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:35,641 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012630845420062542, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008073624223470688, 'eval_loss_2': 0.004557222127914429, 'eval_loss_3': -18.10968589782715, 'eval_loss_4': 2.252725124359131, 'epoch': 4.77}
{'loss': 0.047, 'grad_norm': 14.356844902038574, 'learning_rate': 2.525e-05, 'loss_1': 0.043461788445711136, 'loss_2': 0.0035533905029296875, 'loss_3': -15.756500244140625, 'loss_4': 2.982027053833008, 'epoch': 4.77}
{'loss': 0.0194, 'grad_norm': 7.074933052062988, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.017874298617243767, 'loss_2': 0.0015172958374023438, 'loss_3': -15.767524719238281, 'loss_4': 2.590526819229126, 'epoch': 4.78}
{'loss': 0.0433, 'grad_norm': 16.11659049987793, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.04119056090712547, 'loss_2': 0.0020904541015625, 'loss_3': -16.052215576171875, 'loss_4': 2.8124184608459473, 'epoch': 4.78}
{'loss': 0.0379, 'grad_norm': 15.076358795166016, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.03721092641353607, 'loss_2': 0.0006399154663085938, 'loss_3': -15.769218444824219, 'loss_4': 2.2468740940093994, 'epoch': 4.79}
{'loss': 0.0401, 'grad_norm': 14.273460388183594, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.03729061037302017, 'loss_2': 0.002788543701171875, 'loss_3': -15.946131706237793, 'loss_4': 2.203361988067627, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 09:44:35,641 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:35,641 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:50<1:14:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:42,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016494933515787125, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.356, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.010107995942234993, 'eval_loss_2': 0.006386935710906982, 'eval_loss_3': -18.10875129699707, 'eval_loss_4': 1.8999544382095337, 'epoch': 4.8}
{'loss': 0.0225, 'grad_norm': 8.246031761169434, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.020864320918917656, 'loss_2': 0.0016231536865234375, 'loss_3': -15.600351333618164, 'loss_4': 1.475071668624878, 'epoch': 4.8}
{'loss': 0.0507, 'grad_norm': 21.11543083190918, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.05038626864552498, 'loss_2': 0.000335693359375, 'loss_3': -15.760143280029297, 'loss_4': 2.0291199684143066, 'epoch': 4.81}
{'loss': 0.031, 'grad_norm': 11.51266860961914, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.02733997255563736, 'loss_2': 0.003681182861328125, 'loss_3': -15.712900161743164, 'loss_4': 1.8286703824996948, 'epoch': 4.81}
{'loss': 0.0358, 'grad_norm': 16.019573211669922, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.03259114921092987, 'loss_2': 0.0031719207763671875, 'loss_3': -15.915132522583008, 'loss_4': 1.733205795288086, 'epoch': 4.82}
{'loss': 0.0234, 'grad_norm': 6.1756911277771, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.01621369458734989, 'loss_2': 0.007167816162109375, 'loss_3': -15.657240867614746, 'loss_4': 1.5434131622314453, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 09:44:42,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:42,991 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:57<1:14:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:50,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015992160886526108, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011596529744565487, 'eval_loss_2': 0.004395633935928345, 'eval_loss_3': -18.10889434814453, 'eval_loss_4': 1.5125765800476074, 'epoch': 4.83}
{'loss': 0.0339, 'grad_norm': 12.212928771972656, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.031017879024147987, 'loss_2': 0.00289154052734375, 'loss_3': -15.753172874450684, 'loss_4': 1.0558291673660278, 'epoch': 4.83}
{'loss': 0.043, 'grad_norm': 16.89447784423828, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.042944859713315964, 'loss_2': 0.00010085105895996094, 'loss_3': -15.834877014160156, 'loss_4': 2.1215834617614746, 'epoch': 4.84}
{'loss': 0.0599, 'grad_norm': 17.169105529785156, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.0594281330704689, 'loss_2': 0.0004329681396484375, 'loss_3': -15.962504386901855, 'loss_4': 1.3644626140594482, 'epoch': 4.84}
{'loss': 0.0254, 'grad_norm': 8.132803916931152, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.020423345267772675, 'loss_2': 0.00496673583984375, 'loss_3': -15.811511993408203, 'loss_4': 1.3054134845733643, 'epoch': 4.85}
{'loss': 0.0579, 'grad_norm': 13.746990203857422, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.04558880627155304, 'loss_2': 0.0123138427734375, 'loss_3': -15.928913116455078, 'loss_4': 1.6209614276885986, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 09:44:50,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:50,335 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:04<1:14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:44:57,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014380204491317272, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.88, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011451976373791695, 'eval_loss_2': 0.002928227186203003, 'eval_loss_3': -18.091684341430664, 'eval_loss_4': 1.2113721370697021, 'epoch': 4.85}
{'loss': 0.0544, 'grad_norm': 18.382246017456055, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.04937751591205597, 'loss_2': 0.00501251220703125, 'loss_3': -15.883014678955078, 'loss_4': 1.7178544998168945, 'epoch': 4.86}
{'loss': 0.0348, 'grad_norm': 12.038511276245117, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.03043409250676632, 'loss_2': 0.004360198974609375, 'loss_3': -15.732046127319336, 'loss_4': 1.7586371898651123, 'epoch': 4.87}
{'loss': 0.036, 'grad_norm': 15.594815254211426, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.030704287812113762, 'loss_2': 0.005275726318359375, 'loss_3': -15.745317459106445, 'loss_4': 1.8962346315383911, 'epoch': 4.87}
{'loss': 0.0271, 'grad_norm': 8.786836624145508, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.02354675903916359, 'loss_2': 0.0035400390625, 'loss_3': -15.713396072387695, 'loss_4': 1.6934928894042969, 'epoch': 4.88}
{'loss': 0.0339, 'grad_norm': 10.231962203979492, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.030113302171230316, 'loss_2': 0.0037708282470703125, 'loss_3': -15.850984573364258, 'loss_4': 1.1474419832229614, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 09:44:57,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:44:57,684 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:12<1:14:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:05,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017051266506314278, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.028, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010882425121963024, 'eval_loss_2': 0.006168842315673828, 'eval_loss_3': -18.083385467529297, 'eval_loss_4': 1.3698923587799072, 'epoch': 4.88}
{'loss': 0.077, 'grad_norm': 26.247425079345703, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.06586641818284988, 'loss_2': 0.01117706298828125, 'loss_3': -15.8643798828125, 'loss_4': 2.1149532794952393, 'epoch': 4.89}
{'loss': 0.0169, 'grad_norm': 9.166831970214844, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.016581077128648758, 'loss_2': 0.0002923011779785156, 'loss_3': -15.722061157226562, 'loss_4': 1.3191723823547363, 'epoch': 4.9}
{'loss': 0.0155, 'grad_norm': 5.822354793548584, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.013725649565458298, 'loss_2': 0.0017871856689453125, 'loss_3': -15.713351249694824, 'loss_4': 1.8350152969360352, 'epoch': 4.9}
{'loss': 0.0209, 'grad_norm': 7.014488697052002, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.012158652767539024, 'loss_2': 0.00870513916015625, 'loss_3': -16.137081146240234, 'loss_4': 1.4528381824493408, 'epoch': 4.91}
{'loss': 0.0304, 'grad_norm': 7.810451984405518, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.022246072068810463, 'loss_2': 0.00812530517578125, 'loss_3': -15.931254386901855, 'loss_4': 1.5414727926254272, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 09:45:05,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:05,032 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:19<1:14:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:12,380 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021517805755138397, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.617, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009544900618493557, 'eval_loss_2': 0.011972904205322266, 'eval_loss_3': -18.129602432250977, 'eval_loss_4': 1.2150696516036987, 'epoch': 4.91}
{'loss': 0.0412, 'grad_norm': 10.418922424316406, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.027273444458842278, 'loss_2': 0.0139617919921875, 'loss_3': -15.836116790771484, 'loss_4': 0.3541957139968872, 'epoch': 4.92}
{'loss': 0.0683, 'grad_norm': 28.24331283569336, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.06217580288648605, 'loss_2': 0.00615692138671875, 'loss_3': -15.592085838317871, 'loss_4': 2.1394639015197754, 'epoch': 4.92}
{'loss': 0.0269, 'grad_norm': 10.46322250366211, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.021720679476857185, 'loss_2': 0.00514984130859375, 'loss_3': -15.94315242767334, 'loss_4': 1.1505272388458252, 'epoch': 4.93}
{'loss': 0.0546, 'grad_norm': 19.13602638244629, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.03848819062113762, 'loss_2': 0.0160675048828125, 'loss_3': -15.97307300567627, 'loss_4': 1.3143506050109863, 'epoch': 4.94}
{'loss': 0.046, 'grad_norm': 10.509657859802246, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.04562529921531677, 'loss_2': 0.0003304481506347656, 'loss_3': -15.494474411010742, 'loss_4': 0.5950971245765686, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 09:45:12,380 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:12,380 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:26<1:14:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:19,740 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015329309739172459, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.043, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.008237161673605442, 'eval_loss_2': 0.007092148065567017, 'eval_loss_3': -18.137527465820312, 'eval_loss_4': 1.0860795974731445, 'epoch': 4.94}
{'loss': 0.0244, 'grad_norm': 7.843448638916016, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.015732206404209137, 'loss_2': 0.0086212158203125, 'loss_3': -15.795989990234375, 'loss_4': 1.0120935440063477, 'epoch': 4.95}
{'loss': 0.0549, 'grad_norm': 21.434083938598633, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.04952442646026611, 'loss_2': 0.005401611328125, 'loss_3': -15.61245346069336, 'loss_4': 0.8630469441413879, 'epoch': 4.95}
{'loss': 0.0168, 'grad_norm': 6.683040142059326, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.01539840828627348, 'loss_2': 0.001377105712890625, 'loss_3': -15.802231788635254, 'loss_4': 1.667407751083374, 'epoch': 4.96}
{'loss': 0.0137, 'grad_norm': 5.176706314086914, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.007087241392582655, 'loss_2': 0.00664520263671875, 'loss_3': -15.809523582458496, 'loss_4': 1.6238391399383545, 'epoch': 4.97}
{'loss': 0.0239, 'grad_norm': 8.010611534118652, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.018605120480060577, 'loss_2': 0.005279541015625, 'loss_3': -15.756593704223633, 'loss_4': 1.4871937036514282, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 09:45:19,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:19,740 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:33<1:06:55,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 09:45:26,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009846262633800507, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.377, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.006768278777599335, 'eval_loss_2': 0.003077983856201172, 'eval_loss_3': -18.127750396728516, 'eval_loss_4': 1.009195327758789, 'epoch': 4.97}
{'loss': 0.02, 'grad_norm': 6.58461856842041, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.019096821546554565, 'loss_2': 0.0009183883666992188, 'loss_3': -15.70034408569336, 'loss_4': 1.5237966775894165, 'epoch': 4.98}
{'loss': 0.0447, 'grad_norm': 9.900734901428223, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.029366610571742058, 'loss_2': 0.015289306640625, 'loss_3': -15.963764190673828, 'loss_4': 1.3926870822906494, 'epoch': 4.98}
{'loss': 0.0264, 'grad_norm': 6.427631855010986, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.013528764247894287, 'loss_2': 0.01290130615234375, 'loss_3': -15.859347343444824, 'loss_4': 0.9700115919113159, 'epoch': 4.99}
{'loss': 0.0199, 'grad_norm': 5.967038631439209, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.012632537633180618, 'loss_2': 0.00727081298828125, 'loss_3': -15.847992897033691, 'loss_4': 1.6212553977966309, 'epoch': 4.99}
{'loss': 0.0107, 'grad_norm': 6.985708713531494, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.00580859649926424, 'loss_2': 0.004894256591796875, 'loss_3': -16.021196365356445, 'loss_4': 0.353776216506958, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 09:45:26,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:26,742 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:41<1:13:13,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:45:34,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014607426710426807, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.636, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007054862566292286, 'eval_loss_2': 0.0075525641441345215, 'eval_loss_3': -18.11844253540039, 'eval_loss_4': 1.0197992324829102, 'epoch': 5.0}
{'loss': 0.0517, 'grad_norm': 21.28477668762207, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.05069238692522049, 'loss_2': 0.0009737014770507812, 'loss_3': -15.760480880737305, 'loss_4': 1.8057143688201904, 'epoch': 5.01}
{'loss': 0.0523, 'grad_norm': 16.384767532348633, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.04314953461289406, 'loss_2': 0.00911712646484375, 'loss_3': -15.924337387084961, 'loss_4': 1.3957322835922241, 'epoch': 5.01}
{'loss': 0.0373, 'grad_norm': 8.972756385803223, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.020185405388474464, 'loss_2': 0.017120361328125, 'loss_3': -15.872251510620117, 'loss_4': 0.2782987952232361, 'epoch': 5.02}
{'loss': 0.0265, 'grad_norm': 9.29155158996582, 'learning_rate': 2.5e-05, 'loss_1': 0.023766042664647102, 'loss_2': 0.00275421142578125, 'loss_3': -15.649002075195312, 'loss_4': 1.4447332620620728, 'epoch': 5.02}
{'loss': 0.0292, 'grad_norm': 12.003525733947754, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.02691490203142166, 'loss_2': 0.002292633056640625, 'loss_3': -15.896720886230469, 'loss_4': 0.831653356552124, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 09:45:34,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:34,134 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:45<1:13:13,  1.02s/it][INFO|trainer.py:3910] 2025-01-21 09:45:37,951 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865
[INFO|configuration_utils.py:420] 2025-01-21 09:45:37,952 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865/config.json                                                                              
{'eval_loss': 0.009557164274156094, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.318, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005883492063730955, 'eval_loss_2': 0.0036736726760864258, 'eval_loss_3': -18.10055160522461, 'eval_loss_4': 1.1257001161575317, 'epoch': 5.03}
[INFO|modeling_utils.py:2988] 2025-01-21 09:45:38,444 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:45:38,445 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:45:38,445 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:45:39,357 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-700] due to args.save_total_limit
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:50<1:21:42,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 09:45:42,984 >>
{'loss': 0.0193, 'grad_norm': 8.420099258422852, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.018522653728723526, 'loss_2': 0.0007987022399902344, 'loss_3': -15.787610054016113, 'loss_4': 1.045012354850769, 'epoch': 5.03}
{'loss': 0.0199, 'grad_norm': 7.322739124298096, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.01661134883761406, 'loss_2': 0.003330230712890625, 'loss_3': -15.862142562866211, 'loss_4': 1.3230844736099243, 'epoch': 5.04}
{'loss': 0.057, 'grad_norm': 17.72638511657715, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.05272091552615166, 'loss_2': 0.00432586669921875, 'loss_3': -15.624868392944336, 'loss_4': 1.569873332977295, 'epoch': 5.05}
{'loss': 0.0434, 'grad_norm': 22.60094451904297, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.030751079320907593, 'loss_2': 0.0126190185546875, 'loss_3': -15.874391555786133, 'loss_4': 2.3063998222351074, 'epoch': 5.05}
{'loss': 0.0222, 'grad_norm': 8.11242961883545, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.02052236534655094, 'loss_2': 0.0016918182373046875, 'loss_3': -15.822347640991211, 'loss_4': 1.4348304271697998, 'epoch': 5.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:45:42,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:42,984 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:57<1:15:16,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:45:50,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013757314532995224, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.869, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005754556506872177, 'eval_loss_2': 0.008002758026123047, 'eval_loss_3': -18.14109230041504, 'eval_loss_4': 1.1244378089904785, 'epoch': 5.06}
{'loss': 0.0183, 'grad_norm': 6.5614705085754395, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.01777251996099949, 'loss_2': 0.000537872314453125, 'loss_3': -15.759713172912598, 'loss_4': 1.248652696609497, 'epoch': 5.06}
{'loss': 0.0472, 'grad_norm': 13.181133270263672, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.03856206312775612, 'loss_2': 0.0086517333984375, 'loss_3': -15.741009712219238, 'loss_4': 1.3734495639801025, 'epoch': 5.07}
{'loss': 0.0365, 'grad_norm': 10.473484992980957, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.028419004753232002, 'loss_2': 0.008056640625, 'loss_3': -15.867137908935547, 'loss_4': 1.5749163627624512, 'epoch': 5.08}
{'loss': 0.0268, 'grad_norm': 7.965424537658691, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.01523264218121767, 'loss_2': 0.0115203857421875, 'loss_3': -15.90056037902832, 'loss_4': 1.2706058025360107, 'epoch': 5.08}
{'loss': 0.0347, 'grad_norm': 9.767516136169434, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.022030524909496307, 'loss_2': 0.01264190673828125, 'loss_3': -15.982025146484375, 'loss_4': 1.8565407991409302, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 09:45:50,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:50,329 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:04<1:14:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:45:57,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0175195150077343, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007583661936223507, 'eval_loss_2': 0.009935855865478516, 'eval_loss_3': -18.15511703491211, 'eval_loss_4': 1.378739833831787, 'epoch': 5.09}
{'loss': 0.0242, 'grad_norm': 5.330018520355225, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.012942799367010593, 'loss_2': 0.01129150390625, 'loss_3': -15.894229888916016, 'loss_4': 1.2676482200622559, 'epoch': 5.09}
{'loss': 0.0182, 'grad_norm': 6.8234453201293945, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.010517498478293419, 'loss_2': 0.0077056884765625, 'loss_3': -15.834574699401855, 'loss_4': 1.7443828582763672, 'epoch': 5.1}
{'loss': 0.1067, 'grad_norm': 18.3680477142334, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.09872972965240479, 'loss_2': 0.00799560546875, 'loss_3': -15.62060832977295, 'loss_4': 1.3178341388702393, 'epoch': 5.1}
{'loss': 0.0136, 'grad_norm': 6.922635078430176, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.013476916588842869, 'loss_2': 0.0001590251922607422, 'loss_3': -15.949140548706055, 'loss_4': 1.4430437088012695, 'epoch': 5.11}
{'loss': 0.0099, 'grad_norm': 5.282991886138916, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.009227240458130836, 'loss_2': 0.0006694793701171875, 'loss_3': -15.921823501586914, 'loss_4': 1.4241752624511719, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 09:45:57,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:45:57,672 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:12<1:14:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:05,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015136470086872578, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.266, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007484187372028828, 'eval_loss_2': 0.00765228271484375, 'eval_loss_3': -18.173736572265625, 'eval_loss_4': 1.389772653579712, 'epoch': 5.12}
{'loss': 0.0415, 'grad_norm': 11.133604049682617, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.034632641822099686, 'loss_2': 0.0068817138671875, 'loss_3': -15.8189697265625, 'loss_4': 1.5401127338409424, 'epoch': 5.12}
{'loss': 0.0541, 'grad_norm': 11.910979270935059, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.0378325954079628, 'loss_2': 0.01629638671875, 'loss_3': -15.898051261901855, 'loss_4': 1.730679988861084, 'epoch': 5.13}
{'loss': 0.0357, 'grad_norm': 5.797508716583252, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.01831076480448246, 'loss_2': 0.017425537109375, 'loss_3': -15.76654052734375, 'loss_4': 1.6465098857879639, 'epoch': 5.13}
{'loss': 0.0503, 'grad_norm': 13.655000686645508, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.03889160603284836, 'loss_2': 0.01140594482421875, 'loss_3': -15.949588775634766, 'loss_4': 2.1330718994140625, 'epoch': 5.14}
{'loss': 0.0438, 'grad_norm': 11.9607572555542, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.025527285411953926, 'loss_2': 0.018280029296875, 'loss_3': -15.926721572875977, 'loss_4': 1.372943639755249, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 09:46:05,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:05,033 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:19<1:13:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:12,390 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017693914473056793, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.843, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008072890341281891, 'eval_loss_2': 0.009621024131774902, 'eval_loss_3': -18.169116973876953, 'eval_loss_4': 1.3473923206329346, 'epoch': 5.15}
{'loss': 0.0266, 'grad_norm': 7.2363715171813965, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.017963958904147148, 'loss_2': 0.0085906982421875, 'loss_3': -16.014022827148438, 'loss_4': 1.3401281833648682, 'epoch': 5.15}
{'loss': 0.0647, 'grad_norm': 18.27824592590332, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.04891164228320122, 'loss_2': 0.015777587890625, 'loss_3': -15.97929859161377, 'loss_4': 1.9944472312927246, 'epoch': 5.16}
{'loss': 0.0341, 'grad_norm': 8.04469108581543, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.025318846106529236, 'loss_2': 0.00881195068359375, 'loss_3': -15.693414688110352, 'loss_4': 1.7698109149932861, 'epoch': 5.16}
{'loss': 0.0359, 'grad_norm': 10.806096076965332, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.03221071884036064, 'loss_2': 0.003692626953125, 'loss_3': -16.149919509887695, 'loss_4': 1.6624069213867188, 'epoch': 5.17}
{'loss': 0.037, 'grad_norm': 5.984853267669678, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.018331944942474365, 'loss_2': 0.0186614990234375, 'loss_3': -15.790388107299805, 'loss_4': 0.5726683139801025, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 09:46:12,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:12,390 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:26<1:13:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:19,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014066088013350964, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.849, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009264962747693062, 'eval_loss_2': 0.004801124334335327, 'eval_loss_3': -18.21258544921875, 'eval_loss_4': 0.9861777424812317, 'epoch': 5.17}
{'loss': 0.0357, 'grad_norm': 10.961960792541504, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.02914360538125038, 'loss_2': 0.0065460205078125, 'loss_3': -16.03449058532715, 'loss_4': 0.8730151653289795, 'epoch': 5.18}
{'loss': 0.0449, 'grad_norm': 13.26977825164795, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.03457901254296303, 'loss_2': 0.01033782958984375, 'loss_3': -15.968404769897461, 'loss_4': 1.2004621028900146, 'epoch': 5.19}
{'loss': 0.0275, 'grad_norm': 7.588244915008545, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.019359515979886055, 'loss_2': 0.0081787109375, 'loss_3': -16.05804443359375, 'loss_4': 0.7201520800590515, 'epoch': 5.19}
{'loss': 0.0213, 'grad_norm': 5.1628875732421875, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.013163850642740726, 'loss_2': 0.00811004638671875, 'loss_3': -16.182050704956055, 'loss_4': 0.809506893157959, 'epoch': 5.2}
{'loss': 0.0219, 'grad_norm': 9.920538902282715, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.021827803924679756, 'loss_2': 7.271766662597656e-05, 'loss_3': -16.00565528869629, 'loss_4': 0.4406554400920868, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 09:46:19,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:19,733 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:34<1:13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:27,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01247052475810051, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00913284346461296, 'eval_loss_2': 0.003337681293487549, 'eval_loss_3': -18.227529525756836, 'eval_loss_4': 0.9094513058662415, 'epoch': 5.2}
{'loss': 0.0459, 'grad_norm': 13.54180908203125, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.03533698245882988, 'loss_2': 0.01053619384765625, 'loss_3': -16.011051177978516, 'loss_4': 1.1962332725524902, 'epoch': 5.21}
{'loss': 0.1686, 'grad_norm': 30.11934471130371, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.16598309576511383, 'loss_2': 0.002597808837890625, 'loss_3': -15.80617618560791, 'loss_4': 1.5997834205627441, 'epoch': 5.22}
{'loss': 0.023, 'grad_norm': 7.394967079162598, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.021489912644028664, 'loss_2': 0.00150299072265625, 'loss_3': -16.035083770751953, 'loss_4': 1.3828868865966797, 'epoch': 5.22}
{'loss': 0.0514, 'grad_norm': 14.37476634979248, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.047937389463186264, 'loss_2': 0.0034961700439453125, 'loss_3': -15.93110179901123, 'loss_4': 0.9646636247634888, 'epoch': 5.23}
{'loss': 0.0585, 'grad_norm': 14.316781044006348, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.05310477316379547, 'loss_2': 0.00539398193359375, 'loss_3': -16.023021697998047, 'loss_4': 1.036939263343811, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 09:46:27,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:27,079 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:41<1:13:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:34,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012399770319461823, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.035, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009063339792191982, 'eval_loss_2': 0.0033364295959472656, 'eval_loss_3': -18.233373641967773, 'eval_loss_4': 0.9738453030586243, 'epoch': 5.23}
{'loss': 0.0181, 'grad_norm': 7.389195919036865, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.0172111839056015, 'loss_2': 0.0008535385131835938, 'loss_3': -15.856958389282227, 'loss_4': 1.4578406810760498, 'epoch': 5.24}
{'loss': 0.0711, 'grad_norm': 19.788450241088867, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.06796853244304657, 'loss_2': 0.0031070709228515625, 'loss_3': -16.033702850341797, 'loss_4': 1.4699769020080566, 'epoch': 5.24}
{'loss': 0.0169, 'grad_norm': 5.031109809875488, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.011825601570308208, 'loss_2': 0.00507354736328125, 'loss_3': -16.10491943359375, 'loss_4': 1.328345775604248, 'epoch': 5.25}
{'loss': 0.0464, 'grad_norm': 18.070938110351562, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.04185064882040024, 'loss_2': 0.0045928955078125, 'loss_3': -16.013751983642578, 'loss_4': 1.6372106075286865, 'epoch': 5.26}
{'loss': 0.0609, 'grad_norm': 12.86745834350586, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.05785528942942619, 'loss_2': 0.003021240234375, 'loss_3': -15.938007354736328, 'loss_4': 0.999814510345459, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 09:46:34,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:34,418 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:48<1:13:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:41,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011410918086767197, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.45, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007564973086118698, 'eval_loss_2': 0.0038459450006484985, 'eval_loss_3': -18.222972869873047, 'eval_loss_4': 1.0560400485992432, 'epoch': 5.26}
{'loss': 0.0438, 'grad_norm': 8.426340103149414, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.03373512998223305, 'loss_2': 0.01003265380859375, 'loss_3': -15.971324920654297, 'loss_4': 0.7409787774085999, 'epoch': 5.27}
{'loss': 0.0542, 'grad_norm': 12.758700370788574, 'learning_rate': 2.475e-05, 'loss_1': 0.04985336586833, 'loss_2': 0.004314422607421875, 'loss_3': -16.076061248779297, 'loss_4': 0.9599002599716187, 'epoch': 5.27}
{'loss': 0.0302, 'grad_norm': 8.54912281036377, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.023775571957230568, 'loss_2': 0.0063934326171875, 'loss_3': -15.882941246032715, 'loss_4': 1.4873721599578857, 'epoch': 5.28}
{'loss': 0.0338, 'grad_norm': 11.135419845581055, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.030360497534275055, 'loss_2': 0.0034637451171875, 'loss_3': -15.891130447387695, 'loss_4': 1.1971759796142578, 'epoch': 5.28}
{'loss': 0.0154, 'grad_norm': 5.969589710235596, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.01279288250952959, 'loss_2': 0.00261688232421875, 'loss_3': -15.872106552124023, 'loss_4': 1.054250717163086, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 09:46:41,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:41,774 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:56<1:13:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:49,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010736390016973019, 'eval_runtime': 3.8341, 'eval_samples_per_second': 267.079, 'eval_steps_per_second': 4.173, 'eval_loss_1': 0.0074119409546256065, 'eval_loss_2': 0.003324449062347412, 'eval_loss_3': -18.173416137695312, 'eval_loss_4': 1.2692209482192993, 'epoch': 5.29}
{'loss': 0.0286, 'grad_norm': 8.351700782775879, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.02008647844195366, 'loss_2': 0.008514404296875, 'loss_3': -15.763049125671387, 'loss_4': 1.645484447479248, 'epoch': 5.3}
{'loss': 0.0444, 'grad_norm': 10.73229694366455, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.03325768932700157, 'loss_2': 0.01114654541015625, 'loss_3': -15.599189758300781, 'loss_4': 1.1805295944213867, 'epoch': 5.3}
{'loss': 0.0214, 'grad_norm': 10.089431762695312, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.02029670588672161, 'loss_2': 0.001071929931640625, 'loss_3': -15.901693344116211, 'loss_4': 1.7398641109466553, 'epoch': 5.31}
{'loss': 0.033, 'grad_norm': 10.856078147888184, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.022390324622392654, 'loss_2': 0.0106048583984375, 'loss_3': -16.022693634033203, 'loss_4': 1.7370973825454712, 'epoch': 5.31}
{'loss': 0.021, 'grad_norm': 7.693779945373535, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.01889130473136902, 'loss_2': 0.0020999908447265625, 'loss_3': -15.939309120178223, 'loss_4': 1.6298880577087402, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 09:46:49,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:49,150 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:03<1:13:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:46:56,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01489226520061493, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.712, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009886607527732849, 'eval_loss_2': 0.00500565767288208, 'eval_loss_3': -18.10310935974121, 'eval_loss_4': 1.7323639392852783, 'epoch': 5.32}
{'loss': 0.0291, 'grad_norm': 9.420748710632324, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.02274661511182785, 'loss_2': 0.00638580322265625, 'loss_3': -15.938876152038574, 'loss_4': 1.954824447631836, 'epoch': 5.33}
{'loss': 0.0344, 'grad_norm': 32.56306076049805, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.033273693174123764, 'loss_2': 0.00109100341796875, 'loss_3': -15.832746505737305, 'loss_4': 2.52181077003479, 'epoch': 5.33}
{'loss': 0.0177, 'grad_norm': 7.423475742340088, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.01705486699938774, 'loss_2': 0.0006570816040039062, 'loss_3': -15.862468719482422, 'loss_4': 2.7589926719665527, 'epoch': 5.34}
{'loss': 0.0272, 'grad_norm': 8.608838081359863, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.021093565970659256, 'loss_2': 0.006114959716796875, 'loss_3': -15.725038528442383, 'loss_4': 1.8825839757919312, 'epoch': 5.34}
{'loss': 0.0255, 'grad_norm': 8.680488586425781, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.019541416317224503, 'loss_2': 0.005954742431640625, 'loss_3': -15.682896614074707, 'loss_4': 2.093564748764038, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 09:46:56,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:46:56,504 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:11<1:13:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:03,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010853340849280357, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.761, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007211638148874044, 'eval_loss_2': 0.0036417022347450256, 'eval_loss_3': -18.129716873168945, 'eval_loss_4': 2.441723346710205, 'epoch': 5.35}
{'loss': 0.0351, 'grad_norm': 14.288180351257324, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.02962222881615162, 'loss_2': 0.005474090576171875, 'loss_3': -15.884645462036133, 'loss_4': 3.1486783027648926, 'epoch': 5.35}
{'loss': 0.0363, 'grad_norm': 10.97777271270752, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.027670690789818764, 'loss_2': 0.00867462158203125, 'loss_3': -15.813982009887695, 'loss_4': 2.4421684741973877, 'epoch': 5.36}
{'loss': 0.0174, 'grad_norm': 7.103808879852295, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.015379257500171661, 'loss_2': 0.0020542144775390625, 'loss_3': -15.678946495056152, 'loss_4': 3.3341429233551025, 'epoch': 5.37}
{'loss': 0.016, 'grad_norm': 9.019886016845703, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.014791104011237621, 'loss_2': 0.0012569427490234375, 'loss_3': -15.907024383544922, 'loss_4': 3.0940191745758057, 'epoch': 5.37}
{'loss': 0.0318, 'grad_norm': 9.901854515075684, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.02460426464676857, 'loss_2': 0.0072021484375, 'loss_3': -15.921468734741211, 'loss_4': 2.829335927963257, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 09:47:03,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:03,857 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:18<1:13:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:11,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01413817424327135, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.589, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00711668748408556, 'eval_loss_2': 0.007021486759185791, 'eval_loss_3': -18.150421142578125, 'eval_loss_4': 2.774350881576538, 'epoch': 5.38}
{'loss': 0.023, 'grad_norm': 6.2886962890625, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.014464611187577248, 'loss_2': 0.008575439453125, 'loss_3': -15.85415267944336, 'loss_4': 3.079697847366333, 'epoch': 5.38}
{'loss': 0.0332, 'grad_norm': 9.059734344482422, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.028129739686846733, 'loss_2': 0.00511932373046875, 'loss_3': -15.784525871276855, 'loss_4': 3.396496295928955, 'epoch': 5.39}
{'loss': 0.0159, 'grad_norm': 9.052688598632812, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.013498611748218536, 'loss_2': 0.0023860931396484375, 'loss_3': -15.74046516418457, 'loss_4': 3.6170401573181152, 'epoch': 5.4}
{'loss': 0.0402, 'grad_norm': 8.711315155029297, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.030376680195331573, 'loss_2': 0.00986480712890625, 'loss_3': -15.89797592163086, 'loss_4': 2.490536689758301, 'epoch': 5.4}
{'loss': 0.0278, 'grad_norm': 8.182729721069336, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.026284735649824142, 'loss_2': 0.001514434814453125, 'loss_3': -15.768333435058594, 'loss_4': 4.284360408782959, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 09:47:11,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:11,214 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:25<1:13:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:18,571 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01206144504249096, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.619, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008631294593214989, 'eval_loss_2': 0.0034301504492759705, 'eval_loss_3': -18.130355834960938, 'eval_loss_4': 2.897305965423584, 'epoch': 5.41}
{'loss': 0.0167, 'grad_norm': 6.6016459465026855, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.015460164286196232, 'loss_2': 0.0011930465698242188, 'loss_3': -15.738397598266602, 'loss_4': 2.737136125564575, 'epoch': 5.41}
{'loss': 0.0171, 'grad_norm': 7.779432773590088, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.016457080841064453, 'loss_2': 0.0006322860717773438, 'loss_3': -15.737055778503418, 'loss_4': 3.6995463371276855, 'epoch': 5.42}
{'loss': 0.0385, 'grad_norm': 11.694574356079102, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.03312600776553154, 'loss_2': 0.00539398193359375, 'loss_3': -15.882919311523438, 'loss_4': 2.6122679710388184, 'epoch': 5.42}
{'loss': 0.0217, 'grad_norm': 7.740416526794434, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.017214562743902206, 'loss_2': 0.004486083984375, 'loss_3': -15.703410148620605, 'loss_4': 3.4401228427886963, 'epoch': 5.43}
{'loss': 0.03, 'grad_norm': 13.10365104675293, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.029846439138054848, 'loss_2': 0.00015401840209960938, 'loss_3': -15.551713943481445, 'loss_4': 3.163255214691162, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 09:47:18,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:18,571 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:33<1:13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:25,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012199785560369492, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.505, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008632089011371136, 'eval_loss_2': 0.0035676956176757812, 'eval_loss_3': -18.116750717163086, 'eval_loss_4': 3.01228666305542, 'epoch': 5.44}
{'loss': 0.0343, 'grad_norm': 14.945878982543945, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.028346111997961998, 'loss_2': 0.005931854248046875, 'loss_3': -15.44352912902832, 'loss_4': 3.070435047149658, 'epoch': 5.44}
{'loss': 0.0227, 'grad_norm': 6.789373874664307, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.016338543966412544, 'loss_2': 0.006351470947265625, 'loss_3': -15.886991500854492, 'loss_4': 3.4609217643737793, 'epoch': 5.45}
{'loss': 0.0806, 'grad_norm': 22.548690795898438, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.07695476710796356, 'loss_2': 0.0036296844482421875, 'loss_3': -15.57944107055664, 'loss_4': 3.162153720855713, 'epoch': 5.45}
{'loss': 0.0606, 'grad_norm': 17.50874900817871, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.05494682490825653, 'loss_2': 0.005641937255859375, 'loss_3': -15.938484191894531, 'loss_4': 2.833569288253784, 'epoch': 5.46}
{'loss': 0.0218, 'grad_norm': 5.891684532165527, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.01362023688852787, 'loss_2': 0.008148193359375, 'loss_3': -15.949585914611816, 'loss_4': 3.316882610321045, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 09:47:25,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:25,935 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:40<1:13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:33,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012783541344106197, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.07, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.008358791470527649, 'eval_loss_2': 0.004424750804901123, 'eval_loss_3': -18.092586517333984, 'eval_loss_4': 2.6791839599609375, 'epoch': 5.47}
{'loss': 0.0317, 'grad_norm': 9.892494201660156, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.024126863107085228, 'loss_2': 0.00756072998046875, 'loss_3': -15.518667221069336, 'loss_4': 3.080375909805298, 'epoch': 5.47}
{'loss': 0.0155, 'grad_norm': 6.054861545562744, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.009869752451777458, 'loss_2': 0.005626678466796875, 'loss_3': -15.74899959564209, 'loss_4': 3.2335264682769775, 'epoch': 5.48}
{'loss': 0.0318, 'grad_norm': 12.89180850982666, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.026081673800945282, 'loss_2': 0.00566864013671875, 'loss_3': -15.822874069213867, 'loss_4': 2.5609586238861084, 'epoch': 5.48}
{'loss': 0.0236, 'grad_norm': 9.69684886932373, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.023432612419128418, 'loss_2': 0.00011980533599853516, 'loss_3': -15.961841583251953, 'loss_4': 2.959460973739624, 'epoch': 5.49}
{'loss': 0.027, 'grad_norm': 9.829187393188477, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.020655009895563126, 'loss_2': 0.00635528564453125, 'loss_3': -15.701706886291504, 'loss_4': 3.171668291091919, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 09:47:33,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:33,308 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:47<1:12:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:40,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014959119260311127, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010279230773448944, 'eval_loss_2': 0.004679888486862183, 'eval_loss_3': -18.087865829467773, 'eval_loss_4': 2.271728515625, 'epoch': 5.49}
{'loss': 0.0392, 'grad_norm': 12.598666191101074, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.03785613924264908, 'loss_2': 0.0013408660888671875, 'loss_3': -15.772004127502441, 'loss_4': 3.07673978805542, 'epoch': 5.5}
{'loss': 0.0219, 'grad_norm': 7.930081844329834, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.01697699911892414, 'loss_2': 0.00487518310546875, 'loss_3': -15.78783130645752, 'loss_4': 2.5864293575286865, 'epoch': 5.51}
{'loss': 0.0275, 'grad_norm': 9.063314437866211, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.023037845268845558, 'loss_2': 0.0044708251953125, 'loss_3': -15.66845703125, 'loss_4': 3.0005552768707275, 'epoch': 5.51}
{'loss': 0.0178, 'grad_norm': 8.27572250366211, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.016671860590577126, 'loss_2': 0.001155853271484375, 'loss_3': -15.730328559875488, 'loss_4': 2.723855495452881, 'epoch': 5.52}
{'loss': 0.0329, 'grad_norm': 12.206409454345703, 'learning_rate': 2.45e-05, 'loss_1': 0.031186694279313087, 'loss_2': 0.00170135498046875, 'loss_3': -15.698467254638672, 'loss_4': 2.7629127502441406, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 09:47:40,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:40,671 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:55<1:12:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:48,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01622111350297928, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.671, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010882860980927944, 'eval_loss_2': 0.00533825159072876, 'eval_loss_3': -18.098369598388672, 'eval_loss_4': 2.0145673751831055, 'epoch': 5.52}
{'loss': 0.0407, 'grad_norm': 10.44421100616455, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.03672749176621437, 'loss_2': 0.0040130615234375, 'loss_3': -15.638784408569336, 'loss_4': 3.323155641555786, 'epoch': 5.53}
{'loss': 0.0243, 'grad_norm': 6.742944717407227, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.015733418986201286, 'loss_2': 0.00859832763671875, 'loss_3': -15.628499984741211, 'loss_4': 1.8013758659362793, 'epoch': 5.53}
{'loss': 0.0573, 'grad_norm': 16.51202392578125, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.04646994546055794, 'loss_2': 0.01079559326171875, 'loss_3': -15.525346755981445, 'loss_4': 2.204969644546509, 'epoch': 5.54}
{'loss': 0.0219, 'grad_norm': 5.882715225219727, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.010631709359586239, 'loss_2': 0.01128387451171875, 'loss_3': -16.036413192749023, 'loss_4': 2.5049445629119873, 'epoch': 5.55}
{'loss': 0.023, 'grad_norm': 7.663225173950195, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.017683176323771477, 'loss_2': 0.00530242919921875, 'loss_3': -15.93814468383789, 'loss_4': 2.474010944366455, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 09:47:48,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:48,025 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:02<1:12:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:47:55,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014671850018203259, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01071585901081562, 'eval_loss_2': 0.0039559900760650635, 'eval_loss_3': -18.10691261291504, 'eval_loss_4': 1.880444884300232, 'epoch': 5.55}
{'loss': 0.0151, 'grad_norm': 5.127788066864014, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.008861128240823746, 'loss_2': 0.0062408447265625, 'loss_3': -15.72581672668457, 'loss_4': 2.0740981101989746, 'epoch': 5.56}
{'loss': 0.0134, 'grad_norm': 5.461676597595215, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.010652676224708557, 'loss_2': 0.002727508544921875, 'loss_3': -16.084243774414062, 'loss_4': 2.1619880199432373, 'epoch': 5.56}
{'loss': 0.025, 'grad_norm': 8.041218757629395, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.01571143977344036, 'loss_2': 0.00933074951171875, 'loss_3': -15.686332702636719, 'loss_4': 1.7862783670425415, 'epoch': 5.57}
{'loss': 0.0186, 'grad_norm': 6.748978614807129, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.010303555056452751, 'loss_2': 0.0082855224609375, 'loss_3': -15.889328002929688, 'loss_4': 1.898197054862976, 'epoch': 5.58}
{'loss': 0.0226, 'grad_norm': 8.306201934814453, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.01971472054719925, 'loss_2': 0.002880096435546875, 'loss_3': -15.68074893951416, 'loss_4': 1.9381206035614014, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 09:47:55,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:47:55,376 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:09<1:12:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:02,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0210784412920475, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.78, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011191223748028278, 'eval_loss_2': 0.009887218475341797, 'eval_loss_3': -18.093626022338867, 'eval_loss_4': 1.8585431575775146, 'epoch': 5.58}
{'loss': 0.0143, 'grad_norm': 5.391821384429932, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.007144529838114977, 'loss_2': 0.007190704345703125, 'loss_3': -16.044597625732422, 'loss_4': 2.7719266414642334, 'epoch': 5.59}
{'loss': 0.0196, 'grad_norm': 5.752978324890137, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.00840037316083908, 'loss_2': 0.011199951171875, 'loss_3': -15.890050888061523, 'loss_4': 1.5476590394973755, 'epoch': 5.59}
{'loss': 0.0508, 'grad_norm': 20.645755767822266, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.040774792432785034, 'loss_2': 0.01004791259765625, 'loss_3': -15.876041412353516, 'loss_4': 2.181074857711792, 'epoch': 5.6}
{'loss': 0.0278, 'grad_norm': 7.682422161102295, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.02249975875020027, 'loss_2': 0.005344390869140625, 'loss_3': -15.839326858520508, 'loss_4': 1.6297988891601562, 'epoch': 5.6}
{'loss': 0.0151, 'grad_norm': 10.109939575195312, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.014910631813108921, 'loss_2': 0.0001919269561767578, 'loss_3': -15.9441556930542, 'loss_4': 1.7603708505630493, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 09:48:02,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:02,726 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:17<1:12:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:10,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01591506227850914, 'eval_runtime': 3.8217, 'eval_samples_per_second': 267.942, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.01356976293027401, 'eval_loss_2': 0.0023453012108802795, 'eval_loss_3': -18.070478439331055, 'eval_loss_4': 1.8131003379821777, 'epoch': 5.61}
{'loss': 0.0506, 'grad_norm': 22.088197708129883, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.038868196308612823, 'loss_2': 0.01171875, 'loss_3': -15.9630126953125, 'loss_4': 1.7919683456420898, 'epoch': 5.62}
{'loss': 0.0227, 'grad_norm': 10.07042121887207, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.016479967162013054, 'loss_2': 0.00621795654296875, 'loss_3': -15.778507232666016, 'loss_4': 2.161393642425537, 'epoch': 5.62}
{'loss': 0.0165, 'grad_norm': 8.247819900512695, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.0157038401812315, 'loss_2': 0.0008335113525390625, 'loss_3': -15.795197486877441, 'loss_4': 1.6046245098114014, 'epoch': 5.63}
{'loss': 0.0198, 'grad_norm': 7.41422700881958, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.017635544762015343, 'loss_2': 0.002147674560546875, 'loss_3': -15.930976867675781, 'loss_4': 1.7672725915908813, 'epoch': 5.63}
{'loss': 0.0407, 'grad_norm': 12.663310050964355, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.03984292224049568, 'loss_2': 0.0008597373962402344, 'loss_3': -15.863540649414062, 'loss_4': 2.0693018436431885, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 09:48:10,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:10,084 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:24<1:12:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:17,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017563506960868835, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.77, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011960312724113464, 'eval_loss_2': 0.005603194236755371, 'eval_loss_3': -18.093505859375, 'eval_loss_4': 2.133288621902466, 'epoch': 5.64}
{'loss': 0.0547, 'grad_norm': 15.647120475769043, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.04470747336745262, 'loss_2': 0.009979248046875, 'loss_3': -15.55470085144043, 'loss_4': 2.499960422515869, 'epoch': 5.65}
{'loss': 0.0278, 'grad_norm': 9.022992134094238, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.025807717815041542, 'loss_2': 0.002040863037109375, 'loss_3': -15.676532745361328, 'loss_4': 2.876770496368408, 'epoch': 5.65}
{'loss': 0.0141, 'grad_norm': 6.091088771820068, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.012429575435817242, 'loss_2': 0.0016422271728515625, 'loss_3': -16.173500061035156, 'loss_4': 2.154144287109375, 'epoch': 5.66}
{'loss': 0.016, 'grad_norm': 5.3904805183410645, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.0075654396787285805, 'loss_2': 0.0084075927734375, 'loss_3': -15.784923553466797, 'loss_4': 1.9901387691497803, 'epoch': 5.66}
{'loss': 0.0378, 'grad_norm': 14.900054931640625, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.03419101983308792, 'loss_2': 0.0036144256591796875, 'loss_3': -15.520967483520508, 'loss_4': 2.650111198425293, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 09:48:17,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:17,436 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:32<1:12:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:24,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013856818899512291, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.905, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01046957541257143, 'eval_loss_2': 0.003387242555618286, 'eval_loss_3': -18.14995574951172, 'eval_loss_4': 2.4629881381988525, 'epoch': 5.67}
{'loss': 0.0278, 'grad_norm': 13.037914276123047, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.024797461926937103, 'loss_2': 0.00295257568359375, 'loss_3': -15.82361888885498, 'loss_4': 2.8650264739990234, 'epoch': 5.67}
{'loss': 0.0174, 'grad_norm': 6.655202865600586, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.01236916147172451, 'loss_2': 0.004985809326171875, 'loss_3': -15.96010684967041, 'loss_4': 2.2500197887420654, 'epoch': 5.68}
{'loss': 0.0367, 'grad_norm': 11.089061737060547, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.024102477356791496, 'loss_2': 0.0125885009765625, 'loss_3': -15.776140213012695, 'loss_4': 2.3420002460479736, 'epoch': 5.69}
{'loss': 0.0326, 'grad_norm': 9.969066619873047, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.022777607664465904, 'loss_2': 0.00984954833984375, 'loss_3': -15.894457817077637, 'loss_4': 2.6670374870300293, 'epoch': 5.69}
{'loss': 0.0244, 'grad_norm': 7.746638298034668, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.015791868790984154, 'loss_2': 0.0085601806640625, 'loss_3': -15.868476867675781, 'loss_4': 2.6367685794830322, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 09:48:24,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:24,792 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:39<1:13:15,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:48:32,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021535392850637436, 'eval_runtime': 3.9914, 'eval_samples_per_second': 256.551, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.012042280286550522, 'eval_loss_2': 0.009493112564086914, 'eval_loss_3': -18.21402931213379, 'eval_loss_4': 2.5196638107299805, 'epoch': 5.7}
{'loss': 0.0179, 'grad_norm': 6.725175857543945, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.016542958095669746, 'loss_2': 0.0013475418090820312, 'loss_3': -15.990809440612793, 'loss_4': 2.9155185222625732, 'epoch': 5.7}
{'loss': 0.0408, 'grad_norm': 13.176295280456543, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.03115851804614067, 'loss_2': 0.009613037109375, 'loss_3': -16.037202835083008, 'loss_4': 2.8955137729644775, 'epoch': 5.71}
{'loss': 0.0294, 'grad_norm': 9.963287353515625, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.01967909373342991, 'loss_2': 0.0097503662109375, 'loss_3': -15.836871147155762, 'loss_4': 3.015878677368164, 'epoch': 5.72}
{'loss': 0.0252, 'grad_norm': 8.437255859375, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.021899795159697533, 'loss_2': 0.003284454345703125, 'loss_3': -16.13274383544922, 'loss_4': 3.7951653003692627, 'epoch': 5.72}
{'loss': 0.0283, 'grad_norm': 8.26398754119873, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.0252888984978199, 'loss_2': 0.003040313720703125, 'loss_3': -15.874537467956543, 'loss_4': 3.64850115776062, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 09:48:32,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:32,334 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:46<1:12:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:39,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018466152250766754, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.914, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015391445718705654, 'eval_loss_2': 0.0030747056007385254, 'eval_loss_3': -18.24905776977539, 'eval_loss_4': 3.228097915649414, 'epoch': 5.73}
{'loss': 0.0202, 'grad_norm': 7.493285179138184, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.019304102286696434, 'loss_2': 0.0009307861328125, 'loss_3': -15.923664093017578, 'loss_4': 3.815584659576416, 'epoch': 5.73}
{'loss': 0.0404, 'grad_norm': 12.385798454284668, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.03218210116028786, 'loss_2': 0.00821685791015625, 'loss_3': -15.879039764404297, 'loss_4': 4.329198360443115, 'epoch': 5.74}
{'loss': 0.015, 'grad_norm': 5.134613513946533, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.012817599810659885, 'loss_2': 0.0021724700927734375, 'loss_3': -15.923660278320312, 'loss_4': 3.7454633712768555, 'epoch': 5.74}
{'loss': 0.0254, 'grad_norm': 7.863379001617432, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.0198795385658741, 'loss_2': 0.00550079345703125, 'loss_3': -15.937023162841797, 'loss_4': 3.72274112701416, 'epoch': 5.75}
{'loss': 0.0225, 'grad_norm': 7.881414890289307, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.021655233576893806, 'loss_2': 0.0008258819580078125, 'loss_3': -15.778807640075684, 'loss_4': 3.9523773193359375, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 09:48:39,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:39,688 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:54<1:12:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:47,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01856571063399315, 'eval_runtime': 3.8222, 'eval_samples_per_second': 267.906, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.01379313599318266, 'eval_loss_2': 0.004772573709487915, 'eval_loss_3': -18.240474700927734, 'eval_loss_4': 3.2306783199310303, 'epoch': 5.76}
{'loss': 0.0588, 'grad_norm': 23.585594177246094, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.056847501546144485, 'loss_2': 0.0019054412841796875, 'loss_3': -15.808609008789062, 'loss_4': 3.672628402709961, 'epoch': 5.76}
{'loss': 0.0158, 'grad_norm': 5.832155704498291, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.012450178153812885, 'loss_2': 0.0033931732177734375, 'loss_3': -16.07721710205078, 'loss_4': 3.281285524368286, 'epoch': 5.77}
{'loss': 0.0226, 'grad_norm': 9.494743347167969, 'learning_rate': 2.425e-05, 'loss_1': 0.017857201397418976, 'loss_2': 0.00478363037109375, 'loss_3': -15.89507007598877, 'loss_4': 3.136754035949707, 'epoch': 5.77}
{'loss': 0.0146, 'grad_norm': 6.993692874908447, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.01212223805487156, 'loss_2': 0.0024623870849609375, 'loss_3': -16.156339645385742, 'loss_4': 3.2900612354278564, 'epoch': 5.78}
{'loss': 0.034, 'grad_norm': 10.676969528198242, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.02605064958333969, 'loss_2': 0.0079498291015625, 'loss_3': -16.01263427734375, 'loss_4': 3.806044578552246, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 09:48:47,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:47,060 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:01<1:12:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:48:54,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015885375440120697, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011634609661996365, 'eval_loss_2': 0.004250764846801758, 'eval_loss_3': -18.260578155517578, 'eval_loss_4': 2.814159631729126, 'epoch': 5.78}
{'loss': 0.0194, 'grad_norm': 6.721039772033691, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.017087943851947784, 'loss_2': 0.00228118896484375, 'loss_3': -15.957490921020508, 'loss_4': 3.3041634559631348, 'epoch': 5.79}
{'loss': 0.0265, 'grad_norm': 8.750024795532227, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.020647455006837845, 'loss_2': 0.005889892578125, 'loss_3': -15.86324691772461, 'loss_4': 2.6839370727539062, 'epoch': 5.8}
{'loss': 0.0183, 'grad_norm': 5.68717098236084, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.010484945960342884, 'loss_2': 0.00778961181640625, 'loss_3': -15.87767219543457, 'loss_4': 2.786477565765381, 'epoch': 5.8}
{'loss': 0.0241, 'grad_norm': 8.309667587280273, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.015491644851863384, 'loss_2': 0.00861358642578125, 'loss_3': -16.098793029785156, 'loss_4': 2.1150994300842285, 'epoch': 5.81}
{'loss': 0.0253, 'grad_norm': 7.162097930908203, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.019786085933446884, 'loss_2': 0.00556182861328125, 'loss_3': -15.945804595947266, 'loss_4': 2.536562919616699, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 09:48:54,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:48:54,414 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:08<1:11:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:01,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015139665454626083, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0114828459918499, 'eval_loss_2': 0.003656819462776184, 'eval_loss_3': -18.236427307128906, 'eval_loss_4': 2.3552756309509277, 'epoch': 5.81}
{'loss': 0.0345, 'grad_norm': 9.876738548278809, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.03040686622262001, 'loss_2': 0.00405120849609375, 'loss_3': -15.997434616088867, 'loss_4': 2.2462263107299805, 'epoch': 5.82}
{'loss': 0.0523, 'grad_norm': 17.905357360839844, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.050987716764211655, 'loss_2': 0.0012664794921875, 'loss_3': -15.804262161254883, 'loss_4': 2.1756763458251953, 'epoch': 5.83}
{'loss': 0.0365, 'grad_norm': 21.716642379760742, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.03337416425347328, 'loss_2': 0.0031585693359375, 'loss_3': -15.746423721313477, 'loss_4': 2.230417013168335, 'epoch': 5.83}
{'loss': 0.0206, 'grad_norm': 7.73542594909668, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.01424789521843195, 'loss_2': 0.00637054443359375, 'loss_3': -16.126201629638672, 'loss_4': 2.682276487350464, 'epoch': 5.84}
{'loss': 0.0211, 'grad_norm': 7.044435024261475, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.010779145173728466, 'loss_2': 0.0102996826171875, 'loss_3': -15.78070068359375, 'loss_4': 2.414726734161377, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 09:49:01,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:01,760 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:16<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:09,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01806570589542389, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.709, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010617808438837528, 'eval_loss_2': 0.0074478983879089355, 'eval_loss_3': -18.21451759338379, 'eval_loss_4': 2.17427921295166, 'epoch': 5.84}
{'loss': 0.0247, 'grad_norm': 9.026150703430176, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.021063687279820442, 'loss_2': 0.003662109375, 'loss_3': -15.731776237487793, 'loss_4': 2.3511545658111572, 'epoch': 5.85}
{'loss': 0.0226, 'grad_norm': 7.149740695953369, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.020452827215194702, 'loss_2': 0.002117156982421875, 'loss_3': -15.69527816772461, 'loss_4': 2.2471909523010254, 'epoch': 5.85}
{'loss': 0.026, 'grad_norm': 7.722108364105225, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.02223452925682068, 'loss_2': 0.0037174224853515625, 'loss_3': -15.912961959838867, 'loss_4': 2.4845476150512695, 'epoch': 5.86}
{'loss': 0.0154, 'grad_norm': 6.163815975189209, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.010113618336617947, 'loss_2': 0.005279541015625, 'loss_3': -16.039039611816406, 'loss_4': 2.267272472381592, 'epoch': 5.87}
{'loss': 0.0378, 'grad_norm': 11.213586807250977, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.03540822118520737, 'loss_2': 0.0023899078369140625, 'loss_3': -15.89095687866211, 'loss_4': 2.340757369995117, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 09:49:09,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:09,105 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:23<1:11:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:16,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013320744037628174, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.631, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011001721024513245, 'eval_loss_2': 0.002319023013114929, 'eval_loss_3': -18.212505340576172, 'eval_loss_4': 2.2721009254455566, 'epoch': 5.87}
{'loss': 0.0332, 'grad_norm': 12.944145202636719, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.031139016151428223, 'loss_2': 0.0020904541015625, 'loss_3': -15.95648193359375, 'loss_4': 2.576817750930786, 'epoch': 5.88}
{'loss': 0.0179, 'grad_norm': 6.850264549255371, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.015104333870112896, 'loss_2': 0.0027751922607421875, 'loss_3': -15.758286476135254, 'loss_4': 2.403071880340576, 'epoch': 5.88}
{'loss': 0.0194, 'grad_norm': 8.841480255126953, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.013615954667329788, 'loss_2': 0.005741119384765625, 'loss_3': -16.019020080566406, 'loss_4': 1.8317270278930664, 'epoch': 5.89}
{'loss': 0.0316, 'grad_norm': 8.87103271484375, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.02221822552382946, 'loss_2': 0.00933837890625, 'loss_3': -15.836885452270508, 'loss_4': 2.679962635040283, 'epoch': 5.9}
{'loss': 0.0391, 'grad_norm': 10.771915435791016, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.02540097013115883, 'loss_2': 0.0136871337890625, 'loss_3': -15.834243774414062, 'loss_4': 2.4147980213165283, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 09:49:16,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:16,458 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:31<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:23,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016188206151127815, 'eval_runtime': 3.8197, 'eval_samples_per_second': 268.085, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.010042608715593815, 'eval_loss_2': 0.006145596504211426, 'eval_loss_3': -18.20096206665039, 'eval_loss_4': 2.4985175132751465, 'epoch': 5.9}
{'loss': 0.0375, 'grad_norm': 9.225911140441895, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.03267766535282135, 'loss_2': 0.00482940673828125, 'loss_3': -15.782330513000488, 'loss_4': 2.1671628952026367, 'epoch': 5.91}
{'loss': 0.0178, 'grad_norm': 6.1971964836120605, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.01380741223692894, 'loss_2': 0.00395965576171875, 'loss_3': -15.964946746826172, 'loss_4': 2.538670301437378, 'epoch': 5.91}
{'loss': 0.0415, 'grad_norm': 7.894914150238037, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.031506121158599854, 'loss_2': 0.00994873046875, 'loss_3': -15.652024269104004, 'loss_4': 2.4588723182678223, 'epoch': 5.92}
{'loss': 0.0307, 'grad_norm': 9.718965530395508, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.02608761005103588, 'loss_2': 0.00463104248046875, 'loss_3': -15.956003189086914, 'loss_4': 2.673274278640747, 'epoch': 5.92}
{'loss': 0.0559, 'grad_norm': 17.38121223449707, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.05127910152077675, 'loss_2': 0.0046234130859375, 'loss_3': -15.8444185256958, 'loss_4': 2.96952486038208, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 09:49:23,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:23,824 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:38<1:11:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:31,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013924234546720982, 'eval_runtime': 3.823, 'eval_samples_per_second': 267.852, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.009674407541751862, 'eval_loss_2': 0.004249826073646545, 'eval_loss_3': -18.184307098388672, 'eval_loss_4': 2.5216078758239746, 'epoch': 5.93}
{'loss': 0.0496, 'grad_norm': 20.530845642089844, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.03762790933251381, 'loss_2': 0.01201629638671875, 'loss_3': -16.334144592285156, 'loss_4': 3.2439053058624268, 'epoch': 5.94}
{'loss': 0.0224, 'grad_norm': 9.10563850402832, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.020333601161837578, 'loss_2': 0.0020904541015625, 'loss_3': -16.030500411987305, 'loss_4': 2.6841394901275635, 'epoch': 5.94}
{'loss': 0.0365, 'grad_norm': 11.611637115478516, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.02997070550918579, 'loss_2': 0.006557464599609375, 'loss_3': -15.886459350585938, 'loss_4': 2.74558687210083, 'epoch': 5.95}
{'loss': 0.0213, 'grad_norm': 8.876089096069336, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.01715833693742752, 'loss_2': 0.00414276123046875, 'loss_3': -16.00287628173828, 'loss_4': 3.1642563343048096, 'epoch': 5.95}
{'loss': 0.0109, 'grad_norm': 4.869943618774414, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.009572274051606655, 'loss_2': 0.001308441162109375, 'loss_3': -16.04690933227539, 'loss_4': 2.1524124145507812, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 09:49:31,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:31,195 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:45<1:11:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:49:38,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014121677726507187, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.628, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010772155597805977, 'eval_loss_2': 0.003349520266056061, 'eval_loss_3': -18.190261840820312, 'eval_loss_4': 2.4318368434906006, 'epoch': 5.96}
{'loss': 0.0762, 'grad_norm': 20.946575164794922, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.07476669549942017, 'loss_2': 0.0014057159423828125, 'loss_3': -15.839599609375, 'loss_4': 2.7387266159057617, 'epoch': 5.97}
{'loss': 0.0342, 'grad_norm': 9.018715858459473, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.032552093267440796, 'loss_2': 0.0016536712646484375, 'loss_3': -16.119792938232422, 'loss_4': 2.8073105812072754, 'epoch': 5.97}
{'loss': 0.0215, 'grad_norm': 8.940631866455078, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.018648458644747734, 'loss_2': 0.0028972625732421875, 'loss_3': -15.994123458862305, 'loss_4': 2.971342086791992, 'epoch': 5.98}
{'loss': 0.0378, 'grad_norm': 13.03361701965332, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.03430655971169472, 'loss_2': 0.0034809112548828125, 'loss_3': -16.141250610351562, 'loss_4': 2.7231459617614746, 'epoch': 5.98}
{'loss': 0.0175, 'grad_norm': 6.034244537353516, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.0130583131685853, 'loss_2': 0.00439453125, 'loss_3': -15.918946266174316, 'loss_4': 2.3073713779449463, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 09:49:38,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:38,555 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:52<1:09:19,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 09:49:45,594 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015124259516596794, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010850576683878899, 'eval_loss_2': 0.0042736828327178955, 'eval_loss_3': -18.20102882385254, 'eval_loss_4': 2.151676654815674, 'epoch': 5.99}
{'loss': 0.0319, 'grad_norm': 8.996243476867676, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.027625637128949165, 'loss_2': 0.0042266845703125, 'loss_3': -16.025001525878906, 'loss_4': 2.7373709678649902, 'epoch': 5.99}
{'loss': 0.0336, 'grad_norm': 15.833024024963379, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.022096162661910057, 'loss_2': 0.0115203857421875, 'loss_3': -16.235563278198242, 'loss_4': 1.995152473449707, 'epoch': 6.0}
{'loss': 0.0153, 'grad_norm': 5.669683933258057, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.013764177449047565, 'loss_2': 0.0015459060668945312, 'loss_3': -16.13248634338379, 'loss_4': 2.4239344596862793, 'epoch': 6.01}
{'loss': 0.0191, 'grad_norm': 5.901120185852051, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.01603320613503456, 'loss_2': 0.00302886962890625, 'loss_3': -16.14563751220703, 'loss_4': 2.43237566947937, 'epoch': 6.01}
{'loss': 0.0169, 'grad_norm': 5.759056091308594, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.010268883779644966, 'loss_2': 0.00667572021484375, 'loss_3': -16.254310607910156, 'loss_4': 2.5021681785583496, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 09:49:45,594 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:45,594 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:00<1:10:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:49:52,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01869596540927887, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.519, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01302726473659277, 'eval_loss_2': 0.005668699741363525, 'eval_loss_3': -18.222339630126953, 'eval_loss_4': 2.0400805473327637, 'epoch': 6.02}
{'loss': 0.0241, 'grad_norm': 8.172076225280762, 'learning_rate': 2.4e-05, 'loss_1': 0.021497227251529694, 'loss_2': 0.0025997161865234375, 'loss_3': -16.14590835571289, 'loss_4': 2.059746265411377, 'epoch': 6.02}
{'loss': 0.0322, 'grad_norm': 9.052109718322754, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.02765778638422489, 'loss_2': 0.004547119140625, 'loss_3': -16.193513870239258, 'loss_4': 3.049933910369873, 'epoch': 6.03}
{'loss': 0.0262, 'grad_norm': 6.148290634155273, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.01898493431508541, 'loss_2': 0.0072021484375, 'loss_3': -16.21234703063965, 'loss_4': 2.0965194702148438, 'epoch': 6.03}
{'loss': 0.0227, 'grad_norm': 6.590878009796143, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.014471901580691338, 'loss_2': 0.0082550048828125, 'loss_3': -16.243865966796875, 'loss_4': 2.0777556896209717, 'epoch': 6.04}
{'loss': 0.0423, 'grad_norm': 14.920130729675293, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.03557625785470009, 'loss_2': 0.00669097900390625, 'loss_3': -15.964319229125977, 'loss_4': 2.1874518394470215, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 09:49:52,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:49:52,946 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:07<1:11:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:00,293 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02251316048204899, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.919, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01501466054469347, 'eval_loss_2': 0.007498502731323242, 'eval_loss_3': -18.209453582763672, 'eval_loss_4': 1.6753391027450562, 'epoch': 6.05}
{'loss': 0.0554, 'grad_norm': 16.075424194335938, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.0433519147336483, 'loss_2': 0.0120849609375, 'loss_3': -16.03881072998047, 'loss_4': 1.659301519393921, 'epoch': 6.05}
{'loss': 0.0411, 'grad_norm': 16.71807861328125, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.034268882125616074, 'loss_2': 0.006805419921875, 'loss_3': -16.10059356689453, 'loss_4': 2.5028162002563477, 'epoch': 6.06}
{'loss': 0.0167, 'grad_norm': 6.972341537475586, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.016114329919219017, 'loss_2': 0.0006189346313476562, 'loss_3': -16.306365966796875, 'loss_4': 1.1444048881530762, 'epoch': 6.06}
{'loss': 0.0476, 'grad_norm': 19.918079376220703, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.038626447319984436, 'loss_2': 0.0090179443359375, 'loss_3': -16.117902755737305, 'loss_4': 1.318910837173462, 'epoch': 6.07}
{'loss': 0.0441, 'grad_norm': 18.541183471679688, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.04145003855228424, 'loss_2': 0.0026111602783203125, 'loss_3': -16.123661041259766, 'loss_4': 1.827582597732544, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 09:50:00,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:00,294 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:14<1:11:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:07,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017559554427862167, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.202, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.014127040281891823, 'eval_loss_2': 0.0034325122833251953, 'eval_loss_3': -18.201995849609375, 'eval_loss_4': 1.3005757331848145, 'epoch': 6.08}
{'loss': 0.0673, 'grad_norm': 20.769432067871094, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.06203367933630943, 'loss_2': 0.0052642822265625, 'loss_3': -15.883411407470703, 'loss_4': 1.3271865844726562, 'epoch': 6.08}
{'loss': 0.0246, 'grad_norm': 9.997817039489746, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.021274203434586525, 'loss_2': 0.003299713134765625, 'loss_3': -15.999188423156738, 'loss_4': 0.9368612766265869, 'epoch': 6.09}
{'loss': 0.0277, 'grad_norm': 7.062716960906982, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.018717555329203606, 'loss_2': 0.008941650390625, 'loss_3': -16.16692543029785, 'loss_4': 1.3559870719909668, 'epoch': 6.09}
{'loss': 0.0204, 'grad_norm': 5.627964019775391, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.01292270515114069, 'loss_2': 0.00743865966796875, 'loss_3': -16.104671478271484, 'loss_4': 1.7460078001022339, 'epoch': 6.1}
{'loss': 0.0447, 'grad_norm': 13.387088775634766, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.0402480848133564, 'loss_2': 0.00443267822265625, 'loss_3': -16.07462501525879, 'loss_4': 1.054378628730774, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 09:50:07,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:07,654 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:22<1:10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:14,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01891142502427101, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.721, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013720573857426643, 'eval_loss_2': 0.005190849304199219, 'eval_loss_3': -18.191091537475586, 'eval_loss_4': 1.2194210290908813, 'epoch': 6.1}
{'loss': 0.0263, 'grad_norm': 6.408225059509277, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.014888501726090908, 'loss_2': 0.01142120361328125, 'loss_3': -16.06781578063965, 'loss_4': 1.4322247505187988, 'epoch': 6.11}
{'loss': 0.0468, 'grad_norm': 16.620647430419922, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.0405101478099823, 'loss_2': 0.006256103515625, 'loss_3': -16.012981414794922, 'loss_4': 1.2296475172042847, 'epoch': 6.12}
{'loss': 0.0134, 'grad_norm': 5.485075950622559, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.010136880911886692, 'loss_2': 0.00324249267578125, 'loss_3': -15.984783172607422, 'loss_4': 1.8823769092559814, 'epoch': 6.12}
{'loss': 0.0278, 'grad_norm': 11.457222938537598, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.019485363736748695, 'loss_2': 0.008270263671875, 'loss_3': -16.06317901611328, 'loss_4': 1.9574531316757202, 'epoch': 6.13}
{'loss': 0.0307, 'grad_norm': 11.047597885131836, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.025668511167168617, 'loss_2': 0.0050506591796875, 'loss_3': -16.075428009033203, 'loss_4': 1.9140199422836304, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 09:50:14,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:14,999 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:29<1:10:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:22,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017982080578804016, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.434, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011042906902730465, 'eval_loss_2': 0.0069391727447509766, 'eval_loss_3': -18.174341201782227, 'eval_loss_4': 1.298454761505127, 'epoch': 6.13}
{'loss': 0.0235, 'grad_norm': 6.548924922943115, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.017464904114603996, 'loss_2': 0.006072998046875, 'loss_3': -16.112436294555664, 'loss_4': 2.2549500465393066, 'epoch': 6.14}
{'loss': 0.0326, 'grad_norm': 10.017683029174805, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.029013266786932945, 'loss_2': 0.003566741943359375, 'loss_3': -16.209604263305664, 'loss_4': 1.5848026275634766, 'epoch': 6.15}
{'loss': 0.038, 'grad_norm': 8.584051132202148, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.023195719346404076, 'loss_2': 0.0147705078125, 'loss_3': -16.185718536376953, 'loss_4': 1.4525949954986572, 'epoch': 6.15}
{'loss': 0.0497, 'grad_norm': 20.681135177612305, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.04953069984912872, 'loss_2': 0.00013959407806396484, 'loss_3': -16.294662475585938, 'loss_4': 1.6954247951507568, 'epoch': 6.16}
{'loss': 0.0536, 'grad_norm': 15.562621116638184, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.04394807666540146, 'loss_2': 0.0096435546875, 'loss_3': -16.010000228881836, 'loss_4': 1.615363359451294, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 09:50:22,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:22,361 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:36<1:10:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:29,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016694743186235428, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.551, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009808291681110859, 'eval_loss_2': 0.0068864524364471436, 'eval_loss_3': -18.176942825317383, 'eval_loss_4': 1.6026439666748047, 'epoch': 6.16}
{'loss': 0.0464, 'grad_norm': 17.635406494140625, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.037332382053136826, 'loss_2': 0.00907135009765625, 'loss_3': -16.172908782958984, 'loss_4': 1.80708646774292, 'epoch': 6.17}
{'loss': 0.0256, 'grad_norm': 6.609298229217529, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.015259726904332638, 'loss_2': 0.010345458984375, 'loss_3': -15.99863338470459, 'loss_4': 1.2795233726501465, 'epoch': 6.17}
{'loss': 0.0405, 'grad_norm': 15.407176971435547, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.03989357501268387, 'loss_2': 0.000591278076171875, 'loss_3': -16.100284576416016, 'loss_4': 1.9234977960586548, 'epoch': 6.18}
{'loss': 0.0385, 'grad_norm': 11.282383918762207, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.03692498430609703, 'loss_2': 0.0016002655029296875, 'loss_3': -16.038204193115234, 'loss_4': 2.682426691055298, 'epoch': 6.19}
{'loss': 0.0178, 'grad_norm': 4.7750139236450195, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.008205568417906761, 'loss_2': 0.00960540771484375, 'loss_3': -16.000465393066406, 'loss_4': 2.305720329284668, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 09:50:29,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:29,707 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:44<1:10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:37,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014784235507249832, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.707, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00997927412390709, 'eval_loss_2': 0.004804961383342743, 'eval_loss_3': -18.174179077148438, 'eval_loss_4': 2.090074300765991, 'epoch': 6.19}
{'loss': 0.0415, 'grad_norm': 15.580466270446777, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.04050171375274658, 'loss_2': 0.0009665489196777344, 'loss_3': -15.988468170166016, 'loss_4': 2.778578519821167, 'epoch': 6.2}
{'loss': 0.0125, 'grad_norm': 5.771341800689697, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.011685254983603954, 'loss_2': 0.000797271728515625, 'loss_3': -16.038860321044922, 'loss_4': 2.2914786338806152, 'epoch': 6.2}
{'loss': 0.0219, 'grad_norm': 7.816394805908203, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.021642744541168213, 'loss_2': 0.0002684593200683594, 'loss_3': -16.069076538085938, 'loss_4': 2.479405403137207, 'epoch': 6.21}
{'loss': 0.0304, 'grad_norm': 13.064745903015137, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.020368747413158417, 'loss_2': 0.0100555419921875, 'loss_3': -15.956537246704102, 'loss_4': 2.504023551940918, 'epoch': 6.22}
{'loss': 0.0361, 'grad_norm': 10.769238471984863, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.023262670263648033, 'loss_2': 0.0128021240234375, 'loss_3': -15.901487350463867, 'loss_4': 2.6470284461975098, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 09:50:37,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:37,062 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:51<1:10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:44,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022861171513795853, 'eval_runtime': 3.8182, 'eval_samples_per_second': 268.191, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.010699679143726826, 'eval_loss_2': 0.012161493301391602, 'eval_loss_3': -18.172101974487305, 'eval_loss_4': 2.411123752593994, 'epoch': 6.22}
{'loss': 0.0387, 'grad_norm': 7.424975395202637, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.018259897828102112, 'loss_2': 0.0204010009765625, 'loss_3': -15.832500457763672, 'loss_4': 2.8189311027526855, 'epoch': 6.23}
{'loss': 0.0339, 'grad_norm': 7.313559055328369, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.019697993993759155, 'loss_2': 0.0142364501953125, 'loss_3': -15.897369384765625, 'loss_4': 3.2243480682373047, 'epoch': 6.23}
{'loss': 0.0376, 'grad_norm': 12.343612670898438, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.02446880377829075, 'loss_2': 0.0131683349609375, 'loss_3': -15.966235160827637, 'loss_4': 3.004849910736084, 'epoch': 6.24}
{'loss': 0.027, 'grad_norm': 8.022677421569824, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.024338077753782272, 'loss_2': 0.002655029296875, 'loss_3': -15.870687484741211, 'loss_4': 2.197523593902588, 'epoch': 6.24}
{'loss': 0.0407, 'grad_norm': 9.606863021850586, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.03489360213279724, 'loss_2': 0.00580596923828125, 'loss_3': -15.986876487731934, 'loss_4': 2.1831812858581543, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 09:50:44,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:44,427 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [26:59<1:10:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:51,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01446087472140789, 'eval_runtime': 3.8167, 'eval_samples_per_second': 268.293, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.011118483729660511, 'eval_loss_2': 0.0033423900604248047, 'eval_loss_3': -18.13741683959961, 'eval_loss_4': 2.378830671310425, 'epoch': 6.25}
{'loss': 0.0325, 'grad_norm': 12.165369987487793, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.031088341027498245, 'loss_2': 0.0013780593872070312, 'loss_3': -15.87813949584961, 'loss_4': 2.4730353355407715, 'epoch': 6.26}
{'loss': 0.0171, 'grad_norm': 6.340747356414795, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.017082657665014267, 'loss_2': 2.1696090698242188e-05, 'loss_3': -15.765463829040527, 'loss_4': 2.1833126544952393, 'epoch': 6.26}
{'loss': 0.0481, 'grad_norm': 20.716379165649414, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.043639183044433594, 'loss_2': 0.004486083984375, 'loss_3': -15.731758117675781, 'loss_4': 2.320279598236084, 'epoch': 6.27}
{'loss': 0.0243, 'grad_norm': 8.968842506408691, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.019292207434773445, 'loss_2': 0.00502777099609375, 'loss_3': -15.914981842041016, 'loss_4': 2.854931116104126, 'epoch': 6.27}
{'loss': 0.132, 'grad_norm': 26.435028076171875, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.13190890848636627, 'loss_2': 0.00011146068572998047, 'loss_3': -15.717930793762207, 'loss_4': 2.8917293548583984, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 09:50:51,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:51,797 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:06<1:10:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:50:59,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01650838926434517, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.444, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011298347264528275, 'eval_loss_2': 0.0052100419998168945, 'eval_loss_3': -18.125776290893555, 'eval_loss_4': 2.5940628051757812, 'epoch': 6.28}
{'loss': 0.0236, 'grad_norm': 9.294794082641602, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.022672979161143303, 'loss_2': 0.0009446144104003906, 'loss_3': -15.810712814331055, 'loss_4': 3.119569778442383, 'epoch': 6.28}
{'loss': 0.0348, 'grad_norm': 14.344051361083984, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.03262682631611824, 'loss_2': 0.00222015380859375, 'loss_3': -16.06777572631836, 'loss_4': 2.258023738861084, 'epoch': 6.29}
{'loss': 0.0527, 'grad_norm': 19.99787712097168, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.048985548317432404, 'loss_2': 0.00372314453125, 'loss_3': -16.001253128051758, 'loss_4': 3.6886444091796875, 'epoch': 6.3}
{'loss': 0.036, 'grad_norm': 12.855875015258789, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.03076276183128357, 'loss_2': 0.005279541015625, 'loss_3': -15.774152755737305, 'loss_4': 3.5297536849975586, 'epoch': 6.3}
{'loss': 0.0667, 'grad_norm': 16.553651809692383, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.06544780731201172, 'loss_2': 0.001293182373046875, 'loss_3': -15.880033493041992, 'loss_4': 3.1540536880493164, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 09:50:59,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:50:59,156 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:13<1:10:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:06,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013666743412613869, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.659, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011035796254873276, 'eval_loss_2': 0.002630949020385742, 'eval_loss_3': -18.146137237548828, 'eval_loss_4': 3.2468767166137695, 'epoch': 6.31}
{'loss': 0.0427, 'grad_norm': 12.55444049835205, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.03968781605362892, 'loss_2': 0.00298309326171875, 'loss_3': -15.944456100463867, 'loss_4': 4.537412166595459, 'epoch': 6.31}
{'loss': 0.0303, 'grad_norm': 8.51324462890625, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.022364377975463867, 'loss_2': 0.0079803466796875, 'loss_3': -15.939746856689453, 'loss_4': 3.364942789077759, 'epoch': 6.32}
{'loss': 0.0748, 'grad_norm': 14.354757308959961, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.06494247168302536, 'loss_2': 0.0098114013671875, 'loss_3': -15.788239479064941, 'loss_4': 3.972123622894287, 'epoch': 6.33}
{'loss': 0.0565, 'grad_norm': 18.291006088256836, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.05103839188814163, 'loss_2': 0.00542449951171875, 'loss_3': -15.705108642578125, 'loss_4': 3.4704322814941406, 'epoch': 6.33}
{'loss': 0.0432, 'grad_norm': 9.515439987182617, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.03537292405962944, 'loss_2': 0.007781982421875, 'loss_3': -15.823864936828613, 'loss_4': 3.734098434448242, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 09:51:06,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:06,512 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:21<1:10:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:13,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013700039125978947, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.404, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.010633528232574463, 'eval_loss_2': 0.003066509962081909, 'eval_loss_3': -18.189523696899414, 'eval_loss_4': 3.5248332023620605, 'epoch': 6.34}
{'loss': 0.0313, 'grad_norm': 13.056800842285156, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.0282396599650383, 'loss_2': 0.0030117034912109375, 'loss_3': -16.04651641845703, 'loss_4': 2.8578853607177734, 'epoch': 6.34}
{'loss': 0.0204, 'grad_norm': 6.757774353027344, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.01714165136218071, 'loss_2': 0.0032634735107421875, 'loss_3': -16.06536865234375, 'loss_4': 3.5252442359924316, 'epoch': 6.35}
{'loss': 0.0317, 'grad_norm': 10.27568244934082, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.02267823927104473, 'loss_2': 0.00897979736328125, 'loss_3': -15.933143615722656, 'loss_4': 3.59244966506958, 'epoch': 6.35}
{'loss': 0.053, 'grad_norm': 24.172204971313477, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.04137932136654854, 'loss_2': 0.01163482666015625, 'loss_3': -15.773077011108398, 'loss_4': 4.059628486633301, 'epoch': 6.36}
{'loss': 0.0276, 'grad_norm': 8.288045883178711, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.027401285246014595, 'loss_2': 0.0001569986343383789, 'loss_3': -15.793174743652344, 'loss_4': 3.3412058353424072, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 09:51:13,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:13,874 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:28<1:10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:21,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014612920582294464, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0111312260851264, 'eval_loss_2': 0.0034816935658454895, 'eval_loss_3': -18.2086124420166, 'eval_loss_4': 3.5455679893493652, 'epoch': 6.37}
{'loss': 0.0282, 'grad_norm': 7.0424275398254395, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.02313089929521084, 'loss_2': 0.005096435546875, 'loss_3': -15.986734390258789, 'loss_4': 3.4859938621520996, 'epoch': 6.37}
{'loss': 0.0181, 'grad_norm': 5.966783046722412, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.011500684544444084, 'loss_2': 0.006549835205078125, 'loss_3': -15.96113395690918, 'loss_4': 2.984243869781494, 'epoch': 6.38}
{'loss': 0.0248, 'grad_norm': 6.3545660972595215, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.01519005000591278, 'loss_2': 0.00959014892578125, 'loss_3': -15.955375671386719, 'loss_4': 3.857417106628418, 'epoch': 6.38}
{'loss': 0.0439, 'grad_norm': 12.780564308166504, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.03669656068086624, 'loss_2': 0.007205963134765625, 'loss_3': -15.929043769836426, 'loss_4': 2.791067600250244, 'epoch': 6.39}
{'loss': 0.0135, 'grad_norm': 6.614112377166748, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.01200882624834776, 'loss_2': 0.0015411376953125, 'loss_3': -16.086374282836914, 'loss_4': 3.6152873039245605, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 09:51:21,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:21,235 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:35<1:10:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:28,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012553578242659569, 'eval_runtime': 3.8236, 'eval_samples_per_second': 267.81, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.009214943274855614, 'eval_loss_2': 0.003338634967803955, 'eval_loss_3': -18.21095085144043, 'eval_loss_4': 3.2824854850769043, 'epoch': 6.4}
{'loss': 0.0187, 'grad_norm': 8.292524337768555, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.017178386449813843, 'loss_2': 0.0014934539794921875, 'loss_3': -15.744681358337402, 'loss_4': 3.8737497329711914, 'epoch': 6.4}
{'loss': 0.027, 'grad_norm': 8.154072761535645, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.022984303534030914, 'loss_2': 0.0040435791015625, 'loss_3': -15.877941131591797, 'loss_4': 3.712306499481201, 'epoch': 6.41}
{'loss': 0.0421, 'grad_norm': 10.72199535369873, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.03514587879180908, 'loss_2': 0.006923675537109375, 'loss_3': -15.877557754516602, 'loss_4': 4.230986595153809, 'epoch': 6.41}
{'loss': 0.0262, 'grad_norm': 7.863264560699463, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.022316396236419678, 'loss_2': 0.0038738250732421875, 'loss_3': -15.950693130493164, 'loss_4': 3.519397735595703, 'epoch': 6.42}
{'loss': 0.0266, 'grad_norm': 9.18484115600586, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.024809453636407852, 'loss_2': 0.0018138885498046875, 'loss_3': -15.980716705322266, 'loss_4': 2.9080586433410645, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 09:51:28,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:28,612 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:43<1:10:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:35,971 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01427031122148037, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007960593327879906, 'eval_loss_2': 0.006309717893600464, 'eval_loss_3': -18.21615982055664, 'eval_loss_4': 2.891134738922119, 'epoch': 6.42}
{'loss': 0.0425, 'grad_norm': 14.926774978637695, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.033491350710392, 'loss_2': 0.00905609130859375, 'loss_3': -15.848885536193848, 'loss_4': 3.297607898712158, 'epoch': 6.43}
{'loss': 0.0434, 'grad_norm': 11.238499641418457, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.03110615536570549, 'loss_2': 0.01232147216796875, 'loss_3': -15.957993507385254, 'loss_4': 2.910999298095703, 'epoch': 6.44}
{'loss': 0.0339, 'grad_norm': 10.486583709716797, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.028553467243909836, 'loss_2': 0.00530242919921875, 'loss_3': -16.023067474365234, 'loss_4': 3.1388161182403564, 'epoch': 6.44}
{'loss': 0.0265, 'grad_norm': 6.2034525871276855, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.018514471128582954, 'loss_2': 0.008026123046875, 'loss_3': -15.916196823120117, 'loss_4': 3.1644487380981445, 'epoch': 6.45}
{'loss': 0.0298, 'grad_norm': 11.024548530578613, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.02139429561793804, 'loss_2': 0.00841522216796875, 'loss_3': -16.124618530273438, 'loss_4': 2.303666114807129, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 09:51:35,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:35,972 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:50<1:09:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:43,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014133740216493607, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.709, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009034154005348682, 'eval_loss_2': 0.005099587142467499, 'eval_loss_3': -18.18828582763672, 'eval_loss_4': 2.5430421829223633, 'epoch': 6.45}
{'loss': 0.0248, 'grad_norm': 8.29306697845459, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.02059044875204563, 'loss_2': 0.0042572021484375, 'loss_3': -16.17718505859375, 'loss_4': 2.3812570571899414, 'epoch': 6.46}
{'loss': 0.0301, 'grad_norm': 10.49511432647705, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.02815449796617031, 'loss_2': 0.0019397735595703125, 'loss_3': -15.980392456054688, 'loss_4': 2.7649877071380615, 'epoch': 6.47}
{'loss': 0.01, 'grad_norm': 5.3188958168029785, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.008439023047685623, 'loss_2': 0.001552581787109375, 'loss_3': -16.04950523376465, 'loss_4': 2.8575284481048584, 'epoch': 6.47}
{'loss': 0.0317, 'grad_norm': 10.220585823059082, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.027494242414832115, 'loss_2': 0.00420379638671875, 'loss_3': -15.95897388458252, 'loss_4': 2.2974114418029785, 'epoch': 6.48}
{'loss': 0.0251, 'grad_norm': 8.276457786560059, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.024595363065600395, 'loss_2': 0.0004782676696777344, 'loss_3': -16.005210876464844, 'loss_4': 3.0427513122558594, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 09:51:43,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:43,324 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [27:57<1:09:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:50,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017460957169532776, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.739, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009030595421791077, 'eval_loss_2': 0.0084303617477417, 'eval_loss_3': -18.15690040588379, 'eval_loss_4': 2.5847325325012207, 'epoch': 6.48}
{'loss': 0.0177, 'grad_norm': 5.591996192932129, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.010984282940626144, 'loss_2': 0.0067291259765625, 'loss_3': -15.984548568725586, 'loss_4': 2.5260870456695557, 'epoch': 6.49}
{'loss': 0.0309, 'grad_norm': 6.380519866943359, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.013011753559112549, 'loss_2': 0.0178985595703125, 'loss_3': -16.0025691986084, 'loss_4': 3.5463786125183105, 'epoch': 6.49}
{'loss': 0.0195, 'grad_norm': 6.738821506500244, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.01693708263337612, 'loss_2': 0.0025653839111328125, 'loss_3': -15.885540008544922, 'loss_4': 2.7578296661376953, 'epoch': 6.5}
{'loss': 0.0176, 'grad_norm': 5.838364124298096, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.014772419817745686, 'loss_2': 0.0028057098388671875, 'loss_3': -16.038002014160156, 'loss_4': 2.860894203186035, 'epoch': 6.51}
{'loss': 0.0199, 'grad_norm': 6.3487677574157715, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.014200257137417793, 'loss_2': 0.005672454833984375, 'loss_3': -16.127243041992188, 'loss_4': 2.6396219730377197, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 09:51:50,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:50,679 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:05<1:09:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:51:58,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01755400560796261, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.543, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009524662978947163, 'eval_loss_2': 0.008029341697692871, 'eval_loss_3': -18.14871597290039, 'eval_loss_4': 2.508474349975586, 'epoch': 6.51}
{'loss': 0.03, 'grad_norm': 8.094474792480469, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.022351933643221855, 'loss_2': 0.0076141357421875, 'loss_3': -16.091022491455078, 'loss_4': 3.0952985286712646, 'epoch': 6.52}
{'loss': 0.0187, 'grad_norm': 6.582988739013672, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.012502701953053474, 'loss_2': 0.00615692138671875, 'loss_3': -15.97503662109375, 'loss_4': 2.4638123512268066, 'epoch': 6.52}
{'loss': 0.019, 'grad_norm': 4.968995094299316, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.010513982735574245, 'loss_2': 0.008514404296875, 'loss_3': -15.998490333557129, 'loss_4': 2.661044120788574, 'epoch': 6.53}
{'loss': 0.0245, 'grad_norm': 6.001344203948975, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.012320364825427532, 'loss_2': 0.01219940185546875, 'loss_3': -15.855401039123535, 'loss_4': 2.539597749710083, 'epoch': 6.53}
{'loss': 0.0374, 'grad_norm': 8.015429496765137, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.02166222408413887, 'loss_2': 0.015716552734375, 'loss_3': -16.36803436279297, 'loss_4': 3.0632009506225586, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 09:51:58,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:51:58,041 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:12<1:09:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:05,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01881822943687439, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.07, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.010103552602231503, 'eval_loss_2': 0.008714675903320312, 'eval_loss_3': -18.183887481689453, 'eval_loss_4': 2.478588104248047, 'epoch': 6.54}
{'loss': 0.0281, 'grad_norm': 5.956727504730225, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.015029865317046642, 'loss_2': 0.013031005859375, 'loss_3': -16.028759002685547, 'loss_4': 2.5567872524261475, 'epoch': 6.55}
{'loss': 0.0216, 'grad_norm': 6.703287124633789, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.01478385180234909, 'loss_2': 0.0068511962890625, 'loss_3': -16.004806518554688, 'loss_4': 2.352241277694702, 'epoch': 6.55}
{'loss': 0.0225, 'grad_norm': 6.333619117736816, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.018191836774349213, 'loss_2': 0.004329681396484375, 'loss_3': -16.076210021972656, 'loss_4': 2.9432878494262695, 'epoch': 6.56}
{'loss': 0.0323, 'grad_norm': 10.635900497436523, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.024614160880446434, 'loss_2': 0.007694244384765625, 'loss_3': -16.006710052490234, 'loss_4': 2.3812806606292725, 'epoch': 6.56}
{'loss': 0.0285, 'grad_norm': 10.420126914978027, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.022265741601586342, 'loss_2': 0.00627899169921875, 'loss_3': -16.220035552978516, 'loss_4': 3.0431320667266846, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 09:52:05,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:05,405 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:19<1:09:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:12,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019067484885454178, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.425, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011935744434595108, 'eval_loss_2': 0.00713174045085907, 'eval_loss_3': -18.202423095703125, 'eval_loss_4': 2.2956111431121826, 'epoch': 6.57}
{'loss': 0.0151, 'grad_norm': 5.090343475341797, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.00893342960625887, 'loss_2': 0.00616455078125, 'loss_3': -15.982847213745117, 'loss_4': 2.5002050399780273, 'epoch': 6.58}
{'loss': 0.0409, 'grad_norm': 11.518803596496582, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.0290982685983181, 'loss_2': 0.01177978515625, 'loss_3': -16.34149932861328, 'loss_4': 2.309812307357788, 'epoch': 6.58}
{'loss': 0.0211, 'grad_norm': 5.6825175285339355, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.011194400489330292, 'loss_2': 0.00989532470703125, 'loss_3': -16.156818389892578, 'loss_4': 1.6468220949172974, 'epoch': 6.59}
{'loss': 0.0472, 'grad_norm': 24.304454803466797, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.045796263962984085, 'loss_2': 0.00142669677734375, 'loss_3': -16.116846084594727, 'loss_4': 2.5665206909179688, 'epoch': 6.59}
{'loss': 0.041, 'grad_norm': 13.046111106872559, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.038028549402952194, 'loss_2': 0.002941131591796875, 'loss_3': -16.02633285522461, 'loss_4': 2.605750560760498, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 09:52:12,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:12,766 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:27<1:09:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:20,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014218936674296856, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010721172206103802, 'eval_loss_2': 0.003497764468193054, 'eval_loss_3': -18.304121017456055, 'eval_loss_4': 1.9956443309783936, 'epoch': 6.6}
{'loss': 0.0278, 'grad_norm': 12.18040943145752, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.025568826124072075, 'loss_2': 0.002223968505859375, 'loss_3': -16.135440826416016, 'loss_4': 2.0357918739318848, 'epoch': 6.6}
{'loss': 0.025, 'grad_norm': 8.184944152832031, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.023608656600117683, 'loss_2': 0.0013856887817382812, 'loss_3': -16.042600631713867, 'loss_4': 2.5847244262695312, 'epoch': 6.61}
{'loss': 0.0291, 'grad_norm': 7.31313943862915, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.019979307428002357, 'loss_2': 0.00910186767578125, 'loss_3': -16.102182388305664, 'loss_4': 2.47532320022583, 'epoch': 6.62}
{'loss': 0.0289, 'grad_norm': 8.99644947052002, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.027864310890436172, 'loss_2': 0.0010023117065429688, 'loss_3': -16.121509552001953, 'loss_4': 2.177290201187134, 'epoch': 6.62}
{'loss': 0.0902, 'grad_norm': 18.243412017822266, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.08417648077011108, 'loss_2': 0.00597381591796875, 'loss_3': -16.115102767944336, 'loss_4': 1.6478450298309326, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 09:52:20,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:20,119 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:34<1:09:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:27,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01344966609030962, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.478, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010022818110883236, 'eval_loss_2': 0.003426849842071533, 'eval_loss_3': -18.340635299682617, 'eval_loss_4': 1.7173411846160889, 'epoch': 6.63}
{'loss': 0.0363, 'grad_norm': 10.299911499023438, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.03252585604786873, 'loss_2': 0.003765106201171875, 'loss_3': -16.310218811035156, 'loss_4': 2.2441723346710205, 'epoch': 6.63}
{'loss': 0.0184, 'grad_norm': 5.3029069900512695, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.012398289516568184, 'loss_2': 0.00597381591796875, 'loss_3': -16.176237106323242, 'loss_4': 1.4573663473129272, 'epoch': 6.64}
{'loss': 0.0299, 'grad_norm': 7.16902494430542, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.027162734419107437, 'loss_2': 0.002750396728515625, 'loss_3': -16.13219451904297, 'loss_4': 1.5643501281738281, 'epoch': 6.65}
{'loss': 0.1411, 'grad_norm': 19.196231842041016, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.14054043591022491, 'loss_2': 0.0005893707275390625, 'loss_3': -15.952323913574219, 'loss_4': 1.3805279731750488, 'epoch': 6.65}
{'loss': 0.0478, 'grad_norm': 15.190018653869629, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.04177595674991608, 'loss_2': 0.0060272216796875, 'loss_3': -16.315452575683594, 'loss_4': 1.5907130241394043, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 09:52:27,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:27,482 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:42<1:09:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:34,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015798192471265793, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.548, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008855801075696945, 'eval_loss_2': 0.006942391395568848, 'eval_loss_3': -18.315155029296875, 'eval_loss_4': 1.5141996145248413, 'epoch': 6.66}
{'loss': 0.0344, 'grad_norm': 10.738749504089355, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.03025747649371624, 'loss_2': 0.004138946533203125, 'loss_3': -16.132055282592773, 'loss_4': 1.748213768005371, 'epoch': 6.66}
{'loss': 0.0465, 'grad_norm': 14.496615409851074, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.04177740588784218, 'loss_2': 0.00470733642578125, 'loss_3': -16.157623291015625, 'loss_4': 2.0076398849487305, 'epoch': 6.67}
{'loss': 0.0706, 'grad_norm': 25.675376892089844, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.06801047921180725, 'loss_2': 0.002574920654296875, 'loss_3': -16.052087783813477, 'loss_4': 1.5470085144042969, 'epoch': 6.67}
{'loss': 0.0298, 'grad_norm': 7.5463337898254395, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.026436353102326393, 'loss_2': 0.003360748291015625, 'loss_3': -15.8843355178833, 'loss_4': 1.7940022945404053, 'epoch': 6.68}
{'loss': 0.0766, 'grad_norm': 23.362449645996094, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.06429640203714371, 'loss_2': 0.012298583984375, 'loss_3': -15.980414390563965, 'loss_4': 1.4666154384613037, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 09:52:34,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:34,833 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:49<1:09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:42,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014041091315448284, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.733, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008433494716882706, 'eval_loss_2': 0.005607597529888153, 'eval_loss_3': -18.32890510559082, 'eval_loss_4': 1.3704172372817993, 'epoch': 6.69}
{'loss': 0.0309, 'grad_norm': 8.558859825134277, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.020617159083485603, 'loss_2': 0.0102996826171875, 'loss_3': -15.918665885925293, 'loss_4': 2.249826669692993, 'epoch': 6.69}
{'loss': 0.0181, 'grad_norm': 6.394102096557617, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.01716415211558342, 'loss_2': 0.00093841552734375, 'loss_3': -16.115890502929688, 'loss_4': 1.6072924137115479, 'epoch': 6.7}
{'loss': 0.0258, 'grad_norm': 6.29592752456665, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.021005263552069664, 'loss_2': 0.00481414794921875, 'loss_3': -16.26045799255371, 'loss_4': 1.3890206813812256, 'epoch': 6.7}
{'loss': 0.0219, 'grad_norm': 7.490140438079834, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.020466968417167664, 'loss_2': 0.0014600753784179688, 'loss_3': -16.132341384887695, 'loss_4': 1.7353038787841797, 'epoch': 6.71}
{'loss': 0.0342, 'grad_norm': 23.610107421875, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.03128373995423317, 'loss_2': 0.002872467041015625, 'loss_3': -16.159347534179688, 'loss_4': 1.406977891921997, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 09:52:42,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:42,189 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [28:56<1:09:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:49,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011170780286192894, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.321, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0073469546623528, 'eval_loss_2': 0.0038238242268562317, 'eval_loss_3': -18.337141036987305, 'eval_loss_4': 1.4813508987426758, 'epoch': 6.72}
{'loss': 0.028, 'grad_norm': 8.48001480102539, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.027169575914740562, 'loss_2': 0.0008082389831542969, 'loss_3': -16.080522537231445, 'loss_4': 1.4804033041000366, 'epoch': 6.72}
{'loss': 0.0186, 'grad_norm': 5.365778923034668, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.00940892193466425, 'loss_2': 0.00920867919921875, 'loss_3': -16.090042114257812, 'loss_4': 1.4148443937301636, 'epoch': 6.73}
{'loss': 0.0532, 'grad_norm': 16.67641258239746, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.04667939618229866, 'loss_2': 0.00653839111328125, 'loss_3': -16.057649612426758, 'loss_4': 1.3670973777770996, 'epoch': 6.73}
{'loss': 0.0441, 'grad_norm': 12.401017189025879, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.044030409306287766, 'loss_2': 0.00011622905731201172, 'loss_3': -16.068174362182617, 'loss_4': 2.2297346591949463, 'epoch': 6.74}
{'loss': 0.017, 'grad_norm': 8.779850959777832, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.016938257962465286, 'loss_2': 1.3470649719238281e-05, 'loss_3': -16.116273880004883, 'loss_4': 2.5429744720458984, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 09:52:49,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:49,546 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:04<1:09:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:52:56,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009951620362699032, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006904794368892908, 'eval_loss_2': 0.0030468255281448364, 'eval_loss_3': -18.283199310302734, 'eval_loss_4': 1.878554344177246, 'epoch': 6.74}
{'loss': 0.0173, 'grad_norm': 5.4684529304504395, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.010703956708312035, 'loss_2': 0.006626129150390625, 'loss_3': -16.25313949584961, 'loss_4': 1.7150733470916748, 'epoch': 6.75}
{'loss': 0.0277, 'grad_norm': 9.408561706542969, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.018085820600390434, 'loss_2': 0.00957489013671875, 'loss_3': -16.205415725708008, 'loss_4': 2.000030517578125, 'epoch': 6.76}
{'loss': 0.0267, 'grad_norm': 10.582590103149414, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.021851111203432083, 'loss_2': 0.0048980712890625, 'loss_3': -15.998725891113281, 'loss_4': 1.6437585353851318, 'epoch': 6.76}
{'loss': 0.0441, 'grad_norm': 15.285133361816406, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.032774221152067184, 'loss_2': 0.0113372802734375, 'loss_3': -16.11935043334961, 'loss_4': 2.3015475273132324, 'epoch': 6.77}
{'loss': 0.021, 'grad_norm': 6.165463447570801, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.013119101524353027, 'loss_2': 0.0078582763671875, 'loss_3': -16.281625747680664, 'loss_4': 2.3675897121429443, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 09:52:56,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:52:56,896 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:11<1:09:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:04,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011354170739650726, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.665, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006946094799786806, 'eval_loss_2': 0.0044080764055252075, 'eval_loss_3': -18.244979858398438, 'eval_loss_4': 2.579543352127075, 'epoch': 6.77}
{'loss': 0.0353, 'grad_norm': 7.691980838775635, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.02342022955417633, 'loss_2': 0.01189422607421875, 'loss_3': -16.025959014892578, 'loss_4': 2.7430436611175537, 'epoch': 6.78}
{'loss': 0.0271, 'grad_norm': 13.563715934753418, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.01828298531472683, 'loss_2': 0.0088653564453125, 'loss_3': -16.038572311401367, 'loss_4': 2.6571435928344727, 'epoch': 6.78}
{'loss': 0.0242, 'grad_norm': 6.866621494293213, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.019184483215212822, 'loss_2': 0.00496673583984375, 'loss_3': -16.043540954589844, 'loss_4': 2.772264242172241, 'epoch': 6.79}
{'loss': 0.0184, 'grad_norm': 7.6212921142578125, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.015563415363430977, 'loss_2': 0.0028781890869140625, 'loss_3': -16.024526596069336, 'loss_4': 2.682483673095703, 'epoch': 6.8}
{'loss': 0.0189, 'grad_norm': 6.597401142120361, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.011922010220587254, 'loss_2': 0.00695037841796875, 'loss_3': -15.852500915527344, 'loss_4': 2.836031913757324, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 09:53:04,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:04,250 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:18<1:08:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:11,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010762185789644718, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.776, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00748941395431757, 'eval_loss_2': 0.0032727718353271484, 'eval_loss_3': -18.264402389526367, 'eval_loss_4': 3.1073780059814453, 'epoch': 6.8}
{'loss': 0.0198, 'grad_norm': 6.2451395988464355, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.013155567459762096, 'loss_2': 0.006683349609375, 'loss_3': -16.18712043762207, 'loss_4': 3.1742196083068848, 'epoch': 6.81}
{'loss': 0.0257, 'grad_norm': 7.579165935516357, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.020813196897506714, 'loss_2': 0.0048980712890625, 'loss_3': -16.193431854248047, 'loss_4': 2.7673592567443848, 'epoch': 6.81}
{'loss': 0.0146, 'grad_norm': 5.687596797943115, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.01166104432195425, 'loss_2': 0.0029392242431640625, 'loss_3': -15.965668678283691, 'loss_4': 3.2500312328338623, 'epoch': 6.82}
{'loss': 0.0207, 'grad_norm': 7.323840141296387, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.01352391205728054, 'loss_2': 0.00713348388671875, 'loss_3': -16.162363052368164, 'loss_4': 3.3183648586273193, 'epoch': 6.83}
{'loss': 0.0196, 'grad_norm': 5.897352695465088, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.014583364129066467, 'loss_2': 0.005008697509765625, 'loss_3': -16.041349411010742, 'loss_4': 2.870565414428711, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 09:53:11,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:11,607 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:26<1:08:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:18,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011829432100057602, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008207614533603191, 'eval_loss_2': 0.003621816635131836, 'eval_loss_3': -18.257125854492188, 'eval_loss_4': 3.5571534633636475, 'epoch': 6.83}
{'loss': 0.0294, 'grad_norm': 6.874466896057129, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.02199395000934601, 'loss_2': 0.00739288330078125, 'loss_3': -16.12643814086914, 'loss_4': 3.7152085304260254, 'epoch': 6.84}
{'loss': 0.0314, 'grad_norm': 7.899418354034424, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.025421613827347755, 'loss_2': 0.0059356689453125, 'loss_3': -16.146589279174805, 'loss_4': 3.2999167442321777, 'epoch': 6.84}
{'loss': 0.052, 'grad_norm': 23.038251876831055, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.046806517988443375, 'loss_2': 0.0051727294921875, 'loss_3': -15.950141906738281, 'loss_4': 4.210069179534912, 'epoch': 6.85}
{'loss': 0.0525, 'grad_norm': 10.385762214660645, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.05079469084739685, 'loss_2': 0.001689910888671875, 'loss_3': -16.111568450927734, 'loss_4': 3.096013307571411, 'epoch': 6.85}
{'loss': 0.0291, 'grad_norm': 8.113768577575684, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.026063445955514908, 'loss_2': 0.003017425537109375, 'loss_3': -16.037202835083008, 'loss_4': 3.566852569580078, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 09:53:18,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:18,961 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:33<1:08:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:26,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012280660681426525, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.322, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.008003714494407177, 'eval_loss_2': 0.004276946187019348, 'eval_loss_3': -18.325227737426758, 'eval_loss_4': 3.5842175483703613, 'epoch': 6.86}
{'loss': 0.0469, 'grad_norm': 23.994129180908203, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.045628711581230164, 'loss_2': 0.0012788772583007812, 'loss_3': -15.871309280395508, 'loss_4': 3.5165457725524902, 'epoch': 6.87}
{'loss': 0.0693, 'grad_norm': 19.544300079345703, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.05370108038187027, 'loss_2': 0.015594482421875, 'loss_3': -16.1519832611084, 'loss_4': 3.9549269676208496, 'epoch': 6.87}
{'loss': 0.0243, 'grad_norm': 7.703834056854248, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.018565094098448753, 'loss_2': 0.00574493408203125, 'loss_3': -16.299528121948242, 'loss_4': 3.331916332244873, 'epoch': 6.88}
{'loss': 0.0434, 'grad_norm': 11.814970970153809, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.03495584800839424, 'loss_2': 0.0084228515625, 'loss_3': -16.304340362548828, 'loss_4': 3.396799087524414, 'epoch': 6.88}
{'loss': 0.0506, 'grad_norm': 13.796631813049316, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.04693989083170891, 'loss_2': 0.00368499755859375, 'loss_3': -16.182941436767578, 'loss_4': 3.239663600921631, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 09:53:26,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:26,332 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:40<1:08:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:33,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01699470542371273, 'eval_runtime': 3.8246, 'eval_samples_per_second': 267.741, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.008985748514533043, 'eval_loss_2': 0.008008956909179688, 'eval_loss_3': -18.327289581298828, 'eval_loss_4': 3.610912799835205, 'epoch': 6.89}
{'loss': 0.0376, 'grad_norm': 14.224264144897461, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.028678007423877716, 'loss_2': 0.008941650390625, 'loss_3': -16.2362060546875, 'loss_4': 3.729841709136963, 'epoch': 6.9}
{'loss': 0.0259, 'grad_norm': 6.2521891593933105, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.016129188239574432, 'loss_2': 0.0098114013671875, 'loss_3': -16.054874420166016, 'loss_4': 3.6185379028320312, 'epoch': 6.9}
{'loss': 0.0218, 'grad_norm': 6.83746337890625, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.01933377981185913, 'loss_2': 0.002468109130859375, 'loss_3': -16.211904525756836, 'loss_4': 3.0420501232147217, 'epoch': 6.91}
{'loss': 0.0227, 'grad_norm': 6.0228471755981445, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.019805513322353363, 'loss_2': 0.00286865234375, 'loss_3': -16.064884185791016, 'loss_4': 3.636338233947754, 'epoch': 6.91}
{'loss': 0.0313, 'grad_norm': 9.525812149047852, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.023653078824281693, 'loss_2': 0.007640838623046875, 'loss_3': -16.112808227539062, 'loss_4': 3.5678162574768066, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 09:53:33,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:33,707 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:48<1:08:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:41,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012542382813990116, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.482, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008038356900215149, 'eval_loss_2': 0.004504024982452393, 'eval_loss_3': -18.336074829101562, 'eval_loss_4': 3.641810178756714, 'epoch': 6.92}
{'loss': 0.0407, 'grad_norm': 10.550798416137695, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.035273995250463486, 'loss_2': 0.00545501708984375, 'loss_3': -15.922842025756836, 'loss_4': 4.292018890380859, 'epoch': 6.92}
{'loss': 0.0671, 'grad_norm': 20.61382293701172, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.05941183120012283, 'loss_2': 0.007720947265625, 'loss_3': -16.095680236816406, 'loss_4': 3.6396098136901855, 'epoch': 6.93}
{'loss': 0.0413, 'grad_norm': 8.931929588317871, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.025541910901665688, 'loss_2': 0.015777587890625, 'loss_3': -16.192001342773438, 'loss_4': 4.142817497253418, 'epoch': 6.94}
{'loss': 0.045, 'grad_norm': 12.056406021118164, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.03208914399147034, 'loss_2': 0.0129241943359375, 'loss_3': -16.333581924438477, 'loss_4': 4.278205871582031, 'epoch': 6.94}
{'loss': 0.0293, 'grad_norm': 7.56685733795166, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.022788232192397118, 'loss_2': 0.00653839111328125, 'loss_3': -16.240901947021484, 'loss_4': 4.149811744689941, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 09:53:41,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:41,070 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [29:55<1:08:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:53:48,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016857538372278214, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.628, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008681091479957104, 'eval_loss_2': 0.008176445960998535, 'eval_loss_3': -18.343917846679688, 'eval_loss_4': 4.1081647872924805, 'epoch': 6.95}
{'loss': 0.0256, 'grad_norm': 7.007992744445801, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.016670912504196167, 'loss_2': 0.0089263916015625, 'loss_3': -16.254709243774414, 'loss_4': 4.832469940185547, 'epoch': 6.95}
{'loss': 0.058, 'grad_norm': 11.819628715515137, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.047436174005270004, 'loss_2': 0.010589599609375, 'loss_3': -16.173812866210938, 'loss_4': 3.9092607498168945, 'epoch': 6.96}
{'loss': 0.0344, 'grad_norm': 8.333161354064941, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.02706143446266651, 'loss_2': 0.007293701171875, 'loss_3': -16.092117309570312, 'loss_4': 5.557709693908691, 'epoch': 6.97}
{'loss': 0.0263, 'grad_norm': 7.780794620513916, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.024238426238298416, 'loss_2': 0.002109527587890625, 'loss_3': -15.926206588745117, 'loss_4': 4.881165504455566, 'epoch': 6.97}
{'loss': 0.0162, 'grad_norm': 7.183450698852539, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.015907442197203636, 'loss_2': 0.0003147125244140625, 'loss_3': -16.220184326171875, 'loss_4': 4.374042987823486, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 09:53:48,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:48,428 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:02<1:04:29,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 09:53:55,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015086179599165916, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009174024686217308, 'eval_loss_2': 0.005912154912948608, 'eval_loss_3': -18.363197326660156, 'eval_loss_4': 3.973512649536133, 'epoch': 6.98}
{'loss': 0.0297, 'grad_norm': 29.652406692504883, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.020741432905197144, 'loss_2': 0.0089569091796875, 'loss_3': -15.986653327941895, 'loss_4': 4.238735198974609, 'epoch': 6.98}
{'loss': 0.0439, 'grad_norm': 16.66338539123535, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.03417195752263069, 'loss_2': 0.0096893310546875, 'loss_3': -16.1744327545166, 'loss_4': 4.075305938720703, 'epoch': 6.99}
{'loss': 0.0215, 'grad_norm': 7.587975025177002, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.018049534410238266, 'loss_2': 0.003448486328125, 'loss_3': -16.226287841796875, 'loss_4': 4.244830131530762, 'epoch': 6.99}
{'loss': 0.0121, 'grad_norm': 7.246952533721924, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.006151998415589333, 'loss_2': 0.00595855712890625, 'loss_3': -15.966229438781738, 'loss_4': 4.228370666503906, 'epoch': 7.0}
{'loss': 0.0355, 'grad_norm': 9.310860633850098, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.020538296550512314, 'loss_2': 0.014984130859375, 'loss_3': -16.170522689819336, 'loss_4': 3.99543833732605, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 09:53:55,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:53:55,468 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:10<1:07:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:54:02,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02058596722781658, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007361842319369316, 'eval_loss_2': 0.013224124908447266, 'eval_loss_3': -18.36217498779297, 'eval_loss_4': 3.923666477203369, 'epoch': 7.01}
{'loss': 0.0546, 'grad_norm': 16.270118713378906, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.04154251888394356, 'loss_2': 0.01300811767578125, 'loss_3': -16.139484405517578, 'loss_4': 3.9780712127685547, 'epoch': 7.01}
{'loss': 0.0399, 'grad_norm': 8.209918975830078, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.022941285744309425, 'loss_2': 0.0169677734375, 'loss_3': -16.151264190673828, 'loss_4': 4.69545841217041, 'epoch': 7.02}
{'loss': 0.04, 'grad_norm': 7.723597526550293, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.026940330862998962, 'loss_2': 0.0130615234375, 'loss_3': -16.0947265625, 'loss_4': 4.472927093505859, 'epoch': 7.02}
{'loss': 0.0362, 'grad_norm': 15.091436386108398, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.028120221570134163, 'loss_2': 0.00812530517578125, 'loss_3': -16.02710723876953, 'loss_4': 4.383207321166992, 'epoch': 7.03}
{'loss': 0.0219, 'grad_norm': 6.507362365722656, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.018041692674160004, 'loss_2': 0.003841400146484375, 'loss_3': -16.115673065185547, 'loss_4': 3.8533220291137695, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 09:54:02,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:02,818 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:17<1:08:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:10,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011315491050481796, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.6, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008238960057497025, 'eval_loss_2': 0.0030765309929847717, 'eval_loss_3': -18.371173858642578, 'eval_loss_4': 4.0400896072387695, 'epoch': 7.03}
{'loss': 0.0328, 'grad_norm': 13.608589172363281, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.0280514657497406, 'loss_2': 0.00470733642578125, 'loss_3': -16.325162887573242, 'loss_4': 4.488269805908203, 'epoch': 7.04}
{'loss': 0.0251, 'grad_norm': 9.147113800048828, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.022585980594158173, 'loss_2': 0.002532958984375, 'loss_3': -16.072223663330078, 'loss_4': 4.0133771896362305, 'epoch': 7.05}
{'loss': 0.0242, 'grad_norm': 7.451571941375732, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.022193199023604393, 'loss_2': 0.001995086669921875, 'loss_3': -16.211580276489258, 'loss_4': 4.116920471191406, 'epoch': 7.05}
{'loss': 0.0252, 'grad_norm': 6.099689960479736, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.014912184327840805, 'loss_2': 0.01029205322265625, 'loss_3': -16.136194229125977, 'loss_4': 4.4854936599731445, 'epoch': 7.06}
{'loss': 0.0285, 'grad_norm': 6.586325168609619, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.020231157541275024, 'loss_2': 0.0082550048828125, 'loss_3': -16.275724411010742, 'loss_4': 4.617710590362549, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 09:54:10,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:10,181 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:24<1:08:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:17,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020487800240516663, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.127, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.00761820375919342, 'eval_loss_2': 0.012869596481323242, 'eval_loss_3': -18.3819580078125, 'eval_loss_4': 4.139213562011719, 'epoch': 7.06}
{'loss': 0.0394, 'grad_norm': 5.978692531585693, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.020755240693688393, 'loss_2': 0.01861572265625, 'loss_3': -16.131093978881836, 'loss_4': 3.9020612239837646, 'epoch': 7.07}
{'loss': 0.0436, 'grad_norm': 18.153972625732422, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.032348427921533585, 'loss_2': 0.01126861572265625, 'loss_3': -16.02759552001953, 'loss_4': 5.302495956420898, 'epoch': 7.08}
{'loss': 0.0305, 'grad_norm': 10.693634986877441, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.02522929199039936, 'loss_2': 0.00531768798828125, 'loss_3': -16.254444122314453, 'loss_4': 4.612540245056152, 'epoch': 7.08}
{'loss': 0.0351, 'grad_norm': 11.436028480529785, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.030151808634400368, 'loss_2': 0.004917144775390625, 'loss_3': -16.225051879882812, 'loss_4': 4.0842742919921875, 'epoch': 7.09}
{'loss': 0.0232, 'grad_norm': 7.281366348266602, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.02025136910378933, 'loss_2': 0.002899169921875, 'loss_3': -16.111785888671875, 'loss_4': 4.225688934326172, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 09:54:17,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:17,560 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:32<1:08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:24,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01285908930003643, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.79, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008101803250610828, 'eval_loss_2': 0.004757285118103027, 'eval_loss_3': -18.391159057617188, 'eval_loss_4': 4.081710338592529, 'epoch': 7.09}
{'loss': 0.0378, 'grad_norm': 15.2434720993042, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.031626828014850616, 'loss_2': 0.00620269775390625, 'loss_3': -16.152999877929688, 'loss_4': 4.502554893493652, 'epoch': 7.1}
{'loss': 0.0343, 'grad_norm': 11.169757843017578, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.031505756080150604, 'loss_2': 0.002838134765625, 'loss_3': -16.280548095703125, 'loss_4': 5.081567764282227, 'epoch': 7.1}
{'loss': 0.0311, 'grad_norm': 10.520051002502441, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.03068511001765728, 'loss_2': 0.0003943443298339844, 'loss_3': -16.262187957763672, 'loss_4': 4.465659141540527, 'epoch': 7.11}
{'loss': 0.0204, 'grad_norm': 5.923779010772705, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.019352583214640617, 'loss_2': 0.0010023117065429688, 'loss_3': -16.07618522644043, 'loss_4': 4.181748390197754, 'epoch': 7.12}
{'loss': 0.0414, 'grad_norm': 7.109367370605469, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.031861696392297745, 'loss_2': 0.0095062255859375, 'loss_3': -16.00368309020996, 'loss_4': 3.9292101860046387, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 09:54:24,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:24,915 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:39<1:08:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:32,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013115604408085346, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.779, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008780259639024734, 'eval_loss_2': 0.004335343837738037, 'eval_loss_3': -18.41240692138672, 'eval_loss_4': 3.9720981121063232, 'epoch': 7.12}
{'loss': 0.045, 'grad_norm': 11.145910263061523, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.037297818809747696, 'loss_2': 0.00769805908203125, 'loss_3': -16.115657806396484, 'loss_4': 4.585243225097656, 'epoch': 7.13}
{'loss': 0.0395, 'grad_norm': 17.147666931152344, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.03752659261226654, 'loss_2': 0.0019397735595703125, 'loss_3': -16.44634246826172, 'loss_4': 4.06382942199707, 'epoch': 7.13}
{'loss': 0.0533, 'grad_norm': 13.914459228515625, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.050086211413145065, 'loss_2': 0.003238677978515625, 'loss_3': -16.195131301879883, 'loss_4': 3.245249032974243, 'epoch': 7.14}
{'loss': 0.0181, 'grad_norm': 8.596735000610352, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.017208797857165337, 'loss_2': 0.0009350776672363281, 'loss_3': -16.309518814086914, 'loss_4': 3.99990177154541, 'epoch': 7.15}
{'loss': 0.0683, 'grad_norm': 16.24043083190918, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.06424053013324738, 'loss_2': 0.00403594970703125, 'loss_3': -15.991802215576172, 'loss_4': 4.229227066040039, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 09:54:32,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:32,268 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:46<1:07:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:39,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014931027777493, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.741, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009829582646489143, 'eval_loss_2': 0.005101442337036133, 'eval_loss_3': -18.421993255615234, 'eval_loss_4': 3.869948625564575, 'epoch': 7.15}
{'loss': 0.0379, 'grad_norm': 7.870495796203613, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.03087589703500271, 'loss_2': 0.00707244873046875, 'loss_3': -16.172985076904297, 'loss_4': 3.865396499633789, 'epoch': 7.16}
{'loss': 0.0607, 'grad_norm': 15.701518058776855, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.052153535187244415, 'loss_2': 0.0084991455078125, 'loss_3': -16.168956756591797, 'loss_4': 4.458868980407715, 'epoch': 7.16}
{'loss': 0.0286, 'grad_norm': 8.974392890930176, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.02787427417933941, 'loss_2': 0.0007715225219726562, 'loss_3': -16.292049407958984, 'loss_4': 4.014605522155762, 'epoch': 7.17}
{'loss': 0.0266, 'grad_norm': 8.194994926452637, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.02302197925746441, 'loss_2': 0.0035572052001953125, 'loss_3': -16.311065673828125, 'loss_4': 3.7272229194641113, 'epoch': 7.17}
{'loss': 0.0336, 'grad_norm': 6.681352615356445, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.02447960153222084, 'loss_2': 0.0091552734375, 'loss_3': -16.334030151367188, 'loss_4': 4.2358198165893555, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 09:54:39,622 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:39,622 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:54<1:07:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:46,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015033671632409096, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.674, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00939110666513443, 'eval_loss_2': 0.005642563104629517, 'eval_loss_3': -18.42890739440918, 'eval_loss_4': 3.669419765472412, 'epoch': 7.18}
{'loss': 0.0361, 'grad_norm': 10.716312408447266, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.03523750230669975, 'loss_2': 0.000827789306640625, 'loss_3': -16.176424026489258, 'loss_4': 3.855883836746216, 'epoch': 7.19}
{'loss': 0.0588, 'grad_norm': 13.89378833770752, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.0522291399538517, 'loss_2': 0.006561279296875, 'loss_3': -16.216527938842773, 'loss_4': 3.8777666091918945, 'epoch': 7.19}
{'loss': 0.0405, 'grad_norm': 8.597227096557617, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.029955744743347168, 'loss_2': 0.010528564453125, 'loss_3': -16.36914825439453, 'loss_4': 3.256885051727295, 'epoch': 7.2}
{'loss': 0.0499, 'grad_norm': 12.507454872131348, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.0436013787984848, 'loss_2': 0.006298065185546875, 'loss_3': -16.405040740966797, 'loss_4': 3.677393913269043, 'epoch': 7.2}
{'loss': 0.0427, 'grad_norm': 17.173166275024414, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.038530133664608, 'loss_2': 0.004150390625, 'loss_3': -16.40440559387207, 'loss_4': 3.9392411708831787, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 09:54:46,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:46,976 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:01<1:07:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:54:54,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011014463379979134, 'eval_runtime': 3.8266, 'eval_samples_per_second': 267.604, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.007640899624675512, 'eval_loss_2': 0.003373563289642334, 'eval_loss_3': -18.417980194091797, 'eval_loss_4': 3.538357973098755, 'epoch': 7.21}
{'loss': 0.0202, 'grad_norm': 6.960620880126953, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.015463007614016533, 'loss_2': 0.004703521728515625, 'loss_3': -16.484451293945312, 'loss_4': 3.2693839073181152, 'epoch': 7.22}
{'loss': 0.0595, 'grad_norm': 21.65642547607422, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.05566584691405296, 'loss_2': 0.003818511962890625, 'loss_3': -16.332897186279297, 'loss_4': 3.650852680206299, 'epoch': 7.22}
{'loss': 0.0224, 'grad_norm': 6.916919708251953, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.01707666739821434, 'loss_2': 0.005340576171875, 'loss_3': -16.181110382080078, 'loss_4': 3.7981534004211426, 'epoch': 7.23}
{'loss': 0.0499, 'grad_norm': 20.643146514892578, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.04277516156435013, 'loss_2': 0.00711822509765625, 'loss_3': -16.277700424194336, 'loss_4': 3.6882028579711914, 'epoch': 7.23}
{'loss': 0.0385, 'grad_norm': 9.795835494995117, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.036126017570495605, 'loss_2': 0.0023250579833984375, 'loss_3': -16.245201110839844, 'loss_4': 3.5247764587402344, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 09:54:54,343 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:54:54,343 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:08<1:07:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:01,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015417337417602539, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00766068696975708, 'eval_loss_2': 0.007756650447845459, 'eval_loss_3': -18.421539306640625, 'eval_loss_4': 3.5687129497528076, 'epoch': 7.24}
{'loss': 0.0278, 'grad_norm': 10.967893600463867, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.02105577476322651, 'loss_2': 0.006744384765625, 'loss_3': -16.298397064208984, 'loss_4': 3.4881887435913086, 'epoch': 7.24}
{'loss': 0.027, 'grad_norm': 9.883516311645508, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.024657845497131348, 'loss_2': 0.0022983551025390625, 'loss_3': -16.182456970214844, 'loss_4': 3.9489543437957764, 'epoch': 7.25}
{'loss': 0.0158, 'grad_norm': 6.514045238494873, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.014730066992342472, 'loss_2': 0.001064300537109375, 'loss_3': -16.34065818786621, 'loss_4': 4.121752738952637, 'epoch': 7.26}
{'loss': 0.0221, 'grad_norm': 5.621323585510254, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.012209796346724033, 'loss_2': 0.0098419189453125, 'loss_3': -16.301376342773438, 'loss_4': 4.329504013061523, 'epoch': 7.26}
{'loss': 0.0246, 'grad_norm': 6.649799346923828, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.015195811167359352, 'loss_2': 0.0094146728515625, 'loss_3': -16.28046417236328, 'loss_4': 4.085440158843994, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 09:55:01,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:01,701 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:16<1:07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:09,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010965829715132713, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006701415870338678, 'eval_loss_2': 0.004264414310455322, 'eval_loss_3': -18.422622680664062, 'eval_loss_4': 3.709002733230591, 'epoch': 7.27}
{'loss': 0.016, 'grad_norm': 5.8364739418029785, 'learning_rate': 2.275e-05, 'loss_1': 0.01438436470925808, 'loss_2': 0.0016574859619140625, 'loss_3': -16.319175720214844, 'loss_4': 4.215579032897949, 'epoch': 7.27}
{'loss': 0.0261, 'grad_norm': 5.774044036865234, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.016277631744742393, 'loss_2': 0.00978851318359375, 'loss_3': -16.291717529296875, 'loss_4': 3.8148937225341797, 'epoch': 7.28}
{'loss': 0.025, 'grad_norm': 6.827375411987305, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.018575171008706093, 'loss_2': 0.006427764892578125, 'loss_3': -16.349136352539062, 'loss_4': 3.5635628700256348, 'epoch': 7.28}
{'loss': 0.0206, 'grad_norm': 5.713396072387695, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.012101519852876663, 'loss_2': 0.008544921875, 'loss_3': -16.306062698364258, 'loss_4': 4.1147966384887695, 'epoch': 7.29}
{'loss': 0.0197, 'grad_norm': 6.638626575469971, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.018239814788103104, 'loss_2': 0.0014286041259765625, 'loss_3': -16.225616455078125, 'loss_4': 4.400940418243408, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 09:55:09,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:09,052 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:23<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:16,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011178911663591862, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.117, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007961363531649113, 'eval_loss_2': 0.003217548131942749, 'eval_loss_3': -18.411579132080078, 'eval_loss_4': 3.4384689331054688, 'epoch': 7.3}
{'loss': 0.0323, 'grad_norm': 9.849313735961914, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.023587537929415703, 'loss_2': 0.0086822509765625, 'loss_3': -16.200057983398438, 'loss_4': 4.024958610534668, 'epoch': 7.3}
{'loss': 0.0263, 'grad_norm': 9.572546005249023, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.02002977952361107, 'loss_2': 0.00629425048828125, 'loss_3': -16.14626693725586, 'loss_4': 3.0848801136016846, 'epoch': 7.31}
{'loss': 0.0298, 'grad_norm': 12.618258476257324, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.02852577343583107, 'loss_2': 0.001312255859375, 'loss_3': -16.382568359375, 'loss_4': 3.377352714538574, 'epoch': 7.31}
{'loss': 0.0182, 'grad_norm': 6.905757904052734, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.017762532457709312, 'loss_2': 0.0004093647003173828, 'loss_3': -16.23775291442871, 'loss_4': 3.336829900741577, 'epoch': 7.32}
{'loss': 0.0212, 'grad_norm': 8.283483505249023, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.01752142608165741, 'loss_2': 0.003650665283203125, 'loss_3': -16.249942779541016, 'loss_4': 2.830854892730713, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 09:55:16,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:16,400 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:30<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:23,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010969625785946846, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007777408696711063, 'eval_loss_2': 0.003192216157913208, 'eval_loss_3': -18.398279190063477, 'eval_loss_4': 3.077610969543457, 'epoch': 7.33}
{'loss': 0.038, 'grad_norm': 14.195135116577148, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.03570105507969856, 'loss_2': 0.002277374267578125, 'loss_3': -16.418319702148438, 'loss_4': 3.8569419384002686, 'epoch': 7.33}
{'loss': 0.0401, 'grad_norm': 17.725257873535156, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.03598488122224808, 'loss_2': 0.004150390625, 'loss_3': -16.2208251953125, 'loss_4': 2.9981021881103516, 'epoch': 7.34}
{'loss': 0.0246, 'grad_norm': 10.074357032775879, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.02137833833694458, 'loss_2': 0.0032634735107421875, 'loss_3': -16.261598587036133, 'loss_4': 2.9367752075195312, 'epoch': 7.34}
{'loss': 0.0252, 'grad_norm': 5.345229148864746, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.015025469474494457, 'loss_2': 0.0101318359375, 'loss_3': -16.258901596069336, 'loss_4': 2.726038932800293, 'epoch': 7.35}
{'loss': 0.0197, 'grad_norm': 5.918673515319824, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.012207206338644028, 'loss_2': 0.007450103759765625, 'loss_3': -16.194196701049805, 'loss_4': 3.196664333343506, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 09:55:23,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:23,757 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:38<1:07:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:31,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012652512639760971, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008513836190104485, 'eval_loss_2': 0.004138678312301636, 'eval_loss_3': -18.3848876953125, 'eval_loss_4': 2.847618579864502, 'epoch': 7.35}
{'loss': 0.0403, 'grad_norm': 12.468192100524902, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.03677021339535713, 'loss_2': 0.0034923553466796875, 'loss_3': -16.23080825805664, 'loss_4': 2.5605969429016113, 'epoch': 7.36}
{'loss': 0.0267, 'grad_norm': 12.090274810791016, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.0240649227052927, 'loss_2': 0.0026607513427734375, 'loss_3': -16.104625701904297, 'loss_4': 3.1969919204711914, 'epoch': 7.37}
{'loss': 0.0133, 'grad_norm': 6.298496723175049, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.012194452807307243, 'loss_2': 0.0011281967163085938, 'loss_3': -16.287952423095703, 'loss_4': 3.117506265640259, 'epoch': 7.37}
{'loss': 0.0211, 'grad_norm': 6.341061592102051, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.018846318125724792, 'loss_2': 0.00223541259765625, 'loss_3': -16.220144271850586, 'loss_4': 3.1169791221618652, 'epoch': 7.38}
{'loss': 0.0414, 'grad_norm': 10.932571411132812, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.03238512948155403, 'loss_2': 0.00901031494140625, 'loss_3': -16.260974884033203, 'loss_4': 3.0771076679229736, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 09:55:31,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:31,103 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:45<1:07:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:38,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01598866656422615, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.038, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007919508963823318, 'eval_loss_2': 0.008069157600402832, 'eval_loss_3': -18.386077880859375, 'eval_loss_4': 2.703598976135254, 'epoch': 7.38}
{'loss': 0.0366, 'grad_norm': 8.963593482971191, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.02659166045486927, 'loss_2': 0.0100250244140625, 'loss_3': -16.36865997314453, 'loss_4': 2.7339587211608887, 'epoch': 7.39}
{'loss': 0.0402, 'grad_norm': 9.35836124420166, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.03350850194692612, 'loss_2': 0.0066680908203125, 'loss_3': -16.31949806213379, 'loss_4': 2.8667099475860596, 'epoch': 7.4}
{'loss': 0.0161, 'grad_norm': 5.064176559448242, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.011615771800279617, 'loss_2': 0.0044403076171875, 'loss_3': -16.367782592773438, 'loss_4': 2.920642614364624, 'epoch': 7.4}
{'loss': 0.0299, 'grad_norm': 5.37243127822876, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.012873571366071701, 'loss_2': 0.0170440673828125, 'loss_3': -16.14641571044922, 'loss_4': 3.6104485988616943, 'epoch': 7.41}
{'loss': 0.0423, 'grad_norm': 11.847187995910645, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.03748953714966774, 'loss_2': 0.004791259765625, 'loss_3': -16.045623779296875, 'loss_4': 2.6456940174102783, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 09:55:38,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:38,457 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:53<1:07:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:45,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012558852322399616, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00805241335183382, 'eval_loss_2': 0.004506438970565796, 'eval_loss_3': -18.415910720825195, 'eval_loss_4': 2.491705894470215, 'epoch': 7.41}
{'loss': 0.0532, 'grad_norm': 20.38567543029785, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.04866373911499977, 'loss_2': 0.004550933837890625, 'loss_3': -15.984749794006348, 'loss_4': 2.7165565490722656, 'epoch': 7.42}
{'loss': 0.0506, 'grad_norm': 10.555948257446289, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.044934216886758804, 'loss_2': 0.00562286376953125, 'loss_3': -16.17559051513672, 'loss_4': 2.3304026126861572, 'epoch': 7.42}
{'loss': 0.035, 'grad_norm': 9.900583267211914, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.030855650082230568, 'loss_2': 0.0041046142578125, 'loss_3': -16.19820785522461, 'loss_4': 2.9595932960510254, 'epoch': 7.43}
{'loss': 0.0525, 'grad_norm': 13.612580299377441, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.042867470532655716, 'loss_2': 0.0096435546875, 'loss_3': -16.174171447753906, 'loss_4': 2.0937092304229736, 'epoch': 7.44}
{'loss': 0.0451, 'grad_norm': 10.65454387664795, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.03311588242650032, 'loss_2': 0.0119476318359375, 'loss_3': -16.1278018951416, 'loss_4': 2.434615135192871, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 09:55:45,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:45,800 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:00<1:06:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:55:53,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013110201805830002, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.877, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008098547346889973, 'eval_loss_2': 0.005011655390262604, 'eval_loss_3': -18.42182159423828, 'eval_loss_4': 2.3265414237976074, 'epoch': 7.44}
{'loss': 0.0416, 'grad_norm': 11.02344799041748, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.040935367345809937, 'loss_2': 0.00066375732421875, 'loss_3': -16.094026565551758, 'loss_4': 3.0210461616516113, 'epoch': 7.45}
{'loss': 0.0291, 'grad_norm': 6.815080165863037, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.020764965564012527, 'loss_2': 0.00830078125, 'loss_3': -16.141857147216797, 'loss_4': 2.508735179901123, 'epoch': 7.45}
{'loss': 0.0211, 'grad_norm': 7.9296674728393555, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.016247088089585304, 'loss_2': 0.00482177734375, 'loss_3': -16.270465850830078, 'loss_4': 2.4120001792907715, 'epoch': 7.46}
{'loss': 0.0121, 'grad_norm': 5.247059345245361, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.01196080632507801, 'loss_2': 0.0001857280731201172, 'loss_3': -16.191633224487305, 'loss_4': 2.2977824211120605, 'epoch': 7.47}
{'loss': 0.0174, 'grad_norm': 6.607330799102783, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.015420136041939259, 'loss_2': 0.00201416015625, 'loss_3': -16.19043731689453, 'loss_4': 2.324342966079712, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 09:55:53,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:55:53,146 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:07<1:06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:00,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011754579842090607, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008318409323692322, 'eval_loss_2': 0.003436170518398285, 'eval_loss_3': -18.395565032958984, 'eval_loss_4': 1.9355746507644653, 'epoch': 7.47}
{'loss': 0.0854, 'grad_norm': 21.33405876159668, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.07812491804361343, 'loss_2': 0.007312774658203125, 'loss_3': -16.31240463256836, 'loss_4': 2.277907371520996, 'epoch': 7.48}
{'loss': 0.0221, 'grad_norm': 6.309514045715332, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.01964288018643856, 'loss_2': 0.0024261474609375, 'loss_3': -16.147850036621094, 'loss_4': 2.6371593475341797, 'epoch': 7.48}
{'loss': 0.0161, 'grad_norm': 5.866063117980957, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.013259531930088997, 'loss_2': 0.00286102294921875, 'loss_3': -16.25275421142578, 'loss_4': 1.7231338024139404, 'epoch': 7.49}
{'loss': 0.0142, 'grad_norm': 6.170419692993164, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.014037176966667175, 'loss_2': 0.00015997886657714844, 'loss_3': -16.39605140686035, 'loss_4': 1.9364089965820312, 'epoch': 7.49}
{'loss': 0.0316, 'grad_norm': 10.035379409790039, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.029036853462457657, 'loss_2': 0.0025463104248046875, 'loss_3': -16.0411319732666, 'loss_4': 1.0708818435668945, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 09:56:00,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:00,499 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:15<1:06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:07,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014167668297886848, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.771, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008068055845797062, 'eval_loss_2': 0.006099611520767212, 'eval_loss_3': -18.37809181213379, 'eval_loss_4': 1.6781011819839478, 'epoch': 7.5}
{'loss': 0.0297, 'grad_norm': 8.781234741210938, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.018615659326314926, 'loss_2': 0.0110931396484375, 'loss_3': -16.384967803955078, 'loss_4': 1.9352329969406128, 'epoch': 7.51}
{'loss': 0.0333, 'grad_norm': 12.596339225769043, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.021283192560076714, 'loss_2': 0.0120391845703125, 'loss_3': -16.26683807373047, 'loss_4': 2.2984156608581543, 'epoch': 7.51}
{'loss': 0.0436, 'grad_norm': 15.594894409179688, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.03688948601484299, 'loss_2': 0.00673675537109375, 'loss_3': -16.340173721313477, 'loss_4': 1.8166992664337158, 'epoch': 7.52}
{'loss': 0.0387, 'grad_norm': 14.426397323608398, 'learning_rate': 2.25e-05, 'loss_1': 0.03101896308362484, 'loss_2': 0.007709503173828125, 'loss_3': -15.909788131713867, 'loss_4': 2.0518858432769775, 'epoch': 7.52}
{'loss': 0.0195, 'grad_norm': 5.183603286743164, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.013001414947211742, 'loss_2': 0.00646209716796875, 'loss_3': -16.289852142333984, 'loss_4': 1.6596248149871826, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 09:56:07,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:07,849 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:22<1:06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:15,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011315695010125637, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.042, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.0073638614267110825, 'eval_loss_2': 0.00395183265209198, 'eval_loss_3': -18.355209350585938, 'eval_loss_4': 1.5257139205932617, 'epoch': 7.53}
{'loss': 0.0219, 'grad_norm': 8.40074634552002, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.020221535116434097, 'loss_2': 0.00164031982421875, 'loss_3': -16.268945693969727, 'loss_4': 1.7123589515686035, 'epoch': 7.53}
{'loss': 0.029, 'grad_norm': 8.67484188079834, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.02706838957965374, 'loss_2': 0.001964569091796875, 'loss_3': -16.291213989257812, 'loss_4': 1.820351243019104, 'epoch': 7.54}
{'loss': 0.03, 'grad_norm': 13.54913330078125, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.024934327229857445, 'loss_2': 0.00507354736328125, 'loss_3': -16.23192024230957, 'loss_4': 2.5258758068084717, 'epoch': 7.55}
{'loss': 0.0333, 'grad_norm': 14.089515686035156, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.028285689651966095, 'loss_2': 0.0050201416015625, 'loss_3': -16.071340560913086, 'loss_4': 2.3490653038024902, 'epoch': 7.55}
{'loss': 0.0149, 'grad_norm': 5.4176177978515625, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.010976051911711693, 'loss_2': 0.003936767578125, 'loss_3': -16.342164993286133, 'loss_4': 1.8114204406738281, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 09:56:15,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:15,215 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:29<1:06:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:22,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015042917802929878, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.595, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00686906510964036, 'eval_loss_2': 0.008173853158950806, 'eval_loss_3': -18.31415557861328, 'eval_loss_4': 1.3722455501556396, 'epoch': 7.56}
{'loss': 0.0202, 'grad_norm': 8.715059280395508, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.018043560907244682, 'loss_2': 0.0021953582763671875, 'loss_3': -16.216976165771484, 'loss_4': 1.9140894412994385, 'epoch': 7.56}
{'loss': 0.0271, 'grad_norm': 9.616997718811035, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.021793153136968613, 'loss_2': 0.005275726318359375, 'loss_3': -15.92269515991211, 'loss_4': 1.490638256072998, 'epoch': 7.57}
{'loss': 0.0222, 'grad_norm': 7.0496039390563965, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.016010550782084465, 'loss_2': 0.00616455078125, 'loss_3': -16.14625358581543, 'loss_4': 1.0616018772125244, 'epoch': 7.58}
{'loss': 0.0271, 'grad_norm': 13.16869068145752, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.020728018134832382, 'loss_2': 0.00632476806640625, 'loss_3': -15.989152908325195, 'loss_4': 1.1084235906600952, 'epoch': 7.58}
{'loss': 0.0237, 'grad_norm': 8.30410385131836, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.021447427570819855, 'loss_2': 0.002288818359375, 'loss_3': -16.246292114257812, 'loss_4': 0.8394770622253418, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 09:56:22,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:22,558 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:37<1:06:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:29,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010288359597325325, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006641702260822058, 'eval_loss_2': 0.00364665687084198, 'eval_loss_3': -18.277494430541992, 'eval_loss_4': 0.953174889087677, 'epoch': 7.59}
{'loss': 0.0386, 'grad_norm': 15.331096649169922, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.03552217036485672, 'loss_2': 0.003086090087890625, 'loss_3': -16.069835662841797, 'loss_4': 0.9393341541290283, 'epoch': 7.59}
{'loss': 0.0292, 'grad_norm': 7.394873142242432, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.027131495997309685, 'loss_2': 0.0020751953125, 'loss_3': -16.123624801635742, 'loss_4': 1.165511131286621, 'epoch': 7.6}
{'loss': 0.0469, 'grad_norm': 14.3860445022583, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.045536141842603683, 'loss_2': 0.00133514404296875, 'loss_3': -16.171669006347656, 'loss_4': 1.1246647834777832, 'epoch': 7.6}
{'loss': 0.0205, 'grad_norm': 6.419254302978516, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.01703808829188347, 'loss_2': 0.003452301025390625, 'loss_3': -16.20826530456543, 'loss_4': 1.4607853889465332, 'epoch': 7.61}
{'loss': 0.0182, 'grad_norm': 6.641869068145752, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.013162103481590748, 'loss_2': 0.0050048828125, 'loss_3': -16.191186904907227, 'loss_4': 1.1406556367874146, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 09:56:29,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:29,901 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:44<1:06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:37,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010599268600344658, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.949, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006344044115394354, 'eval_loss_2': 0.004255224019289017, 'eval_loss_3': -18.264080047607422, 'eval_loss_4': 0.8323653340339661, 'epoch': 7.62}
{'loss': 0.0156, 'grad_norm': 5.858699321746826, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.015014450997114182, 'loss_2': 0.0005550384521484375, 'loss_3': -16.248924255371094, 'loss_4': 0.39828765392303467, 'epoch': 7.62}
{'loss': 0.0202, 'grad_norm': 8.437514305114746, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.01940144971013069, 'loss_2': 0.000797271728515625, 'loss_3': -16.29326057434082, 'loss_4': 0.875718355178833, 'epoch': 7.63}
{'loss': 0.0099, 'grad_norm': 5.6837544441223145, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.009470069780945778, 'loss_2': 0.0003952980041503906, 'loss_3': -16.068571090698242, 'loss_4': 0.761152982711792, 'epoch': 7.63}
{'loss': 0.0248, 'grad_norm': 9.94705867767334, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.022160671651363373, 'loss_2': 0.002674102783203125, 'loss_3': -16.08324432373047, 'loss_4': 1.162869930267334, 'epoch': 7.64}
{'loss': 0.0485, 'grad_norm': 20.113893508911133, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.04004892334342003, 'loss_2': 0.00843048095703125, 'loss_3': -16.041255950927734, 'loss_4': 0.9049261808395386, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 09:56:37,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:37,242 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:51<1:06:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:44,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015045784413814545, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005717895459383726, 'eval_loss_2': 0.009327888488769531, 'eval_loss_3': -18.25933074951172, 'eval_loss_4': 0.7617677450180054, 'epoch': 7.65}
{'loss': 0.0259, 'grad_norm': 6.370248794555664, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.012806160375475883, 'loss_2': 0.01306915283203125, 'loss_3': -15.966559410095215, 'loss_4': 0.34636715054512024, 'epoch': 7.65}
{'loss': 0.0152, 'grad_norm': 7.558856010437012, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.011262583546340466, 'loss_2': 0.003917694091796875, 'loss_3': -16.236576080322266, 'loss_4': 1.5025084018707275, 'epoch': 7.66}
{'loss': 0.0317, 'grad_norm': 10.183606147766113, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.024360593408346176, 'loss_2': 0.007350921630859375, 'loss_3': -15.896909713745117, 'loss_4': 1.1429572105407715, 'epoch': 7.66}
{'loss': 0.0263, 'grad_norm': 5.969302177429199, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.016040632501244545, 'loss_2': 0.01024627685546875, 'loss_3': -16.097370147705078, 'loss_4': 0.773067057132721, 'epoch': 7.67}
{'loss': 0.0205, 'grad_norm': 6.457735061645508, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.01355120912194252, 'loss_2': 0.006927490234375, 'loss_3': -16.192392349243164, 'loss_4': 0.32132476568222046, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 09:56:44,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:44,591 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [32:59<1:06:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:56:51,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012251066043972969, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.288, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006230504252016544, 'eval_loss_2': 0.00602056086063385, 'eval_loss_3': -18.252595901489258, 'eval_loss_4': 0.6124088764190674, 'epoch': 7.67}
{'loss': 0.0131, 'grad_norm': 5.845826148986816, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.009133409708738327, 'loss_2': 0.0039825439453125, 'loss_3': -15.942984580993652, 'loss_4': 0.7661235928535461, 'epoch': 7.68}
{'loss': 0.0243, 'grad_norm': 8.75554084777832, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.019942188635468483, 'loss_2': 0.00435638427734375, 'loss_3': -15.928566932678223, 'loss_4': 0.7495662569999695, 'epoch': 7.69}
{'loss': 0.0225, 'grad_norm': 6.69710636138916, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.01719425432384014, 'loss_2': 0.00531005859375, 'loss_3': -16.023963928222656, 'loss_4': 0.7244468927383423, 'epoch': 7.69}
{'loss': 0.0336, 'grad_norm': 15.48359489440918, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.03200976923108101, 'loss_2': 0.0015583038330078125, 'loss_3': -16.02808380126953, 'loss_4': 0.1011466532945633, 'epoch': 7.7}
{'loss': 0.0317, 'grad_norm': 7.950189113616943, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.022067245095968246, 'loss_2': 0.0096282958984375, 'loss_3': -16.062257766723633, 'loss_4': 0.2927476167678833, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 09:56:51,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:51,947 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:06<1:09:45,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 09:56:59,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012056287378072739, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006556924898177385, 'eval_loss_2': 0.005499362945556641, 'eval_loss_3': -18.23572540283203, 'eval_loss_4': 0.28758174180984497, 'epoch': 7.7}
{'loss': 0.0222, 'grad_norm': 6.623207092285156, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.01531174499541521, 'loss_2': 0.006908416748046875, 'loss_3': -15.979249954223633, 'loss_4': 0.739891529083252, 'epoch': 7.71}
{'loss': 0.0231, 'grad_norm': 10.433424949645996, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.02037070505321026, 'loss_2': 0.00272369384765625, 'loss_3': -16.22998809814453, 'loss_4': 0.17738640308380127, 'epoch': 7.72}
{'loss': 0.021, 'grad_norm': 6.8094329833984375, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.015001446940004826, 'loss_2': 0.006015777587890625, 'loss_3': -16.078935623168945, 'loss_4': 0.38722944259643555, 'epoch': 7.72}
{'loss': 0.0225, 'grad_norm': 7.787120819091797, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.019180666655302048, 'loss_2': 0.0033512115478515625, 'loss_3': -16.28717803955078, 'loss_4': -0.11643415689468384, 'epoch': 7.73}
{'loss': 0.0228, 'grad_norm': 7.912199020385742, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.016306517645716667, 'loss_2': 0.00650787353515625, 'loss_3': -16.179845809936523, 'loss_4': 0.10452491044998169, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 09:56:59,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:56:59,479 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:14<1:06:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:57:06,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010992283001542091, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.821, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006640041712671518, 'eval_loss_2': 0.00435224175453186, 'eval_loss_3': -18.236854553222656, 'eval_loss_4': 0.041877273470163345, 'epoch': 7.73}
{'loss': 0.0227, 'grad_norm': 6.521109580993652, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.016986431553959846, 'loss_2': 0.00572967529296875, 'loss_3': -16.061519622802734, 'loss_4': -0.3541710078716278, 'epoch': 7.74}
{'loss': 0.0358, 'grad_norm': 7.963019847869873, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.026831207796931267, 'loss_2': 0.008941650390625, 'loss_3': -16.19449234008789, 'loss_4': 0.3665197193622589, 'epoch': 7.74}
{'loss': 0.0309, 'grad_norm': 8.870827674865723, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.02760789357125759, 'loss_2': 0.003314971923828125, 'loss_3': -16.139379501342773, 'loss_4': -0.8135360479354858, 'epoch': 7.75}
{'loss': 0.0272, 'grad_norm': 7.786962032318115, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.020473048090934753, 'loss_2': 0.00677490234375, 'loss_3': -15.988641738891602, 'loss_4': -0.4047269821166992, 'epoch': 7.76}
{'loss': 0.0152, 'grad_norm': 8.404226303100586, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.013514932245016098, 'loss_2': 0.001667022705078125, 'loss_3': -16.04078483581543, 'loss_4': -0.0017211586236953735, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 09:57:06,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:06,824 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:21<1:06:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:14,167 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011362692341208458, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.775, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0063673630356788635, 'eval_loss_2': 0.004995331168174744, 'eval_loss_3': -18.22714614868164, 'eval_loss_4': -0.0025919396430253983, 'epoch': 7.76}
{'loss': 0.068, 'grad_norm': 23.735105514526367, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.06511075794696808, 'loss_2': 0.002849578857421875, 'loss_3': -16.11884307861328, 'loss_4': 0.185863196849823, 'epoch': 7.77}
{'loss': 0.0232, 'grad_norm': 6.813873291015625, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.017879053950309753, 'loss_2': 0.005321502685546875, 'loss_3': -16.15367317199707, 'loss_4': -0.6469178199768066, 'epoch': 7.77}
{'loss': 0.0379, 'grad_norm': 9.937285423278809, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.03292420133948326, 'loss_2': 0.0049591064453125, 'loss_3': -16.131834030151367, 'loss_4': -0.36069440841674805, 'epoch': 7.78}
{'loss': 0.0264, 'grad_norm': 8.429443359375, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.02511685900390148, 'loss_2': 0.0012407302856445312, 'loss_3': -16.054580688476562, 'loss_4': 0.3027893304824829, 'epoch': 7.78}
{'loss': 0.0145, 'grad_norm': 6.113598346710205, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.012564781121909618, 'loss_2': 0.0019683837890625, 'loss_3': -15.877060890197754, 'loss_4': 0.060620516538619995, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 09:57:14,167 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:14,167 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:28<1:05:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:21,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01058270875364542, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.89, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006910943426191807, 'eval_loss_2': 0.0036717653274536133, 'eval_loss_3': -18.20171356201172, 'eval_loss_4': 0.0843103900551796, 'epoch': 7.79}
{'loss': 0.0163, 'grad_norm': 5.165655136108398, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.009377546608448029, 'loss_2': 0.006927490234375, 'loss_3': -16.07573127746582, 'loss_4': 0.14419493079185486, 'epoch': 7.8}
{'loss': 0.0279, 'grad_norm': 8.101970672607422, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.0221088994294405, 'loss_2': 0.0057525634765625, 'loss_3': -16.267471313476562, 'loss_4': 0.12641757726669312, 'epoch': 7.8}
{'loss': 0.0258, 'grad_norm': 7.459858417510986, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.016546595841646194, 'loss_2': 0.00927734375, 'loss_3': -15.98134708404541, 'loss_4': 0.28708070516586304, 'epoch': 7.81}
{'loss': 0.01, 'grad_norm': 5.369045257568359, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.006938223261386156, 'loss_2': 0.003101348876953125, 'loss_3': -16.237390518188477, 'loss_4': 0.4155060946941376, 'epoch': 7.81}
{'loss': 0.0215, 'grad_norm': 7.008890151977539, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.01378735899925232, 'loss_2': 0.007740020751953125, 'loss_3': -16.12063980102539, 'loss_4': -0.10655450075864792, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 09:57:21,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:21,518 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:36<1:05:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:28,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013923859223723412, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007583220489323139, 'eval_loss_2': 0.006340637803077698, 'eval_loss_3': -18.166217803955078, 'eval_loss_4': 0.19329656660556793, 'epoch': 7.82}
{'loss': 0.0381, 'grad_norm': 10.356882095336914, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.0293705053627491, 'loss_2': 0.008697509765625, 'loss_3': -16.019920349121094, 'loss_4': -0.24336428940296173, 'epoch': 7.83}
{'loss': 0.0232, 'grad_norm': 7.482610702514648, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.019407134503126144, 'loss_2': 0.003757476806640625, 'loss_3': -16.1479549407959, 'loss_4': 0.023493990302085876, 'epoch': 7.83}
{'loss': 0.0204, 'grad_norm': 8.667287826538086, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.01726769655942917, 'loss_2': 0.003143310546875, 'loss_3': -16.06500244140625, 'loss_4': 0.03303316980600357, 'epoch': 7.84}
{'loss': 0.0102, 'grad_norm': 6.037119388580322, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.009570094756782055, 'loss_2': 0.0006613731384277344, 'loss_3': -16.184358596801758, 'loss_4': 0.1187322586774826, 'epoch': 7.84}
{'loss': 0.0117, 'grad_norm': 5.464466094970703, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.010660113766789436, 'loss_2': 0.0010662078857421875, 'loss_3': -16.090343475341797, 'loss_4': 0.3166320323944092, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 09:57:28,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:28,872 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:43<1:05:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:36,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013717018067836761, 'eval_runtime': 3.8226, 'eval_samples_per_second': 267.883, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.008165411651134491, 'eval_loss_2': 0.0055516064167022705, 'eval_loss_3': -18.172874450683594, 'eval_loss_4': 0.25151264667510986, 'epoch': 7.85}
{'loss': 0.0258, 'grad_norm': 9.701043128967285, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.02266600728034973, 'loss_2': 0.003124237060546875, 'loss_3': -16.239572525024414, 'loss_4': 0.31592124700546265, 'epoch': 7.85}
{'loss': 0.0174, 'grad_norm': 5.922067165374756, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.011061059311032295, 'loss_2': 0.00632476806640625, 'loss_3': -15.940011024475098, 'loss_4': -0.5249216556549072, 'epoch': 7.86}
{'loss': 0.0123, 'grad_norm': 6.699664115905762, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.012253171764314175, 'loss_2': 5.1081180572509766e-05, 'loss_3': -16.107860565185547, 'loss_4': -0.017901577055454254, 'epoch': 7.87}
{'loss': 0.0149, 'grad_norm': 5.959389686584473, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.012713738717138767, 'loss_2': 0.0022125244140625, 'loss_3': -16.29623794555664, 'loss_4': 0.5629028081893921, 'epoch': 7.87}
{'loss': 0.0223, 'grad_norm': 5.964608192443848, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.013754425570368767, 'loss_2': 0.008575439453125, 'loss_3': -16.018917083740234, 'loss_4': 0.883636474609375, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 09:57:36,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:36,238 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:50<1:05:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:43,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015224417671561241, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.759, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007964927703142166, 'eval_loss_2': 0.007259488105773926, 'eval_loss_3': -18.231319427490234, 'eval_loss_4': 0.13235628604888916, 'epoch': 7.88}
{'loss': 0.0187, 'grad_norm': 12.357889175415039, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.0182825718075037, 'loss_2': 0.00039577484130859375, 'loss_3': -16.314720153808594, 'loss_4': 0.06857812404632568, 'epoch': 7.88}
{'loss': 0.027, 'grad_norm': 8.11501407623291, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.01834188774228096, 'loss_2': 0.00867462158203125, 'loss_3': -16.244218826293945, 'loss_4': 0.23433223366737366, 'epoch': 7.89}
{'loss': 0.0232, 'grad_norm': 5.828001976013184, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.013103771954774857, 'loss_2': 0.0100555419921875, 'loss_3': -16.351547241210938, 'loss_4': -0.2163083553314209, 'epoch': 7.9}
{'loss': 0.0235, 'grad_norm': 6.2219743728637695, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.013963775709271431, 'loss_2': 0.00954437255859375, 'loss_3': -16.297657012939453, 'loss_4': 0.37068748474121094, 'epoch': 7.9}
{'loss': 0.0633, 'grad_norm': 21.509883880615234, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.05796290189027786, 'loss_2': 0.005290985107421875, 'loss_3': -16.108612060546875, 'loss_4': 0.03530452027916908, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 09:57:43,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:43,590 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [33:58<1:05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:50,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012625184841454029, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.677, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008616609498858452, 'eval_loss_2': 0.004008576273918152, 'eval_loss_3': -18.26114845275879, 'eval_loss_4': 0.10037094354629517, 'epoch': 7.91}
{'loss': 0.032, 'grad_norm': 7.5919599533081055, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.024395162239670753, 'loss_2': 0.007556915283203125, 'loss_3': -16.287445068359375, 'loss_4': 0.1657552272081375, 'epoch': 7.91}
{'loss': 0.0271, 'grad_norm': 5.935930252075195, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.017779525369405746, 'loss_2': 0.0093231201171875, 'loss_3': -16.200607299804688, 'loss_4': 0.18809841573238373, 'epoch': 7.92}
{'loss': 0.0372, 'grad_norm': 9.841495513916016, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.02523246593773365, 'loss_2': 0.01200103759765625, 'loss_3': -16.20989418029785, 'loss_4': 0.157363623380661, 'epoch': 7.92}
{'loss': 0.0233, 'grad_norm': 6.7434868812561035, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.015229242853820324, 'loss_2': 0.00811767578125, 'loss_3': -16.297883987426758, 'loss_4': 0.29630404710769653, 'epoch': 7.93}
{'loss': 0.0458, 'grad_norm': 16.41443634033203, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.03406858816742897, 'loss_2': 0.01175689697265625, 'loss_3': -16.144235610961914, 'loss_4': 0.7384395599365234, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 09:57:50,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:50,941 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:05<1:05:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:57:58,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016151845455169678, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.071, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008816776797175407, 'eval_loss_2': 0.007335066795349121, 'eval_loss_3': -18.28540802001953, 'eval_loss_4': 0.4696865975856781, 'epoch': 7.94}
{'loss': 0.0335, 'grad_norm': 11.624062538146973, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.026683779433369637, 'loss_2': 0.0068511962890625, 'loss_3': -16.192684173583984, 'loss_4': 0.15785706043243408, 'epoch': 7.94}
{'loss': 0.0328, 'grad_norm': 14.45458984375, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.031689420342445374, 'loss_2': 0.00109100341796875, 'loss_3': -15.920202255249023, 'loss_4': 0.602975070476532, 'epoch': 7.95}
{'loss': 0.0213, 'grad_norm': 8.478446960449219, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.019606010988354683, 'loss_2': 0.001689910888671875, 'loss_3': -16.183225631713867, 'loss_4': 0.969870924949646, 'epoch': 7.95}
{'loss': 0.017, 'grad_norm': 7.004709243774414, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.014353089965879917, 'loss_2': 0.00260162353515625, 'loss_3': -16.08449935913086, 'loss_4': 0.755800724029541, 'epoch': 7.96}
{'loss': 0.0189, 'grad_norm': 7.378490924835205, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.017257938161492348, 'loss_2': 0.0016031265258789062, 'loss_3': -16.079118728637695, 'loss_4': 1.212015151977539, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 09:57:58,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:57:58,288 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:12<1:05:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 09:58:05,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014270907267928123, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.576, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.00909397378563881, 'eval_loss_2': 0.005176931619644165, 'eval_loss_3': -18.259174346923828, 'eval_loss_4': 0.9668099284172058, 'epoch': 7.97}
{'loss': 0.0232, 'grad_norm': 9.888327598571777, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.01798260025680065, 'loss_2': 0.0051727294921875, 'loss_3': -16.090959548950195, 'loss_4': 0.9975465536117554, 'epoch': 7.97}
{'loss': 0.0271, 'grad_norm': 6.979930400848389, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.016046961769461632, 'loss_2': 0.01104736328125, 'loss_3': -16.298444747924805, 'loss_4': 1.0254662036895752, 'epoch': 7.98}
{'loss': 0.0314, 'grad_norm': 8.243264198303223, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.030278492718935013, 'loss_2': 0.0010967254638671875, 'loss_3': -16.15351676940918, 'loss_4': 2.3049378395080566, 'epoch': 7.98}
{'loss': 0.0533, 'grad_norm': 14.24440860748291, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.051018696278333664, 'loss_2': 0.002231597900390625, 'loss_3': -16.399005889892578, 'loss_4': 1.0492315292358398, 'epoch': 7.99}
{'loss': 0.025, 'grad_norm': 7.319977283477783, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.018707744777202606, 'loss_2': 0.006317138671875, 'loss_3': -16.201337814331055, 'loss_4': 1.8751908540725708, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 09:58:05,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:05,624 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:19<1:04:08,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 09:58:12,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011220390908420086, 'eval_runtime': 3.8175, 'eval_samples_per_second': 268.241, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007226402871310711, 'eval_loss_2': 0.003993988037109375, 'eval_loss_3': -18.289453506469727, 'eval_loss_4': 1.359951138496399, 'epoch': 7.99}
{'loss': 0.0154, 'grad_norm': 8.76675033569336, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.015090547502040863, 'loss_2': 0.000286102294921875, 'loss_3': -16.237489700317383, 'loss_4': 0.6248854398727417, 'epoch': 8.0}
{'loss': 0.0188, 'grad_norm': 6.969232082366943, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.018414461985230446, 'loss_2': 0.00034546852111816406, 'loss_3': -16.154285430908203, 'loss_4': 2.0258431434631348, 'epoch': 8.01}
{'loss': 0.0214, 'grad_norm': 6.076218605041504, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.016187988221645355, 'loss_2': 0.005218505859375, 'loss_3': -16.242931365966797, 'loss_4': 0.9235239028930664, 'epoch': 8.01}
{'loss': 0.0258, 'grad_norm': 8.479884147644043, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.02038041315972805, 'loss_2': 0.00540924072265625, 'loss_3': -16.18157196044922, 'loss_4': 1.688100814819336, 'epoch': 8.02}
{'loss': 0.0144, 'grad_norm': 5.663434982299805, 'learning_rate': 2.2e-05, 'loss_1': 0.013076170347630978, 'loss_2': 0.0012874603271484375, 'loss_3': -16.10696029663086, 'loss_4': 1.3311052322387695, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 09:58:12,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:12,693 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:23<1:04:08,  1.02s/it][INFO|trainer.py:3910] 2025-01-21 09:58:16,513 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380
[INFO|configuration_utils.py:420] 2025-01-21 09:58:16,514 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380/config.json                                                                             
{'eval_loss': 0.00932545680552721, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.184, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006446593441069126, 'eval_loss_2': 0.002878863364458084, 'eval_loss_3': -18.266277313232422, 'eval_loss_4': 1.461217999458313, 'epoch': 8.02}
[INFO|modeling_utils.py:2988] 2025-01-21 09:58:17,000 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:58:17,002 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:58:17,002 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:58:17,953 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-865] due to args.save_total_limit
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:28<1:12:03,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:58:21,587 >>
{'loss': 0.0177, 'grad_norm': 9.665447235107422, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.017537370324134827, 'loss_2': 0.00011587142944335938, 'loss_3': -16.153018951416016, 'loss_4': 1.3988018035888672, 'epoch': 8.03}
{'loss': 0.0161, 'grad_norm': 8.741791725158691, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.014527247287333012, 'loss_2': 0.0015888214111328125, 'loss_3': -16.09098243713379, 'loss_4': 1.6797593832015991, 'epoch': 8.03}
{'loss': 0.0274, 'grad_norm': 8.145085334777832, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.021677689626812935, 'loss_2': 0.0057220458984375, 'loss_3': -16.231874465942383, 'loss_4': 1.4085571765899658, 'epoch': 8.04}
{'loss': 0.0129, 'grad_norm': 6.513506889343262, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.011875595897436142, 'loss_2': 0.001068115234375, 'loss_3': -16.192493438720703, 'loss_4': 1.107366919517517, 'epoch': 8.05}
{'loss': 0.0116, 'grad_norm': 6.507365703582764, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.010331208817660809, 'loss_2': 0.0012941360473632812, 'loss_3': -16.033153533935547, 'loss_4': 1.4095135927200317, 'epoch': 8.05}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:58:21,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:21,587 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:36<1:06:14,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:58:28,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010144544765353203, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005976063199341297, 'eval_loss_2': 0.004168480634689331, 'eval_loss_3': -18.273967742919922, 'eval_loss_4': 1.5266591310501099, 'epoch': 8.05}
{'loss': 0.0129, 'grad_norm': 6.219491958618164, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.010488742962479591, 'loss_2': 0.002445220947265625, 'loss_3': -16.199512481689453, 'loss_4': 2.003427743911743, 'epoch': 8.06}
{'loss': 0.0206, 'grad_norm': 18.765426635742188, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.019088691100478172, 'loss_2': 0.00146484375, 'loss_3': -16.132524490356445, 'loss_4': 1.8933064937591553, 'epoch': 8.06}
{'loss': 0.0187, 'grad_norm': 8.409831047058105, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.014115121215581894, 'loss_2': 0.00455474853515625, 'loss_3': -16.101764678955078, 'loss_4': 1.9551644325256348, 'epoch': 8.07}
{'loss': 0.0201, 'grad_norm': 4.894702911376953, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.005497327074408531, 'loss_2': 0.0145721435546875, 'loss_3': -16.3065185546875, 'loss_4': 1.0630178451538086, 'epoch': 8.08}
{'loss': 0.0141, 'grad_norm': 5.1572418212890625, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.00598404835909605, 'loss_2': 0.008087158203125, 'loss_3': -16.23775863647461, 'loss_4': 1.6472976207733154, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 09:58:28,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:28,930 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:43<1:05:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:36,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014682970941066742, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0052647218108177185, 'eval_loss_2': 0.009418249130249023, 'eval_loss_3': -18.252466201782227, 'eval_loss_4': 1.218043565750122, 'epoch': 8.08}
{'loss': 0.0203, 'grad_norm': 5.9158477783203125, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.011427115648984909, 'loss_2': 0.00882720947265625, 'loss_3': -16.112632751464844, 'loss_4': 1.626879096031189, 'epoch': 8.09}
{'loss': 0.0349, 'grad_norm': 13.640881538391113, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.03182236850261688, 'loss_2': 0.0030975341796875, 'loss_3': -16.286190032958984, 'loss_4': 0.6489660739898682, 'epoch': 8.09}
{'loss': 0.0161, 'grad_norm': 7.468047142028809, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.013415376655757427, 'loss_2': 0.0026397705078125, 'loss_3': -16.271804809570312, 'loss_4': 0.8279983401298523, 'epoch': 8.1}
{'loss': 0.0148, 'grad_norm': 5.344603538513184, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.010019530542194843, 'loss_2': 0.00475311279296875, 'loss_3': -16.094894409179688, 'loss_4': 1.4451125860214233, 'epoch': 8.1}
{'loss': 0.022, 'grad_norm': 8.596928596496582, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.016712060198187828, 'loss_2': 0.00530242919921875, 'loss_3': -16.218807220458984, 'loss_4': 1.2389531135559082, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 09:58:36,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:36,277 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:50<1:04:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:43,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009351694956421852, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.787, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005930566694587469, 'eval_loss_2': 0.0034211277961730957, 'eval_loss_3': -18.22231101989746, 'eval_loss_4': 1.0106874704360962, 'epoch': 8.11}
{'loss': 0.0222, 'grad_norm': 11.862129211425781, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.021964145824313164, 'loss_2': 0.00024580955505371094, 'loss_3': -16.033538818359375, 'loss_4': 1.7118823528289795, 'epoch': 8.12}
{'loss': 0.0172, 'grad_norm': 7.30869197845459, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.010366417467594147, 'loss_2': 0.00681304931640625, 'loss_3': -16.108501434326172, 'loss_4': 1.2787386178970337, 'epoch': 8.12}
{'loss': 0.0092, 'grad_norm': 5.262076377868652, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.007459843065589666, 'loss_2': 0.00177764892578125, 'loss_3': -16.266143798828125, 'loss_4': 0.6972452402114868, 'epoch': 8.13}
{'loss': 0.0339, 'grad_norm': 8.811419486999512, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.02526002936065197, 'loss_2': 0.00864410400390625, 'loss_3': -15.977195739746094, 'loss_4': 0.450296014547348, 'epoch': 8.13}
{'loss': 0.0242, 'grad_norm': 7.431893348693848, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.014859615825116634, 'loss_2': 0.00931549072265625, 'loss_3': -16.19440460205078, 'loss_4': 1.1785118579864502, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 09:58:43,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:43,624 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [34:58<1:04:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:50,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011175946332514286, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.513, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006016328930854797, 'eval_loss_2': 0.005159616470336914, 'eval_loss_3': -18.24945068359375, 'eval_loss_4': 0.7164544463157654, 'epoch': 8.14}
{'loss': 0.0357, 'grad_norm': 13.264811515808105, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.03193709999322891, 'loss_2': 0.003742218017578125, 'loss_3': -15.994219779968262, 'loss_4': 0.2139560878276825, 'epoch': 8.15}
{'loss': 0.0269, 'grad_norm': 9.760093688964844, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.023551661521196365, 'loss_2': 0.00333404541015625, 'loss_3': -16.445602416992188, 'loss_4': 0.4586106538772583, 'epoch': 8.15}
{'loss': 0.0307, 'grad_norm': 12.059331893920898, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.026338744908571243, 'loss_2': 0.00439453125, 'loss_3': -16.178041458129883, 'loss_4': 0.6276088953018188, 'epoch': 8.16}
{'loss': 0.0217, 'grad_norm': 7.090783596038818, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.01496750395745039, 'loss_2': 0.00673675537109375, 'loss_3': -16.319290161132812, 'loss_4': 1.3207414150238037, 'epoch': 8.16}
{'loss': 0.0212, 'grad_norm': 5.376711845397949, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.012284140102565289, 'loss_2': 0.0089569091796875, 'loss_3': -16.19520378112793, 'loss_4': 0.48062342405319214, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 09:58:50,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:50,981 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:05<1:04:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:58:58,345 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01319378986954689, 'eval_runtime': 3.8215, 'eval_samples_per_second': 267.955, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.007191005162894726, 'eval_loss_2': 0.00600278377532959, 'eval_loss_3': -18.285192489624023, 'eval_loss_4': 0.6111963987350464, 'epoch': 8.17}
{'loss': 0.0321, 'grad_norm': 11.450117111206055, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.02709188498556614, 'loss_2': 0.00504302978515625, 'loss_3': -16.34572982788086, 'loss_4': 0.34948164224624634, 'epoch': 8.17}
{'loss': 0.0198, 'grad_norm': 5.152989387512207, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.01412032451480627, 'loss_2': 0.00567626953125, 'loss_3': -16.245912551879883, 'loss_4': 1.2241300344467163, 'epoch': 8.18}
{'loss': 0.0138, 'grad_norm': 6.274730205535889, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.010831867344677448, 'loss_2': 0.00292205810546875, 'loss_3': -16.405406951904297, 'loss_4': 0.5753372311592102, 'epoch': 8.19}
{'loss': 0.0108, 'grad_norm': 4.766735553741455, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.010730001144111156, 'loss_2': 6.312131881713867e-05, 'loss_3': -16.425800323486328, 'loss_4': 0.7278030514717102, 'epoch': 8.19}
{'loss': 0.0242, 'grad_norm': 8.866147994995117, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.023513322696089745, 'loss_2': 0.0006608963012695312, 'loss_3': -16.449987411499023, 'loss_4': 1.9090495109558105, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 09:58:58,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:58:58,345 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:12<1:04:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:05,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013706669211387634, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.524, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008709006011486053, 'eval_loss_2': 0.004997663199901581, 'eval_loss_3': -18.331928253173828, 'eval_loss_4': 0.7529987096786499, 'epoch': 8.2}
{'loss': 0.034, 'grad_norm': 11.095577239990234, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.027894379571080208, 'loss_2': 0.0061187744140625, 'loss_3': -16.34685516357422, 'loss_4': 0.8684113025665283, 'epoch': 8.2}
{'loss': 0.0167, 'grad_norm': 6.86596155166626, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.015917165204882622, 'loss_2': 0.0008296966552734375, 'loss_3': -16.313846588134766, 'loss_4': 1.2119114398956299, 'epoch': 8.21}
{'loss': 0.0274, 'grad_norm': 8.03764820098877, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.024382147938013077, 'loss_2': 0.002986907958984375, 'loss_3': -16.44304847717285, 'loss_4': 0.9265671968460083, 'epoch': 8.22}
{'loss': 0.0263, 'grad_norm': 9.713240623474121, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.022888239473104477, 'loss_2': 0.003398895263671875, 'loss_3': -16.416759490966797, 'loss_4': 0.5717822313308716, 'epoch': 8.22}
{'loss': 0.0286, 'grad_norm': 7.441699028015137, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.023035502061247826, 'loss_2': 0.00555419921875, 'loss_3': -16.34992218017578, 'loss_4': 0.8598208427429199, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 09:59:05,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:05,697 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:20<1:04:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:13,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01352720521390438, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.424, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009456543251872063, 'eval_loss_2': 0.004070661962032318, 'eval_loss_3': -18.337364196777344, 'eval_loss_4': 1.1260147094726562, 'epoch': 8.23}
{'loss': 0.0469, 'grad_norm': 11.342347145080566, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.0455063134431839, 'loss_2': 0.0013484954833984375, 'loss_3': -16.310251235961914, 'loss_4': 1.4335614442825317, 'epoch': 8.23}
{'loss': 0.0156, 'grad_norm': 5.994133472442627, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.01226145587861538, 'loss_2': 0.003387451171875, 'loss_3': -16.234172821044922, 'loss_4': 1.5187819004058838, 'epoch': 8.24}
{'loss': 0.0369, 'grad_norm': 11.318633079528809, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.026931317523121834, 'loss_2': 0.00994873046875, 'loss_3': -16.458892822265625, 'loss_4': 1.518261432647705, 'epoch': 8.24}
{'loss': 0.0713, 'grad_norm': 18.6910457611084, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.0629926323890686, 'loss_2': 0.0082855224609375, 'loss_3': -16.330904006958008, 'loss_4': 1.415052056312561, 'epoch': 8.25}
{'loss': 0.0332, 'grad_norm': 6.589284896850586, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.01777711510658264, 'loss_2': 0.015472412109375, 'loss_3': -16.408355712890625, 'loss_4': 1.963285207748413, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 09:59:13,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:13,050 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:27<1:04:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:20,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020696882158517838, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.764, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00953221507370472, 'eval_loss_2': 0.011164665222167969, 'eval_loss_3': -18.34214973449707, 'eval_loss_4': 1.3629924058914185, 'epoch': 8.26}
{'loss': 0.0702, 'grad_norm': 16.476408004760742, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.05023045465350151, 'loss_2': 0.02001953125, 'loss_3': -16.230941772460938, 'loss_4': 1.1495481729507446, 'epoch': 8.26}
{'loss': 0.0677, 'grad_norm': 19.89557456970215, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.05726552754640579, 'loss_2': 0.01043701171875, 'loss_3': -16.363216400146484, 'loss_4': 1.1472856998443604, 'epoch': 8.27}
{'loss': 0.0538, 'grad_norm': 16.68983268737793, 'learning_rate': 2.175e-05, 'loss_1': 0.044708237051963806, 'loss_2': 0.009063720703125, 'loss_3': -16.374439239501953, 'loss_4': 1.3858506679534912, 'epoch': 8.27}
{'loss': 0.0167, 'grad_norm': 6.639284610748291, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.013758484274148941, 'loss_2': 0.002895355224609375, 'loss_3': -16.430591583251953, 'loss_4': 1.3139569759368896, 'epoch': 8.28}
{'loss': 0.0254, 'grad_norm': 6.0601115226745605, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.013526738621294498, 'loss_2': 0.0118865966796875, 'loss_3': -16.42110824584961, 'loss_4': 1.539637565612793, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 09:59:20,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:20,431 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:34<1:04:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:27,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01219659112393856, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00831067468971014, 'eval_loss_2': 0.003885917365550995, 'eval_loss_3': -18.312911987304688, 'eval_loss_4': 1.6330413818359375, 'epoch': 8.28}
{'loss': 0.0321, 'grad_norm': 14.382688522338867, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.02945270761847496, 'loss_2': 0.00267791748046875, 'loss_3': -16.356006622314453, 'loss_4': 1.7190511226654053, 'epoch': 8.29}
{'loss': 0.0216, 'grad_norm': 8.280616760253906, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.01889580860733986, 'loss_2': 0.002696990966796875, 'loss_3': -16.422683715820312, 'loss_4': 1.977545976638794, 'epoch': 8.3}
{'loss': 0.0162, 'grad_norm': 6.846789836883545, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.01578587107360363, 'loss_2': 0.0004210472106933594, 'loss_3': -16.413047790527344, 'loss_4': 2.2720186710357666, 'epoch': 8.3}
{'loss': 0.0266, 'grad_norm': 7.784910678863525, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.022055217996239662, 'loss_2': 0.004505157470703125, 'loss_3': -16.261699676513672, 'loss_4': 2.515533924102783, 'epoch': 8.31}
{'loss': 0.0303, 'grad_norm': 6.966763019561768, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.017248816788196564, 'loss_2': 0.0130157470703125, 'loss_3': -16.295215606689453, 'loss_4': 2.260530948638916, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 09:59:27,777 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:27,777 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:42<1:04:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:35,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01260245218873024, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006818943656980991, 'eval_loss_2': 0.005783509463071823, 'eval_loss_3': -18.295677185058594, 'eval_loss_4': 1.524418592453003, 'epoch': 8.31}
{'loss': 0.0245, 'grad_norm': 9.332135200500488, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.017439380288124084, 'loss_2': 0.00710296630859375, 'loss_3': -16.296228408813477, 'loss_4': 1.6863090991973877, 'epoch': 8.32}
{'loss': 0.0266, 'grad_norm': 8.149735450744629, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.02276069112122059, 'loss_2': 0.0038356781005859375, 'loss_3': -16.116104125976562, 'loss_4': 1.9106311798095703, 'epoch': 8.33}
{'loss': 0.0184, 'grad_norm': 10.280000686645508, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.018024098128080368, 'loss_2': 0.00041866302490234375, 'loss_3': -16.3087158203125, 'loss_4': 1.91573965549469, 'epoch': 8.33}
{'loss': 0.022, 'grad_norm': 7.284195423126221, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.015136538073420525, 'loss_2': 0.00685882568359375, 'loss_3': -16.3626708984375, 'loss_4': 1.6543216705322266, 'epoch': 8.34}
{'loss': 0.0255, 'grad_norm': 9.908965110778809, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.02407030202448368, 'loss_2': 0.001399993896484375, 'loss_3': -16.35157585144043, 'loss_4': 1.2706639766693115, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 09:59:35,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:35,131 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:49<1:04:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 09:59:42,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010844043456017971, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.325, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0055573503486812115, 'eval_loss_2': 0.005286693572998047, 'eval_loss_3': -18.279088973999023, 'eval_loss_4': 1.4017659425735474, 'epoch': 8.34}
{'loss': 0.0211, 'grad_norm': 6.514023780822754, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.015622980892658234, 'loss_2': 0.0055084228515625, 'loss_3': -16.183841705322266, 'loss_4': 1.5878441333770752, 'epoch': 8.35}
{'loss': 0.0128, 'grad_norm': 6.819080829620361, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.012304119765758514, 'loss_2': 0.0005054473876953125, 'loss_3': -16.28895378112793, 'loss_4': 1.3709664344787598, 'epoch': 8.35}
{'loss': 0.019, 'grad_norm': 10.29146957397461, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.01808367297053337, 'loss_2': 0.0008764266967773438, 'loss_3': -16.24102210998535, 'loss_4': 1.5767083168029785, 'epoch': 8.36}
{'loss': 0.0254, 'grad_norm': 9.356575965881348, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.024845242500305176, 'loss_2': 0.0005350112915039062, 'loss_3': -16.30087661743164, 'loss_4': 1.9682347774505615, 'epoch': 8.37}
{'loss': 0.0178, 'grad_norm': 5.493618488311768, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.010969075374305248, 'loss_2': 0.00679779052734375, 'loss_3': -16.404232025146484, 'loss_4': 1.3926594257354736, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 09:59:42,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:42,481 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:53<1:04:17,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 09:59:46,290 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440
[INFO|configuration_utils.py:420] 2025-01-21 09:59:46,291 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440/config.json                                                                             
{'eval_loss': 0.008406420238316059, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005853553768247366, 'eval_loss_2': 0.0025528669357299805, 'eval_loss_3': -18.270002365112305, 'eval_loss_4': 1.4016647338867188, 'epoch': 8.37}
[INFO|modeling_utils.py:2988] 2025-01-21 09:59:46,786 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 09:59:46,787 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 09:59:46,788 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 09:59:47,779 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1380] due to args.save_total_limit
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [35:58<1:11:12,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 09:59:51,408 >>
{'loss': 0.0198, 'grad_norm': 8.42489242553711, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.019578026607632637, 'loss_2': 0.0002053976058959961, 'loss_3': -16.081302642822266, 'loss_4': 1.2451515197753906, 'epoch': 8.38}
{'loss': 0.0114, 'grad_norm': 5.476606845855713, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.007515221834182739, 'loss_2': 0.003932952880859375, 'loss_3': -16.173248291015625, 'loss_4': 1.698433756828308, 'epoch': 8.38}
{'loss': 0.0203, 'grad_norm': 7.435375690460205, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.01770658604800701, 'loss_2': 0.0026416778564453125, 'loss_3': -16.2138671875, 'loss_4': 2.0609140396118164, 'epoch': 8.39}
{'loss': 0.0129, 'grad_norm': 5.376138687133789, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.012025495991110802, 'loss_2': 0.0009202957153320312, 'loss_3': -16.189579010009766, 'loss_4': 0.615669846534729, 'epoch': 8.4}
{'loss': 0.024, 'grad_norm': 7.920020580291748, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.02329445071518421, 'loss_2': 0.000736236572265625, 'loss_3': -16.27582550048828, 'loss_4': 1.8517615795135498, 'epoch': 8.4}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 09:59:51,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:51,408 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:05<1:05:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 09:59:58,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009032070636749268, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00573685672134161, 'eval_loss_2': 0.003295212984085083, 'eval_loss_3': -18.243453979492188, 'eval_loss_4': 1.4108004570007324, 'epoch': 8.4}
{'loss': 0.0384, 'grad_norm': 17.122831344604492, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.03581884503364563, 'loss_2': 0.002597808837890625, 'loss_3': -16.24129295349121, 'loss_4': 1.6337831020355225, 'epoch': 8.41}
{'loss': 0.0226, 'grad_norm': 10.04135799407959, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.01634516566991806, 'loss_2': 0.0062408447265625, 'loss_3': -16.124481201171875, 'loss_4': 1.6653038263320923, 'epoch': 8.41}
{'loss': 0.0202, 'grad_norm': 14.482461929321289, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.019547810778021812, 'loss_2': 0.0006237030029296875, 'loss_3': -16.199180603027344, 'loss_4': 1.8889942169189453, 'epoch': 8.42}
{'loss': 0.012, 'grad_norm': 5.177154541015625, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.008022311143577099, 'loss_2': 0.00394439697265625, 'loss_3': -16.332162857055664, 'loss_4': 1.6266942024230957, 'epoch': 8.42}
{'loss': 0.0332, 'grad_norm': 11.960165977478027, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.028810089454054832, 'loss_2': 0.0043487548828125, 'loss_3': -16.26799964904785, 'loss_4': 1.790459156036377, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 09:59:58,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 09:59:58,747 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:09<1:05:10,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 10:00:02,555 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450
[INFO|configuration_utils.py:420] 2025-01-21 10:00:02,557 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450/config.json                                                                             
{'eval_loss': 0.008104220032691956, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005135857500135899, 'eval_loss_2': 0.0029683634638786316, 'eval_loss_3': -18.224346160888672, 'eval_loss_4': 1.7523388862609863, 'epoch': 8.43}
[INFO|modeling_utils.py:2988] 2025-01-21 10:00:03,057 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:00:03,059 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:00:03,059 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:00:04,036 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1440] due to args.save_total_limit
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:14<1:11:03,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 10:00:07,648 >>
{'loss': 0.0192, 'grad_norm': 9.51195240020752, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.016015861183404922, 'loss_2': 0.003147125244140625, 'loss_3': -16.273773193359375, 'loss_4': 2.162818193435669, 'epoch': 8.44}
{'loss': 0.0256, 'grad_norm': 9.081378936767578, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.02039429172873497, 'loss_2': 0.00518798828125, 'loss_3': -16.094053268432617, 'loss_4': 1.4514143466949463, 'epoch': 8.44}
{'loss': 0.0302, 'grad_norm': 10.547079086303711, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.02804875373840332, 'loss_2': 0.00215911865234375, 'loss_3': -16.19487953186035, 'loss_4': 1.932105302810669, 'epoch': 8.45}
{'loss': 0.0283, 'grad_norm': 11.63570499420166, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.020689040422439575, 'loss_2': 0.00757598876953125, 'loss_3': -16.16154670715332, 'loss_4': 1.677985429763794, 'epoch': 8.45}
{'loss': 0.0184, 'grad_norm': 5.021563529968262, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.006136407144367695, 'loss_2': 0.01227569580078125, 'loss_3': -16.47249984741211, 'loss_4': 2.040834426879883, 'epoch': 8.46}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:00:07,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:07,648 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:22<1:05:11,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:00:15,000 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010180546902120113, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.611, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005862310528755188, 'eval_loss_2': 0.0043182373046875, 'eval_loss_3': -18.21827507019043, 'eval_loss_4': 2.0526881217956543, 'epoch': 8.46}
{'loss': 0.0306, 'grad_norm': 10.885804176330566, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.024002131074666977, 'loss_2': 0.00661468505859375, 'loss_3': -15.802695274353027, 'loss_4': 2.593822956085205, 'epoch': 8.47}
{'loss': 0.0333, 'grad_norm': 9.76535701751709, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.021963194012641907, 'loss_2': 0.01129913330078125, 'loss_3': -16.127185821533203, 'loss_4': 1.6247036457061768, 'epoch': 8.47}
{'loss': 0.019, 'grad_norm': 7.131424903869629, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.014472492039203644, 'loss_2': 0.00452423095703125, 'loss_3': -16.18156623840332, 'loss_4': 2.421504020690918, 'epoch': 8.48}
{'loss': 0.0153, 'grad_norm': 8.097650527954102, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.015236967243254185, 'loss_2': 1.4901161193847656e-05, 'loss_3': -16.195682525634766, 'loss_4': 2.826624870300293, 'epoch': 8.48}
{'loss': 0.018, 'grad_norm': 7.537240028381348, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.017201248556375504, 'loss_2': 0.00080108642578125, 'loss_3': -16.163036346435547, 'loss_4': 2.544602394104004, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 10:00:15,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:15,000 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:29<1:04:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:22,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010449053719639778, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.56, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005939381197094917, 'eval_loss_2': 0.004509672522544861, 'eval_loss_3': -18.239049911499023, 'eval_loss_4': 2.262906074523926, 'epoch': 8.49}
{'loss': 0.0185, 'grad_norm': 6.4119954109191895, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.012825019657611847, 'loss_2': 0.00571441650390625, 'loss_3': -16.313579559326172, 'loss_4': 3.094515800476074, 'epoch': 8.49}
{'loss': 0.0147, 'grad_norm': 6.1377034187316895, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.012137200683355331, 'loss_2': 0.002521514892578125, 'loss_3': -16.483322143554688, 'loss_4': 1.8769376277923584, 'epoch': 8.5}
{'loss': 0.0152, 'grad_norm': 5.218143939971924, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.00843360461294651, 'loss_2': 0.00673675537109375, 'loss_3': -16.252376556396484, 'loss_4': 2.4652304649353027, 'epoch': 8.51}
{'loss': 0.0303, 'grad_norm': 12.918452262878418, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.025571530684828758, 'loss_2': 0.0047760009765625, 'loss_3': -16.22809600830078, 'loss_4': 1.9777629375457764, 'epoch': 8.51}
{'loss': 0.0296, 'grad_norm': 11.667208671569824, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.027401786297559738, 'loss_2': 0.002223968505859375, 'loss_3': -16.326862335205078, 'loss_4': 2.4504663944244385, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 10:00:22,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:22,354 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:36<1:03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:29,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009934359230101109, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005747096613049507, 'eval_loss_2': 0.004187263548374176, 'eval_loss_3': -18.22987174987793, 'eval_loss_4': 2.1917800903320312, 'epoch': 8.52}
{'loss': 0.0123, 'grad_norm': 6.033553600311279, 'learning_rate': 2.15e-05, 'loss_1': 0.011512603610754013, 'loss_2': 0.0008258819580078125, 'loss_3': -16.171554565429688, 'loss_4': 2.740582227706909, 'epoch': 8.52}
{'loss': 0.0266, 'grad_norm': 12.318284034729004, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.02013954147696495, 'loss_2': 0.006488800048828125, 'loss_3': -16.38235855102539, 'loss_4': 2.7224068641662598, 'epoch': 8.53}
{'loss': 0.009, 'grad_norm': 5.759528636932373, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.00876061711460352, 'loss_2': 0.00023674964904785156, 'loss_3': -16.414688110351562, 'loss_4': 2.4523448944091797, 'epoch': 8.53}
{'loss': 0.018, 'grad_norm': 6.815039157867432, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.014079463668167591, 'loss_2': 0.0038776397705078125, 'loss_3': -16.06777572631836, 'loss_4': 2.418199300765991, 'epoch': 8.54}
{'loss': 0.0107, 'grad_norm': 5.150655269622803, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.010326936841011047, 'loss_2': 0.0003948211669921875, 'loss_3': -16.17436981201172, 'loss_4': 3.1001181602478027, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 10:00:29,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:29,696 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:44<1:03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:37,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009977301582694054, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005385031923651695, 'eval_loss_2': 0.004592269659042358, 'eval_loss_3': -18.239681243896484, 'eval_loss_4': 2.42055606842041, 'epoch': 8.55}
{'loss': 0.0107, 'grad_norm': 5.803563594818115, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.008913589641451836, 'loss_2': 0.0017871856689453125, 'loss_3': -16.440996170043945, 'loss_4': 2.269394636154175, 'epoch': 8.55}
{'loss': 0.0661, 'grad_norm': 27.714801788330078, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.0570688359439373, 'loss_2': 0.00907135009765625, 'loss_3': -16.219867706298828, 'loss_4': 2.43231201171875, 'epoch': 8.56}
{'loss': 0.0254, 'grad_norm': 7.0800580978393555, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.016150644049048424, 'loss_2': 0.00921630859375, 'loss_3': -16.16815185546875, 'loss_4': 2.7585771083831787, 'epoch': 8.56}
{'loss': 0.0297, 'grad_norm': 7.322563648223877, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.017876531928777695, 'loss_2': 0.01180267333984375, 'loss_3': -16.448436737060547, 'loss_4': 1.7115662097930908, 'epoch': 8.57}
{'loss': 0.0233, 'grad_norm': 8.76911449432373, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.010953407734632492, 'loss_2': 0.012298583984375, 'loss_3': -16.242542266845703, 'loss_4': 3.171149253845215, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 10:00:37,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:37,037 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:51<1:03:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:44,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009211122989654541, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005614580120891333, 'eval_loss_2': 0.0035965442657470703, 'eval_loss_3': -18.22774887084961, 'eval_loss_4': 2.605484962463379, 'epoch': 8.58}
{'loss': 0.0169, 'grad_norm': 7.859634876251221, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.012453938834369183, 'loss_2': 0.00446319580078125, 'loss_3': -16.286020278930664, 'loss_4': 3.055422782897949, 'epoch': 8.58}
{'loss': 0.0181, 'grad_norm': 6.496424198150635, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.012742718681693077, 'loss_2': 0.00537109375, 'loss_3': -16.17119598388672, 'loss_4': 2.4373810291290283, 'epoch': 8.59}
{'loss': 0.0174, 'grad_norm': 7.617894172668457, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.01725481078028679, 'loss_2': 0.0001552104949951172, 'loss_3': -16.277896881103516, 'loss_4': 1.9508085250854492, 'epoch': 8.59}
{'loss': 0.0314, 'grad_norm': 8.353494644165039, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.02352316863834858, 'loss_2': 0.00788116455078125, 'loss_3': -16.304229736328125, 'loss_4': 2.9146668910980225, 'epoch': 8.6}
{'loss': 0.0151, 'grad_norm': 5.5786943435668945, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.011785177513957024, 'loss_2': 0.003314971923828125, 'loss_3': -16.208614349365234, 'loss_4': 3.2822728157043457, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 10:00:44,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:44,386 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [36:58<1:03:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:51,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010205244645476341, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005451580975204706, 'eval_loss_2': 0.004753664135932922, 'eval_loss_3': -18.228076934814453, 'eval_loss_4': 2.8181405067443848, 'epoch': 8.6}
{'loss': 0.0159, 'grad_norm': 6.98929500579834, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.015772569924592972, 'loss_2': 0.00012683868408203125, 'loss_3': -16.223194122314453, 'loss_4': 2.881228446960449, 'epoch': 8.61}
{'loss': 0.0179, 'grad_norm': 5.130351543426514, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.009755298495292664, 'loss_2': 0.0081787109375, 'loss_3': -16.31877899169922, 'loss_4': 2.948762893676758, 'epoch': 8.62}
{'loss': 0.0246, 'grad_norm': 7.480198383331299, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.016976330429315567, 'loss_2': 0.007598876953125, 'loss_3': -16.0140438079834, 'loss_4': 3.2513644695281982, 'epoch': 8.62}
{'loss': 0.0115, 'grad_norm': 5.718679904937744, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.01090365368872881, 'loss_2': 0.0006227493286132812, 'loss_3': -16.149967193603516, 'loss_4': 3.2444188594818115, 'epoch': 8.63}
{'loss': 0.0133, 'grad_norm': 6.640787124633789, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.010506692342460155, 'loss_2': 0.002788543701171875, 'loss_3': -16.167709350585938, 'loss_4': 2.6983656883239746, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 10:00:51,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:51,737 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:06<1:03:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:00:59,101 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010987425222992897, 'eval_runtime': 3.8182, 'eval_samples_per_second': 268.19, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005640233866870403, 'eval_loss_2': 0.005347192287445068, 'eval_loss_3': -18.21453285217285, 'eval_loss_4': 3.1311521530151367, 'epoch': 8.63}
{'loss': 0.0262, 'grad_norm': 16.001243591308594, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.021901654079556465, 'loss_2': 0.0043182373046875, 'loss_3': -16.341737747192383, 'loss_4': 3.361631393432617, 'epoch': 8.64}
{'loss': 0.019, 'grad_norm': 6.403993606567383, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.013381957076489925, 'loss_2': 0.005580902099609375, 'loss_3': -16.1712646484375, 'loss_4': 3.5462303161621094, 'epoch': 8.65}
{'loss': 0.016, 'grad_norm': 6.6850666999816895, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.016006076708436012, 'loss_2': 3.540515899658203e-05, 'loss_3': -16.368520736694336, 'loss_4': 3.5329103469848633, 'epoch': 8.65}
{'loss': 0.0355, 'grad_norm': 12.212090492248535, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.03518099710345268, 'loss_2': 0.0002808570861816406, 'loss_3': -16.017452239990234, 'loss_4': 4.030196666717529, 'epoch': 8.66}
{'loss': 0.0819, 'grad_norm': 25.10586166381836, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.0800982192158699, 'loss_2': 0.001766204833984375, 'loss_3': -15.920161247253418, 'loss_4': 3.1643056869506836, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 10:00:59,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:00:59,102 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:13<1:03:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:06,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011599046178162098, 'eval_runtime': 3.8214, 'eval_samples_per_second': 267.962, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.006935385521501303, 'eval_loss_2': 0.0046636611223220825, 'eval_loss_3': -18.22549057006836, 'eval_loss_4': 3.3898048400878906, 'epoch': 8.66}
{'loss': 0.011, 'grad_norm': 9.273326873779297, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.009031145833432674, 'loss_2': 0.0019989013671875, 'loss_3': -16.05480194091797, 'loss_4': 3.643397092819214, 'epoch': 8.67}
{'loss': 0.0289, 'grad_norm': 6.743652820587158, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.014358124695718288, 'loss_2': 0.01458740234375, 'loss_3': -16.289287567138672, 'loss_4': 3.4088268280029297, 'epoch': 8.67}
{'loss': 0.0222, 'grad_norm': 9.831635475158691, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.017504509538412094, 'loss_2': 0.00464630126953125, 'loss_3': -16.125207901000977, 'loss_4': 3.2681617736816406, 'epoch': 8.68}
{'loss': 0.0178, 'grad_norm': 7.53098201751709, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.014095999300479889, 'loss_2': 0.003749847412109375, 'loss_3': -16.343006134033203, 'loss_4': 2.9058971405029297, 'epoch': 8.69}
{'loss': 0.0088, 'grad_norm': 5.632421493530273, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.007198696956038475, 'loss_2': 0.0016450881958007812, 'loss_3': -15.999326705932617, 'loss_4': 3.6951823234558105, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 10:01:06,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:06,470 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:21<1:03:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:13,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009892567992210388, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.617, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005757051985710859, 'eval_loss_2': 0.004135515540838242, 'eval_loss_3': -18.236974716186523, 'eval_loss_4': 3.348689079284668, 'epoch': 8.69}
{'loss': 0.0108, 'grad_norm': 5.654069900512695, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.009288951754570007, 'loss_2': 0.0014858245849609375, 'loss_3': -16.135583877563477, 'loss_4': 3.2136518955230713, 'epoch': 8.7}
{'loss': 0.0198, 'grad_norm': 9.583293914794922, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.019470179453492165, 'loss_2': 0.0003643035888671875, 'loss_3': -16.13860321044922, 'loss_4': 3.3098392486572266, 'epoch': 8.7}
{'loss': 0.0177, 'grad_norm': 6.060116767883301, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.015745369717478752, 'loss_2': 0.00196075439453125, 'loss_3': -16.074800491333008, 'loss_4': 3.9112517833709717, 'epoch': 8.71}
{'loss': 0.0165, 'grad_norm': 6.334192276000977, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.011232647113502026, 'loss_2': 0.005275726318359375, 'loss_3': -16.15716552734375, 'loss_4': 3.294707775115967, 'epoch': 8.72}
{'loss': 0.0254, 'grad_norm': 9.004400253295898, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.02058890275657177, 'loss_2': 0.00485992431640625, 'loss_3': -16.118816375732422, 'loss_4': 3.0771281719207764, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 10:01:13,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:13,825 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:28<1:03:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:21,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00979304313659668, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.758, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005563661921769381, 'eval_loss_2': 0.004229381680488586, 'eval_loss_3': -18.260913848876953, 'eval_loss_4': 3.469539165496826, 'epoch': 8.72}
{'loss': 0.0164, 'grad_norm': 7.944441318511963, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.01446247287094593, 'loss_2': 0.001987457275390625, 'loss_3': -16.201112747192383, 'loss_4': 3.664543867111206, 'epoch': 8.73}
{'loss': 0.0124, 'grad_norm': 4.808686256408691, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.006637559272348881, 'loss_2': 0.00574493408203125, 'loss_3': -16.112030029296875, 'loss_4': 3.8422203063964844, 'epoch': 8.73}
{'loss': 0.0125, 'grad_norm': 5.618721961975098, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.010358787141740322, 'loss_2': 0.00213623046875, 'loss_3': -16.02214813232422, 'loss_4': 2.768146514892578, 'epoch': 8.74}
{'loss': 0.0198, 'grad_norm': 5.287820339202881, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.010526375845074654, 'loss_2': 0.009307861328125, 'loss_3': -16.23280143737793, 'loss_4': 3.1775779724121094, 'epoch': 8.74}
{'loss': 0.0137, 'grad_norm': 7.078506946563721, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.012695345096290112, 'loss_2': 0.00102996826171875, 'loss_3': -16.181842803955078, 'loss_4': 3.6765236854553223, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 10:01:21,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:21,172 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:35<1:03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:28,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011028526350855827, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.822, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005954084452241659, 'eval_loss_2': 0.005074441432952881, 'eval_loss_3': -18.28286361694336, 'eval_loss_4': 3.6244518756866455, 'epoch': 8.75}
{'loss': 0.0206, 'grad_norm': 6.5851969718933105, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.011566292494535446, 'loss_2': 0.0090179443359375, 'loss_3': -16.008092880249023, 'loss_4': 3.5896544456481934, 'epoch': 8.76}
{'loss': 0.0169, 'grad_norm': 8.960909843444824, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.01480097696185112, 'loss_2': 0.002124786376953125, 'loss_3': -16.231861114501953, 'loss_4': 3.804213762283325, 'epoch': 8.76}
{'loss': 0.0175, 'grad_norm': 7.218462944030762, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.01416048128157854, 'loss_2': 0.0033054351806640625, 'loss_3': -16.205642700195312, 'loss_4': 4.529784679412842, 'epoch': 8.77}
{'loss': 0.0111, 'grad_norm': 5.310756683349609, 'learning_rate': 2.125e-05, 'loss_1': 0.008884633891284466, 'loss_2': 0.0022449493408203125, 'loss_3': -16.192340850830078, 'loss_4': 3.9997189044952393, 'epoch': 8.77}
{'loss': 0.0103, 'grad_norm': 6.294832229614258, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.009520085528492928, 'loss_2': 0.0007534027099609375, 'loss_3': -16.36736488342285, 'loss_4': 4.079632759094238, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 10:01:28,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:28,521 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:43<1:03:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:35,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010242790915071964, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.175, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006285220850259066, 'eval_loss_2': 0.003957569599151611, 'eval_loss_3': -18.33171844482422, 'eval_loss_4': 4.085671424865723, 'epoch': 8.78}
{'loss': 0.0394, 'grad_norm': 15.61174201965332, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.03477635234594345, 'loss_2': 0.0046539306640625, 'loss_3': -16.187599182128906, 'loss_4': 3.814422607421875, 'epoch': 8.78}
{'loss': 0.0377, 'grad_norm': 16.734785079956055, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.031606607139110565, 'loss_2': 0.0061187744140625, 'loss_3': -16.245819091796875, 'loss_4': 3.7020676136016846, 'epoch': 8.79}
{'loss': 0.02, 'grad_norm': 6.179646015167236, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.01393202692270279, 'loss_2': 0.00605010986328125, 'loss_3': -15.98025131225586, 'loss_4': 4.111724376678467, 'epoch': 8.8}
{'loss': 0.0249, 'grad_norm': 8.986383438110352, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.022359678521752357, 'loss_2': 0.0025157928466796875, 'loss_3': -16.378314971923828, 'loss_4': 4.247930526733398, 'epoch': 8.8}
{'loss': 0.0383, 'grad_norm': 13.31410026550293, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.0345207117497921, 'loss_2': 0.0037403106689453125, 'loss_3': -16.03567886352539, 'loss_4': 4.31179141998291, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 10:01:35,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:35,882 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:50<1:02:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:43,237 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010020703077316284, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.59, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00666566239669919, 'eval_loss_2': 0.0033550411462783813, 'eval_loss_3': -18.35953140258789, 'eval_loss_4': 4.330915451049805, 'epoch': 8.81}
{'loss': 0.0353, 'grad_norm': 9.468844413757324, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.0264961626380682, 'loss_2': 0.00878143310546875, 'loss_3': -16.11815643310547, 'loss_4': 4.465639114379883, 'epoch': 8.81}
{'loss': 0.0113, 'grad_norm': 5.0774712562561035, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.010386942885816097, 'loss_2': 0.0009579658508300781, 'loss_3': -16.168689727783203, 'loss_4': 4.140460014343262, 'epoch': 8.82}
{'loss': 0.0295, 'grad_norm': 7.934919357299805, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.023017022758722305, 'loss_2': 0.006458282470703125, 'loss_3': -16.080608367919922, 'loss_4': 4.590461254119873, 'epoch': 8.83}
{'loss': 0.023, 'grad_norm': 5.648712158203125, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.014368899166584015, 'loss_2': 0.00859832763671875, 'loss_3': -16.068851470947266, 'loss_4': 4.326272010803223, 'epoch': 8.83}
{'loss': 0.0316, 'grad_norm': 9.805763244628906, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.024255482479929924, 'loss_2': 0.00731658935546875, 'loss_3': -15.961145401000977, 'loss_4': 4.3663506507873535, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 10:01:43,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:43,237 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [37:57<1:02:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:50,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010973704978823662, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006852125748991966, 'eval_loss_2': 0.0041215792298316956, 'eval_loss_3': -18.354690551757812, 'eval_loss_4': 4.468732833862305, 'epoch': 8.84}
{'loss': 0.0194, 'grad_norm': 7.36047887802124, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.018081238493323326, 'loss_2': 0.001277923583984375, 'loss_3': -16.208938598632812, 'loss_4': 4.724130630493164, 'epoch': 8.84}
{'loss': 0.0202, 'grad_norm': 9.725526809692383, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.019887320697307587, 'loss_2': 0.00034332275390625, 'loss_3': -16.155731201171875, 'loss_4': 4.248707294464111, 'epoch': 8.85}
{'loss': 0.0329, 'grad_norm': 12.28642749786377, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.02450406178832054, 'loss_2': 0.00841522216796875, 'loss_3': -16.34209442138672, 'loss_4': 4.503515720367432, 'epoch': 8.85}
{'loss': 0.0223, 'grad_norm': 8.034401893615723, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.01858743093907833, 'loss_2': 0.00370025634765625, 'loss_3': -16.204139709472656, 'loss_4': 4.464066982269287, 'epoch': 8.86}
{'loss': 0.0279, 'grad_norm': 8.416155815124512, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.023196272552013397, 'loss_2': 0.00472259521484375, 'loss_3': -16.257478713989258, 'loss_4': 4.482895851135254, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 10:01:50,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:50,585 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:05<1:02:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:01:57,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010670123621821404, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007029704283922911, 'eval_loss_2': 0.0036404207348823547, 'eval_loss_3': -18.330930709838867, 'eval_loss_4': 4.229063034057617, 'epoch': 8.87}
{'loss': 0.0177, 'grad_norm': 9.618619918823242, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.016616735607385635, 'loss_2': 0.0010862350463867188, 'loss_3': -16.035400390625, 'loss_4': 4.066915512084961, 'epoch': 8.87}
{'loss': 0.0222, 'grad_norm': 6.7462158203125, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.019804079085588455, 'loss_2': 0.00244140625, 'loss_3': -16.1051025390625, 'loss_4': 4.660213947296143, 'epoch': 8.88}
{'loss': 0.0415, 'grad_norm': 12.956974983215332, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.03946040943264961, 'loss_2': 0.00205230712890625, 'loss_3': -16.325138092041016, 'loss_4': 4.368792533874512, 'epoch': 8.88}
{'loss': 0.0249, 'grad_norm': 7.828000545501709, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.020536242052912712, 'loss_2': 0.00432586669921875, 'loss_3': -16.09941864013672, 'loss_4': 4.071453094482422, 'epoch': 8.89}
{'loss': 0.0157, 'grad_norm': 5.041330337524414, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.008244874887168407, 'loss_2': 0.007419586181640625, 'loss_3': -16.212299346923828, 'loss_4': 3.5364530086517334, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 10:01:57,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:01:57,935 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:12<1:02:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:05,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01490002404898405, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.648, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006555372383445501, 'eval_loss_2': 0.008344650268554688, 'eval_loss_3': -18.318241119384766, 'eval_loss_4': 4.120765209197998, 'epoch': 8.9}
{'loss': 0.0252, 'grad_norm': 8.116588592529297, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.019653024151921272, 'loss_2': 0.00551605224609375, 'loss_3': -16.144142150878906, 'loss_4': 3.3366637229919434, 'epoch': 8.9}
{'loss': 0.0246, 'grad_norm': 11.20250129699707, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.020633479580283165, 'loss_2': 0.00399017333984375, 'loss_3': -16.24264144897461, 'loss_4': 3.7053732872009277, 'epoch': 8.91}
{'loss': 0.0319, 'grad_norm': 13.403435707092285, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.029816707596182823, 'loss_2': 0.002063751220703125, 'loss_3': -16.42364501953125, 'loss_4': 3.3099417686462402, 'epoch': 8.91}
{'loss': 0.0141, 'grad_norm': 6.007931709289551, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.011937346309423447, 'loss_2': 0.0022125244140625, 'loss_3': -16.09343147277832, 'loss_4': 4.236621856689453, 'epoch': 8.92}
{'loss': 0.0114, 'grad_norm': 5.35072135925293, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.010668754577636719, 'loss_2': 0.0006999969482421875, 'loss_3': -16.114742279052734, 'loss_4': 4.039044380187988, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 10:02:05,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:05,286 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:19<1:02:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:12,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009897463023662567, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.908, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005798450671136379, 'eval_loss_2': 0.004099011421203613, 'eval_loss_3': -18.34933853149414, 'eval_loss_4': 3.927098512649536, 'epoch': 8.92}
{'loss': 0.0299, 'grad_norm': 9.524065017700195, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.02611081674695015, 'loss_2': 0.0037555694580078125, 'loss_3': -15.989860534667969, 'loss_4': 3.5005455017089844, 'epoch': 8.93}
{'loss': 0.0413, 'grad_norm': 10.759122848510742, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.03913291543722153, 'loss_2': 0.002124786376953125, 'loss_3': -16.130054473876953, 'loss_4': 4.793123722076416, 'epoch': 8.94}
{'loss': 0.0207, 'grad_norm': 6.423930644989014, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.01790936291217804, 'loss_2': 0.0027713775634765625, 'loss_3': -16.28738021850586, 'loss_4': 3.3393754959106445, 'epoch': 8.94}
{'loss': 0.0142, 'grad_norm': 5.890077590942383, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.010410886257886887, 'loss_2': 0.003814697265625, 'loss_3': -15.941394805908203, 'loss_4': 3.221710443496704, 'epoch': 8.95}
{'loss': 0.0248, 'grad_norm': 8.471001625061035, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.019956231117248535, 'loss_2': 0.004833221435546875, 'loss_3': -16.23145294189453, 'loss_4': 4.087629795074463, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 10:02:12,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:12,637 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:27<1:02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:19,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01159611251205206, 'eval_runtime': 3.8187, 'eval_samples_per_second': 268.156, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006262450944632292, 'eval_loss_2': 0.005333662033081055, 'eval_loss_3': -18.34766960144043, 'eval_loss_4': 3.7544660568237305, 'epoch': 8.95}
{'loss': 0.0099, 'grad_norm': 5.623635768890381, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.00926407240331173, 'loss_2': 0.0006208419799804688, 'loss_3': -16.28227424621582, 'loss_4': 4.160337448120117, 'epoch': 8.96}
{'loss': 0.0408, 'grad_norm': 8.893268585205078, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.03299904987215996, 'loss_2': 0.00775909423828125, 'loss_3': -16.072052001953125, 'loss_4': 3.881629467010498, 'epoch': 8.97}
{'loss': 0.013, 'grad_norm': 6.274420261383057, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.012658115476369858, 'loss_2': 0.0003333091735839844, 'loss_3': -16.29035186767578, 'loss_4': 3.107916831970215, 'epoch': 8.97}
{'loss': 0.0168, 'grad_norm': 8.631329536437988, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.01605561375617981, 'loss_2': 0.0007295608520507812, 'loss_3': -16.015419006347656, 'loss_4': 2.6171984672546387, 'epoch': 8.98}
{'loss': 0.0163, 'grad_norm': 9.085226058959961, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.016042472794651985, 'loss_2': 0.00026416778564453125, 'loss_3': -16.142406463623047, 'loss_4': 3.452052116394043, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 10:02:19,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:19,997 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:34<59:51,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 10:02:27,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010241973213851452, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.354, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005859035532921553, 'eval_loss_2': 0.0043829381465911865, 'eval_loss_3': -18.33881950378418, 'eval_loss_4': 3.3508641719818115, 'epoch': 8.98}
{'loss': 0.018, 'grad_norm': 6.961244106292725, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.011837135069072247, 'loss_2': 0.006160736083984375, 'loss_3': -16.327014923095703, 'loss_4': 3.2241992950439453, 'epoch': 8.99}
{'loss': 0.0219, 'grad_norm': 6.131236553192139, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.01786896400153637, 'loss_2': 0.00403594970703125, 'loss_3': -15.934261322021484, 'loss_4': 3.0888023376464844, 'epoch': 8.99}
{'loss': 0.0081, 'grad_norm': 6.169921398162842, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.0028350618667900562, 'loss_2': 0.0052642822265625, 'loss_3': -16.175159454345703, 'loss_4': 2.6666510105133057, 'epoch': 9.0}
{'loss': 0.0211, 'grad_norm': 6.767927646636963, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.01844172738492489, 'loss_2': 0.002651214599609375, 'loss_3': -16.299457550048828, 'loss_4': 3.3932015895843506, 'epoch': 9.01}
{'loss': 0.0195, 'grad_norm': 7.0951032638549805, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.018143534660339355, 'loss_2': 0.0013303756713867188, 'loss_3': -16.096982955932617, 'loss_4': 3.4059739112854004, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 10:02:27,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:27,038 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:41<1:01:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:02:34,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009919640608131886, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.094, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006217626854777336, 'eval_loss_2': 0.003702014684677124, 'eval_loss_3': -18.311233520507812, 'eval_loss_4': 3.3348236083984375, 'epoch': 9.01}
{'loss': 0.0363, 'grad_norm': 7.370815277099609, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.024358630180358887, 'loss_2': 0.0119171142578125, 'loss_3': -16.113059997558594, 'loss_4': 3.2540218830108643, 'epoch': 9.02}
{'loss': 0.0307, 'grad_norm': 14.315299034118652, 'learning_rate': 2.1e-05, 'loss_1': 0.02717950940132141, 'loss_2': 0.003475189208984375, 'loss_3': -16.273422241210938, 'loss_4': 2.8010759353637695, 'epoch': 9.02}
{'loss': 0.0135, 'grad_norm': 6.195271015167236, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.010416877456009388, 'loss_2': 0.0030975341796875, 'loss_3': -16.087705612182617, 'loss_4': 2.9953017234802246, 'epoch': 9.03}
{'loss': 0.0112, 'grad_norm': 4.9370832443237305, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.010090665891766548, 'loss_2': 0.001064300537109375, 'loss_3': -16.2137451171875, 'loss_4': 3.250549077987671, 'epoch': 9.03}
{'loss': 0.0451, 'grad_norm': 13.195524215698242, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.041640546172857285, 'loss_2': 0.0034332275390625, 'loss_3': -16.21879005432129, 'loss_4': 3.961268424987793, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 10:02:34,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:34,384 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:48<1:02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:41,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010831225663423538, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.9, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006325114518404007, 'eval_loss_2': 0.004506111145019531, 'eval_loss_3': -18.326810836791992, 'eval_loss_4': 3.272733449935913, 'epoch': 9.04}
{'loss': 0.0189, 'grad_norm': 6.115751266479492, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.011778372339904308, 'loss_2': 0.007110595703125, 'loss_3': -16.246936798095703, 'loss_4': 3.114971160888672, 'epoch': 9.05}
{'loss': 0.0196, 'grad_norm': 9.801193237304688, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.017155243083834648, 'loss_2': 0.002414703369140625, 'loss_3': -16.235275268554688, 'loss_4': 3.0189664363861084, 'epoch': 9.05}
{'loss': 0.0141, 'grad_norm': 5.587129592895508, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.009806506335735321, 'loss_2': 0.00424957275390625, 'loss_3': -16.274662017822266, 'loss_4': 3.5353193283081055, 'epoch': 9.06}
{'loss': 0.0117, 'grad_norm': 4.980504989624023, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.009040609933435917, 'loss_2': 0.002620697021484375, 'loss_3': -16.12746810913086, 'loss_4': 3.0598926544189453, 'epoch': 9.06}
{'loss': 0.0101, 'grad_norm': 4.944983959197998, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.009882630780339241, 'loss_2': 0.0001704692840576172, 'loss_3': -16.340003967285156, 'loss_4': 3.141547441482544, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 10:02:41,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:41,740 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [38:56<1:02:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:49,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010552924126386642, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.965, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007047596387565136, 'eval_loss_2': 0.003505326807498932, 'eval_loss_3': -18.325590133666992, 'eval_loss_4': 3.366428852081299, 'epoch': 9.07}
{'loss': 0.0235, 'grad_norm': 10.538503646850586, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.01670665666460991, 'loss_2': 0.00681304931640625, 'loss_3': -16.380924224853516, 'loss_4': 3.301346778869629, 'epoch': 9.08}
{'loss': 0.0239, 'grad_norm': 13.652851104736328, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.02216120809316635, 'loss_2': 0.0017261505126953125, 'loss_3': -16.19232177734375, 'loss_4': 3.836796760559082, 'epoch': 9.08}
{'loss': 0.0234, 'grad_norm': 6.788451194763184, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.018660562112927437, 'loss_2': 0.0047149658203125, 'loss_3': -16.06151580810547, 'loss_4': 3.145803451538086, 'epoch': 9.09}
{'loss': 0.0236, 'grad_norm': 6.359772682189941, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.014320318587124348, 'loss_2': 0.0092315673828125, 'loss_3': -16.029075622558594, 'loss_4': 3.830197334289551, 'epoch': 9.09}
{'loss': 0.0062, 'grad_norm': 4.789663314819336, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.004049445502460003, 'loss_2': 0.00217437744140625, 'loss_3': -16.458080291748047, 'loss_4': 3.732349157333374, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 10:02:49,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:49,089 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:03<1:02:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:02:56,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01148538663983345, 'eval_runtime': 3.822, 'eval_samples_per_second': 267.925, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.006774320732802153, 'eval_loss_2': 0.00471106544137001, 'eval_loss_3': -18.32865333557129, 'eval_loss_4': 3.465752601623535, 'epoch': 9.1}
{'loss': 0.0268, 'grad_norm': 6.533964157104492, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.017241904512047768, 'loss_2': 0.0095367431640625, 'loss_3': -16.258039474487305, 'loss_4': 3.811795234680176, 'epoch': 9.1}
{'loss': 0.0189, 'grad_norm': 5.940670967102051, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.016376394778490067, 'loss_2': 0.002521514892578125, 'loss_3': -16.210651397705078, 'loss_4': 3.7775766849517822, 'epoch': 9.11}
{'loss': 0.0107, 'grad_norm': 5.506824970245361, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.009287076070904732, 'loss_2': 0.0013942718505859375, 'loss_3': -16.29780387878418, 'loss_4': 3.6449179649353027, 'epoch': 9.12}
{'loss': 0.0122, 'grad_norm': 5.691981315612793, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.010833042673766613, 'loss_2': 0.0013942718505859375, 'loss_3': -16.221216201782227, 'loss_4': 4.095466613769531, 'epoch': 9.12}
{'loss': 0.0371, 'grad_norm': 6.797913551330566, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.02077576145529747, 'loss_2': 0.0163116455078125, 'loss_3': -16.108388900756836, 'loss_4': 3.3231663703918457, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 10:02:56,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:02:56,460 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:11<1:02:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:03,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010334916412830353, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.373, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.006702728103846312, 'eval_loss_2': 0.003632187843322754, 'eval_loss_3': -18.3341007232666, 'eval_loss_4': 3.4594931602478027, 'epoch': 9.13}
{'loss': 0.0125, 'grad_norm': 5.408792018890381, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.008584062568843365, 'loss_2': 0.00390625, 'loss_3': -16.358348846435547, 'loss_4': 3.06093692779541, 'epoch': 9.13}
{'loss': 0.0353, 'grad_norm': 8.391338348388672, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.028011774644255638, 'loss_2': 0.00733184814453125, 'loss_3': -16.20577049255371, 'loss_4': 3.635265827178955, 'epoch': 9.14}
{'loss': 0.0232, 'grad_norm': 8.507102966308594, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.01549002155661583, 'loss_2': 0.007709503173828125, 'loss_3': -16.162540435791016, 'loss_4': 3.26711368560791, 'epoch': 9.15}
{'loss': 0.0443, 'grad_norm': 19.286521911621094, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.040810588747262955, 'loss_2': 0.003505706787109375, 'loss_3': -16.140649795532227, 'loss_4': 3.280499219894409, 'epoch': 9.15}
{'loss': 0.0168, 'grad_norm': 6.5049729347229, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.014625209383666515, 'loss_2': 0.002185821533203125, 'loss_3': -16.129379272460938, 'loss_4': 3.888730525970459, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 10:03:03,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:03,815 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:18<1:01:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:11,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01127533707767725, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006298289634287357, 'eval_loss_2': 0.004977047443389893, 'eval_loss_3': -18.35637664794922, 'eval_loss_4': 3.6349785327911377, 'epoch': 9.16}
{'loss': 0.0199, 'grad_norm': 5.8561835289001465, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.012013285420835018, 'loss_2': 0.00789642333984375, 'loss_3': -16.23223304748535, 'loss_4': 3.2127795219421387, 'epoch': 9.16}
{'loss': 0.0165, 'grad_norm': 7.100683212280273, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.013947611674666405, 'loss_2': 0.002513885498046875, 'loss_3': -16.158992767333984, 'loss_4': 3.5886831283569336, 'epoch': 9.17}
{'loss': 0.0222, 'grad_norm': 7.980867385864258, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.018607817590236664, 'loss_2': 0.0036106109619140625, 'loss_3': -16.21005630493164, 'loss_4': 3.844550132751465, 'epoch': 9.17}
{'loss': 0.0168, 'grad_norm': 5.439187526702881, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.010891616344451904, 'loss_2': 0.0058746337890625, 'loss_3': -16.330739974975586, 'loss_4': 3.9695780277252197, 'epoch': 9.18}
{'loss': 0.0418, 'grad_norm': 14.375274658203125, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.03757638484239578, 'loss_2': 0.004207611083984375, 'loss_3': -16.331430435180664, 'loss_4': 3.984720468521118, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 10:03:11,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:11,163 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:25<1:01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:18,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011298546567559242, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.978, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006116430275142193, 'eval_loss_2': 0.005182117223739624, 'eval_loss_3': -18.335872650146484, 'eval_loss_4': 3.786412239074707, 'epoch': 9.19}
{'loss': 0.0256, 'grad_norm': 8.521160125732422, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.022826269268989563, 'loss_2': 0.0028171539306640625, 'loss_3': -16.320707321166992, 'loss_4': 3.32064151763916, 'epoch': 9.19}
{'loss': 0.0236, 'grad_norm': 10.001851081848145, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.018437575548887253, 'loss_2': 0.00521087646484375, 'loss_3': -16.199560165405273, 'loss_4': 3.5747454166412354, 'epoch': 9.2}
{'loss': 0.0425, 'grad_norm': 16.275447845458984, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.03936147317290306, 'loss_2': 0.0031642913818359375, 'loss_3': -16.154144287109375, 'loss_4': 4.407541751861572, 'epoch': 9.2}
{'loss': 0.0376, 'grad_norm': 14.018889427185059, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.03560197725892067, 'loss_2': 0.0019483566284179688, 'loss_3': -16.396705627441406, 'loss_4': 3.3838255405426025, 'epoch': 9.21}
{'loss': 0.0231, 'grad_norm': 7.593207359313965, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.01567307487130165, 'loss_2': 0.007442474365234375, 'loss_3': -16.367538452148438, 'loss_4': 3.5499496459960938, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 10:03:18,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:18,508 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:33<1:01:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:25,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009241094812750816, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006341470405459404, 'eval_loss_2': 0.0028996244072914124, 'eval_loss_3': -18.378559112548828, 'eval_loss_4': 3.831592559814453, 'epoch': 9.22}
{'loss': 0.0126, 'grad_norm': 4.978663444519043, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.009678038768470287, 'loss_2': 0.0029296875, 'loss_3': -16.269664764404297, 'loss_4': 3.7603368759155273, 'epoch': 9.22}
{'loss': 0.0282, 'grad_norm': 8.0960693359375, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.020037392154335976, 'loss_2': 0.00818634033203125, 'loss_3': -16.46487808227539, 'loss_4': 4.3772664070129395, 'epoch': 9.23}
{'loss': 0.0236, 'grad_norm': 7.133878707885742, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.022293532267212868, 'loss_2': 0.001285552978515625, 'loss_3': -16.333545684814453, 'loss_4': 3.135789632797241, 'epoch': 9.23}
{'loss': 0.0368, 'grad_norm': 18.026578903198242, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.03589877113699913, 'loss_2': 0.0009350776672363281, 'loss_3': -16.187347412109375, 'loss_4': 4.113361835479736, 'epoch': 9.24}
{'loss': 0.0159, 'grad_norm': 6.9897236824035645, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.013409030623733997, 'loss_2': 0.00254058837890625, 'loss_3': -16.14729881286621, 'loss_4': 4.343044281005859, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 10:03:25,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:25,857 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:40<1:01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:33,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010927027091383934, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0065873172134160995, 'eval_loss_2': 0.0043397098779678345, 'eval_loss_3': -18.364622116088867, 'eval_loss_4': 3.556417465209961, 'epoch': 9.24}
{'loss': 0.0171, 'grad_norm': 5.951910495758057, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.013352755457162857, 'loss_2': 0.0037841796875, 'loss_3': -16.342159271240234, 'loss_4': 3.7269768714904785, 'epoch': 9.25}
{'loss': 0.0301, 'grad_norm': 12.246013641357422, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.024680789560079575, 'loss_2': 0.00537109375, 'loss_3': -16.576377868652344, 'loss_4': 3.6747655868530273, 'epoch': 9.26}
{'loss': 0.0101, 'grad_norm': 5.285017967224121, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.008225580677390099, 'loss_2': 0.0018749237060546875, 'loss_3': -16.40414810180664, 'loss_4': 4.254853248596191, 'epoch': 9.26}
{'loss': 0.0338, 'grad_norm': 10.252948760986328, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.03065146878361702, 'loss_2': 0.0031890869140625, 'loss_3': -16.169355392456055, 'loss_4': 4.135020732879639, 'epoch': 9.27}
{'loss': 0.0137, 'grad_norm': 5.271534442901611, 'learning_rate': 2.075e-05, 'loss_1': 0.010691963136196136, 'loss_2': 0.003040313720703125, 'loss_3': -16.22764778137207, 'loss_4': 3.5215530395507812, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 10:03:33,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:33,213 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:47<1:01:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:40,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012262661941349506, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.263, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007099887356162071, 'eval_loss_2': 0.00516277551651001, 'eval_loss_3': -18.33304786682129, 'eval_loss_4': 2.782630443572998, 'epoch': 9.27}
{'loss': 0.0301, 'grad_norm': 8.115252494812012, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.02257266268134117, 'loss_2': 0.00756072998046875, 'loss_3': -16.371671676635742, 'loss_4': 2.921074867248535, 'epoch': 9.28}
{'loss': 0.0105, 'grad_norm': 5.790060043334961, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.010509228333830833, 'loss_2': 2.2172927856445312e-05, 'loss_3': -16.1343994140625, 'loss_4': 1.8263591527938843, 'epoch': 9.28}
{'loss': 0.0306, 'grad_norm': 6.001019477844238, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.013767600990831852, 'loss_2': 0.01678466796875, 'loss_3': -16.087060928344727, 'loss_4': 2.9538705348968506, 'epoch': 9.29}
{'loss': 0.0118, 'grad_norm': 5.139914512634277, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.007796005811542273, 'loss_2': 0.00403594970703125, 'loss_3': -16.446041107177734, 'loss_4': 2.647212028503418, 'epoch': 9.3}
{'loss': 0.0106, 'grad_norm': 4.774825096130371, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.007246631663292646, 'loss_2': 0.0033740997314453125, 'loss_3': -16.493309020996094, 'loss_4': 1.983442783355713, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 10:03:40,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:40,570 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:55<1:01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:47,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011349743232131004, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007158791646361351, 'eval_loss_2': 0.004190951585769653, 'eval_loss_3': -18.3380184173584, 'eval_loss_4': 1.8634881973266602, 'epoch': 9.3}
{'loss': 0.0381, 'grad_norm': 16.27178955078125, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.032947853207588196, 'loss_2': 0.0051422119140625, 'loss_3': -16.348979949951172, 'loss_4': 2.3834869861602783, 'epoch': 9.31}
{'loss': 0.0447, 'grad_norm': 15.258260726928711, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.03890939801931381, 'loss_2': 0.005767822265625, 'loss_3': -16.36041259765625, 'loss_4': 1.7057859897613525, 'epoch': 9.31}
{'loss': 0.0127, 'grad_norm': 4.6507158279418945, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.008256964385509491, 'loss_2': 0.00441741943359375, 'loss_3': -16.251258850097656, 'loss_4': 1.3492025136947632, 'epoch': 9.32}
{'loss': 0.0255, 'grad_norm': 7.036759376525879, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.017613299190998077, 'loss_2': 0.007904052734375, 'loss_3': -16.38651466369629, 'loss_4': 1.372910737991333, 'epoch': 9.33}
{'loss': 0.0069, 'grad_norm': 5.223771095275879, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.006790230516344309, 'loss_2': 0.00015664100646972656, 'loss_3': -16.256696701049805, 'loss_4': 1.4450604915618896, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 10:03:47,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:47,918 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:02<1:01:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:03:55,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009598156437277794, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00562474736943841, 'eval_loss_2': 0.003973409533500671, 'eval_loss_3': -18.337718963623047, 'eval_loss_4': 1.1328346729278564, 'epoch': 9.33}
{'loss': 0.0238, 'grad_norm': 7.953476905822754, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.023293813690543175, 'loss_2': 0.0005178451538085938, 'loss_3': -16.26939582824707, 'loss_4': 1.092076301574707, 'epoch': 9.34}
{'loss': 0.0114, 'grad_norm': 5.747395992279053, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.010398255661129951, 'loss_2': 0.0010318756103515625, 'loss_3': -16.378597259521484, 'loss_4': 1.2255054712295532, 'epoch': 9.34}
{'loss': 0.0214, 'grad_norm': 6.163122177124023, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.0163436196744442, 'loss_2': 0.005016326904296875, 'loss_3': -16.228843688964844, 'loss_4': 0.5380361080169678, 'epoch': 9.35}
{'loss': 0.0178, 'grad_norm': 5.459140777587891, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.014605133794248104, 'loss_2': 0.003185272216796875, 'loss_3': -16.373844146728516, 'loss_4': 0.8481742143630981, 'epoch': 9.35}
{'loss': 0.0225, 'grad_norm': 6.161430358886719, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.016065744683146477, 'loss_2': 0.00640106201171875, 'loss_3': -16.37065887451172, 'loss_4': 1.3680475950241089, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 10:03:55,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:03:55,260 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:09<1:01:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:02,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0097635043784976, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.099, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006184647791087627, 'eval_loss_2': 0.003578856587409973, 'eval_loss_3': -18.32488250732422, 'eval_loss_4': 0.8542674779891968, 'epoch': 9.36}
{'loss': 0.0408, 'grad_norm': 10.054228782653809, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.03319520875811577, 'loss_2': 0.0076141357421875, 'loss_3': -16.388973236083984, 'loss_4': 1.1785131692886353, 'epoch': 9.37}
{'loss': 0.0192, 'grad_norm': 7.270511627197266, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.017327317968010902, 'loss_2': 0.0018329620361328125, 'loss_3': -16.489805221557617, 'loss_4': 0.8044352531433105, 'epoch': 9.37}
{'loss': 0.0232, 'grad_norm': 7.006902694702148, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.021706294268369675, 'loss_2': 0.0015239715576171875, 'loss_3': -16.51358413696289, 'loss_4': -0.05840916931629181, 'epoch': 9.38}
{'loss': 0.0178, 'grad_norm': 6.904475212097168, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.012004855088889599, 'loss_2': 0.0058135986328125, 'loss_3': -16.25152587890625, 'loss_4': 0.5017727017402649, 'epoch': 9.38}
{'loss': 0.0138, 'grad_norm': 6.054135322570801, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.010105006396770477, 'loss_2': 0.00373077392578125, 'loss_3': -16.355060577392578, 'loss_4': 1.4042062759399414, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 10:04:02,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:02,602 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:17<1:01:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:09,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015404828824102879, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.992, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008132107555866241, 'eval_loss_2': 0.0072727203369140625, 'eval_loss_3': -18.298789978027344, 'eval_loss_4': 0.8129196166992188, 'epoch': 9.39}
{'loss': 0.0238, 'grad_norm': 6.145562171936035, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.018146689981222153, 'loss_2': 0.0056915283203125, 'loss_3': -16.398818969726562, 'loss_4': 1.353724718093872, 'epoch': 9.4}
{'loss': 0.0165, 'grad_norm': 6.637152671813965, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.01564747281372547, 'loss_2': 0.000888824462890625, 'loss_3': -16.02587127685547, 'loss_4': 0.5608655214309692, 'epoch': 9.4}
{'loss': 0.0162, 'grad_norm': 6.297744274139404, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.010814698413014412, 'loss_2': 0.00534820556640625, 'loss_3': -16.338977813720703, 'loss_4': 1.4257636070251465, 'epoch': 9.41}
{'loss': 0.025, 'grad_norm': 5.595488548278809, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.013968274928629398, 'loss_2': 0.010986328125, 'loss_3': -16.336959838867188, 'loss_4': 0.9728444814682007, 'epoch': 9.41}
{'loss': 0.0512, 'grad_norm': 19.234989166259766, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.044572215527296066, 'loss_2': 0.0066680908203125, 'loss_3': -16.27828598022461, 'loss_4': 1.1576554775238037, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 10:04:09,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:09,947 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:24<1:01:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:17,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011429788544774055, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.522, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007897980511188507, 'eval_loss_2': 0.003531806170940399, 'eval_loss_3': -18.286571502685547, 'eval_loss_4': 0.8967890739440918, 'epoch': 9.42}
{'loss': 0.0372, 'grad_norm': 13.040855407714844, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.029808446764945984, 'loss_2': 0.00740814208984375, 'loss_3': -16.37328338623047, 'loss_4': 0.9694072008132935, 'epoch': 9.42}
{'loss': 0.0113, 'grad_norm': 5.349119186401367, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.008943278342485428, 'loss_2': 0.002391815185546875, 'loss_3': -16.58495330810547, 'loss_4': 0.5953799486160278, 'epoch': 9.43}
{'loss': 0.0131, 'grad_norm': 6.759644031524658, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.011458647437393665, 'loss_2': 0.0016832351684570312, 'loss_3': -16.346622467041016, 'loss_4': 1.6603200435638428, 'epoch': 9.44}
{'loss': 0.0078, 'grad_norm': 5.037561416625977, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.005284457467496395, 'loss_2': 0.002536773681640625, 'loss_3': -16.309307098388672, 'loss_4': 1.4437425136566162, 'epoch': 9.44}
{'loss': 0.019, 'grad_norm': 5.532256126403809, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.011248177848756313, 'loss_2': 0.00778961181640625, 'loss_3': -16.391029357910156, 'loss_4': 1.3136858940124512, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 10:04:17,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:17,305 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:31<1:00:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:24,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010318389162421227, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006799300666898489, 'eval_loss_2': 0.00351908802986145, 'eval_loss_3': -18.29987907409668, 'eval_loss_4': 1.2072709798812866, 'epoch': 9.45}
{'loss': 0.0122, 'grad_norm': 5.167479515075684, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.007766207214444876, 'loss_2': 0.004405975341796875, 'loss_3': -16.39755630493164, 'loss_4': 1.4855644702911377, 'epoch': 9.45}
{'loss': 0.0153, 'grad_norm': 6.857155799865723, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.011132881045341492, 'loss_2': 0.004119873046875, 'loss_3': -16.101940155029297, 'loss_4': 1.192375659942627, 'epoch': 9.46}
{'loss': 0.0111, 'grad_norm': 5.565307140350342, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.00837757345288992, 'loss_2': 0.002712249755859375, 'loss_3': -16.16265296936035, 'loss_4': 1.6234767436981201, 'epoch': 9.47}
{'loss': 0.0206, 'grad_norm': 11.322211265563965, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.014182834886014462, 'loss_2': 0.006381988525390625, 'loss_3': -16.327030181884766, 'loss_4': 0.8200728297233582, 'epoch': 9.47}
{'loss': 0.029, 'grad_norm': 9.434149742126465, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.02219134382903576, 'loss_2': 0.006805419921875, 'loss_3': -16.188621520996094, 'loss_4': 1.4050674438476562, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 10:04:24,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:24,642 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:39<1:00:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:31,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011773059144616127, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00677699688822031, 'eval_loss_2': 0.004996061325073242, 'eval_loss_3': -18.291908264160156, 'eval_loss_4': 1.2019706964492798, 'epoch': 9.48}
{'loss': 0.0302, 'grad_norm': 13.153804779052734, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.027302660048007965, 'loss_2': 0.002918243408203125, 'loss_3': -16.20509910583496, 'loss_4': 1.2558698654174805, 'epoch': 9.48}
{'loss': 0.0269, 'grad_norm': 10.442039489746094, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.0200868621468544, 'loss_2': 0.00684356689453125, 'loss_3': -16.265825271606445, 'loss_4': 2.0659008026123047, 'epoch': 9.49}
{'loss': 0.0254, 'grad_norm': 6.464972972869873, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.01348524447530508, 'loss_2': 0.0119476318359375, 'loss_3': -16.268007278442383, 'loss_4': 1.0567269325256348, 'epoch': 9.49}
{'loss': 0.028, 'grad_norm': 13.139043807983398, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.027657048776745796, 'loss_2': 0.0003809928894042969, 'loss_3': -16.12697982788086, 'loss_4': 1.0150431394577026, 'epoch': 9.5}
{'loss': 0.0139, 'grad_norm': 5.217761516571045, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.004997757729142904, 'loss_2': 0.0088958740234375, 'loss_3': -16.47364616394043, 'loss_4': 1.2979333400726318, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 10:04:31,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:31,986 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:46<1:00:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:39,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00845381710678339, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006021323148161173, 'eval_loss_2': 0.002432495355606079, 'eval_loss_3': -18.31070327758789, 'eval_loss_4': 1.0506458282470703, 'epoch': 9.51}
{'loss': 0.0176, 'grad_norm': 6.3762736320495605, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.014974442310631275, 'loss_2': 0.00258636474609375, 'loss_3': -16.370479583740234, 'loss_4': 1.8700625896453857, 'epoch': 9.51}
{'loss': 0.0214, 'grad_norm': 10.153996467590332, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.018481260165572166, 'loss_2': 0.0029144287109375, 'loss_3': -16.471925735473633, 'loss_4': 1.874351978302002, 'epoch': 9.52}
{'loss': 0.0273, 'grad_norm': 10.075643539428711, 'learning_rate': 2.05e-05, 'loss_1': 0.02555002085864544, 'loss_2': 0.001712799072265625, 'loss_3': -16.251224517822266, 'loss_4': 1.4416091442108154, 'epoch': 9.52}
{'loss': 0.0154, 'grad_norm': 6.224937438964844, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.01273109670728445, 'loss_2': 0.002651214599609375, 'loss_3': -16.414474487304688, 'loss_4': 0.8886376619338989, 'epoch': 9.53}
{'loss': 0.019, 'grad_norm': 6.5150885581970215, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.012982835993170738, 'loss_2': 0.006015777587890625, 'loss_3': -16.27012825012207, 'loss_4': 1.335242748260498, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 10:04:39,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:39,324 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [40:53<1:00:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:46,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009140925481915474, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006626741029322147, 'eval_loss_2': 0.002514183521270752, 'eval_loss_3': -18.303295135498047, 'eval_loss_4': 0.8629440665245056, 'epoch': 9.53}
{'loss': 0.0291, 'grad_norm': 10.055754661560059, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.024875598028302193, 'loss_2': 0.00421142578125, 'loss_3': -16.20107078552246, 'loss_4': 0.8367588520050049, 'epoch': 9.54}
{'loss': 0.0415, 'grad_norm': 11.635987281799316, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.03844577819108963, 'loss_2': 0.003055572509765625, 'loss_3': -16.341651916503906, 'loss_4': 1.1016005277633667, 'epoch': 9.55}
{'loss': 0.0339, 'grad_norm': 9.880237579345703, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.020374424755573273, 'loss_2': 0.01351165771484375, 'loss_3': -16.039081573486328, 'loss_4': 0.32930251955986023, 'epoch': 9.55}
{'loss': 0.0284, 'grad_norm': 11.320345878601074, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.02296845242381096, 'loss_2': 0.00540924072265625, 'loss_3': -16.254615783691406, 'loss_4': 0.8344676494598389, 'epoch': 9.56}
{'loss': 0.0169, 'grad_norm': 5.961849212646484, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.014947556890547276, 'loss_2': 0.0019168853759765625, 'loss_3': -16.10786247253418, 'loss_4': 1.0767699480056763, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 10:04:46,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:46,671 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:01<1:00:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:04:54,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012094104662537575, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.02, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007531129289418459, 'eval_loss_2': 0.004562973976135254, 'eval_loss_3': -18.282787322998047, 'eval_loss_4': 0.5694586038589478, 'epoch': 9.56}
{'loss': 0.037, 'grad_norm': 11.819042205810547, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.035976946353912354, 'loss_2': 0.000980377197265625, 'loss_3': -16.534652709960938, 'loss_4': 0.7240049242973328, 'epoch': 9.57}
{'loss': 0.0133, 'grad_norm': 4.936704158782959, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.009408422745764256, 'loss_2': 0.00388336181640625, 'loss_3': -16.17884063720703, 'loss_4': 0.7950414419174194, 'epoch': 9.58}
{'loss': 0.0259, 'grad_norm': 12.682097434997559, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.020466675981879234, 'loss_2': 0.005435943603515625, 'loss_3': -16.33547019958496, 'loss_4': 1.0015888214111328, 'epoch': 9.58}
{'loss': 0.0655, 'grad_norm': 20.635068893432617, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.06213049590587616, 'loss_2': 0.003326416015625, 'loss_3': -16.20945167541504, 'loss_4': 0.9111371040344238, 'epoch': 9.59}
{'loss': 0.0209, 'grad_norm': 5.616147518157959, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.011818915605545044, 'loss_2': 0.00908660888671875, 'loss_3': -16.396848678588867, 'loss_4': 0.5891863703727722, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 10:04:54,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:04:54,020 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:08<1:00:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:01,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00967798288911581, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.615, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007242865394800901, 'eval_loss_2': 0.0024351179599761963, 'eval_loss_3': -18.292640686035156, 'eval_loss_4': 0.3099103569984436, 'epoch': 9.59}
{'loss': 0.0198, 'grad_norm': 5.2186150550842285, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.011339040473103523, 'loss_2': 0.00844573974609375, 'loss_3': -16.092403411865234, 'loss_4': 0.4104078412055969, 'epoch': 9.6}
{'loss': 0.0338, 'grad_norm': 15.328237533569336, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.03196023777127266, 'loss_2': 0.0018062591552734375, 'loss_3': -16.478839874267578, 'loss_4': 0.352738618850708, 'epoch': 9.6}
{'loss': 0.0152, 'grad_norm': 6.209311485290527, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.012555125169456005, 'loss_2': 0.002597808837890625, 'loss_3': -16.347885131835938, 'loss_4': 0.7711889743804932, 'epoch': 9.61}
{'loss': 0.0147, 'grad_norm': 4.92406702041626, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.008272752165794373, 'loss_2': 0.0063934326171875, 'loss_3': -16.300952911376953, 'loss_4': 0.00454229861497879, 'epoch': 9.62}
{'loss': 0.0101, 'grad_norm': 5.352809906005859, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.008692060597240925, 'loss_2': 0.001369476318359375, 'loss_3': -16.444393157958984, 'loss_4': 0.17982622981071472, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 10:05:01,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:01,370 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:15<1:00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:08,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011217323131859303, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008132998831570148, 'eval_loss_2': 0.003084324300289154, 'eval_loss_3': -18.26458740234375, 'eval_loss_4': 0.10530971735715866, 'epoch': 9.62}
{'loss': 0.0129, 'grad_norm': 4.703389644622803, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.010297014378011227, 'loss_2': 0.00258636474609375, 'loss_3': -16.425004959106445, 'loss_4': 0.6062482595443726, 'epoch': 9.63}
{'loss': 0.0174, 'grad_norm': 6.214383602142334, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.011100828647613525, 'loss_2': 0.00626373291015625, 'loss_3': -16.21828842163086, 'loss_4': 0.3510540723800659, 'epoch': 9.63}
{'loss': 0.0266, 'grad_norm': 9.569429397583008, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.02453877218067646, 'loss_2': 0.00206756591796875, 'loss_3': -16.19744300842285, 'loss_4': -0.12690116465091705, 'epoch': 9.64}
{'loss': 0.0213, 'grad_norm': 7.2461347579956055, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.01610049232840538, 'loss_2': 0.005176544189453125, 'loss_3': -16.164615631103516, 'loss_4': 0.16625171899795532, 'epoch': 9.65}
{'loss': 0.0123, 'grad_norm': 5.845539569854736, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.01088313665241003, 'loss_2': 0.0014324188232421875, 'loss_3': -16.249011993408203, 'loss_4': 0.1695411652326584, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 10:05:08,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:08,710 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:23<1:00:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:16,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010955335572361946, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.012, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0076494826935231686, 'eval_loss_2': 0.0033058524131774902, 'eval_loss_3': -18.202531814575195, 'eval_loss_4': -0.05769025534391403, 'epoch': 9.65}
{'loss': 0.0346, 'grad_norm': 10.96011734008789, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.0321953110396862, 'loss_2': 0.00244903564453125, 'loss_3': -16.199493408203125, 'loss_4': -0.2659587264060974, 'epoch': 9.66}
{'loss': 0.0172, 'grad_norm': 6.818710803985596, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.012942077592015266, 'loss_2': 0.00421905517578125, 'loss_3': -16.317689895629883, 'loss_4': 0.04615544527769089, 'epoch': 9.66}
{'loss': 0.0176, 'grad_norm': 8.7189359664917, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.015007893554866314, 'loss_2': 0.0026397705078125, 'loss_3': -16.16919708251953, 'loss_4': 0.09972399473190308, 'epoch': 9.67}
{'loss': 0.0222, 'grad_norm': 5.626919746398926, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.0154989343136549, 'loss_2': 0.00669097900390625, 'loss_3': -16.187091827392578, 'loss_4': -0.12469299137592316, 'epoch': 9.67}
{'loss': 0.0248, 'grad_norm': 9.72033405303955, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.022530648857355118, 'loss_2': 0.00225067138671875, 'loss_3': -16.17626190185547, 'loss_4': -0.0700332447886467, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 10:05:16,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:16,056 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:30<1:00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:23,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009115008637309074, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005555420648306608, 'eval_loss_2': 0.003559589385986328, 'eval_loss_3': -18.2042293548584, 'eval_loss_4': -0.1451960653066635, 'epoch': 9.68}
{'loss': 0.0243, 'grad_norm': 16.112552642822266, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.02274862863123417, 'loss_2': 0.0015583038330078125, 'loss_3': -16.457202911376953, 'loss_4': -0.13399048149585724, 'epoch': 9.69}
{'loss': 0.0122, 'grad_norm': 4.770033359527588, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.008593841455876827, 'loss_2': 0.003559112548828125, 'loss_3': -16.130794525146484, 'loss_4': 0.22828614711761475, 'epoch': 9.69}
{'loss': 0.0137, 'grad_norm': 5.940268516540527, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.008578844368457794, 'loss_2': 0.00507354736328125, 'loss_3': -16.253705978393555, 'loss_4': 0.430403470993042, 'epoch': 9.7}
{'loss': 0.0323, 'grad_norm': 10.924752235412598, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.025281768292188644, 'loss_2': 0.0070648193359375, 'loss_3': -16.296531677246094, 'loss_4': -0.4946753680706024, 'epoch': 9.7}
{'loss': 0.0177, 'grad_norm': 8.726483345031738, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.017120350152254105, 'loss_2': 0.0005669593811035156, 'loss_3': -16.359771728515625, 'loss_4': -0.28465789556503296, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 10:05:23,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:23,403 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:37<1:00:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:30,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014300540089607239, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.882, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005570277571678162, 'eval_loss_2': 0.008730262517929077, 'eval_loss_3': -18.22528839111328, 'eval_loss_4': 0.08508018404245377, 'epoch': 9.71}
{'loss': 0.0226, 'grad_norm': 7.178916931152344, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.014466771855950356, 'loss_2': 0.00814056396484375, 'loss_3': -16.195842742919922, 'loss_4': -0.25138941407203674, 'epoch': 9.72}
{'loss': 0.027, 'grad_norm': 5.235601425170898, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.012330135330557823, 'loss_2': 0.01462554931640625, 'loss_3': -15.993597030639648, 'loss_4': 0.9311478734016418, 'epoch': 9.72}
{'loss': 0.0174, 'grad_norm': 4.946207523345947, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.009276116266846657, 'loss_2': 0.0081329345703125, 'loss_3': -16.332000732421875, 'loss_4': 0.5694268345832825, 'epoch': 9.73}
{'loss': 0.0154, 'grad_norm': 5.048618793487549, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.008410755544900894, 'loss_2': 0.00702667236328125, 'loss_3': -16.2565975189209, 'loss_4': 0.5546568632125854, 'epoch': 9.73}
{'loss': 0.0121, 'grad_norm': 5.404289722442627, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.0073546539060771465, 'loss_2': 0.004730224609375, 'loss_3': -16.33930206298828, 'loss_4': 1.0942432880401611, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 10:05:30,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:30,744 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:45<1:02:25,  1.08s/it][INFO|trainer.py:4226] 2025-01-21 10:05:38,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009057901799678802, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.669, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005555357318371534, 'eval_loss_2': 0.003502544015645981, 'eval_loss_3': -18.257526397705078, 'eval_loss_4': 0.4361485242843628, 'epoch': 9.74}
{'loss': 0.0236, 'grad_norm': 9.518531799316406, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.018050992861390114, 'loss_2': 0.00559234619140625, 'loss_3': -16.22683334350586, 'loss_4': 0.7587197422981262, 'epoch': 9.74}
{'loss': 0.0159, 'grad_norm': 7.014560699462891, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.012900728732347488, 'loss_2': 0.003040313720703125, 'loss_3': -16.31012725830078, 'loss_4': 0.8445378541946411, 'epoch': 9.75}
{'loss': 0.03, 'grad_norm': 9.1793851852417, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.02846996672451496, 'loss_2': 0.0015726089477539062, 'loss_3': -16.03599739074707, 'loss_4': -0.27460944652557373, 'epoch': 9.76}
{'loss': 0.0234, 'grad_norm': 9.843708992004395, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.014617503620684147, 'loss_2': 0.0088043212890625, 'loss_3': -16.0664005279541, 'loss_4': 1.416474461555481, 'epoch': 9.76}
{'loss': 0.0143, 'grad_norm': 5.672874927520752, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.010318707674741745, 'loss_2': 0.003971099853515625, 'loss_3': -16.188180923461914, 'loss_4': 1.0714569091796875, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 10:05:38,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:38,277 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:52<1:00:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:45,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014554332941770554, 'eval_runtime': 3.8193, 'eval_samples_per_second': 268.109, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.00609059352427721, 'eval_loss_2': 0.008463740348815918, 'eval_loss_3': -18.299774169921875, 'eval_loss_4': 0.8558530807495117, 'epoch': 9.77}
{'loss': 0.0294, 'grad_norm': 9.051273345947266, 'learning_rate': 2.025e-05, 'loss_1': 0.021528445184230804, 'loss_2': 0.0078277587890625, 'loss_3': -16.19026756286621, 'loss_4': 0.3688482642173767, 'epoch': 9.77}
{'loss': 0.0145, 'grad_norm': 5.235249996185303, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.01026978436857462, 'loss_2': 0.0042724609375, 'loss_3': -16.172203063964844, 'loss_4': 0.7803393006324768, 'epoch': 9.78}
{'loss': 0.0149, 'grad_norm': 5.4510931968688965, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.011018471792340279, 'loss_2': 0.0038604736328125, 'loss_3': -16.197032928466797, 'loss_4': 1.0780049562454224, 'epoch': 9.78}
{'loss': 0.0203, 'grad_norm': 10.12261962890625, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.016618117690086365, 'loss_2': 0.0037021636962890625, 'loss_3': -16.198366165161133, 'loss_4': 0.5696845054626465, 'epoch': 9.79}
{'loss': 0.0256, 'grad_norm': 12.84733772277832, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.019154444336891174, 'loss_2': 0.00641632080078125, 'loss_3': -16.18526840209961, 'loss_4': 1.414153814315796, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 10:05:45,635 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:45,635 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [42:00<1:00:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:05:52,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009818954393267632, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.707, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006219587288796902, 'eval_loss_2': 0.0035993680357933044, 'eval_loss_3': -18.276872634887695, 'eval_loss_4': 1.1799201965332031, 'epoch': 9.8}
{'loss': 0.012, 'grad_norm': 6.406345367431641, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.009072362445294857, 'loss_2': 0.002971649169921875, 'loss_3': -16.223556518554688, 'loss_4': 0.8532562851905823, 'epoch': 9.8}
{'loss': 0.0172, 'grad_norm': 5.651439666748047, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.012240526266396046, 'loss_2': 0.005008697509765625, 'loss_3': -16.183189392089844, 'loss_4': 1.6112451553344727, 'epoch': 9.81}
{'loss': 0.0121, 'grad_norm': 6.996313571929932, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.011271368712186813, 'loss_2': 0.0008487701416015625, 'loss_3': -16.18476104736328, 'loss_4': 2.1000804901123047, 'epoch': 9.81}
{'loss': 0.0185, 'grad_norm': 6.28369140625, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.009989161975681782, 'loss_2': 0.008514404296875, 'loss_3': -16.289794921875, 'loss_4': 1.4389081001281738, 'epoch': 9.82}
{'loss': 0.019, 'grad_norm': 7.974217891693115, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.01183142140507698, 'loss_2': 0.007171630859375, 'loss_3': -16.171184539794922, 'loss_4': 2.019477367401123, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 10:05:52,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:05:52,981 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [42:07<59:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:00,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010923749767243862, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.494, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0068326364271342754, 'eval_loss_2': 0.004091113805770874, 'eval_loss_3': -18.295963287353516, 'eval_loss_4': 1.3243123292922974, 'epoch': 9.83}
{'loss': 0.0177, 'grad_norm': 7.740842342376709, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.014867688529193401, 'loss_2': 0.002880096435546875, 'loss_3': -16.010635375976562, 'loss_4': 1.53079354763031, 'epoch': 9.83}
{'loss': 0.0139, 'grad_norm': 8.33341121673584, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.013031559996306896, 'loss_2': 0.0008406639099121094, 'loss_3': -16.30921173095703, 'loss_4': 2.00576114654541, 'epoch': 9.84}
{'loss': 0.0258, 'grad_norm': 6.498161792755127, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.017722729593515396, 'loss_2': 0.008056640625, 'loss_3': -16.113203048706055, 'loss_4': 1.6869502067565918, 'epoch': 9.84}
{'loss': 0.0105, 'grad_norm': 6.300654888153076, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.009755204431712627, 'loss_2': 0.0007877349853515625, 'loss_3': -16.120540618896484, 'loss_4': 1.0798134803771973, 'epoch': 9.85}
{'loss': 0.0113, 'grad_norm': 4.951066493988037, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.0072697182185947895, 'loss_2': 0.00406646728515625, 'loss_3': -16.351123809814453, 'loss_4': 1.5722315311431885, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 10:06:00,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:00,331 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:14<59:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:07,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01083776168525219, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.286, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006499005481600761, 'eval_loss_2': 0.004338756203651428, 'eval_loss_3': -18.279434204101562, 'eval_loss_4': 1.538468599319458, 'epoch': 9.85}
{'loss': 0.0199, 'grad_norm': 10.485740661621094, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.01790301315486431, 'loss_2': 0.002010345458984375, 'loss_3': -16.420612335205078, 'loss_4': 2.0900473594665527, 'epoch': 9.86}
{'loss': 0.0133, 'grad_norm': 8.215059280395508, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.011018532328307629, 'loss_2': 0.0023193359375, 'loss_3': -16.502426147460938, 'loss_4': 1.5985568761825562, 'epoch': 9.87}
{'loss': 0.0107, 'grad_norm': 5.500468730926514, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.010176092386245728, 'loss_2': 0.0005335807800292969, 'loss_3': -16.321353912353516, 'loss_4': 2.073319435119629, 'epoch': 9.87}
{'loss': 0.0088, 'grad_norm': 5.470091342926025, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.0073219602927565575, 'loss_2': 0.0014820098876953125, 'loss_3': -16.1093807220459, 'loss_4': 2.179030418395996, 'epoch': 9.88}
{'loss': 0.0297, 'grad_norm': 9.002250671386719, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.02394195832312107, 'loss_2': 0.00572967529296875, 'loss_3': -16.101591110229492, 'loss_4': 1.7083665132522583, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 10:06:07,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:07,690 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:22<59:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:15,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015176016837358475, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.598, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006755669601261616, 'eval_loss_2': 0.008420348167419434, 'eval_loss_3': -18.2720947265625, 'eval_loss_4': 1.614107370376587, 'epoch': 9.88}
{'loss': 0.0199, 'grad_norm': 6.270615577697754, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.009717917069792747, 'loss_2': 0.01021575927734375, 'loss_3': -16.06124496459961, 'loss_4': 2.1836702823638916, 'epoch': 9.89}
{'loss': 0.0177, 'grad_norm': 5.664168834686279, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.01118486188352108, 'loss_2': 0.0065460205078125, 'loss_3': -15.929903030395508, 'loss_4': 1.9827914237976074, 'epoch': 9.9}
{'loss': 0.025, 'grad_norm': 5.884997844696045, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.015069842338562012, 'loss_2': 0.00994873046875, 'loss_3': -16.148712158203125, 'loss_4': 1.8583486080169678, 'epoch': 9.9}
{'loss': 0.026, 'grad_norm': 7.87807559967041, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.017966710031032562, 'loss_2': 0.00799560546875, 'loss_3': -16.303787231445312, 'loss_4': 2.6650054454803467, 'epoch': 9.91}
{'loss': 0.029, 'grad_norm': 8.384858131408691, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.01991010643541813, 'loss_2': 0.009124755859375, 'loss_3': -16.158594131469727, 'loss_4': 2.0231029987335205, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 10:06:15,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:15,038 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:29<59:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:22,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01100320927798748, 'eval_runtime': 3.8265, 'eval_samples_per_second': 267.607, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.005880189593881369, 'eval_loss_2': 0.005123019218444824, 'eval_loss_3': -18.262855529785156, 'eval_loss_4': 1.6665384769439697, 'epoch': 9.91}
{'loss': 0.0134, 'grad_norm': 4.863943099975586, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.006836417131125927, 'loss_2': 0.00659942626953125, 'loss_3': -16.21096420288086, 'loss_4': 2.1303772926330566, 'epoch': 9.92}
{'loss': 0.0225, 'grad_norm': 6.335471153259277, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.011089224368333817, 'loss_2': 0.0113983154296875, 'loss_3': -16.132282257080078, 'loss_4': 1.1006109714508057, 'epoch': 9.92}
{'loss': 0.0131, 'grad_norm': 6.6882829666137695, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.012037558481097221, 'loss_2': 0.0011091232299804688, 'loss_3': -16.012882232666016, 'loss_4': 1.425459861755371, 'epoch': 9.93}
{'loss': 0.0435, 'grad_norm': 13.41402530670166, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.04048089310526848, 'loss_2': 0.0030498504638671875, 'loss_3': -16.186546325683594, 'loss_4': 2.049865245819092, 'epoch': 9.94}
{'loss': 0.0216, 'grad_norm': 7.228598594665527, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.018123257905244827, 'loss_2': 0.0034942626953125, 'loss_3': -16.32646942138672, 'loss_4': 1.1540141105651855, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 10:06:22,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:22,402 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:36<59:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:29,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010260766372084618, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.464, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0063382405787706375, 'eval_loss_2': 0.00392252579331398, 'eval_loss_3': -18.23200035095215, 'eval_loss_4': 1.312056541442871, 'epoch': 9.94}
{'loss': 0.0228, 'grad_norm': 6.994570255279541, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.01726987585425377, 'loss_2': 0.00555419921875, 'loss_3': -16.378246307373047, 'loss_4': 1.9618666172027588, 'epoch': 9.95}
{'loss': 0.0332, 'grad_norm': 15.160173416137695, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.02951887622475624, 'loss_2': 0.0036773681640625, 'loss_3': -16.229610443115234, 'loss_4': 0.8609998822212219, 'epoch': 9.95}
{'loss': 0.028, 'grad_norm': 7.117334842681885, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.014085534028708935, 'loss_2': 0.0139007568359375, 'loss_3': -16.277976989746094, 'loss_4': 0.7643910050392151, 'epoch': 9.96}
{'loss': 0.0287, 'grad_norm': 10.710919380187988, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.024620043113827705, 'loss_2': 0.00408172607421875, 'loss_3': -16.07419204711914, 'loss_4': 1.0239648818969727, 'epoch': 9.97}
{'loss': 0.0071, 'grad_norm': 5.143423557281494, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.0041775950230658054, 'loss_2': 0.0029468536376953125, 'loss_3': -16.194076538085938, 'loss_4': 0.8499323129653931, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 10:06:29,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:29,753 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:43<53:29,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:06:36,746 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01085570827126503, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00699051097035408, 'eval_loss_2': 0.0038651973009109497, 'eval_loss_3': -18.19476890563965, 'eval_loss_4': 1.1355634927749634, 'epoch': 9.97}
{'loss': 0.0247, 'grad_norm': 8.343360900878906, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.019124826416373253, 'loss_2': 0.00559234619140625, 'loss_3': -16.229820251464844, 'loss_4': 0.7792832851409912, 'epoch': 9.98}
{'loss': 0.0108, 'grad_norm': 5.888440132141113, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.006072451826184988, 'loss_2': 0.0047454833984375, 'loss_3': -16.286033630371094, 'loss_4': 0.7312143445014954, 'epoch': 9.98}
{'loss': 0.0159, 'grad_norm': 5.25114107131958, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.010182018391788006, 'loss_2': 0.00574493408203125, 'loss_3': -16.151718139648438, 'loss_4': 0.8965508937835693, 'epoch': 9.99}
{'loss': 0.0114, 'grad_norm': 5.601541519165039, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.010041111148893833, 'loss_2': 0.0013723373413085938, 'loss_3': -16.03766632080078, 'loss_4': 1.0505801439285278, 'epoch': 9.99}
{'loss': 0.0109, 'grad_norm': 5.654608726501465, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.0009714459301903844, 'loss_2': 0.0099334716796875, 'loss_3': -16.064762115478516, 'loss_4': 0.5681612491607666, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 10:06:36,746 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:36,746 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:51<58:31,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:06:44,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018046990036964417, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.692, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01200421154499054, 'eval_loss_2': 0.006042778491973877, 'eval_loss_3': -18.118741989135742, 'eval_loss_4': 1.1014734506607056, 'epoch': 10.0}
{'loss': 0.0136, 'grad_norm': 6.027303218841553, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.012717630714178085, 'loss_2': 0.000888824462890625, 'loss_3': -16.160842895507812, 'loss_4': 1.165151596069336, 'epoch': 10.01}
{'loss': 0.0169, 'grad_norm': 5.225835800170898, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.01079845242202282, 'loss_2': 0.006122589111328125, 'loss_3': -16.02446937561035, 'loss_4': 0.8875974416732788, 'epoch': 10.01}
{'loss': 0.0181, 'grad_norm': 13.10889720916748, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.012918861582875252, 'loss_2': 0.005157470703125, 'loss_3': -16.125429153442383, 'loss_4': 1.2387425899505615, 'epoch': 10.02}
{'loss': 0.0196, 'grad_norm': 5.126221179962158, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.00734086986631155, 'loss_2': 0.01226806640625, 'loss_3': -15.971050262451172, 'loss_4': 0.4522283673286438, 'epoch': 10.02}
{'loss': 0.0122, 'grad_norm': 6.382122039794922, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.008018712513148785, 'loss_2': 0.004161834716796875, 'loss_3': -16.15625762939453, 'loss_4': 0.9739943146705627, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 10:06:44,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:44,136 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [42:58<59:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:06:51,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020746957510709763, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.313, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.01393815502524376, 'eval_loss_2': 0.006808802485466003, 'eval_loss_3': -18.0874080657959, 'eval_loss_4': 1.058496356010437, 'epoch': 10.03}
{'loss': 0.0635, 'grad_norm': 25.056917190551758, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.056667447090148926, 'loss_2': 0.00685882568359375, 'loss_3': -16.089906692504883, 'loss_4': 0.635357677936554, 'epoch': 10.03}
{'loss': 0.0137, 'grad_norm': 5.165520668029785, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.007904056459665298, 'loss_2': 0.005764007568359375, 'loss_3': -16.339881896972656, 'loss_4': 1.18919837474823, 'epoch': 10.04}
{'loss': 0.0097, 'grad_norm': 5.045371055603027, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.007309724111109972, 'loss_2': 0.002368927001953125, 'loss_3': -16.002193450927734, 'loss_4': 0.7265270352363586, 'epoch': 10.05}
{'loss': 0.0084, 'grad_norm': 5.38405179977417, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.0075785331428050995, 'loss_2': 0.0008182525634765625, 'loss_3': -16.33359146118164, 'loss_4': 0.26840993762016296, 'epoch': 10.05}
{'loss': 0.0154, 'grad_norm': 6.0131449699401855, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.010602359659969807, 'loss_2': 0.004833221435546875, 'loss_3': -16.24722671508789, 'loss_4': 0.8012154698371887, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 10:06:51,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:51,487 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [43:06<59:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:06:58,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010967632755637169, 'eval_runtime': 3.8275, 'eval_samples_per_second': 267.535, 'eval_steps_per_second': 4.18, 'eval_loss_1': 0.007358839735388756, 'eval_loss_2': 0.003608793020248413, 'eval_loss_3': -18.1989803314209, 'eval_loss_4': 1.2813934087753296, 'epoch': 10.06}
{'loss': 0.0086, 'grad_norm': 4.550414562225342, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.003996479324996471, 'loss_2': 0.00460052490234375, 'loss_3': -16.308238983154297, 'loss_4': 1.7812888622283936, 'epoch': 10.06}
{'loss': 0.0184, 'grad_norm': 8.177734375, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.017934363335371017, 'loss_2': 0.0004515647888183594, 'loss_3': -16.084957122802734, 'loss_4': 1.502901315689087, 'epoch': 10.07}
{'loss': 0.0231, 'grad_norm': 7.648777008056641, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.013455991633236408, 'loss_2': 0.00960540771484375, 'loss_3': -16.286327362060547, 'loss_4': 1.331651210784912, 'epoch': 10.08}
{'loss': 0.0539, 'grad_norm': 13.107748031616211, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.052133142948150635, 'loss_2': 0.0018148422241210938, 'loss_3': -16.380783081054688, 'loss_4': 1.3704638481140137, 'epoch': 10.08}
{'loss': 0.0337, 'grad_norm': 14.58503532409668, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.030018799006938934, 'loss_2': 0.00365447998046875, 'loss_3': -16.12938690185547, 'loss_4': 1.6016349792480469, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 10:06:58,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:06:58,862 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:13<59:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:06,218 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009221500717103481, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.375, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.006127527914941311, 'eval_loss_2': 0.0030939728021621704, 'eval_loss_3': -18.257709503173828, 'eval_loss_4': 1.7362312078475952, 'epoch': 10.09}
{'loss': 0.0125, 'grad_norm': 5.383358001708984, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.008303324691951275, 'loss_2': 0.004154205322265625, 'loss_3': -16.198671340942383, 'loss_4': 1.2610125541687012, 'epoch': 10.09}
{'loss': 0.0173, 'grad_norm': 5.702613353729248, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.009364142082631588, 'loss_2': 0.007965087890625, 'loss_3': -16.138214111328125, 'loss_4': 1.6736286878585815, 'epoch': 10.1}
{'loss': 0.0113, 'grad_norm': 4.945394515991211, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.009516282007098198, 'loss_2': 0.0018291473388671875, 'loss_3': -16.142215728759766, 'loss_4': 1.4712413549423218, 'epoch': 10.1}
{'loss': 0.0215, 'grad_norm': 6.368361473083496, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.0186430923640728, 'loss_2': 0.002849578857421875, 'loss_3': -16.140682220458984, 'loss_4': 2.126458168029785, 'epoch': 10.11}
{'loss': 0.0246, 'grad_norm': 17.102569580078125, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.02201044000685215, 'loss_2': 0.0025463104248046875, 'loss_3': -16.297605514526367, 'loss_4': 2.4192867279052734, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 10:07:06,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:06,218 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:20<59:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:13,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009787485003471375, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.507, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0062747010961174965, 'eval_loss_2': 0.0035127848386764526, 'eval_loss_3': -18.246580123901367, 'eval_loss_4': 2.030421733856201, 'epoch': 10.12}
{'loss': 0.0098, 'grad_norm': 6.151318550109863, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.008596859872341156, 'loss_2': 0.001209259033203125, 'loss_3': -16.405380249023438, 'loss_4': 2.421656370162964, 'epoch': 10.12}
{'loss': 0.0204, 'grad_norm': 6.658790111541748, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.012800718657672405, 'loss_2': 0.0076141357421875, 'loss_3': -16.158916473388672, 'loss_4': 2.386547565460205, 'epoch': 10.13}
{'loss': 0.0111, 'grad_norm': 5.607867240905762, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.007688930258154869, 'loss_2': 0.003414154052734375, 'loss_3': -16.320480346679688, 'loss_4': 2.143573522567749, 'epoch': 10.13}
{'loss': 0.016, 'grad_norm': 6.886232376098633, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.01448883954435587, 'loss_2': 0.001468658447265625, 'loss_3': -16.322999954223633, 'loss_4': 1.6521146297454834, 'epoch': 10.14}
{'loss': 0.0092, 'grad_norm': 5.238842487335205, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.007832848466932774, 'loss_2': 0.001354217529296875, 'loss_3': -16.248088836669922, 'loss_4': 2.1041464805603027, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 10:07:13,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:13,573 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:28<58:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:20,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009450011886656284, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.713, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0064636105671525, 'eval_loss_2': 0.002986401319503784, 'eval_loss_3': -18.26844024658203, 'eval_loss_4': 2.1229043006896973, 'epoch': 10.15}
{'loss': 0.0071, 'grad_norm': 5.137783527374268, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.006851927377283573, 'loss_2': 0.0002218484878540039, 'loss_3': -15.991438865661621, 'loss_4': 2.3841233253479004, 'epoch': 10.15}
{'loss': 0.0173, 'grad_norm': 7.156599044799805, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.012419437058269978, 'loss_2': 0.0048828125, 'loss_3': -16.12717056274414, 'loss_4': 1.997798204421997, 'epoch': 10.16}
{'loss': 0.0282, 'grad_norm': 11.449498176574707, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.018273090943694115, 'loss_2': 0.00994873046875, 'loss_3': -16.266014099121094, 'loss_4': 2.26617431640625, 'epoch': 10.16}
{'loss': 0.016, 'grad_norm': 7.68737268447876, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.014955500140786171, 'loss_2': 0.0010223388671875, 'loss_3': -16.10386848449707, 'loss_4': 2.27986478805542, 'epoch': 10.17}
{'loss': 0.036, 'grad_norm': 16.202117919921875, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.03304704651236534, 'loss_2': 0.0029163360595703125, 'loss_3': -16.34191131591797, 'loss_4': 2.064586639404297, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 10:07:20,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:20,925 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:35<58:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:28,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010247188620269299, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.169, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.00720233004540205, 'eval_loss_2': 0.0030448585748672485, 'eval_loss_3': -18.293209075927734, 'eval_loss_4': 2.1450865268707275, 'epoch': 10.17}
{'loss': 0.0128, 'grad_norm': 6.09324312210083, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.012474172748625278, 'loss_2': 0.00030612945556640625, 'loss_3': -16.421680450439453, 'loss_4': 2.5125017166137695, 'epoch': 10.18}
{'loss': 0.0111, 'grad_norm': 4.112839698791504, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.008433645591139793, 'loss_2': 0.0026397705078125, 'loss_3': -16.225032806396484, 'loss_4': 2.2413196563720703, 'epoch': 10.19}
{'loss': 0.0229, 'grad_norm': 6.0277204513549805, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.011062046512961388, 'loss_2': 0.0118865966796875, 'loss_3': -16.203256607055664, 'loss_4': 2.574293613433838, 'epoch': 10.19}
{'loss': 0.015, 'grad_norm': 4.945207595825195, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.007286520209163427, 'loss_2': 0.00771331787109375, 'loss_3': -16.3769474029541, 'loss_4': 1.8059804439544678, 'epoch': 10.2}
{'loss': 0.025, 'grad_norm': 14.283397674560547, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.024110399186611176, 'loss_2': 0.0009164810180664062, 'loss_3': -16.03314208984375, 'loss_4': 1.9864119291305542, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 10:07:28,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:28,280 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:42<58:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:35,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01076645590364933, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.79, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006743038073182106, 'eval_loss_2': 0.004023417830467224, 'eval_loss_3': -18.273571014404297, 'eval_loss_4': 2.2409088611602783, 'epoch': 10.2}
{'loss': 0.0254, 'grad_norm': 6.650200843811035, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.021669844165444374, 'loss_2': 0.003772735595703125, 'loss_3': -16.19121551513672, 'loss_4': 2.6578867435455322, 'epoch': 10.21}
{'loss': 0.0229, 'grad_norm': 5.2952775955200195, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.01383549626916647, 'loss_2': 0.009063720703125, 'loss_3': -16.254467010498047, 'loss_4': 2.0487213134765625, 'epoch': 10.22}
{'loss': 0.0154, 'grad_norm': 6.457728862762451, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.015034656971693039, 'loss_2': 0.00033926963806152344, 'loss_3': -16.159896850585938, 'loss_4': 2.302248001098633, 'epoch': 10.22}
{'loss': 0.0085, 'grad_norm': 5.205531597137451, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.008327702060341835, 'loss_2': 0.00013399124145507812, 'loss_3': -16.3238468170166, 'loss_4': 2.1832706928253174, 'epoch': 10.23}
{'loss': 0.0182, 'grad_norm': 7.162873268127441, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.013908307068049908, 'loss_2': 0.00433349609375, 'loss_3': -16.028118133544922, 'loss_4': 2.4328367710113525, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 10:07:35,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:35,625 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:50<58:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:42,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010794799774885178, 'eval_runtime': 3.8341, 'eval_samples_per_second': 267.075, 'eval_steps_per_second': 4.173, 'eval_loss_1': 0.0070192040875554085, 'eval_loss_2': 0.0037755966186523438, 'eval_loss_3': -18.263507843017578, 'eval_loss_4': 2.261636734008789, 'epoch': 10.23}
{'loss': 0.012, 'grad_norm': 5.203227996826172, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.009934021160006523, 'loss_2': 0.00211334228515625, 'loss_3': -16.312192916870117, 'loss_4': 2.604935646057129, 'epoch': 10.24}
{'loss': 0.0132, 'grad_norm': 5.222934246063232, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.010036330670118332, 'loss_2': 0.003154754638671875, 'loss_3': -16.136220932006836, 'loss_4': 2.038024663925171, 'epoch': 10.24}
{'loss': 0.0112, 'grad_norm': 6.194206237792969, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.008324295282363892, 'loss_2': 0.0029125213623046875, 'loss_3': -16.081634521484375, 'loss_4': 2.148589611053467, 'epoch': 10.25}
{'loss': 0.0195, 'grad_norm': 8.298791885375977, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.017677927389740944, 'loss_2': 0.0017786026000976562, 'loss_3': -16.23794937133789, 'loss_4': 2.4567713737487793, 'epoch': 10.26}
{'loss': 0.0181, 'grad_norm': 5.263594150543213, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.006466955412179232, 'loss_2': 0.011627197265625, 'loss_3': -16.40689468383789, 'loss_4': 3.0046944618225098, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 10:07:42,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:42,998 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [43:57<58:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:50,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009340955875813961, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006191416643559933, 'eval_loss_2': 0.0031495392322540283, 'eval_loss_3': -18.281923294067383, 'eval_loss_4': 2.2795510292053223, 'epoch': 10.26}
{'loss': 0.0194, 'grad_norm': 7.271181583404541, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.012975272722542286, 'loss_2': 0.006420135498046875, 'loss_3': -16.192665100097656, 'loss_4': 2.07893967628479, 'epoch': 10.27}
{'loss': 0.0126, 'grad_norm': 7.584114074707031, 'learning_rate': 1.975e-05, 'loss_1': 0.011227725073695183, 'loss_2': 0.001373291015625, 'loss_3': -16.166934967041016, 'loss_4': 2.2968268394470215, 'epoch': 10.27}
{'loss': 0.0109, 'grad_norm': 5.590620040893555, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.008210686966776848, 'loss_2': 0.002651214599609375, 'loss_3': -16.36039924621582, 'loss_4': 2.953134298324585, 'epoch': 10.28}
{'loss': 0.0231, 'grad_norm': 5.9825263023376465, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.013122648000717163, 'loss_2': 0.0099945068359375, 'loss_3': -16.183574676513672, 'loss_4': 2.62082576751709, 'epoch': 10.28}
{'loss': 0.0229, 'grad_norm': 10.176054954528809, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.020154356956481934, 'loss_2': 0.0027256011962890625, 'loss_3': -16.297388076782227, 'loss_4': 3.2179012298583984, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 10:07:50,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:50,351 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:04<58:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:07:57,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011063339188694954, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0062143513932824135, 'eval_loss_2': 0.004848986864089966, 'eval_loss_3': -18.29315948486328, 'eval_loss_4': 2.4571478366851807, 'epoch': 10.29}
{'loss': 0.0166, 'grad_norm': 4.869783878326416, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.00739935552701354, 'loss_2': 0.009246826171875, 'loss_3': -16.25669288635254, 'loss_4': 2.117180347442627, 'epoch': 10.3}
{'loss': 0.0187, 'grad_norm': 7.627466201782227, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.014132650569081306, 'loss_2': 0.004611968994140625, 'loss_3': -16.297508239746094, 'loss_4': 2.9369492530822754, 'epoch': 10.3}
{'loss': 0.0259, 'grad_norm': 11.4338960647583, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.025159204378724098, 'loss_2': 0.0007486343383789062, 'loss_3': -16.21508026123047, 'loss_4': 2.828664541244507, 'epoch': 10.31}
{'loss': 0.0228, 'grad_norm': 6.359911918640137, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.01737980544567108, 'loss_2': 0.00545501708984375, 'loss_3': -16.164899826049805, 'loss_4': 2.1129531860351562, 'epoch': 10.31}
{'loss': 0.0223, 'grad_norm': 7.14195442199707, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.017017513513565063, 'loss_2': 0.005268096923828125, 'loss_3': -16.232192993164062, 'loss_4': 2.191305160522461, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 10:07:57,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:07:57,695 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:12<58:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:05,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010900909081101418, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.778, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0060808006674051285, 'eval_loss_2': 0.004820108413696289, 'eval_loss_3': -18.288707733154297, 'eval_loss_4': 2.529724359512329, 'epoch': 10.32}
{'loss': 0.0139, 'grad_norm': 5.336491584777832, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.009510143660008907, 'loss_2': 0.004421234130859375, 'loss_3': -16.05467987060547, 'loss_4': 2.369297504425049, 'epoch': 10.33}
{'loss': 0.0326, 'grad_norm': 23.4356632232666, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.0319531224668026, 'loss_2': 0.000637054443359375, 'loss_3': -16.294273376464844, 'loss_4': 2.569363594055176, 'epoch': 10.33}
{'loss': 0.0176, 'grad_norm': 7.173226833343506, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.013561815023422241, 'loss_2': 0.004016876220703125, 'loss_3': -16.393367767333984, 'loss_4': 3.4614930152893066, 'epoch': 10.34}
{'loss': 0.0112, 'grad_norm': 5.081845760345459, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.008524536155164242, 'loss_2': 0.002643585205078125, 'loss_3': -16.253774642944336, 'loss_4': 2.8299899101257324, 'epoch': 10.34}
{'loss': 0.0138, 'grad_norm': 5.712985992431641, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.012872366234660149, 'loss_2': 0.000946044921875, 'loss_3': -16.196212768554688, 'loss_4': 2.4589710235595703, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 10:08:05,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:05,039 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:19<58:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:12,380 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008646875619888306, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.022, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0056414310820400715, 'eval_loss_2': 0.0030054450035095215, 'eval_loss_3': -18.273895263671875, 'eval_loss_4': 2.321854829788208, 'epoch': 10.35}
{'loss': 0.012, 'grad_norm': 5.914351463317871, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.00956273078918457, 'loss_2': 0.00244140625, 'loss_3': -16.185752868652344, 'loss_4': 2.3855669498443604, 'epoch': 10.35}
{'loss': 0.0152, 'grad_norm': 5.973904609680176, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.01199705433100462, 'loss_2': 0.003200531005859375, 'loss_3': -16.238489151000977, 'loss_4': 2.5947351455688477, 'epoch': 10.36}
{'loss': 0.0118, 'grad_norm': 5.9910054206848145, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.011231637559831142, 'loss_2': 0.000568389892578125, 'loss_3': -16.18568992614746, 'loss_4': 2.721513509750366, 'epoch': 10.37}
{'loss': 0.0123, 'grad_norm': 5.864501476287842, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.010343407280743122, 'loss_2': 0.001995086669921875, 'loss_3': -16.400123596191406, 'loss_4': 1.8334002494812012, 'epoch': 10.37}
{'loss': 0.0221, 'grad_norm': 9.306378364562988, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.019710563123226166, 'loss_2': 0.00235748291015625, 'loss_3': -16.31357192993164, 'loss_4': 2.1901307106018066, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 10:08:12,380 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:12,380 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:26<58:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:19,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00953841581940651, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.54, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005680090747773647, 'eval_loss_2': 0.0038583241403102875, 'eval_loss_3': -18.256166458129883, 'eval_loss_4': 1.9999496936798096, 'epoch': 10.38}
{'loss': 0.0297, 'grad_norm': 15.31428337097168, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.027708381414413452, 'loss_2': 0.001953125, 'loss_3': -16.288818359375, 'loss_4': 1.6218631267547607, 'epoch': 10.38}
{'loss': 0.0228, 'grad_norm': 6.741788387298584, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.012952552177011967, 'loss_2': 0.0098419189453125, 'loss_3': -16.385086059570312, 'loss_4': 2.7988407611846924, 'epoch': 10.39}
{'loss': 0.0087, 'grad_norm': 5.572630882263184, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.008182593621313572, 'loss_2': 0.0005331039428710938, 'loss_3': -16.198659896850586, 'loss_4': 1.9294993877410889, 'epoch': 10.4}
{'loss': 0.0228, 'grad_norm': 4.762773513793945, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.008634067140519619, 'loss_2': 0.01413726806640625, 'loss_3': -16.453357696533203, 'loss_4': 1.4172954559326172, 'epoch': 10.4}
{'loss': 0.0136, 'grad_norm': 5.558528900146484, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.013484051451086998, 'loss_2': 0.00010544061660766602, 'loss_3': -16.354707717895508, 'loss_4': 1.8034882545471191, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 10:08:19,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:19,742 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:34<58:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:27,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01013784110546112, 'eval_runtime': 3.8246, 'eval_samples_per_second': 267.739, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.005922951269894838, 'eval_loss_2': 0.00421489030122757, 'eval_loss_3': -18.276805877685547, 'eval_loss_4': 1.5356967449188232, 'epoch': 10.41}
{'loss': 0.0147, 'grad_norm': 4.605567455291748, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.005561862140893936, 'loss_2': 0.0091705322265625, 'loss_3': -16.41569709777832, 'loss_4': 1.8132150173187256, 'epoch': 10.41}
{'loss': 0.0208, 'grad_norm': 7.1620073318481445, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.017362700775265694, 'loss_2': 0.003406524658203125, 'loss_3': -16.398353576660156, 'loss_4': 1.1165882349014282, 'epoch': 10.42}
{'loss': 0.029, 'grad_norm': 9.045005798339844, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.023101430386304855, 'loss_2': 0.00592041015625, 'loss_3': -16.09328842163086, 'loss_4': 0.8760519027709961, 'epoch': 10.42}
{'loss': 0.0321, 'grad_norm': 11.71453857421875, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.02943931147456169, 'loss_2': 0.00264739990234375, 'loss_3': -16.308208465576172, 'loss_4': 1.1567554473876953, 'epoch': 10.43}
{'loss': 0.0201, 'grad_norm': 7.807929039001465, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.01904367282986641, 'loss_2': 0.001102447509765625, 'loss_3': -16.215412139892578, 'loss_4': 1.3733081817626953, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 10:08:27,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:27,105 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:41<58:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:34,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00940360501408577, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006084236316382885, 'eval_loss_2': 0.00331936776638031, 'eval_loss_3': -18.288232803344727, 'eval_loss_4': 1.329619288444519, 'epoch': 10.44}
{'loss': 0.0125, 'grad_norm': 5.830101490020752, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.010179838165640831, 'loss_2': 0.0022983551025390625, 'loss_3': -16.296371459960938, 'loss_4': 1.0153188705444336, 'epoch': 10.44}
{'loss': 0.0258, 'grad_norm': 11.515429496765137, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.02368425391614437, 'loss_2': 0.0021457672119140625, 'loss_3': -16.283645629882812, 'loss_4': 1.239166498184204, 'epoch': 10.45}
{'loss': 0.0334, 'grad_norm': 8.56815242767334, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.024597542360424995, 'loss_2': 0.00885009765625, 'loss_3': -16.362565994262695, 'loss_4': 0.7155622839927673, 'epoch': 10.45}
{'loss': 0.0275, 'grad_norm': 5.697075366973877, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.017603129148483276, 'loss_2': 0.00988006591796875, 'loss_3': -16.306827545166016, 'loss_4': 1.280992031097412, 'epoch': 10.46}
{'loss': 0.038, 'grad_norm': 12.422178268432617, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.02660454250872135, 'loss_2': 0.01140594482421875, 'loss_3': -16.376907348632812, 'loss_4': 1.7671961784362793, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 10:08:34,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:34,443 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:49<57:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:41,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009386547841131687, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0064645493403077126, 'eval_loss_2': 0.0029219985008239746, 'eval_loss_3': -18.308807373046875, 'eval_loss_4': 1.22321617603302, 'epoch': 10.47}
{'loss': 0.0214, 'grad_norm': 8.196666717529297, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.020677248015999794, 'loss_2': 0.0007314682006835938, 'loss_3': -16.299945831298828, 'loss_4': 1.4235650300979614, 'epoch': 10.47}
{'loss': 0.0138, 'grad_norm': 5.650279998779297, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.013248701579868793, 'loss_2': 0.0005273818969726562, 'loss_3': -16.263591766357422, 'loss_4': 0.8008416891098022, 'epoch': 10.48}
{'loss': 0.0228, 'grad_norm': 6.333993911743164, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.012001659721136093, 'loss_2': 0.0108184814453125, 'loss_3': -16.40436553955078, 'loss_4': 0.7872602939605713, 'epoch': 10.48}
{'loss': 0.0203, 'grad_norm': 7.212337493896484, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.01666661724448204, 'loss_2': 0.0036258697509765625, 'loss_3': -16.331241607666016, 'loss_4': 0.5852071642875671, 'epoch': 10.49}
{'loss': 0.0128, 'grad_norm': 5.981812000274658, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.011515635065734386, 'loss_2': 0.0012874603271484375, 'loss_3': -16.39114761352539, 'loss_4': 1.4962615966796875, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 10:08:41,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:41,786 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [44:56<57:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:49,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009798004291951656, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.031, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006082681939005852, 'eval_loss_2': 0.00371532142162323, 'eval_loss_3': -18.342178344726562, 'eval_loss_4': 1.063122034072876, 'epoch': 10.49}
{'loss': 0.0238, 'grad_norm': 5.492702484130859, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.014990115538239479, 'loss_2': 0.0088043212890625, 'loss_3': -16.282882690429688, 'loss_4': 0.7589874267578125, 'epoch': 10.5}
{'loss': 0.0103, 'grad_norm': 6.049619197845459, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.009016964584589005, 'loss_2': 0.0013141632080078125, 'loss_3': -16.364864349365234, 'loss_4': 1.5758377313613892, 'epoch': 10.51}
{'loss': 0.0303, 'grad_norm': 10.957106590270996, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.02845836617052555, 'loss_2': 0.0018491744995117188, 'loss_3': -16.230682373046875, 'loss_4': 0.7242474555969238, 'epoch': 10.51}
{'loss': 0.0296, 'grad_norm': 8.658793449401855, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.02542700618505478, 'loss_2': 0.00421905517578125, 'loss_3': -16.233291625976562, 'loss_4': 1.4040448665618896, 'epoch': 10.52}
{'loss': 0.0143, 'grad_norm': 4.896405220031738, 'learning_rate': 1.95e-05, 'loss_1': 0.007125962525606155, 'loss_2': 0.0071258544921875, 'loss_3': -16.40485191345215, 'loss_4': 1.8401645421981812, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 10:08:49,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:49,130 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:03<57:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:08:56,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009171472862362862, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005619616247713566, 'eval_loss_2': 0.003551855683326721, 'eval_loss_3': -18.35535430908203, 'eval_loss_4': 1.140842318534851, 'epoch': 10.52}
{'loss': 0.0078, 'grad_norm': 4.314815998077393, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.007043611258268356, 'loss_2': 0.0007205009460449219, 'loss_3': -16.419540405273438, 'loss_4': 0.9894657135009766, 'epoch': 10.53}
{'loss': 0.0297, 'grad_norm': 9.819426536560059, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.025801455602049828, 'loss_2': 0.00392913818359375, 'loss_3': -16.352331161499023, 'loss_4': 1.4407087564468384, 'epoch': 10.53}
{'loss': 0.0177, 'grad_norm': 5.866860866546631, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.01458705309778452, 'loss_2': 0.003162384033203125, 'loss_3': -16.43952178955078, 'loss_4': 1.6830449104309082, 'epoch': 10.54}
{'loss': 0.0193, 'grad_norm': 8.291312217712402, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.01895001158118248, 'loss_2': 0.0003933906555175781, 'loss_3': -16.19282341003418, 'loss_4': 1.0042669773101807, 'epoch': 10.55}
{'loss': 0.0172, 'grad_norm': 6.949195861816406, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.014091153629124165, 'loss_2': 0.003070831298828125, 'loss_3': -16.334712982177734, 'loss_4': 1.7046127319335938, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 10:08:56,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:08:56,472 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:11<57:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:03,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011671793647110462, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.178, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006348263472318649, 'eval_loss_2': 0.005323529243469238, 'eval_loss_3': -18.361682891845703, 'eval_loss_4': 1.541787028312683, 'epoch': 10.55}
{'loss': 0.0372, 'grad_norm': 11.878764152526855, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.033357977867126465, 'loss_2': 0.0038356781005859375, 'loss_3': -16.477991104125977, 'loss_4': 2.5931835174560547, 'epoch': 10.56}
{'loss': 0.0192, 'grad_norm': 11.704191207885742, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.018216796219348907, 'loss_2': 0.000934600830078125, 'loss_3': -16.526817321777344, 'loss_4': 1.6711881160736084, 'epoch': 10.56}
{'loss': 0.0153, 'grad_norm': 5.35936975479126, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.008999175392091274, 'loss_2': 0.006320953369140625, 'loss_3': -16.499910354614258, 'loss_4': 1.6479976177215576, 'epoch': 10.57}
{'loss': 0.0262, 'grad_norm': 9.457138061523438, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.021016668528318405, 'loss_2': 0.00514984130859375, 'loss_3': -16.289878845214844, 'loss_4': 2.5288777351379395, 'epoch': 10.58}
{'loss': 0.0176, 'grad_norm': 5.541335582733154, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.008307033218443394, 'loss_2': 0.009246826171875, 'loss_3': -16.332059860229492, 'loss_4': 1.7209138870239258, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 10:09:03,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:03,836 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:18<57:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:11,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009382529184222221, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006451142951846123, 'eval_loss_2': 0.0029313862323760986, 'eval_loss_3': -18.355396270751953, 'eval_loss_4': 1.6473939418792725, 'epoch': 10.58}
{'loss': 0.0122, 'grad_norm': 5.4687418937683105, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.011512575671076775, 'loss_2': 0.0006999969482421875, 'loss_3': -16.40812873840332, 'loss_4': 1.1774489879608154, 'epoch': 10.59}
{'loss': 0.0112, 'grad_norm': 5.811990261077881, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.010566099546849728, 'loss_2': 0.00067901611328125, 'loss_3': -16.331653594970703, 'loss_4': 1.868672490119934, 'epoch': 10.59}
{'loss': 0.0355, 'grad_norm': 7.60451602935791, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.02793515846133232, 'loss_2': 0.007610321044921875, 'loss_3': -16.43585777282715, 'loss_4': 2.187746047973633, 'epoch': 10.6}
{'loss': 0.0353, 'grad_norm': 12.224799156188965, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.034404173493385315, 'loss_2': 0.0009145736694335938, 'loss_3': -16.37447166442871, 'loss_4': 2.119314670562744, 'epoch': 10.6}
{'loss': 0.0199, 'grad_norm': 4.987508296966553, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.012419058009982109, 'loss_2': 0.007503509521484375, 'loss_3': -16.12472915649414, 'loss_4': 2.04358172416687, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 10:09:11,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:11,183 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:25<57:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:18,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013665813952684402, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007295328192412853, 'eval_loss_2': 0.006370484828948975, 'eval_loss_3': -18.390785217285156, 'eval_loss_4': 1.5909620523452759, 'epoch': 10.61}
{'loss': 0.0223, 'grad_norm': 7.0295844078063965, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.017761919647455215, 'loss_2': 0.00453948974609375, 'loss_3': -16.522174835205078, 'loss_4': 1.9937026500701904, 'epoch': 10.62}
{'loss': 0.0229, 'grad_norm': 9.236499786376953, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.018195485696196556, 'loss_2': 0.00469970703125, 'loss_3': -16.153522491455078, 'loss_4': 1.6317996978759766, 'epoch': 10.62}
{'loss': 0.0322, 'grad_norm': 10.491670608520508, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.026588931679725647, 'loss_2': 0.005580902099609375, 'loss_3': -16.223304748535156, 'loss_4': 1.0877983570098877, 'epoch': 10.63}
{'loss': 0.0335, 'grad_norm': 7.03455924987793, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.02355891652405262, 'loss_2': 0.0099029541015625, 'loss_3': -16.340042114257812, 'loss_4': 1.5481059551239014, 'epoch': 10.63}
{'loss': 0.0378, 'grad_norm': 11.62460994720459, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.03453919291496277, 'loss_2': 0.003253936767578125, 'loss_3': -16.346160888671875, 'loss_4': 2.2139816284179688, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 10:09:18,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:18,523 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:33<57:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:25,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010205836966633797, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.065, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006970572285354137, 'eval_loss_2': 0.003235265612602234, 'eval_loss_3': -18.381105422973633, 'eval_loss_4': 1.2996368408203125, 'epoch': 10.64}
{'loss': 0.0287, 'grad_norm': 10.342781066894531, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.027339033782482147, 'loss_2': 0.001399993896484375, 'loss_3': -16.256591796875, 'loss_4': 1.3474230766296387, 'epoch': 10.65}
{'loss': 0.0127, 'grad_norm': 5.293835639953613, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.01127469539642334, 'loss_2': 0.00139617919921875, 'loss_3': -16.239944458007812, 'loss_4': 1.4194135665893555, 'epoch': 10.65}
{'loss': 0.0342, 'grad_norm': 10.43078327178955, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.02488107606768608, 'loss_2': 0.00933837890625, 'loss_3': -16.22797203063965, 'loss_4': 2.2035224437713623, 'epoch': 10.66}
{'loss': 0.0407, 'grad_norm': 12.487778663635254, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.03694424405694008, 'loss_2': 0.0037250518798828125, 'loss_3': -16.30337142944336, 'loss_4': 1.8987302780151367, 'epoch': 10.66}
{'loss': 0.0299, 'grad_norm': 8.303092956542969, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.020720666274428368, 'loss_2': 0.00913238525390625, 'loss_3': -16.29888153076172, 'loss_4': 1.9332120418548584, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 10:09:25,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:25,861 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:40<57:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:33,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013965334743261337, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0069607156328856945, 'eval_loss_2': 0.0070046186447143555, 'eval_loss_3': -18.387367248535156, 'eval_loss_4': 1.0868713855743408, 'epoch': 10.67}
{'loss': 0.0248, 'grad_norm': 12.179564476013184, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.021439220756292343, 'loss_2': 0.00336456298828125, 'loss_3': -16.082801818847656, 'loss_4': 1.9201772212982178, 'epoch': 10.67}
{'loss': 0.0534, 'grad_norm': 18.092838287353516, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.04264850541949272, 'loss_2': 0.01074981689453125, 'loss_3': -16.12819480895996, 'loss_4': 1.407496452331543, 'epoch': 10.68}
{'loss': 0.0378, 'grad_norm': 8.554825782775879, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.03203783929347992, 'loss_2': 0.005748748779296875, 'loss_3': -16.2337703704834, 'loss_4': 1.8518240451812744, 'epoch': 10.69}
{'loss': 0.0198, 'grad_norm': 5.027790069580078, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.011310093104839325, 'loss_2': 0.00847625732421875, 'loss_3': -16.319063186645508, 'loss_4': 0.7863326668739319, 'epoch': 10.69}
{'loss': 0.0189, 'grad_norm': 6.846075057983398, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.018525155261158943, 'loss_2': 0.0003581047058105469, 'loss_3': -16.19888687133789, 'loss_4': 1.5911152362823486, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 10:09:33,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:33,195 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:47<57:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:40,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01011900044977665, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007471623830497265, 'eval_loss_2': 0.0026473775506019592, 'eval_loss_3': -18.36776351928711, 'eval_loss_4': 0.841164231300354, 'epoch': 10.7}
{'loss': 0.0156, 'grad_norm': 5.853366851806641, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.013345631770789623, 'loss_2': 0.0022716522216796875, 'loss_3': -16.210899353027344, 'loss_4': 0.764936089515686, 'epoch': 10.7}
{'loss': 0.0794, 'grad_norm': 13.167941093444824, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.07541035115718842, 'loss_2': 0.003955841064453125, 'loss_3': -16.375778198242188, 'loss_4': 0.9488739967346191, 'epoch': 10.71}
{'loss': 0.0313, 'grad_norm': 9.439305305480957, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.026736397296190262, 'loss_2': 0.00460052490234375, 'loss_3': -16.30377197265625, 'loss_4': 0.5308140516281128, 'epoch': 10.72}
{'loss': 0.0198, 'grad_norm': 7.330065727233887, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.01417760830372572, 'loss_2': 0.00560760498046875, 'loss_3': -16.276670455932617, 'loss_4': 0.580335795879364, 'epoch': 10.72}
{'loss': 0.0347, 'grad_norm': 9.373217582702637, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.033073361963033676, 'loss_2': 0.0016078948974609375, 'loss_3': -16.212608337402344, 'loss_4': 1.0819010734558105, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 10:09:40,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:40,539 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [45:55<57:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:47,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011748160235583782, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.126, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.007477369159460068, 'eval_loss_2': 0.004270792007446289, 'eval_loss_3': -18.312742233276367, 'eval_loss_4': 0.8231794238090515, 'epoch': 10.73}
{'loss': 0.0172, 'grad_norm': 6.5712761878967285, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.01666499860584736, 'loss_2': 0.0005097389221191406, 'loss_3': -16.13266372680664, 'loss_4': 1.0880334377288818, 'epoch': 10.73}
{'loss': 0.0435, 'grad_norm': 12.499682426452637, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.03953200951218605, 'loss_2': 0.00397491455078125, 'loss_3': -16.257369995117188, 'loss_4': 1.6261358261108398, 'epoch': 10.74}
{'loss': 0.037, 'grad_norm': 7.898064613342285, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.03373219445347786, 'loss_2': 0.003253936767578125, 'loss_3': -16.502166748046875, 'loss_4': 0.6513113379478455, 'epoch': 10.74}
{'loss': 0.0182, 'grad_norm': 7.476874828338623, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.018003080040216446, 'loss_2': 0.0001722574234008789, 'loss_3': -16.27374267578125, 'loss_4': 0.8140528202056885, 'epoch': 10.75}
{'loss': 0.0483, 'grad_norm': 15.60790729522705, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.045267172157764435, 'loss_2': 0.00299072265625, 'loss_3': -16.384191513061523, 'loss_4': 1.0910873413085938, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 10:09:47,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:47,895 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:02<57:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:09:55,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0104078259319067, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.83, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007164156064391136, 'eval_loss_2': 0.003243669867515564, 'eval_loss_3': -18.29656219482422, 'eval_loss_4': 1.0740764141082764, 'epoch': 10.76}
{'loss': 0.015, 'grad_norm': 5.660733222961426, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.012006291188299656, 'loss_2': 0.00298309326171875, 'loss_3': -16.373130798339844, 'loss_4': 1.2723814249038696, 'epoch': 10.76}
{'loss': 0.0239, 'grad_norm': 10.272512435913086, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.018747640773653984, 'loss_2': 0.0051422119140625, 'loss_3': -16.255983352661133, 'loss_4': 1.0697146654129028, 'epoch': 10.77}
{'loss': 0.0322, 'grad_norm': 17.899269104003906, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.02979229763150215, 'loss_2': 0.002399444580078125, 'loss_3': -16.233936309814453, 'loss_4': 1.343994379043579, 'epoch': 10.77}
{'loss': 0.0202, 'grad_norm': 8.344415664672852, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.017256876453757286, 'loss_2': 0.00299072265625, 'loss_3': -16.206954956054688, 'loss_4': 1.4652888774871826, 'epoch': 10.78}
{'loss': 0.0227, 'grad_norm': 7.024141311645508, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.013335278257727623, 'loss_2': 0.00934600830078125, 'loss_3': -16.358991622924805, 'loss_4': 0.9842654466629028, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 10:09:55,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:09:55,236 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:09<57:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:02,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011994733475148678, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007460907567292452, 'eval_loss_2': 0.004533827304840088, 'eval_loss_3': -18.278703689575195, 'eval_loss_4': 1.3394980430603027, 'epoch': 10.78}
{'loss': 0.0145, 'grad_norm': 5.161634922027588, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.00920573715120554, 'loss_2': 0.005279541015625, 'loss_3': -16.147968292236328, 'loss_4': 1.0759499073028564, 'epoch': 10.79}
{'loss': 0.01, 'grad_norm': 5.212292194366455, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.00852723978459835, 'loss_2': 0.001461029052734375, 'loss_3': -16.210636138916016, 'loss_4': 1.25699782371521, 'epoch': 10.8}
{'loss': 0.0135, 'grad_norm': 5.23976993560791, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.010313899256289005, 'loss_2': 0.003162384033203125, 'loss_3': -16.347915649414062, 'loss_4': 1.4559706449508667, 'epoch': 10.8}
{'loss': 0.0474, 'grad_norm': 13.822965621948242, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.034425295889377594, 'loss_2': 0.012939453125, 'loss_3': -16.134056091308594, 'loss_4': 1.7544609308242798, 'epoch': 10.81}
{'loss': 0.0246, 'grad_norm': 8.298001289367676, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.020166130736470222, 'loss_2': 0.0044403076171875, 'loss_3': -16.45406150817871, 'loss_4': 1.609837532043457, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 10:10:02,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:02,579 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:17<56:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:09,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011377844959497452, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00739031657576561, 'eval_loss_2': 0.003987528383731842, 'eval_loss_3': -18.246923446655273, 'eval_loss_4': 1.5170612335205078, 'epoch': 10.81}
{'loss': 0.0152, 'grad_norm': 5.30425500869751, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.014827407896518707, 'loss_2': 0.000339508056640625, 'loss_3': -16.187118530273438, 'loss_4': 1.1780328750610352, 'epoch': 10.82}
{'loss': 0.0124, 'grad_norm': 4.58432149887085, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.00923924706876278, 'loss_2': 0.0032100677490234375, 'loss_3': -16.390451431274414, 'loss_4': 1.6117093563079834, 'epoch': 10.83}
{'loss': 0.0157, 'grad_norm': 6.635136604309082, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.014344711787998676, 'loss_2': 0.0013780593872070312, 'loss_3': -16.13202667236328, 'loss_4': 1.3793803453445435, 'epoch': 10.83}
{'loss': 0.102, 'grad_norm': 22.30209732055664, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.09570571035146713, 'loss_2': 0.006256103515625, 'loss_3': -16.258136749267578, 'loss_4': 1.6325757503509521, 'epoch': 10.84}
{'loss': 0.0107, 'grad_norm': 5.906435966491699, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.010494960471987724, 'loss_2': 0.00021469593048095703, 'loss_3': -16.410409927368164, 'loss_4': 1.2242010831832886, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 10:10:09,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:09,926 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:24<56:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:17,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010108500719070435, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0068721771240234375, 'eval_loss_2': 0.003236323595046997, 'eval_loss_3': -18.277637481689453, 'eval_loss_4': 1.7063225507736206, 'epoch': 10.84}
{'loss': 0.0173, 'grad_norm': 6.808229923248291, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.01194852963089943, 'loss_2': 0.0053558349609375, 'loss_3': -16.121231079101562, 'loss_4': 1.793644905090332, 'epoch': 10.85}
{'loss': 0.0205, 'grad_norm': 6.02239990234375, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.013893116265535355, 'loss_2': 0.006565093994140625, 'loss_3': -16.186948776245117, 'loss_4': 1.3253588676452637, 'epoch': 10.85}
{'loss': 0.0159, 'grad_norm': 6.052828788757324, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.010419688187539577, 'loss_2': 0.00548553466796875, 'loss_3': -16.404830932617188, 'loss_4': 2.0304112434387207, 'epoch': 10.86}
{'loss': 0.0118, 'grad_norm': 5.131309986114502, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.011163230985403061, 'loss_2': 0.0006132125854492188, 'loss_3': -16.390207290649414, 'loss_4': 1.8333534002304077, 'epoch': 10.87}
{'loss': 0.0118, 'grad_norm': 6.3927531242370605, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.01058226265013218, 'loss_2': 0.00124359130859375, 'loss_3': -16.333038330078125, 'loss_4': 2.066901922225952, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 10:10:17,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:17,262 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:31<56:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:24,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012686189264059067, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.512, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006100501865148544, 'eval_loss_2': 0.0065856873989105225, 'eval_loss_3': -18.31454849243164, 'eval_loss_4': 1.9135217666625977, 'epoch': 10.87}
{'loss': 0.0174, 'grad_norm': 7.565555095672607, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.015452033840119839, 'loss_2': 0.00193023681640625, 'loss_3': -16.230632781982422, 'loss_4': 1.4823064804077148, 'epoch': 10.88}
{'loss': 0.023, 'grad_norm': 6.414949417114258, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.01518405694514513, 'loss_2': 0.0078582763671875, 'loss_3': -16.189105987548828, 'loss_4': 1.9271913766860962, 'epoch': 10.88}
{'loss': 0.0307, 'grad_norm': 12.478413581848145, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.023909758776426315, 'loss_2': 0.006805419921875, 'loss_3': -16.349201202392578, 'loss_4': 2.3294758796691895, 'epoch': 10.89}
{'loss': 0.0191, 'grad_norm': 5.84591007232666, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.01061814185231924, 'loss_2': 0.00848388671875, 'loss_3': -16.184186935424805, 'loss_4': 1.9037861824035645, 'epoch': 10.9}
{'loss': 0.0147, 'grad_norm': 7.520106315612793, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.013568737544119358, 'loss_2': 0.00109100341796875, 'loss_3': -16.424043655395508, 'loss_4': 2.4075798988342285, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 10:10:24,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:24,623 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:39<56:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:31,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012211859226226807, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.242, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.0060412283055484295, 'eval_loss_2': 0.00617063045501709, 'eval_loss_3': -18.286651611328125, 'eval_loss_4': 2.2072503566741943, 'epoch': 10.9}
{'loss': 0.0138, 'grad_norm': 6.605165481567383, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.013008582405745983, 'loss_2': 0.0008106231689453125, 'loss_3': -16.142684936523438, 'loss_4': 2.753929376602173, 'epoch': 10.91}
{'loss': 0.0165, 'grad_norm': 5.350606918334961, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.01076775137335062, 'loss_2': 0.0057373046875, 'loss_3': -16.283906936645508, 'loss_4': 2.7273759841918945, 'epoch': 10.91}
{'loss': 0.0387, 'grad_norm': 8.050067901611328, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.028817443177103996, 'loss_2': 0.0098724365234375, 'loss_3': -16.162181854248047, 'loss_4': 2.3718698024749756, 'epoch': 10.92}
{'loss': 0.015, 'grad_norm': 7.2742533683776855, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.012343901209533215, 'loss_2': 0.002666473388671875, 'loss_3': -16.158187866210938, 'loss_4': 2.512592315673828, 'epoch': 10.92}
{'loss': 0.0065, 'grad_norm': 4.560556411743164, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.006218201480805874, 'loss_2': 0.0003027915954589844, 'loss_3': -16.478492736816406, 'loss_4': 1.8907968997955322, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 10:10:31,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:31,976 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:46<56:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:39,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00880084466189146, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005746553651988506, 'eval_loss_2': 0.003054291009902954, 'eval_loss_3': -18.32482147216797, 'eval_loss_4': 2.272700309753418, 'epoch': 10.93}
{'loss': 0.0279, 'grad_norm': 8.77399730682373, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.0266241654753685, 'loss_2': 0.0012454986572265625, 'loss_3': -16.64714813232422, 'loss_4': 2.3796019554138184, 'epoch': 10.94}
{'loss': 0.0364, 'grad_norm': 15.082653045654297, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.03169287368655205, 'loss_2': 0.004718780517578125, 'loss_3': -16.35063934326172, 'loss_4': 2.586545944213867, 'epoch': 10.94}
{'loss': 0.0452, 'grad_norm': 13.999545097351074, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.03679777309298515, 'loss_2': 0.00836181640625, 'loss_3': -16.283456802368164, 'loss_4': 2.9012603759765625, 'epoch': 10.95}
{'loss': 0.0202, 'grad_norm': 8.366671562194824, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.012276831082999706, 'loss_2': 0.00797271728515625, 'loss_3': -16.410518646240234, 'loss_4': 2.037149429321289, 'epoch': 10.95}
{'loss': 0.0203, 'grad_norm': 8.077338218688965, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.018027732148766518, 'loss_2': 0.002239227294921875, 'loss_3': -16.35406494140625, 'loss_4': 1.9333364963531494, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 10:10:39,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:39,319 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [46:53<56:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:10:46,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009630183689296246, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.849, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005559186451137066, 'eval_loss_2': 0.00407099723815918, 'eval_loss_3': -18.379182815551758, 'eval_loss_4': 2.2698721885681152, 'epoch': 10.96}
{'loss': 0.0286, 'grad_norm': 6.803217887878418, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.020906200632452965, 'loss_2': 0.00768280029296875, 'loss_3': -16.595510482788086, 'loss_4': 2.963593006134033, 'epoch': 10.97}
{'loss': 0.0426, 'grad_norm': 13.209576606750488, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.03484971448779106, 'loss_2': 0.00772857666015625, 'loss_3': -16.44045639038086, 'loss_4': 2.6164608001708984, 'epoch': 10.97}
{'loss': 0.025, 'grad_norm': 5.341831207275391, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.01590406894683838, 'loss_2': 0.0091400146484375, 'loss_3': -16.53301239013672, 'loss_4': 2.440105438232422, 'epoch': 10.98}
{'loss': 0.0237, 'grad_norm': 7.035980224609375, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.01772330515086651, 'loss_2': 0.006000518798828125, 'loss_3': -16.423877716064453, 'loss_4': 2.0451228618621826, 'epoch': 10.98}
{'loss': 0.0277, 'grad_norm': 9.036076545715332, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.02204129658639431, 'loss_2': 0.00567626953125, 'loss_3': -16.33765411376953, 'loss_4': 2.430166006088257, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 10:10:46,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:46,662 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:00<54:44,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:10:53,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009695464745163918, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006021039094775915, 'eval_loss_2': 0.003674425184726715, 'eval_loss_3': -18.415706634521484, 'eval_loss_4': 2.2972168922424316, 'epoch': 10.99}
{'loss': 0.0152, 'grad_norm': 6.844818592071533, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.013537794351577759, 'loss_2': 0.001628875732421875, 'loss_3': -16.483951568603516, 'loss_4': 3.1192574501037598, 'epoch': 10.99}
{'loss': 0.0105, 'grad_norm': 4.93920373916626, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.0033475395757704973, 'loss_2': 0.00710296630859375, 'loss_3': -16.754898071289062, 'loss_4': 2.4988808631896973, 'epoch': 11.0}
{'loss': 0.0462, 'grad_norm': 20.20537757873535, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.04153905808925629, 'loss_2': 0.00466156005859375, 'loss_3': -16.456918716430664, 'loss_4': 2.7572426795959473, 'epoch': 11.01}
{'loss': 0.0265, 'grad_norm': 7.8758111000061035, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.01637219823896885, 'loss_2': 0.010162353515625, 'loss_3': -16.3990478515625, 'loss_4': 2.566204071044922, 'epoch': 11.01}
{'loss': 0.0222, 'grad_norm': 5.927519798278809, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.01621926762163639, 'loss_2': 0.0059356689453125, 'loss_3': -16.458829879760742, 'loss_4': 3.2656450271606445, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 10:10:53,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:10:53,690 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:08<56:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:11:01,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008531634695827961, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.405, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005802338011562824, 'eval_loss_2': 0.0027292966842651367, 'eval_loss_3': -18.43329429626465, 'eval_loss_4': 2.495243549346924, 'epoch': 11.02}
{'loss': 0.0135, 'grad_norm': 5.639097213745117, 'learning_rate': 1.9e-05, 'loss_1': 0.009413586929440498, 'loss_2': 0.00405120849609375, 'loss_3': -16.43036651611328, 'loss_4': 3.303746461868286, 'epoch': 11.02}
{'loss': 0.0134, 'grad_norm': 5.633790493011475, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.010200247168540955, 'loss_2': 0.0031528472900390625, 'loss_3': -16.50613021850586, 'loss_4': 2.73715877532959, 'epoch': 11.03}
{'loss': 0.0402, 'grad_norm': 8.516823768615723, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.02807096764445305, 'loss_2': 0.01213836669921875, 'loss_3': -16.30137062072754, 'loss_4': 2.8051705360412598, 'epoch': 11.03}
{'loss': 0.0147, 'grad_norm': 4.166745185852051, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.008169112727046013, 'loss_2': 0.006542205810546875, 'loss_3': -16.491840362548828, 'loss_4': 2.985342502593994, 'epoch': 11.04}
{'loss': 0.0218, 'grad_norm': 4.991363048553467, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.009765359573066235, 'loss_2': 0.012054443359375, 'loss_3': -16.536935806274414, 'loss_4': 3.493058681488037, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 10:11:01,029 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:01,029 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:15<56:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:08,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010810202918946743, 'eval_runtime': 3.8187, 'eval_samples_per_second': 268.156, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005929520353674889, 'eval_loss_2': 0.00488068163394928, 'eval_loss_3': -18.454448699951172, 'eval_loss_4': 2.484055995941162, 'epoch': 11.05}
{'loss': 0.0255, 'grad_norm': 11.575469017028809, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.02037264034152031, 'loss_2': 0.00508880615234375, 'loss_3': -16.57006072998047, 'loss_4': 2.9366159439086914, 'epoch': 11.05}
{'loss': 0.0265, 'grad_norm': 8.631200790405273, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.02338200993835926, 'loss_2': 0.003147125244140625, 'loss_3': -16.421411514282227, 'loss_4': 3.671236753463745, 'epoch': 11.06}
{'loss': 0.0301, 'grad_norm': 5.35148811340332, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.011301033198833466, 'loss_2': 0.018829345703125, 'loss_3': -16.466764450073242, 'loss_4': 2.723245859146118, 'epoch': 11.06}
{'loss': 0.0305, 'grad_norm': 7.199493885040283, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.02179514244198799, 'loss_2': 0.0086669921875, 'loss_3': -16.34474754333496, 'loss_4': 2.7618398666381836, 'epoch': 11.07}
{'loss': 0.0312, 'grad_norm': 10.824671745300293, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.024744892492890358, 'loss_2': 0.00641632080078125, 'loss_3': -16.579347610473633, 'loss_4': 2.7607762813568115, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 10:11:08,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:08,389 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:22<56:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:15,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010916739702224731, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.151, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007169655524194241, 'eval_loss_2': 0.0037470832467079163, 'eval_loss_3': -18.445640563964844, 'eval_loss_4': 2.0817131996154785, 'epoch': 11.08}
{'loss': 0.0228, 'grad_norm': 6.902856349945068, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.020955538377165794, 'loss_2': 0.0018320083618164062, 'loss_3': -16.494434356689453, 'loss_4': 2.8884801864624023, 'epoch': 11.08}
{'loss': 0.0243, 'grad_norm': 8.906435012817383, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.02370602637529373, 'loss_2': 0.0005555152893066406, 'loss_3': -16.43914031982422, 'loss_4': 2.3641042709350586, 'epoch': 11.09}
{'loss': 0.0217, 'grad_norm': 5.478230953216553, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.015412998385727406, 'loss_2': 0.0063323974609375, 'loss_3': -16.499303817749023, 'loss_4': 2.7032792568206787, 'epoch': 11.09}
{'loss': 0.0451, 'grad_norm': 13.640583992004395, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.03823127970099449, 'loss_2': 0.00690460205078125, 'loss_3': -16.549938201904297, 'loss_4': 1.8903777599334717, 'epoch': 11.1}
{'loss': 0.0502, 'grad_norm': 14.417555809020996, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.045218709856271744, 'loss_2': 0.00499725341796875, 'loss_3': -16.2723388671875, 'loss_4': 2.5290441513061523, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 10:11:15,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:15,738 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:30<56:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:23,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016993634402751923, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.898, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008843296207487583, 'eval_loss_2': 0.008150339126586914, 'eval_loss_3': -18.449356079101562, 'eval_loss_4': 1.6848418712615967, 'epoch': 11.1}
{'loss': 0.0236, 'grad_norm': 8.76887035369873, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.019664321094751358, 'loss_2': 0.00391387939453125, 'loss_3': -16.39212417602539, 'loss_4': 1.8606398105621338, 'epoch': 11.11}
{'loss': 0.0355, 'grad_norm': 10.031294822692871, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.026710327714681625, 'loss_2': 0.0087738037109375, 'loss_3': -16.306900024414062, 'loss_4': 1.6533751487731934, 'epoch': 11.12}
{'loss': 0.0155, 'grad_norm': 5.644906997680664, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.01091114990413189, 'loss_2': 0.004566192626953125, 'loss_3': -16.43388557434082, 'loss_4': 3.137296199798584, 'epoch': 11.12}
{'loss': 0.0158, 'grad_norm': 5.742569446563721, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.013454196974635124, 'loss_2': 0.002391815185546875, 'loss_3': -16.512800216674805, 'loss_4': 1.815819263458252, 'epoch': 11.13}
{'loss': 0.0204, 'grad_norm': 5.9450459480285645, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.013542866334319115, 'loss_2': 0.006809234619140625, 'loss_3': -16.543514251708984, 'loss_4': 1.7950773239135742, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 10:11:23,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:23,081 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:37<56:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:30,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010508492588996887, 'eval_runtime': 3.8253, 'eval_samples_per_second': 267.689, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.00813316646963358, 'eval_loss_2': 0.0023753270506858826, 'eval_loss_3': -18.41799545288086, 'eval_loss_4': 1.3033668994903564, 'epoch': 11.13}
{'loss': 0.0213, 'grad_norm': 6.815262794494629, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.01791483722627163, 'loss_2': 0.003421783447265625, 'loss_3': -16.40549087524414, 'loss_4': 2.9257378578186035, 'epoch': 11.14}
{'loss': 0.0291, 'grad_norm': 11.326891899108887, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.02375129610300064, 'loss_2': 0.00531005859375, 'loss_3': -16.421043395996094, 'loss_4': 1.4404048919677734, 'epoch': 11.15}
{'loss': 0.0205, 'grad_norm': 5.556200981140137, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.013257657177746296, 'loss_2': 0.0072174072265625, 'loss_3': -16.562686920166016, 'loss_4': 1.748558759689331, 'epoch': 11.15}
{'loss': 0.0273, 'grad_norm': 7.515363693237305, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.02305145375430584, 'loss_2': 0.00421905517578125, 'loss_3': -16.490232467651367, 'loss_4': 1.1959044933319092, 'epoch': 11.16}
{'loss': 0.0249, 'grad_norm': 7.682287216186523, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.02008317969739437, 'loss_2': 0.004810333251953125, 'loss_3': -16.3002986907959, 'loss_4': 1.6873079538345337, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 10:11:30,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:30,445 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:45<55:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:37,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01301275659352541, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008993852883577347, 'eval_loss_2': 0.004018902778625488, 'eval_loss_3': -18.432588577270508, 'eval_loss_4': 0.9981333613395691, 'epoch': 11.16}
{'loss': 0.0186, 'grad_norm': 7.325462818145752, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.013491748832166195, 'loss_2': 0.005130767822265625, 'loss_3': -16.222862243652344, 'loss_4': 2.3390867710113525, 'epoch': 11.17}
{'loss': 0.0216, 'grad_norm': 5.1865081787109375, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.013999615795910358, 'loss_2': 0.00762176513671875, 'loss_3': -16.425891876220703, 'loss_4': 1.7833993434906006, 'epoch': 11.17}
{'loss': 0.0408, 'grad_norm': 10.762310981750488, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.03839126601815224, 'loss_2': 0.002361297607421875, 'loss_3': -16.303808212280273, 'loss_4': 1.460287094116211, 'epoch': 11.18}
{'loss': 0.0378, 'grad_norm': 11.934690475463867, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.03343861177563667, 'loss_2': 0.00434112548828125, 'loss_3': -16.35406494140625, 'loss_4': 0.7598260641098022, 'epoch': 11.19}
{'loss': 0.0235, 'grad_norm': 8.61160945892334, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.019465982913970947, 'loss_2': 0.004047393798828125, 'loss_3': -16.38925552368164, 'loss_4': 1.784959077835083, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 10:11:37,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:37,786 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:52<55:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:45,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015602633357048035, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00972693506628275, 'eval_loss_2': 0.00587569922208786, 'eval_loss_3': -18.450395584106445, 'eval_loss_4': 0.977678120136261, 'epoch': 11.19}
{'loss': 0.0353, 'grad_norm': 13.972660064697266, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.032067228108644485, 'loss_2': 0.00319671630859375, 'loss_3': -16.473922729492188, 'loss_4': 0.7014065980911255, 'epoch': 11.2}
{'loss': 0.0272, 'grad_norm': 9.209980010986328, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.024360550567507744, 'loss_2': 0.00286102294921875, 'loss_3': -16.658611297607422, 'loss_4': 1.6494148969650269, 'epoch': 11.2}
{'loss': 0.0279, 'grad_norm': 6.111973285675049, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.020736031234264374, 'loss_2': 0.007198333740234375, 'loss_3': -16.442298889160156, 'loss_4': 2.483328342437744, 'epoch': 11.21}
{'loss': 0.0226, 'grad_norm': 9.023050308227539, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.02098860964179039, 'loss_2': 0.0016107559204101562, 'loss_3': -16.702991485595703, 'loss_4': 2.0864596366882324, 'epoch': 11.22}
{'loss': 0.0334, 'grad_norm': 12.84005069732666, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.02940978854894638, 'loss_2': 0.003955841064453125, 'loss_3': -16.432758331298828, 'loss_4': 1.7851672172546387, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 10:11:45,126 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:45,126 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [47:59<55:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:52,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013196672312915325, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.433, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009589544497430325, 'eval_loss_2': 0.0036071278154850006, 'eval_loss_3': -18.44650650024414, 'eval_loss_4': 1.065464973449707, 'epoch': 11.22}
{'loss': 0.0266, 'grad_norm': 8.940975189208984, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.025792697444558144, 'loss_2': 0.00079345703125, 'loss_3': -16.33387565612793, 'loss_4': 2.169786214828491, 'epoch': 11.23}
{'loss': 0.0312, 'grad_norm': 9.70767879486084, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.026272974908351898, 'loss_2': 0.004894256591796875, 'loss_3': -16.240402221679688, 'loss_4': 1.1694891452789307, 'epoch': 11.23}
{'loss': 0.0441, 'grad_norm': 12.839868545532227, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.03555937111377716, 'loss_2': 0.00849151611328125, 'loss_3': -16.510326385498047, 'loss_4': 1.9731788635253906, 'epoch': 11.24}
{'loss': 0.0211, 'grad_norm': 5.663125514984131, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.01431436650454998, 'loss_2': 0.006778717041015625, 'loss_3': -16.67861557006836, 'loss_4': 1.5374982357025146, 'epoch': 11.24}
{'loss': 0.0419, 'grad_norm': 8.362425804138184, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.03516611456871033, 'loss_2': 0.0067138671875, 'loss_3': -16.4375, 'loss_4': 1.099442958831787, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 10:11:52,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:52,481 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:07<55:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:11:59,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013810953125357628, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009223846718668938, 'eval_loss_2': 0.00458710640668869, 'eval_loss_3': -18.435606002807617, 'eval_loss_4': 1.223370909690857, 'epoch': 11.25}
{'loss': 0.0437, 'grad_norm': 13.75371265411377, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.04142357036471367, 'loss_2': 0.002262115478515625, 'loss_3': -16.50433349609375, 'loss_4': 1.5801920890808105, 'epoch': 11.26}
{'loss': 0.0175, 'grad_norm': 5.654303550720215, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.015311202965676785, 'loss_2': 0.0022296905517578125, 'loss_3': -16.48737335205078, 'loss_4': 1.3887948989868164, 'epoch': 11.26}
{'loss': 0.021, 'grad_norm': 6.460273742675781, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.017372017726302147, 'loss_2': 0.003631591796875, 'loss_3': -16.41705322265625, 'loss_4': 1.563128113746643, 'epoch': 11.27}
{'loss': 0.0344, 'grad_norm': 7.904136657714844, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.0303004402667284, 'loss_2': 0.004058837890625, 'loss_3': -16.282407760620117, 'loss_4': 1.384095311164856, 'epoch': 11.27}
{'loss': 0.0167, 'grad_norm': 5.080465793609619, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.011637916788458824, 'loss_2': 0.00507354736328125, 'loss_3': -16.253450393676758, 'loss_4': 2.2065703868865967, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 10:11:59,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:11:59,819 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:14<55:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:07,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012497888877987862, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.784, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007796690799295902, 'eval_loss_2': 0.004701197147369385, 'eval_loss_3': -18.406368255615234, 'eval_loss_4': 1.311126708984375, 'epoch': 11.28}
{'loss': 0.0314, 'grad_norm': 9.330238342285156, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.023305363953113556, 'loss_2': 0.0080718994140625, 'loss_3': -16.29417610168457, 'loss_4': 1.6117128133773804, 'epoch': 11.28}
{'loss': 0.04, 'grad_norm': 13.97712230682373, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.03571969270706177, 'loss_2': 0.00424957275390625, 'loss_3': -16.435958862304688, 'loss_4': 1.7210148572921753, 'epoch': 11.29}
{'loss': 0.0146, 'grad_norm': 7.379591941833496, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.012306088581681252, 'loss_2': 0.00226593017578125, 'loss_3': -16.232946395874023, 'loss_4': 2.2105724811553955, 'epoch': 11.3}
{'loss': 0.0115, 'grad_norm': 5.063351631164551, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.009881853125989437, 'loss_2': 0.0015811920166015625, 'loss_3': -16.1989688873291, 'loss_4': 1.4735872745513916, 'epoch': 11.3}
{'loss': 0.0224, 'grad_norm': 14.263717651367188, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.021922407671809196, 'loss_2': 0.0005273818969726562, 'loss_3': -16.287174224853516, 'loss_4': 1.6040970087051392, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 10:12:07,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:07,166 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:21<55:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:14,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01122806966304779, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.065, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006512641906738281, 'eval_loss_2': 0.004715427756309509, 'eval_loss_3': -18.3395938873291, 'eval_loss_4': 1.3951009511947632, 'epoch': 11.31}
{'loss': 0.0147, 'grad_norm': 5.737158298492432, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.01024986244738102, 'loss_2': 0.00444793701171875, 'loss_3': -16.27847671508789, 'loss_4': 1.7088117599487305, 'epoch': 11.31}
{'loss': 0.0127, 'grad_norm': 4.759289741516113, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.007227009627968073, 'loss_2': 0.00545501708984375, 'loss_3': -16.290504455566406, 'loss_4': 1.5059534311294556, 'epoch': 11.32}
{'loss': 0.0119, 'grad_norm': 6.313056468963623, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.011007572524249554, 'loss_2': 0.0009055137634277344, 'loss_3': -16.58454704284668, 'loss_4': 1.785637378692627, 'epoch': 11.33}
{'loss': 0.0124, 'grad_norm': 5.937117576599121, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.010260015726089478, 'loss_2': 0.0021572113037109375, 'loss_3': -16.25510597229004, 'loss_4': 1.8382099866867065, 'epoch': 11.33}
{'loss': 0.0135, 'grad_norm': 6.0422139167785645, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.01229093037545681, 'loss_2': 0.001163482666015625, 'loss_3': -16.34076690673828, 'loss_4': 1.151007890701294, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 10:12:14,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:14,506 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:29<55:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:21,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012365445494651794, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.26, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007642685901373625, 'eval_loss_2': 0.004722759127616882, 'eval_loss_3': -18.325931549072266, 'eval_loss_4': 1.5549836158752441, 'epoch': 11.34}
{'loss': 0.0304, 'grad_norm': 15.726072311401367, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.029818419367074966, 'loss_2': 0.000560760498046875, 'loss_3': -16.28946304321289, 'loss_4': 1.7616602182388306, 'epoch': 11.34}
{'loss': 0.0243, 'grad_norm': 9.45114517211914, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.017036398872733116, 'loss_2': 0.0072174072265625, 'loss_3': -16.239933013916016, 'loss_4': 2.0113120079040527, 'epoch': 11.35}
{'loss': 0.0191, 'grad_norm': 5.852485656738281, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.010948723182082176, 'loss_2': 0.00811767578125, 'loss_3': -16.149200439453125, 'loss_4': 1.7929017543792725, 'epoch': 11.35}
{'loss': 0.0096, 'grad_norm': 5.112674713134766, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.008806470781564713, 'loss_2': 0.00083160400390625, 'loss_3': -16.391178131103516, 'loss_4': 1.6965041160583496, 'epoch': 11.36}
{'loss': 0.0125, 'grad_norm': 6.101423263549805, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.012235240079462528, 'loss_2': 0.0002598762512207031, 'loss_3': -16.388723373413086, 'loss_4': 1.566509485244751, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 10:12:21,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:21,841 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:36<55:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:29,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013616872951388359, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.206, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.008436603471636772, 'eval_loss_2': 0.005180269479751587, 'eval_loss_3': -18.3149356842041, 'eval_loss_4': 1.6430511474609375, 'epoch': 11.37}
{'loss': 0.0117, 'grad_norm': 5.595676422119141, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.01050019171088934, 'loss_2': 0.0012359619140625, 'loss_3': -16.435789108276367, 'loss_4': 1.9545118808746338, 'epoch': 11.37}
{'loss': 0.0082, 'grad_norm': 4.438639163970947, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.007754365913569927, 'loss_2': 0.0004513263702392578, 'loss_3': -16.20562171936035, 'loss_4': 1.866377830505371, 'epoch': 11.38}
{'loss': 0.0148, 'grad_norm': 6.867404460906982, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.014594297856092453, 'loss_2': 0.0001773834228515625, 'loss_3': -16.258525848388672, 'loss_4': 1.4018254280090332, 'epoch': 11.38}
{'loss': 0.0258, 'grad_norm': 7.393228054046631, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.018957650288939476, 'loss_2': 0.0068359375, 'loss_3': -16.199020385742188, 'loss_4': 1.9091050624847412, 'epoch': 11.39}
{'loss': 0.014, 'grad_norm': 4.787992477416992, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.0060525136068463326, 'loss_2': 0.0079498291015625, 'loss_3': -16.232694625854492, 'loss_4': 1.5044314861297607, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 10:12:29,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:29,201 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:43<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:36,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013750415295362473, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.796, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009759267792105675, 'eval_loss_2': 0.003991149365901947, 'eval_loss_3': -18.307973861694336, 'eval_loss_4': 1.5529417991638184, 'epoch': 11.4}
{'loss': 0.0124, 'grad_norm': 5.73958158493042, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.01107068918645382, 'loss_2': 0.001285552978515625, 'loss_3': -16.405620574951172, 'loss_4': 1.8244903087615967, 'epoch': 11.4}
{'loss': 0.0375, 'grad_norm': 14.495959281921387, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.032971881330013275, 'loss_2': 0.004520416259765625, 'loss_3': -16.297142028808594, 'loss_4': 2.344050407409668, 'epoch': 11.41}
{'loss': 0.0194, 'grad_norm': 7.335193634033203, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.018041860312223434, 'loss_2': 0.00139617919921875, 'loss_3': -16.30912208557129, 'loss_4': 1.4289518594741821, 'epoch': 11.41}
{'loss': 0.0225, 'grad_norm': 7.2251129150390625, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.019603747874498367, 'loss_2': 0.0028781890869140625, 'loss_3': -16.331466674804688, 'loss_4': 1.8203022480010986, 'epoch': 11.42}
{'loss': 0.0176, 'grad_norm': 9.031778335571289, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.01650361530482769, 'loss_2': 0.001140594482421875, 'loss_3': -16.238658905029297, 'loss_4': 1.7144138813018799, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 10:12:36,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:36,552 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:51<55:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:43,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016869692131876945, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01044347696006298, 'eval_loss_2': 0.006426215171813965, 'eval_loss_3': -18.307403564453125, 'eval_loss_4': 1.552229881286621, 'epoch': 11.42}
{'loss': 0.0171, 'grad_norm': 5.274252891540527, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.010698242112994194, 'loss_2': 0.00644683837890625, 'loss_3': -16.383419036865234, 'loss_4': 1.6305384635925293, 'epoch': 11.43}
{'loss': 0.0222, 'grad_norm': 10.53043270111084, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.01805337704718113, 'loss_2': 0.004180908203125, 'loss_3': -16.30704116821289, 'loss_4': 1.6620731353759766, 'epoch': 11.44}
{'loss': 0.0171, 'grad_norm': 7.933732986450195, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.015916328877210617, 'loss_2': 0.0011425018310546875, 'loss_3': -16.216585159301758, 'loss_4': 1.4703145027160645, 'epoch': 11.44}
{'loss': 0.016, 'grad_norm': 4.84059476852417, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.010713313706219196, 'loss_2': 0.005313873291015625, 'loss_3': -16.416259765625, 'loss_4': 1.519020676612854, 'epoch': 11.45}
{'loss': 0.0161, 'grad_norm': 5.458218574523926, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.012659494765102863, 'loss_2': 0.0034332275390625, 'loss_3': -16.429847717285156, 'loss_4': 1.5939452648162842, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 10:12:43,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:43,894 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [48:58<55:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:51,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015824491158127785, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009108612313866615, 'eval_loss_2': 0.006715878844261169, 'eval_loss_3': -18.407766342163086, 'eval_loss_4': 1.6529003381729126, 'epoch': 11.45}
{'loss': 0.015, 'grad_norm': 5.617936134338379, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.01477043330669403, 'loss_2': 0.00022912025451660156, 'loss_3': -16.409299850463867, 'loss_4': 2.015925645828247, 'epoch': 11.46}
{'loss': 0.0139, 'grad_norm': 4.629901885986328, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.009281284175813198, 'loss_2': 0.00461578369140625, 'loss_3': -16.519287109375, 'loss_4': 1.562548041343689, 'epoch': 11.47}
{'loss': 0.0215, 'grad_norm': 5.185407638549805, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.011134265922009945, 'loss_2': 0.010345458984375, 'loss_3': -16.20800018310547, 'loss_4': 1.8593974113464355, 'epoch': 11.47}
{'loss': 0.0392, 'grad_norm': 11.113738059997559, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.037721842527389526, 'loss_2': 0.00152587890625, 'loss_3': -16.4901065826416, 'loss_4': 1.532233715057373, 'epoch': 11.48}
{'loss': 0.0154, 'grad_norm': 5.798325538635254, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.013199632987380028, 'loss_2': 0.0021820068359375, 'loss_3': -16.37476921081543, 'loss_4': 2.7672793865203857, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 10:12:51,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:51,238 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:05<55:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:12:58,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01531238853931427, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.989, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011828199960291386, 'eval_loss_2': 0.003484189510345459, 'eval_loss_3': -18.464658737182617, 'eval_loss_4': 2.238736152648926, 'epoch': 11.48}
{'loss': 0.023, 'grad_norm': 5.81467866897583, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.016718177124857903, 'loss_2': 0.00624847412109375, 'loss_3': -16.402854919433594, 'loss_4': 2.833883285522461, 'epoch': 11.49}
{'loss': 0.0209, 'grad_norm': 5.993859767913818, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.015033119358122349, 'loss_2': 0.00591278076171875, 'loss_3': -16.57863998413086, 'loss_4': 3.289539098739624, 'epoch': 11.49}
{'loss': 0.017, 'grad_norm': 6.5693840980529785, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.016992567107081413, 'loss_2': 2.2649765014648438e-06, 'loss_3': -16.36103630065918, 'loss_4': 3.0552327632904053, 'epoch': 11.5}
{'loss': 0.0238, 'grad_norm': 7.59414529800415, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.01953645795583725, 'loss_2': 0.00426483154296875, 'loss_3': -16.282812118530273, 'loss_4': 3.11826229095459, 'epoch': 11.51}
{'loss': 0.027, 'grad_norm': 11.485000610351562, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.026916220784187317, 'loss_2': 6.878376007080078e-05, 'loss_3': -16.55197525024414, 'loss_4': 3.115396499633789, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 10:12:58,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:12:58,589 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:13<54:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:05,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015989582985639572, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.359, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011492157354950905, 'eval_loss_2': 0.004497423768043518, 'eval_loss_3': -18.458227157592773, 'eval_loss_4': 2.7951900959014893, 'epoch': 11.51}
{'loss': 0.0326, 'grad_norm': 9.443305015563965, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.02721296064555645, 'loss_2': 0.005359649658203125, 'loss_3': -16.435853958129883, 'loss_4': 3.432154893875122, 'epoch': 11.52}
{'loss': 0.0238, 'grad_norm': 7.512545585632324, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.019974494352936745, 'loss_2': 0.0038738250732421875, 'loss_3': -16.298110961914062, 'loss_4': 2.6583099365234375, 'epoch': 11.52}
{'loss': 0.039, 'grad_norm': 14.16682243347168, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.03413268178701401, 'loss_2': 0.004852294921875, 'loss_3': -16.436962127685547, 'loss_4': 2.8825345039367676, 'epoch': 11.53}
{'loss': 0.0267, 'grad_norm': 5.866169452667236, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.025529587641358376, 'loss_2': 0.0011425018310546875, 'loss_3': -16.446189880371094, 'loss_4': 3.9242348670959473, 'epoch': 11.53}
{'loss': 0.0336, 'grad_norm': 16.092742919921875, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.03265621140599251, 'loss_2': 0.0009708404541015625, 'loss_3': -16.249961853027344, 'loss_4': 3.2658467292785645, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 10:13:05,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:05,930 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:20<54:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:13,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015840288251638412, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.547, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011622367426753044, 'eval_loss_2': 0.004217922687530518, 'eval_loss_3': -18.473167419433594, 'eval_loss_4': 2.935950517654419, 'epoch': 11.54}
{'loss': 0.0474, 'grad_norm': 8.109552383422852, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.03477337956428528, 'loss_2': 0.01267242431640625, 'loss_3': -16.270267486572266, 'loss_4': 4.136847019195557, 'epoch': 11.55}
{'loss': 0.0211, 'grad_norm': 5.737071990966797, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.017077164724469185, 'loss_2': 0.00402069091796875, 'loss_3': -16.512134552001953, 'loss_4': 3.506380796432495, 'epoch': 11.55}
{'loss': 0.0167, 'grad_norm': 5.569725036621094, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.013529634103178978, 'loss_2': 0.003208160400390625, 'loss_3': -16.38482093811035, 'loss_4': 3.592693328857422, 'epoch': 11.56}
{'loss': 0.0119, 'grad_norm': 5.418396472930908, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.008122695609927177, 'loss_2': 0.0037631988525390625, 'loss_3': -16.44146156311035, 'loss_4': 2.771747589111328, 'epoch': 11.56}
{'loss': 0.0284, 'grad_norm': 8.644420623779297, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.0222789216786623, 'loss_2': 0.0061492919921875, 'loss_3': -16.324251174926758, 'loss_4': 2.4251315593719482, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 10:13:13,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:13,285 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:27<54:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:20,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013782098889350891, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010030141100287437, 'eval_loss_2': 0.0037519559264183044, 'eval_loss_3': -18.429977416992188, 'eval_loss_4': 2.368036985397339, 'epoch': 11.57}
{'loss': 0.0219, 'grad_norm': 10.648715019226074, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.01669260673224926, 'loss_2': 0.005245208740234375, 'loss_3': -16.38753890991211, 'loss_4': 3.009988307952881, 'epoch': 11.58}
{'loss': 0.0246, 'grad_norm': 13.127081871032715, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.021939123049378395, 'loss_2': 0.0026950836181640625, 'loss_3': -16.347305297851562, 'loss_4': 2.932652235031128, 'epoch': 11.58}
{'loss': 0.0456, 'grad_norm': 15.859071731567383, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.044237565249204636, 'loss_2': 0.0013217926025390625, 'loss_3': -16.362178802490234, 'loss_4': 2.3053667545318604, 'epoch': 11.59}
{'loss': 0.0372, 'grad_norm': 12.146556854248047, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.034460216760635376, 'loss_2': 0.002777099609375, 'loss_3': -16.423460006713867, 'loss_4': 2.7347006797790527, 'epoch': 11.59}
{'loss': 0.0145, 'grad_norm': 5.128130912780762, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.010398472659289837, 'loss_2': 0.004119873046875, 'loss_3': -16.327369689941406, 'loss_4': 1.923403024673462, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 10:13:20,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:20,626 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:35<54:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:27,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013704653829336166, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01053871214389801, 'eval_loss_2': 0.003165941685438156, 'eval_loss_3': -18.417423248291016, 'eval_loss_4': 1.841125726699829, 'epoch': 11.6}
{'loss': 0.0225, 'grad_norm': 5.209305286407471, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.014143034815788269, 'loss_2': 0.0083160400390625, 'loss_3': -16.408777236938477, 'loss_4': 2.1856422424316406, 'epoch': 11.6}
{'loss': 0.0159, 'grad_norm': 5.359381198883057, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.009664380922913551, 'loss_2': 0.0062408447265625, 'loss_3': -16.478450775146484, 'loss_4': 2.2720041275024414, 'epoch': 11.61}
{'loss': 0.0291, 'grad_norm': 15.537666320800781, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.026562156155705452, 'loss_2': 0.0025348663330078125, 'loss_3': -16.545042037963867, 'loss_4': 1.711669921875, 'epoch': 11.62}
{'loss': 0.0212, 'grad_norm': 5.646280288696289, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.009064684621989727, 'loss_2': 0.0121002197265625, 'loss_3': -16.31035804748535, 'loss_4': 2.2845351696014404, 'epoch': 11.62}
{'loss': 0.0125, 'grad_norm': 5.432412147521973, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.008823374286293983, 'loss_2': 0.003665924072265625, 'loss_3': -16.27790069580078, 'loss_4': 2.3731346130371094, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 10:13:27,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:27,961 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:42<54:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:35,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013831516727805138, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.224, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008796177804470062, 'eval_loss_2': 0.005035340785980225, 'eval_loss_3': -18.420562744140625, 'eval_loss_4': 1.4483405351638794, 'epoch': 11.63}
{'loss': 0.0125, 'grad_norm': 5.003044128417969, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.009478319436311722, 'loss_2': 0.003063201904296875, 'loss_3': -16.49298095703125, 'loss_4': 0.9244171380996704, 'epoch': 11.63}
{'loss': 0.018, 'grad_norm': 8.155012130737305, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.016827251762151718, 'loss_2': 0.0011997222900390625, 'loss_3': -16.497854232788086, 'loss_4': 1.9763063192367554, 'epoch': 11.64}
{'loss': 0.0187, 'grad_norm': 5.496093273162842, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.01221445668488741, 'loss_2': 0.00649261474609375, 'loss_3': -16.314504623413086, 'loss_4': 1.5466995239257812, 'epoch': 11.65}
{'loss': 0.0243, 'grad_norm': 8.9044828414917, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.02349214255809784, 'loss_2': 0.0007772445678710938, 'loss_3': -16.208431243896484, 'loss_4': 1.6144447326660156, 'epoch': 11.65}
{'loss': 0.009, 'grad_norm': 4.99006986618042, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.00842579547315836, 'loss_2': 0.0006055831909179688, 'loss_3': -16.427566528320312, 'loss_4': 1.7841520309448242, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 10:13:35,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:35,301 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:49<54:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:42,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01238204538822174, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008893830701708794, 'eval_loss_2': 0.003488212823867798, 'eval_loss_3': -18.393495559692383, 'eval_loss_4': 1.038779616355896, 'epoch': 11.66}
{'loss': 0.0158, 'grad_norm': 7.11388635635376, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.010835791006684303, 'loss_2': 0.00499725341796875, 'loss_3': -16.523422241210938, 'loss_4': 0.9337886571884155, 'epoch': 11.66}
{'loss': 0.0412, 'grad_norm': 11.871346473693848, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.03469204157590866, 'loss_2': 0.006542205810546875, 'loss_3': -16.474899291992188, 'loss_4': 2.159743309020996, 'epoch': 11.67}
{'loss': 0.0141, 'grad_norm': 8.188395500183105, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.012458358891308308, 'loss_2': 0.0016498565673828125, 'loss_3': -16.516414642333984, 'loss_4': 0.5625311732292175, 'epoch': 11.67}
{'loss': 0.0282, 'grad_norm': 6.799576282501221, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.022474579513072968, 'loss_2': 0.005767822265625, 'loss_3': -16.458179473876953, 'loss_4': 0.7916540503501892, 'epoch': 11.68}
{'loss': 0.0136, 'grad_norm': 5.768298149108887, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.0095117362216115, 'loss_2': 0.0041351318359375, 'loss_3': -16.538639068603516, 'loss_4': 0.952670693397522, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 10:13:42,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:42,643 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [49:57<54:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:49,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01322332676500082, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.326, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.009008554741740227, 'eval_loss_2': 0.004214771091938019, 'eval_loss_3': -18.413681030273438, 'eval_loss_4': 0.7903544902801514, 'epoch': 11.69}
{'loss': 0.023, 'grad_norm': 10.317264556884766, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.018657319247722626, 'loss_2': 0.0043487548828125, 'loss_3': -16.527116775512695, 'loss_4': 1.5997569561004639, 'epoch': 11.69}
{'loss': 0.0208, 'grad_norm': 11.560585021972656, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.020075811073184013, 'loss_2': 0.0007233619689941406, 'loss_3': -16.4627628326416, 'loss_4': 1.1471599340438843, 'epoch': 11.7}
{'loss': 0.0112, 'grad_norm': 5.552734375, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.00760180689394474, 'loss_2': 0.003597259521484375, 'loss_3': -16.40379524230957, 'loss_4': 0.6720730066299438, 'epoch': 11.7}
{'loss': 0.027, 'grad_norm': 9.671393394470215, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.022680087015032768, 'loss_2': 0.004299163818359375, 'loss_3': -16.364748001098633, 'loss_4': 1.456267237663269, 'epoch': 11.71}
{'loss': 0.0356, 'grad_norm': 16.47842025756836, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.034114450216293335, 'loss_2': 0.001491546630859375, 'loss_3': -16.529464721679688, 'loss_4': 0.8638207912445068, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 10:13:49,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:49,998 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:04<54:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:13:57,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013226388022303581, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.718, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0092314463108778, 'eval_loss_2': 0.003994941711425781, 'eval_loss_3': -18.39891242980957, 'eval_loss_4': 0.7822869420051575, 'epoch': 11.72}
{'loss': 0.0141, 'grad_norm': 4.610899448394775, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.009768185205757618, 'loss_2': 0.00434112548828125, 'loss_3': -16.375709533691406, 'loss_4': 1.0957697629928589, 'epoch': 11.72}
{'loss': 0.0156, 'grad_norm': 5.53719425201416, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.014018459245562553, 'loss_2': 0.001537322998046875, 'loss_3': -16.581634521484375, 'loss_4': 1.3004170656204224, 'epoch': 11.73}
{'loss': 0.0247, 'grad_norm': 8.780319213867188, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.020750511437654495, 'loss_2': 0.00396728515625, 'loss_3': -16.493860244750977, 'loss_4': 1.1920961141586304, 'epoch': 11.73}
{'loss': 0.0214, 'grad_norm': 11.555431365966797, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.018059922382235527, 'loss_2': 0.00334930419921875, 'loss_3': -16.50779914855957, 'loss_4': 1.9487173557281494, 'epoch': 11.74}
{'loss': 0.0122, 'grad_norm': 5.569919109344482, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.01032037753611803, 'loss_2': 0.0018711090087890625, 'loss_3': -16.284931182861328, 'loss_4': 1.7111403942108154, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 10:13:57,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:13:57,347 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:11<54:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:04,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011718650348484516, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008515458554029465, 'eval_loss_2': 0.003203190863132477, 'eval_loss_3': -18.38321876525879, 'eval_loss_4': 0.9968013763427734, 'epoch': 11.74}
{'loss': 0.016, 'grad_norm': 5.8643083572387695, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.012813436798751354, 'loss_2': 0.0032329559326171875, 'loss_3': -16.426959991455078, 'loss_4': 0.45176130533218384, 'epoch': 11.75}
{'loss': 0.0235, 'grad_norm': 10.167929649353027, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.02123836986720562, 'loss_2': 0.002216339111328125, 'loss_3': -16.403953552246094, 'loss_4': 0.7839561700820923, 'epoch': 11.76}
{'loss': 0.0168, 'grad_norm': 5.222550868988037, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.013516899198293686, 'loss_2': 0.003253936767578125, 'loss_3': -16.620864868164062, 'loss_4': 0.7965982556343079, 'epoch': 11.76}
{'loss': 0.0289, 'grad_norm': 12.416939735412598, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.026851419359445572, 'loss_2': 0.00205230712890625, 'loss_3': -16.641435623168945, 'loss_4': 1.182518482208252, 'epoch': 11.77}
{'loss': 0.0214, 'grad_norm': 9.484696388244629, 'learning_rate': 1.825e-05, 'loss_1': 0.02049846574664116, 'loss_2': 0.0008916854858398438, 'loss_3': -16.312358856201172, 'loss_4': 1.122702717781067, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 10:14:04,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:04,694 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:19<54:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:12,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011922257021069527, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00875082053244114, 'eval_loss_2': 0.0031714364886283875, 'eval_loss_3': -18.397838592529297, 'eval_loss_4': 1.3314684629440308, 'epoch': 11.77}
{'loss': 0.0144, 'grad_norm': 5.6123857498168945, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.009827651083469391, 'loss_2': 0.0045623779296875, 'loss_3': -16.531810760498047, 'loss_4': 1.4346165657043457, 'epoch': 11.78}
{'loss': 0.0242, 'grad_norm': 13.570106506347656, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.024071315303444862, 'loss_2': 0.00012874603271484375, 'loss_3': -16.523635864257812, 'loss_4': 1.982235074043274, 'epoch': 11.78}
{'loss': 0.015, 'grad_norm': 5.408957004547119, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.008491424843668938, 'loss_2': 0.00650787353515625, 'loss_3': -16.47842788696289, 'loss_4': 1.2601726055145264, 'epoch': 11.79}
{'loss': 0.0211, 'grad_norm': 7.6669440269470215, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.018439562991261482, 'loss_2': 0.002696990966796875, 'loss_3': -16.344886779785156, 'loss_4': 1.0238449573516846, 'epoch': 11.8}
{'loss': 0.0386, 'grad_norm': 13.595138549804688, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.03539596498012543, 'loss_2': 0.0031757354736328125, 'loss_3': -16.637691497802734, 'loss_4': 1.848270297050476, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 10:14:12,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:12,043 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:26<54:45,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:14:19,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012237505055963993, 'eval_runtime': 3.9981, 'eval_samples_per_second': 256.121, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.008757546544075012, 'eval_loss_2': 0.0034799575805664062, 'eval_loss_3': -18.39033317565918, 'eval_loss_4': 1.541892647743225, 'epoch': 11.8}
{'loss': 0.0164, 'grad_norm': 5.472104549407959, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.014477737247943878, 'loss_2': 0.001953125, 'loss_3': -16.416112899780273, 'loss_4': 2.0683069229125977, 'epoch': 11.81}
{'loss': 0.0228, 'grad_norm': 8.389810562133789, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.02000344730913639, 'loss_2': 0.0027751922607421875, 'loss_3': -16.52596664428711, 'loss_4': 1.73280930519104, 'epoch': 11.81}
{'loss': 0.0419, 'grad_norm': 9.752242088317871, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.03943629190325737, 'loss_2': 0.0024871826171875, 'loss_3': -16.476856231689453, 'loss_4': 2.735391139984131, 'epoch': 11.82}
{'loss': 0.0228, 'grad_norm': 7.09427547454834, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.01577562466263771, 'loss_2': 0.00701904296875, 'loss_3': -16.50104522705078, 'loss_4': 1.3308926820755005, 'epoch': 11.83}
{'loss': 0.0204, 'grad_norm': 7.196440696716309, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.01205909252166748, 'loss_2': 0.0083160400390625, 'loss_3': -16.48387908935547, 'loss_4': 1.0566312074661255, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 10:14:19,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:19,581 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:34<54:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:26,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016945816576480865, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.033, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008940315805375576, 'eval_loss_2': 0.008005499839782715, 'eval_loss_3': -18.37920570373535, 'eval_loss_4': 1.8080519437789917, 'epoch': 11.83}
{'loss': 0.0231, 'grad_norm': 8.317740440368652, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.01839631237089634, 'loss_2': 0.00467681884765625, 'loss_3': -16.464176177978516, 'loss_4': 1.88783597946167, 'epoch': 11.84}
{'loss': 0.0291, 'grad_norm': 10.162936210632324, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.022477343678474426, 'loss_2': 0.00658416748046875, 'loss_3': -16.476024627685547, 'loss_4': 2.3273215293884277, 'epoch': 11.84}
{'loss': 0.0222, 'grad_norm': 6.863741874694824, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.01725010760128498, 'loss_2': 0.004974365234375, 'loss_3': -16.44538116455078, 'loss_4': 2.1402230262756348, 'epoch': 11.85}
{'loss': 0.064, 'grad_norm': 10.809518814086914, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.05234880745410919, 'loss_2': 0.01168060302734375, 'loss_3': -16.449729919433594, 'loss_4': 1.7683091163635254, 'epoch': 11.85}
{'loss': 0.0243, 'grad_norm': 7.150903701782227, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.02359614148736, 'loss_2': 0.0007047653198242188, 'loss_3': -16.49283790588379, 'loss_4': 2.6077704429626465, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 10:14:26,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:26,923 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:41<53:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:34,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012898068875074387, 'eval_runtime': 3.8247, 'eval_samples_per_second': 267.731, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.008374374359846115, 'eval_loss_2': 0.0045236945152282715, 'eval_loss_3': -18.390459060668945, 'eval_loss_4': 1.9800883531570435, 'epoch': 11.86}
{'loss': 0.0231, 'grad_norm': 12.313278198242188, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.015894224867224693, 'loss_2': 0.0072174072265625, 'loss_3': -16.62770652770996, 'loss_4': 2.013249397277832, 'epoch': 11.87}
{'loss': 0.0149, 'grad_norm': 4.76279354095459, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.008328400552272797, 'loss_2': 0.006591796875, 'loss_3': -16.362262725830078, 'loss_4': 2.189788579940796, 'epoch': 11.87}
{'loss': 0.0213, 'grad_norm': 7.143803119659424, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.021178511902689934, 'loss_2': 0.00014138221740722656, 'loss_3': -16.509138107299805, 'loss_4': 2.5324316024780273, 'epoch': 11.88}
{'loss': 0.024, 'grad_norm': 8.012957572937012, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.015604342333972454, 'loss_2': 0.00838470458984375, 'loss_3': -16.417545318603516, 'loss_4': 2.008826494216919, 'epoch': 11.88}
{'loss': 0.0175, 'grad_norm': 5.015496253967285, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.01118281576782465, 'loss_2': 0.00634765625, 'loss_3': -16.409658432006836, 'loss_4': 2.1255528926849365, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 10:14:34,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:34,288 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:48<53:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:41,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012158669531345367, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.254, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007710591424256563, 'eval_loss_2': 0.0044480785727500916, 'eval_loss_3': -18.391754150390625, 'eval_loss_4': 2.10758113861084, 'epoch': 11.89}
{'loss': 0.0222, 'grad_norm': 7.60274076461792, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.01792229153215885, 'loss_2': 0.004261016845703125, 'loss_3': -16.345815658569336, 'loss_4': 1.8736071586608887, 'epoch': 11.9}
{'loss': 0.0146, 'grad_norm': 5.492265224456787, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.012724876403808594, 'loss_2': 0.0018520355224609375, 'loss_3': -16.498249053955078, 'loss_4': 2.999253988265991, 'epoch': 11.9}
{'loss': 0.0144, 'grad_norm': 5.84003210067749, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.012917163781821728, 'loss_2': 0.00152587890625, 'loss_3': -16.5316104888916, 'loss_4': 2.1110987663269043, 'epoch': 11.91}
{'loss': 0.0155, 'grad_norm': 5.362759113311768, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.011753818951547146, 'loss_2': 0.003749847412109375, 'loss_3': -16.393396377563477, 'loss_4': 1.6493332386016846, 'epoch': 11.91}
{'loss': 0.0423, 'grad_norm': 8.624048233032227, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.039724476635456085, 'loss_2': 0.0025501251220703125, 'loss_3': -16.24893569946289, 'loss_4': 2.0599770545959473, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 10:14:41,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:41,636 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [50:56<53:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:48,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011622008867561817, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00901822466403246, 'eval_loss_2': 0.002603784203529358, 'eval_loss_3': -18.351083755493164, 'eval_loss_4': 1.9187169075012207, 'epoch': 11.92}
{'loss': 0.0174, 'grad_norm': 5.270237922668457, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.010444678366184235, 'loss_2': 0.0069122314453125, 'loss_3': -16.483867645263672, 'loss_4': 1.9649845361709595, 'epoch': 11.92}
{'loss': 0.0142, 'grad_norm': 6.988312721252441, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.014022835530340672, 'loss_2': 0.0001347064971923828, 'loss_3': -16.512187957763672, 'loss_4': 1.7562611103057861, 'epoch': 11.93}
{'loss': 0.018, 'grad_norm': 5.653623580932617, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.010592031292617321, 'loss_2': 0.0074005126953125, 'loss_3': -16.439476013183594, 'loss_4': 1.945212483406067, 'epoch': 11.94}
{'loss': 0.0188, 'grad_norm': 7.13062858581543, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.014225100167095661, 'loss_2': 0.00455474853515625, 'loss_3': -16.34515380859375, 'loss_4': 2.4688222408294678, 'epoch': 11.94}
{'loss': 0.0325, 'grad_norm': 12.802164077758789, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.027810508385300636, 'loss_2': 0.00464630126953125, 'loss_3': -16.461374282836914, 'loss_4': 2.8903541564941406, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 10:14:48,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:48,980 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:03<53:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:14:56,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011259552091360092, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.359, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.008608323521912098, 'eval_loss_2': 0.002651229500770569, 'eval_loss_3': -18.36840057373047, 'eval_loss_4': 2.2175979614257812, 'epoch': 11.95}
{'loss': 0.0146, 'grad_norm': 6.609981060028076, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.014422138221561909, 'loss_2': 0.000194549560546875, 'loss_3': -16.402801513671875, 'loss_4': 2.0204415321350098, 'epoch': 11.95}
{'loss': 0.0183, 'grad_norm': 5.594759941101074, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.01621444895863533, 'loss_2': 0.002117156982421875, 'loss_3': -16.363388061523438, 'loss_4': 2.491255283355713, 'epoch': 11.96}
{'loss': 0.0247, 'grad_norm': 10.815258979797363, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.015829164534807205, 'loss_2': 0.0088653564453125, 'loss_3': -16.428926467895508, 'loss_4': 2.4852709770202637, 'epoch': 11.97}
{'loss': 0.0273, 'grad_norm': 8.798026084899902, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.02256123721599579, 'loss_2': 0.00472259521484375, 'loss_3': -16.263595581054688, 'loss_4': 1.9556210041046143, 'epoch': 11.97}
{'loss': 0.0164, 'grad_norm': 7.475179195404053, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.014340018853545189, 'loss_2': 0.00209808349609375, 'loss_3': -16.466026306152344, 'loss_4': 1.7740113735198975, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 10:14:56,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:14:56,335 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:10<50:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:15:03,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010249445214867592, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.551, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006636688951402903, 'eval_loss_2': 0.0036127567291259766, 'eval_loss_3': -18.363361358642578, 'eval_loss_4': 2.087193489074707, 'epoch': 11.98}
{'loss': 0.067, 'grad_norm': 24.35164451599121, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.06558971852064133, 'loss_2': 0.0013818740844726562, 'loss_3': -16.34665298461914, 'loss_4': 2.6670966148376465, 'epoch': 11.98}
{'loss': 0.0145, 'grad_norm': 5.500696659088135, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.01228297594934702, 'loss_2': 0.002193450927734375, 'loss_3': -16.446456909179688, 'loss_4': 2.209845542907715, 'epoch': 11.99}
{'loss': 0.0219, 'grad_norm': 4.546472072601318, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.010501638986170292, 'loss_2': 0.01141357421875, 'loss_3': -16.318052291870117, 'loss_4': 1.9721752405166626, 'epoch': 11.99}
{'loss': 0.0271, 'grad_norm': 16.10455894470215, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.024916041642427444, 'loss_2': 0.0022125244140625, 'loss_3': -16.320068359375, 'loss_4': 2.1028800010681152, 'epoch': 12.0}
{'loss': 0.0507, 'grad_norm': 15.794564247131348, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.05048610270023346, 'loss_2': 0.0002257823944091797, 'loss_3': -16.314102172851562, 'loss_4': 2.4237637519836426, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 10:15:03,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:03,376 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:17<52:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:15:10,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010579954832792282, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006268751807510853, 'eval_loss_2': 0.004311203956604004, 'eval_loss_3': -18.366220474243164, 'eval_loss_4': 1.599279522895813, 'epoch': 12.01}
{'loss': 0.0219, 'grad_norm': 6.144992828369141, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.014255721122026443, 'loss_2': 0.0076904296875, 'loss_3': -16.38538932800293, 'loss_4': 2.0845375061035156, 'epoch': 12.01}
{'loss': 0.0208, 'grad_norm': 6.3914923667907715, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.015866650268435478, 'loss_2': 0.00498199462890625, 'loss_3': -16.36444664001465, 'loss_4': 1.957174301147461, 'epoch': 12.02}
{'loss': 0.0147, 'grad_norm': 5.212730884552002, 'learning_rate': 1.8e-05, 'loss_1': 0.007416435517370701, 'loss_2': 0.00731658935546875, 'loss_3': -16.28575897216797, 'loss_4': 1.6002182960510254, 'epoch': 12.02}
{'loss': 0.0142, 'grad_norm': 5.769607067108154, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.008162676356732845, 'loss_2': 0.006023406982421875, 'loss_3': -16.442256927490234, 'loss_4': 1.255948781967163, 'epoch': 12.03}
{'loss': 0.0245, 'grad_norm': 7.447484493255615, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.016236789524555206, 'loss_2': 0.0082244873046875, 'loss_3': -16.492069244384766, 'loss_4': 1.4378092288970947, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 10:15:10,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:10,719 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:25<53:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:15:18,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012287596240639687, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0067711262963712215, 'eval_loss_2': 0.005516469478607178, 'eval_loss_3': -18.378074645996094, 'eval_loss_4': 1.3052829504013062, 'epoch': 12.03}
{'loss': 0.03, 'grad_norm': 8.51858139038086, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.025583811104297638, 'loss_2': 0.00439453125, 'loss_3': -16.494863510131836, 'loss_4': 1.2039262056350708, 'epoch': 12.04}
{'loss': 0.0124, 'grad_norm': 5.531954288482666, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.01219768077135086, 'loss_2': 0.00017762184143066406, 'loss_3': -16.508941650390625, 'loss_4': 1.134729027748108, 'epoch': 12.05}
{'loss': 0.0211, 'grad_norm': 7.7823381423950195, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.01696343533694744, 'loss_2': 0.00415802001953125, 'loss_3': -16.437484741210938, 'loss_4': 1.9583041667938232, 'epoch': 12.05}
{'loss': 0.0473, 'grad_norm': 18.780914306640625, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.046595729887485504, 'loss_2': 0.0007243156433105469, 'loss_3': -16.48979377746582, 'loss_4': 0.6589044332504272, 'epoch': 12.06}
{'loss': 0.0121, 'grad_norm': 4.902700901031494, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.008404008112847805, 'loss_2': 0.00366973876953125, 'loss_3': -16.570663452148438, 'loss_4': 1.7403395175933838, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 10:15:18,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:18,063 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:32<53:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:25,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010818877257406712, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006473012734204531, 'eval_loss_2': 0.0043458640575408936, 'eval_loss_3': -18.378494262695312, 'eval_loss_4': 0.9205366373062134, 'epoch': 12.06}
{'loss': 0.0367, 'grad_norm': 12.762673377990723, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.031443387269973755, 'loss_2': 0.0052337646484375, 'loss_3': -16.45968246459961, 'loss_4': 1.3752506971359253, 'epoch': 12.07}
{'loss': 0.0175, 'grad_norm': 5.4256486892700195, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.01572342962026596, 'loss_2': 0.0018100738525390625, 'loss_3': -16.410396575927734, 'loss_4': 0.14592118561267853, 'epoch': 12.08}
{'loss': 0.0238, 'grad_norm': 8.016085624694824, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.022085033357143402, 'loss_2': 0.0017337799072265625, 'loss_3': -16.571870803833008, 'loss_4': 1.2782891988754272, 'epoch': 12.08}
{'loss': 0.0259, 'grad_norm': 11.357720375061035, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.024937311187386513, 'loss_2': 0.0009260177612304688, 'loss_3': -16.443655014038086, 'loss_4': 1.1532119512557983, 'epoch': 12.09}
{'loss': 0.0284, 'grad_norm': 8.422412872314453, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.026014966890215874, 'loss_2': 0.0024261474609375, 'loss_3': -16.52324104309082, 'loss_4': 0.46204957365989685, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 10:15:25,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:25,395 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:39<53:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:32,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011043978855013847, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006368887610733509, 'eval_loss_2': 0.004675090312957764, 'eval_loss_3': -18.375293731689453, 'eval_loss_4': 0.6933180093765259, 'epoch': 12.09}
{'loss': 0.0103, 'grad_norm': 5.036319255828857, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.008908499963581562, 'loss_2': 0.0013637542724609375, 'loss_3': -16.50943946838379, 'loss_4': 0.6910620927810669, 'epoch': 12.1}
{'loss': 0.0175, 'grad_norm': 6.755285739898682, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.014340429566800594, 'loss_2': 0.003204345703125, 'loss_3': -16.327072143554688, 'loss_4': 1.1025722026824951, 'epoch': 12.1}
{'loss': 0.0137, 'grad_norm': 6.5740437507629395, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.013656284660100937, 'loss_2': 9.262561798095703e-05, 'loss_3': -16.331249237060547, 'loss_4': 0.33556267619132996, 'epoch': 12.11}
{'loss': 0.0124, 'grad_norm': 4.53769063949585, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.005229105707257986, 'loss_2': 0.007137298583984375, 'loss_3': -16.527990341186523, 'loss_4': 1.0594309568405151, 'epoch': 12.12}
{'loss': 0.0187, 'grad_norm': 5.964444160461426, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.01782544143497944, 'loss_2': 0.0008859634399414062, 'loss_3': -16.443300247192383, 'loss_4': 0.6771045923233032, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 10:15:32,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:32,732 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:47<52:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:40,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01045179832726717, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005814147647470236, 'eval_loss_2': 0.0046376511454582214, 'eval_loss_3': -18.38382339477539, 'eval_loss_4': 0.5925008058547974, 'epoch': 12.12}
{'loss': 0.0263, 'grad_norm': 6.777134895324707, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.020453836768865585, 'loss_2': 0.0058746337890625, 'loss_3': -16.374858856201172, 'loss_4': 0.08615700155496597, 'epoch': 12.13}
{'loss': 0.0169, 'grad_norm': 6.032569885253906, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.01367128361016512, 'loss_2': 0.003253936767578125, 'loss_3': -16.46297836303711, 'loss_4': 0.03236198425292969, 'epoch': 12.13}
{'loss': 0.0101, 'grad_norm': 4.841785907745361, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.007199704181402922, 'loss_2': 0.002895355224609375, 'loss_3': -16.473085403442383, 'loss_4': 0.5217186212539673, 'epoch': 12.14}
{'loss': 0.0098, 'grad_norm': 5.611210823059082, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.009099897928535938, 'loss_2': 0.0007500648498535156, 'loss_3': -16.41849136352539, 'loss_4': 1.1223456859588623, 'epoch': 12.15}
{'loss': 0.025, 'grad_norm': 5.527227878570557, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.016566608101129532, 'loss_2': 0.008392333984375, 'loss_3': -16.379234313964844, 'loss_4': 1.0354351997375488, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 10:15:40,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:40,067 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [51:54<52:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:47,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009761838242411613, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0051984768360853195, 'eval_loss_2': 0.004563361406326294, 'eval_loss_3': -18.373451232910156, 'eval_loss_4': 0.5455049872398376, 'epoch': 12.15}
{'loss': 0.028, 'grad_norm': 8.544673919677734, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.019976181909441948, 'loss_2': 0.008056640625, 'loss_3': -16.61933135986328, 'loss_4': 0.5959205627441406, 'epoch': 12.16}
{'loss': 0.0212, 'grad_norm': 6.00029993057251, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.015700798481702805, 'loss_2': 0.00554656982421875, 'loss_3': -16.355453491210938, 'loss_4': 1.1365876197814941, 'epoch': 12.16}
{'loss': 0.0276, 'grad_norm': 10.171978950500488, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.02306791953742504, 'loss_2': 0.004547119140625, 'loss_3': -16.47039794921875, 'loss_4': 0.6956968307495117, 'epoch': 12.17}
{'loss': 0.0132, 'grad_norm': 7.060060501098633, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.009733814746141434, 'loss_2': 0.003452301025390625, 'loss_3': -16.398944854736328, 'loss_4': 0.6441327333450317, 'epoch': 12.17}
{'loss': 0.0095, 'grad_norm': 4.915933609008789, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.006854850798845291, 'loss_2': 0.002605438232421875, 'loss_3': -16.501419067382812, 'loss_4': 1.0051381587982178, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 10:15:47,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:47,401 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:01<52:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:15:54,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008914332836866379, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.927, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0050630467012524605, 'eval_loss_2': 0.003851287066936493, 'eval_loss_3': -18.339611053466797, 'eval_loss_4': 0.6215461492538452, 'epoch': 12.18}
{'loss': 0.0213, 'grad_norm': 9.540555953979492, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.019038978964090347, 'loss_2': 0.0023040771484375, 'loss_3': -16.35379981994629, 'loss_4': 0.8694692850112915, 'epoch': 12.19}
{'loss': 0.017, 'grad_norm': 5.017187118530273, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.009059334173798561, 'loss_2': 0.007965087890625, 'loss_3': -16.36595344543457, 'loss_4': 0.6237748861312866, 'epoch': 12.19}
{'loss': 0.0116, 'grad_norm': 5.82981014251709, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.011443562805652618, 'loss_2': 0.00018453598022460938, 'loss_3': -16.419841766357422, 'loss_4': 0.20668601989746094, 'epoch': 12.2}
{'loss': 0.0108, 'grad_norm': 5.537221908569336, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.010582846589386463, 'loss_2': 0.00022339820861816406, 'loss_3': -16.514766693115234, 'loss_4': 0.8077556490898132, 'epoch': 12.2}
{'loss': 0.0109, 'grad_norm': 4.72478723526001, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.004982267506420612, 'loss_2': 0.00594329833984375, 'loss_3': -16.47197151184082, 'loss_4': 0.31717270612716675, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 10:15:54,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:15:54,744 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:09<52:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:02,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008944211527705193, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0056636459194123745, 'eval_loss_2': 0.0032805651426315308, 'eval_loss_3': -18.289661407470703, 'eval_loss_4': 0.6600714921951294, 'epoch': 12.21}
{'loss': 0.0128, 'grad_norm': 7.364902973175049, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.012186642736196518, 'loss_2': 0.0005817413330078125, 'loss_3': -16.35296630859375, 'loss_4': 0.8007667064666748, 'epoch': 12.22}
{'loss': 0.0112, 'grad_norm': 4.8468098640441895, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.006734349764883518, 'loss_2': 0.004421234130859375, 'loss_3': -16.41506576538086, 'loss_4': 0.6038732528686523, 'epoch': 12.22}
{'loss': 0.0111, 'grad_norm': 5.312580108642578, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.006449572276324034, 'loss_2': 0.00460052490234375, 'loss_3': -16.484912872314453, 'loss_4': 0.3331630825996399, 'epoch': 12.23}
{'loss': 0.0143, 'grad_norm': 6.213170528411865, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.00935982633382082, 'loss_2': 0.00495147705078125, 'loss_3': -16.371416091918945, 'loss_4': 0.6451634168624878, 'epoch': 12.23}
{'loss': 0.0159, 'grad_norm': 5.90614652633667, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.010680938139557838, 'loss_2': 0.00521087646484375, 'loss_3': -16.48643684387207, 'loss_4': 0.5628854632377625, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 10:16:02,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:02,076 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:16<52:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:09,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01224835216999054, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0070419833064079285, 'eval_loss_2': 0.005206368863582611, 'eval_loss_3': -18.22295379638672, 'eval_loss_4': 0.6772832870483398, 'epoch': 12.24}
{'loss': 0.0094, 'grad_norm': 5.432672023773193, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.0076344748958945274, 'loss_2': 0.001766204833984375, 'loss_3': -16.419418334960938, 'loss_4': 0.5805580615997314, 'epoch': 12.24}
{'loss': 0.0123, 'grad_norm': 6.041109561920166, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.010227189399302006, 'loss_2': 0.0020751953125, 'loss_3': -16.409069061279297, 'loss_4': 0.36648282408714294, 'epoch': 12.25}
{'loss': 0.0253, 'grad_norm': 8.404069900512695, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.018966585397720337, 'loss_2': 0.00634002685546875, 'loss_3': -16.32235336303711, 'loss_4': 0.8320941925048828, 'epoch': 12.26}
{'loss': 0.0129, 'grad_norm': 5.440939903259277, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.012644215486943722, 'loss_2': 0.0002541542053222656, 'loss_3': -16.37409210205078, 'loss_4': 0.8579682111740112, 'epoch': 12.26}
{'loss': 0.0397, 'grad_norm': 18.077192306518555, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.03603409230709076, 'loss_2': 0.00366973876953125, 'loss_3': -16.066896438598633, 'loss_4': 0.49441614747047424, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 10:16:09,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:09,420 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:23<52:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:16,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017371609807014465, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.787, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013119274750351906, 'eval_loss_2': 0.004252336919307709, 'eval_loss_3': -18.160818099975586, 'eval_loss_4': 0.8476082682609558, 'epoch': 12.27}
{'loss': 0.0065, 'grad_norm': 5.034616947174072, 'learning_rate': 1.775e-05, 'loss_1': 0.005829351954162121, 'loss_2': 0.0006227493286132812, 'loss_3': -16.239112854003906, 'loss_4': 0.3479056656360626, 'epoch': 12.27}
{'loss': 0.0153, 'grad_norm': 4.687127113342285, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.008144417777657509, 'loss_2': 0.007160186767578125, 'loss_3': -16.359291076660156, 'loss_4': 0.6450462937355042, 'epoch': 12.28}
{'loss': 0.0166, 'grad_norm': 4.760447025299072, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.009000691585242748, 'loss_2': 0.0076446533203125, 'loss_3': -16.42975616455078, 'loss_4': 0.8603949546813965, 'epoch': 12.28}
{'loss': 0.0176, 'grad_norm': 6.581298828125, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.01638447307050228, 'loss_2': 0.0012598037719726562, 'loss_3': -16.320480346679688, 'loss_4': 0.6440705060958862, 'epoch': 12.29}
{'loss': 0.0095, 'grad_norm': 4.575088024139404, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.007504488807171583, 'loss_2': 0.002025604248046875, 'loss_3': -16.301868438720703, 'loss_4': 0.7776057124137878, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 10:16:16,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:16,764 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:31<52:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:24,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02043876051902771, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.214, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0162256620824337, 'eval_loss_2': 0.004213098436594009, 'eval_loss_3': -18.162363052368164, 'eval_loss_4': 1.143276572227478, 'epoch': 12.3}
{'loss': 0.0116, 'grad_norm': 5.127350330352783, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.010426844470202923, 'loss_2': 0.0012140274047851562, 'loss_3': -16.53522491455078, 'loss_4': 0.9779870510101318, 'epoch': 12.3}
{'loss': 0.0124, 'grad_norm': 5.4470601081848145, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.01078785490244627, 'loss_2': 0.0016384124755859375, 'loss_3': -16.28407096862793, 'loss_4': 0.644037127494812, 'epoch': 12.31}
{'loss': 0.011, 'grad_norm': 5.915322303771973, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.01058767270296812, 'loss_2': 0.00037670135498046875, 'loss_3': -16.282861709594727, 'loss_4': 1.0765947103500366, 'epoch': 12.31}
{'loss': 0.0112, 'grad_norm': 5.768337726593018, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.011119621805846691, 'loss_2': 8.016824722290039e-05, 'loss_3': -16.236642837524414, 'loss_4': 0.33438006043434143, 'epoch': 12.32}
{'loss': 0.0281, 'grad_norm': 14.010784149169922, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.02621319331228733, 'loss_2': 0.0018768310546875, 'loss_3': -16.255966186523438, 'loss_4': 1.164901614189148, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 10:16:24,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:24,108 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:38<52:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:31,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014848506078124046, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010555960237979889, 'eval_loss_2': 0.004292547702789307, 'eval_loss_3': -18.177021026611328, 'eval_loss_4': 1.1950263977050781, 'epoch': 12.33}
{'loss': 0.0144, 'grad_norm': 6.180683135986328, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.011769866570830345, 'loss_2': 0.00267791748046875, 'loss_3': -16.298646926879883, 'loss_4': 0.7298818826675415, 'epoch': 12.33}
{'loss': 0.0218, 'grad_norm': 7.106278419494629, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.016275327652692795, 'loss_2': 0.0054931640625, 'loss_3': -16.21429443359375, 'loss_4': 1.079225778579712, 'epoch': 12.34}
{'loss': 0.0186, 'grad_norm': 5.730669975280762, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.010564575903117657, 'loss_2': 0.00807952880859375, 'loss_3': -16.235759735107422, 'loss_4': 1.1762055158615112, 'epoch': 12.34}
{'loss': 0.032, 'grad_norm': 20.144750595092773, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.028360964730381966, 'loss_2': 0.00363922119140625, 'loss_3': -16.21368408203125, 'loss_4': 1.781986951828003, 'epoch': 12.35}
{'loss': 0.0116, 'grad_norm': 6.1478166580200195, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.008506099693477154, 'loss_2': 0.003124237060546875, 'loss_3': -16.380840301513672, 'loss_4': 0.8668060302734375, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 10:16:31,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:31,457 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:46<52:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:38,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009452865459024906, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.306, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007260486949235201, 'eval_loss_2': 0.002192378044128418, 'eval_loss_3': -18.19814109802246, 'eval_loss_4': 1.1590720415115356, 'epoch': 12.35}
{'loss': 0.0153, 'grad_norm': 5.176117897033691, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.00959390215575695, 'loss_2': 0.005695343017578125, 'loss_3': -16.297306060791016, 'loss_4': 1.2532880306243896, 'epoch': 12.36}
{'loss': 0.0133, 'grad_norm': 4.845481872558594, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.009273597970604897, 'loss_2': 0.004058837890625, 'loss_3': -16.258153915405273, 'loss_4': 0.8560382723808289, 'epoch': 12.37}
{'loss': 0.0145, 'grad_norm': 6.168435096740723, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.009991367347538471, 'loss_2': 0.00453948974609375, 'loss_3': -16.25977325439453, 'loss_4': 1.5483081340789795, 'epoch': 12.37}
{'loss': 0.0087, 'grad_norm': 6.120965957641602, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.00794103555381298, 'loss_2': 0.0007519721984863281, 'loss_3': -16.268953323364258, 'loss_4': 1.4959999322891235, 'epoch': 12.38}
{'loss': 0.0111, 'grad_norm': 6.072717666625977, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.010588363744318485, 'loss_2': 0.0005350112915039062, 'loss_3': -16.373340606689453, 'loss_4': 1.3279006481170654, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 10:16:38,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:38,817 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [52:53<52:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:16:46,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0100793968886137, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007207213900983334, 'eval_loss_2': 0.002872183918952942, 'eval_loss_3': -18.183368682861328, 'eval_loss_4': 1.4059231281280518, 'epoch': 12.38}
{'loss': 0.0116, 'grad_norm': 4.86928653717041, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.005515052936971188, 'loss_2': 0.006046295166015625, 'loss_3': -16.449127197265625, 'loss_4': 0.9888262152671814, 'epoch': 12.39}
{'loss': 0.0268, 'grad_norm': 9.397195816040039, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.021785646677017212, 'loss_2': 0.005035400390625, 'loss_3': -16.349761962890625, 'loss_4': 1.1237291097640991, 'epoch': 12.4}
{'loss': 0.0165, 'grad_norm': 6.114161491394043, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.009237347170710564, 'loss_2': 0.00730133056640625, 'loss_3': -16.023082733154297, 'loss_4': 1.523836612701416, 'epoch': 12.4}
{'loss': 0.0142, 'grad_norm': 5.462920188903809, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.013164576143026352, 'loss_2': 0.001056671142578125, 'loss_3': -16.211597442626953, 'loss_4': 1.2444467544555664, 'epoch': 12.41}
{'loss': 0.0196, 'grad_norm': 8.570521354675293, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.01454775221645832, 'loss_2': 0.0050201416015625, 'loss_3': -16.14319610595703, 'loss_4': 1.9847171306610107, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 10:16:46,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:46,158 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:00<52:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:16:53,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01393679529428482, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006137944292277098, 'eval_loss_2': 0.0077988505363464355, 'eval_loss_3': -18.19076156616211, 'eval_loss_4': 1.799932599067688, 'epoch': 12.41}
{'loss': 0.0222, 'grad_norm': 5.993778705596924, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.010458352044224739, 'loss_2': 0.01177978515625, 'loss_3': -16.29907989501953, 'loss_4': 1.9943089485168457, 'epoch': 12.42}
{'loss': 0.02, 'grad_norm': 8.045626640319824, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.013868855312466621, 'loss_2': 0.00612640380859375, 'loss_3': -16.249937057495117, 'loss_4': 2.0997061729431152, 'epoch': 12.42}
{'loss': 0.0169, 'grad_norm': 8.215119361877441, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.01599241979420185, 'loss_2': 0.000911712646484375, 'loss_3': -16.253353118896484, 'loss_4': 1.6086373329162598, 'epoch': 12.43}
{'loss': 0.0136, 'grad_norm': 6.57143497467041, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.009311037138104439, 'loss_2': 0.004337310791015625, 'loss_3': -16.054475784301758, 'loss_4': 1.5923097133636475, 'epoch': 12.44}
{'loss': 0.0183, 'grad_norm': 5.1822943687438965, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.007852470502257347, 'loss_2': 0.01043701171875, 'loss_3': -16.135555267333984, 'loss_4': 1.828290343284607, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 10:16:53,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:16:53,486 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:08<52:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:00,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009913284331560135, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.243, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005579386372119188, 'eval_loss_2': 0.004333898425102234, 'eval_loss_3': -18.1861629486084, 'eval_loss_4': 1.8420077562332153, 'epoch': 12.44}
{'loss': 0.0144, 'grad_norm': 6.614430904388428, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.011656462214887142, 'loss_2': 0.002777099609375, 'loss_3': -16.218090057373047, 'loss_4': 1.9305152893066406, 'epoch': 12.45}
{'loss': 0.0117, 'grad_norm': 5.638391971588135, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.006980451755225658, 'loss_2': 0.00472259521484375, 'loss_3': -16.425613403320312, 'loss_4': 1.4787386655807495, 'epoch': 12.45}
{'loss': 0.0153, 'grad_norm': 6.767154693603516, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.014258048497140408, 'loss_2': 0.0010843276977539062, 'loss_3': -16.169570922851562, 'loss_4': 1.3698375225067139, 'epoch': 12.46}
{'loss': 0.025, 'grad_norm': 13.613228797912598, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.023922983556985855, 'loss_2': 0.001064300537109375, 'loss_3': -16.10112953186035, 'loss_4': 1.198678731918335, 'epoch': 12.47}
{'loss': 0.0094, 'grad_norm': 5.21716833114624, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.009290884248912334, 'loss_2': 0.0001513957977294922, 'loss_3': -16.440288543701172, 'loss_4': 1.3755501508712769, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 10:17:00,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:00,827 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:15<51:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:08,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009493404999375343, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005726437084376812, 'eval_loss_2': 0.003766968846321106, 'eval_loss_3': -18.204866409301758, 'eval_loss_4': 1.7627085447311401, 'epoch': 12.47}
{'loss': 0.0131, 'grad_norm': 4.584332466125488, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.007273934781551361, 'loss_2': 0.00579833984375, 'loss_3': -16.40365219116211, 'loss_4': 1.9602327346801758, 'epoch': 12.48}
{'loss': 0.0108, 'grad_norm': 5.952373027801514, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.009422780945897102, 'loss_2': 0.0013751983642578125, 'loss_3': -16.27019500732422, 'loss_4': 1.904087781906128, 'epoch': 12.48}
{'loss': 0.0126, 'grad_norm': 6.221229553222656, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.011289977468550205, 'loss_2': 0.001262664794921875, 'loss_3': -16.11017417907715, 'loss_4': 1.613412857055664, 'epoch': 12.49}
{'loss': 0.0106, 'grad_norm': 6.249851226806641, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.00921934936195612, 'loss_2': 0.00136566162109375, 'loss_3': -16.18909454345703, 'loss_4': 2.0142788887023926, 'epoch': 12.49}
{'loss': 0.0185, 'grad_norm': 4.914359092712402, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.008582104928791523, 'loss_2': 0.0098876953125, 'loss_3': -16.069061279296875, 'loss_4': 2.174452543258667, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 10:17:08,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:08,166 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:22<51:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:15,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010991551913321018, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.289, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005729250609874725, 'eval_loss_2': 0.005262300372123718, 'eval_loss_3': -18.194869995117188, 'eval_loss_4': 1.8682861328125, 'epoch': 12.5}
{'loss': 0.0187, 'grad_norm': 6.411423683166504, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.009843505918979645, 'loss_2': 0.00885009765625, 'loss_3': -16.18927764892578, 'loss_4': 1.5870981216430664, 'epoch': 12.51}
{'loss': 0.0323, 'grad_norm': 7.7640156745910645, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.019620733335614204, 'loss_2': 0.0126953125, 'loss_3': -16.40399932861328, 'loss_4': 1.5786021947860718, 'epoch': 12.51}
{'loss': 0.0119, 'grad_norm': 6.080661773681641, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.009904328733682632, 'loss_2': 0.002025604248046875, 'loss_3': -16.342021942138672, 'loss_4': 1.6282663345336914, 'epoch': 12.52}
{'loss': 0.0193, 'grad_norm': 7.285220623016357, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.012625833041965961, 'loss_2': 0.00670623779296875, 'loss_3': -16.098682403564453, 'loss_4': 2.1498801708221436, 'epoch': 12.52}
{'loss': 0.0141, 'grad_norm': 5.480509281158447, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.010685027576982975, 'loss_2': 0.0034236907958984375, 'loss_3': -16.190887451171875, 'loss_4': 1.6756430864334106, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 10:17:15,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:15,525 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:30<51:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:22,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012447765097022057, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007594697177410126, 'eval_loss_2': 0.00485306978225708, 'eval_loss_3': -18.15312385559082, 'eval_loss_4': 2.107452154159546, 'epoch': 12.53}
{'loss': 0.0239, 'grad_norm': 10.05838680267334, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.019929759204387665, 'loss_2': 0.0040130615234375, 'loss_3': -16.290679931640625, 'loss_4': 2.6214866638183594, 'epoch': 12.53}
{'loss': 0.0355, 'grad_norm': 20.738468170166016, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.031164541840553284, 'loss_2': 0.004360198974609375, 'loss_3': -16.432674407958984, 'loss_4': 2.2327308654785156, 'epoch': 12.54}
{'loss': 0.0158, 'grad_norm': 7.729022979736328, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.015406537801027298, 'loss_2': 0.00036144256591796875, 'loss_3': -16.133502960205078, 'loss_4': 1.9434127807617188, 'epoch': 12.55}
{'loss': 0.0177, 'grad_norm': 5.057595729827881, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.007936161942780018, 'loss_2': 0.009765625, 'loss_3': -16.355066299438477, 'loss_4': 2.3187527656555176, 'epoch': 12.55}
{'loss': 0.0125, 'grad_norm': 4.671379089355469, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.010042620822787285, 'loss_2': 0.002445220947265625, 'loss_3': -16.427959442138672, 'loss_4': 2.513241767883301, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 10:17:22,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:22,866 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:37<51:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:30,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011257467791438103, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.392, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006196437869220972, 'eval_loss_2': 0.005061030387878418, 'eval_loss_3': -18.158645629882812, 'eval_loss_4': 1.908879280090332, 'epoch': 12.56}
{'loss': 0.0165, 'grad_norm': 6.751833438873291, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.013547620736062527, 'loss_2': 0.0029754638671875, 'loss_3': -16.288305282592773, 'loss_4': 2.5028579235076904, 'epoch': 12.56}
{'loss': 0.0134, 'grad_norm': 4.942150592803955, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.005810364615172148, 'loss_2': 0.007556915283203125, 'loss_3': -16.34263801574707, 'loss_4': 1.6873369216918945, 'epoch': 12.57}
{'loss': 0.0109, 'grad_norm': 5.527065753936768, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.008044926449656487, 'loss_2': 0.002902984619140625, 'loss_3': -16.141887664794922, 'loss_4': 2.1794140338897705, 'epoch': 12.58}
{'loss': 0.0166, 'grad_norm': 9.1422758102417, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.015169386751949787, 'loss_2': 0.0013828277587890625, 'loss_3': -16.308429718017578, 'loss_4': 2.355879783630371, 'epoch': 12.58}
{'loss': 0.0105, 'grad_norm': 5.184098720550537, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.010269347578287125, 'loss_2': 0.00021541118621826172, 'loss_3': -16.297870635986328, 'loss_4': 2.0251808166503906, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 10:17:30,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:30,207 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:44<51:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:37,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00911354087293148, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004779494367539883, 'eval_loss_2': 0.004334047436714172, 'eval_loss_3': -18.213029861450195, 'eval_loss_4': 1.8065288066864014, 'epoch': 12.59}
{'loss': 0.0182, 'grad_norm': 13.39850902557373, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.015930768102407455, 'loss_2': 0.002262115478515625, 'loss_3': -16.413467407226562, 'loss_4': 2.0106000900268555, 'epoch': 12.59}
{'loss': 0.0198, 'grad_norm': 5.871370315551758, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.012047238647937775, 'loss_2': 0.00775909423828125, 'loss_3': -16.251815795898438, 'loss_4': 1.078708529472351, 'epoch': 12.6}
{'loss': 0.0141, 'grad_norm': 4.5065388679504395, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.0036929838825017214, 'loss_2': 0.01038360595703125, 'loss_3': -16.365432739257812, 'loss_4': 2.1576144695281982, 'epoch': 12.6}
{'loss': 0.0143, 'grad_norm': 11.160697937011719, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.014156837947666645, 'loss_2': 0.0001475811004638672, 'loss_3': -16.21937370300293, 'loss_4': 1.4235724210739136, 'epoch': 12.61}
{'loss': 0.0205, 'grad_norm': 13.321125984191895, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.01601933129131794, 'loss_2': 0.00452423095703125, 'loss_3': -16.419763565063477, 'loss_4': 1.600959300994873, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 10:17:37,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:37,545 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:52<51:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:44,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010469870641827583, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004479097202420235, 'eval_loss_2': 0.005990773439407349, 'eval_loss_3': -18.251598358154297, 'eval_loss_4': 1.9001210927963257, 'epoch': 12.62}
{'loss': 0.0149, 'grad_norm': 5.744415760040283, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.009717066772282124, 'loss_2': 0.005218505859375, 'loss_3': -16.241676330566406, 'loss_4': 1.9908666610717773, 'epoch': 12.62}
{'loss': 0.0254, 'grad_norm': 6.503801345825195, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.009521462954580784, 'loss_2': 0.015838623046875, 'loss_3': -16.338481903076172, 'loss_4': 1.5460891723632812, 'epoch': 12.63}
{'loss': 0.0197, 'grad_norm': 5.115992546081543, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.011414806358516216, 'loss_2': 0.00830078125, 'loss_3': -16.452632904052734, 'loss_4': 1.7632578611373901, 'epoch': 12.63}
{'loss': 0.0206, 'grad_norm': 11.668619155883789, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.016554629430174828, 'loss_2': 0.00400543212890625, 'loss_3': -16.23113250732422, 'loss_4': 2.6940927505493164, 'epoch': 12.64}
{'loss': 0.0149, 'grad_norm': 5.002172946929932, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.006215584464371204, 'loss_2': 0.0086669921875, 'loss_3': -16.349105834960938, 'loss_4': 2.7236194610595703, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 10:17:44,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:44,884 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [53:59<51:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:52,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009632770903408527, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.193, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005220332182943821, 'eval_loss_2': 0.004412438720464706, 'eval_loss_3': -18.26447296142578, 'eval_loss_4': 1.998478889465332, 'epoch': 12.65}
{'loss': 0.0297, 'grad_norm': 11.467144966125488, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.02113584615290165, 'loss_2': 0.00860595703125, 'loss_3': -16.434162139892578, 'loss_4': 3.5075130462646484, 'epoch': 12.65}
{'loss': 0.019, 'grad_norm': 6.010251522064209, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.011454802006483078, 'loss_2': 0.007572174072265625, 'loss_3': -16.315876007080078, 'loss_4': 2.5076892375946045, 'epoch': 12.66}
{'loss': 0.0244, 'grad_norm': 10.230337142944336, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.022919047623872757, 'loss_2': 0.0015106201171875, 'loss_3': -16.300941467285156, 'loss_4': 2.8518168926239014, 'epoch': 12.66}
{'loss': 0.0217, 'grad_norm': 6.194782733917236, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.015248874202370644, 'loss_2': 0.0064849853515625, 'loss_3': -16.183664321899414, 'loss_4': 2.7225918769836426, 'epoch': 12.67}
{'loss': 0.0163, 'grad_norm': 4.881068229675293, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.00865987315773964, 'loss_2': 0.007678985595703125, 'loss_3': -16.46904754638672, 'loss_4': 2.7460851669311523, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 10:17:52,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:52,228 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:06<51:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:17:59,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00872811395674944, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.491, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005043563432991505, 'eval_loss_2': 0.0036845505237579346, 'eval_loss_3': -18.26768684387207, 'eval_loss_4': 2.148660898208618, 'epoch': 12.67}
{'loss': 0.0111, 'grad_norm': 5.4888811111450195, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.00991236325353384, 'loss_2': 0.0011615753173828125, 'loss_3': -16.38258934020996, 'loss_4': 2.3254878520965576, 'epoch': 12.68}
{'loss': 0.022, 'grad_norm': 9.377704620361328, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.017361419275403023, 'loss_2': 0.00464630126953125, 'loss_3': -16.100135803222656, 'loss_4': 1.9445829391479492, 'epoch': 12.69}
{'loss': 0.0215, 'grad_norm': 10.400591850280762, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.021170467138290405, 'loss_2': 0.00030517578125, 'loss_3': -16.369050979614258, 'loss_4': 2.118605136871338, 'epoch': 12.69}
{'loss': 0.0096, 'grad_norm': 5.444415092468262, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.007903505116701126, 'loss_2': 0.0017251968383789062, 'loss_3': -16.625370025634766, 'loss_4': 2.681840419769287, 'epoch': 12.7}
{'loss': 0.0137, 'grad_norm': 5.83065128326416, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.009751436300575733, 'loss_2': 0.00396728515625, 'loss_3': -16.360748291015625, 'loss_4': 2.623356342315674, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 10:17:59,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:17:59,583 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:14<51:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:06,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010083233006298542, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.576, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006159578450024128, 'eval_loss_2': 0.003923654556274414, 'eval_loss_3': -18.296167373657227, 'eval_loss_4': 2.2747795581817627, 'epoch': 12.7}
{'loss': 0.0289, 'grad_norm': 7.865352153778076, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.019643424078822136, 'loss_2': 0.00930023193359375, 'loss_3': -16.59143829345703, 'loss_4': 2.233717679977417, 'epoch': 12.71}
{'loss': 0.0277, 'grad_norm': 7.131011486053467, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.021684978157281876, 'loss_2': 0.0060577392578125, 'loss_3': -16.318052291870117, 'loss_4': 3.0495591163635254, 'epoch': 12.72}
{'loss': 0.0217, 'grad_norm': 6.272363662719727, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.014888596720993519, 'loss_2': 0.00677490234375, 'loss_3': -16.564449310302734, 'loss_4': 2.880148410797119, 'epoch': 12.72}
{'loss': 0.0283, 'grad_norm': 9.880819320678711, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.027839770540595055, 'loss_2': 0.0004868507385253906, 'loss_3': -16.37000846862793, 'loss_4': 3.17739200592041, 'epoch': 12.73}
{'loss': 0.0128, 'grad_norm': 4.728845596313477, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.007726270705461502, 'loss_2': 0.00506591796875, 'loss_3': -16.591697692871094, 'loss_4': 2.8012967109680176, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 10:18:06,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:06,918 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:21<51:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:14,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009729987010359764, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006524253636598587, 'eval_loss_2': 0.003205731511116028, 'eval_loss_3': -18.293983459472656, 'eval_loss_4': 2.3052515983581543, 'epoch': 12.73}
{'loss': 0.0219, 'grad_norm': 8.074007034301758, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.021528856828808784, 'loss_2': 0.00042057037353515625, 'loss_3': -16.296104431152344, 'loss_4': 2.783726930618286, 'epoch': 12.74}
{'loss': 0.0233, 'grad_norm': 7.443190097808838, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.014106986112892628, 'loss_2': 0.00922393798828125, 'loss_3': -16.302669525146484, 'loss_4': 2.57613468170166, 'epoch': 12.74}
{'loss': 0.0086, 'grad_norm': 5.136524677276611, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.00707043195143342, 'loss_2': 0.0015745162963867188, 'loss_3': -16.457813262939453, 'loss_4': 2.808783769607544, 'epoch': 12.75}
{'loss': 0.0222, 'grad_norm': 5.6659159660339355, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.011430817656219006, 'loss_2': 0.0107879638671875, 'loss_3': -16.466171264648438, 'loss_4': 3.3350648880004883, 'epoch': 12.76}
{'loss': 0.0216, 'grad_norm': 11.927441596984863, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.017372487112879753, 'loss_2': 0.00418853759765625, 'loss_3': -16.30221176147461, 'loss_4': 3.0418105125427246, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 10:18:14,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:14,253 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:28<51:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:21,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012880741618573666, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006801007315516472, 'eval_loss_2': 0.006079733371734619, 'eval_loss_3': -18.293537139892578, 'eval_loss_4': 2.243166446685791, 'epoch': 12.76}
{'loss': 0.0163, 'grad_norm': 8.02580451965332, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.013199230656027794, 'loss_2': 0.0031223297119140625, 'loss_3': -16.42340850830078, 'loss_4': 2.60153865814209, 'epoch': 12.77}
{'loss': 0.0192, 'grad_norm': 8.250732421875, 'learning_rate': 1.725e-05, 'loss_1': 0.015780063346028328, 'loss_2': 0.003398895263671875, 'loss_3': -16.344127655029297, 'loss_4': 2.5646891593933105, 'epoch': 12.77}
{'loss': 0.0188, 'grad_norm': 7.536468029022217, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.013452602550387383, 'loss_2': 0.00531005859375, 'loss_3': -16.27037239074707, 'loss_4': 2.6979146003723145, 'epoch': 12.78}
{'loss': 0.0203, 'grad_norm': 9.308996200561523, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.014971701428294182, 'loss_2': 0.00530242919921875, 'loss_3': -16.386119842529297, 'loss_4': 2.2999427318573, 'epoch': 12.78}
{'loss': 0.013, 'grad_norm': 5.117918014526367, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.007108026649802923, 'loss_2': 0.0059051513671875, 'loss_3': -16.331573486328125, 'loss_4': 3.30046010017395, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 10:18:21,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:21,594 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:36<51:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:28,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011727197095751762, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007399260066449642, 'eval_loss_2': 0.004327937960624695, 'eval_loss_3': -18.274585723876953, 'eval_loss_4': 2.1001386642456055, 'epoch': 12.79}
{'loss': 0.0129, 'grad_norm': 5.426443099975586, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.00837474875152111, 'loss_2': 0.0045013427734375, 'loss_3': -16.571048736572266, 'loss_4': 2.819932460784912, 'epoch': 12.8}
{'loss': 0.021, 'grad_norm': 7.307552337646484, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.016769496724009514, 'loss_2': 0.00428009033203125, 'loss_3': -16.399372100830078, 'loss_4': 2.348940134048462, 'epoch': 12.8}
{'loss': 0.0117, 'grad_norm': 4.727460861206055, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.006799767725169659, 'loss_2': 0.004901885986328125, 'loss_3': -16.49378204345703, 'loss_4': 2.1911184787750244, 'epoch': 12.81}
{'loss': 0.0082, 'grad_norm': 4.522772789001465, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.006324504502117634, 'loss_2': 0.00191497802734375, 'loss_3': -16.272998809814453, 'loss_4': 2.6869475841522217, 'epoch': 12.81}
{'loss': 0.0161, 'grad_norm': 7.130735874176025, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.014151709154248238, 'loss_2': 0.0019359588623046875, 'loss_3': -16.159427642822266, 'loss_4': 2.6046323776245117, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 10:18:28,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:28,940 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:43<51:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:36,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010098166763782501, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.461, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006403795909136534, 'eval_loss_2': 0.00369437038898468, 'eval_loss_3': -18.25054359436035, 'eval_loss_4': 2.204092025756836, 'epoch': 12.82}
{'loss': 0.0103, 'grad_norm': 5.110668659210205, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.008048314601182938, 'loss_2': 0.002231597900390625, 'loss_3': -16.319721221923828, 'loss_4': 2.695584774017334, 'epoch': 12.83}
{'loss': 0.0113, 'grad_norm': 4.459132671356201, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.00819738395512104, 'loss_2': 0.003101348876953125, 'loss_3': -16.3060302734375, 'loss_4': 2.8604226112365723, 'epoch': 12.83}
{'loss': 0.0152, 'grad_norm': 6.995551586151123, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.012597949244081974, 'loss_2': 0.002643585205078125, 'loss_3': -16.32303237915039, 'loss_4': 3.030836582183838, 'epoch': 12.84}
{'loss': 0.0099, 'grad_norm': 5.0144171714782715, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.007096613757312298, 'loss_2': 0.002777099609375, 'loss_3': -16.374385833740234, 'loss_4': 2.247908353805542, 'epoch': 12.84}
{'loss': 0.0116, 'grad_norm': 5.509546279907227, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.0069754840806126595, 'loss_2': 0.0046234130859375, 'loss_3': -16.461376190185547, 'loss_4': 2.480238437652588, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 10:18:36,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:36,297 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:50<50:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:43,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008757843635976315, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.21, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005257382523268461, 'eval_loss_2': 0.0035004615783691406, 'eval_loss_3': -18.23188018798828, 'eval_loss_4': 2.4405670166015625, 'epoch': 12.85}
{'loss': 0.0116, 'grad_norm': 4.814288139343262, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.009816533885896206, 'loss_2': 0.0017642974853515625, 'loss_3': -16.368698120117188, 'loss_4': 2.633899211883545, 'epoch': 12.85}
{'loss': 0.0093, 'grad_norm': 5.31828498840332, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.008289369754493237, 'loss_2': 0.00099945068359375, 'loss_3': -16.353641510009766, 'loss_4': 2.820870876312256, 'epoch': 12.86}
{'loss': 0.0111, 'grad_norm': 4.759174346923828, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.006730921100825071, 'loss_2': 0.00437164306640625, 'loss_3': -16.356121063232422, 'loss_4': 2.5685853958129883, 'epoch': 12.87}
{'loss': 0.0126, 'grad_norm': 4.890174865722656, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.005532522220164537, 'loss_2': 0.007110595703125, 'loss_3': -16.363170623779297, 'loss_4': 3.022481918334961, 'epoch': 12.87}
{'loss': 0.011, 'grad_norm': 4.987244129180908, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.008427362889051437, 'loss_2': 0.0026111602783203125, 'loss_3': -16.3505859375, 'loss_4': 3.0363595485687256, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 10:18:43,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:43,642 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [54:58<50:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:50,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009306993335485458, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005113433580845594, 'eval_loss_2': 0.004193559288978577, 'eval_loss_3': -18.240018844604492, 'eval_loss_4': 2.567652463912964, 'epoch': 12.88}
{'loss': 0.0232, 'grad_norm': 12.74325942993164, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.020780690014362335, 'loss_2': 0.0024242401123046875, 'loss_3': -16.33211898803711, 'loss_4': 2.768366575241089, 'epoch': 12.88}
{'loss': 0.0194, 'grad_norm': 8.349569320678711, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.017444385215640068, 'loss_2': 0.0019989013671875, 'loss_3': -16.22154998779297, 'loss_4': 3.0458199977874756, 'epoch': 12.89}
{'loss': 0.0133, 'grad_norm': 6.139737606048584, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.010873883962631226, 'loss_2': 0.0024204254150390625, 'loss_3': -16.308794021606445, 'loss_4': 2.526381492614746, 'epoch': 12.9}
{'loss': 0.0074, 'grad_norm': 4.885284900665283, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.006807668600231409, 'loss_2': 0.0005483627319335938, 'loss_3': -16.14568519592285, 'loss_4': 3.466510534286499, 'epoch': 12.9}
{'loss': 0.0211, 'grad_norm': 6.057069301605225, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.01553830411285162, 'loss_2': 0.00556182861328125, 'loss_3': -16.210323333740234, 'loss_4': 2.9460368156433105, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 10:18:50,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:50,986 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:05<50:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:18:58,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008750437758862972, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.585, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0056279744021594524, 'eval_loss_2': 0.003122463822364807, 'eval_loss_3': -18.249143600463867, 'eval_loss_4': 2.6269333362579346, 'epoch': 12.91}
{'loss': 0.0163, 'grad_norm': 5.638463973999023, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.009389561600983143, 'loss_2': 0.0069122314453125, 'loss_3': -16.184139251708984, 'loss_4': 2.85016131401062, 'epoch': 12.91}
{'loss': 0.008, 'grad_norm': 4.583800792694092, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.0063393437303602695, 'loss_2': 0.001659393310546875, 'loss_3': -16.373205184936523, 'loss_4': 3.3542351722717285, 'epoch': 12.92}
{'loss': 0.009, 'grad_norm': 5.333597183227539, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.007932431995868683, 'loss_2': 0.0010433197021484375, 'loss_3': -16.165437698364258, 'loss_4': 2.9456026554107666, 'epoch': 12.92}
{'loss': 0.0127, 'grad_norm': 5.324246883392334, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.007852455601096153, 'loss_2': 0.00489044189453125, 'loss_3': -16.229106903076172, 'loss_4': 2.4980247020721436, 'epoch': 12.93}
{'loss': 0.0119, 'grad_norm': 4.342349529266357, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.009220738895237446, 'loss_2': 0.002685546875, 'loss_3': -16.31366729736328, 'loss_4': 2.6825289726257324, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 10:18:58,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:18:58,337 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:12<50:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:05,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009162642993032932, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005016885232180357, 'eval_loss_2': 0.004145756363868713, 'eval_loss_3': -18.24622917175293, 'eval_loss_4': 2.5415291786193848, 'epoch': 12.94}
{'loss': 0.0628, 'grad_norm': 15.283623695373535, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.05562739074230194, 'loss_2': 0.0071258544921875, 'loss_3': -16.207399368286133, 'loss_4': 3.076381206512451, 'epoch': 12.94}
{'loss': 0.0309, 'grad_norm': 12.734920501708984, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.02683577872812748, 'loss_2': 0.0040740966796875, 'loss_3': -16.386276245117188, 'loss_4': 2.5394835472106934, 'epoch': 12.95}
{'loss': 0.018, 'grad_norm': 8.110857963562012, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.014356866478919983, 'loss_2': 0.00362396240234375, 'loss_3': -16.1514835357666, 'loss_4': 2.3849105834960938, 'epoch': 12.95}
{'loss': 0.0144, 'grad_norm': 6.935919761657715, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.0134803531691432, 'loss_2': 0.000881195068359375, 'loss_3': -16.201961517333984, 'loss_4': 2.7015109062194824, 'epoch': 12.96}
{'loss': 0.0171, 'grad_norm': 5.2132344245910645, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.009238692000508308, 'loss_2': 0.00786590576171875, 'loss_3': -16.405763626098633, 'loss_4': 3.5320582389831543, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 10:19:05,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:05,680 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:20<50:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:19:12,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01235932856798172, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0061734081245958805, 'eval_loss_2': 0.0061859190464019775, 'eval_loss_3': -18.2643985748291, 'eval_loss_4': 2.7386937141418457, 'epoch': 12.97}
{'loss': 0.0482, 'grad_norm': 10.88430404663086, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.03720112890005112, 'loss_2': 0.01100921630859375, 'loss_3': -16.242843627929688, 'loss_4': 3.494251012802124, 'epoch': 12.97}
{'loss': 0.0159, 'grad_norm': 5.706427574157715, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.011998504400253296, 'loss_2': 0.0038604736328125, 'loss_3': -16.249797821044922, 'loss_4': 2.8881030082702637, 'epoch': 12.98}
{'loss': 0.0125, 'grad_norm': 5.334628582000732, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.011908269487321377, 'loss_2': 0.0006184577941894531, 'loss_3': -16.264694213867188, 'loss_4': 3.8288016319274902, 'epoch': 12.98}
{'loss': 0.0341, 'grad_norm': 11.115179061889648, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.024135295301675797, 'loss_2': 0.010009765625, 'loss_3': -16.27677345275879, 'loss_4': 2.524007797241211, 'epoch': 12.99}
{'loss': 0.019, 'grad_norm': 5.686554431915283, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.013886597007513046, 'loss_2': 0.00514984130859375, 'loss_3': -16.148191452026367, 'loss_4': 3.3064017295837402, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 10:19:12,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:12,998 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:27<49:32,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:19:20,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009585615247488022, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.177, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006309916730970144, 'eval_loss_2': 0.0032756999135017395, 'eval_loss_3': -18.280757904052734, 'eval_loss_4': 2.8665730953216553, 'epoch': 12.99}
{'loss': 0.0057, 'grad_norm': 5.738155841827393, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.0022594567853957415, 'loss_2': 0.003429412841796875, 'loss_3': -16.253799438476562, 'loss_4': 2.528474807739258, 'epoch': 13.0}
{'loss': 0.0229, 'grad_norm': 11.46366024017334, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.01907786726951599, 'loss_2': 0.003780364990234375, 'loss_3': -16.136695861816406, 'loss_4': 3.386033535003662, 'epoch': 13.01}
{'loss': 0.0185, 'grad_norm': 6.0160322189331055, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.0137491375207901, 'loss_2': 0.004791259765625, 'loss_3': -16.373620986938477, 'loss_4': 2.738781452178955, 'epoch': 13.01}
{'loss': 0.0108, 'grad_norm': 4.658122539520264, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.00907700601965189, 'loss_2': 0.00176239013671875, 'loss_3': -16.38324737548828, 'loss_4': 3.0692858695983887, 'epoch': 13.02}
{'loss': 0.0166, 'grad_norm': 5.162319183349609, 'learning_rate': 1.7e-05, 'loss_1': 0.0094138877466321, 'loss_2': 0.007171630859375, 'loss_3': -16.41157341003418, 'loss_4': 3.213353395462036, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 10:19:20,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:20,067 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:34<50:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:19:27,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01363113522529602, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006180316209793091, 'eval_loss_2': 0.00745081901550293, 'eval_loss_3': -18.267253875732422, 'eval_loss_4': 2.926621913909912, 'epoch': 13.02}
{'loss': 0.0226, 'grad_norm': 10.390593528747559, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.020333094522356987, 'loss_2': 0.002315521240234375, 'loss_3': -16.54399871826172, 'loss_4': 3.2419819831848145, 'epoch': 13.03}
{'loss': 0.0211, 'grad_norm': 5.672548770904541, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.01276937872171402, 'loss_2': 0.00830078125, 'loss_3': -16.370559692382812, 'loss_4': 3.200270891189575, 'epoch': 13.03}
{'loss': 0.0174, 'grad_norm': 7.47116756439209, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.011520693078637123, 'loss_2': 0.00583648681640625, 'loss_3': -16.42275047302246, 'loss_4': 3.872896671295166, 'epoch': 13.04}
{'loss': 0.0152, 'grad_norm': 6.39929723739624, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.009961633943021297, 'loss_2': 0.005275726318359375, 'loss_3': -16.379507064819336, 'loss_4': 2.2146544456481934, 'epoch': 13.05}
{'loss': 0.0223, 'grad_norm': 6.033586025238037, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.013202753849327564, 'loss_2': 0.0090484619140625, 'loss_3': -16.269752502441406, 'loss_4': 3.1173272132873535, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 10:19:27,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:27,407 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:41<50:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:34,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010814256966114044, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006967759691178799, 'eval_loss_2': 0.003846496343612671, 'eval_loss_3': -18.274084091186523, 'eval_loss_4': 2.8866095542907715, 'epoch': 13.05}
{'loss': 0.0212, 'grad_norm': 6.624728202819824, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.013636919669806957, 'loss_2': 0.007598876953125, 'loss_3': -16.145065307617188, 'loss_4': 3.067586660385132, 'epoch': 13.06}
{'loss': 0.0112, 'grad_norm': 5.582167148590088, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.009537752717733383, 'loss_2': 0.001617431640625, 'loss_3': -16.36107063293457, 'loss_4': 3.198935031890869, 'epoch': 13.06}
{'loss': 0.0107, 'grad_norm': 5.013787746429443, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.006386729422956705, 'loss_2': 0.00428009033203125, 'loss_3': -16.406564712524414, 'loss_4': 2.7039639949798584, 'epoch': 13.07}
{'loss': 0.0121, 'grad_norm': 6.251628398895264, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.011995583772659302, 'loss_2': 6.622076034545898e-05, 'loss_3': -16.388151168823242, 'loss_4': 3.4463484287261963, 'epoch': 13.08}
{'loss': 0.0156, 'grad_norm': 5.017995357513428, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.006493168883025646, 'loss_2': 0.00914764404296875, 'loss_3': -16.16126251220703, 'loss_4': 3.4089622497558594, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 10:19:34,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:34,745 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:49<50:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:42,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012865755707025528, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007367026060819626, 'eval_loss_2': 0.005498729646205902, 'eval_loss_3': -18.271404266357422, 'eval_loss_4': 2.7989320755004883, 'epoch': 13.08}
{'loss': 0.0155, 'grad_norm': 6.992517471313477, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.009764798916876316, 'loss_2': 0.005725860595703125, 'loss_3': -16.25115203857422, 'loss_4': 3.0800068378448486, 'epoch': 13.09}
{'loss': 0.0165, 'grad_norm': 7.048253536224365, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.015627726912498474, 'loss_2': 0.0008783340454101562, 'loss_3': -16.229955673217773, 'loss_4': 3.861832857131958, 'epoch': 13.09}
{'loss': 0.0164, 'grad_norm': 4.653282642364502, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.006352557335048914, 'loss_2': 0.01004791259765625, 'loss_3': -16.314790725708008, 'loss_4': 3.4535484313964844, 'epoch': 13.1}
{'loss': 0.0158, 'grad_norm': 7.389447212219238, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.009804111905395985, 'loss_2': 0.0059814453125, 'loss_3': -16.290321350097656, 'loss_4': 3.9318032264709473, 'epoch': 13.1}
{'loss': 0.019, 'grad_norm': 6.240975379943848, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.014638147316873074, 'loss_2': 0.00434112548828125, 'loss_3': -16.26378631591797, 'loss_4': 3.949139356613159, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 10:19:42,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:42,086 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [55:56<50:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:49,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012814579531550407, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.148, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007504262030124664, 'eval_loss_2': 0.005310319364070892, 'eval_loss_3': -18.275005340576172, 'eval_loss_4': 2.7364420890808105, 'epoch': 13.11}
{'loss': 0.023, 'grad_norm': 9.028863906860352, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.02243739739060402, 'loss_2': 0.0006036758422851562, 'loss_3': -16.465349197387695, 'loss_4': 3.5444140434265137, 'epoch': 13.12}
{'loss': 0.0159, 'grad_norm': 6.693663597106934, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.008193492889404297, 'loss_2': 0.00775146484375, 'loss_3': -16.489091873168945, 'loss_4': 3.179349184036255, 'epoch': 13.12}
{'loss': 0.0114, 'grad_norm': 5.411107540130615, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.006347816437482834, 'loss_2': 0.005039215087890625, 'loss_3': -16.387414932250977, 'loss_4': 2.2360029220581055, 'epoch': 13.13}
{'loss': 0.0205, 'grad_norm': 6.414872646331787, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.017518149688839912, 'loss_2': 0.0029430389404296875, 'loss_3': -16.317466735839844, 'loss_4': 2.792311429977417, 'epoch': 13.13}
{'loss': 0.0078, 'grad_norm': 4.81682825088501, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.006260368041694164, 'loss_2': 0.00157928466796875, 'loss_3': -16.52345085144043, 'loss_4': 3.0387258529663086, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 10:19:49,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:49,434 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:03<50:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:19:56,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010026219300925732, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006765695754438639, 'eval_loss_2': 0.0032605230808258057, 'eval_loss_3': -18.277584075927734, 'eval_loss_4': 2.5727486610412598, 'epoch': 13.14}
{'loss': 0.0127, 'grad_norm': 5.92818021774292, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.008186951279640198, 'loss_2': 0.00452423095703125, 'loss_3': -16.473445892333984, 'loss_4': 2.898681163787842, 'epoch': 13.15}
{'loss': 0.0194, 'grad_norm': 8.298646926879883, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.016985520720481873, 'loss_2': 0.00241851806640625, 'loss_3': -16.446205139160156, 'loss_4': 3.80401873588562, 'epoch': 13.15}
{'loss': 0.0282, 'grad_norm': 6.507147789001465, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.01489474531263113, 'loss_2': 0.0133056640625, 'loss_3': -16.354690551757812, 'loss_4': 3.4214930534362793, 'epoch': 13.16}
{'loss': 0.0134, 'grad_norm': 6.764584064483643, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.012927990406751633, 'loss_2': 0.00046706199645996094, 'loss_3': -16.30736541748047, 'loss_4': 2.9699440002441406, 'epoch': 13.16}
{'loss': 0.0214, 'grad_norm': 6.029484272003174, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.013949854299426079, 'loss_2': 0.00745391845703125, 'loss_3': -16.26463508605957, 'loss_4': 3.059323310852051, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 10:19:56,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:19:56,785 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:11<50:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:04,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010350512340664864, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.464, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006254600360989571, 'eval_loss_2': 0.004095911979675293, 'eval_loss_3': -18.25992774963379, 'eval_loss_4': 2.5426814556121826, 'epoch': 13.17}
{'loss': 0.0353, 'grad_norm': 11.27632999420166, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.027777263894677162, 'loss_2': 0.00749969482421875, 'loss_3': -16.31987762451172, 'loss_4': 3.4379212856292725, 'epoch': 13.17}
{'loss': 0.0225, 'grad_norm': 8.59830093383789, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.01910889893770218, 'loss_2': 0.00335693359375, 'loss_3': -16.291093826293945, 'loss_4': 3.1316566467285156, 'epoch': 13.18}
{'loss': 0.0417, 'grad_norm': 8.665825843811035, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.0328802615404129, 'loss_2': 0.00879669189453125, 'loss_3': -16.463916778564453, 'loss_4': 3.012845993041992, 'epoch': 13.19}
{'loss': 0.0139, 'grad_norm': 4.825506687164307, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.007439706940203905, 'loss_2': 0.006504058837890625, 'loss_3': -16.511577606201172, 'loss_4': 2.6494216918945312, 'epoch': 13.19}
{'loss': 0.0219, 'grad_norm': 7.199792385101318, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.017534177750349045, 'loss_2': 0.0043182373046875, 'loss_3': -16.537151336669922, 'loss_4': 2.6623013019561768, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 10:20:04,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:04,142 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:18<49:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:11,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00994417816400528, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.784, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00654350221157074, 'eval_loss_2': 0.00340067595243454, 'eval_loss_3': -18.214946746826172, 'eval_loss_4': 2.4929561614990234, 'epoch': 13.2}
{'loss': 0.0224, 'grad_norm': 7.167476654052734, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.01624424010515213, 'loss_2': 0.00616455078125, 'loss_3': -16.346805572509766, 'loss_4': 3.295163631439209, 'epoch': 13.2}
{'loss': 0.0354, 'grad_norm': 10.16010856628418, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.029535729438066483, 'loss_2': 0.00589752197265625, 'loss_3': -16.47638702392578, 'loss_4': 3.251221179962158, 'epoch': 13.21}
{'loss': 0.0182, 'grad_norm': 5.367147445678711, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.015719998627901077, 'loss_2': 0.002483367919921875, 'loss_3': -16.358186721801758, 'loss_4': 2.5240437984466553, 'epoch': 13.22}
{'loss': 0.0292, 'grad_norm': 11.599580764770508, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.027317272499203682, 'loss_2': 0.0018768310546875, 'loss_3': -16.22635269165039, 'loss_4': 2.0930490493774414, 'epoch': 13.22}
{'loss': 0.0168, 'grad_norm': 6.372476577758789, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.014746494591236115, 'loss_2': 0.0020275115966796875, 'loss_3': -16.481029510498047, 'loss_4': 3.125718355178833, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 10:20:11,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:11,495 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:26<49:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:18,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01109958253800869, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00764734111726284, 'eval_loss_2': 0.0034522414207458496, 'eval_loss_3': -18.21917724609375, 'eval_loss_4': 2.4615869522094727, 'epoch': 13.23}
{'loss': 0.0182, 'grad_norm': 6.795522212982178, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.012990175746381283, 'loss_2': 0.00524139404296875, 'loss_3': -16.648426055908203, 'loss_4': 3.154477119445801, 'epoch': 13.23}
{'loss': 0.0209, 'grad_norm': 9.933089256286621, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.020103642717003822, 'loss_2': 0.0007963180541992188, 'loss_3': -16.317415237426758, 'loss_4': 3.0102624893188477, 'epoch': 13.24}
{'loss': 0.0309, 'grad_norm': 9.512349128723145, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.027959512546658516, 'loss_2': 0.002956390380859375, 'loss_3': -16.284992218017578, 'loss_4': 3.5251972675323486, 'epoch': 13.24}
{'loss': 0.0198, 'grad_norm': 14.34351634979248, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.015879608690738678, 'loss_2': 0.003902435302734375, 'loss_3': -16.37411880493164, 'loss_4': 2.6107301712036133, 'epoch': 13.25}
{'loss': 0.0101, 'grad_norm': 5.698819637298584, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.008588318713009357, 'loss_2': 0.0015316009521484375, 'loss_3': -16.245731353759766, 'loss_4': 3.055391788482666, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 10:20:18,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:18,846 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:33<49:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:26,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012585949152708054, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008466015569865704, 'eval_loss_2': 0.004119932651519775, 'eval_loss_3': -18.20680046081543, 'eval_loss_4': 2.700577735900879, 'epoch': 13.26}
{'loss': 0.0285, 'grad_norm': 17.487794876098633, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.027278736233711243, 'loss_2': 0.0012359619140625, 'loss_3': -16.354480743408203, 'loss_4': 2.705573320388794, 'epoch': 13.26}
{'loss': 0.0375, 'grad_norm': 16.874746322631836, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.03739115223288536, 'loss_2': 0.0001252889633178711, 'loss_3': -16.384654998779297, 'loss_4': 2.207923173904419, 'epoch': 13.27}
{'loss': 0.0303, 'grad_norm': 9.368886947631836, 'learning_rate': 1.675e-05, 'loss_1': 0.02661760151386261, 'loss_2': 0.0037059783935546875, 'loss_3': -16.405561447143555, 'loss_4': 3.2577080726623535, 'epoch': 13.27}
{'loss': 0.0101, 'grad_norm': 4.79900598526001, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.00908795464783907, 'loss_2': 0.0010423660278320312, 'loss_3': -16.476293563842773, 'loss_4': 2.3333868980407715, 'epoch': 13.28}
{'loss': 0.0332, 'grad_norm': 9.359238624572754, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.030632533133029938, 'loss_2': 0.00254058837890625, 'loss_3': -16.23202896118164, 'loss_4': 3.6200153827667236, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 10:20:26,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:26,188 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:40<49:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:33,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014489255845546722, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009701869450509548, 'eval_loss_2': 0.0047873854637146, 'eval_loss_3': -18.180349349975586, 'eval_loss_4': 2.903844118118286, 'epoch': 13.28}
{'loss': 0.016, 'grad_norm': 5.450336933135986, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.011728068813681602, 'loss_2': 0.00424957275390625, 'loss_3': -16.47955322265625, 'loss_4': 3.0298686027526855, 'epoch': 13.29}
{'loss': 0.0146, 'grad_norm': 8.508868217468262, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.014433691278100014, 'loss_2': 0.00019598007202148438, 'loss_3': -16.39804458618164, 'loss_4': 3.2632546424865723, 'epoch': 13.3}
{'loss': 0.0214, 'grad_norm': 7.01287317276001, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.019877055659890175, 'loss_2': 0.0015201568603515625, 'loss_3': -15.974992752075195, 'loss_4': 3.5174570083618164, 'epoch': 13.3}
{'loss': 0.0192, 'grad_norm': 8.24550724029541, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.014808416366577148, 'loss_2': 0.00438690185546875, 'loss_3': -16.34072494506836, 'loss_4': 3.127427577972412, 'epoch': 13.31}
{'loss': 0.0175, 'grad_norm': 5.987302780151367, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.010514832101762295, 'loss_2': 0.007015228271484375, 'loss_3': -16.46979522705078, 'loss_4': 3.815002918243408, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 10:20:33,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:33,536 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:48<49:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:40,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0131919514387846, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.394, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.00972522422671318, 'eval_loss_2': 0.0034667253494262695, 'eval_loss_3': -18.19133758544922, 'eval_loss_4': 3.049077033996582, 'epoch': 13.31}
{'loss': 0.0238, 'grad_norm': 8.186774253845215, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.021011188626289368, 'loss_2': 0.0027484893798828125, 'loss_3': -16.372406005859375, 'loss_4': 3.570711135864258, 'epoch': 13.32}
{'loss': 0.0152, 'grad_norm': 4.9100728034973145, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.009237761609256268, 'loss_2': 0.0059356689453125, 'loss_3': -16.383716583251953, 'loss_4': 3.833502769470215, 'epoch': 13.33}
{'loss': 0.0284, 'grad_norm': 7.59805154800415, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.023357268422842026, 'loss_2': 0.0050048828125, 'loss_3': -16.448293685913086, 'loss_4': 3.5426418781280518, 'epoch': 13.33}
{'loss': 0.0153, 'grad_norm': 4.776919364929199, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.0074806176126003265, 'loss_2': 0.0078125, 'loss_3': -16.443984985351562, 'loss_4': 3.1492905616760254, 'epoch': 13.34}
{'loss': 0.0255, 'grad_norm': 8.368252754211426, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.02055354043841362, 'loss_2': 0.004985809326171875, 'loss_3': -16.63199806213379, 'loss_4': 3.228950023651123, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 10:20:40,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:40,901 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [56:55<49:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:48,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015467382967472076, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009549180045723915, 'eval_loss_2': 0.0059182047843933105, 'eval_loss_3': -18.20136260986328, 'eval_loss_4': 2.748767852783203, 'epoch': 13.34}
{'loss': 0.0208, 'grad_norm': 7.5392680168151855, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.016581077128648758, 'loss_2': 0.004230499267578125, 'loss_3': -16.388254165649414, 'loss_4': 2.503180980682373, 'epoch': 13.35}
{'loss': 0.0194, 'grad_norm': 5.57605504989624, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.013407924212515354, 'loss_2': 0.00603485107421875, 'loss_3': -16.344255447387695, 'loss_4': 3.1456074714660645, 'epoch': 13.35}
{'loss': 0.0394, 'grad_norm': 11.133345603942871, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.02944415621459484, 'loss_2': 0.00994873046875, 'loss_3': -16.363115310668945, 'loss_4': 2.816462993621826, 'epoch': 13.36}
{'loss': 0.0089, 'grad_norm': 5.117634296417236, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.007997257634997368, 'loss_2': 0.0008835792541503906, 'loss_3': -16.61096954345703, 'loss_4': 2.621140480041504, 'epoch': 13.37}
{'loss': 0.039, 'grad_norm': 16.921295166015625, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.03240755572915077, 'loss_2': 0.006610870361328125, 'loss_3': -16.50956153869629, 'loss_4': 2.378695249557495, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 10:20:48,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:48,249 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:02<49:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:20:55,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013278096914291382, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009369611740112305, 'eval_loss_2': 0.003908485174179077, 'eval_loss_3': -18.222274780273438, 'eval_loss_4': 2.33357310295105, 'epoch': 13.37}
{'loss': 0.0155, 'grad_norm': 6.535347938537598, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.010772893205285072, 'loss_2': 0.0046844482421875, 'loss_3': -16.419023513793945, 'loss_4': 3.052966594696045, 'epoch': 13.38}
{'loss': 0.0311, 'grad_norm': 10.193567276000977, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.02629072032868862, 'loss_2': 0.0047607421875, 'loss_3': -16.374652862548828, 'loss_4': 3.161388635635376, 'epoch': 13.38}
{'loss': 0.0139, 'grad_norm': 5.956234455108643, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.010893885977566242, 'loss_2': 0.0030040740966796875, 'loss_3': -16.221187591552734, 'loss_4': 2.207317352294922, 'epoch': 13.39}
{'loss': 0.0216, 'grad_norm': 6.7907795906066895, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.015401382930576801, 'loss_2': 0.00617218017578125, 'loss_3': -16.392261505126953, 'loss_4': 3.002028226852417, 'epoch': 13.4}
{'loss': 0.0254, 'grad_norm': 6.498063087463379, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.014739591628313065, 'loss_2': 0.01070404052734375, 'loss_3': -16.50722885131836, 'loss_4': 2.6998913288116455, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 10:20:55,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:20:55,591 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:10<49:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:02,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016528375446796417, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.034, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009592182002961636, 'eval_loss_2': 0.006936192512512207, 'eval_loss_3': -18.259307861328125, 'eval_loss_4': 2.1443381309509277, 'epoch': 13.4}
{'loss': 0.017, 'grad_norm': 5.825640678405762, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.012935894541442394, 'loss_2': 0.0040740966796875, 'loss_3': -16.562103271484375, 'loss_4': 2.780191421508789, 'epoch': 13.41}
{'loss': 0.0378, 'grad_norm': 14.10309886932373, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.029984556138515472, 'loss_2': 0.0078582763671875, 'loss_3': -16.35356330871582, 'loss_4': 2.7374582290649414, 'epoch': 13.41}
{'loss': 0.0324, 'grad_norm': 9.684486389160156, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.02290142886340618, 'loss_2': 0.009490966796875, 'loss_3': -16.26127052307129, 'loss_4': 2.2765817642211914, 'epoch': 13.42}
{'loss': 0.0217, 'grad_norm': 6.398619174957275, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.015316933393478394, 'loss_2': 0.00640869140625, 'loss_3': -16.61245346069336, 'loss_4': 2.256972312927246, 'epoch': 13.42}
{'loss': 0.0204, 'grad_norm': 8.106221199035645, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.017486756667494774, 'loss_2': 0.0029201507568359375, 'loss_3': -16.30255889892578, 'loss_4': 2.8729827404022217, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 10:21:02,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:02,938 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:17<49:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:10,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014574318192899227, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.262, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010242998600006104, 'eval_loss_2': 0.004331320524215698, 'eval_loss_3': -18.313627243041992, 'eval_loss_4': 2.020075798034668, 'epoch': 13.43}
{'loss': 0.0185, 'grad_norm': 5.884334087371826, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.013369318097829819, 'loss_2': 0.005126953125, 'loss_3': -16.507797241210938, 'loss_4': 2.6941287517547607, 'epoch': 13.44}
{'loss': 0.0146, 'grad_norm': 6.272339820861816, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.013514243997633457, 'loss_2': 0.0010499954223632812, 'loss_3': -16.454326629638672, 'loss_4': 2.588843822479248, 'epoch': 13.44}
{'loss': 0.0142, 'grad_norm': 5.0405073165893555, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.010662106797099113, 'loss_2': 0.0034885406494140625, 'loss_3': -16.528581619262695, 'loss_4': 1.9948790073394775, 'epoch': 13.45}
{'loss': 0.0287, 'grad_norm': 7.242741584777832, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.020844068378210068, 'loss_2': 0.007904052734375, 'loss_3': -16.456470489501953, 'loss_4': 3.251588821411133, 'epoch': 13.45}
{'loss': 0.0204, 'grad_norm': 7.0879926681518555, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.01927627995610237, 'loss_2': 0.00109100341796875, 'loss_3': -16.4788818359375, 'loss_4': 2.6604623794555664, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 10:21:10,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:10,277 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:24<49:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:17,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012612566351890564, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009739980101585388, 'eval_loss_2': 0.0028725862503051758, 'eval_loss_3': -18.33326530456543, 'eval_loss_4': 2.082305908203125, 'epoch': 13.46}
{'loss': 0.0276, 'grad_norm': 10.968859672546387, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.024123135954141617, 'loss_2': 0.003513336181640625, 'loss_3': -16.46848487854004, 'loss_4': 2.32541561126709, 'epoch': 13.47}
{'loss': 0.0165, 'grad_norm': 6.9862895011901855, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.013032975606620312, 'loss_2': 0.003421783447265625, 'loss_3': -16.431028366088867, 'loss_4': 2.4134702682495117, 'epoch': 13.47}
{'loss': 0.0206, 'grad_norm': 7.124053955078125, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.01722857914865017, 'loss_2': 0.003383636474609375, 'loss_3': -16.49676513671875, 'loss_4': 2.1536426544189453, 'epoch': 13.48}
{'loss': 0.0166, 'grad_norm': 4.963916778564453, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.011443953961133957, 'loss_2': 0.00511932373046875, 'loss_3': -16.778392791748047, 'loss_4': 2.1790125370025635, 'epoch': 13.48}
{'loss': 0.0226, 'grad_norm': 9.642058372497559, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.015094554051756859, 'loss_2': 0.0074920654296875, 'loss_3': -16.474170684814453, 'loss_4': 2.3972482681274414, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 10:21:17,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:17,618 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:32<49:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:24,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012998750433325768, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.31, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.009558937512338161, 'eval_loss_2': 0.0034398138523101807, 'eval_loss_3': -18.33344078063965, 'eval_loss_4': 2.1092050075531006, 'epoch': 13.49}
{'loss': 0.0151, 'grad_norm': 6.594560623168945, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.01254692766815424, 'loss_2': 0.002544403076171875, 'loss_3': -16.448808670043945, 'loss_4': 3.0475375652313232, 'epoch': 13.49}
{'loss': 0.014, 'grad_norm': 4.981625556945801, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.010871868580579758, 'loss_2': 0.003139495849609375, 'loss_3': -16.43890380859375, 'loss_4': 2.5517196655273438, 'epoch': 13.5}
{'loss': 0.0116, 'grad_norm': 5.1950154304504395, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.009493199177086353, 'loss_2': 0.0020904541015625, 'loss_3': -16.439058303833008, 'loss_4': 2.756148099899292, 'epoch': 13.51}
{'loss': 0.0193, 'grad_norm': 6.51380729675293, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.017897265031933784, 'loss_2': 0.001399993896484375, 'loss_3': -16.423004150390625, 'loss_4': 2.7474284172058105, 'epoch': 13.51}
{'loss': 0.0239, 'grad_norm': 7.605715274810791, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.019421234726905823, 'loss_2': 0.0044708251953125, 'loss_3': -16.539522171020508, 'loss_4': 2.4664642810821533, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 10:21:24,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:24,972 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:39<48:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:32,317 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013367353938519955, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.855, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009682005271315575, 'eval_loss_2': 0.0036853477358818054, 'eval_loss_3': -18.333227157592773, 'eval_loss_4': 2.2223963737487793, 'epoch': 13.52}
{'loss': 0.0108, 'grad_norm': 5.0454020500183105, 'learning_rate': 1.65e-05, 'loss_1': 0.009577324613928795, 'loss_2': 0.0011739730834960938, 'loss_3': -16.519058227539062, 'loss_4': 2.5930423736572266, 'epoch': 13.52}
{'loss': 0.031, 'grad_norm': 7.856444358825684, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.020555704832077026, 'loss_2': 0.01049041748046875, 'loss_3': -16.022903442382812, 'loss_4': 2.2414722442626953, 'epoch': 13.53}
{'loss': 0.0158, 'grad_norm': 5.54373836517334, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.009112770669162273, 'loss_2': 0.00667572021484375, 'loss_3': -16.611125946044922, 'loss_4': 2.588599681854248, 'epoch': 13.53}
{'loss': 0.0248, 'grad_norm': 5.950705051422119, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.014794886112213135, 'loss_2': 0.0100250244140625, 'loss_3': -16.51809310913086, 'loss_4': 2.8541622161865234, 'epoch': 13.54}
{'loss': 0.0175, 'grad_norm': 7.2185258865356445, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.012270287610590458, 'loss_2': 0.005199432373046875, 'loss_3': -16.589319229125977, 'loss_4': 2.052537441253662, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 10:21:32,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:32,317 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:46<48:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:39,669 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014954967424273491, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.015, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010001106187701225, 'eval_loss_2': 0.004953861236572266, 'eval_loss_3': -18.323570251464844, 'eval_loss_4': 2.096405267715454, 'epoch': 13.55}
{'loss': 0.0148, 'grad_norm': 4.4911675453186035, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.0068387119099497795, 'loss_2': 0.00798797607421875, 'loss_3': -16.352828979492188, 'loss_4': 2.306194543838501, 'epoch': 13.55}
{'loss': 0.022, 'grad_norm': 6.315945625305176, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.013411293737590313, 'loss_2': 0.0085601806640625, 'loss_3': -16.337116241455078, 'loss_4': 2.751460075378418, 'epoch': 13.56}
{'loss': 0.0233, 'grad_norm': 7.693993091583252, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.020549001172184944, 'loss_2': 0.0027103424072265625, 'loss_3': -16.56658935546875, 'loss_4': 2.837533712387085, 'epoch': 13.56}
{'loss': 0.0125, 'grad_norm': 5.824002742767334, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.011285098269581795, 'loss_2': 0.0012035369873046875, 'loss_3': -16.386653900146484, 'loss_4': 2.8026442527770996, 'epoch': 13.57}
{'loss': 0.0112, 'grad_norm': 6.735560894012451, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.010607282631099224, 'loss_2': 0.0005998611450195312, 'loss_3': -16.42989730834961, 'loss_4': 2.3786871433258057, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 10:21:39,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:39,669 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [57:54<48:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:47,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01521079521626234, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.777, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00996526051312685, 'eval_loss_2': 0.00524553656578064, 'eval_loss_3': -18.321313858032227, 'eval_loss_4': 2.0776143074035645, 'epoch': 13.58}
{'loss': 0.0229, 'grad_norm': 10.052812576293945, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.021724343299865723, 'loss_2': 0.0011796951293945312, 'loss_3': -16.410377502441406, 'loss_4': 1.8558869361877441, 'epoch': 13.58}
{'loss': 0.0168, 'grad_norm': 5.637753963470459, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.012917714193463326, 'loss_2': 0.0038394927978515625, 'loss_3': -16.36371421813965, 'loss_4': 2.261847496032715, 'epoch': 13.59}
{'loss': 0.0202, 'grad_norm': 6.039087295532227, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.01079593226313591, 'loss_2': 0.0093841552734375, 'loss_3': -16.488929748535156, 'loss_4': 2.350642442703247, 'epoch': 13.59}
{'loss': 0.0325, 'grad_norm': 6.240748882293701, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.016841528937220573, 'loss_2': 0.015655517578125, 'loss_3': -16.564762115478516, 'loss_4': 2.7673556804656982, 'epoch': 13.6}
{'loss': 0.0209, 'grad_norm': 5.996572017669678, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.011710116639733315, 'loss_2': 0.00920867919921875, 'loss_3': -16.406267166137695, 'loss_4': 2.7735674381256104, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 10:21:47,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:47,023 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:01<48:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:21:54,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02030264399945736, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009593773633241653, 'eval_loss_2': 0.010708868503570557, 'eval_loss_3': -18.2923641204834, 'eval_loss_4': 1.9941279888153076, 'epoch': 13.6}
{'loss': 0.0268, 'grad_norm': 8.895892143249512, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.014844296500086784, 'loss_2': 0.011932373046875, 'loss_3': -16.190013885498047, 'loss_4': 2.705869436264038, 'epoch': 13.61}
{'loss': 0.0147, 'grad_norm': 5.5101213455200195, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.009070244617760181, 'loss_2': 0.005596160888671875, 'loss_3': -16.5174617767334, 'loss_4': 2.5380759239196777, 'epoch': 13.62}
{'loss': 0.0126, 'grad_norm': 4.610316753387451, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.009558661840856075, 'loss_2': 0.003078460693359375, 'loss_3': -16.41514015197754, 'loss_4': 1.315980076789856, 'epoch': 13.62}
{'loss': 0.0257, 'grad_norm': 6.895725250244141, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.021176176145672798, 'loss_2': 0.004486083984375, 'loss_3': -16.42478370666504, 'loss_4': 1.3319487571716309, 'epoch': 13.63}
{'loss': 0.0179, 'grad_norm': 6.747089385986328, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.013190542347729206, 'loss_2': 0.00469970703125, 'loss_3': -16.469196319580078, 'loss_4': 1.967242956161499, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 10:21:54,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:21:54,360 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:08<48:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:01,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014325329102575779, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.484, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00985446572303772, 'eval_loss_2': 0.004470862448215485, 'eval_loss_3': -18.28311538696289, 'eval_loss_4': 1.7614333629608154, 'epoch': 13.63}
{'loss': 0.0097, 'grad_norm': 4.490722179412842, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.005681673530489206, 'loss_2': 0.0040130615234375, 'loss_3': -16.381479263305664, 'loss_4': 2.67764949798584, 'epoch': 13.64}
{'loss': 0.0068, 'grad_norm': 4.793810844421387, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.005365325137972832, 'loss_2': 0.00145721435546875, 'loss_3': -16.431400299072266, 'loss_4': 2.101088047027588, 'epoch': 13.65}
{'loss': 0.0161, 'grad_norm': 5.220125675201416, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.010003149509429932, 'loss_2': 0.00611114501953125, 'loss_3': -16.38311195373535, 'loss_4': 1.7646355628967285, 'epoch': 13.65}
{'loss': 0.0202, 'grad_norm': 10.62585163116455, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.016998089849948883, 'loss_2': 0.0031585693359375, 'loss_3': -16.29187774658203, 'loss_4': 2.0017261505126953, 'epoch': 13.66}
{'loss': 0.028, 'grad_norm': 10.13830280303955, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.021382523700594902, 'loss_2': 0.006572723388671875, 'loss_3': -16.27937889099121, 'loss_4': 1.8088181018829346, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 10:22:01,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:01,716 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:16<48:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:09,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014207862317562103, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.643, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009816311299800873, 'eval_loss_2': 0.0043915510177612305, 'eval_loss_3': -18.287588119506836, 'eval_loss_4': 1.4289847612380981, 'epoch': 13.66}
{'loss': 0.0104, 'grad_norm': 4.671032905578613, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.008640455082058907, 'loss_2': 0.0017490386962890625, 'loss_3': -16.370237350463867, 'loss_4': 1.9388175010681152, 'epoch': 13.67}
{'loss': 0.0284, 'grad_norm': 12.950167655944824, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.020920876413583755, 'loss_2': 0.0074920654296875, 'loss_3': -16.544315338134766, 'loss_4': 1.51051926612854, 'epoch': 13.67}
{'loss': 0.0269, 'grad_norm': 9.340538024902344, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.02062218450009823, 'loss_2': 0.006313323974609375, 'loss_3': -16.32811737060547, 'loss_4': 1.5991346836090088, 'epoch': 13.68}
{'loss': 0.0069, 'grad_norm': 5.5279693603515625, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.006786997430026531, 'loss_2': 0.0001004934310913086, 'loss_3': -16.442768096923828, 'loss_4': 1.3630293607711792, 'epoch': 13.69}
{'loss': 0.0128, 'grad_norm': 5.121336936950684, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.007475567050278187, 'loss_2': 0.00537109375, 'loss_3': -16.235883712768555, 'loss_4': 1.5341581106185913, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 10:22:09,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:09,065 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:23<48:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:16,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015804346650838852, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008962673135101795, 'eval_loss_2': 0.006841674447059631, 'eval_loss_3': -18.262113571166992, 'eval_loss_4': 1.0707149505615234, 'epoch': 13.69}
{'loss': 0.0192, 'grad_norm': 5.611837863922119, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.009985248558223248, 'loss_2': 0.00921630859375, 'loss_3': -16.492584228515625, 'loss_4': 1.6372779607772827, 'epoch': 13.7}
{'loss': 0.0073, 'grad_norm': 4.498291969299316, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.003244826104491949, 'loss_2': 0.004093170166015625, 'loss_3': -16.329591751098633, 'loss_4': 1.2298462390899658, 'epoch': 13.7}
{'loss': 0.0123, 'grad_norm': 5.038628101348877, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.006068876013159752, 'loss_2': 0.00626373291015625, 'loss_3': -16.34821319580078, 'loss_4': 1.3100908994674683, 'epoch': 13.71}
{'loss': 0.0199, 'grad_norm': 5.352588653564453, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.01788858324289322, 'loss_2': 0.0020122528076171875, 'loss_3': -16.5693302154541, 'loss_4': 1.301677942276001, 'epoch': 13.72}
{'loss': 0.0117, 'grad_norm': 5.434930324554443, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.00809746515005827, 'loss_2': 0.00362396240234375, 'loss_3': -16.459354400634766, 'loss_4': 1.5155386924743652, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 10:22:16,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:16,408 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:30<48:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:23,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012810745276510715, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.883, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009998769499361515, 'eval_loss_2': 0.0028119757771492004, 'eval_loss_3': -18.23380470275879, 'eval_loss_4': 0.940038800239563, 'epoch': 13.72}
{'loss': 0.0146, 'grad_norm': 6.089702606201172, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.01334019098430872, 'loss_2': 0.001300811767578125, 'loss_3': -16.24488067626953, 'loss_4': 1.1444091796875, 'epoch': 13.73}
{'loss': 0.006, 'grad_norm': 4.250838279724121, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.004335049539804459, 'loss_2': 0.001621246337890625, 'loss_3': -16.4693603515625, 'loss_4': 1.3529322147369385, 'epoch': 13.73}
{'loss': 0.0115, 'grad_norm': 7.4121832847595215, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.010465609841048717, 'loss_2': 0.001071929931640625, 'loss_3': -16.33580780029297, 'loss_4': 0.49510639905929565, 'epoch': 13.74}
{'loss': 0.0124, 'grad_norm': 6.459084987640381, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.009907159954309464, 'loss_2': 0.0025272369384765625, 'loss_3': -16.285160064697266, 'loss_4': 0.8922152519226074, 'epoch': 13.74}
{'loss': 0.0243, 'grad_norm': 10.697821617126465, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.0236642025411129, 'loss_2': 0.0006618499755859375, 'loss_3': -16.414297103881836, 'loss_4': 1.0219426155090332, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 10:22:23,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:23,760 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:38<48:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:31,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015568562783300877, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011012977920472622, 'eval_loss_2': 0.0045555830001831055, 'eval_loss_3': -18.233497619628906, 'eval_loss_4': 0.940460205078125, 'epoch': 13.75}
{'loss': 0.0065, 'grad_norm': 4.744410991668701, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.005649958737194538, 'loss_2': 0.0008001327514648438, 'loss_3': -16.3848819732666, 'loss_4': 0.547747015953064, 'epoch': 13.76}
{'loss': 0.0104, 'grad_norm': 5.587093830108643, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.007772219367325306, 'loss_2': 0.00261688232421875, 'loss_3': -16.071842193603516, 'loss_4': 1.5533976554870605, 'epoch': 13.76}
{'loss': 0.0111, 'grad_norm': 5.281903266906738, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.00986641924828291, 'loss_2': 0.0011997222900390625, 'loss_3': -16.323780059814453, 'loss_4': 1.490668773651123, 'epoch': 13.77}
{'loss': 0.0182, 'grad_norm': 6.615002632141113, 'learning_rate': 1.625e-05, 'loss_1': 0.01582450419664383, 'loss_2': 0.002399444580078125, 'loss_3': -16.184558868408203, 'loss_4': 1.1448363065719604, 'epoch': 13.77}
{'loss': 0.0305, 'grad_norm': 11.035602569580078, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.027068613097071648, 'loss_2': 0.003421783447265625, 'loss_3': -16.463943481445312, 'loss_4': 0.7880522012710571, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 10:22:31,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:31,106 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:45<48:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:38,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020106453448534012, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012312670238316059, 'eval_loss_2': 0.007793784141540527, 'eval_loss_3': -18.23080062866211, 'eval_loss_4': 0.9108012914657593, 'epoch': 13.78}
{'loss': 0.0175, 'grad_norm': 6.764301776885986, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.008906693197786808, 'loss_2': 0.008636474609375, 'loss_3': -16.416061401367188, 'loss_4': 0.9753366708755493, 'epoch': 13.78}
{'loss': 0.017, 'grad_norm': 5.13687801361084, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.009699331596493721, 'loss_2': 0.007320404052734375, 'loss_3': -16.30657958984375, 'loss_4': 2.0895721912384033, 'epoch': 13.79}
{'loss': 0.0151, 'grad_norm': 5.166006565093994, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.007356141693890095, 'loss_2': 0.00774383544921875, 'loss_3': -16.286476135253906, 'loss_4': 1.3090224266052246, 'epoch': 13.8}
{'loss': 0.0131, 'grad_norm': 6.73330020904541, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.01287853717803955, 'loss_2': 0.000225067138671875, 'loss_3': -16.36416244506836, 'loss_4': -0.15544366836547852, 'epoch': 13.8}
{'loss': 0.0115, 'grad_norm': 7.174808502197266, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.008371833711862564, 'loss_2': 0.0030879974365234375, 'loss_3': -16.441530227661133, 'loss_4': 1.2369269132614136, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 10:22:38,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:38,445 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [58:53<48:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:45,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014811499044299126, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.408, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011667104437947273, 'eval_loss_2': 0.0031443946063518524, 'eval_loss_3': -18.23801040649414, 'eval_loss_4': 1.1147353649139404, 'epoch': 13.81}
{'loss': 0.0103, 'grad_norm': 5.008148193359375, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.005211450159549713, 'loss_2': 0.005126953125, 'loss_3': -16.323686599731445, 'loss_4': 1.4061038494110107, 'epoch': 13.81}
{'loss': 0.0167, 'grad_norm': 7.853909492492676, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.015455891378223896, 'loss_2': 0.0012340545654296875, 'loss_3': -16.41720199584961, 'loss_4': 1.3419798612594604, 'epoch': 13.82}
{'loss': 0.0132, 'grad_norm': 8.727988243103027, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.01154895406216383, 'loss_2': 0.0016994476318359375, 'loss_3': -16.237892150878906, 'loss_4': 1.3842614889144897, 'epoch': 13.83}
{'loss': 0.0219, 'grad_norm': 6.6032490730285645, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.013414238579571247, 'loss_2': 0.00848388671875, 'loss_3': -16.437599182128906, 'loss_4': 1.2485616207122803, 'epoch': 13.83}
{'loss': 0.0195, 'grad_norm': 4.70355749130249, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.011769360862672329, 'loss_2': 0.0077362060546875, 'loss_3': -16.454055786132812, 'loss_4': 1.420111894607544, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 10:22:45,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:45,804 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:00<47:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:22:53,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015538988634943962, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011016899719834328, 'eval_loss_2': 0.004522088915109634, 'eval_loss_3': -18.246740341186523, 'eval_loss_4': 1.3038040399551392, 'epoch': 13.84}
{'loss': 0.0337, 'grad_norm': 19.09535789489746, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.03092447854578495, 'loss_2': 0.002765655517578125, 'loss_3': -16.438541412353516, 'loss_4': 1.9502969980239868, 'epoch': 13.84}
{'loss': 0.0184, 'grad_norm': 5.292422294616699, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.010831806808710098, 'loss_2': 0.00760650634765625, 'loss_3': -16.500871658325195, 'loss_4': 1.5724296569824219, 'epoch': 13.85}
{'loss': 0.024, 'grad_norm': 5.89962100982666, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.017667032778263092, 'loss_2': 0.0063629150390625, 'loss_3': -16.54303741455078, 'loss_4': 2.168025493621826, 'epoch': 13.85}
{'loss': 0.027, 'grad_norm': 7.551027297973633, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.015391126275062561, 'loss_2': 0.0115966796875, 'loss_3': -16.37619400024414, 'loss_4': 1.3656973838806152, 'epoch': 13.86}
{'loss': 0.0082, 'grad_norm': 4.740482807159424, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.005823259707540274, 'loss_2': 0.002361297607421875, 'loss_3': -16.332788467407227, 'loss_4': 1.51177978515625, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 10:22:53,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:22:53,148 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:07<48:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:23:00,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013210228644311428, 'eval_runtime': 3.999, 'eval_samples_per_second': 256.065, 'eval_steps_per_second': 4.001, 'eval_loss_1': 0.010075485333800316, 'eval_loss_2': 0.0031347423791885376, 'eval_loss_3': -18.26331329345703, 'eval_loss_4': 1.3636438846588135, 'epoch': 13.87}
{'loss': 0.0249, 'grad_norm': 6.956383228302002, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.023560650646686554, 'loss_2': 0.0013380050659179688, 'loss_3': -16.38717269897461, 'loss_4': 1.0962941646575928, 'epoch': 13.87}
{'loss': 0.0363, 'grad_norm': 9.230913162231445, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.03067067638039589, 'loss_2': 0.0056610107421875, 'loss_3': -16.359840393066406, 'loss_4': 1.1253776550292969, 'epoch': 13.88}
{'loss': 0.0123, 'grad_norm': 5.637392044067383, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.00782789010554552, 'loss_2': 0.004444122314453125, 'loss_3': -16.478851318359375, 'loss_4': 1.8725097179412842, 'epoch': 13.88}
{'loss': 0.0299, 'grad_norm': 13.06372356414795, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.024212835356593132, 'loss_2': 0.005641937255859375, 'loss_3': -16.473915100097656, 'loss_4': 1.431898593902588, 'epoch': 13.89}
{'loss': 0.0143, 'grad_norm': 5.155673980712891, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.013227604329586029, 'loss_2': 0.00110626220703125, 'loss_3': -16.542373657226562, 'loss_4': 1.4384154081344604, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 10:23:00,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:00,681 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:15<47:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:08,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015334383584558964, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.99, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010871886275708675, 'eval_loss_2': 0.004462495446205139, 'eval_loss_3': -18.242765426635742, 'eval_loss_4': 1.3915644884109497, 'epoch': 13.9}
{'loss': 0.0269, 'grad_norm': 8.414971351623535, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.021855486556887627, 'loss_2': 0.00506591796875, 'loss_3': -16.427064895629883, 'loss_4': 0.9150801301002502, 'epoch': 13.9}
{'loss': 0.0263, 'grad_norm': 6.49202299118042, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.024709749966859818, 'loss_2': 0.0015773773193359375, 'loss_3': -16.73419761657715, 'loss_4': 1.1789186000823975, 'epoch': 13.91}
{'loss': 0.009, 'grad_norm': 4.357791900634766, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.005624174606055021, 'loss_2': 0.00341033935546875, 'loss_3': -16.755165100097656, 'loss_4': 1.2947285175323486, 'epoch': 13.91}
{'loss': 0.0241, 'grad_norm': 8.621411323547363, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.022977054119110107, 'loss_2': 0.0011157989501953125, 'loss_3': -16.36669158935547, 'loss_4': 1.12710702419281, 'epoch': 13.92}
{'loss': 0.017, 'grad_norm': 5.377506256103516, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.01362276915460825, 'loss_2': 0.0033473968505859375, 'loss_3': -16.47336196899414, 'loss_4': 1.3130598068237305, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 10:23:08,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:08,023 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:22<47:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:15,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017531611025333405, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.041, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012220955453813076, 'eval_loss_2': 0.005310654640197754, 'eval_loss_3': -18.235002517700195, 'eval_loss_4': 1.1856625080108643, 'epoch': 13.92}
{'loss': 0.0101, 'grad_norm': 4.921009540557861, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.007427924778312445, 'loss_2': 0.002689361572265625, 'loss_3': -16.46100616455078, 'loss_4': 1.0168834924697876, 'epoch': 13.93}
{'loss': 0.0149, 'grad_norm': 5.742056846618652, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.013497328385710716, 'loss_2': 0.001415252685546875, 'loss_3': -16.586000442504883, 'loss_4': 1.198542594909668, 'epoch': 13.94}
{'loss': 0.0234, 'grad_norm': 12.8798246383667, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.019951360300183296, 'loss_2': 0.003437042236328125, 'loss_3': -16.276996612548828, 'loss_4': 0.5631252527236938, 'epoch': 13.94}
{'loss': 0.0212, 'grad_norm': 11.482860565185547, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.017332609742879868, 'loss_2': 0.0038299560546875, 'loss_3': -16.382408142089844, 'loss_4': 1.3457863330841064, 'epoch': 13.95}
{'loss': 0.0138, 'grad_norm': 5.285233497619629, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.008271649479866028, 'loss_2': 0.00557708740234375, 'loss_3': -16.50783920288086, 'loss_4': 0.7257093191146851, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 10:23:15,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:15,370 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:29<47:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:22,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019717857241630554, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.535, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.013659104704856873, 'eval_loss_2': 0.006058752536773682, 'eval_loss_3': -18.258403778076172, 'eval_loss_4': 0.8193208575248718, 'epoch': 13.95}
{'loss': 0.0178, 'grad_norm': 5.859485626220703, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.015355940908193588, 'loss_2': 0.0024871826171875, 'loss_3': -16.43134307861328, 'loss_4': 0.7801242470741272, 'epoch': 13.96}
{'loss': 0.0127, 'grad_norm': 5.239749431610107, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.008089275099337101, 'loss_2': 0.0045928955078125, 'loss_3': -16.541202545166016, 'loss_4': 1.104172706604004, 'epoch': 13.97}
{'loss': 0.0182, 'grad_norm': 7.459025859832764, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.015159531496465206, 'loss_2': 0.003047943115234375, 'loss_3': -16.214296340942383, 'loss_4': -0.07124301791191101, 'epoch': 13.97}
{'loss': 0.0074, 'grad_norm': 4.85800313949585, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.005980254150927067, 'loss_2': 0.0014209747314453125, 'loss_3': -16.55022430419922, 'loss_4': 0.7781169414520264, 'epoch': 13.98}
{'loss': 0.0208, 'grad_norm': 7.383233547210693, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.019963597878813744, 'loss_2': 0.000850677490234375, 'loss_3': -16.472789764404297, 'loss_4': 0.38236212730407715, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 10:23:22,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:22,728 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:36<45:40,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 10:23:29,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01835877262055874, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.2, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.013242430053651333, 'eval_loss_2': 0.0051163434982299805, 'eval_loss_3': -18.239280700683594, 'eval_loss_4': 0.7623577117919922, 'epoch': 13.98}
{'loss': 0.0272, 'grad_norm': 7.437383651733398, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.01582987979054451, 'loss_2': 0.01141357421875, 'loss_3': -16.502721786499023, 'loss_4': 0.8133454322814941, 'epoch': 13.99}
{'loss': 0.0502, 'grad_norm': 21.4132137298584, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.040301691740751266, 'loss_2': 0.0098724365234375, 'loss_3': -16.394954681396484, 'loss_4': 0.5351725220680237, 'epoch': 13.99}
{'loss': 0.0206, 'grad_norm': 6.86403751373291, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.007013327442109585, 'loss_2': 0.013580322265625, 'loss_3': -16.51685333251953, 'loss_4': 1.1531076431274414, 'epoch': 14.0}
{'loss': 0.0227, 'grad_norm': 7.673262119293213, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.01674771122634411, 'loss_2': 0.0059051513671875, 'loss_3': -16.63999366760254, 'loss_4': 0.7499732971191406, 'epoch': 14.01}
{'loss': 0.0263, 'grad_norm': 6.5032243728637695, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.01705070585012436, 'loss_2': 0.0092620849609375, 'loss_3': -16.559738159179688, 'loss_4': 0.6704368591308594, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 10:23:29,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:29,778 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:44<47:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:23:37,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02272750809788704, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01405074167996645, 'eval_loss_2': 0.008676767349243164, 'eval_loss_3': -18.216144561767578, 'eval_loss_4': 1.010985016822815, 'epoch': 14.01}
{'loss': 0.0185, 'grad_norm': 5.825244903564453, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.012699339538812637, 'loss_2': 0.0057525634765625, 'loss_3': -16.414962768554688, 'loss_4': 1.1719510555267334, 'epoch': 14.02}
{'loss': 0.0383, 'grad_norm': 10.03695297241211, 'learning_rate': 1.6e-05, 'loss_1': 0.028795555233955383, 'loss_2': 0.009552001953125, 'loss_3': -16.34654998779297, 'loss_4': 1.7725343704223633, 'epoch': 14.02}
{'loss': 0.0187, 'grad_norm': 6.1413044929504395, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.01141475047916174, 'loss_2': 0.0073089599609375, 'loss_3': -16.463319778442383, 'loss_4': 1.032065987586975, 'epoch': 14.03}
{'loss': 0.0252, 'grad_norm': 5.9338226318359375, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.017703335732221603, 'loss_2': 0.00749969482421875, 'loss_3': -16.315229415893555, 'loss_4': 1.4827401638031006, 'epoch': 14.03}
{'loss': 0.0217, 'grad_norm': 7.3656487464904785, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.01912868767976761, 'loss_2': 0.002620697021484375, 'loss_3': -16.474212646484375, 'loss_4': 1.4389015436172485, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 10:23:37,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:37,115 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:51<47:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:23:44,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01770196668803692, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013700421899557114, 'eval_loss_2': 0.004001542925834656, 'eval_loss_3': -18.20657730102539, 'eval_loss_4': 0.8473397493362427, 'epoch': 14.04}
{'loss': 0.0113, 'grad_norm': 4.850050449371338, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.007370804436504841, 'loss_2': 0.0038909912109375, 'loss_3': -16.461318969726562, 'loss_4': 0.8654839992523193, 'epoch': 14.05}
{'loss': 0.0182, 'grad_norm': 7.010342597961426, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.015210571698844433, 'loss_2': 0.003032684326171875, 'loss_3': -16.43775749206543, 'loss_4': 0.6559343338012695, 'epoch': 14.05}
{'loss': 0.0214, 'grad_norm': 9.789151191711426, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.020494870841503143, 'loss_2': 0.0008840560913085938, 'loss_3': -16.681642532348633, 'loss_4': 0.48168954253196716, 'epoch': 14.06}
{'loss': 0.0222, 'grad_norm': 10.962919235229492, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.019978925585746765, 'loss_2': 0.002231597900390625, 'loss_3': -16.48663902282715, 'loss_4': 1.2129921913146973, 'epoch': 14.06}
{'loss': 0.0456, 'grad_norm': 17.097484588623047, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.0330086313188076, 'loss_2': 0.012603759765625, 'loss_3': -16.400415420532227, 'loss_4': 0.5076307058334351, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 10:23:44,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:44,454 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 2425/5160 [59:59<47:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:51,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020072225481271744, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.08, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013065402396023273, 'eval_loss_2': 0.007006824016571045, 'eval_loss_3': -18.22480583190918, 'eval_loss_4': 0.7233258485794067, 'epoch': 14.07}
{'loss': 0.0321, 'grad_norm': 14.652656555175781, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.024109620600938797, 'loss_2': 0.0080108642578125, 'loss_3': -16.467052459716797, 'loss_4': 0.4170611500740051, 'epoch': 14.08}
{'loss': 0.0115, 'grad_norm': 5.021152019500732, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.0074559892527759075, 'loss_2': 0.00408935546875, 'loss_3': -16.559707641601562, 'loss_4': 0.7937915325164795, 'epoch': 14.08}
{'loss': 0.0214, 'grad_norm': 7.231435298919678, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.0188865028321743, 'loss_2': 0.00249481201171875, 'loss_3': -16.3633975982666, 'loss_4': 0.4709658920764923, 'epoch': 14.09}
{'loss': 0.0238, 'grad_norm': 6.91274881362915, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.014991523697972298, 'loss_2': 0.00876617431640625, 'loss_3': -16.461566925048828, 'loss_4': 0.5534067153930664, 'epoch': 14.09}
{'loss': 0.0154, 'grad_norm': 5.4103617668151855, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.011571155861020088, 'loss_2': 0.00386810302734375, 'loss_3': -16.528141021728516, 'loss_4': -0.08029888570308685, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 10:23:51,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:51,800 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:06<47:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:23:59,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01849650777876377, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01096844021230936, 'eval_loss_2': 0.007528066635131836, 'eval_loss_3': -18.240737915039062, 'eval_loss_4': 0.6593130230903625, 'epoch': 14.1}
{'loss': 0.0336, 'grad_norm': 12.922761917114258, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.02973802201449871, 'loss_2': 0.003833770751953125, 'loss_3': -16.300559997558594, 'loss_4': 1.0237418413162231, 'epoch': 14.1}
{'loss': 0.0398, 'grad_norm': 16.446521759033203, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.03141634911298752, 'loss_2': 0.00835418701171875, 'loss_3': -16.527097702026367, 'loss_4': 0.42733412981033325, 'epoch': 14.11}
{'loss': 0.0252, 'grad_norm': 7.6167473793029785, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.021739622578024864, 'loss_2': 0.0034637451171875, 'loss_3': -16.668289184570312, 'loss_4': 0.34166213870048523, 'epoch': 14.12}
{'loss': 0.0091, 'grad_norm': 4.676692962646484, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.00699564628303051, 'loss_2': 0.0020599365234375, 'loss_3': -16.480308532714844, 'loss_4': 1.096584439277649, 'epoch': 14.12}
{'loss': 0.0226, 'grad_norm': 7.400960445404053, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.013995680026710033, 'loss_2': 0.00859832763671875, 'loss_3': -16.46165657043457, 'loss_4': 0.15305936336517334, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 10:23:59,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:23:59,139 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:13<47:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:06,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015428828075528145, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.619, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011483103036880493, 'eval_loss_2': 0.0039457231760025024, 'eval_loss_3': -18.243450164794922, 'eval_loss_4': 0.5119057297706604, 'epoch': 14.13}
{'loss': 0.0187, 'grad_norm': 6.468373775482178, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.018638789653778076, 'loss_2': 8.976459503173828e-05, 'loss_3': -16.529003143310547, 'loss_4': 0.13689763844013214, 'epoch': 14.13}
{'loss': 0.0168, 'grad_norm': 7.2034077644348145, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.01658257283270359, 'loss_2': 0.00019431114196777344, 'loss_3': -16.47800636291504, 'loss_4': 0.9823887348175049, 'epoch': 14.14}
{'loss': 0.0192, 'grad_norm': 8.552995681762695, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.016854513436555862, 'loss_2': 0.0023345947265625, 'loss_3': -16.43726921081543, 'loss_4': 0.7985752820968628, 'epoch': 14.15}
{'loss': 0.0367, 'grad_norm': 8.705327033996582, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.03464837744832039, 'loss_2': 0.00208282470703125, 'loss_3': -16.526334762573242, 'loss_4': 0.9453777074813843, 'epoch': 14.15}
{'loss': 0.0196, 'grad_norm': 7.277358531951904, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.015499223954975605, 'loss_2': 0.00405120849609375, 'loss_3': -16.443496704101562, 'loss_4': 0.5258449912071228, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 10:24:06,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:06,487 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:21<47:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:13,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016876960173249245, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.924, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013332629576325417, 'eval_loss_2': 0.003544330596923828, 'eval_loss_3': -18.278026580810547, 'eval_loss_4': 0.4004361629486084, 'epoch': 14.16}
{'loss': 0.0092, 'grad_norm': 5.172872066497803, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.0074338894337415695, 'loss_2': 0.00177764892578125, 'loss_3': -16.4603271484375, 'loss_4': 1.1327428817749023, 'epoch': 14.16}
{'loss': 0.017, 'grad_norm': 7.218214511871338, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.0157199464738369, 'loss_2': 0.0012674331665039062, 'loss_3': -16.299301147460938, 'loss_4': 0.9445062875747681, 'epoch': 14.17}
{'loss': 0.0288, 'grad_norm': 8.917252540588379, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.02196189947426319, 'loss_2': 0.006805419921875, 'loss_3': -16.639982223510742, 'loss_4': 0.4170522093772888, 'epoch': 14.17}
{'loss': 0.0163, 'grad_norm': 6.335509777069092, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.01554050948470831, 'loss_2': 0.0007963180541992188, 'loss_3': -16.691017150878906, 'loss_4': 0.6157251596450806, 'epoch': 14.18}
{'loss': 0.0169, 'grad_norm': 10.51176929473877, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.01504861656576395, 'loss_2': 0.001827239990234375, 'loss_3': -16.41208839416504, 'loss_4': 0.9094959497451782, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 10:24:13,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:13,838 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:28<46:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:21,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017610561102628708, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011746923439204693, 'eval_loss_2': 0.00586363673210144, 'eval_loss_3': -18.278573989868164, 'eval_loss_4': 0.5404074192047119, 'epoch': 14.19}
{'loss': 0.0387, 'grad_norm': 12.047662734985352, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.032789114862680435, 'loss_2': 0.00592803955078125, 'loss_3': -16.58823585510254, 'loss_4': 0.22533366084098816, 'epoch': 14.19}
{'loss': 0.0218, 'grad_norm': 5.841799736022949, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.010616866871714592, 'loss_2': 0.01122283935546875, 'loss_3': -16.5426025390625, 'loss_4': 0.5981650352478027, 'epoch': 14.2}
{'loss': 0.0246, 'grad_norm': 9.86890697479248, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.02356717735528946, 'loss_2': 0.0009851455688476562, 'loss_3': -16.481735229492188, 'loss_4': 0.5845720171928406, 'epoch': 14.2}
{'loss': 0.0121, 'grad_norm': 5.446986198425293, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.010846517980098724, 'loss_2': 0.0012054443359375, 'loss_3': -16.464099884033203, 'loss_4': 1.8917243480682373, 'epoch': 14.21}
{'loss': 0.0207, 'grad_norm': 9.369573593139648, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.015840625390410423, 'loss_2': 0.00482940673828125, 'loss_3': -16.378023147583008, 'loss_4': 0.8761692643165588, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 10:24:21,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:21,182 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:35<46:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:28,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013661121018230915, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.002, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010772583074867725, 'eval_loss_2': 0.0028885379433631897, 'eval_loss_3': -18.272897720336914, 'eval_loss_4': 0.7605856657028198, 'epoch': 14.22}
{'loss': 0.0108, 'grad_norm': 4.7445855140686035, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.005967883393168449, 'loss_2': 0.004852294921875, 'loss_3': -16.676223754882812, 'loss_4': 1.6065313816070557, 'epoch': 14.22}
{'loss': 0.0155, 'grad_norm': 6.075680732727051, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.009185305796563625, 'loss_2': 0.006305694580078125, 'loss_3': -16.4832706451416, 'loss_4': 0.8263516426086426, 'epoch': 14.23}
{'loss': 0.0184, 'grad_norm': 7.128057479858398, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.01571340672671795, 'loss_2': 0.0026378631591796875, 'loss_3': -16.471527099609375, 'loss_4': 0.3295919895172119, 'epoch': 14.23}
{'loss': 0.0158, 'grad_norm': 5.176669120788574, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.011964221484959126, 'loss_2': 0.00383758544921875, 'loss_3': -16.55199432373047, 'loss_4': 1.188432216644287, 'epoch': 14.24}
{'loss': 0.0234, 'grad_norm': 9.785416603088379, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.018848732113838196, 'loss_2': 0.0045166015625, 'loss_3': -16.697582244873047, 'loss_4': 1.490319848060608, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 10:24:28,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:28,530 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:43<46:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:35,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01463300734758377, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011638721451163292, 'eval_loss_2': 0.0029942840337753296, 'eval_loss_3': -18.25661849975586, 'eval_loss_4': 1.1678235530853271, 'epoch': 14.24}
{'loss': 0.0188, 'grad_norm': 6.642838001251221, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.014418454840779305, 'loss_2': 0.0043792724609375, 'loss_3': -16.37627601623535, 'loss_4': 1.355635643005371, 'epoch': 14.25}
{'loss': 0.013, 'grad_norm': 4.9205851554870605, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.006360442377626896, 'loss_2': 0.00667572021484375, 'loss_3': -16.345294952392578, 'loss_4': 2.473242998123169, 'epoch': 14.26}
{'loss': 0.0198, 'grad_norm': 7.061380863189697, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.014604524709284306, 'loss_2': 0.00514984130859375, 'loss_3': -16.32342529296875, 'loss_4': 1.590188980102539, 'epoch': 14.26}
{'loss': 0.0069, 'grad_norm': 4.804304599761963, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.004736265633255243, 'loss_2': 0.002140045166015625, 'loss_3': -16.648500442504883, 'loss_4': 0.9434869289398193, 'epoch': 14.27}
{'loss': 0.009, 'grad_norm': 4.807492256164551, 'learning_rate': 1.575e-05, 'loss_1': 0.008797040209174156, 'loss_2': 0.0001742839813232422, 'loss_3': -16.319488525390625, 'loss_4': 1.1898767948150635, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 10:24:35,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:35,874 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:50<46:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:43,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01942533254623413, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.012, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013062418438494205, 'eval_loss_2': 0.0063629150390625, 'eval_loss_3': -18.259244918823242, 'eval_loss_4': 1.5248072147369385, 'epoch': 14.27}
{'loss': 0.0095, 'grad_norm': 4.655178546905518, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.006111257243901491, 'loss_2': 0.0034122467041015625, 'loss_3': -16.62654685974121, 'loss_4': 2.1486003398895264, 'epoch': 14.28}
{'loss': 0.0097, 'grad_norm': 5.102280139923096, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.008003435097634792, 'loss_2': 0.0016536712646484375, 'loss_3': -16.419719696044922, 'loss_4': 1.8515989780426025, 'epoch': 14.28}
{'loss': 0.0161, 'grad_norm': 5.312214374542236, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.00891847163438797, 'loss_2': 0.00714874267578125, 'loss_3': -16.536846160888672, 'loss_4': 2.158824920654297, 'epoch': 14.29}
{'loss': 0.0094, 'grad_norm': 4.335257053375244, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.005919580813497305, 'loss_2': 0.003437042236328125, 'loss_3': -16.42816925048828, 'loss_4': 1.7359517812728882, 'epoch': 14.3}
{'loss': 0.0099, 'grad_norm': 5.508971214294434, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.007749637588858604, 'loss_2': 0.002197265625, 'loss_3': -16.480823516845703, 'loss_4': 1.4947246313095093, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 10:24:43,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:43,229 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:00:57<46:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:50,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018838010728359222, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.616, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012950504198670387, 'eval_loss_2': 0.005887508392333984, 'eval_loss_3': -18.255308151245117, 'eval_loss_4': 1.7418549060821533, 'epoch': 14.3}
{'loss': 0.0245, 'grad_norm': 11.933551788330078, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.02428019791841507, 'loss_2': 0.00023555755615234375, 'loss_3': -16.53204917907715, 'loss_4': 1.492103099822998, 'epoch': 14.31}
{'loss': 0.0164, 'grad_norm': 5.039976119995117, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.008889847435057163, 'loss_2': 0.0074920654296875, 'loss_3': -16.665407180786133, 'loss_4': 2.567708730697632, 'epoch': 14.31}
{'loss': 0.0123, 'grad_norm': 5.090982913970947, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.009979932568967342, 'loss_2': 0.0023593902587890625, 'loss_3': -16.27571678161621, 'loss_4': 1.8276358842849731, 'epoch': 14.32}
{'loss': 0.0142, 'grad_norm': 5.174718379974365, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.007024787366390228, 'loss_2': 0.00713348388671875, 'loss_3': -16.415353775024414, 'loss_4': 2.253180980682373, 'epoch': 14.33}
{'loss': 0.0266, 'grad_norm': 7.079498291015625, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.02134791389107704, 'loss_2': 0.005252838134765625, 'loss_3': -16.283966064453125, 'loss_4': 2.3971071243286133, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 10:24:50,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:50,579 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:05<46:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:24:57,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014203852042555809, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.028, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011282254941761494, 'eval_loss_2': 0.0029215961694717407, 'eval_loss_3': -18.252513885498047, 'eval_loss_4': 1.9707400798797607, 'epoch': 14.33}
{'loss': 0.012, 'grad_norm': 4.699732780456543, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.00754005741328001, 'loss_2': 0.00447845458984375, 'loss_3': -16.504169464111328, 'loss_4': 2.2558252811431885, 'epoch': 14.34}
{'loss': 0.0078, 'grad_norm': 4.919478893280029, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.0046022552996873856, 'loss_2': 0.003215789794921875, 'loss_3': -16.498153686523438, 'loss_4': 3.0068705081939697, 'epoch': 14.34}
{'loss': 0.0147, 'grad_norm': 5.308298587799072, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.011531573720276356, 'loss_2': 0.003124237060546875, 'loss_3': -16.44438934326172, 'loss_4': 2.7299318313598633, 'epoch': 14.35}
{'loss': 0.0065, 'grad_norm': 4.558341979980469, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.0032810731790959835, 'loss_2': 0.0031833648681640625, 'loss_3': -16.51470947265625, 'loss_4': 2.680176258087158, 'epoch': 14.35}
{'loss': 0.0092, 'grad_norm': 4.851779937744141, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.006318951491266489, 'loss_2': 0.00287628173828125, 'loss_3': -16.447813034057617, 'loss_4': 2.819582462310791, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 10:24:57,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:24:57,928 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:12<46:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:05,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013637695461511612, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.726, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009878400713205338, 'eval_loss_2': 0.0037592947483062744, 'eval_loss_3': -18.25775146484375, 'eval_loss_4': 2.148662805557251, 'epoch': 14.36}
{'loss': 0.0095, 'grad_norm': 5.7553534507751465, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.00929415225982666, 'loss_2': 0.0002073049545288086, 'loss_3': -16.597667694091797, 'loss_4': 2.6329643726348877, 'epoch': 14.37}
{'loss': 0.0131, 'grad_norm': 6.129745006561279, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.01077707763761282, 'loss_2': 0.0023632049560546875, 'loss_3': -16.433212280273438, 'loss_4': 2.1275386810302734, 'epoch': 14.37}
{'loss': 0.0126, 'grad_norm': 5.414348125457764, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.012264952063560486, 'loss_2': 0.0002956390380859375, 'loss_3': -16.435199737548828, 'loss_4': 2.3482465744018555, 'epoch': 14.38}
{'loss': 0.0054, 'grad_norm': 5.230844020843506, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.005126532632857561, 'loss_2': 0.00030612945556640625, 'loss_3': -16.404756546020508, 'loss_4': 2.516129970550537, 'epoch': 14.38}
{'loss': 0.0262, 'grad_norm': 12.384840965270996, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.015087676234543324, 'loss_2': 0.01110076904296875, 'loss_3': -16.3834228515625, 'loss_4': 2.29042649269104, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 10:25:05,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:05,280 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:19<46:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:12,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01603030040860176, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009702194482088089, 'eval_loss_2': 0.006328105926513672, 'eval_loss_3': -18.26172637939453, 'eval_loss_4': 2.179685354232788, 'epoch': 14.39}
{'loss': 0.0154, 'grad_norm': 5.408688068389893, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.008603599853813648, 'loss_2': 0.006805419921875, 'loss_3': -16.567813873291016, 'loss_4': 2.805574893951416, 'epoch': 14.4}
{'loss': 0.0145, 'grad_norm': 4.631905555725098, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.005267628002911806, 'loss_2': 0.00927734375, 'loss_3': -16.462093353271484, 'loss_4': 2.4021174907684326, 'epoch': 14.4}
{'loss': 0.0204, 'grad_norm': 6.809493541717529, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.012809040024876595, 'loss_2': 0.007633209228515625, 'loss_3': -16.33454132080078, 'loss_4': 2.5170562267303467, 'epoch': 14.41}
{'loss': 0.0069, 'grad_norm': 4.465484142303467, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.004329866264015436, 'loss_2': 0.00258636474609375, 'loss_3': -16.63687515258789, 'loss_4': 2.3975830078125, 'epoch': 14.41}
{'loss': 0.0127, 'grad_norm': 5.470900058746338, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.010328317992389202, 'loss_2': 0.00234222412109375, 'loss_3': -16.320873260498047, 'loss_4': 2.358509063720703, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 10:25:12,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:12,629 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:27<46:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:19,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014239287003874779, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010088000446557999, 'eval_loss_2': 0.004151284694671631, 'eval_loss_3': -18.282346725463867, 'eval_loss_4': 1.985945463180542, 'epoch': 14.42}
{'loss': 0.0525, 'grad_norm': 13.53256607055664, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.04972086474299431, 'loss_2': 0.002777099609375, 'loss_3': -16.627962112426758, 'loss_4': 2.143801212310791, 'epoch': 14.42}
{'loss': 0.0239, 'grad_norm': 10.233169555664062, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.01769212819635868, 'loss_2': 0.00618743896484375, 'loss_3': -16.358318328857422, 'loss_4': 3.0526771545410156, 'epoch': 14.43}
{'loss': 0.0098, 'grad_norm': 5.013054370880127, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.0054610371589660645, 'loss_2': 0.00432586669921875, 'loss_3': -16.436134338378906, 'loss_4': 1.301505446434021, 'epoch': 14.44}
{'loss': 0.0343, 'grad_norm': 9.43730640411377, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.026448983699083328, 'loss_2': 0.0078887939453125, 'loss_3': -16.311182022094727, 'loss_4': 2.739537477493286, 'epoch': 14.44}
{'loss': 0.0124, 'grad_norm': 7.859384536743164, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.011765963397920132, 'loss_2': 0.000591278076171875, 'loss_3': -16.516572952270508, 'loss_4': 2.7761707305908203, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 10:25:19,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:19,979 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:34<46:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:27,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013372967019677162, 'eval_runtime': 3.8212, 'eval_samples_per_second': 267.979, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.00928253959864378, 'eval_loss_2': 0.004090428352355957, 'eval_loss_3': -18.291492462158203, 'eval_loss_4': 1.8200410604476929, 'epoch': 14.45}
{'loss': 0.0097, 'grad_norm': 5.527837753295898, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.007848081178963184, 'loss_2': 0.0018148422241210938, 'loss_3': -16.329296112060547, 'loss_4': 2.510267496109009, 'epoch': 14.45}
{'loss': 0.0418, 'grad_norm': 17.827722549438477, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.03800717741250992, 'loss_2': 0.00380706787109375, 'loss_3': -16.467735290527344, 'loss_4': 1.7366975545883179, 'epoch': 14.46}
{'loss': 0.0097, 'grad_norm': 4.567808628082275, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.004554114304482937, 'loss_2': 0.005115509033203125, 'loss_3': -16.456701278686523, 'loss_4': 1.8423444032669067, 'epoch': 14.47}
{'loss': 0.0209, 'grad_norm': 5.554904460906982, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.010902795940637589, 'loss_2': 0.0099945068359375, 'loss_3': -16.392925262451172, 'loss_4': 2.1666293144226074, 'epoch': 14.47}
{'loss': 0.0084, 'grad_norm': 4.944121360778809, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.007203931454569101, 'loss_2': 0.0011491775512695312, 'loss_3': -16.607707977294922, 'loss_4': 2.4960155487060547, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 10:25:27,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:27,346 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:41<46:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:34,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01289330143481493, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009726119227707386, 'eval_loss_2': 0.003167182207107544, 'eval_loss_3': -18.263551712036133, 'eval_loss_4': 1.717085838317871, 'epoch': 14.48}
{'loss': 0.0153, 'grad_norm': 5.988033294677734, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.008370959199965, 'loss_2': 0.0069580078125, 'loss_3': -16.256858825683594, 'loss_4': 2.224306106567383, 'epoch': 14.48}
{'loss': 0.0301, 'grad_norm': 6.021711349487305, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.0204452071338892, 'loss_2': 0.0096282958984375, 'loss_3': -16.449831008911133, 'loss_4': 2.1054487228393555, 'epoch': 14.49}
{'loss': 0.011, 'grad_norm': 4.934693336486816, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.0067995889112353325, 'loss_2': 0.00420379638671875, 'loss_3': -16.328479766845703, 'loss_4': 1.8020679950714111, 'epoch': 14.49}
{'loss': 0.0153, 'grad_norm': 5.319198131561279, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.009788192808628082, 'loss_2': 0.005550384521484375, 'loss_3': -16.45993423461914, 'loss_4': 1.7956689596176147, 'epoch': 14.5}
{'loss': 0.0159, 'grad_norm': 4.822782516479492, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.00613640621304512, 'loss_2': 0.0097198486328125, 'loss_3': -16.46927261352539, 'loss_4': 1.6206847429275513, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 10:25:34,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:34,691 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:49<45:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:42,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018036585301160812, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011091930791735649, 'eval_loss_2': 0.0069446563720703125, 'eval_loss_3': -18.284143447875977, 'eval_loss_4': 1.3192651271820068, 'epoch': 14.51}
{'loss': 0.0338, 'grad_norm': 7.3792405128479, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.020508766174316406, 'loss_2': 0.0133056640625, 'loss_3': -16.155826568603516, 'loss_4': 1.609576940536499, 'epoch': 14.51}
{'loss': 0.0149, 'grad_norm': 8.712872505187988, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.010276093147695065, 'loss_2': 0.004627227783203125, 'loss_3': -16.47345733642578, 'loss_4': 1.8548502922058105, 'epoch': 14.52}
{'loss': 0.0159, 'grad_norm': 5.0816731452941895, 'learning_rate': 1.55e-05, 'loss_1': 0.01004522480070591, 'loss_2': 0.005809783935546875, 'loss_3': -16.42964744567871, 'loss_4': 1.4878137111663818, 'epoch': 14.52}
{'loss': 0.0256, 'grad_norm': 10.78333568572998, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.022908784449100494, 'loss_2': 0.002712249755859375, 'loss_3': -16.484647750854492, 'loss_4': 1.1543021202087402, 'epoch': 14.53}
{'loss': 0.0096, 'grad_norm': 4.649525165557861, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.007872605696320534, 'loss_2': 0.0017261505126953125, 'loss_3': -16.590679168701172, 'loss_4': 1.2959318161010742, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 10:25:42,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:42,034 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:01:56<45:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:49,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574324257671833, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011900916695594788, 'eval_loss_2': 0.0038423240184783936, 'eval_loss_3': -18.288597106933594, 'eval_loss_4': 1.0699725151062012, 'epoch': 14.53}
{'loss': 0.0042, 'grad_norm': 4.489381313323975, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.004101868253201246, 'loss_2': 6.651878356933594e-05, 'loss_3': -16.60432243347168, 'loss_4': 0.37946704030036926, 'epoch': 14.54}
{'loss': 0.0175, 'grad_norm': 6.563610553741455, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.015702569857239723, 'loss_2': 0.001758575439453125, 'loss_3': -16.322898864746094, 'loss_4': 1.7534596920013428, 'epoch': 14.55}
{'loss': 0.0139, 'grad_norm': 8.796478271484375, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.012911816127598286, 'loss_2': 0.0009508132934570312, 'loss_3': -16.572168350219727, 'loss_4': 1.1990528106689453, 'epoch': 14.55}
{'loss': 0.0197, 'grad_norm': 14.56805419921875, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.01793631538748741, 'loss_2': 0.00171661376953125, 'loss_3': -16.441679000854492, 'loss_4': 1.3718016147613525, 'epoch': 14.56}
{'loss': 0.0163, 'grad_norm': 10.2157564163208, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.014811958186328411, 'loss_2': 0.0014438629150390625, 'loss_3': -16.620018005371094, 'loss_4': 1.7096996307373047, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 10:25:49,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:49,375 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:03<45:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:25:56,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01713189110159874, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013194901868700981, 'eval_loss_2': 0.003936991095542908, 'eval_loss_3': -18.29863739013672, 'eval_loss_4': 0.9623947739601135, 'epoch': 14.56}
{'loss': 0.0125, 'grad_norm': 4.7358622550964355, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.008267414756119251, 'loss_2': 0.004241943359375, 'loss_3': -16.67466163635254, 'loss_4': 0.9162417650222778, 'epoch': 14.57}
{'loss': 0.0228, 'grad_norm': 15.929242134094238, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.018189003691077232, 'loss_2': 0.00461578369140625, 'loss_3': -16.517330169677734, 'loss_4': 1.2771981954574585, 'epoch': 14.58}
{'loss': 0.0232, 'grad_norm': 8.363085746765137, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.015846529975533485, 'loss_2': 0.007381439208984375, 'loss_3': -16.416160583496094, 'loss_4': 1.0590994358062744, 'epoch': 14.58}
{'loss': 0.014, 'grad_norm': 5.107462406158447, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.008893237449228764, 'loss_2': 0.005096435546875, 'loss_3': -16.535383224487305, 'loss_4': 1.324151873588562, 'epoch': 14.59}
{'loss': 0.019, 'grad_norm': 6.614864826202393, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.014862703159451485, 'loss_2': 0.004119873046875, 'loss_3': -16.570938110351562, 'loss_4': 1.0171722173690796, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 10:25:56,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:25:56,715 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:11<45:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:04,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01759495958685875, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.062, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01273658499121666, 'eval_loss_2': 0.00485837459564209, 'eval_loss_3': -18.293359756469727, 'eval_loss_4': 0.9551147222518921, 'epoch': 14.59}
{'loss': 0.013, 'grad_norm': 5.829472541809082, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.01095900870859623, 'loss_2': 0.0020599365234375, 'loss_3': -16.684974670410156, 'loss_4': 1.4595459699630737, 'epoch': 14.6}
{'loss': 0.0159, 'grad_norm': 5.6819658279418945, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.012624343857169151, 'loss_2': 0.00322723388671875, 'loss_3': -16.45229721069336, 'loss_4': 0.7274499535560608, 'epoch': 14.6}
{'loss': 0.0351, 'grad_norm': 10.967869758605957, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.031234420835971832, 'loss_2': 0.00389862060546875, 'loss_3': -16.735240936279297, 'loss_4': 1.9825435876846313, 'epoch': 14.61}
{'loss': 0.0078, 'grad_norm': 4.781671047210693, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.0065900590270757675, 'loss_2': 0.0012187957763671875, 'loss_3': -16.5966739654541, 'loss_4': 0.9076790809631348, 'epoch': 14.62}
{'loss': 0.0084, 'grad_norm': 5.145954132080078, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.006040547508746386, 'loss_2': 0.002376556396484375, 'loss_3': -16.455718994140625, 'loss_4': 1.4757509231567383, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 10:26:04,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:04,068 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:18<45:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:11,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014748982153832912, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.525, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.010730765759944916, 'eval_loss_2': 0.004018217325210571, 'eval_loss_3': -18.294891357421875, 'eval_loss_4': 1.3684792518615723, 'epoch': 14.62}
{'loss': 0.0236, 'grad_norm': 5.778295040130615, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.012432792223989964, 'loss_2': 0.01114654541015625, 'loss_3': -16.53232765197754, 'loss_4': 2.014662742614746, 'epoch': 14.63}
{'loss': 0.0226, 'grad_norm': 6.5215606689453125, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.014366934075951576, 'loss_2': 0.008209228515625, 'loss_3': -16.38951873779297, 'loss_4': 1.2620123624801636, 'epoch': 14.63}
{'loss': 0.0091, 'grad_norm': 5.705612659454346, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.008313843049108982, 'loss_2': 0.0007419586181640625, 'loss_3': -16.441431045532227, 'loss_4': 1.24709153175354, 'epoch': 14.64}
{'loss': 0.0071, 'grad_norm': 5.5268120765686035, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.006840272340923548, 'loss_2': 0.0002925395965576172, 'loss_3': -16.606040954589844, 'loss_4': 1.8260905742645264, 'epoch': 14.65}
{'loss': 0.0184, 'grad_norm': 4.987881660461426, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.009389457292854786, 'loss_2': 0.0090179443359375, 'loss_3': -16.561397552490234, 'loss_4': 1.606337070465088, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 10:26:11,422 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:11,423 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:25<45:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:18,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0185558944940567, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01325076911598444, 'eval_loss_2': 0.005305126309394836, 'eval_loss_3': -18.266990661621094, 'eval_loss_4': 1.8240985870361328, 'epoch': 14.65}
{'loss': 0.0179, 'grad_norm': 5.463659286499023, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.008740654215216637, 'loss_2': 0.0092010498046875, 'loss_3': -16.47505760192871, 'loss_4': 1.7276780605316162, 'epoch': 14.66}
{'loss': 0.0155, 'grad_norm': 5.665228366851807, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.013876651413738728, 'loss_2': 0.0015974044799804688, 'loss_3': -16.485546112060547, 'loss_4': 2.35817813873291, 'epoch': 14.66}
{'loss': 0.0092, 'grad_norm': 6.091286659240723, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.0073935301043093204, 'loss_2': 0.0017566680908203125, 'loss_3': -16.57093048095703, 'loss_4': 1.9229273796081543, 'epoch': 14.67}
{'loss': 0.0132, 'grad_norm': 5.594811916351318, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.0095912404358387, 'loss_2': 0.003620147705078125, 'loss_3': -16.4080810546875, 'loss_4': 2.308103322982788, 'epoch': 14.67}
{'loss': 0.0073, 'grad_norm': 4.639705657958984, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.006892485544085503, 'loss_2': 0.0004374980926513672, 'loss_3': -16.360675811767578, 'loss_4': 2.2633891105651855, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 10:26:18,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:18,768 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:33<45:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:26,113 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01663324236869812, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013645746745169163, 'eval_loss_2': 0.002987496554851532, 'eval_loss_3': -18.27667999267578, 'eval_loss_4': 2.2463927268981934, 'epoch': 14.68}
{'loss': 0.0172, 'grad_norm': 6.994401454925537, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.015245662070810795, 'loss_2': 0.0019741058349609375, 'loss_3': -16.512805938720703, 'loss_4': 2.532392978668213, 'epoch': 14.69}
{'loss': 0.0178, 'grad_norm': 8.046662330627441, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.016802538186311722, 'loss_2': 0.00096893310546875, 'loss_3': -16.475582122802734, 'loss_4': 2.132859706878662, 'epoch': 14.69}
{'loss': 0.0213, 'grad_norm': 6.049631118774414, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.01184177864342928, 'loss_2': 0.0094757080078125, 'loss_3': -16.593917846679688, 'loss_4': 2.916987657546997, 'epoch': 14.7}
{'loss': 0.0253, 'grad_norm': 5.1568074226379395, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.014801857993006706, 'loss_2': 0.01047515869140625, 'loss_3': -16.446456909179688, 'loss_4': 3.0730278491973877, 'epoch': 14.7}
{'loss': 0.0271, 'grad_norm': 9.114202499389648, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.022100389003753662, 'loss_2': 0.005046844482421875, 'loss_3': -16.28403091430664, 'loss_4': 3.0725412368774414, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 10:26:26,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:26,113 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:40<45:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:33,456 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016689483076334, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014100659638643265, 'eval_loss_2': 0.002588823437690735, 'eval_loss_3': -18.23516845703125, 'eval_loss_4': 2.7285501956939697, 'epoch': 14.71}
{'loss': 0.0219, 'grad_norm': 7.427587985992432, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.018614744767546654, 'loss_2': 0.0032501220703125, 'loss_3': -16.355239868164062, 'loss_4': 3.2295446395874023, 'epoch': 14.72}
{'loss': 0.0262, 'grad_norm': 11.102599143981934, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.024165889248251915, 'loss_2': 0.00202178955078125, 'loss_3': -16.30299186706543, 'loss_4': 2.7512032985687256, 'epoch': 14.72}
{'loss': 0.0216, 'grad_norm': 6.680179595947266, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.016413535922765732, 'loss_2': 0.005218505859375, 'loss_3': -16.254737854003906, 'loss_4': 2.4503607749938965, 'epoch': 14.73}
{'loss': 0.0249, 'grad_norm': 9.288174629211426, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.016016202047467232, 'loss_2': 0.00891876220703125, 'loss_3': -16.698410034179688, 'loss_4': 2.659492015838623, 'epoch': 14.73}
{'loss': 0.0225, 'grad_norm': 7.450138568878174, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.019125375896692276, 'loss_2': 0.0033359527587890625, 'loss_3': -16.333328247070312, 'loss_4': 3.614687442779541, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 10:26:33,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:33,457 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:48<45:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:40,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01961977779865265, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0169917494058609, 'eval_loss_2': 0.002628028392791748, 'eval_loss_3': -18.20307159423828, 'eval_loss_4': 3.0063958168029785, 'epoch': 14.74}
{'loss': 0.0253, 'grad_norm': 10.03624153137207, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.02250327542424202, 'loss_2': 0.00281524658203125, 'loss_3': -16.20242691040039, 'loss_4': 3.0094237327575684, 'epoch': 14.74}
{'loss': 0.0268, 'grad_norm': 14.703169822692871, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.02491280436515808, 'loss_2': 0.0019350051879882812, 'loss_3': -16.529808044433594, 'loss_4': 2.678988218307495, 'epoch': 14.75}
{'loss': 0.0447, 'grad_norm': 10.123673439025879, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.04029681161046028, 'loss_2': 0.0044097900390625, 'loss_3': -16.24777603149414, 'loss_4': 3.6077985763549805, 'epoch': 14.76}
{'loss': 0.0439, 'grad_norm': 13.815598487854004, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.038340527564287186, 'loss_2': 0.00560760498046875, 'loss_3': -16.318256378173828, 'loss_4': 3.7940120697021484, 'epoch': 14.76}
{'loss': 0.0105, 'grad_norm': 4.993969917297363, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.010133566334843636, 'loss_2': 0.00032019615173339844, 'loss_3': -16.668659210205078, 'loss_4': 2.987957000732422, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 10:26:40,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:40,800 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:02:55<45:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:48,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019386697560548782, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.096, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.01656210422515869, 'eval_loss_2': 0.0028245896100997925, 'eval_loss_3': -18.20619010925293, 'eval_loss_4': 3.2030625343322754, 'epoch': 14.77}
{'loss': 0.0212, 'grad_norm': 7.89217472076416, 'learning_rate': 1.525e-05, 'loss_1': 0.019181735813617706, 'loss_2': 0.00203704833984375, 'loss_3': -16.563777923583984, 'loss_4': 3.9449758529663086, 'epoch': 14.77}
{'loss': 0.013, 'grad_norm': 5.301896095275879, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.009553402662277222, 'loss_2': 0.003490447998046875, 'loss_3': -16.388141632080078, 'loss_4': 2.4158973693847656, 'epoch': 14.78}
{'loss': 0.04, 'grad_norm': 11.070653915405273, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.03481164947152138, 'loss_2': 0.005237579345703125, 'loss_3': -16.427989959716797, 'loss_4': 3.6436619758605957, 'epoch': 14.78}
{'loss': 0.0225, 'grad_norm': 6.303408145904541, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.018805773928761482, 'loss_2': 0.003662109375, 'loss_3': -16.295289993286133, 'loss_4': 2.8303279876708984, 'epoch': 14.79}
{'loss': 0.0128, 'grad_norm': 5.332979202270508, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.010276560671627522, 'loss_2': 0.002513885498046875, 'loss_3': -16.428730010986328, 'loss_4': 2.5953054428100586, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 10:26:48,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:48,163 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:02<45:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:26:55,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020753739401698112, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016563234850764275, 'eval_loss_2': 0.004190504550933838, 'eval_loss_3': -18.18739128112793, 'eval_loss_4': 3.200082302093506, 'epoch': 14.8}
{'loss': 0.0252, 'grad_norm': 5.756398677825928, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.013163832947611809, 'loss_2': 0.01203155517578125, 'loss_3': -16.478147506713867, 'loss_4': 2.879215717315674, 'epoch': 14.8}
{'loss': 0.0181, 'grad_norm': 5.308836460113525, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.009328183718025684, 'loss_2': 0.00881195068359375, 'loss_3': -16.39249038696289, 'loss_4': 2.889451503753662, 'epoch': 14.81}
{'loss': 0.0288, 'grad_norm': 10.64531421661377, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.022445470094680786, 'loss_2': 0.006317138671875, 'loss_3': -16.337200164794922, 'loss_4': 3.0786614418029785, 'epoch': 14.81}
{'loss': 0.0311, 'grad_norm': 7.9959259033203125, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.02124672755599022, 'loss_2': 0.00982666015625, 'loss_3': -16.49529266357422, 'loss_4': 2.773973226547241, 'epoch': 14.82}
{'loss': 0.0164, 'grad_norm': 6.285541534423828, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.010424938052892685, 'loss_2': 0.0059814453125, 'loss_3': -16.245588302612305, 'loss_4': 2.8564884662628174, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 10:26:55,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:26:55,512 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:10<45:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:02,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016325820237398148, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01312355324625969, 'eval_loss_2': 0.0032022669911384583, 'eval_loss_3': -18.209169387817383, 'eval_loss_4': 2.894684076309204, 'epoch': 14.83}
{'loss': 0.0377, 'grad_norm': 12.164301872253418, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.022959928959608078, 'loss_2': 0.0147552490234375, 'loss_3': -16.395370483398438, 'loss_4': 2.529275894165039, 'epoch': 14.83}
{'loss': 0.0174, 'grad_norm': 6.901623725891113, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.017352426424622536, 'loss_2': 2.9325485229492188e-05, 'loss_3': -16.547836303710938, 'loss_4': 2.3409583568573, 'epoch': 14.84}
{'loss': 0.0086, 'grad_norm': 4.7323689460754395, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.0071257008239626884, 'loss_2': 0.0014276504516601562, 'loss_3': -16.416751861572266, 'loss_4': 2.5557053089141846, 'epoch': 14.84}
{'loss': 0.0117, 'grad_norm': 5.340137004852295, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.010336539708077908, 'loss_2': 0.0013179779052734375, 'loss_3': -16.37181854248047, 'loss_4': 2.631044387817383, 'epoch': 14.85}
{'loss': 0.0157, 'grad_norm': 6.185605049133301, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.0134707260876894, 'loss_2': 0.002223968505859375, 'loss_3': -16.570287704467773, 'loss_4': 2.063369035720825, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 10:27:02,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:02,860 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:17<44:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:10,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019391976296901703, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012486658990383148, 'eval_loss_2': 0.006905317306518555, 'eval_loss_3': -18.21452522277832, 'eval_loss_4': 2.8957748413085938, 'epoch': 14.85}
{'loss': 0.0191, 'grad_norm': 8.229212760925293, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.01842944510281086, 'loss_2': 0.0006866455078125, 'loss_3': -16.441648483276367, 'loss_4': 3.045477867126465, 'epoch': 14.86}
{'loss': 0.0317, 'grad_norm': 15.177970886230469, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.022307338193058968, 'loss_2': 0.00940704345703125, 'loss_3': -16.32976722717285, 'loss_4': 3.1096415519714355, 'epoch': 14.87}
{'loss': 0.0147, 'grad_norm': 5.151963710784912, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.007143367547541857, 'loss_2': 0.00760650634765625, 'loss_3': -16.287315368652344, 'loss_4': 1.7150077819824219, 'epoch': 14.87}
{'loss': 0.0328, 'grad_norm': 8.461133003234863, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.02296917513012886, 'loss_2': 0.0098114013671875, 'loss_3': -16.175973892211914, 'loss_4': 3.1111063957214355, 'epoch': 14.88}
{'loss': 0.0211, 'grad_norm': 5.808914661407471, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.00854303315281868, 'loss_2': 0.01259613037109375, 'loss_3': -16.51213836669922, 'loss_4': 1.8778927326202393, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 10:27:10,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:10,203 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:24<44:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:17,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024337856099009514, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.832, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013222305104136467, 'eval_loss_2': 0.011115550994873047, 'eval_loss_3': -18.21846580505371, 'eval_loss_4': 2.6898651123046875, 'epoch': 14.88}
{'loss': 0.012, 'grad_norm': 5.798198699951172, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.011412656866014004, 'loss_2': 0.00058746337890625, 'loss_3': -16.48176383972168, 'loss_4': 2.748713254928589, 'epoch': 14.89}
{'loss': 0.0345, 'grad_norm': 15.886249542236328, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.01899999938905239, 'loss_2': 0.0155487060546875, 'loss_3': -16.436655044555664, 'loss_4': 3.0019164085388184, 'epoch': 14.9}
{'loss': 0.0318, 'grad_norm': 8.009834289550781, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.019922679290175438, 'loss_2': 0.011871337890625, 'loss_3': -16.375730514526367, 'loss_4': 2.7378945350646973, 'epoch': 14.9}
{'loss': 0.0231, 'grad_norm': 8.838375091552734, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.01913476176559925, 'loss_2': 0.00394439697265625, 'loss_3': -16.431930541992188, 'loss_4': 2.914750576019287, 'epoch': 14.91}
{'loss': 0.0221, 'grad_norm': 8.46373462677002, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.016006186604499817, 'loss_2': 0.006137847900390625, 'loss_3': -16.28384017944336, 'loss_4': 2.9727180004119873, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 10:27:17,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:17,553 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:32<44:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:24,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019151417538523674, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.877, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012735662050545216, 'eval_loss_2': 0.006415754556655884, 'eval_loss_3': -18.25387191772461, 'eval_loss_4': 2.5761799812316895, 'epoch': 14.91}
{'loss': 0.016, 'grad_norm': 6.124650478363037, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.011977381072938442, 'loss_2': 0.003997802734375, 'loss_3': -16.401653289794922, 'loss_4': 2.420032501220703, 'epoch': 14.92}
{'loss': 0.0111, 'grad_norm': 5.332647323608398, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.008913076482713223, 'loss_2': 0.002231597900390625, 'loss_3': -16.458038330078125, 'loss_4': 3.204422950744629, 'epoch': 14.92}
{'loss': 0.0157, 'grad_norm': 6.108143329620361, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.013064637780189514, 'loss_2': 0.002674102783203125, 'loss_3': -16.265275955200195, 'loss_4': 3.1991126537323, 'epoch': 14.93}
{'loss': 0.026, 'grad_norm': 15.74325180053711, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.023495011031627655, 'loss_2': 0.002544403076171875, 'loss_3': -16.566871643066406, 'loss_4': 1.7970867156982422, 'epoch': 14.94}
{'loss': 0.0095, 'grad_norm': 5.431330680847168, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.007620310876518488, 'loss_2': 0.0018901824951171875, 'loss_3': -16.424116134643555, 'loss_4': 3.0328009128570557, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 10:27:24,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:24,901 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:39<44:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:27:32,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017139101400971413, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013018514029681683, 'eval_loss_2': 0.004120588302612305, 'eval_loss_3': -18.270587921142578, 'eval_loss_4': 2.42185378074646, 'epoch': 14.94}
{'loss': 0.0119, 'grad_norm': 5.565950393676758, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.010589477606117725, 'loss_2': 0.0012607574462890625, 'loss_3': -16.47551727294922, 'loss_4': 2.73569917678833, 'epoch': 14.95}
{'loss': 0.0195, 'grad_norm': 7.54580545425415, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.01791875995695591, 'loss_2': 0.0015773773193359375, 'loss_3': -16.279998779296875, 'loss_4': 1.7927656173706055, 'epoch': 14.95}
{'loss': 0.008, 'grad_norm': 4.537953853607178, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.006875567603856325, 'loss_2': 0.0011320114135742188, 'loss_3': -16.383464813232422, 'loss_4': 3.559054374694824, 'epoch': 14.96}
{'loss': 0.0166, 'grad_norm': 5.836399078369141, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.015083564445376396, 'loss_2': 0.0014848709106445312, 'loss_3': -16.335044860839844, 'loss_4': 2.0559580326080322, 'epoch': 14.97}
{'loss': 0.0228, 'grad_norm': 7.146928787231445, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.014371504075825214, 'loss_2': 0.008453369140625, 'loss_3': -16.4755916595459, 'loss_4': 1.8329815864562988, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 10:27:32,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:32,248 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:46<40:06,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:27:39,237 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017027627676725388, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0126145388931036, 'eval_loss_2': 0.004413090646266937, 'eval_loss_3': -18.285186767578125, 'eval_loss_4': 2.4175972938537598, 'epoch': 14.97}
{'loss': 0.0081, 'grad_norm': 4.595529556274414, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.0067411451600492, 'loss_2': 0.001331329345703125, 'loss_3': -16.35283088684082, 'loss_4': 3.282864570617676, 'epoch': 14.98}
{'loss': 0.0523, 'grad_norm': 16.37417221069336, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.04901095852255821, 'loss_2': 0.0032901763916015625, 'loss_3': -16.496967315673828, 'loss_4': 2.6372742652893066, 'epoch': 14.98}
{'loss': 0.0236, 'grad_norm': 7.997635841369629, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.02001284249126911, 'loss_2': 0.003620147705078125, 'loss_3': -16.42172622680664, 'loss_4': 2.1948866844177246, 'epoch': 14.99}
{'loss': 0.0257, 'grad_norm': 10.671148300170898, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.02286890149116516, 'loss_2': 0.00286865234375, 'loss_3': -16.399398803710938, 'loss_4': 2.3710758686065674, 'epoch': 14.99}
{'loss': 0.0081, 'grad_norm': 5.380931854248047, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.004193366039544344, 'loss_2': 0.003948211669921875, 'loss_3': -16.322240829467773, 'loss_4': 3.116455554962158, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 10:27:39,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:39,237 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:03:53<43:53,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:27:46,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016837546601891518, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011365765705704689, 'eval_loss_2': 0.005471780896186829, 'eval_loss_3': -18.307554244995117, 'eval_loss_4': 2.5667104721069336, 'epoch': 15.0}
{'loss': 0.0173, 'grad_norm': 6.303350925445557, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.012072836980223656, 'loss_2': 0.00522613525390625, 'loss_3': -16.271961212158203, 'loss_4': 2.4828810691833496, 'epoch': 15.01}
{'loss': 0.0211, 'grad_norm': 9.248425483703613, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.019694454967975616, 'loss_2': 0.0013799667358398438, 'loss_3': -16.40903091430664, 'loss_4': 2.4063830375671387, 'epoch': 15.01}
{'loss': 0.0189, 'grad_norm': 9.109975814819336, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.01845688186585903, 'loss_2': 0.00044536590576171875, 'loss_3': -16.393890380859375, 'loss_4': 2.590935230255127, 'epoch': 15.02}
{'loss': 0.0167, 'grad_norm': 6.066702842712402, 'learning_rate': 1.5e-05, 'loss_1': 0.016610393300652504, 'loss_2': 0.00010156631469726562, 'loss_3': -16.252666473388672, 'loss_4': 2.6528799533843994, 'epoch': 15.02}
{'loss': 0.0114, 'grad_norm': 5.911640167236328, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.009586989879608154, 'loss_2': 0.0017910003662109375, 'loss_3': -16.433868408203125, 'loss_4': 2.686645269393921, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 10:27:46,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:46,625 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:01<44:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:27:53,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013499315828084946, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010201034136116505, 'eval_loss_2': 0.0032982826232910156, 'eval_loss_3': -18.30913734436035, 'eval_loss_4': 2.544062614440918, 'epoch': 15.03}
{'loss': 0.0113, 'grad_norm': 4.953357696533203, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.007981617003679276, 'loss_2': 0.00327301025390625, 'loss_3': -16.57085418701172, 'loss_4': 2.7107458114624023, 'epoch': 15.03}
{'loss': 0.0149, 'grad_norm': 5.056844711303711, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.008412154391407967, 'loss_2': 0.006473541259765625, 'loss_3': -16.208003997802734, 'loss_4': 3.4172000885009766, 'epoch': 15.04}
{'loss': 0.0148, 'grad_norm': 6.635140419006348, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.013824095018208027, 'loss_2': 0.0009899139404296875, 'loss_3': -16.39618682861328, 'loss_4': 3.304633378982544, 'epoch': 15.05}
{'loss': 0.0209, 'grad_norm': 7.337390422821045, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.014351209625601768, 'loss_2': 0.00653839111328125, 'loss_3': -16.465972900390625, 'loss_4': 3.1527938842773438, 'epoch': 15.05}
{'loss': 0.0179, 'grad_norm': 5.488696098327637, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.011562238447368145, 'loss_2': 0.006378173828125, 'loss_3': -16.268722534179688, 'loss_4': 2.866488456726074, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 10:27:53,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:27:53,964 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:08<44:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:01,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014311350882053375, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.145, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01051696389913559, 'eval_loss_2': 0.0037943869829177856, 'eval_loss_3': -18.282257080078125, 'eval_loss_4': 2.5772476196289062, 'epoch': 15.06}
{'loss': 0.0132, 'grad_norm': 5.182196617126465, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.008584393188357353, 'loss_2': 0.004604339599609375, 'loss_3': -16.43766212463379, 'loss_4': 2.934295654296875, 'epoch': 15.06}
{'loss': 0.0208, 'grad_norm': 13.947274208068848, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.020100349560379982, 'loss_2': 0.0007448196411132812, 'loss_3': -16.09303092956543, 'loss_4': 2.798741579055786, 'epoch': 15.07}
{'loss': 0.0112, 'grad_norm': 6.353692054748535, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.011131580919027328, 'loss_2': 9.679794311523438e-05, 'loss_3': -16.446393966674805, 'loss_4': 2.9374985694885254, 'epoch': 15.08}
{'loss': 0.018, 'grad_norm': 6.21679162979126, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.012915126048028469, 'loss_2': 0.005096435546875, 'loss_3': -16.56021499633789, 'loss_4': 2.4256582260131836, 'epoch': 15.08}
{'loss': 0.0193, 'grad_norm': 5.333899974822998, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.011804815381765366, 'loss_2': 0.007534027099609375, 'loss_3': -16.306716918945312, 'loss_4': 3.1131174564361572, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 10:28:01,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:01,313 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:15<44:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:08,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01606343314051628, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.864, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0106457294896245, 'eval_loss_2': 0.0054177045822143555, 'eval_loss_3': -18.264101028442383, 'eval_loss_4': 2.504960775375366, 'epoch': 15.09}
{'loss': 0.0245, 'grad_norm': 10.28602123260498, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.017707666382193565, 'loss_2': 0.006805419921875, 'loss_3': -16.52362060546875, 'loss_4': 3.0352344512939453, 'epoch': 15.09}
{'loss': 0.0087, 'grad_norm': 4.283768177032471, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.00657133013010025, 'loss_2': 0.0021209716796875, 'loss_3': -16.337881088256836, 'loss_4': 2.5747203826904297, 'epoch': 15.1}
{'loss': 0.0145, 'grad_norm': 8.41610050201416, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.01417121198028326, 'loss_2': 0.00032806396484375, 'loss_3': -16.162120819091797, 'loss_4': 2.7297163009643555, 'epoch': 15.1}
{'loss': 0.0108, 'grad_norm': 4.783466339111328, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.004999913275241852, 'loss_2': 0.00576019287109375, 'loss_3': -16.5831298828125, 'loss_4': 2.4845218658447266, 'epoch': 15.11}
{'loss': 0.0106, 'grad_norm': 5.63036584854126, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.009707418270409107, 'loss_2': 0.0009312629699707031, 'loss_3': -16.350675582885742, 'loss_4': 3.5168895721435547, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 10:28:08,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:08,665 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:23<44:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:16,008 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015713274478912354, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011412203311920166, 'eval_loss_2': 0.0043010711669921875, 'eval_loss_3': -18.27029800415039, 'eval_loss_4': 2.3946354389190674, 'epoch': 15.12}
{'loss': 0.0134, 'grad_norm': 5.186047077178955, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.008651645854115486, 'loss_2': 0.004703521728515625, 'loss_3': -16.202241897583008, 'loss_4': 2.3636507987976074, 'epoch': 15.12}
{'loss': 0.0095, 'grad_norm': 5.1893439292907715, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.007963928394019604, 'loss_2': 0.0015459060668945312, 'loss_3': -16.222721099853516, 'loss_4': 2.611891031265259, 'epoch': 15.13}
{'loss': 0.0292, 'grad_norm': 10.367624282836914, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.027772748842835426, 'loss_2': 0.0014095306396484375, 'loss_3': -16.41756820678711, 'loss_4': 2.768881320953369, 'epoch': 15.13}
{'loss': 0.0113, 'grad_norm': 5.521718978881836, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.010334206745028496, 'loss_2': 0.0009822845458984375, 'loss_3': -16.39187240600586, 'loss_4': 3.028716564178467, 'epoch': 15.14}
{'loss': 0.0087, 'grad_norm': 5.6515350341796875, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.00741024874150753, 'loss_2': 0.00127410888671875, 'loss_3': -16.410255432128906, 'loss_4': 1.8257815837860107, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 10:28:16,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:16,009 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:30<44:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:23,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014855057932436466, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.31, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011363118886947632, 'eval_loss_2': 0.0034919381141662598, 'eval_loss_3': -18.259626388549805, 'eval_loss_4': 2.234992742538452, 'epoch': 15.15}
{'loss': 0.0133, 'grad_norm': 5.72885274887085, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.0076711648143827915, 'loss_2': 0.005584716796875, 'loss_3': -16.328662872314453, 'loss_4': 3.2428059577941895, 'epoch': 15.15}
{'loss': 0.018, 'grad_norm': 8.55394458770752, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.012833744287490845, 'loss_2': 0.005191802978515625, 'loss_3': -16.45452117919922, 'loss_4': 2.428126335144043, 'epoch': 15.16}
{'loss': 0.0097, 'grad_norm': 4.824333190917969, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.006636170670390129, 'loss_2': 0.003055572509765625, 'loss_3': -16.44143295288086, 'loss_4': 1.2699964046478271, 'epoch': 15.16}
{'loss': 0.0443, 'grad_norm': 16.53177833557129, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.04363570362329483, 'loss_2': 0.0006704330444335938, 'loss_3': -16.366252899169922, 'loss_4': 2.383317232131958, 'epoch': 15.17}
{'loss': 0.0322, 'grad_norm': 8.779212951660156, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.025152016431093216, 'loss_2': 0.007068634033203125, 'loss_3': -16.510644912719727, 'loss_4': 2.2776050567626953, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 10:28:23,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:23,349 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:37<43:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:30,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015647539868950844, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012044096365571022, 'eval_loss_2': 0.0036034435033798218, 'eval_loss_3': -18.251266479492188, 'eval_loss_4': 2.075723648071289, 'epoch': 15.17}
{'loss': 0.0202, 'grad_norm': 7.536132335662842, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.01946045644581318, 'loss_2': 0.0007419586181640625, 'loss_3': -16.50981330871582, 'loss_4': 2.128121852874756, 'epoch': 15.18}
{'loss': 0.0085, 'grad_norm': 4.942074775695801, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.007434808183461428, 'loss_2': 0.001102447509765625, 'loss_3': -16.582538604736328, 'loss_4': 1.9290482997894287, 'epoch': 15.19}
{'loss': 0.0135, 'grad_norm': 4.679666519165039, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.007402627728879452, 'loss_2': 0.00606536865234375, 'loss_3': -16.474332809448242, 'loss_4': 2.379784107208252, 'epoch': 15.19}
{'loss': 0.019, 'grad_norm': 6.799874782562256, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.013525922782719135, 'loss_2': 0.005458831787109375, 'loss_3': -16.450790405273438, 'loss_4': 2.039803981781006, 'epoch': 15.2}
{'loss': 0.024, 'grad_norm': 16.486780166625977, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.023372218012809753, 'loss_2': 0.0006313323974609375, 'loss_3': -16.42804718017578, 'loss_4': 2.3571205139160156, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 10:28:30,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:30,688 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:45<43:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:38,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017583347856998444, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.221, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013167180120944977, 'eval_loss_2': 0.004416167736053467, 'eval_loss_3': -18.273292541503906, 'eval_loss_4': 1.8331619501113892, 'epoch': 15.2}
{'loss': 0.0087, 'grad_norm': 6.083751201629639, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.00798464473336935, 'loss_2': 0.0006952285766601562, 'loss_3': -16.297306060791016, 'loss_4': 1.5590167045593262, 'epoch': 15.21}
{'loss': 0.0115, 'grad_norm': 5.013981819152832, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.007526322267949581, 'loss_2': 0.00399017333984375, 'loss_3': -16.249664306640625, 'loss_4': 2.1323330402374268, 'epoch': 15.22}
{'loss': 0.0254, 'grad_norm': 7.3240485191345215, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.02233305387198925, 'loss_2': 0.003047943115234375, 'loss_3': -16.492717742919922, 'loss_4': 1.7325966358184814, 'epoch': 15.22}
{'loss': 0.0224, 'grad_norm': 10.861839294433594, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.019855313003063202, 'loss_2': 0.00257110595703125, 'loss_3': -16.23700523376465, 'loss_4': 1.8367505073547363, 'epoch': 15.23}
{'loss': 0.0187, 'grad_norm': 13.12328052520752, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.01687757298350334, 'loss_2': 0.001834869384765625, 'loss_3': -16.290508270263672, 'loss_4': 2.4688172340393066, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 10:28:38,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:38,034 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:52<43:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:45,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016571585088968277, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.239, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012587818317115307, 'eval_loss_2': 0.0039837658405303955, 'eval_loss_3': -18.268632888793945, 'eval_loss_4': 1.7673978805541992, 'epoch': 15.23}
{'loss': 0.0446, 'grad_norm': 15.566075325012207, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.036583807319402695, 'loss_2': 0.0079803466796875, 'loss_3': -16.323213577270508, 'loss_4': 2.8740196228027344, 'epoch': 15.24}
{'loss': 0.0272, 'grad_norm': 9.907524108886719, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.020097695291042328, 'loss_2': 0.007137298583984375, 'loss_3': -16.334684371948242, 'loss_4': 2.5343990325927734, 'epoch': 15.24}
{'loss': 0.0198, 'grad_norm': 8.906351089477539, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.016848690807819366, 'loss_2': 0.0029659271240234375, 'loss_3': -16.459823608398438, 'loss_4': 1.6809895038604736, 'epoch': 15.25}
{'loss': 0.0104, 'grad_norm': 4.410950660705566, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.004090417176485062, 'loss_2': 0.00627899169921875, 'loss_3': -16.48238754272461, 'loss_4': 1.5769051313400269, 'epoch': 15.26}
{'loss': 0.0174, 'grad_norm': 6.87146520614624, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.015378703363239765, 'loss_2': 0.00201416015625, 'loss_3': -16.492855072021484, 'loss_4': 1.3820723295211792, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 10:28:45,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:45,382 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:04:59<43:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:28:52,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018638398498296738, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.261, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.01312175765633583, 'eval_loss_2': 0.005516640841960907, 'eval_loss_3': -18.280319213867188, 'eval_loss_4': 1.5572723150253296, 'epoch': 15.26}
{'loss': 0.0108, 'grad_norm': 5.309586048126221, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.007702689617872238, 'loss_2': 0.003124237060546875, 'loss_3': -16.453895568847656, 'loss_4': 1.6235902309417725, 'epoch': 15.27}
{'loss': 0.0059, 'grad_norm': 5.68924617767334, 'learning_rate': 1.475e-05, 'loss_1': 0.005479821935296059, 'loss_2': 0.0004425048828125, 'loss_3': -16.523738861083984, 'loss_4': 1.7844420671463013, 'epoch': 15.27}
{'loss': 0.0154, 'grad_norm': 6.638957977294922, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.01174541562795639, 'loss_2': 0.003665924072265625, 'loss_3': -16.40273666381836, 'loss_4': 1.5055395364761353, 'epoch': 15.28}
{'loss': 0.0276, 'grad_norm': 9.46577262878418, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.0200358759611845, 'loss_2': 0.00753021240234375, 'loss_3': -16.520187377929688, 'loss_4': 1.5074151754379272, 'epoch': 15.28}
{'loss': 0.013, 'grad_norm': 5.565859794616699, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.008365876972675323, 'loss_2': 0.004596710205078125, 'loss_3': -16.700454711914062, 'loss_4': 0.7286798357963562, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 10:28:52,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:28:52,740 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:07<43:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:00,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015513193793594837, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011909013614058495, 'eval_loss_2': 0.0036041811108589172, 'eval_loss_3': -18.27264404296875, 'eval_loss_4': 1.3250408172607422, 'epoch': 15.29}
{'loss': 0.011, 'grad_norm': 4.841919422149658, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.005894377361983061, 'loss_2': 0.005126953125, 'loss_3': -16.40513801574707, 'loss_4': 1.5193486213684082, 'epoch': 15.3}
{'loss': 0.0119, 'grad_norm': 5.052875518798828, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.007360984105616808, 'loss_2': 0.0045318603515625, 'loss_3': -16.325008392333984, 'loss_4': 2.0412774085998535, 'epoch': 15.3}
{'loss': 0.0083, 'grad_norm': 4.838504791259766, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.005469980649650097, 'loss_2': 0.002834320068359375, 'loss_3': -16.513628005981445, 'loss_4': 1.7348816394805908, 'epoch': 15.31}
{'loss': 0.0252, 'grad_norm': 10.565250396728516, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.02366509474813938, 'loss_2': 0.0015554428100585938, 'loss_3': -16.367467880249023, 'loss_4': 1.587421178817749, 'epoch': 15.31}
{'loss': 0.0136, 'grad_norm': 4.903871536254883, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.006592727266252041, 'loss_2': 0.00702667236328125, 'loss_3': -16.53049087524414, 'loss_4': 1.527557611465454, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 10:29:00,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:00,084 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:14<43:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:07,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014499301090836525, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011674979701638222, 'eval_loss_2': 0.0028243213891983032, 'eval_loss_3': -18.268917083740234, 'eval_loss_4': 1.2145743370056152, 'epoch': 15.32}
{'loss': 0.0135, 'grad_norm': 4.908632755279541, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.004363005980849266, 'loss_2': 0.0091094970703125, 'loss_3': -16.52576446533203, 'loss_4': 1.519499659538269, 'epoch': 15.33}
{'loss': 0.0218, 'grad_norm': 9.250784873962402, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.01710936799645424, 'loss_2': 0.00472259521484375, 'loss_3': -16.54220199584961, 'loss_4': 0.29438233375549316, 'epoch': 15.33}
{'loss': 0.014, 'grad_norm': 4.762750625610352, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.008444315753877163, 'loss_2': 0.00551605224609375, 'loss_3': -16.425403594970703, 'loss_4': 1.316885232925415, 'epoch': 15.34}
{'loss': 0.0119, 'grad_norm': 5.874113082885742, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.009733514860272408, 'loss_2': 0.002132415771484375, 'loss_3': -16.36342430114746, 'loss_4': 1.6845428943634033, 'epoch': 15.34}
{'loss': 0.0066, 'grad_norm': 4.513354778289795, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.005517228506505489, 'loss_2': 0.0010585784912109375, 'loss_3': -16.572019577026367, 'loss_4': 1.121037483215332, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 10:29:07,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:07,425 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:21<43:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:14,762 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01506718248128891, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.23, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010412171483039856, 'eval_loss_2': 0.004655010998249054, 'eval_loss_3': -18.262327194213867, 'eval_loss_4': 1.1799869537353516, 'epoch': 15.35}
{'loss': 0.0114, 'grad_norm': 5.838651180267334, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.009220460429787636, 'loss_2': 0.0021820068359375, 'loss_3': -16.47060775756836, 'loss_4': 0.977763295173645, 'epoch': 15.35}
{'loss': 0.0088, 'grad_norm': 5.49152135848999, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.0086336899548769, 'loss_2': 0.00014340877532958984, 'loss_3': -16.31113052368164, 'loss_4': 1.3513250350952148, 'epoch': 15.36}
{'loss': 0.0218, 'grad_norm': 12.387943267822266, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.018755843862891197, 'loss_2': 0.0030231475830078125, 'loss_3': -16.47350311279297, 'loss_4': 1.0564799308776855, 'epoch': 15.37}
{'loss': 0.0215, 'grad_norm': 6.454879283905029, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.015617585740983486, 'loss_2': 0.00588226318359375, 'loss_3': -16.305837631225586, 'loss_4': 1.2542953491210938, 'epoch': 15.37}
{'loss': 0.0104, 'grad_norm': 5.220991611480713, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.005759434308856726, 'loss_2': 0.004596710205078125, 'loss_3': -16.49013900756836, 'loss_4': 1.970952033996582, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 10:29:14,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:14,763 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:29<43:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:22,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014916502870619297, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009047353640198708, 'eval_loss_2': 0.005869150161743164, 'eval_loss_3': -18.27543067932129, 'eval_loss_4': 1.2774393558502197, 'epoch': 15.38}
{'loss': 0.0134, 'grad_norm': 4.706051349639893, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.006449962500482798, 'loss_2': 0.00698089599609375, 'loss_3': -16.457202911376953, 'loss_4': 0.9653429985046387, 'epoch': 15.38}
{'loss': 0.0264, 'grad_norm': 12.273202896118164, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.01808604784309864, 'loss_2': 0.0083465576171875, 'loss_3': -16.465797424316406, 'loss_4': 2.1582584381103516, 'epoch': 15.39}
{'loss': 0.0316, 'grad_norm': 13.841774940490723, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.02984287589788437, 'loss_2': 0.00176239013671875, 'loss_3': -16.195941925048828, 'loss_4': 1.5225138664245605, 'epoch': 15.4}
{'loss': 0.0146, 'grad_norm': 6.060413837432861, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.00833110511302948, 'loss_2': 0.006256103515625, 'loss_3': -16.541540145874023, 'loss_4': 2.9238715171813965, 'epoch': 15.4}
{'loss': 0.0204, 'grad_norm': 6.20840311050415, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.015416166745126247, 'loss_2': 0.005001068115234375, 'loss_3': -16.338878631591797, 'loss_4': 2.155086040496826, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 10:29:22,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:22,107 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:36<43:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:29,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01402192935347557, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010886665433645248, 'eval_loss_2': 0.0031352639198303223, 'eval_loss_3': -18.27335548400879, 'eval_loss_4': 1.6453179121017456, 'epoch': 15.41}
{'loss': 0.009, 'grad_norm': 4.334940433502197, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.003411385929211974, 'loss_2': 0.00563812255859375, 'loss_3': -16.385677337646484, 'loss_4': 2.036177158355713, 'epoch': 15.41}
{'loss': 0.019, 'grad_norm': 6.250952243804932, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.014082669280469418, 'loss_2': 0.00495147705078125, 'loss_3': -16.35874366760254, 'loss_4': 2.4882442951202393, 'epoch': 15.42}
{'loss': 0.0142, 'grad_norm': 6.398823261260986, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.010043331421911716, 'loss_2': 0.00415802001953125, 'loss_3': -16.378936767578125, 'loss_4': 2.2782065868377686, 'epoch': 15.42}
{'loss': 0.0221, 'grad_norm': 7.3225226402282715, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.012962952256202698, 'loss_2': 0.0091705322265625, 'loss_3': -16.312002182006836, 'loss_4': 1.698154330253601, 'epoch': 15.43}
{'loss': 0.0099, 'grad_norm': 5.7934346199035645, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.0071740709245204926, 'loss_2': 0.0026874542236328125, 'loss_3': -16.336994171142578, 'loss_4': 2.187775135040283, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 10:29:29,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:29,455 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:44<43:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:36,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013949651271104813, 'eval_runtime': 3.8167, 'eval_samples_per_second': 268.293, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.010183881968259811, 'eval_loss_2': 0.0037657693028450012, 'eval_loss_3': -18.292926788330078, 'eval_loss_4': 1.9033948183059692, 'epoch': 15.44}
{'loss': 0.0091, 'grad_norm': 5.47240686416626, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.006872114725410938, 'loss_2': 0.002254486083984375, 'loss_3': -16.487852096557617, 'loss_4': 2.531554698944092, 'epoch': 15.44}
{'loss': 0.0151, 'grad_norm': 10.130249977111816, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.014701691456139088, 'loss_2': 0.0004215240478515625, 'loss_3': -16.342906951904297, 'loss_4': 2.842991828918457, 'epoch': 15.45}
{'loss': 0.0312, 'grad_norm': 10.066681861877441, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.024958711117506027, 'loss_2': 0.00620269775390625, 'loss_3': -16.374252319335938, 'loss_4': 1.5123178958892822, 'epoch': 15.45}
{'loss': 0.0285, 'grad_norm': 8.146591186523438, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.020853040739893913, 'loss_2': 0.0076904296875, 'loss_3': -16.439041137695312, 'loss_4': 2.2717528343200684, 'epoch': 15.46}
{'loss': 0.0346, 'grad_norm': 17.002124786376953, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.030954891815781593, 'loss_2': 0.003604888916015625, 'loss_3': -16.397212982177734, 'loss_4': 3.4495773315429688, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 10:29:36,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:36,811 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:51<43:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:44,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013385827653110027, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010646755807101727, 'eval_loss_2': 0.0027390718460083008, 'eval_loss_3': -18.30593490600586, 'eval_loss_4': 2.0290236473083496, 'epoch': 15.47}
{'loss': 0.0166, 'grad_norm': 17.5841007232666, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.01607365906238556, 'loss_2': 0.0005025863647460938, 'loss_3': -16.457530975341797, 'loss_4': 2.741054058074951, 'epoch': 15.47}
{'loss': 0.012, 'grad_norm': 5.898007392883301, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.009099364280700684, 'loss_2': 0.00289154052734375, 'loss_3': -16.33599090576172, 'loss_4': 2.3154873847961426, 'epoch': 15.48}
{'loss': 0.0189, 'grad_norm': 5.815602779388428, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.01391710713505745, 'loss_2': 0.00498199462890625, 'loss_3': -16.513063430786133, 'loss_4': 2.417571544647217, 'epoch': 15.48}
{'loss': 0.0128, 'grad_norm': 5.585902214050293, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.012616929598152637, 'loss_2': 0.000232696533203125, 'loss_3': -16.554668426513672, 'loss_4': 3.6116418838500977, 'epoch': 15.49}
{'loss': 0.0206, 'grad_norm': 9.29499626159668, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.01815914176404476, 'loss_2': 0.002414703369140625, 'loss_3': -16.441940307617188, 'loss_4': 3.3360886573791504, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 10:29:44,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:44,160 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:05:58<43:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:51,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013610309921205044, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009887058287858963, 'eval_loss_2': 0.0037232525646686554, 'eval_loss_3': -18.306535720825195, 'eval_loss_4': 2.25285005569458, 'epoch': 15.49}
{'loss': 0.0152, 'grad_norm': 7.49464750289917, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.013362362049520016, 'loss_2': 0.0018672943115234375, 'loss_3': -16.249168395996094, 'loss_4': 3.682830333709717, 'epoch': 15.5}
{'loss': 0.0135, 'grad_norm': 6.733888626098633, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.012467341497540474, 'loss_2': 0.000988006591796875, 'loss_3': -16.40060043334961, 'loss_4': 3.0546298027038574, 'epoch': 15.51}
{'loss': 0.025, 'grad_norm': 7.126129150390625, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.012918689288198948, 'loss_2': 0.0120391845703125, 'loss_3': -16.028635025024414, 'loss_4': 3.196467399597168, 'epoch': 15.51}
{'loss': 0.018, 'grad_norm': 6.158782005310059, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.014754191972315311, 'loss_2': 0.003215789794921875, 'loss_3': -16.547561645507812, 'loss_4': 3.0389962196350098, 'epoch': 15.52}
{'loss': 0.0089, 'grad_norm': 5.557699680328369, 'learning_rate': 1.45e-05, 'loss_1': 0.007253686897456646, 'loss_2': 0.0016202926635742188, 'loss_3': -16.3453311920166, 'loss_4': 3.268521785736084, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 10:29:51,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:51,509 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:06<43:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:29:58,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014408654533326626, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010350709781050682, 'eval_loss_2': 0.004057943820953369, 'eval_loss_3': -18.320323944091797, 'eval_loss_4': 2.2271668910980225, 'epoch': 15.52}
{'loss': 0.0095, 'grad_norm': 4.531259536743164, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.005909712985157967, 'loss_2': 0.0035533905029296875, 'loss_3': -16.55197525024414, 'loss_4': 2.087855577468872, 'epoch': 15.53}
{'loss': 0.0192, 'grad_norm': 7.170783519744873, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.012016714550554752, 'loss_2': 0.00720977783203125, 'loss_3': -16.458330154418945, 'loss_4': 2.769399404525757, 'epoch': 15.53}
{'loss': 0.0159, 'grad_norm': 4.9566121101379395, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.007328994106501341, 'loss_2': 0.00860595703125, 'loss_3': -16.326459884643555, 'loss_4': 2.8561758995056152, 'epoch': 15.54}
{'loss': 0.022, 'grad_norm': 12.693979263305664, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.02016594633460045, 'loss_2': 0.0018062591552734375, 'loss_3': -16.459819793701172, 'loss_4': 1.9907262325286865, 'epoch': 15.55}
{'loss': 0.0357, 'grad_norm': 12.462976455688477, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.03507466986775398, 'loss_2': 0.0005893707275390625, 'loss_3': -16.330902099609375, 'loss_4': 2.5765328407287598, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 10:29:58,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:29:58,861 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:13<42:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:06,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01477578841149807, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.377, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010789653286337852, 'eval_loss_2': 0.003986135125160217, 'eval_loss_3': -18.315120697021484, 'eval_loss_4': 2.0489237308502197, 'epoch': 15.55}
{'loss': 0.0093, 'grad_norm': 5.956963539123535, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.008364977315068245, 'loss_2': 0.000965118408203125, 'loss_3': -16.358095169067383, 'loss_4': 2.1026344299316406, 'epoch': 15.56}
{'loss': 0.027, 'grad_norm': 9.036344528198242, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.026531454175710678, 'loss_2': 0.0004608631134033203, 'loss_3': -16.28044319152832, 'loss_4': 2.2689104080200195, 'epoch': 15.56}
{'loss': 0.0123, 'grad_norm': 5.880034446716309, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.010241498239338398, 'loss_2': 0.002063751220703125, 'loss_3': -16.373191833496094, 'loss_4': 2.512645721435547, 'epoch': 15.57}
{'loss': 0.0115, 'grad_norm': 6.05236291885376, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.009948181919753551, 'loss_2': 0.0015869140625, 'loss_3': -16.46090316772461, 'loss_4': 2.1567540168762207, 'epoch': 15.58}
{'loss': 0.0379, 'grad_norm': 17.33241844177246, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.026316555216908455, 'loss_2': 0.01157379150390625, 'loss_3': -16.410518646240234, 'loss_4': 1.8572309017181396, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 10:30:06,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:06,207 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:20<42:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:13,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017993910238146782, 'eval_runtime': 3.8231, 'eval_samples_per_second': 267.847, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.009586198255419731, 'eval_loss_2': 0.00840771198272705, 'eval_loss_3': -18.297863006591797, 'eval_loss_4': 2.002150297164917, 'epoch': 15.58}
{'loss': 0.0121, 'grad_norm': 4.975188255310059, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.00777314230799675, 'loss_2': 0.004344940185546875, 'loss_3': -16.366474151611328, 'loss_4': 1.6863678693771362, 'epoch': 15.59}
{'loss': 0.0235, 'grad_norm': 6.945429801940918, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.011723793111741543, 'loss_2': 0.0118255615234375, 'loss_3': -16.3623046875, 'loss_4': 1.854569673538208, 'epoch': 15.59}
{'loss': 0.017, 'grad_norm': 5.009767532348633, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.006386133376508951, 'loss_2': 0.0106048583984375, 'loss_3': -16.347415924072266, 'loss_4': 2.5056934356689453, 'epoch': 15.6}
{'loss': 0.0314, 'grad_norm': 8.349357604980469, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.01753535494208336, 'loss_2': 0.01381683349609375, 'loss_3': -16.182764053344727, 'loss_4': 3.5381357669830322, 'epoch': 15.6}
{'loss': 0.0312, 'grad_norm': 12.399274826049805, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.020082011818885803, 'loss_2': 0.01108551025390625, 'loss_3': -16.50752830505371, 'loss_4': 2.3500046730041504, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 10:30:13,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:13,574 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:28<42:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:20,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016987428069114685, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009901988320052624, 'eval_loss_2': 0.007085442543029785, 'eval_loss_3': -18.288806915283203, 'eval_loss_4': 2.023503303527832, 'epoch': 15.61}
{'loss': 0.018, 'grad_norm': 6.63146448135376, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.012303306721150875, 'loss_2': 0.00569915771484375, 'loss_3': -16.526498794555664, 'loss_4': 1.1311626434326172, 'epoch': 15.62}
{'loss': 0.028, 'grad_norm': 7.484378337860107, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.01417004968971014, 'loss_2': 0.0138702392578125, 'loss_3': -16.34387969970703, 'loss_4': 2.1370222568511963, 'epoch': 15.62}
{'loss': 0.0115, 'grad_norm': 5.063294410705566, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.007354904431849718, 'loss_2': 0.00415802001953125, 'loss_3': -16.4962158203125, 'loss_4': 2.001086711883545, 'epoch': 15.63}
{'loss': 0.0122, 'grad_norm': 5.690496444702148, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.011776148341596127, 'loss_2': 0.000431060791015625, 'loss_3': -16.21588134765625, 'loss_4': 2.482588768005371, 'epoch': 15.63}
{'loss': 0.0075, 'grad_norm': 5.669175148010254, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.007458216976374388, 'loss_2': 3.910064697265625e-05, 'loss_3': -16.43372917175293, 'loss_4': 2.4985198974609375, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 10:30:20,921 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:20,921 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:35<42:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:28,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013629075139760971, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.378, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010236945934593678, 'eval_loss_2': 0.003392130136489868, 'eval_loss_3': -18.286291122436523, 'eval_loss_4': 1.8661470413208008, 'epoch': 15.64}
{'loss': 0.0245, 'grad_norm': 16.231233596801758, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.018886685371398926, 'loss_2': 0.0055694580078125, 'loss_3': -16.31818962097168, 'loss_4': 1.9301204681396484, 'epoch': 15.65}
{'loss': 0.0095, 'grad_norm': 5.106175899505615, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.00885026901960373, 'loss_2': 0.000690460205078125, 'loss_3': -16.23070526123047, 'loss_4': 1.794700264930725, 'epoch': 15.65}
{'loss': 0.0132, 'grad_norm': 4.9834818840026855, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.005787293892353773, 'loss_2': 0.0074005126953125, 'loss_3': -16.39650535583496, 'loss_4': 2.495762348175049, 'epoch': 15.66}
{'loss': 0.0078, 'grad_norm': 5.218512058258057, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.004557610489428043, 'loss_2': 0.0032215118408203125, 'loss_3': -16.226486206054688, 'loss_4': 2.289722204208374, 'epoch': 15.66}
{'loss': 0.016, 'grad_norm': 6.318636417388916, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.012356694787740707, 'loss_2': 0.003620147705078125, 'loss_3': -16.44770050048828, 'loss_4': 1.9219720363616943, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 10:30:28,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:28,258 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:42<42:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:35,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013427299447357655, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009766736067831516, 'eval_loss_2': 0.0036605633795261383, 'eval_loss_3': -18.276533126831055, 'eval_loss_4': 1.7849750518798828, 'epoch': 15.67}
{'loss': 0.007, 'grad_norm': 5.010298252105713, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.005717044230550528, 'loss_2': 0.0013256072998046875, 'loss_3': -16.678369522094727, 'loss_4': 1.913098692893982, 'epoch': 15.67}
{'loss': 0.0056, 'grad_norm': 4.823343276977539, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.004209567792713642, 'loss_2': 0.0014047622680664062, 'loss_3': -16.6989803314209, 'loss_4': 2.712289333343506, 'epoch': 15.68}
{'loss': 0.0084, 'grad_norm': 4.2297797203063965, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.003874489339068532, 'loss_2': 0.00457000732421875, 'loss_3': -16.47913932800293, 'loss_4': 1.1724828481674194, 'epoch': 15.69}
{'loss': 0.0117, 'grad_norm': 6.636640548706055, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.007439295761287212, 'loss_2': 0.0042877197265625, 'loss_3': -16.475175857543945, 'loss_4': 2.3216841220855713, 'epoch': 15.69}
{'loss': 0.0297, 'grad_norm': 14.928305625915527, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.027590101584792137, 'loss_2': 0.002071380615234375, 'loss_3': -16.314250946044922, 'loss_4': 1.9712191820144653, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 10:30:35,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:35,603 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:50<42:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:42,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014879938215017319, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009425799362361431, 'eval_loss_2': 0.005454137921333313, 'eval_loss_3': -18.265607833862305, 'eval_loss_4': 1.7751439809799194, 'epoch': 15.7}
{'loss': 0.0114, 'grad_norm': 5.015563011169434, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.004135156981647015, 'loss_2': 0.007293701171875, 'loss_3': -16.225173950195312, 'loss_4': 1.3670680522918701, 'epoch': 15.7}
{'loss': 0.0136, 'grad_norm': 6.878469467163086, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.013303304091095924, 'loss_2': 0.0003256797790527344, 'loss_3': -16.47667694091797, 'loss_4': 2.2518720626831055, 'epoch': 15.71}
{'loss': 0.0142, 'grad_norm': 5.341423988342285, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.007937366142868996, 'loss_2': 0.00624847412109375, 'loss_3': -16.414203643798828, 'loss_4': 2.159700632095337, 'epoch': 15.72}
{'loss': 0.0258, 'grad_norm': 11.73489761352539, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.024363849312067032, 'loss_2': 0.001434326171875, 'loss_3': -16.38595962524414, 'loss_4': 1.4323315620422363, 'epoch': 15.72}
{'loss': 0.0127, 'grad_norm': 6.108761787414551, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.011812559328973293, 'loss_2': 0.00089263916015625, 'loss_3': -16.37190055847168, 'loss_4': 2.2989091873168945, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 10:30:42,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:42,951 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:06:57<42:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:50,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017740579321980476, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00991174578666687, 'eval_loss_2': 0.007828831672668457, 'eval_loss_3': -18.273399353027344, 'eval_loss_4': 1.7388163805007935, 'epoch': 15.73}
{'loss': 0.0134, 'grad_norm': 6.409296989440918, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.013263150118291378, 'loss_2': 0.00012886524200439453, 'loss_3': -16.326448440551758, 'loss_4': 2.0093865394592285, 'epoch': 15.73}
{'loss': 0.0136, 'grad_norm': 4.663494110107422, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.0052091870456933975, 'loss_2': 0.00836944580078125, 'loss_3': -16.347185134887695, 'loss_4': 1.947934627532959, 'epoch': 15.74}
{'loss': 0.0118, 'grad_norm': 5.0278191566467285, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.0056889597326517105, 'loss_2': 0.0060882568359375, 'loss_3': -16.526771545410156, 'loss_4': 2.476902961730957, 'epoch': 15.74}
{'loss': 0.0179, 'grad_norm': 6.582447528839111, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.011739074252545834, 'loss_2': 0.00618743896484375, 'loss_3': -16.242292404174805, 'loss_4': 2.3906285762786865, 'epoch': 15.75}
{'loss': 0.0068, 'grad_norm': 4.637111186981201, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.004591583274304867, 'loss_2': 0.0021724700927734375, 'loss_3': -16.490806579589844, 'loss_4': 2.0129756927490234, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 10:30:50,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:50,297 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:04<42:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:30:57,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014025205746293068, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.169, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.008614295162260532, 'eval_loss_2': 0.005410909652709961, 'eval_loss_3': -18.254356384277344, 'eval_loss_4': 1.5060145854949951, 'epoch': 15.76}
{'loss': 0.0103, 'grad_norm': 5.333237648010254, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.007048329804092646, 'loss_2': 0.00327301025390625, 'loss_3': -16.413639068603516, 'loss_4': 1.9792451858520508, 'epoch': 15.76}
{'loss': 0.0136, 'grad_norm': 6.558403968811035, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.011375738307833672, 'loss_2': 0.00225067138671875, 'loss_3': -16.270153045654297, 'loss_4': 2.324969530105591, 'epoch': 15.77}
{'loss': 0.0082, 'grad_norm': 4.744213581085205, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.005608099978417158, 'loss_2': 0.0025882720947265625, 'loss_3': -16.388774871826172, 'loss_4': 1.9406616687774658, 'epoch': 15.77}
{'loss': 0.0125, 'grad_norm': 5.6940388679504395, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.01074276678264141, 'loss_2': 0.001800537109375, 'loss_3': -16.37582015991211, 'loss_4': 1.8588428497314453, 'epoch': 15.78}
{'loss': 0.013, 'grad_norm': 6.567999362945557, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.009969066828489304, 'loss_2': 0.003009796142578125, 'loss_3': -16.359004974365234, 'loss_4': 1.872357726097107, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 10:30:57,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:30:57,655 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:12<42:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:04,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012607406824827194, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.174, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009128432720899582, 'eval_loss_2': 0.0034789741039276123, 'eval_loss_3': -18.24726104736328, 'eval_loss_4': 1.2731835842132568, 'epoch': 15.78}
{'loss': 0.0078, 'grad_norm': 5.695226192474365, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.005771706346422434, 'loss_2': 0.0020751953125, 'loss_3': -16.388656616210938, 'loss_4': 2.0422842502593994, 'epoch': 15.79}
{'loss': 0.0357, 'grad_norm': 13.35340690612793, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.0346706248819828, 'loss_2': 0.000980377197265625, 'loss_3': -16.446529388427734, 'loss_4': 2.9728031158447266, 'epoch': 15.8}
{'loss': 0.0096, 'grad_norm': 4.867257118225098, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.0076160370372235775, 'loss_2': 0.0019359588623046875, 'loss_3': -16.32088279724121, 'loss_4': 0.999858558177948, 'epoch': 15.8}
{'loss': 0.0159, 'grad_norm': 5.970003604888916, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.009106824174523354, 'loss_2': 0.00679779052734375, 'loss_3': -16.22991180419922, 'loss_4': 2.187379837036133, 'epoch': 15.81}
{'loss': 0.0082, 'grad_norm': 4.986518859863281, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.005164421163499355, 'loss_2': 0.00305938720703125, 'loss_3': -16.50649642944336, 'loss_4': 1.290344476699829, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 10:31:04,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:04,997 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:19<42:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:12,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013310704380273819, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.103, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008051756769418716, 'eval_loss_2': 0.0052589476108551025, 'eval_loss_3': -18.2440185546875, 'eval_loss_4': 1.330570101737976, 'epoch': 15.81}
{'loss': 0.0114, 'grad_norm': 5.802212715148926, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.007119590416550636, 'loss_2': 0.004329681396484375, 'loss_3': -16.311153411865234, 'loss_4': 0.9667778611183167, 'epoch': 15.82}
{'loss': 0.0068, 'grad_norm': 4.702856540679932, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.003775201505050063, 'loss_2': 0.003047943115234375, 'loss_3': -16.61742401123047, 'loss_4': 1.7413517236709595, 'epoch': 15.83}
{'loss': 0.0187, 'grad_norm': 11.734660148620605, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.011023679748177528, 'loss_2': 0.00768280029296875, 'loss_3': -16.413969039916992, 'loss_4': 1.5725376605987549, 'epoch': 15.83}
{'loss': 0.0176, 'grad_norm': 4.781486511230469, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.0057831741869449615, 'loss_2': 0.011810302734375, 'loss_3': -16.16776466369629, 'loss_4': 1.5022063255310059, 'epoch': 15.84}
{'loss': 0.0135, 'grad_norm': 6.783824443817139, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.009644930250942707, 'loss_2': 0.00386810302734375, 'loss_3': -16.277048110961914, 'loss_4': 1.6811444759368896, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 10:31:12,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:12,339 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:26<41:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:19,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010067393071949482, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006369893439114094, 'eval_loss_2': 0.003697499632835388, 'eval_loss_3': -18.22467803955078, 'eval_loss_4': 1.622793436050415, 'epoch': 15.84}
{'loss': 0.0213, 'grad_norm': 9.503937721252441, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.016791587695479393, 'loss_2': 0.004486083984375, 'loss_3': -16.39991569519043, 'loss_4': 1.8760894536972046, 'epoch': 15.85}
{'loss': 0.0072, 'grad_norm': 4.3054094314575195, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.005558860022574663, 'loss_2': 0.001651763916015625, 'loss_3': -16.38070297241211, 'loss_4': 1.4851460456848145, 'epoch': 15.85}
{'loss': 0.0127, 'grad_norm': 6.17873477935791, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.010344266891479492, 'loss_2': 0.002349853515625, 'loss_3': -16.372478485107422, 'loss_4': 1.7759653329849243, 'epoch': 15.86}
{'loss': 0.0101, 'grad_norm': 4.735747814178467, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.00516957463696599, 'loss_2': 0.00496673583984375, 'loss_3': -16.667755126953125, 'loss_4': 2.6689932346343994, 'epoch': 15.87}
{'loss': 0.0099, 'grad_norm': 5.251248836517334, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.007749936077743769, 'loss_2': 0.002193450927734375, 'loss_3': -16.183507919311523, 'loss_4': 2.2896852493286133, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 10:31:19,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:19,677 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:34<41:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:27,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009029890410602093, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006276386324316263, 'eval_loss_2': 0.0027535036206245422, 'eval_loss_3': -18.23199462890625, 'eval_loss_4': 1.8324806690216064, 'epoch': 15.87}
{'loss': 0.0363, 'grad_norm': 18.919681549072266, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.03402980417013168, 'loss_2': 0.002231597900390625, 'loss_3': -16.405548095703125, 'loss_4': 1.903928279876709, 'epoch': 15.88}
{'loss': 0.0081, 'grad_norm': 5.031657695770264, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.005957378074526787, 'loss_2': 0.00209808349609375, 'loss_3': -16.52893829345703, 'loss_4': 2.6456332206726074, 'epoch': 15.88}
{'loss': 0.0258, 'grad_norm': 13.401676177978516, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.022343933582305908, 'loss_2': 0.0034503936767578125, 'loss_3': -16.346017837524414, 'loss_4': 2.788184404373169, 'epoch': 15.89}
{'loss': 0.0425, 'grad_norm': 19.287582397460938, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.03851614147424698, 'loss_2': 0.0040130615234375, 'loss_3': -16.414663314819336, 'loss_4': 2.4183778762817383, 'epoch': 15.9}
{'loss': 0.0175, 'grad_norm': 7.585843563079834, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.014855433255434036, 'loss_2': 0.002658843994140625, 'loss_3': -16.319866180419922, 'loss_4': 2.225471019744873, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 10:31:27,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:27,019 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:41<41:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:34,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009664291515946388, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.034, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006734921131283045, 'eval_loss_2': 0.0029293708503246307, 'eval_loss_3': -18.25060272216797, 'eval_loss_4': 1.9343981742858887, 'epoch': 15.9}
{'loss': 0.0056, 'grad_norm': 4.778161525726318, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.005140878725796938, 'loss_2': 0.000457763671875, 'loss_3': -16.207984924316406, 'loss_4': 2.108793020248413, 'epoch': 15.91}
{'loss': 0.0175, 'grad_norm': 6.525789737701416, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.014690560288727283, 'loss_2': 0.002841949462890625, 'loss_3': -16.29920768737793, 'loss_4': 2.5502305030822754, 'epoch': 15.91}
{'loss': 0.0091, 'grad_norm': 4.905062675476074, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.007333338726311922, 'loss_2': 0.0017824172973632812, 'loss_3': -16.348173141479492, 'loss_4': 2.4101171493530273, 'epoch': 15.92}
{'loss': 0.0295, 'grad_norm': 13.425832748413086, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.02312641218304634, 'loss_2': 0.006389617919921875, 'loss_3': -16.27363395690918, 'loss_4': 1.7971687316894531, 'epoch': 15.92}
{'loss': 0.0094, 'grad_norm': 5.118628978729248, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.007485743146389723, 'loss_2': 0.0019083023071289062, 'loss_3': -16.6415958404541, 'loss_4': 1.9648199081420898, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 10:31:34,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:34,364 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:49<43:25,  1.08s/it][INFO|trainer.py:4226] 2025-01-21 10:31:41,906 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00982333067804575, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.895, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006983304396271706, 'eval_loss_2': 0.0028400272130966187, 'eval_loss_3': -18.256439208984375, 'eval_loss_4': 1.9002940654754639, 'epoch': 15.93}
{'loss': 0.0136, 'grad_norm': 6.128396034240723, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.010247087106108665, 'loss_2': 0.003322601318359375, 'loss_3': -16.153568267822266, 'loss_4': 2.076251268386841, 'epoch': 15.94}
{'loss': 0.0089, 'grad_norm': 5.307203769683838, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.006962951272726059, 'loss_2': 0.001918792724609375, 'loss_3': -16.447946548461914, 'loss_4': 2.506110906600952, 'epoch': 15.94}
{'loss': 0.016, 'grad_norm': 5.64047908782959, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.011437341570854187, 'loss_2': 0.004558563232421875, 'loss_3': -16.3432559967041, 'loss_4': 2.2770848274230957, 'epoch': 15.95}
{'loss': 0.0199, 'grad_norm': 6.968742847442627, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.017375687137246132, 'loss_2': 0.0025577545166015625, 'loss_3': -16.497318267822266, 'loss_4': 2.640918254852295, 'epoch': 15.95}
{'loss': 0.0118, 'grad_norm': 6.177034854888916, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.008345136418938637, 'loss_2': 0.00344085693359375, 'loss_3': -16.434314727783203, 'loss_4': 2.5363056659698486, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 10:31:41,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:41,907 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:07:56<41:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:31:49,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011385804042220116, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007779052015393972, 'eval_loss_2': 0.003606751561164856, 'eval_loss_3': -18.250930786132812, 'eval_loss_4': 1.9379186630249023, 'epoch': 15.96}
{'loss': 0.0073, 'grad_norm': 5.059409141540527, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.006880695931613445, 'loss_2': 0.00039577484130859375, 'loss_3': -16.011425018310547, 'loss_4': 2.2550392150878906, 'epoch': 15.97}
{'loss': 0.0214, 'grad_norm': 9.213580131530762, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.01714007928967476, 'loss_2': 0.00426483154296875, 'loss_3': -16.340286254882812, 'loss_4': 2.3333630561828613, 'epoch': 15.97}
{'loss': 0.0141, 'grad_norm': 7.7794904708862305, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.012205303646624088, 'loss_2': 0.00188446044921875, 'loss_3': -16.397581100463867, 'loss_4': 1.70758056640625, 'epoch': 15.98}
{'loss': 0.013, 'grad_norm': 6.158368110656738, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.010923235677182674, 'loss_2': 0.002063751220703125, 'loss_3': -16.52340316772461, 'loss_4': 1.6981260776519775, 'epoch': 15.98}
{'loss': 0.018, 'grad_norm': 4.771413803100586, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.00421041389927268, 'loss_2': 0.01374053955078125, 'loss_3': -16.306283950805664, 'loss_4': 2.4075889587402344, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 10:31:49,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:49,254 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:03<40:24,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:31:56,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01182843279093504, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008047613315284252, 'eval_loss_2': 0.0037808194756507874, 'eval_loss_3': -18.2451171875, 'eval_loss_4': 1.9256045818328857, 'epoch': 15.99}
{'loss': 0.016, 'grad_norm': 8.062045097351074, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.014589609578251839, 'loss_2': 0.001399993896484375, 'loss_3': -16.44522476196289, 'loss_4': 2.38928484916687, 'epoch': 15.99}
{'loss': 0.0061, 'grad_norm': 6.3521504402160645, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.002102009952068329, 'loss_2': 0.00397491455078125, 'loss_3': -16.08409309387207, 'loss_4': 1.5658023357391357, 'epoch': 16.0}
{'loss': 0.0174, 'grad_norm': 6.286831378936768, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.01660897582769394, 'loss_2': 0.0007429122924804688, 'loss_3': -16.31629753112793, 'loss_4': 1.432532787322998, 'epoch': 16.01}
{'loss': 0.0322, 'grad_norm': 11.546883583068848, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.028697369620203972, 'loss_2': 0.00347900390625, 'loss_3': -16.290966033935547, 'loss_4': 1.8008511066436768, 'epoch': 16.01}
{'loss': 0.0091, 'grad_norm': 5.049783229827881, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.008202843368053436, 'loss_2': 0.0008831024169921875, 'loss_3': -16.46619415283203, 'loss_4': 1.8626196384429932, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 10:31:56,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:31:56,288 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:10<41:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:32:03,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011793584562838078, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.762, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007046490907669067, 'eval_loss_2': 0.0047470927238464355, 'eval_loss_3': -18.25164794921875, 'eval_loss_4': 1.863520860671997, 'epoch': 16.02}
{'loss': 0.016, 'grad_norm': 13.537477493286133, 'learning_rate': 1.4e-05, 'loss_1': 0.012613972648978233, 'loss_2': 0.0033721923828125, 'loss_3': -16.40747833251953, 'loss_4': 2.150883197784424, 'epoch': 16.02}
{'loss': 0.0482, 'grad_norm': 11.876041412353516, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.04683509096503258, 'loss_2': 0.0013427734375, 'loss_3': -16.37099266052246, 'loss_4': 1.9484970569610596, 'epoch': 16.03}
{'loss': 0.0205, 'grad_norm': 6.928737640380859, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.010489022359251976, 'loss_2': 0.01001739501953125, 'loss_3': -16.411083221435547, 'loss_4': 1.8843762874603271, 'epoch': 16.03}
{'loss': 0.0161, 'grad_norm': 6.111248970031738, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.008866607211530209, 'loss_2': 0.007259368896484375, 'loss_3': -16.406835556030273, 'loss_4': 1.791059970855713, 'epoch': 16.04}
{'loss': 0.0216, 'grad_norm': 9.78074836730957, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.018008781597018242, 'loss_2': 0.00356292724609375, 'loss_3': -16.389427185058594, 'loss_4': 1.9302384853363037, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 10:32:03,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:03,631 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:18<41:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:10,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011976225301623344, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007145760580897331, 'eval_loss_2': 0.004830464720726013, 'eval_loss_3': -18.26207160949707, 'eval_loss_4': 1.7592144012451172, 'epoch': 16.05}
{'loss': 0.0124, 'grad_norm': 6.4166741371154785, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.011122969910502434, 'loss_2': 0.001323699951171875, 'loss_3': -16.355112075805664, 'loss_4': 2.6131253242492676, 'epoch': 16.05}
{'loss': 0.0208, 'grad_norm': 5.723204135894775, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.011969529092311859, 'loss_2': 0.008819580078125, 'loss_3': -16.136707305908203, 'loss_4': 1.508263111114502, 'epoch': 16.06}
{'loss': 0.0157, 'grad_norm': 6.736822605133057, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.0128698218613863, 'loss_2': 0.002864837646484375, 'loss_3': -16.335678100585938, 'loss_4': 1.4602240324020386, 'epoch': 16.06}
{'loss': 0.0078, 'grad_norm': 4.63488245010376, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.005985910072922707, 'loss_2': 0.0017986297607421875, 'loss_3': -16.619873046875, 'loss_4': 1.1355737447738647, 'epoch': 16.07}
{'loss': 0.0277, 'grad_norm': 10.094047546386719, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.022679517045617104, 'loss_2': 0.005069732666015625, 'loss_3': -16.441303253173828, 'loss_4': 2.298586368560791, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 10:32:10,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:10,983 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:25<41:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:18,345 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01022212952375412, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.379, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0066126203164458275, 'eval_loss_2': 0.0036095082759857178, 'eval_loss_3': -18.238807678222656, 'eval_loss_4': 1.8208081722259521, 'epoch': 16.08}
{'loss': 0.0115, 'grad_norm': 5.282700538635254, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.005779447499662638, 'loss_2': 0.00574493408203125, 'loss_3': -16.380680084228516, 'loss_4': 1.5447624921798706, 'epoch': 16.08}
{'loss': 0.0296, 'grad_norm': 15.840226173400879, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.0264197438955307, 'loss_2': 0.00319671630859375, 'loss_3': -16.302997589111328, 'loss_4': 1.8767094612121582, 'epoch': 16.09}
{'loss': 0.016, 'grad_norm': 6.523186683654785, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.01318002212792635, 'loss_2': 0.0028533935546875, 'loss_3': -16.350460052490234, 'loss_4': 1.7005523443222046, 'epoch': 16.09}
{'loss': 0.0069, 'grad_norm': 5.636232852935791, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.005890622269362211, 'loss_2': 0.001018524169921875, 'loss_3': -16.60689353942871, 'loss_4': 2.5831546783447266, 'epoch': 16.1}
{'loss': 0.0158, 'grad_norm': 6.179538726806641, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.008872760459780693, 'loss_2': 0.006938934326171875, 'loss_3': -16.492753982543945, 'loss_4': 2.044271469116211, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 10:32:18,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:18,346 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:32<41:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:25,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008552423678338528, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005544512532651424, 'eval_loss_2': 0.0030079111456871033, 'eval_loss_3': -18.253116607666016, 'eval_loss_4': 2.0855681896209717, 'epoch': 16.1}
{'loss': 0.0055, 'grad_norm': 4.734260082244873, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.005410881247371435, 'loss_2': 7.408857345581055e-05, 'loss_3': -16.493694305419922, 'loss_4': 1.4252163171768188, 'epoch': 16.11}
{'loss': 0.0148, 'grad_norm': 5.670238971710205, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.01155752595514059, 'loss_2': 0.0032634735107421875, 'loss_3': -16.16023063659668, 'loss_4': 1.7292152643203735, 'epoch': 16.12}
{'loss': 0.009, 'grad_norm': 5.8022236824035645, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.005861781537532806, 'loss_2': 0.003170013427734375, 'loss_3': -16.35854721069336, 'loss_4': 2.418647050857544, 'epoch': 16.12}
{'loss': 0.0096, 'grad_norm': 5.22360897064209, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.0076786368153989315, 'loss_2': 0.0019397735595703125, 'loss_3': -16.36831283569336, 'loss_4': 1.8222062587738037, 'epoch': 16.13}
{'loss': 0.0142, 'grad_norm': 5.662717819213867, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.009882308542728424, 'loss_2': 0.004322052001953125, 'loss_3': -16.559959411621094, 'loss_4': 1.7578654289245605, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 10:32:25,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:25,682 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:40<41:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:33,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010004467330873013, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.211, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005734509788453579, 'eval_loss_2': 0.004269957542419434, 'eval_loss_3': -18.266752243041992, 'eval_loss_4': 2.4551661014556885, 'epoch': 16.13}
{'loss': 0.0089, 'grad_norm': 4.7676167488098145, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.006020983215421438, 'loss_2': 0.002895355224609375, 'loss_3': -16.296550750732422, 'loss_4': 1.8586421012878418, 'epoch': 16.14}
{'loss': 0.0133, 'grad_norm': 5.052038669586182, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.008825612254440784, 'loss_2': 0.00445556640625, 'loss_3': -16.246427536010742, 'loss_4': 2.650122880935669, 'epoch': 16.15}
{'loss': 0.0184, 'grad_norm': 7.323182582855225, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.01316901296377182, 'loss_2': 0.005260467529296875, 'loss_3': -16.556825637817383, 'loss_4': 2.8111491203308105, 'epoch': 16.15}
{'loss': 0.0113, 'grad_norm': 5.029989242553711, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.005398614332079887, 'loss_2': 0.005889892578125, 'loss_3': -16.455514907836914, 'loss_4': 3.1163816452026367, 'epoch': 16.16}
{'loss': 0.0112, 'grad_norm': 5.153075695037842, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.01027197577059269, 'loss_2': 0.0008840560913085938, 'loss_3': -16.311267852783203, 'loss_4': 3.1481966972351074, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 10:32:33,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:33,027 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:47<41:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:40,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008390750735998154, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005472551565617323, 'eval_loss_2': 0.0029181987047195435, 'eval_loss_3': -18.275211334228516, 'eval_loss_4': 2.608320713043213, 'epoch': 16.16}
{'loss': 0.0096, 'grad_norm': 4.913541316986084, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.008074521087110043, 'loss_2': 0.00152587890625, 'loss_3': -16.573040008544922, 'loss_4': 2.255764961242676, 'epoch': 16.17}
{'loss': 0.0303, 'grad_norm': 12.271207809448242, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.029581405222415924, 'loss_2': 0.0006899833679199219, 'loss_3': -16.403411865234375, 'loss_4': 2.4837045669555664, 'epoch': 16.17}
{'loss': 0.0252, 'grad_norm': 9.666916847229004, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.019355706870555878, 'loss_2': 0.005859375, 'loss_3': -16.193918228149414, 'loss_4': 2.542985439300537, 'epoch': 16.18}
{'loss': 0.011, 'grad_norm': 6.114528179168701, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.008655539713799953, 'loss_2': 0.002300262451171875, 'loss_3': -16.165546417236328, 'loss_4': 2.730238437652588, 'epoch': 16.19}
{'loss': 0.0114, 'grad_norm': 5.250260829925537, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.007013669703155756, 'loss_2': 0.00438690185546875, 'loss_3': -16.31082534790039, 'loss_4': 3.1387739181518555, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 10:32:40,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:40,377 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:08:54<41:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:47,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00850258395075798, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005982656031847, 'eval_loss_2': 0.0025199279189109802, 'eval_loss_3': -18.285629272460938, 'eval_loss_4': 2.7222399711608887, 'epoch': 16.19}
{'loss': 0.0193, 'grad_norm': 5.319360256195068, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.00691796513274312, 'loss_2': 0.01242828369140625, 'loss_3': -16.34800910949707, 'loss_4': 2.7741129398345947, 'epoch': 16.2}
{'loss': 0.0081, 'grad_norm': 5.440392017364502, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.007899160496890545, 'loss_2': 0.00020503997802734375, 'loss_3': -16.20452880859375, 'loss_4': 2.673299789428711, 'epoch': 16.2}
{'loss': 0.0243, 'grad_norm': 9.594264030456543, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.023327656090259552, 'loss_2': 0.0010128021240234375, 'loss_3': -16.524179458618164, 'loss_4': 2.2734999656677246, 'epoch': 16.21}
{'loss': 0.007, 'grad_norm': 5.347146511077881, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.006422857753932476, 'loss_2': 0.0006093978881835938, 'loss_3': -16.327178955078125, 'loss_4': 2.4453954696655273, 'epoch': 16.22}
{'loss': 0.0131, 'grad_norm': 6.305341720581055, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.011404311284422874, 'loss_2': 0.0017223358154296875, 'loss_3': -16.373716354370117, 'loss_4': 2.640460729598999, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 10:32:47,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:47,725 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:02<40:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:32:55,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008860456757247448, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.879, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006081688217818737, 'eval_loss_2': 0.002778768539428711, 'eval_loss_3': -18.300010681152344, 'eval_loss_4': 2.7954697608947754, 'epoch': 16.22}
{'loss': 0.0189, 'grad_norm': 6.5825395584106445, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.015770044177770615, 'loss_2': 0.003139495849609375, 'loss_3': -16.28549575805664, 'loss_4': 2.5163140296936035, 'epoch': 16.23}
{'loss': 0.034, 'grad_norm': 10.61973762512207, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.031567782163619995, 'loss_2': 0.0024547576904296875, 'loss_3': -16.234180450439453, 'loss_4': 2.3018460273742676, 'epoch': 16.23}
{'loss': 0.0121, 'grad_norm': 4.387188911437988, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.0065200477838516235, 'loss_2': 0.00554656982421875, 'loss_3': -16.294919967651367, 'loss_4': 2.713771104812622, 'epoch': 16.24}
{'loss': 0.0261, 'grad_norm': 8.006763458251953, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.025478355586528778, 'loss_2': 0.0005741119384765625, 'loss_3': -16.55818748474121, 'loss_4': 3.3397207260131836, 'epoch': 16.24}
{'loss': 0.0138, 'grad_norm': 5.357116222381592, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.007416881155222654, 'loss_2': 0.006412506103515625, 'loss_3': -16.41444969177246, 'loss_4': 2.610663414001465, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 10:32:55,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:32:55,081 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:09<40:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:02,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01107107475399971, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.419, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006633211392909288, 'eval_loss_2': 0.004437863826751709, 'eval_loss_3': -18.319011688232422, 'eval_loss_4': 2.6579360961914062, 'epoch': 16.25}
{'loss': 0.0151, 'grad_norm': 6.356485366821289, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.013100648298859596, 'loss_2': 0.001987457275390625, 'loss_3': -16.32191276550293, 'loss_4': 2.640552520751953, 'epoch': 16.26}
{'loss': 0.0154, 'grad_norm': 6.511274814605713, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.01375163160264492, 'loss_2': 0.0016651153564453125, 'loss_3': -16.54253387451172, 'loss_4': 2.81013822555542, 'epoch': 16.26}
{'loss': 0.0098, 'grad_norm': 5.096567153930664, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.006741255987435579, 'loss_2': 0.00305938720703125, 'loss_3': -16.321346282958984, 'loss_4': 2.7716760635375977, 'epoch': 16.27}
{'loss': 0.0129, 'grad_norm': 5.423038959503174, 'learning_rate': 1.375e-05, 'loss_1': 0.010278558358550072, 'loss_2': 0.002593994140625, 'loss_3': -16.36395263671875, 'loss_4': 2.542677640914917, 'epoch': 16.27}
{'loss': 0.0235, 'grad_norm': 6.705075740814209, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.015942558646202087, 'loss_2': 0.00759124755859375, 'loss_3': -16.326828002929688, 'loss_4': 2.9182839393615723, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 10:33:02,438 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:02,438 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:16<40:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:09,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011831266805529594, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00633078720420599, 'eval_loss_2': 0.005500480532646179, 'eval_loss_3': -18.321266174316406, 'eval_loss_4': 2.6524806022644043, 'epoch': 16.28}
{'loss': 0.027, 'grad_norm': 15.116214752197266, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.020368564873933792, 'loss_2': 0.00665283203125, 'loss_3': -16.435565948486328, 'loss_4': 3.117291212081909, 'epoch': 16.28}
{'loss': 0.0081, 'grad_norm': 5.0798563957214355, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.007902846671640873, 'loss_2': 0.00018715858459472656, 'loss_3': -16.434003829956055, 'loss_4': 3.1925888061523438, 'epoch': 16.29}
{'loss': 0.0201, 'grad_norm': 6.10422420501709, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.015394497662782669, 'loss_2': 0.0047454833984375, 'loss_3': -16.396942138671875, 'loss_4': 3.031643867492676, 'epoch': 16.3}
{'loss': 0.0162, 'grad_norm': 7.388296127319336, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.016103632748126984, 'loss_2': 0.00011688470840454102, 'loss_3': -16.311744689941406, 'loss_4': 2.564229965209961, 'epoch': 16.3}
{'loss': 0.0157, 'grad_norm': 6.990686893463135, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.013437445275485516, 'loss_2': 0.0022430419921875, 'loss_3': -16.439346313476562, 'loss_4': 3.11958646774292, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 10:33:09,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:09,785 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:24<40:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:17,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010626349598169327, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0065197087824344635, 'eval_loss_2': 0.004106640815734863, 'eval_loss_3': -18.32765769958496, 'eval_loss_4': 2.6241490840911865, 'epoch': 16.31}
{'loss': 0.0183, 'grad_norm': 6.581367015838623, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.01820172555744648, 'loss_2': 6.22868537902832e-05, 'loss_3': -16.25162124633789, 'loss_4': 2.8674933910369873, 'epoch': 16.31}
{'loss': 0.0117, 'grad_norm': 6.112333297729492, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.011002040468156338, 'loss_2': 0.0006608963012695312, 'loss_3': -16.40176773071289, 'loss_4': 2.7424745559692383, 'epoch': 16.32}
{'loss': 0.0128, 'grad_norm': 5.250877380371094, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.009312057867646217, 'loss_2': 0.003490447998046875, 'loss_3': -16.503145217895508, 'loss_4': 3.200119972229004, 'epoch': 16.33}
{'loss': 0.0122, 'grad_norm': 5.460273265838623, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.009004974737763405, 'loss_2': 0.003170013427734375, 'loss_3': -16.27862548828125, 'loss_4': 1.7320406436920166, 'epoch': 16.33}
{'loss': 0.0107, 'grad_norm': 4.465676784515381, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.007297028787434101, 'loss_2': 0.0033740997314453125, 'loss_3': -16.26930809020996, 'loss_4': 3.4253313541412354, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 10:33:17,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:17,130 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:31<40:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:24,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010360416024923325, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006057377904653549, 'eval_loss_2': 0.004303038120269775, 'eval_loss_3': -18.320701599121094, 'eval_loss_4': 2.522264003753662, 'epoch': 16.34}
{'loss': 0.0236, 'grad_norm': 6.955575466156006, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.013959384523332119, 'loss_2': 0.0096893310546875, 'loss_3': -16.49776840209961, 'loss_4': 2.7445740699768066, 'epoch': 16.34}
{'loss': 0.0142, 'grad_norm': 5.553705215454102, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.00929535273462534, 'loss_2': 0.004863739013671875, 'loss_3': -16.270641326904297, 'loss_4': 2.506164073944092, 'epoch': 16.35}
{'loss': 0.0118, 'grad_norm': 5.594217777252197, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.007950672879815102, 'loss_2': 0.0038166046142578125, 'loss_3': -16.30368423461914, 'loss_4': 2.81299090385437, 'epoch': 16.35}
{'loss': 0.0102, 'grad_norm': 5.112659454345703, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.009770014323294163, 'loss_2': 0.0004591941833496094, 'loss_3': -16.21654510498047, 'loss_4': 2.9755306243896484, 'epoch': 16.36}
{'loss': 0.0174, 'grad_norm': 5.824367523193359, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.01086865458637476, 'loss_2': 0.0065765380859375, 'loss_3': -16.390865325927734, 'loss_4': 2.8523268699645996, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 10:33:24,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:24,481 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:39<40:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:31,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010297397151589394, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005933055654168129, 'eval_loss_2': 0.004364341497421265, 'eval_loss_3': -18.297245025634766, 'eval_loss_4': 2.3278939723968506, 'epoch': 16.37}
{'loss': 0.0278, 'grad_norm': 9.077258110046387, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.021883631125092506, 'loss_2': 0.005893707275390625, 'loss_3': -16.183076858520508, 'loss_4': 2.3614120483398438, 'epoch': 16.37}
{'loss': 0.0253, 'grad_norm': 11.283374786376953, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.02239532396197319, 'loss_2': 0.00292205810546875, 'loss_3': -16.14798355102539, 'loss_4': 2.8738088607788086, 'epoch': 16.38}
{'loss': 0.0055, 'grad_norm': 4.95979642868042, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.005306525621563196, 'loss_2': 0.00020122528076171875, 'loss_3': -16.547632217407227, 'loss_4': 2.329110860824585, 'epoch': 16.38}
{'loss': 0.0155, 'grad_norm': 6.727237224578857, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.01236642524600029, 'loss_2': 0.00315093994140625, 'loss_3': -16.470537185668945, 'loss_4': 2.9425065517425537, 'epoch': 16.39}
{'loss': 0.0401, 'grad_norm': 19.369754791259766, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.03921214118599892, 'loss_2': 0.000881195068359375, 'loss_3': -16.368562698364258, 'loss_4': 3.5431532859802246, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 10:33:31,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:31,828 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:46<40:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:39,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008536071516573429, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.015, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.0049711186438798904, 'eval_loss_2': 0.0035649538040161133, 'eval_loss_3': -18.30854034423828, 'eval_loss_4': 2.237781524658203, 'epoch': 16.4}
{'loss': 0.0164, 'grad_norm': 5.250959396362305, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.012170165777206421, 'loss_2': 0.004268646240234375, 'loss_3': -16.207611083984375, 'loss_4': 2.6878321170806885, 'epoch': 16.4}
{'loss': 0.0215, 'grad_norm': 8.005511283874512, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.017415205016732216, 'loss_2': 0.00406646728515625, 'loss_3': -16.217559814453125, 'loss_4': 2.0215468406677246, 'epoch': 16.41}
{'loss': 0.02, 'grad_norm': 6.579569339752197, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.010070385411381721, 'loss_2': 0.009918212890625, 'loss_3': -16.417823791503906, 'loss_4': 2.7902469635009766, 'epoch': 16.41}
{'loss': 0.0222, 'grad_norm': 8.079556465148926, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.014520198106765747, 'loss_2': 0.007659912109375, 'loss_3': -16.425670623779297, 'loss_4': 2.849494695663452, 'epoch': 16.42}
{'loss': 0.0085, 'grad_norm': 4.838334083557129, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.006268314551562071, 'loss_2': 0.00225830078125, 'loss_3': -16.31714630126953, 'loss_4': 1.8343958854675293, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 10:33:39,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:39,195 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:09:53<40:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:46,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010917878709733486, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005052916705608368, 'eval_loss_2': 0.005864962935447693, 'eval_loss_3': -18.29789161682129, 'eval_loss_4': 2.0743257999420166, 'epoch': 16.42}
{'loss': 0.0098, 'grad_norm': 4.9366278648376465, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.005843007005751133, 'loss_2': 0.004001617431640625, 'loss_3': -16.437185287475586, 'loss_4': 1.6990361213684082, 'epoch': 16.43}
{'loss': 0.0192, 'grad_norm': 5.263504981994629, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.008716416545212269, 'loss_2': 0.010498046875, 'loss_3': -16.311241149902344, 'loss_4': 2.4083964824676514, 'epoch': 16.44}
{'loss': 0.0079, 'grad_norm': 5.656014919281006, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.006433188449591398, 'loss_2': 0.0014553070068359375, 'loss_3': -16.395263671875, 'loss_4': 2.5289974212646484, 'epoch': 16.44}
{'loss': 0.0094, 'grad_norm': 5.132718563079834, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.00913805142045021, 'loss_2': 0.00023818016052246094, 'loss_3': -16.38524627685547, 'loss_4': 2.8050172328948975, 'epoch': 16.45}
{'loss': 0.0111, 'grad_norm': 5.38785457611084, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.006747400853782892, 'loss_2': 0.00432586669921875, 'loss_3': -16.34883689880371, 'loss_4': 2.9874534606933594, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 10:33:46,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:46,531 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:01<40:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:33:53,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010000191628932953, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005216262303292751, 'eval_loss_2': 0.004783928394317627, 'eval_loss_3': -18.29811668395996, 'eval_loss_4': 2.0751006603240967, 'epoch': 16.45}
{'loss': 0.0232, 'grad_norm': 8.538681983947754, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.01669778861105442, 'loss_2': 0.00650787353515625, 'loss_3': -16.55829620361328, 'loss_4': 2.522122859954834, 'epoch': 16.46}
{'loss': 0.0577, 'grad_norm': 19.22568130493164, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.05254394933581352, 'loss_2': 0.005130767822265625, 'loss_3': -16.310897827148438, 'loss_4': 1.913195013999939, 'epoch': 16.47}
{'loss': 0.0097, 'grad_norm': 4.887874126434326, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.007218881510198116, 'loss_2': 0.00252532958984375, 'loss_3': -16.26494598388672, 'loss_4': 2.2957282066345215, 'epoch': 16.47}
{'loss': 0.0129, 'grad_norm': 7.626936912536621, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.010303663089871407, 'loss_2': 0.002613067626953125, 'loss_3': -16.396066665649414, 'loss_4': 1.746431827545166, 'epoch': 16.48}
{'loss': 0.013, 'grad_norm': 6.336432456970215, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.01284389104694128, 'loss_2': 0.00020051002502441406, 'loss_3': -16.308135986328125, 'loss_4': 2.342686176300049, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 10:33:53,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:33:53,869 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:08<40:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:01,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009392205625772476, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.322, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00551403034478426, 'eval_loss_2': 0.003878176212310791, 'eval_loss_3': -18.288503646850586, 'eval_loss_4': 1.858878493309021, 'epoch': 16.48}
{'loss': 0.0121, 'grad_norm': 5.3512725830078125, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.008461639285087585, 'loss_2': 0.003612518310546875, 'loss_3': -16.336488723754883, 'loss_4': 1.6049714088439941, 'epoch': 16.49}
{'loss': 0.03, 'grad_norm': 10.271260261535645, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.02584763616323471, 'loss_2': 0.00414276123046875, 'loss_3': -16.48224639892578, 'loss_4': 2.7045140266418457, 'epoch': 16.49}
{'loss': 0.0299, 'grad_norm': 7.6094279289245605, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.020218951627612114, 'loss_2': 0.0097198486328125, 'loss_3': -16.312255859375, 'loss_4': 1.3908354043960571, 'epoch': 16.5}
{'loss': 0.01, 'grad_norm': 4.583175182342529, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.004405398387461901, 'loss_2': 0.0056304931640625, 'loss_3': -16.375329971313477, 'loss_4': 1.5046021938323975, 'epoch': 16.51}
{'loss': 0.0051, 'grad_norm': 5.1009016036987305, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.0039800615049898624, 'loss_2': 0.0011653900146484375, 'loss_3': -16.250804901123047, 'loss_4': 1.8276793956756592, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 10:34:01,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:01,212 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:15<39:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:08,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010311036370694637, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006038455758243799, 'eval_loss_2': 0.004272580146789551, 'eval_loss_3': -18.27326011657715, 'eval_loss_4': 1.5825979709625244, 'epoch': 16.51}
{'loss': 0.0204, 'grad_norm': 6.7708306312561035, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.016600869596004486, 'loss_2': 0.00382232666015625, 'loss_3': -16.377077102661133, 'loss_4': 1.6600395441055298, 'epoch': 16.52}
{'loss': 0.0072, 'grad_norm': 4.7275495529174805, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.00574441347271204, 'loss_2': 0.001483917236328125, 'loss_3': -16.2322998046875, 'loss_4': 2.0919361114501953, 'epoch': 16.52}
{'loss': 0.0135, 'grad_norm': 6.147622585296631, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.010454965755343437, 'loss_2': 0.003021240234375, 'loss_3': -16.376300811767578, 'loss_4': 1.377091884613037, 'epoch': 16.53}
{'loss': 0.0251, 'grad_norm': 8.871273040771484, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.022877758368849754, 'loss_2': 0.0021800994873046875, 'loss_3': -16.42035484313965, 'loss_4': 1.5087594985961914, 'epoch': 16.53}
{'loss': 0.0162, 'grad_norm': 6.435039043426514, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.013463204726576805, 'loss_2': 0.002777099609375, 'loss_3': -16.402202606201172, 'loss_4': 1.781966209411621, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 10:34:08,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:08,553 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:23<39:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:15,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010771929286420345, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006516038440167904, 'eval_loss_2': 0.004255890846252441, 'eval_loss_3': -18.253604888916016, 'eval_loss_4': 1.4744936227798462, 'epoch': 16.54}
{'loss': 0.0154, 'grad_norm': 5.205966472625732, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.010140170343220234, 'loss_2': 0.0052337646484375, 'loss_3': -16.321979522705078, 'loss_4': 1.852584719657898, 'epoch': 16.55}
{'loss': 0.013, 'grad_norm': 6.255316734313965, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.011923876591026783, 'loss_2': 0.001071929931640625, 'loss_3': -16.36798095703125, 'loss_4': 0.9329143166542053, 'epoch': 16.55}
{'loss': 0.0137, 'grad_norm': 4.953516006469727, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.008549786172807217, 'loss_2': 0.00519561767578125, 'loss_3': -16.24724006652832, 'loss_4': 1.607187271118164, 'epoch': 16.56}
{'loss': 0.0158, 'grad_norm': 5.980231285095215, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.009088451974093914, 'loss_2': 0.0066986083984375, 'loss_3': -16.462017059326172, 'loss_4': 1.4839825630187988, 'epoch': 16.56}
{'loss': 0.0149, 'grad_norm': 7.592035293579102, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.012874392792582512, 'loss_2': 0.002056121826171875, 'loss_3': -16.434890747070312, 'loss_4': 1.363113284111023, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 10:34:15,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:15,897 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:30<39:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:23,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009776659309864044, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.396, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005691476631909609, 'eval_loss_2': 0.004085183143615723, 'eval_loss_3': -18.256221771240234, 'eval_loss_4': 1.5685354471206665, 'epoch': 16.57}
{'loss': 0.011, 'grad_norm': 4.59792947769165, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.00510520301759243, 'loss_2': 0.005889892578125, 'loss_3': -16.551570892333984, 'loss_4': 1.5310955047607422, 'epoch': 16.58}
{'loss': 0.0125, 'grad_norm': 5.394535541534424, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.009345532394945621, 'loss_2': 0.003170013427734375, 'loss_3': -16.249486923217773, 'loss_4': 1.1916590929031372, 'epoch': 16.58}
{'loss': 0.0297, 'grad_norm': 9.376283645629883, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.027823271229863167, 'loss_2': 0.0019197463989257812, 'loss_3': -16.186538696289062, 'loss_4': 1.4840589761734009, 'epoch': 16.59}
{'loss': 0.0182, 'grad_norm': 6.306716442108154, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.013865405693650246, 'loss_2': 0.00431060791015625, 'loss_3': -16.190048217773438, 'loss_4': 1.3831348419189453, 'epoch': 16.59}
{'loss': 0.0209, 'grad_norm': 7.250753879547119, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.01973266340792179, 'loss_2': 0.00113677978515625, 'loss_3': -16.4140625, 'loss_4': 1.97214674949646, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 10:34:23,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:23,247 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:37<39:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:30,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009694244712591171, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005010958295315504, 'eval_loss_2': 0.00468328595161438, 'eval_loss_3': -18.25316619873047, 'eval_loss_4': 1.6971255540847778, 'epoch': 16.6}
{'loss': 0.0054, 'grad_norm': 4.677669525146484, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.004911791533231735, 'loss_2': 0.00048351287841796875, 'loss_3': -16.178163528442383, 'loss_4': 1.6689552068710327, 'epoch': 16.6}
{'loss': 0.0133, 'grad_norm': 4.710598945617676, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.006686780601739883, 'loss_2': 0.00658416748046875, 'loss_3': -16.227642059326172, 'loss_4': 1.522524356842041, 'epoch': 16.61}
{'loss': 0.0132, 'grad_norm': 5.287513732910156, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.006411648355424404, 'loss_2': 0.00681304931640625, 'loss_3': -16.251754760742188, 'loss_4': 2.043525457382202, 'epoch': 16.62}
{'loss': 0.0238, 'grad_norm': 8.197385787963867, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.01828758418560028, 'loss_2': 0.00556182861328125, 'loss_3': -16.506729125976562, 'loss_4': 1.6906545162200928, 'epoch': 16.62}
{'loss': 0.0344, 'grad_norm': 18.07830238342285, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.024768782779574394, 'loss_2': 0.009674072265625, 'loss_3': -16.202091217041016, 'loss_4': 2.200934886932373, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 10:34:30,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:30,593 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:45<39:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:37,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009429545141756535, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004660085309296846, 'eval_loss_2': 0.004769459366798401, 'eval_loss_3': -18.23412322998047, 'eval_loss_4': 1.7924911975860596, 'epoch': 16.63}
{'loss': 0.0274, 'grad_norm': 9.887580871582031, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.015516773797571659, 'loss_2': 0.01184844970703125, 'loss_3': -16.43421173095703, 'loss_4': 2.1884710788726807, 'epoch': 16.63}
{'loss': 0.0159, 'grad_norm': 8.833553314208984, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.01262119971215725, 'loss_2': 0.00324249267578125, 'loss_3': -16.11354637145996, 'loss_4': 2.0807952880859375, 'epoch': 16.64}
{'loss': 0.0151, 'grad_norm': 8.227973937988281, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.010601303540170193, 'loss_2': 0.00452423095703125, 'loss_3': -16.241865158081055, 'loss_4': 1.5678060054779053, 'epoch': 16.65}
{'loss': 0.011, 'grad_norm': 5.330763339996338, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.007847406901419163, 'loss_2': 0.00310516357421875, 'loss_3': -16.309581756591797, 'loss_4': 1.4759899377822876, 'epoch': 16.65}
{'loss': 0.0079, 'grad_norm': 4.713624954223633, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.005407759919762611, 'loss_2': 0.0025157928466796875, 'loss_3': -16.262344360351562, 'loss_4': 1.543336033821106, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 10:34:37,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:37,935 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:52<39:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:45,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008278468623757362, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00426689675077796, 'eval_loss_2': 0.004011571407318115, 'eval_loss_3': -18.229337692260742, 'eval_loss_4': 1.7374950647354126, 'epoch': 16.66}
{'loss': 0.013, 'grad_norm': 4.640291690826416, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.006147427950054407, 'loss_2': 0.006824493408203125, 'loss_3': -16.462766647338867, 'loss_4': 1.7607686519622803, 'epoch': 16.66}
{'loss': 0.0088, 'grad_norm': 5.244427680969238, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.007745623588562012, 'loss_2': 0.0010919570922851562, 'loss_3': -16.272083282470703, 'loss_4': 2.0382657051086426, 'epoch': 16.67}
{'loss': 0.0128, 'grad_norm': 4.495030879974365, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.0049898819997906685, 'loss_2': 0.007785797119140625, 'loss_3': -16.378807067871094, 'loss_4': 1.690946340560913, 'epoch': 16.67}
{'loss': 0.0145, 'grad_norm': 6.621805191040039, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.01435789093375206, 'loss_2': 0.0001571178436279297, 'loss_3': -16.32332992553711, 'loss_4': 2.355380058288574, 'epoch': 16.68}
{'loss': 0.011, 'grad_norm': 4.828732967376709, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.00865472387522459, 'loss_2': 0.00234222412109375, 'loss_3': -16.297718048095703, 'loss_4': 1.6281570196151733, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 10:34:45,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:45,282 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:10:59<39:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:52,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008982766419649124, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.221, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004334126133471727, 'eval_loss_2': 0.004648640751838684, 'eval_loss_3': -18.21993637084961, 'eval_loss_4': 1.614155650138855, 'epoch': 16.69}
{'loss': 0.013, 'grad_norm': 5.785519123077393, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.01130048930644989, 'loss_2': 0.0016536712646484375, 'loss_3': -16.361421585083008, 'loss_4': 2.2223496437072754, 'epoch': 16.69}
{'loss': 0.0396, 'grad_norm': 7.085839748382568, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.03347385674715042, 'loss_2': 0.00616455078125, 'loss_3': -16.2889404296875, 'loss_4': 1.8154950141906738, 'epoch': 16.7}
{'loss': 0.0135, 'grad_norm': 5.935746669769287, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.009442546404898167, 'loss_2': 0.004009246826171875, 'loss_3': -16.259206771850586, 'loss_4': 2.010356903076172, 'epoch': 16.7}
{'loss': 0.0073, 'grad_norm': 4.460937023162842, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.0035346313379704952, 'loss_2': 0.0037860870361328125, 'loss_3': -16.298803329467773, 'loss_4': 1.5189502239227295, 'epoch': 16.71}
{'loss': 0.0165, 'grad_norm': 7.761702060699463, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.013992656022310257, 'loss_2': 0.00249481201171875, 'loss_3': -16.434038162231445, 'loss_4': 1.2593730688095093, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 10:34:52,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:52,621 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:07<39:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:34:59,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008392265066504478, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.436, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005412047263234854, 'eval_loss_2': 0.0029802173376083374, 'eval_loss_3': -18.22221565246582, 'eval_loss_4': 1.449815273284912, 'epoch': 16.72}
{'loss': 0.0092, 'grad_norm': 5.248480319976807, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.005599082913249731, 'loss_2': 0.003582000732421875, 'loss_3': -16.345809936523438, 'loss_4': 1.2704999446868896, 'epoch': 16.72}
{'loss': 0.0117, 'grad_norm': 5.292975425720215, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.007784899324178696, 'loss_2': 0.003940582275390625, 'loss_3': -16.55370330810547, 'loss_4': 1.405989170074463, 'epoch': 16.73}
{'loss': 0.0151, 'grad_norm': 9.662654876708984, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.014146732166409492, 'loss_2': 0.0009355545043945312, 'loss_3': -16.42043685913086, 'loss_4': 1.1973754167556763, 'epoch': 16.73}
{'loss': 0.0116, 'grad_norm': 4.820572376251221, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.004828552715480328, 'loss_2': 0.006725311279296875, 'loss_3': -16.349308013916016, 'loss_4': 1.7846014499664307, 'epoch': 16.74}
{'loss': 0.0154, 'grad_norm': 7.303256511688232, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.012438644655048847, 'loss_2': 0.0029754638671875, 'loss_3': -16.2864990234375, 'loss_4': 1.4708993434906006, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 10:34:59,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:34:59,980 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:14<39:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:07,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00920660886913538, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.85, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005749599542468786, 'eval_loss_2': 0.003457009792327881, 'eval_loss_3': -18.21558952331543, 'eval_loss_4': 1.3930366039276123, 'epoch': 16.74}
{'loss': 0.0269, 'grad_norm': 8.901612281799316, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.01773187145590782, 'loss_2': 0.00921630859375, 'loss_3': -16.46401596069336, 'loss_4': 2.0716207027435303, 'epoch': 16.75}
{'loss': 0.0282, 'grad_norm': 11.318840980529785, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.022946590557694435, 'loss_2': 0.00528717041015625, 'loss_3': -16.35704231262207, 'loss_4': 1.7565536499023438, 'epoch': 16.76}
{'loss': 0.0142, 'grad_norm': 5.662872791290283, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.01097368635237217, 'loss_2': 0.003215789794921875, 'loss_3': -16.425838470458984, 'loss_4': 2.255814552307129, 'epoch': 16.76}
{'loss': 0.0102, 'grad_norm': 8.557794570922852, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.009810672141611576, 'loss_2': 0.0003757476806640625, 'loss_3': -16.32420539855957, 'loss_4': 1.5402581691741943, 'epoch': 16.77}
{'loss': 0.0153, 'grad_norm': 5.602185249328613, 'learning_rate': 1.325e-05, 'loss_1': 0.00985991582274437, 'loss_2': 0.0054473876953125, 'loss_3': -16.291515350341797, 'loss_4': 1.6485252380371094, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 10:35:07,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:07,320 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:21<39:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:14,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010942451655864716, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006014280021190643, 'eval_loss_2': 0.004928171634674072, 'eval_loss_3': -18.21056365966797, 'eval_loss_4': 1.3626295328140259, 'epoch': 16.77}
{'loss': 0.0098, 'grad_norm': 4.438021659851074, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.006030811928212643, 'loss_2': 0.003742218017578125, 'loss_3': -16.29540252685547, 'loss_4': 1.741589903831482, 'epoch': 16.78}
{'loss': 0.0163, 'grad_norm': 5.399518013000488, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.010432378388941288, 'loss_2': 0.005916595458984375, 'loss_3': -16.410709381103516, 'loss_4': 2.025270700454712, 'epoch': 16.78}
{'loss': 0.0108, 'grad_norm': 6.084011554718018, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.009785845875740051, 'loss_2': 0.0009665489196777344, 'loss_3': -16.182748794555664, 'loss_4': 1.4954073429107666, 'epoch': 16.79}
{'loss': 0.0164, 'grad_norm': 6.314794540405273, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.01235123723745346, 'loss_2': 0.0040283203125, 'loss_3': -16.360240936279297, 'loss_4': 1.633852243423462, 'epoch': 16.8}
{'loss': 0.034, 'grad_norm': 12.759779930114746, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.029762083664536476, 'loss_2': 0.00424957275390625, 'loss_3': -16.366802215576172, 'loss_4': 2.0675578117370605, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 10:35:14,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:14,662 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:29<39:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:21,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01052108220756054, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.512, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00609602639451623, 'eval_loss_2': 0.004425056278705597, 'eval_loss_3': -18.208209991455078, 'eval_loss_4': 1.30706787109375, 'epoch': 16.8}
{'loss': 0.0171, 'grad_norm': 8.521024703979492, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.014398531056940556, 'loss_2': 0.002689361572265625, 'loss_3': -16.365283966064453, 'loss_4': 1.4405508041381836, 'epoch': 16.81}
{'loss': 0.0151, 'grad_norm': 5.761549472808838, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.009372621774673462, 'loss_2': 0.00576019287109375, 'loss_3': -16.362163543701172, 'loss_4': 1.547641396522522, 'epoch': 16.81}
{'loss': 0.013, 'grad_norm': 4.3381195068359375, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.0058438475243747234, 'loss_2': 0.007110595703125, 'loss_3': -16.39024543762207, 'loss_4': 1.6068098545074463, 'epoch': 16.82}
{'loss': 0.0131, 'grad_norm': 4.979857921600342, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.007479414343833923, 'loss_2': 0.005603790283203125, 'loss_3': -16.28476333618164, 'loss_4': 2.0004491806030273, 'epoch': 16.83}
{'loss': 0.0356, 'grad_norm': 10.471185684204102, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.031822651624679565, 'loss_2': 0.0037822723388671875, 'loss_3': -16.030879974365234, 'loss_4': 1.6845180988311768, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 10:35:21,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:21,997 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:36<39:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:29,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00940920040011406, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.118, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0062696002423763275, 'eval_loss_2': 0.003139600157737732, 'eval_loss_3': -18.212404251098633, 'eval_loss_4': 1.41848886013031, 'epoch': 16.83}
{'loss': 0.0105, 'grad_norm': 5.225569725036621, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.0053029973059892654, 'loss_2': 0.005218505859375, 'loss_3': -16.408275604248047, 'loss_4': 1.6320905685424805, 'epoch': 16.84}
{'loss': 0.0109, 'grad_norm': 6.971785545349121, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.008985212072730064, 'loss_2': 0.0019321441650390625, 'loss_3': -16.330408096313477, 'loss_4': 1.7711329460144043, 'epoch': 16.84}
{'loss': 0.0094, 'grad_norm': 4.814291954040527, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.004233875777572393, 'loss_2': 0.00518798828125, 'loss_3': -16.440868377685547, 'loss_4': 1.2891546487808228, 'epoch': 16.85}
{'loss': 0.0095, 'grad_norm': 6.341273784637451, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.00790548324584961, 'loss_2': 0.0015735626220703125, 'loss_3': -16.288999557495117, 'loss_4': 1.432068109512329, 'epoch': 16.85}
{'loss': 0.035, 'grad_norm': 15.742587089538574, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.03464914858341217, 'loss_2': 0.00034332275390625, 'loss_3': -16.429901123046875, 'loss_4': 2.55399227142334, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 10:35:29,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:29,336 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:43<38:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:36,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009665204212069511, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006256101652979851, 'eval_loss_2': 0.0034091025590896606, 'eval_loss_3': -18.249698638916016, 'eval_loss_4': 1.5960853099822998, 'epoch': 16.86}
{'loss': 0.0182, 'grad_norm': 6.2624430656433105, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.013444647192955017, 'loss_2': 0.00475311279296875, 'loss_3': -16.29226303100586, 'loss_4': 2.48075532913208, 'epoch': 16.87}
{'loss': 0.0191, 'grad_norm': 6.096864223480225, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.009260782971978188, 'loss_2': 0.00980377197265625, 'loss_3': -16.236419677734375, 'loss_4': 1.9431002140045166, 'epoch': 16.87}
{'loss': 0.0394, 'grad_norm': 13.123492240905762, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.03478797897696495, 'loss_2': 0.004619598388671875, 'loss_3': -16.325578689575195, 'loss_4': 1.9684875011444092, 'epoch': 16.88}
{'loss': 0.0133, 'grad_norm': 4.884235382080078, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.009649105370044708, 'loss_2': 0.0036487579345703125, 'loss_3': -16.210514068603516, 'loss_4': 2.1245415210723877, 'epoch': 16.88}
{'loss': 0.0165, 'grad_norm': 5.966777324676514, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.011899503879249096, 'loss_2': 0.00464630126953125, 'loss_3': -16.154762268066406, 'loss_4': 2.543311595916748, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 10:35:36,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:36,681 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:51<38:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:44,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00982287060469389, 'eval_runtime': 3.8169, 'eval_samples_per_second': 268.277, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006279516499489546, 'eval_loss_2': 0.003543354570865631, 'eval_loss_3': -18.24002456665039, 'eval_loss_4': 1.5376081466674805, 'epoch': 16.89}
{'loss': 0.008, 'grad_norm': 5.504674911499023, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.00761632202193141, 'loss_2': 0.0004305839538574219, 'loss_3': -16.33568572998047, 'loss_4': 2.188363552093506, 'epoch': 16.9}
{'loss': 0.0147, 'grad_norm': 5.957737445831299, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.010826783254742622, 'loss_2': 0.003894805908203125, 'loss_3': -16.388317108154297, 'loss_4': 2.5382943153381348, 'epoch': 16.9}
{'loss': 0.0125, 'grad_norm': 5.552297115325928, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.011647714301943779, 'loss_2': 0.0008230209350585938, 'loss_3': -16.324966430664062, 'loss_4': 2.4095406532287598, 'epoch': 16.91}
{'loss': 0.0174, 'grad_norm': 6.4246039390563965, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.012674523517489433, 'loss_2': 0.004730224609375, 'loss_3': -16.28386688232422, 'loss_4': 1.7805733680725098, 'epoch': 16.91}
{'loss': 0.0172, 'grad_norm': 9.362519264221191, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.014358462765812874, 'loss_2': 0.0028228759765625, 'loss_3': -16.18753433227539, 'loss_4': 1.833418369293213, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 10:35:44,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:44,037 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:11:58<38:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:51,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012204502709209919, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.606, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007034544833004475, 'eval_loss_2': 0.005169957876205444, 'eval_loss_3': -18.250988006591797, 'eval_loss_4': 1.334320306777954, 'epoch': 16.92}
{'loss': 0.0108, 'grad_norm': 6.026791572570801, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.008662614971399307, 'loss_2': 0.002109527587890625, 'loss_3': -16.31450653076172, 'loss_4': 2.291914463043213, 'epoch': 16.92}
{'loss': 0.0088, 'grad_norm': 4.734779357910156, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.006455704569816589, 'loss_2': 0.002338409423828125, 'loss_3': -16.26940155029297, 'loss_4': 1.431219220161438, 'epoch': 16.93}
{'loss': 0.0128, 'grad_norm': 4.606410503387451, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.004496813751757145, 'loss_2': 0.0083465576171875, 'loss_3': -16.200382232666016, 'loss_4': 1.8449221849441528, 'epoch': 16.94}
{'loss': 0.0101, 'grad_norm': 6.106034755706787, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.009715406224131584, 'loss_2': 0.0003383159637451172, 'loss_3': -16.19654083251953, 'loss_4': 1.6391501426696777, 'epoch': 16.94}
{'loss': 0.0101, 'grad_norm': 4.897152900695801, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.005867335945367813, 'loss_2': 0.00421142578125, 'loss_3': -16.268856048583984, 'loss_4': 1.56290864944458, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 10:35:51,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:51,377 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:05<38:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:35:58,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011135036125779152, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007530699949711561, 'eval_loss_2': 0.0036043375730514526, 'eval_loss_3': -18.253820419311523, 'eval_loss_4': 1.1805121898651123, 'epoch': 16.95}
{'loss': 0.0166, 'grad_norm': 8.219559669494629, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.013802289962768555, 'loss_2': 0.0027942657470703125, 'loss_3': -16.35102653503418, 'loss_4': 1.1725482940673828, 'epoch': 16.95}
{'loss': 0.011, 'grad_norm': 4.343911170959473, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.004290329292416573, 'loss_2': 0.00669097900390625, 'loss_3': -16.268177032470703, 'loss_4': 1.4963810443878174, 'epoch': 16.96}
{'loss': 0.022, 'grad_norm': 6.271956443786621, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.014112577773630619, 'loss_2': 0.00786590576171875, 'loss_3': -16.279542922973633, 'loss_4': 1.8799304962158203, 'epoch': 16.97}
{'loss': 0.0507, 'grad_norm': 18.279203414916992, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.048247743397951126, 'loss_2': 0.002490997314453125, 'loss_3': -16.1279239654541, 'loss_4': 1.6286827325820923, 'epoch': 16.97}
{'loss': 0.0094, 'grad_norm': 5.700376033782959, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.006373419892042875, 'loss_2': 0.003070831298828125, 'loss_3': -16.403654098510742, 'loss_4': 1.2759991884231567, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 10:35:58,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:35:58,718 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:12<36:19,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 10:36:05,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011850736103951931, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008972457610070705, 'eval_loss_2': 0.0028782784938812256, 'eval_loss_3': -18.27931022644043, 'eval_loss_4': 0.9452281594276428, 'epoch': 16.98}
{'loss': 0.0401, 'grad_norm': 12.458745002746582, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.03899786248803139, 'loss_2': 0.001094818115234375, 'loss_3': -16.372467041015625, 'loss_4': 1.658847451210022, 'epoch': 16.98}
{'loss': 0.0108, 'grad_norm': 5.091135501861572, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.009486210532486439, 'loss_2': 0.0013427734375, 'loss_3': -16.233642578125, 'loss_4': 1.075892686843872, 'epoch': 16.99}
{'loss': 0.007, 'grad_norm': 5.372766017913818, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.006475457455962896, 'loss_2': 0.0004849433898925781, 'loss_3': -16.569604873657227, 'loss_4': 0.8386431336402893, 'epoch': 16.99}
{'loss': 0.0075, 'grad_norm': 6.091402530670166, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.0019668687600642443, 'loss_2': 0.005580902099609375, 'loss_3': -16.08354377746582, 'loss_4': 2.085426092147827, 'epoch': 17.0}
{'loss': 0.0179, 'grad_norm': 6.7521162033081055, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.0165159460157156, 'loss_2': 0.00133514404296875, 'loss_3': -16.423128128051758, 'loss_4': 1.0091676712036133, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 10:36:05,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:05,743 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:20<38:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:36:13,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013621503487229347, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009305769577622414, 'eval_loss_2': 0.004315733909606934, 'eval_loss_3': -18.28004264831543, 'eval_loss_4': 0.7907224297523499, 'epoch': 17.01}
{'loss': 0.0158, 'grad_norm': 5.784287929534912, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.014061246067285538, 'loss_2': 0.00174713134765625, 'loss_3': -16.618526458740234, 'loss_4': 1.8054598569869995, 'epoch': 17.01}
{'loss': 0.0143, 'grad_norm': 7.1175665855407715, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.013777593150734901, 'loss_2': 0.000499725341796875, 'loss_3': -16.374282836914062, 'loss_4': 0.9246314167976379, 'epoch': 17.02}
{'loss': 0.0183, 'grad_norm': 9.214766502380371, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.01798388548195362, 'loss_2': 0.00030517578125, 'loss_3': -16.239906311035156, 'loss_4': 0.68471360206604, 'epoch': 17.02}
{'loss': 0.0099, 'grad_norm': 5.529186725616455, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.007672460284084082, 'loss_2': 0.0021800994873046875, 'loss_3': -16.299400329589844, 'loss_4': 0.8919461965560913, 'epoch': 17.03}
{'loss': 0.0112, 'grad_norm': 6.442402362823486, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.007933354005217552, 'loss_2': 0.003276824951171875, 'loss_3': -16.344816207885742, 'loss_4': 0.8906655311584473, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 10:36:13,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:13,075 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:27<38:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:36:20,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012564181350171566, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.369, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009082190692424774, 'eval_loss_2': 0.0034819915890693665, 'eval_loss_3': -18.282724380493164, 'eval_loss_4': 0.7390776872634888, 'epoch': 17.03}
{'loss': 0.0189, 'grad_norm': 7.397610664367676, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.014505690895020962, 'loss_2': 0.00441741943359375, 'loss_3': -16.313486099243164, 'loss_4': 0.9692754745483398, 'epoch': 17.04}
{'loss': 0.0198, 'grad_norm': 6.974854469299316, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.01577780582010746, 'loss_2': 0.00403594970703125, 'loss_3': -16.25070571899414, 'loss_4': 0.6426444053649902, 'epoch': 17.05}
{'loss': 0.025, 'grad_norm': 10.312322616577148, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.021952375769615173, 'loss_2': 0.00307464599609375, 'loss_3': -16.29434585571289, 'loss_4': 1.5524659156799316, 'epoch': 17.05}
{'loss': 0.0074, 'grad_norm': 5.333359718322754, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.006514431908726692, 'loss_2': 0.0008840560913085938, 'loss_3': -16.246307373046875, 'loss_4': 1.2958658933639526, 'epoch': 17.06}
{'loss': 0.0257, 'grad_norm': 11.90206241607666, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.02178419940173626, 'loss_2': 0.00388336181640625, 'loss_3': -16.121097564697266, 'loss_4': 1.2652647495269775, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 10:36:20,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:20,406 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:34<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:27,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012021093629300594, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009013338014483452, 'eval_loss_2': 0.003007754683494568, 'eval_loss_3': -18.278600692749023, 'eval_loss_4': 0.6970254778862, 'epoch': 17.06}
{'loss': 0.013, 'grad_norm': 5.630078315734863, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.011802589520812035, 'loss_2': 0.0012226104736328125, 'loss_3': -16.257984161376953, 'loss_4': 1.2078022956848145, 'epoch': 17.07}
{'loss': 0.0137, 'grad_norm': 4.645421504974365, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.006113671697676182, 'loss_2': 0.00757598876953125, 'loss_3': -16.459291458129883, 'loss_4': 0.5815359354019165, 'epoch': 17.08}
{'loss': 0.0089, 'grad_norm': 4.9111552238464355, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.007180705200880766, 'loss_2': 0.0017547607421875, 'loss_3': -16.405712127685547, 'loss_4': 0.8336418867111206, 'epoch': 17.08}
{'loss': 0.0121, 'grad_norm': 5.631033420562744, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.009621557779610157, 'loss_2': 0.00246429443359375, 'loss_3': -16.281206130981445, 'loss_4': 0.8810387849807739, 'epoch': 17.09}
{'loss': 0.0117, 'grad_norm': 5.634068012237549, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.008240235969424248, 'loss_2': 0.0034885406494140625, 'loss_3': -16.253313064575195, 'loss_4': 0.24504804611206055, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 10:36:27,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:27,744 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:42<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:35,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013268590904772282, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00889665074646473, 'eval_loss_2': 0.004371941089630127, 'eval_loss_3': -18.25959014892578, 'eval_loss_4': 0.7880422472953796, 'epoch': 17.09}
{'loss': 0.0097, 'grad_norm': 4.583509922027588, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.006697303149849176, 'loss_2': 0.002956390380859375, 'loss_3': -16.39307403564453, 'loss_4': 0.8810439109802246, 'epoch': 17.1}
{'loss': 0.0155, 'grad_norm': 5.065147399902344, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.0067399172112345695, 'loss_2': 0.00872039794921875, 'loss_3': -16.315996170043945, 'loss_4': 1.2201411724090576, 'epoch': 17.1}
{'loss': 0.017, 'grad_norm': 6.00056791305542, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.0127319460734725, 'loss_2': 0.00423431396484375, 'loss_3': -16.43809700012207, 'loss_4': 1.2177196741104126, 'epoch': 17.11}
{'loss': 0.0173, 'grad_norm': 8.015832901000977, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.010581145994365215, 'loss_2': 0.0067596435546875, 'loss_3': -16.221515655517578, 'loss_4': 0.908936619758606, 'epoch': 17.12}
{'loss': 0.0134, 'grad_norm': 5.6105194091796875, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.010474678128957748, 'loss_2': 0.002960205078125, 'loss_3': -16.316316604614258, 'loss_4': 1.675605297088623, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 10:36:35,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:35,092 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:49<38:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:42,438 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01334063895046711, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008697541430592537, 'eval_loss_2': 0.004643097519874573, 'eval_loss_3': -18.25743865966797, 'eval_loss_4': 0.9336085319519043, 'epoch': 17.12}
{'loss': 0.0173, 'grad_norm': 9.650673866271973, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.010543640702962875, 'loss_2': 0.006732940673828125, 'loss_3': -16.161821365356445, 'loss_4': 1.1264896392822266, 'epoch': 17.13}
{'loss': 0.0076, 'grad_norm': 5.046757698059082, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.0065462589263916016, 'loss_2': 0.001094818115234375, 'loss_3': -16.466779708862305, 'loss_4': 0.7368415594100952, 'epoch': 17.13}
{'loss': 0.0153, 'grad_norm': 6.848723411560059, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.013860107399523258, 'loss_2': 0.00146484375, 'loss_3': -16.251678466796875, 'loss_4': 1.0668039321899414, 'epoch': 17.14}
{'loss': 0.0074, 'grad_norm': 5.108897686004639, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.006428589578717947, 'loss_2': 0.0010061264038085938, 'loss_3': -16.335166931152344, 'loss_4': 1.4243992567062378, 'epoch': 17.15}
{'loss': 0.0307, 'grad_norm': 9.891267776489258, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.027891239151358604, 'loss_2': 0.0028095245361328125, 'loss_3': -16.29906463623047, 'loss_4': 1.1515388488769531, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 10:36:42,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:42,439 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:12:56<38:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:49,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011526349931955338, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007934813387691975, 'eval_loss_2': 0.0035915374755859375, 'eval_loss_3': -18.276947021484375, 'eval_loss_4': 1.0652027130126953, 'epoch': 17.15}
{'loss': 0.022, 'grad_norm': 8.518756866455078, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.013578499667346478, 'loss_2': 0.0084228515625, 'loss_3': -16.460468292236328, 'loss_4': 1.5581272840499878, 'epoch': 17.16}
{'loss': 0.0147, 'grad_norm': 7.554410457611084, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.01264200173318386, 'loss_2': 0.00208282470703125, 'loss_3': -16.26011848449707, 'loss_4': 0.7654299736022949, 'epoch': 17.16}
{'loss': 0.0462, 'grad_norm': 14.82787036895752, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.04259200394153595, 'loss_2': 0.0036029815673828125, 'loss_3': -16.18391227722168, 'loss_4': 0.8383656144142151, 'epoch': 17.17}
{'loss': 0.0128, 'grad_norm': 5.250901699066162, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.010746929794549942, 'loss_2': 0.00209808349609375, 'loss_3': -16.54013442993164, 'loss_4': 1.0073678493499756, 'epoch': 17.17}
{'loss': 0.0294, 'grad_norm': 12.657282829284668, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.02197324112057686, 'loss_2': 0.00742340087890625, 'loss_3': -16.397363662719727, 'loss_4': 1.418212890625, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 10:36:49,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:49,784 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:04<37:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:36:57,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011798959225416183, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008699917234480381, 'eval_loss_2': 0.003099042922258377, 'eval_loss_3': -18.285009384155273, 'eval_loss_4': 1.117695927619934, 'epoch': 17.18}
{'loss': 0.0142, 'grad_norm': 5.00242805480957, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.009585285559296608, 'loss_2': 0.00460052490234375, 'loss_3': -16.391231536865234, 'loss_4': 0.7447552680969238, 'epoch': 17.19}
{'loss': 0.0123, 'grad_norm': 5.929168224334717, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.010758032090961933, 'loss_2': 0.0015277862548828125, 'loss_3': -16.370792388916016, 'loss_4': 1.1056137084960938, 'epoch': 17.19}
{'loss': 0.014, 'grad_norm': 5.424129486083984, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.010978379286825657, 'loss_2': 0.0030612945556640625, 'loss_3': -16.243783950805664, 'loss_4': 1.1422061920166016, 'epoch': 17.2}
{'loss': 0.0102, 'grad_norm': 4.912378311157227, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.009253188036382198, 'loss_2': 0.0009126663208007812, 'loss_3': -16.3869686126709, 'loss_4': 0.516011118888855, 'epoch': 17.2}
{'loss': 0.0132, 'grad_norm': 5.395931720733643, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.011525065638124943, 'loss_2': 0.0016422271728515625, 'loss_3': -16.300533294677734, 'loss_4': 0.4849058985710144, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 10:36:57,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:36:57,120 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:11<37:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:04,464 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012939744628965855, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.928, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008977288380265236, 'eval_loss_2': 0.003962457180023193, 'eval_loss_3': -18.28350067138672, 'eval_loss_4': 0.90945965051651, 'epoch': 17.21}
{'loss': 0.0159, 'grad_norm': 7.653023719787598, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.012906682677567005, 'loss_2': 0.002971649169921875, 'loss_3': -16.40526008605957, 'loss_4': 1.1565430164337158, 'epoch': 17.22}
{'loss': 0.0231, 'grad_norm': 11.96815299987793, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.023008044809103012, 'loss_2': 0.0001176595687866211, 'loss_3': -16.509830474853516, 'loss_4': 1.0095309019088745, 'epoch': 17.22}
{'loss': 0.0171, 'grad_norm': 6.20526647567749, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.01300861220806837, 'loss_2': 0.00412750244140625, 'loss_3': -16.436891555786133, 'loss_4': 1.4127609729766846, 'epoch': 17.23}
{'loss': 0.0188, 'grad_norm': 6.886764049530029, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.017371632158756256, 'loss_2': 0.0014743804931640625, 'loss_3': -16.333980560302734, 'loss_4': 1.1250736713409424, 'epoch': 17.23}
{'loss': 0.0289, 'grad_norm': 9.294058799743652, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.02742558717727661, 'loss_2': 0.00147247314453125, 'loss_3': -16.370088577270508, 'loss_4': 1.402551293373108, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 10:37:04,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:04,464 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:19<37:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:11,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014423605985939503, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.629, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008068155497312546, 'eval_loss_2': 0.006355449557304382, 'eval_loss_3': -18.291887283325195, 'eval_loss_4': 0.8292528390884399, 'epoch': 17.24}
{'loss': 0.0122, 'grad_norm': 4.893815994262695, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.005938108544796705, 'loss_2': 0.0062255859375, 'loss_3': -16.58194923400879, 'loss_4': 0.3537406027317047, 'epoch': 17.24}
{'loss': 0.0133, 'grad_norm': 5.928434371948242, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.012817521579563618, 'loss_2': 0.0004968643188476562, 'loss_3': -16.29082489013672, 'loss_4': 0.8220933079719543, 'epoch': 17.25}
{'loss': 0.0132, 'grad_norm': 5.358518600463867, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.009039750322699547, 'loss_2': 0.004169464111328125, 'loss_3': -16.46800994873047, 'loss_4': 0.6275432705879211, 'epoch': 17.26}
{'loss': 0.0202, 'grad_norm': 7.938948631286621, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.012643424794077873, 'loss_2': 0.00757598876953125, 'loss_3': -16.225217819213867, 'loss_4': 0.9063357710838318, 'epoch': 17.26}
{'loss': 0.026, 'grad_norm': 6.217501640319824, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.013700026087462902, 'loss_2': 0.0123443603515625, 'loss_3': -16.57036590576172, 'loss_4': 0.873610258102417, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 10:37:11,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:11,799 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:26<37:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:19,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014594011940062046, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.39, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008047216571867466, 'eval_loss_2': 0.00654679536819458, 'eval_loss_3': -18.290843963623047, 'eval_loss_4': 0.7184766530990601, 'epoch': 17.27}
{'loss': 0.0145, 'grad_norm': 5.8437180519104, 'learning_rate': 1.275e-05, 'loss_1': 0.011698189191520214, 'loss_2': 0.0027637481689453125, 'loss_3': -16.350162506103516, 'loss_4': 1.335719347000122, 'epoch': 17.27}
{'loss': 0.0206, 'grad_norm': 10.090328216552734, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.017086651176214218, 'loss_2': 0.0035400390625, 'loss_3': -16.338665008544922, 'loss_4': 0.8040788173675537, 'epoch': 17.28}
{'loss': 0.0122, 'grad_norm': 5.6205620765686035, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.009147957898676395, 'loss_2': 0.0030364990234375, 'loss_3': -16.416629791259766, 'loss_4': 0.5814922451972961, 'epoch': 17.28}
{'loss': 0.021, 'grad_norm': 10.614599227905273, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.020341496914625168, 'loss_2': 0.0006480216979980469, 'loss_3': -16.385498046875, 'loss_4': 0.8750208020210266, 'epoch': 17.29}
{'loss': 0.0114, 'grad_norm': 5.3928751945495605, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.0070899976417422295, 'loss_2': 0.00429534912109375, 'loss_3': -16.21476936340332, 'loss_4': 0.9753522276878357, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 10:37:19,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:19,140 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:33<37:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:26,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012812095694243908, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008479224517941475, 'eval_loss_2': 0.004332870244979858, 'eval_loss_3': -18.287784576416016, 'eval_loss_4': 0.6703367829322815, 'epoch': 17.3}
{'loss': 0.0123, 'grad_norm': 4.875742435455322, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.010606029070913792, 'loss_2': 0.001712799072265625, 'loss_3': -16.413867950439453, 'loss_4': 0.6777448058128357, 'epoch': 17.3}
{'loss': 0.0191, 'grad_norm': 6.51742696762085, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.016175517812371254, 'loss_2': 0.002895355224609375, 'loss_3': -16.246313095092773, 'loss_4': 0.98199462890625, 'epoch': 17.31}
{'loss': 0.0109, 'grad_norm': 6.630581855773926, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.01028610859066248, 'loss_2': 0.0005831718444824219, 'loss_3': -16.561115264892578, 'loss_4': 0.46873706579208374, 'epoch': 17.31}
{'loss': 0.0178, 'grad_norm': 9.332633972167969, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.01681322604417801, 'loss_2': 0.0009641647338867188, 'loss_3': -16.199588775634766, 'loss_4': 0.9545722603797913, 'epoch': 17.32}
{'loss': 0.0116, 'grad_norm': 7.289380073547363, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.011225092224776745, 'loss_2': 0.0003516674041748047, 'loss_3': -16.261592864990234, 'loss_4': 0.5732409358024597, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 10:37:26,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:26,476 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:41<37:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:33,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01314812432974577, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008572792634367943, 'eval_loss_2': 0.004575330764055252, 'eval_loss_3': -18.280344009399414, 'eval_loss_4': 0.746208906173706, 'epoch': 17.33}
{'loss': 0.0304, 'grad_norm': 15.12427806854248, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.030303433537483215, 'loss_2': 5.602836608886719e-05, 'loss_3': -16.256099700927734, 'loss_4': 1.3959896564483643, 'epoch': 17.33}
{'loss': 0.0185, 'grad_norm': 7.3872551918029785, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.015769511461257935, 'loss_2': 0.0027027130126953125, 'loss_3': -16.490324020385742, 'loss_4': 1.102898120880127, 'epoch': 17.34}
{'loss': 0.0173, 'grad_norm': 9.537919998168945, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.014727138914167881, 'loss_2': 0.002529144287109375, 'loss_3': -16.48345947265625, 'loss_4': 0.6621487140655518, 'epoch': 17.34}
{'loss': 0.0493, 'grad_norm': 25.888687133789062, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.04677809029817581, 'loss_2': 0.0025634765625, 'loss_3': -16.19658851623535, 'loss_4': 1.3255583047866821, 'epoch': 17.35}
{'loss': 0.0167, 'grad_norm': 6.858258247375488, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.013089556246995926, 'loss_2': 0.0036067962646484375, 'loss_3': -16.34866714477539, 'loss_4': 0.460382878780365, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 10:37:33,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:33,822 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:48<37:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:41,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014262259006500244, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.198, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008890122175216675, 'eval_loss_2': 0.005372136831283569, 'eval_loss_3': -18.27737808227539, 'eval_loss_4': 0.8659670948982239, 'epoch': 17.35}
{'loss': 0.0249, 'grad_norm': 9.992499351501465, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.02120680920779705, 'loss_2': 0.00366973876953125, 'loss_3': -16.55414581298828, 'loss_4': 0.9012498259544373, 'epoch': 17.36}
{'loss': 0.0253, 'grad_norm': 10.153558731079102, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.01824771612882614, 'loss_2': 0.00705718994140625, 'loss_3': -16.451135635375977, 'loss_4': 0.9898560643196106, 'epoch': 17.37}
{'loss': 0.0137, 'grad_norm': 5.077433109283447, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.009366914629936218, 'loss_2': 0.0043182373046875, 'loss_3': -16.356809616088867, 'loss_4': 0.8847506642341614, 'epoch': 17.37}
{'loss': 0.0156, 'grad_norm': 6.080395221710205, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.015544218011200428, 'loss_2': 8.118152618408203e-05, 'loss_3': -16.22049331665039, 'loss_4': 0.9737178087234497, 'epoch': 17.38}
{'loss': 0.0105, 'grad_norm': 5.046358585357666, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.00955779105424881, 'loss_2': 0.0009469985961914062, 'loss_3': -16.562236785888672, 'loss_4': 0.9589346647262573, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 10:37:41,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:41,164 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:13:55<37:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:48,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01337837241590023, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.649, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007922491058707237, 'eval_loss_2': 0.005455881357192993, 'eval_loss_3': -18.25560188293457, 'eval_loss_4': 0.9438163638114929, 'epoch': 17.38}
{'loss': 0.0233, 'grad_norm': 7.112488269805908, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.02183874137699604, 'loss_2': 0.0014972686767578125, 'loss_3': -16.277507781982422, 'loss_4': 1.289958119392395, 'epoch': 17.39}
{'loss': 0.0226, 'grad_norm': 9.082488059997559, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.017697812989354134, 'loss_2': 0.004852294921875, 'loss_3': -16.460657119750977, 'loss_4': 0.6510322093963623, 'epoch': 17.4}
{'loss': 0.0067, 'grad_norm': 4.846654415130615, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.0061262547969818115, 'loss_2': 0.00057220458984375, 'loss_3': -16.450735092163086, 'loss_4': 0.2968233525753021, 'epoch': 17.4}
{'loss': 0.0382, 'grad_norm': 13.994893074035645, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.035040657967329025, 'loss_2': 0.0032062530517578125, 'loss_3': -16.27776336669922, 'loss_4': 0.9162402153015137, 'epoch': 17.41}
{'loss': 0.0135, 'grad_norm': 5.325292110443115, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.009864812716841698, 'loss_2': 0.003665924072265625, 'loss_3': -16.339542388916016, 'loss_4': 1.4908924102783203, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 10:37:48,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:48,513 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:03<37:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:37:55,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013055803254246712, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008217932656407356, 'eval_loss_2': 0.0048378705978393555, 'eval_loss_3': -18.259199142456055, 'eval_loss_4': 0.8817260265350342, 'epoch': 17.41}
{'loss': 0.0107, 'grad_norm': 5.129045486450195, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.008562754839658737, 'loss_2': 0.0021266937255859375, 'loss_3': -16.519269943237305, 'loss_4': 1.1127649545669556, 'epoch': 17.42}
{'loss': 0.0084, 'grad_norm': 5.98607873916626, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.007744553964585066, 'loss_2': 0.0006628036499023438, 'loss_3': -16.309268951416016, 'loss_4': 0.5224204063415527, 'epoch': 17.42}
{'loss': 0.0133, 'grad_norm': 5.121710300445557, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.008230562321841717, 'loss_2': 0.00507354736328125, 'loss_3': -16.385129928588867, 'loss_4': 0.9914019703865051, 'epoch': 17.43}
{'loss': 0.0126, 'grad_norm': 4.96403169631958, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.004542757757008076, 'loss_2': 0.0080413818359375, 'loss_3': -16.48983383178711, 'loss_4': 1.5158836841583252, 'epoch': 17.44}
{'loss': 0.0095, 'grad_norm': 4.63522481918335, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.00637975987046957, 'loss_2': 0.003078460693359375, 'loss_3': -16.457904815673828, 'loss_4': 0.835539698600769, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 10:37:55,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:37:55,844 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:10<37:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:03,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012754561379551888, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008484283462166786, 'eval_loss_2': 0.004270277917385101, 'eval_loss_3': -18.25327491760254, 'eval_loss_4': 0.8192278146743774, 'epoch': 17.44}
{'loss': 0.0122, 'grad_norm': 9.06927490234375, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.012012158520519733, 'loss_2': 0.00015211105346679688, 'loss_3': -16.279319763183594, 'loss_4': 1.344874382019043, 'epoch': 17.45}
{'loss': 0.0163, 'grad_norm': 4.967591762542725, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.010192176327109337, 'loss_2': 0.006099700927734375, 'loss_3': -16.433374404907227, 'loss_4': 0.9529425501823425, 'epoch': 17.45}
{'loss': 0.0111, 'grad_norm': 6.9352874755859375, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.010213416069746017, 'loss_2': 0.0008702278137207031, 'loss_3': -16.272747039794922, 'loss_4': 0.5424917936325073, 'epoch': 17.46}
{'loss': 0.015, 'grad_norm': 5.9533209800720215, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.0072026061825454235, 'loss_2': 0.007755279541015625, 'loss_3': -16.273540496826172, 'loss_4': 1.2794885635375977, 'epoch': 17.47}
{'loss': 0.0186, 'grad_norm': 6.435176849365234, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.011146891862154007, 'loss_2': 0.007450103759765625, 'loss_3': -16.549251556396484, 'loss_4': 1.3833231925964355, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 10:38:03,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:03,185 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:17<37:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:10,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012965339235961437, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.151, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00893778633326292, 'eval_loss_2': 0.004027552902698517, 'eval_loss_3': -18.252248764038086, 'eval_loss_4': 0.6985533833503723, 'epoch': 17.47}
{'loss': 0.0108, 'grad_norm': 5.994582653045654, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.009397328831255436, 'loss_2': 0.0014438629150390625, 'loss_3': -16.421998977661133, 'loss_4': 0.772908091545105, 'epoch': 17.48}
{'loss': 0.01, 'grad_norm': 5.261949062347412, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.005734735168516636, 'loss_2': 0.0042266845703125, 'loss_3': -16.440792083740234, 'loss_4': 1.0527406930923462, 'epoch': 17.48}
{'loss': 0.0072, 'grad_norm': 4.568288326263428, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.0037693376652896404, 'loss_2': 0.0034580230712890625, 'loss_3': -16.308406829833984, 'loss_4': 1.2261183261871338, 'epoch': 17.49}
{'loss': 0.0114, 'grad_norm': 4.549709320068359, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.004948161076754332, 'loss_2': 0.006458282470703125, 'loss_3': -16.392642974853516, 'loss_4': 0.6877458095550537, 'epoch': 17.49}
{'loss': 0.0118, 'grad_norm': 4.757082939147949, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.0052330088801681995, 'loss_2': 0.006557464599609375, 'loss_3': -16.39192008972168, 'loss_4': 0.39323946833610535, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 10:38:10,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:10,523 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:25<37:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:17,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013172595761716366, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009231059812009335, 'eval_loss_2': 0.003941535949707031, 'eval_loss_3': -18.260393142700195, 'eval_loss_4': 0.5773355960845947, 'epoch': 17.5}
{'loss': 0.0082, 'grad_norm': 4.764791965484619, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.0054517751559615135, 'loss_2': 0.00274658203125, 'loss_3': -16.474557876586914, 'loss_4': 0.5652130842208862, 'epoch': 17.51}
{'loss': 0.0081, 'grad_norm': 5.644938945770264, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.007843215949833393, 'loss_2': 0.00030612945556640625, 'loss_3': -16.506071090698242, 'loss_4': 0.7688260674476624, 'epoch': 17.51}
{'loss': 0.0277, 'grad_norm': 18.494915008544922, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.024074919521808624, 'loss_2': 0.0036373138427734375, 'loss_3': -16.361722946166992, 'loss_4': 1.6825273036956787, 'epoch': 17.52}
{'loss': 0.0126, 'grad_norm': 7.160759449005127, 'learning_rate': 1.25e-05, 'loss_1': 0.01207876205444336, 'loss_2': 0.0005016326904296875, 'loss_3': -16.152603149414062, 'loss_4': 0.7082624435424805, 'epoch': 17.52}
{'loss': 0.0213, 'grad_norm': 5.253170013427734, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.008998825214803219, 'loss_2': 0.01226806640625, 'loss_3': -16.511722564697266, 'loss_4': 0.6587100028991699, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 10:38:17,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:17,858 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:32<36:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:25,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013529722578823566, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008814340457320213, 'eval_loss_2': 0.004715383052825928, 'eval_loss_3': -18.264846801757812, 'eval_loss_4': 0.5063784718513489, 'epoch': 17.53}
{'loss': 0.0153, 'grad_norm': 6.194633960723877, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.014666128903627396, 'loss_2': 0.0006771087646484375, 'loss_3': -16.384653091430664, 'loss_4': 0.7649753093719482, 'epoch': 17.53}
{'loss': 0.0106, 'grad_norm': 5.224147796630859, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.007090211380273104, 'loss_2': 0.0035552978515625, 'loss_3': -16.318553924560547, 'loss_4': 0.5221368074417114, 'epoch': 17.54}
{'loss': 0.0076, 'grad_norm': 5.519927024841309, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.005929483566433191, 'loss_2': 0.0017080307006835938, 'loss_3': -16.09039878845215, 'loss_4': 0.4143502712249756, 'epoch': 17.55}
{'loss': 0.0167, 'grad_norm': 6.888550281524658, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.011853719130158424, 'loss_2': 0.004894256591796875, 'loss_3': -16.395240783691406, 'loss_4': 0.07230210304260254, 'epoch': 17.55}
{'loss': 0.0151, 'grad_norm': 7.019222259521484, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.0130830192938447, 'loss_2': 0.001972198486328125, 'loss_3': -16.432273864746094, 'loss_4': 0.7124593257904053, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 10:38:25,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:25,204 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:39<36:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:32,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011377235874533653, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.886, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008077530190348625, 'eval_loss_2': 0.003299705684185028, 'eval_loss_3': -18.274173736572266, 'eval_loss_4': 0.2824438214302063, 'epoch': 17.56}
{'loss': 0.0098, 'grad_norm': 5.153944969177246, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.008235679939389229, 'loss_2': 0.0015926361083984375, 'loss_3': -16.260099411010742, 'loss_4': 0.3495699167251587, 'epoch': 17.56}
{'loss': 0.007, 'grad_norm': 4.930449962615967, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.005027661565691233, 'loss_2': 0.001979827880859375, 'loss_3': -16.138713836669922, 'loss_4': 0.18756699562072754, 'epoch': 17.57}
{'loss': 0.0063, 'grad_norm': 5.5994672775268555, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.0055086081847548485, 'loss_2': 0.0007734298706054688, 'loss_3': -16.515195846557617, 'loss_4': 0.7963408827781677, 'epoch': 17.58}
{'loss': 0.0098, 'grad_norm': 5.338003635406494, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.008779332973062992, 'loss_2': 0.0010204315185546875, 'loss_3': -16.392148971557617, 'loss_4': 0.40132373571395874, 'epoch': 17.58}
{'loss': 0.0183, 'grad_norm': 6.0026702880859375, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.009955771267414093, 'loss_2': 0.00830078125, 'loss_3': -16.37949562072754, 'loss_4': 1.120652198791504, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 10:38:32,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:32,551 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:47<36:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:38:39,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011473685503005981, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007680803537368774, 'eval_loss_2': 0.003792881965637207, 'eval_loss_3': -18.280078887939453, 'eval_loss_4': 0.20063625276088715, 'epoch': 17.59}
{'loss': 0.0066, 'grad_norm': 5.0626325607299805, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.005981311202049255, 'loss_2': 0.00058746337890625, 'loss_3': -16.39906883239746, 'loss_4': 1.1050753593444824, 'epoch': 17.59}
{'loss': 0.0156, 'grad_norm': 5.5472588539123535, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.011489597149193287, 'loss_2': 0.0040740966796875, 'loss_3': -16.63222312927246, 'loss_4': 0.6131119728088379, 'epoch': 17.6}
{'loss': 0.0081, 'grad_norm': 5.644950866699219, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.008014560677111149, 'loss_2': 8.487701416015625e-05, 'loss_3': -16.368408203125, 'loss_4': 1.1332488059997559, 'epoch': 17.6}
{'loss': 0.016, 'grad_norm': 5.761775493621826, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.011770859360694885, 'loss_2': 0.004261016845703125, 'loss_3': -16.296138763427734, 'loss_4': 0.22666563093662262, 'epoch': 17.61}
{'loss': 0.0143, 'grad_norm': 7.462951183319092, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.009723675437271595, 'loss_2': 0.00455474853515625, 'loss_3': -16.566692352294922, 'loss_4': 0.8179759979248047, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 10:38:39,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:39,879 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:14:54<36:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:38:47,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01118670403957367, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007177778519690037, 'eval_loss_2': 0.004008926451206207, 'eval_loss_3': -18.27741050720215, 'eval_loss_4': 0.06532543897628784, 'epoch': 17.62}
{'loss': 0.0168, 'grad_norm': 6.311301231384277, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.006253186613321304, 'loss_2': 0.01056671142578125, 'loss_3': -16.480436325073242, 'loss_4': 0.05749775469303131, 'epoch': 17.62}
{'loss': 0.0124, 'grad_norm': 5.9109086990356445, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.010543902404606342, 'loss_2': 0.001827239990234375, 'loss_3': -16.50620460510254, 'loss_4': 0.038196057081222534, 'epoch': 17.63}
{'loss': 0.0172, 'grad_norm': 7.130622863769531, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.015131432563066483, 'loss_2': 0.00208282470703125, 'loss_3': -16.44243812561035, 'loss_4': -0.06515982747077942, 'epoch': 17.63}
{'loss': 0.0067, 'grad_norm': 4.3827924728393555, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.00510971387848258, 'loss_2': 0.0016326904296875, 'loss_3': -16.582433700561523, 'loss_4': 0.20938870310783386, 'epoch': 17.64}
{'loss': 0.0089, 'grad_norm': 5.547748565673828, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.008515812456607819, 'loss_2': 0.0003781318664550781, 'loss_3': -16.523059844970703, 'loss_4': 0.12422072887420654, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 10:38:47,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:47,221 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:01<36:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:38:54,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011190825141966343, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007526152301579714, 'eval_loss_2': 0.003664672374725342, 'eval_loss_3': -18.273542404174805, 'eval_loss_4': -0.007113620638847351, 'epoch': 17.65}
{'loss': 0.0134, 'grad_norm': 5.033193588256836, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.00887324009090662, 'loss_2': 0.004520416259765625, 'loss_3': -16.440731048583984, 'loss_4': 0.3283320367336273, 'epoch': 17.65}
{'loss': 0.0108, 'grad_norm': 4.99602746963501, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.00959978997707367, 'loss_2': 0.0011692047119140625, 'loss_3': -16.331165313720703, 'loss_4': -0.17935964465141296, 'epoch': 17.66}
{'loss': 0.0205, 'grad_norm': 10.29476547241211, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.01646634005010128, 'loss_2': 0.004077911376953125, 'loss_3': -16.319332122802734, 'loss_4': 0.18185490369796753, 'epoch': 17.66}
{'loss': 0.0275, 'grad_norm': 12.87322998046875, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.02694302424788475, 'loss_2': 0.0005626678466796875, 'loss_3': -16.38253402709961, 'loss_4': 0.8547357320785522, 'epoch': 17.67}
{'loss': 0.0191, 'grad_norm': 6.730459690093994, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.016242293640971184, 'loss_2': 0.002838134765625, 'loss_3': -16.540916442871094, 'loss_4': -0.42181941866874695, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 10:38:54,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:38:54,548 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:09<36:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:01,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01211632788181305, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.562, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008140317164361477, 'eval_loss_2': 0.003976009786128998, 'eval_loss_3': -18.270090103149414, 'eval_loss_4': 0.0008851625025272369, 'epoch': 17.67}
{'loss': 0.0095, 'grad_norm': 5.258243083953857, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.008054861798882484, 'loss_2': 0.00142669677734375, 'loss_3': -16.38864517211914, 'loss_4': -0.07845792174339294, 'epoch': 17.68}
{'loss': 0.0114, 'grad_norm': 10.963441848754883, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.010394041426479816, 'loss_2': 0.00102996826171875, 'loss_3': -16.39841651916504, 'loss_4': 0.10988061130046844, 'epoch': 17.69}
{'loss': 0.0098, 'grad_norm': 6.563246726989746, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.008240804076194763, 'loss_2': 0.0015506744384765625, 'loss_3': -16.41008949279785, 'loss_4': -0.3830617070198059, 'epoch': 17.69}
{'loss': 0.0213, 'grad_norm': 7.210762023925781, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.016642563045024872, 'loss_2': 0.00469970703125, 'loss_3': -16.236318588256836, 'loss_4': -0.5632498264312744, 'epoch': 17.7}
{'loss': 0.0091, 'grad_norm': 4.742081642150879, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.007619443349540234, 'loss_2': 0.001461029052734375, 'loss_3': -16.716035842895508, 'loss_4': 0.11827681213617325, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 10:39:01,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:01,886 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:16<36:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:09,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011623464524745941, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.449, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007390922866761684, 'eval_loss_2': 0.004232540726661682, 'eval_loss_3': -18.270883560180664, 'eval_loss_4': -0.04537263885140419, 'epoch': 17.7}
{'loss': 0.0089, 'grad_norm': 4.46219539642334, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.005121925380080938, 'loss_2': 0.0037593841552734375, 'loss_3': -16.408763885498047, 'loss_4': 0.3232552409172058, 'epoch': 17.71}
{'loss': 0.0076, 'grad_norm': 4.488359451293945, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.005516394507139921, 'loss_2': 0.002132415771484375, 'loss_3': -16.397377014160156, 'loss_4': 0.21861346065998077, 'epoch': 17.72}
{'loss': 0.0227, 'grad_norm': 6.049067974090576, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.012725211679935455, 'loss_2': 0.0099945068359375, 'loss_3': -16.408897399902344, 'loss_4': 0.07068318128585815, 'epoch': 17.72}
{'loss': 0.0215, 'grad_norm': 6.1803812980651855, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.011175666004419327, 'loss_2': 0.01035308837890625, 'loss_3': -16.359949111938477, 'loss_4': 0.059640318155288696, 'epoch': 17.73}
{'loss': 0.0138, 'grad_norm': 5.865322589874268, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.011301481164991856, 'loss_2': 0.002460479736328125, 'loss_3': -16.33291244506836, 'loss_4': 0.9416223168373108, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 10:39:09,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:09,233 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:23<36:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:39:16,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011990321800112724, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007765663787722588, 'eval_loss_2': 0.004224658012390137, 'eval_loss_3': -18.289588928222656, 'eval_loss_4': -0.15843868255615234, 'epoch': 17.73}
{'loss': 0.0379, 'grad_norm': 13.179394721984863, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.036272384226322174, 'loss_2': 0.00165557861328125, 'loss_3': -16.389968872070312, 'loss_4': 0.29725009202957153, 'epoch': 17.74}
{'loss': 0.0123, 'grad_norm': 5.92818021774292, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.007165233604609966, 'loss_2': 0.00510406494140625, 'loss_3': -16.30682373046875, 'loss_4': 0.15948212146759033, 'epoch': 17.74}
{'loss': 0.0103, 'grad_norm': 4.920209884643555, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.007267957553267479, 'loss_2': 0.00305938720703125, 'loss_3': -16.56280517578125, 'loss_4': 0.25220662355422974, 'epoch': 17.75}
{'loss': 0.0136, 'grad_norm': 6.503977298736572, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.009705753065645695, 'loss_2': 0.003879547119140625, 'loss_3': -16.505252838134766, 'loss_4': 0.3733317255973816, 'epoch': 17.76}
{'loss': 0.0354, 'grad_norm': 17.057130813598633, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.033971600234508514, 'loss_2': 0.001415252685546875, 'loss_3': -16.231342315673828, 'loss_4': 0.6334731578826904, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 10:39:16,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:16,558 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:31<36:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:23,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01152314618229866, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.299, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007338545750826597, 'eval_loss_2': 0.004184599965810776, 'eval_loss_3': -18.292325973510742, 'eval_loss_4': -0.19201798737049103, 'epoch': 17.76}
{'loss': 0.0114, 'grad_norm': 5.658515453338623, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.008355477824807167, 'loss_2': 0.003063201904296875, 'loss_3': -16.446577072143555, 'loss_4': 0.17009785771369934, 'epoch': 17.77}
{'loss': 0.007, 'grad_norm': 5.19861364364624, 'learning_rate': 1.225e-05, 'loss_1': 0.0064937639981508255, 'loss_2': 0.00046896934509277344, 'loss_3': -16.515369415283203, 'loss_4': 0.7572333812713623, 'epoch': 17.77}
{'loss': 0.0287, 'grad_norm': 8.863296508789062, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.01904156804084778, 'loss_2': 0.00966644287109375, 'loss_3': -16.468738555908203, 'loss_4': -0.7946698665618896, 'epoch': 17.78}
{'loss': 0.0196, 'grad_norm': 10.440482139587402, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.01885892078280449, 'loss_2': 0.0006999969482421875, 'loss_3': -16.300514221191406, 'loss_4': -0.051830634474754333, 'epoch': 17.78}
{'loss': 0.0108, 'grad_norm': 5.705645561218262, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.01068994589149952, 'loss_2': 0.00010645389556884766, 'loss_3': -16.433807373046875, 'loss_4': -0.12837128341197968, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 10:39:23,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:23,895 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:38<36:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:31,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011829198338091373, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007652544416487217, 'eval_loss_2': 0.0041766539216041565, 'eval_loss_3': -18.29340362548828, 'eval_loss_4': -0.1137256771326065, 'epoch': 17.79}
{'loss': 0.0205, 'grad_norm': 9.21996021270752, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.012852304615080357, 'loss_2': 0.00762176513671875, 'loss_3': -16.383989334106445, 'loss_4': 0.14520838856697083, 'epoch': 17.8}
{'loss': 0.0231, 'grad_norm': 7.308351039886475, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.018830392509698868, 'loss_2': 0.00424957275390625, 'loss_3': -16.332698822021484, 'loss_4': 0.06804372370243073, 'epoch': 17.8}
{'loss': 0.0132, 'grad_norm': 4.911526679992676, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.00915216002613306, 'loss_2': 0.0040283203125, 'loss_3': -16.467941284179688, 'loss_4': 0.5638286471366882, 'epoch': 17.81}
{'loss': 0.0229, 'grad_norm': 6.9789934158325195, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.014785351231694221, 'loss_2': 0.00811767578125, 'loss_3': -16.425025939941406, 'loss_4': 0.03730442374944687, 'epoch': 17.81}
{'loss': 0.0146, 'grad_norm': 8.203714370727539, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.011292916722595692, 'loss_2': 0.0033130645751953125, 'loss_3': -16.563879013061523, 'loss_4': -0.061482250690460205, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 10:39:31,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:31,229 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:45<36:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:38,570 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011635374277830124, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007031153421849012, 'eval_loss_2': 0.004604220390319824, 'eval_loss_3': -18.293216705322266, 'eval_loss_4': -0.02929288148880005, 'epoch': 17.82}
{'loss': 0.0112, 'grad_norm': 4.715835094451904, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.008434060961008072, 'loss_2': 0.0027523040771484375, 'loss_3': -16.58926010131836, 'loss_4': 0.7370943427085876, 'epoch': 17.83}
{'loss': 0.0092, 'grad_norm': 4.9877400398254395, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.005160297267138958, 'loss_2': 0.0040283203125, 'loss_3': -16.253625869750977, 'loss_4': 0.04146900773048401, 'epoch': 17.83}
{'loss': 0.0101, 'grad_norm': 5.137548446655273, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.009460436180233955, 'loss_2': 0.000675201416015625, 'loss_3': -16.398571014404297, 'loss_4': 0.3144887685775757, 'epoch': 17.84}
{'loss': 0.0114, 'grad_norm': 6.045007705688477, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.00815943069756031, 'loss_2': 0.003261566162109375, 'loss_3': -16.582393646240234, 'loss_4': -0.05030477046966553, 'epoch': 17.84}
{'loss': 0.0045, 'grad_norm': 4.5148468017578125, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.003577057970687747, 'loss_2': 0.0009126663208007812, 'loss_3': -16.480613708496094, 'loss_4': -0.4087572991847992, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 10:39:38,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:38,570 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:15:53<36:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:45,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011068920604884624, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.622, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006653765682131052, 'eval_loss_2': 0.004415154457092285, 'eval_loss_3': -18.294010162353516, 'eval_loss_4': -0.08016663789749146, 'epoch': 17.85}
{'loss': 0.0061, 'grad_norm': 5.675180435180664, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.005668556783348322, 'loss_2': 0.00042724609375, 'loss_3': -16.483022689819336, 'loss_4': -0.3649771809577942, 'epoch': 17.85}
{'loss': 0.0053, 'grad_norm': 4.914175033569336, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.003169839968904853, 'loss_2': 0.0021381378173828125, 'loss_3': -16.54339599609375, 'loss_4': -0.05682489275932312, 'epoch': 17.86}
{'loss': 0.0236, 'grad_norm': 15.374759674072266, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.02204621583223343, 'loss_2': 0.0015583038330078125, 'loss_3': -16.401321411132812, 'loss_4': 0.09392640739679337, 'epoch': 17.87}
{'loss': 0.0157, 'grad_norm': 6.519578456878662, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.010770616121590137, 'loss_2': 0.00494384765625, 'loss_3': -16.460525512695312, 'loss_4': -0.1961270123720169, 'epoch': 17.87}
{'loss': 0.0059, 'grad_norm': 4.675387382507324, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.0040939743630588055, 'loss_2': 0.0017681121826171875, 'loss_3': -16.58696746826172, 'loss_4': 0.7089215517044067, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 10:39:45,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:45,918 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:00<35:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:39:53,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010286035016179085, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.921, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005869062151759863, 'eval_loss_2': 0.004416972398757935, 'eval_loss_3': -18.265155792236328, 'eval_loss_4': -0.15040628612041473, 'epoch': 17.88}
{'loss': 0.0172, 'grad_norm': 13.129385948181152, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.013747044838964939, 'loss_2': 0.0034351348876953125, 'loss_3': -16.568309783935547, 'loss_4': -0.24851880967617035, 'epoch': 17.88}
{'loss': 0.0116, 'grad_norm': 5.717279434204102, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.008228866383433342, 'loss_2': 0.0033397674560546875, 'loss_3': -16.523624420166016, 'loss_4': 0.47073519229888916, 'epoch': 17.89}
{'loss': 0.0065, 'grad_norm': 4.641143321990967, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.006195783615112305, 'loss_2': 0.0002999305725097656, 'loss_3': -16.481876373291016, 'loss_4': 0.2509022653102875, 'epoch': 17.9}
{'loss': 0.0078, 'grad_norm': 4.573541164398193, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.005058690905570984, 'loss_2': 0.002777099609375, 'loss_3': -16.54960823059082, 'loss_4': -0.13908378779888153, 'epoch': 17.9}
{'loss': 0.0151, 'grad_norm': 7.815902233123779, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.01446705311536789, 'loss_2': 0.0006093978881835938, 'loss_3': -16.31597900390625, 'loss_4': -0.15482458472251892, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 10:39:53,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:39:53,261 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:07<35:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:00,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00978929828852415, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005617916118353605, 'eval_loss_2': 0.004171382635831833, 'eval_loss_3': -18.232025146484375, 'eval_loss_4': -0.11693751066923141, 'epoch': 17.91}
{'loss': 0.0094, 'grad_norm': 4.8942484855651855, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.0035575469955801964, 'loss_2': 0.0058441162109375, 'loss_3': -16.4993896484375, 'loss_4': -0.43639373779296875, 'epoch': 17.91}
{'loss': 0.0241, 'grad_norm': 7.622318744659424, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.02151649445295334, 'loss_2': 0.00262451171875, 'loss_3': -16.665748596191406, 'loss_4': 0.8119736909866333, 'epoch': 17.92}
{'loss': 0.0097, 'grad_norm': 4.779754638671875, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.005202207248657942, 'loss_2': 0.004497528076171875, 'loss_3': -16.39128875732422, 'loss_4': -0.008386336266994476, 'epoch': 17.92}
{'loss': 0.0092, 'grad_norm': 5.0672807693481445, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.006197661627084017, 'loss_2': 0.002960205078125, 'loss_3': -16.473979949951172, 'loss_4': -0.07169193774461746, 'epoch': 17.93}
{'loss': 0.0174, 'grad_norm': 6.657863616943359, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.01451075542718172, 'loss_2': 0.0028820037841796875, 'loss_3': -16.290674209594727, 'loss_4': 1.4164268970489502, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 10:40:00,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:00,602 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:15<35:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:07,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010061182081699371, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006252347491681576, 'eval_loss_2': 0.003808833658695221, 'eval_loss_3': -18.214475631713867, 'eval_loss_4': 0.0825267881155014, 'epoch': 17.94}
{'loss': 0.0161, 'grad_norm': 5.304406642913818, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.008350550197064877, 'loss_2': 0.007732391357421875, 'loss_3': -16.48295783996582, 'loss_4': 0.6292929649353027, 'epoch': 17.94}
{'loss': 0.0121, 'grad_norm': 4.775835990905762, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.005309374537318945, 'loss_2': 0.0067901611328125, 'loss_3': -16.501527786254883, 'loss_4': 0.11691680550575256, 'epoch': 17.95}
{'loss': 0.0064, 'grad_norm': 4.961739540100098, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.004110600333660841, 'loss_2': 0.0022735595703125, 'loss_3': -16.442806243896484, 'loss_4': 0.15298038721084595, 'epoch': 17.95}
{'loss': 0.0101, 'grad_norm': 4.848863124847412, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.005552888847887516, 'loss_2': 0.004512786865234375, 'loss_3': -16.74988555908203, 'loss_4': 0.5309152603149414, 'epoch': 17.96}
{'loss': 0.0124, 'grad_norm': 6.195322513580322, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.010212874040007591, 'loss_2': 0.002223968505859375, 'loss_3': -16.547863006591797, 'loss_4': 0.2013622522354126, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 10:40:07,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:07,937 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:22<35:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:15,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009154879488050938, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005510472692549229, 'eval_loss_2': 0.003644406795501709, 'eval_loss_3': -18.200132369995117, 'eval_loss_4': 0.2582007348537445, 'epoch': 17.97}
{'loss': 0.0152, 'grad_norm': 5.622854232788086, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.01051240973174572, 'loss_2': 0.00464630126953125, 'loss_3': -16.36307716369629, 'loss_4': 0.5202652215957642, 'epoch': 17.97}
{'loss': 0.0078, 'grad_norm': 4.775055885314941, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.0042465147562325, 'loss_2': 0.003574371337890625, 'loss_3': -16.513996124267578, 'loss_4': 0.7807313799858093, 'epoch': 17.98}
{'loss': 0.0218, 'grad_norm': 7.032475471496582, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.016296839341521263, 'loss_2': 0.00547027587890625, 'loss_3': -16.26186752319336, 'loss_4': 0.053647011518478394, 'epoch': 17.98}
{'loss': 0.0102, 'grad_norm': 8.500611305236816, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.00805071834474802, 'loss_2': 0.0021343231201171875, 'loss_3': -16.28091049194336, 'loss_4': 0.33173781633377075, 'epoch': 17.99}
{'loss': 0.007, 'grad_norm': 4.752377986907959, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.0031485112849622965, 'loss_2': 0.00388336181640625, 'loss_3': -16.3204402923584, 'loss_4': 0.9611515998840332, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 10:40:15,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:15,265 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:29<34:50,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:40:22,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009092304855585098, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005098219960927963, 'eval_loss_2': 0.003994084894657135, 'eval_loss_3': -18.180233001708984, 'eval_loss_4': 0.381902813911438, 'epoch': 17.99}
{'loss': 0.0045, 'grad_norm': 6.209938049316406, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.0013886382803320885, 'loss_2': 0.0031108856201171875, 'loss_3': -16.097728729248047, 'loss_4': 0.9557288885116577, 'epoch': 18.0}
{'loss': 0.0181, 'grad_norm': 6.530356407165527, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.011510603129863739, 'loss_2': 0.006595611572265625, 'loss_3': -16.36656951904297, 'loss_4': 0.0027553439140319824, 'epoch': 18.01}
{'loss': 0.0117, 'grad_norm': 6.006627559661865, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.008475899696350098, 'loss_2': 0.00327301025390625, 'loss_3': -16.021080017089844, 'loss_4': 0.22480177879333496, 'epoch': 18.01}
{'loss': 0.006, 'grad_norm': 4.815133094787598, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.0034973169676959515, 'loss_2': 0.0025482177734375, 'loss_3': -16.42192840576172, 'loss_4': 0.12163614481687546, 'epoch': 18.02}
{'loss': 0.0114, 'grad_norm': 5.2538323402404785, 'learning_rate': 1.2e-05, 'loss_1': 0.009595895186066628, 'loss_2': 0.0018301010131835938, 'loss_3': -16.00848388671875, 'loss_4': 0.47089606523513794, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 10:40:22,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:22,312 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:36<35:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:40:29,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00950118713080883, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.862, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005250481888651848, 'eval_loss_2': 0.004250705242156982, 'eval_loss_3': -18.18391990661621, 'eval_loss_4': 0.47952789068222046, 'epoch': 18.02}
{'loss': 0.009, 'grad_norm': 4.77123498916626, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.004694437142461538, 'loss_2': 0.0042877197265625, 'loss_3': -16.315340042114258, 'loss_4': 0.28490105271339417, 'epoch': 18.03}
{'loss': 0.0064, 'grad_norm': 5.599468231201172, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.005797265563160181, 'loss_2': 0.0006089210510253906, 'loss_3': -16.458786010742188, 'loss_4': 0.8786685466766357, 'epoch': 18.03}
{'loss': 0.0103, 'grad_norm': 5.311089515686035, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.004318078514188528, 'loss_2': 0.006011962890625, 'loss_3': -16.238365173339844, 'loss_4': 0.15526849031448364, 'epoch': 18.04}
{'loss': 0.0272, 'grad_norm': 7.633773326873779, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.01735750213265419, 'loss_2': 0.009857177734375, 'loss_3': -16.47824478149414, 'loss_4': 0.560042142868042, 'epoch': 18.05}
{'loss': 0.0156, 'grad_norm': 5.8453264236450195, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.010803482495248318, 'loss_2': 0.0047760009765625, 'loss_3': -16.454967498779297, 'loss_4': 0.8733571767807007, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 10:40:29,657 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:29,657 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:44<35:53,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:40:37,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009958148002624512, 'eval_runtime': 3.9962, 'eval_samples_per_second': 256.244, 'eval_steps_per_second': 4.004, 'eval_loss_1': 0.005199149250984192, 'eval_loss_2': 0.00475899875164032, 'eval_loss_3': -18.18947410583496, 'eval_loss_4': 0.5591062903404236, 'epoch': 18.05}
{'loss': 0.0068, 'grad_norm': 4.958258628845215, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.005789372604340315, 'loss_2': 0.0010509490966796875, 'loss_3': -16.319799423217773, 'loss_4': 1.2159756422042847, 'epoch': 18.06}
{'loss': 0.0131, 'grad_norm': 11.203490257263184, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.009767582640051842, 'loss_2': 0.0033321380615234375, 'loss_3': -16.116947174072266, 'loss_4': 1.0772454738616943, 'epoch': 18.06}
{'loss': 0.0074, 'grad_norm': 5.428586959838867, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.006463190540671349, 'loss_2': 0.0009407997131347656, 'loss_3': -16.25574493408203, 'loss_4': 0.4760238528251648, 'epoch': 18.07}
{'loss': 0.0101, 'grad_norm': 4.7499284744262695, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.006258535664528608, 'loss_2': 0.003795623779296875, 'loss_3': -16.30679702758789, 'loss_4': 0.9464762806892395, 'epoch': 18.08}
{'loss': 0.0265, 'grad_norm': 10.690454483032227, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.02247283048927784, 'loss_2': 0.004001617431640625, 'loss_3': -16.397605895996094, 'loss_4': 1.0367348194122314, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 10:40:37,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:37,194 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:51<35:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:44,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008863366208970547, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.262, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0051686521619558334, 'eval_loss_2': 0.0036947131156921387, 'eval_loss_3': -18.213491439819336, 'eval_loss_4': 0.7825088500976562, 'epoch': 18.08}
{'loss': 0.0105, 'grad_norm': 6.788827896118164, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.0082744425162673, 'loss_2': 0.002246856689453125, 'loss_3': -16.351688385009766, 'loss_4': 0.8378748297691345, 'epoch': 18.09}
{'loss': 0.0062, 'grad_norm': 5.190407752990723, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.006140714976936579, 'loss_2': 0.00010716915130615234, 'loss_3': -16.297504425048828, 'loss_4': 1.159001350402832, 'epoch': 18.09}
{'loss': 0.0115, 'grad_norm': 4.98814058303833, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.007231011986732483, 'loss_2': 0.0042877197265625, 'loss_3': -16.27676010131836, 'loss_4': 1.5745354890823364, 'epoch': 18.1}
{'loss': 0.007, 'grad_norm': 4.5773186683654785, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.0037095181178301573, 'loss_2': 0.00330352783203125, 'loss_3': -16.29023551940918, 'loss_4': 0.9143754839897156, 'epoch': 18.1}
{'loss': 0.0256, 'grad_norm': 14.836296081542969, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.024055292829871178, 'loss_2': 0.001560211181640625, 'loss_3': -16.437828063964844, 'loss_4': 1.8029720783233643, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 10:40:44,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:44,539 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:16:59<35:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:51,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00841464102268219, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.301, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005033083725720644, 'eval_loss_2': 0.0033815577626228333, 'eval_loss_3': -18.225027084350586, 'eval_loss_4': 0.8458091020584106, 'epoch': 18.11}
{'loss': 0.0231, 'grad_norm': 11.352927207946777, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.0220104418694973, 'loss_2': 0.0011272430419921875, 'loss_3': -16.22968101501465, 'loss_4': -0.006434917449951172, 'epoch': 18.12}
{'loss': 0.0131, 'grad_norm': 6.486279010772705, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.00833054631948471, 'loss_2': 0.004741668701171875, 'loss_3': -16.30325698852539, 'loss_4': 1.2810139656066895, 'epoch': 18.12}
{'loss': 0.0085, 'grad_norm': 4.906686782836914, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.008246180601418018, 'loss_2': 0.00026416778564453125, 'loss_3': -16.43201446533203, 'loss_4': 1.2919995784759521, 'epoch': 18.13}
{'loss': 0.0112, 'grad_norm': 5.48887300491333, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.005700864363461733, 'loss_2': 0.00550079345703125, 'loss_3': -16.32635498046875, 'loss_4': 1.3160302639007568, 'epoch': 18.13}
{'loss': 0.0144, 'grad_norm': 5.227054595947266, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.007797930855304003, 'loss_2': 0.00664520263671875, 'loss_3': -16.20244789123535, 'loss_4': 1.4265810251235962, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 10:40:51,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:51,872 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:06<35:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:40:59,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008204861544072628, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.305, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00536136282607913, 'eval_loss_2': 0.002843499183654785, 'eval_loss_3': -18.22776222229004, 'eval_loss_4': 0.9114099740982056, 'epoch': 18.14}
{'loss': 0.0033, 'grad_norm': 4.1506667137146, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.002169376704841852, 'loss_2': 0.0011682510375976562, 'loss_3': -16.310863494873047, 'loss_4': 1.32859468460083, 'epoch': 18.15}
{'loss': 0.0523, 'grad_norm': 17.14481544494629, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.04623333364725113, 'loss_2': 0.006076812744140625, 'loss_3': -16.314586639404297, 'loss_4': 0.9335821270942688, 'epoch': 18.15}
{'loss': 0.0101, 'grad_norm': 6.030160903930664, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.0087254224345088, 'loss_2': 0.001331329345703125, 'loss_3': -16.35468292236328, 'loss_4': 1.156714916229248, 'epoch': 18.16}
{'loss': 0.0177, 'grad_norm': 4.614508628845215, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.007567449938505888, 'loss_2': 0.0101470947265625, 'loss_3': -16.449228286743164, 'loss_4': 1.8075138330459595, 'epoch': 18.16}
{'loss': 0.0063, 'grad_norm': 5.208089828491211, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.005414572544395924, 'loss_2': 0.0009260177612304688, 'loss_3': -16.252099990844727, 'loss_4': 0.3831663429737091, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 10:40:59,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:40:59,215 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:13<35:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:06,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008629275485873222, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.212, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005689484998583794, 'eval_loss_2': 0.0029397904872894287, 'eval_loss_3': -18.197633743286133, 'eval_loss_4': 1.0192012786865234, 'epoch': 18.17}
{'loss': 0.0077, 'grad_norm': 4.808524131774902, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.00658502196893096, 'loss_2': 0.001117706298828125, 'loss_3': -16.192739486694336, 'loss_4': 1.4939827919006348, 'epoch': 18.17}
{'loss': 0.0179, 'grad_norm': 8.467740058898926, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.012164734303951263, 'loss_2': 0.0057830810546875, 'loss_3': -16.26438331604004, 'loss_4': 1.3430752754211426, 'epoch': 18.18}
{'loss': 0.0111, 'grad_norm': 6.836367607116699, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.01084569375962019, 'loss_2': 0.00029015541076660156, 'loss_3': -16.195537567138672, 'loss_4': 0.7275643348693848, 'epoch': 18.19}
{'loss': 0.0317, 'grad_norm': 7.563772201538086, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.026454724371433258, 'loss_2': 0.00525665283203125, 'loss_3': -16.365543365478516, 'loss_4': 1.327587604522705, 'epoch': 18.19}
{'loss': 0.0131, 'grad_norm': 4.62980318069458, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.0044141593389213085, 'loss_2': 0.008697509765625, 'loss_3': -16.30748748779297, 'loss_4': 0.8117817640304565, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 10:41:06,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:06,557 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:21<35:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:13,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00894659198820591, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.662, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0053764525800943375, 'eval_loss_2': 0.0035701394081115723, 'eval_loss_3': -18.22532844543457, 'eval_loss_4': 1.1906989812850952, 'epoch': 18.2}
{'loss': 0.0062, 'grad_norm': 5.44611120223999, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.0051659708842635155, 'loss_2': 0.001026153564453125, 'loss_3': -16.157907485961914, 'loss_4': 1.4302864074707031, 'epoch': 18.2}
{'loss': 0.0051, 'grad_norm': 5.3587164878845215, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.004038890358060598, 'loss_2': 0.00103759765625, 'loss_3': -16.316329956054688, 'loss_4': 1.886949896812439, 'epoch': 18.21}
{'loss': 0.0105, 'grad_norm': 4.41517448425293, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.0028081757482141256, 'loss_2': 0.00769805908203125, 'loss_3': -16.490861892700195, 'loss_4': 1.1693034172058105, 'epoch': 18.22}
{'loss': 0.0165, 'grad_norm': 7.964963912963867, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.012512889690697193, 'loss_2': 0.0039825439453125, 'loss_3': -16.323793411254883, 'loss_4': 1.5301697254180908, 'epoch': 18.22}
{'loss': 0.0197, 'grad_norm': 7.244268417358398, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.012726866640150547, 'loss_2': 0.0069427490234375, 'loss_3': -16.378616333007812, 'loss_4': 1.4892257452011108, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 10:41:13,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:13,911 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:28<34:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:21,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013838725164532661, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006455437745898962, 'eval_loss_2': 0.007383286952972412, 'eval_loss_3': -18.217565536499023, 'eval_loss_4': 1.5566567182540894, 'epoch': 18.23}
{'loss': 0.0153, 'grad_norm': 5.33615255355835, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.010629339143633842, 'loss_2': 0.00469207763671875, 'loss_3': -16.36660385131836, 'loss_4': 2.6075940132141113, 'epoch': 18.23}
{'loss': 0.0305, 'grad_norm': 10.330045700073242, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.024462144821882248, 'loss_2': 0.006061553955078125, 'loss_3': -16.385046005249023, 'loss_4': 1.8514693975448608, 'epoch': 18.24}
{'loss': 0.0104, 'grad_norm': 4.7273850440979, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.004688953049480915, 'loss_2': 0.005725860595703125, 'loss_3': -16.299577713012695, 'loss_4': 1.8638132810592651, 'epoch': 18.24}
{'loss': 0.024, 'grad_norm': 5.247594356536865, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.008836571127176285, 'loss_2': 0.01515960693359375, 'loss_3': -16.37999725341797, 'loss_4': 1.7386715412139893, 'epoch': 18.25}
{'loss': 0.0164, 'grad_norm': 4.711144924163818, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.0038892317097634077, 'loss_2': 0.0125579833984375, 'loss_3': -16.431406021118164, 'loss_4': 1.9690431356430054, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 10:41:21,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:21,253 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:35<34:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:28,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014848466031253338, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006675597280263901, 'eval_loss_2': 0.008172869682312012, 'eval_loss_3': -18.216407775878906, 'eval_loss_4': 1.8336395025253296, 'epoch': 18.26}
{'loss': 0.0186, 'grad_norm': 6.9843525886535645, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.011554824188351631, 'loss_2': 0.00708770751953125, 'loss_3': -16.396072387695312, 'loss_4': 2.0401196479797363, 'epoch': 18.26}
{'loss': 0.0099, 'grad_norm': 5.56931209564209, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.005569026339799166, 'loss_2': 0.0043792724609375, 'loss_3': -16.455644607543945, 'loss_4': 1.195546269416809, 'epoch': 18.27}
{'loss': 0.0181, 'grad_norm': 5.865894317626953, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.012000801041722298, 'loss_2': 0.006107330322265625, 'loss_3': -16.396053314208984, 'loss_4': 1.9276444911956787, 'epoch': 18.27}
{'loss': 0.0194, 'grad_norm': 5.26099157333374, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.008138630539178848, 'loss_2': 0.01129150390625, 'loss_3': -16.3687744140625, 'loss_4': 2.379274368286133, 'epoch': 18.28}
{'loss': 0.0103, 'grad_norm': 6.573155879974365, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.00857164990156889, 'loss_2': 0.00174713134765625, 'loss_3': -16.265602111816406, 'loss_4': 2.353079319000244, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 10:41:28,596 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:28,596 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:43<34:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:35,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010439535602927208, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0070184385403990746, 'eval_loss_2': 0.003421097993850708, 'eval_loss_3': -18.203540802001953, 'eval_loss_4': 1.961677074432373, 'epoch': 18.28}
{'loss': 0.0041, 'grad_norm': 4.4036712646484375, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.0033069646451622248, 'loss_2': 0.0007715225219726562, 'loss_3': -16.24802017211914, 'loss_4': 1.5567561388015747, 'epoch': 18.29}
{'loss': 0.0129, 'grad_norm': 5.774363994598389, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.00983755849301815, 'loss_2': 0.0030364990234375, 'loss_3': -16.344764709472656, 'loss_4': 2.2833778858184814, 'epoch': 18.3}
{'loss': 0.0223, 'grad_norm': 7.727315425872803, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.02117302641272545, 'loss_2': 0.001140594482421875, 'loss_3': -16.298587799072266, 'loss_4': 2.051009178161621, 'epoch': 18.3}
{'loss': 0.0061, 'grad_norm': 4.382801055908203, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.00477999821305275, 'loss_2': 0.0013093948364257812, 'loss_3': -16.479671478271484, 'loss_4': 2.2864041328430176, 'epoch': 18.31}
{'loss': 0.0071, 'grad_norm': 4.713892459869385, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.005662333685904741, 'loss_2': 0.001434326171875, 'loss_3': -16.523967742919922, 'loss_4': 3.4866034984588623, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 10:41:35,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:35,937 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:50<34:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:43,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010294797830283642, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007052603177726269, 'eval_loss_2': 0.003242194652557373, 'eval_loss_3': -18.201894760131836, 'eval_loss_4': 2.2037057876586914, 'epoch': 18.31}
{'loss': 0.0085, 'grad_norm': 4.52422571182251, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.005161064211279154, 'loss_2': 0.00330352783203125, 'loss_3': -16.301652908325195, 'loss_4': 2.3209228515625, 'epoch': 18.32}
{'loss': 0.0067, 'grad_norm': 4.8427348136901855, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.004762184806168079, 'loss_2': 0.0019435882568359375, 'loss_3': -16.203655242919922, 'loss_4': 1.7682764530181885, 'epoch': 18.33}
{'loss': 0.0154, 'grad_norm': 7.026343822479248, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.01183477696031332, 'loss_2': 0.0035858154296875, 'loss_3': -16.273765563964844, 'loss_4': 3.03633975982666, 'epoch': 18.33}
{'loss': 0.0131, 'grad_norm': 5.38136625289917, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.007518501486629248, 'loss_2': 0.00557708740234375, 'loss_3': -16.394041061401367, 'loss_4': 2.7233738899230957, 'epoch': 18.34}
{'loss': 0.0141, 'grad_norm': 4.55691385269165, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.007658872753381729, 'loss_2': 0.00640869140625, 'loss_3': -16.550434112548828, 'loss_4': 2.7727293968200684, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 10:41:43,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:43,277 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:17:57<34:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:50,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010095175355672836, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.421, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007102933246642351, 'eval_loss_2': 0.0029922425746917725, 'eval_loss_3': -18.194034576416016, 'eval_loss_4': 2.3641037940979004, 'epoch': 18.34}
{'loss': 0.0105, 'grad_norm': 5.421945571899414, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.008947466500103474, 'loss_2': 0.001567840576171875, 'loss_3': -16.24546241760254, 'loss_4': 2.6103878021240234, 'epoch': 18.35}
{'loss': 0.0138, 'grad_norm': 5.477608680725098, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.010825609788298607, 'loss_2': 0.002979278564453125, 'loss_3': -16.247411727905273, 'loss_4': 2.582556962966919, 'epoch': 18.35}
{'loss': 0.0192, 'grad_norm': 7.878796577453613, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.013222039677202702, 'loss_2': 0.00592803955078125, 'loss_3': -16.293071746826172, 'loss_4': 2.23734974861145, 'epoch': 18.36}
{'loss': 0.015, 'grad_norm': 7.62581205368042, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.014105602167546749, 'loss_2': 0.0008535385131835938, 'loss_3': -16.443641662597656, 'loss_4': 1.9501680135726929, 'epoch': 18.37}
{'loss': 0.0188, 'grad_norm': 8.620240211486816, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.01638919673860073, 'loss_2': 0.00237274169921875, 'loss_3': -16.20472526550293, 'loss_4': 2.9412074089050293, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 10:41:50,639 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:50,639 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:05<34:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:41:57,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00911423284560442, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006079461891204119, 'eval_loss_2': 0.0030347704887390137, 'eval_loss_3': -18.194974899291992, 'eval_loss_4': 2.35459566116333, 'epoch': 18.37}
{'loss': 0.0135, 'grad_norm': 7.863734245300293, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.010304604656994343, 'loss_2': 0.003238677978515625, 'loss_3': -16.426429748535156, 'loss_4': 2.32558536529541, 'epoch': 18.38}
{'loss': 0.0066, 'grad_norm': 5.2815752029418945, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.006246376782655716, 'loss_2': 0.0003993511199951172, 'loss_3': -16.311796188354492, 'loss_4': 2.6226658821105957, 'epoch': 18.38}
{'loss': 0.0108, 'grad_norm': 4.8988237380981445, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.0052429321222007275, 'loss_2': 0.0055084228515625, 'loss_3': -16.426219940185547, 'loss_4': 2.0389981269836426, 'epoch': 18.39}
{'loss': 0.0203, 'grad_norm': 7.056621551513672, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.01533378753811121, 'loss_2': 0.00495147705078125, 'loss_3': -16.187660217285156, 'loss_4': 2.894953727722168, 'epoch': 18.4}
{'loss': 0.0061, 'grad_norm': 4.262220859527588, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.00419603381305933, 'loss_2': 0.0018796920776367188, 'loss_3': -16.151294708251953, 'loss_4': 2.1017725467681885, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 10:41:57,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:41:57,981 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:12<34:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:05,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009118904359638691, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006519470363855362, 'eval_loss_2': 0.0025994330644607544, 'eval_loss_3': -18.193601608276367, 'eval_loss_4': 2.3045010566711426, 'epoch': 18.4}
{'loss': 0.0057, 'grad_norm': 4.960994720458984, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.004492553416639566, 'loss_2': 0.001255035400390625, 'loss_3': -16.481775283813477, 'loss_4': 2.6039934158325195, 'epoch': 18.41}
{'loss': 0.014, 'grad_norm': 4.909186840057373, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.007059876807034016, 'loss_2': 0.00695037841796875, 'loss_3': -16.31005096435547, 'loss_4': 2.588107109069824, 'epoch': 18.41}
{'loss': 0.0127, 'grad_norm': 4.448862075805664, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.0069160740822553635, 'loss_2': 0.0057830810546875, 'loss_3': -16.102954864501953, 'loss_4': 2.30564022064209, 'epoch': 18.42}
{'loss': 0.0123, 'grad_norm': 5.743668556213379, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.008888913318514824, 'loss_2': 0.0034046173095703125, 'loss_3': -16.29527473449707, 'loss_4': 2.1972484588623047, 'epoch': 18.42}
{'loss': 0.0098, 'grad_norm': 5.526666641235352, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.008001401089131832, 'loss_2': 0.0018310546875, 'loss_3': -16.27138900756836, 'loss_4': 2.257951021194458, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 10:42:05,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:05,324 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:19<34:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:12,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00976051576435566, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006434934213757515, 'eval_loss_2': 0.0033255815505981445, 'eval_loss_3': -18.190473556518555, 'eval_loss_4': 2.1258857250213623, 'epoch': 18.43}
{'loss': 0.0067, 'grad_norm': 4.218771934509277, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.003504794090986252, 'loss_2': 0.0032196044921875, 'loss_3': -16.43462371826172, 'loss_4': 2.3478872776031494, 'epoch': 18.44}
{'loss': 0.0195, 'grad_norm': 6.20831823348999, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.010023796930909157, 'loss_2': 0.00949859619140625, 'loss_3': -16.272724151611328, 'loss_4': 2.3630928993225098, 'epoch': 18.44}
{'loss': 0.0156, 'grad_norm': 4.867111682891846, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.011585844680666924, 'loss_2': 0.004024505615234375, 'loss_3': -16.228240966796875, 'loss_4': 1.93274986743927, 'epoch': 18.45}
{'loss': 0.0096, 'grad_norm': 5.722244739532471, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.008329781703650951, 'loss_2': 0.0012416839599609375, 'loss_3': -16.261096954345703, 'loss_4': 2.5566368103027344, 'epoch': 18.45}
{'loss': 0.0131, 'grad_norm': 5.0483784675598145, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.010590767487883568, 'loss_2': 0.002552032470703125, 'loss_3': -16.269060134887695, 'loss_4': 1.935010313987732, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 10:42:12,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:12,665 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:27<34:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:20,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009889071807265282, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00706429174169898, 'eval_loss_2': 0.002824779599905014, 'eval_loss_3': -18.20463752746582, 'eval_loss_4': 1.9599189758300781, 'epoch': 18.46}
{'loss': 0.0119, 'grad_norm': 7.908578872680664, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.011598520912230015, 'loss_2': 0.00034880638122558594, 'loss_3': -16.531003952026367, 'loss_4': 2.1833503246307373, 'epoch': 18.47}
{'loss': 0.0058, 'grad_norm': 5.083409786224365, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.0037393567617982626, 'loss_2': 0.0020656585693359375, 'loss_3': -16.413265228271484, 'loss_4': 2.138049602508545, 'epoch': 18.47}
{'loss': 0.0144, 'grad_norm': 5.069584846496582, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.012734667398035526, 'loss_2': 0.0016326904296875, 'loss_3': -16.462553024291992, 'loss_4': 1.8792222738265991, 'epoch': 18.48}
{'loss': 0.0181, 'grad_norm': 5.65123176574707, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.012008224613964558, 'loss_2': 0.006084442138671875, 'loss_3': -16.280559539794922, 'loss_4': 2.7307300567626953, 'epoch': 18.48}
{'loss': 0.0112, 'grad_norm': 5.291387557983398, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.010763511061668396, 'loss_2': 0.00045418739318847656, 'loss_3': -16.169286727905273, 'loss_4': 2.36014461517334, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 10:42:20,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:20,001 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:34<34:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:27,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011232289485633373, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00722036836668849, 'eval_loss_2': 0.004011921584606171, 'eval_loss_3': -18.196002960205078, 'eval_loss_4': 1.9720127582550049, 'epoch': 18.49}
{'loss': 0.0111, 'grad_norm': 4.957850933074951, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.0075411247089505196, 'loss_2': 0.00357818603515625, 'loss_3': -16.294857025146484, 'loss_4': 2.7873995304107666, 'epoch': 18.49}
{'loss': 0.014, 'grad_norm': 5.681431770324707, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.011602809652686119, 'loss_2': 0.0023708343505859375, 'loss_3': -16.16119956970215, 'loss_4': 2.5766000747680664, 'epoch': 18.5}
{'loss': 0.0176, 'grad_norm': 9.17195987701416, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.01626630872488022, 'loss_2': 0.0013523101806640625, 'loss_3': -16.315683364868164, 'loss_4': 2.196397304534912, 'epoch': 18.51}
{'loss': 0.0105, 'grad_norm': 4.741825103759766, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.009106213226914406, 'loss_2': 0.001399993896484375, 'loss_3': -16.25580596923828, 'loss_4': 2.492936134338379, 'epoch': 18.51}
{'loss': 0.005, 'grad_norm': 5.0462751388549805, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.004364162217825651, 'loss_2': 0.000682830810546875, 'loss_3': -16.256145477294922, 'loss_4': 2.5627126693725586, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 10:42:27,343 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:27,343 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:41<34:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:34,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010704273357987404, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.621, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006831848993897438, 'eval_loss_2': 0.003872424364089966, 'eval_loss_3': -18.1861572265625, 'eval_loss_4': 1.9279708862304688, 'epoch': 18.52}
{'loss': 0.0086, 'grad_norm': 4.491277694702148, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.003980942536145449, 'loss_2': 0.00460052490234375, 'loss_3': -16.53685188293457, 'loss_4': 2.206342935562134, 'epoch': 18.52}
{'loss': 0.0178, 'grad_norm': 5.441774368286133, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.0137091726064682, 'loss_2': 0.004123687744140625, 'loss_3': -16.219871520996094, 'loss_4': 2.688100576400757, 'epoch': 18.53}
{'loss': 0.0084, 'grad_norm': 5.173893451690674, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.008013173937797546, 'loss_2': 0.000347137451171875, 'loss_3': -16.415876388549805, 'loss_4': 1.7317323684692383, 'epoch': 18.53}
{'loss': 0.0143, 'grad_norm': 10.133654594421387, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.01368933916091919, 'loss_2': 0.0006580352783203125, 'loss_3': -16.44424819946289, 'loss_4': 1.9964438676834106, 'epoch': 18.54}
{'loss': 0.0113, 'grad_norm': 5.088578701019287, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.0057526747696101665, 'loss_2': 0.00554656982421875, 'loss_3': -16.109567642211914, 'loss_4': 2.333920955657959, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 10:42:34,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:34,695 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:49<33:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:42,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009666422381997108, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.515, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006668785586953163, 'eval_loss_2': 0.0029976367950439453, 'eval_loss_3': -18.199337005615234, 'eval_loss_4': 1.8865370750427246, 'epoch': 18.55}
{'loss': 0.0134, 'grad_norm': 6.746476650238037, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.011751831509172916, 'loss_2': 0.00160980224609375, 'loss_3': -16.569866180419922, 'loss_4': 1.6687978506088257, 'epoch': 18.55}
{'loss': 0.0068, 'grad_norm': 5.019242286682129, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.005168392322957516, 'loss_2': 0.0016460418701171875, 'loss_3': -16.08868408203125, 'loss_4': 2.078860282897949, 'epoch': 18.56}
{'loss': 0.0216, 'grad_norm': 13.591323852539062, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.0216282457113266, 'loss_2': 1.990795135498047e-05, 'loss_3': -16.138347625732422, 'loss_4': 2.4805586338043213, 'epoch': 18.56}
{'loss': 0.0167, 'grad_norm': 5.759352684020996, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.00823305081576109, 'loss_2': 0.00850677490234375, 'loss_3': -16.34530258178711, 'loss_4': 2.3699734210968018, 'epoch': 18.57}
{'loss': 0.0091, 'grad_norm': 4.852269649505615, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.0043892827816307545, 'loss_2': 0.00472259521484375, 'loss_3': -16.251617431640625, 'loss_4': 2.474698066711426, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 10:42:42,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:42,037 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:18:56<33:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:49,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010911863297224045, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0067969076335430145, 'eval_loss_2': 0.00411495566368103, 'eval_loss_3': -18.20357322692871, 'eval_loss_4': 1.913869023323059, 'epoch': 18.58}
{'loss': 0.0074, 'grad_norm': 4.73270845413208, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.0050839995965361595, 'loss_2': 0.002292633056640625, 'loss_3': -16.282352447509766, 'loss_4': 2.5951857566833496, 'epoch': 18.58}
{'loss': 0.0117, 'grad_norm': 4.9470367431640625, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.0079139843583107, 'loss_2': 0.0037708282470703125, 'loss_3': -16.169872283935547, 'loss_4': 2.5552849769592285, 'epoch': 18.59}
{'loss': 0.0157, 'grad_norm': 5.040419578552246, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.007885097526013851, 'loss_2': 0.0078277587890625, 'loss_3': -16.297693252563477, 'loss_4': 2.085747718811035, 'epoch': 18.59}
{'loss': 0.0395, 'grad_norm': 15.982330322265625, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.033009160310029984, 'loss_2': 0.00653076171875, 'loss_3': -16.110551834106445, 'loss_4': 2.8886919021606445, 'epoch': 18.6}
{'loss': 0.0225, 'grad_norm': 6.749672889709473, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.018629277125000954, 'loss_2': 0.0038547515869140625, 'loss_3': -16.297794342041016, 'loss_4': 2.056542158126831, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 10:42:49,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:49,374 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:03<33:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:42:56,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010609710589051247, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.39, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006552838254719973, 'eval_loss_2': 0.004056870937347412, 'eval_loss_3': -18.209150314331055, 'eval_loss_4': 1.8350573778152466, 'epoch': 18.6}
{'loss': 0.0342, 'grad_norm': 10.160877227783203, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.027442673221230507, 'loss_2': 0.006755828857421875, 'loss_3': -16.300983428955078, 'loss_4': 1.9162721633911133, 'epoch': 18.61}
{'loss': 0.008, 'grad_norm': 4.448043346405029, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.0035041493829339743, 'loss_2': 0.00452423095703125, 'loss_3': -16.405029296875, 'loss_4': 1.8017653226852417, 'epoch': 18.62}
{'loss': 0.0127, 'grad_norm': 6.67447566986084, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.012460807338356972, 'loss_2': 0.00022935867309570312, 'loss_3': -16.314937591552734, 'loss_4': 2.008281707763672, 'epoch': 18.62}
{'loss': 0.013, 'grad_norm': 4.684359550476074, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.005938828457146883, 'loss_2': 0.00710296630859375, 'loss_3': -16.404987335205078, 'loss_4': 1.0811371803283691, 'epoch': 18.63}
{'loss': 0.0167, 'grad_norm': 5.265220642089844, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.009733276441693306, 'loss_2': 0.007015228271484375, 'loss_3': -16.355979919433594, 'loss_4': 1.3394365310668945, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 10:42:56,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:42:56,711 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:11<33:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:04,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01160731166601181, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.086, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0070555987767875195, 'eval_loss_2': 0.0045517124235630035, 'eval_loss_3': -18.203489303588867, 'eval_loss_4': 1.6370370388031006, 'epoch': 18.63}
{'loss': 0.0095, 'grad_norm': 5.550960540771484, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.00832298118621111, 'loss_2': 0.0011386871337890625, 'loss_3': -16.286762237548828, 'loss_4': 1.6626516580581665, 'epoch': 18.64}
{'loss': 0.0067, 'grad_norm': 4.765987396240234, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.0050569684244692326, 'loss_2': 0.0016117095947265625, 'loss_3': -16.556100845336914, 'loss_4': 1.374929666519165, 'epoch': 18.65}
{'loss': 0.0125, 'grad_norm': 4.789562225341797, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.010230112820863724, 'loss_2': 0.002307891845703125, 'loss_3': -16.406085968017578, 'loss_4': 1.0333964824676514, 'epoch': 18.65}
{'loss': 0.0093, 'grad_norm': 4.910054683685303, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.004316684324294329, 'loss_2': 0.00498199462890625, 'loss_3': -16.24612808227539, 'loss_4': 2.328076124191284, 'epoch': 18.66}
{'loss': 0.0134, 'grad_norm': 4.9315667152404785, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.007148982957005501, 'loss_2': 0.006229400634765625, 'loss_3': -16.25558090209961, 'loss_4': 1.9293842315673828, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 10:43:04,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:04,048 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:18<33:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:11,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013242567889392376, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008042480796575546, 'eval_loss_2': 0.005200088024139404, 'eval_loss_3': -18.21714210510254, 'eval_loss_4': 1.576263189315796, 'epoch': 18.66}
{'loss': 0.0138, 'grad_norm': 4.22303581237793, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.004579263739287853, 'loss_2': 0.00920867919921875, 'loss_3': -16.2103271484375, 'loss_4': 1.317479133605957, 'epoch': 18.67}
{'loss': 0.0155, 'grad_norm': 9.740577697753906, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.013756274245679379, 'loss_2': 0.001750946044921875, 'loss_3': -16.372468948364258, 'loss_4': 1.5454611778259277, 'epoch': 18.67}
{'loss': 0.0186, 'grad_norm': 9.66645336151123, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.015473801642656326, 'loss_2': 0.0031280517578125, 'loss_3': -16.275279998779297, 'loss_4': 2.20127272605896, 'epoch': 18.68}
{'loss': 0.0202, 'grad_norm': 10.085030555725098, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.01876603439450264, 'loss_2': 0.0014629364013671875, 'loss_3': -16.550798416137695, 'loss_4': 1.295910358428955, 'epoch': 18.69}
{'loss': 0.0134, 'grad_norm': 5.514462471008301, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.008932093158364296, 'loss_2': 0.004425048828125, 'loss_3': -16.461063385009766, 'loss_4': 1.8013966083526611, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 10:43:11,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:11,396 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:25<33:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:18,741 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01098810788244009, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00760046998038888, 'eval_loss_2': 0.003387637436389923, 'eval_loss_3': -18.23729705810547, 'eval_loss_4': 1.4154589176177979, 'epoch': 18.69}
{'loss': 0.0111, 'grad_norm': 4.311396598815918, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.005106113851070404, 'loss_2': 0.005962371826171875, 'loss_3': -16.194595336914062, 'loss_4': 1.1216057538986206, 'epoch': 18.7}
{'loss': 0.0233, 'grad_norm': 9.395374298095703, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.020176567137241364, 'loss_2': 0.003147125244140625, 'loss_3': -16.32771110534668, 'loss_4': 1.1774488687515259, 'epoch': 18.7}
{'loss': 0.0048, 'grad_norm': 4.64254903793335, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.003753488417714834, 'loss_2': 0.001007080078125, 'loss_3': -16.432838439941406, 'loss_4': 0.9553554058074951, 'epoch': 18.71}
{'loss': 0.01, 'grad_norm': 4.947368144989014, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.0068558696657419205, 'loss_2': 0.003131866455078125, 'loss_3': -16.460952758789062, 'loss_4': 1.7322289943695068, 'epoch': 18.72}
{'loss': 0.0084, 'grad_norm': 4.756584644317627, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.006089991424232721, 'loss_2': 0.002307891845703125, 'loss_3': -16.381881713867188, 'loss_4': 1.4417402744293213, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 10:43:18,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:18,742 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:33<33:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:26,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010888899676501751, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007997089996933937, 'eval_loss_2': 0.0028918087482452393, 'eval_loss_3': -18.246902465820312, 'eval_loss_4': 1.1939003467559814, 'epoch': 18.72}
{'loss': 0.0208, 'grad_norm': 8.529704093933105, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.014973383396863937, 'loss_2': 0.0058135986328125, 'loss_3': -16.491506576538086, 'loss_4': 1.2203168869018555, 'epoch': 18.73}
{'loss': 0.0232, 'grad_norm': 8.84105110168457, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.021079272031784058, 'loss_2': 0.002132415771484375, 'loss_3': -16.52712059020996, 'loss_4': 1.0719455480575562, 'epoch': 18.73}
{'loss': 0.0193, 'grad_norm': 5.296438217163086, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.007317539304494858, 'loss_2': 0.01201629638671875, 'loss_3': -16.410167694091797, 'loss_4': 0.9973133206367493, 'epoch': 18.74}
{'loss': 0.0139, 'grad_norm': 5.744438648223877, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.009749798104166985, 'loss_2': 0.00414276123046875, 'loss_3': -16.282001495361328, 'loss_4': 1.8147534132003784, 'epoch': 18.74}
{'loss': 0.0102, 'grad_norm': 5.479770660400391, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.009406509809195995, 'loss_2': 0.0008115768432617188, 'loss_3': -16.4314022064209, 'loss_4': 0.9704345464706421, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 10:43:26,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:26,079 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:40<33:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:33,413 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012322952039539814, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007383008953183889, 'eval_loss_2': 0.004939943552017212, 'eval_loss_3': -18.268728256225586, 'eval_loss_4': 0.9415473937988281, 'epoch': 18.75}
{'loss': 0.011, 'grad_norm': 8.631176948547363, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.010088170878589153, 'loss_2': 0.0009393692016601562, 'loss_3': -16.576765060424805, 'loss_4': 1.148512840270996, 'epoch': 18.76}
{'loss': 0.0135, 'grad_norm': 5.357031345367432, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.009245316497981548, 'loss_2': 0.00424957275390625, 'loss_3': -16.23983383178711, 'loss_4': 1.246405839920044, 'epoch': 18.76}
{'loss': 0.0078, 'grad_norm': 5.149416923522949, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.007003302685916424, 'loss_2': 0.0007658004760742188, 'loss_3': -16.357364654541016, 'loss_4': 0.9203406572341919, 'epoch': 18.77}
{'loss': 0.0131, 'grad_norm': 5.541558265686035, 'learning_rate': 1.125e-05, 'loss_1': 0.009109115228056908, 'loss_2': 0.00399017333984375, 'loss_3': -16.4711971282959, 'loss_4': 1.390839695930481, 'epoch': 18.77}
{'loss': 0.0178, 'grad_norm': 5.533921718597412, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.009862259030342102, 'loss_2': 0.0079498291015625, 'loss_3': -16.320446014404297, 'loss_4': 1.6711986064910889, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 10:43:33,413 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:33,413 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:47<33:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:40,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011319300159811974, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007439276669174433, 'eval_loss_2': 0.003880023956298828, 'eval_loss_3': -18.269498825073242, 'eval_loss_4': 0.8259061574935913, 'epoch': 18.78}
{'loss': 0.015, 'grad_norm': 6.87257194519043, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.014119421131908894, 'loss_2': 0.0008449554443359375, 'loss_3': -16.39820098876953, 'loss_4': 0.6320594549179077, 'epoch': 18.78}
{'loss': 0.0088, 'grad_norm': 5.1606125831604, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.008051781915128231, 'loss_2': 0.0007557868957519531, 'loss_3': -16.31114959716797, 'loss_4': 1.4486839771270752, 'epoch': 18.79}
{'loss': 0.0067, 'grad_norm': 5.184529781341553, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.006600622553378344, 'loss_2': 9.97781753540039e-05, 'loss_3': -16.568359375, 'loss_4': 0.8753919005393982, 'epoch': 18.8}
{'loss': 0.0096, 'grad_norm': 4.771002292633057, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.006167934741824865, 'loss_2': 0.003448486328125, 'loss_3': -16.556716918945312, 'loss_4': 0.8337658047676086, 'epoch': 18.8}
{'loss': 0.0094, 'grad_norm': 5.066655158996582, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.007837967947125435, 'loss_2': 0.0015163421630859375, 'loss_3': -16.169086456298828, 'loss_4': 0.6732137203216553, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 10:43:40,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:40,749 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:19:55<33:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:43:48,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01105422992259264, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007851330563426018, 'eval_loss_2': 0.0032029002904891968, 'eval_loss_3': -18.261478424072266, 'eval_loss_4': 0.6577510833740234, 'epoch': 18.81}
{'loss': 0.014, 'grad_norm': 6.168458461761475, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.013071050867438316, 'loss_2': 0.0009202957153320312, 'loss_3': -16.562288284301758, 'loss_4': 1.3673009872436523, 'epoch': 18.81}
{'loss': 0.0173, 'grad_norm': 5.944942951202393, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.010554151609539986, 'loss_2': 0.0067596435546875, 'loss_3': -16.45966339111328, 'loss_4': 1.731283187866211, 'epoch': 18.82}
{'loss': 0.0128, 'grad_norm': 4.973123073577881, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.006410146597772837, 'loss_2': 0.00640106201171875, 'loss_3': -16.412504196166992, 'loss_4': 0.7453573942184448, 'epoch': 18.83}
{'loss': 0.0077, 'grad_norm': 4.616541385650635, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.004154271446168423, 'loss_2': 0.0035400390625, 'loss_3': -16.31643295288086, 'loss_4': 1.1813983917236328, 'epoch': 18.83}
{'loss': 0.0084, 'grad_norm': 4.970963954925537, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.006419692188501358, 'loss_2': 0.0019512176513671875, 'loss_3': -16.40338897705078, 'loss_4': 1.2109365463256836, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 10:43:48,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:48,082 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:02<33:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:43:55,428 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012891698628664017, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008971171453595161, 'eval_loss_2': 0.003920525312423706, 'eval_loss_3': -18.250581741333008, 'eval_loss_4': 0.6085516810417175, 'epoch': 18.84}
{'loss': 0.0107, 'grad_norm': 4.715724945068359, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.006062694825232029, 'loss_2': 0.0045928955078125, 'loss_3': -16.54239845275879, 'loss_4': 1.3411552906036377, 'epoch': 18.84}
{'loss': 0.0146, 'grad_norm': 5.538960933685303, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.007991834543645382, 'loss_2': 0.006591796875, 'loss_3': -16.375015258789062, 'loss_4': 1.0040507316589355, 'epoch': 18.85}
{'loss': 0.0056, 'grad_norm': 4.604001998901367, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.0045144762843847275, 'loss_2': 0.0010709762573242188, 'loss_3': -16.255672454833984, 'loss_4': 1.600740671157837, 'epoch': 18.85}
{'loss': 0.0225, 'grad_norm': 10.747268676757812, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.022429805248975754, 'loss_2': 3.4332275390625e-05, 'loss_3': -16.605144500732422, 'loss_4': 0.9277760982513428, 'epoch': 18.86}
{'loss': 0.0118, 'grad_norm': 5.259907245635986, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.006593907251954079, 'loss_2': 0.0052337646484375, 'loss_3': -16.40362548828125, 'loss_4': 0.7406027317047119, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 10:43:55,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:43:55,428 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:09<32:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:02,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015176152810454369, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009796654805541039, 'eval_loss_2': 0.00537949800491333, 'eval_loss_3': -18.2489070892334, 'eval_loss_4': 0.6189271211624146, 'epoch': 18.87}
{'loss': 0.0125, 'grad_norm': 5.288127422332764, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.0060468814335763454, 'loss_2': 0.006500244140625, 'loss_3': -16.248546600341797, 'loss_4': 1.4047223329544067, 'epoch': 18.87}
{'loss': 0.0223, 'grad_norm': 7.00600004196167, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.015458703972399235, 'loss_2': 0.00682830810546875, 'loss_3': -16.147964477539062, 'loss_4': 1.713451862335205, 'epoch': 18.88}
{'loss': 0.011, 'grad_norm': 5.2486724853515625, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.006165673024952412, 'loss_2': 0.004791259765625, 'loss_3': -16.395374298095703, 'loss_4': 1.4929276704788208, 'epoch': 18.88}
{'loss': 0.005, 'grad_norm': 5.037489414215088, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.004363400395959616, 'loss_2': 0.0006794929504394531, 'loss_3': -16.334949493408203, 'loss_4': 1.4478925466537476, 'epoch': 18.89}
{'loss': 0.0037, 'grad_norm': 4.948971748352051, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.003204478183761239, 'loss_2': 0.0004563331604003906, 'loss_3': -16.428083419799805, 'loss_4': 0.8927090764045715, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 10:44:02,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:02,760 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:17<32:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:44:10,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013761909678578377, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008858265355229378, 'eval_loss_2': 0.004903644323348999, 'eval_loss_3': -18.239656448364258, 'eval_loss_4': 0.7940657138824463, 'epoch': 18.9}
{'loss': 0.0199, 'grad_norm': 7.897083282470703, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.019748566672205925, 'loss_2': 0.00014770030975341797, 'loss_3': -16.302772521972656, 'loss_4': 1.2472625970840454, 'epoch': 18.9}
{'loss': 0.0128, 'grad_norm': 6.3716654777526855, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.010884963907301426, 'loss_2': 0.001926422119140625, 'loss_3': -16.254709243774414, 'loss_4': 1.0463855266571045, 'epoch': 18.91}
{'loss': 0.0147, 'grad_norm': 8.87935733795166, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.013664836063981056, 'loss_2': 0.0010528564453125, 'loss_3': -16.299667358398438, 'loss_4': 0.952338457107544, 'epoch': 18.91}
{'loss': 0.0097, 'grad_norm': 5.753410816192627, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.008465886116027832, 'loss_2': 0.0012540817260742188, 'loss_3': -16.420215606689453, 'loss_4': 1.2103080749511719, 'epoch': 18.92}
{'loss': 0.0087, 'grad_norm': 4.359115123748779, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.0028188859578222036, 'loss_2': 0.00585174560546875, 'loss_3': -16.267770767211914, 'loss_4': 1.4806147813796997, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 10:44:10,094 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:10,094 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:24<32:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:17,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013481030240654945, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009659450501203537, 'eval_loss_2': 0.0038215816020965576, 'eval_loss_3': -18.235729217529297, 'eval_loss_4': 0.8371052742004395, 'epoch': 18.92}
{'loss': 0.0067, 'grad_norm': 5.000742435455322, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.004719724878668785, 'loss_2': 0.0019893646240234375, 'loss_3': -16.325428009033203, 'loss_4': 0.7589768171310425, 'epoch': 18.93}
{'loss': 0.0206, 'grad_norm': 5.526440620422363, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.009759828448295593, 'loss_2': 0.0108489990234375, 'loss_3': -16.49102783203125, 'loss_4': 1.0226426124572754, 'epoch': 18.94}
{'loss': 0.008, 'grad_norm': 5.386674404144287, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.006369427777826786, 'loss_2': 0.0016422271728515625, 'loss_3': -16.30135726928711, 'loss_4': 0.8970715403556824, 'epoch': 18.94}
{'loss': 0.0111, 'grad_norm': 6.702470302581787, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.006733778398483992, 'loss_2': 0.004367828369140625, 'loss_3': -16.354576110839844, 'loss_4': 0.7045395970344543, 'epoch': 18.95}
{'loss': 0.006, 'grad_norm': 4.743640422821045, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.0042937216348946095, 'loss_2': 0.001667022705078125, 'loss_3': -16.41239356994629, 'loss_4': 1.4455993175506592, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 10:44:17,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:17,425 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:31<32:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:24,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013056057505309582, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009194153361022472, 'eval_loss_2': 0.0038619041442871094, 'eval_loss_3': -18.221895217895508, 'eval_loss_4': 0.7704736590385437, 'epoch': 18.95}
{'loss': 0.0175, 'grad_norm': 6.612453460693359, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.012126331217586994, 'loss_2': 0.005401611328125, 'loss_3': -16.32526206970215, 'loss_4': 0.36916857957839966, 'epoch': 18.96}
{'loss': 0.0097, 'grad_norm': 6.443060874938965, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.008897298946976662, 'loss_2': 0.0007872581481933594, 'loss_3': -16.512535095214844, 'loss_4': 1.0677285194396973, 'epoch': 18.97}
{'loss': 0.0101, 'grad_norm': 5.500297546386719, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.00753331184387207, 'loss_2': 0.0026073455810546875, 'loss_3': -16.700096130371094, 'loss_4': 1.3523081541061401, 'epoch': 18.97}
{'loss': 0.0055, 'grad_norm': 4.445181846618652, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.003021641168743372, 'loss_2': 0.0024471282958984375, 'loss_3': -16.491945266723633, 'loss_4': 0.9401757717132568, 'epoch': 18.98}
{'loss': 0.0111, 'grad_norm': 5.6438822746276855, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.011039377190172672, 'loss_2': 4.029273986816406e-05, 'loss_3': -16.41039276123047, 'loss_4': 1.2827961444854736, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 10:44:24,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:24,760 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:39<31:19,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 10:44:31,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012991716153919697, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008861338719725609, 'eval_loss_2': 0.004130378365516663, 'eval_loss_3': -18.24266815185547, 'eval_loss_4': 0.6190736293792725, 'epoch': 18.98}
{'loss': 0.0121, 'grad_norm': 5.038220405578613, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.005174805875867605, 'loss_2': 0.00696563720703125, 'loss_3': -16.37118911743164, 'loss_4': 1.1428606510162354, 'epoch': 18.99}
{'loss': 0.0172, 'grad_norm': 6.804725170135498, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.012892900966107845, 'loss_2': 0.00431060791015625, 'loss_3': -16.411237716674805, 'loss_4': 0.7970376014709473, 'epoch': 18.99}
{'loss': 0.0274, 'grad_norm': 14.367469787597656, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.016615109518170357, 'loss_2': 0.01076507568359375, 'loss_3': -16.46918487548828, 'loss_4': 0.7660296559333801, 'epoch': 19.0}
{'loss': 0.0106, 'grad_norm': 4.724724769592285, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.007296198979020119, 'loss_2': 0.0033111572265625, 'loss_3': -16.382274627685547, 'loss_4': 0.7934587597846985, 'epoch': 19.01}
{'loss': 0.0204, 'grad_norm': 6.337279319763184, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.015079530887305737, 'loss_2': 0.0052947998046875, 'loss_3': -16.438098907470703, 'loss_4': 0.8343230485916138, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 10:44:31,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:31,793 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:46<32:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:44:39,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013494824059307575, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.689, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00899147056043148, 'eval_loss_2': 0.004503354430198669, 'eval_loss_3': -18.25337791442871, 'eval_loss_4': 0.5741853713989258, 'epoch': 19.01}
{'loss': 0.0111, 'grad_norm': 5.470089912414551, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.008476769551634789, 'loss_2': 0.002574920654296875, 'loss_3': -16.223194122314453, 'loss_4': 1.1886504888534546, 'epoch': 19.02}
{'loss': 0.0167, 'grad_norm': 5.765852451324463, 'learning_rate': 1.1e-05, 'loss_1': 0.0066556064411997795, 'loss_2': 0.0100555419921875, 'loss_3': -16.394302368164062, 'loss_4': 1.1815533638000488, 'epoch': 19.02}
{'loss': 0.0089, 'grad_norm': 5.902299880981445, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.008610100485384464, 'loss_2': 0.00028824806213378906, 'loss_3': -16.41135597229004, 'loss_4': 0.9774683713912964, 'epoch': 19.03}
{'loss': 0.0121, 'grad_norm': 5.702706813812256, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.009214605204761028, 'loss_2': 0.0028591156005859375, 'loss_3': -16.46481704711914, 'loss_4': 0.8944374918937683, 'epoch': 19.03}
{'loss': 0.0115, 'grad_norm': 5.462793350219727, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.009743567556142807, 'loss_2': 0.0017671585083007812, 'loss_3': -16.410037994384766, 'loss_4': 0.43433448672294617, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 10:44:39,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:39,142 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:20:53<32:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:44:46,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01326821744441986, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.291, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00959357526153326, 'eval_loss_2': 0.003674641251564026, 'eval_loss_3': -18.25242805480957, 'eval_loss_4': 0.6009951233863831, 'epoch': 19.04}
{'loss': 0.0121, 'grad_norm': 4.800322532653809, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.006029692944139242, 'loss_2': 0.00608062744140625, 'loss_3': -16.442594528198242, 'loss_4': 1.367194414138794, 'epoch': 19.05}
{'loss': 0.0074, 'grad_norm': 4.655557155609131, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.004724418744444847, 'loss_2': 0.0026454925537109375, 'loss_3': -16.58258056640625, 'loss_4': 1.4318286180496216, 'epoch': 19.05}
{'loss': 0.0203, 'grad_norm': 6.750670909881592, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.016919901594519615, 'loss_2': 0.00339508056640625, 'loss_3': -16.275081634521484, 'loss_4': 1.5235202312469482, 'epoch': 19.06}
{'loss': 0.0117, 'grad_norm': 5.8836164474487305, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.007905731908977032, 'loss_2': 0.00374603271484375, 'loss_3': -16.258174896240234, 'loss_4': 0.601760745048523, 'epoch': 19.06}
{'loss': 0.0079, 'grad_norm': 4.734853744506836, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.005168361123651266, 'loss_2': 0.002758026123046875, 'loss_3': -16.241044998168945, 'loss_4': 0.34591740369796753, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 10:44:46,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:46,477 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:01<32:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:44:53,823 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012142656370997429, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008794045075774193, 'eval_loss_2': 0.003348611295223236, 'eval_loss_3': -18.260684967041016, 'eval_loss_4': 0.7163620591163635, 'epoch': 19.07}
{'loss': 0.0143, 'grad_norm': 5.795055866241455, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.008256600238382816, 'loss_2': 0.0059967041015625, 'loss_3': -16.446636199951172, 'loss_4': 1.4420366287231445, 'epoch': 19.08}
{'loss': 0.0177, 'grad_norm': 5.400406360626221, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.008423972874879837, 'loss_2': 0.0092926025390625, 'loss_3': -16.436397552490234, 'loss_4': 0.8640669584274292, 'epoch': 19.08}
{'loss': 0.0188, 'grad_norm': 6.785473823547363, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.015278234146535397, 'loss_2': 0.003513336181640625, 'loss_3': -16.418123245239258, 'loss_4': 1.1311241388320923, 'epoch': 19.09}
{'loss': 0.0104, 'grad_norm': 5.651602268218994, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.009280805476009846, 'loss_2': 0.0010833740234375, 'loss_3': -16.334524154663086, 'loss_4': 1.062509298324585, 'epoch': 19.09}
{'loss': 0.0079, 'grad_norm': 4.713998317718506, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.005208044312894344, 'loss_2': 0.002712249755859375, 'loss_3': -16.180002212524414, 'loss_4': 0.9629114866256714, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 10:44:53,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:44:53,824 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:08<32:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:01,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012906089425086975, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.528, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008981822989881039, 'eval_loss_2': 0.003924265503883362, 'eval_loss_3': -18.258180618286133, 'eval_loss_4': 0.8950660824775696, 'epoch': 19.1}
{'loss': 0.0055, 'grad_norm': 4.756520748138428, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.005390120670199394, 'loss_2': 6.377696990966797e-05, 'loss_3': -16.386016845703125, 'loss_4': 1.0811381340026855, 'epoch': 19.1}
{'loss': 0.0085, 'grad_norm': 5.438060283660889, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.00681177107617259, 'loss_2': 0.0016422271728515625, 'loss_3': -16.415651321411133, 'loss_4': 0.8012474775314331, 'epoch': 19.11}
{'loss': 0.0087, 'grad_norm': 4.890122890472412, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.00643351161852479, 'loss_2': 0.00231170654296875, 'loss_3': -16.474258422851562, 'loss_4': 1.0578089952468872, 'epoch': 19.12}
{'loss': 0.0152, 'grad_norm': 7.818149089813232, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.01325385831296444, 'loss_2': 0.0019168853759765625, 'loss_3': -16.36927032470703, 'loss_4': 1.3198938369750977, 'epoch': 19.12}
{'loss': 0.0035, 'grad_norm': 4.66029167175293, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.002945209853351116, 'loss_2': 0.0005769729614257812, 'loss_3': -16.68073272705078, 'loss_4': 1.3288087844848633, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 10:45:01,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:01,163 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:15<32:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:08,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01069655828177929, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007653889711946249, 'eval_loss_2': 0.003042668104171753, 'eval_loss_3': -18.240280151367188, 'eval_loss_4': 0.9406728744506836, 'epoch': 19.13}
{'loss': 0.0092, 'grad_norm': 5.324385166168213, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.007218967657536268, 'loss_2': 0.0019369125366210938, 'loss_3': -16.234642028808594, 'loss_4': 1.1529712677001953, 'epoch': 19.13}
{'loss': 0.0203, 'grad_norm': 5.544228553771973, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.011727998033165932, 'loss_2': 0.008575439453125, 'loss_3': -16.3911190032959, 'loss_4': 1.3976789712905884, 'epoch': 19.14}
{'loss': 0.0057, 'grad_norm': 4.86470365524292, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.005570976063609123, 'loss_2': 0.0001417398452758789, 'loss_3': -16.406997680664062, 'loss_4': 1.4091479778289795, 'epoch': 19.15}
{'loss': 0.0111, 'grad_norm': 5.502967357635498, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.008174925111234188, 'loss_2': 0.002899169921875, 'loss_3': -16.332937240600586, 'loss_4': 1.410895824432373, 'epoch': 19.15}
{'loss': 0.0111, 'grad_norm': 4.935941219329834, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.008259528316557407, 'loss_2': 0.0028591156005859375, 'loss_3': -16.56721305847168, 'loss_4': 0.866571843624115, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 10:45:08,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:08,501 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:23<32:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:15,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00987805426120758, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.602, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00678433571010828, 'eval_loss_2': 0.003093719482421875, 'eval_loss_3': -18.218130111694336, 'eval_loss_4': 1.0315492153167725, 'epoch': 19.16}
{'loss': 0.0184, 'grad_norm': 6.11882209777832, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.012495690025389194, 'loss_2': 0.005916595458984375, 'loss_3': -16.3483829498291, 'loss_4': 0.9072955846786499, 'epoch': 19.16}
{'loss': 0.0174, 'grad_norm': 8.919340133666992, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.017145875841379166, 'loss_2': 0.0003018379211425781, 'loss_3': -16.610546112060547, 'loss_4': 0.7153019905090332, 'epoch': 19.17}
{'loss': 0.0118, 'grad_norm': 11.921070098876953, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.008063429035246372, 'loss_2': 0.003692626953125, 'loss_3': -16.369701385498047, 'loss_4': 1.4273535013198853, 'epoch': 19.17}
{'loss': 0.0134, 'grad_norm': 5.286346912384033, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.008902194909751415, 'loss_2': 0.00447845458984375, 'loss_3': -16.40424346923828, 'loss_4': 2.297414779663086, 'epoch': 19.18}
{'loss': 0.0122, 'grad_norm': 5.01577615737915, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.008073439821600914, 'loss_2': 0.004108428955078125, 'loss_3': -16.303329467773438, 'loss_4': 0.420488178730011, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 10:45:15,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:15,855 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:30<32:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:23,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009098201990127563, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006048336159437895, 'eval_loss_2': 0.0030498653650283813, 'eval_loss_3': -18.2141170501709, 'eval_loss_4': 1.0717450380325317, 'epoch': 19.19}
{'loss': 0.0065, 'grad_norm': 5.464829921722412, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.006463826168328524, 'loss_2': 3.0994415283203125e-05, 'loss_3': -16.23927116394043, 'loss_4': 1.3508707284927368, 'epoch': 19.19}
{'loss': 0.0164, 'grad_norm': 7.080763816833496, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.010507765226066113, 'loss_2': 0.00591278076171875, 'loss_3': -16.482860565185547, 'loss_4': 1.520308256149292, 'epoch': 19.2}
{'loss': 0.0233, 'grad_norm': 16.7322998046875, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.021644143387675285, 'loss_2': 0.001659393310546875, 'loss_3': -16.154193878173828, 'loss_4': 1.682807445526123, 'epoch': 19.2}
{'loss': 0.0276, 'grad_norm': 7.354213714599609, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.015849217772483826, 'loss_2': 0.01171112060546875, 'loss_3': -16.33568572998047, 'loss_4': 1.3092644214630127, 'epoch': 19.21}
{'loss': 0.0138, 'grad_norm': 5.5540595054626465, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.010524428449571133, 'loss_2': 0.0032901763916015625, 'loss_3': -16.380353927612305, 'loss_4': 1.9084792137145996, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 10:45:23,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:23,191 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:37<31:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:30,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009663774631917477, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005380346439778805, 'eval_loss_2': 0.004283428192138672, 'eval_loss_3': -18.22184181213379, 'eval_loss_4': 1.3397777080535889, 'epoch': 19.22}
{'loss': 0.0119, 'grad_norm': 5.172094821929932, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.007987036369740963, 'loss_2': 0.003871917724609375, 'loss_3': -16.33766746520996, 'loss_4': 1.805867314338684, 'epoch': 19.22}
{'loss': 0.0133, 'grad_norm': 7.723724365234375, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.012903568334877491, 'loss_2': 0.00039696693420410156, 'loss_3': -16.402151107788086, 'loss_4': 2.3489179611206055, 'epoch': 19.23}
{'loss': 0.0097, 'grad_norm': 5.12730598449707, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.004993060603737831, 'loss_2': 0.004703521728515625, 'loss_3': -16.431241989135742, 'loss_4': 1.6492040157318115, 'epoch': 19.23}
{'loss': 0.0103, 'grad_norm': 5.039047718048096, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.006015843711793423, 'loss_2': 0.0042877197265625, 'loss_3': -16.372032165527344, 'loss_4': 1.2586716413497925, 'epoch': 19.24}
{'loss': 0.0066, 'grad_norm': 4.403700828552246, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.004438038915395737, 'loss_2': 0.00217437744140625, 'loss_3': -16.39829444885254, 'loss_4': 1.7443664073944092, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 10:45:30,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:30,529 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:45<31:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:37,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009307529777288437, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.005462434142827988, 'eval_loss_2': 0.0038450956344604492, 'eval_loss_3': -18.228134155273438, 'eval_loss_4': 1.4218748807907104, 'epoch': 19.24}
{'loss': 0.006, 'grad_norm': 4.888978481292725, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.005448759067803621, 'loss_2': 0.0005359649658203125, 'loss_3': -16.240488052368164, 'loss_4': 1.4995331764221191, 'epoch': 19.25}
{'loss': 0.0089, 'grad_norm': 4.4726481437683105, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.006039376836270094, 'loss_2': 0.00290679931640625, 'loss_3': -16.334016799926758, 'loss_4': 1.625359296798706, 'epoch': 19.26}
{'loss': 0.0096, 'grad_norm': 6.781495094299316, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.008721502497792244, 'loss_2': 0.0008602142333984375, 'loss_3': -16.184467315673828, 'loss_4': 1.748767375946045, 'epoch': 19.26}
{'loss': 0.0057, 'grad_norm': 4.687688827514648, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.005646975245326757, 'loss_2': 7.021427154541016e-05, 'loss_3': -16.398944854736328, 'loss_4': 1.23384690284729, 'epoch': 19.27}
{'loss': 0.0165, 'grad_norm': 5.272956371307373, 'learning_rate': 1.075e-05, 'loss_1': 0.01114892028272152, 'loss_2': 0.005382537841796875, 'loss_3': -16.282560348510742, 'loss_4': 1.2077804803848267, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 10:45:37,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:37,861 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:52<31:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:45,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00854921992868185, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0049696750938892365, 'eval_loss_2': 0.0035795457661151886, 'eval_loss_3': -18.242128372192383, 'eval_loss_4': 1.3736348152160645, 'epoch': 19.27}
{'loss': 0.0062, 'grad_norm': 5.041476726531982, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.003450507763773203, 'loss_2': 0.0027828216552734375, 'loss_3': -16.416397094726562, 'loss_4': 2.1636228561401367, 'epoch': 19.28}
{'loss': 0.0197, 'grad_norm': 14.23763370513916, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.017462696880102158, 'loss_2': 0.00228118896484375, 'loss_3': -16.492656707763672, 'loss_4': 1.122099757194519, 'epoch': 19.28}
{'loss': 0.0073, 'grad_norm': 5.026679515838623, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.005838665179908276, 'loss_2': 0.0014743804931640625, 'loss_3': -16.186885833740234, 'loss_4': 1.3847284317016602, 'epoch': 19.29}
{'loss': 0.0124, 'grad_norm': 5.214441299438477, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.008555743843317032, 'loss_2': 0.003833770751953125, 'loss_3': -16.44003677368164, 'loss_4': 2.5199666023254395, 'epoch': 19.3}
{'loss': 0.0075, 'grad_norm': 4.524350643157959, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.0037556623574346304, 'loss_2': 0.0037479400634765625, 'loss_3': -16.297096252441406, 'loss_4': 2.029417037963867, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 10:45:45,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:45,195 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:21:59<31:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:52,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009183738380670547, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0049726106226444244, 'eval_loss_2': 0.004211127758026123, 'eval_loss_3': -18.236316680908203, 'eval_loss_4': 1.4375219345092773, 'epoch': 19.3}
{'loss': 0.0077, 'grad_norm': 5.2227373123168945, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.005868966691195965, 'loss_2': 0.0018053054809570312, 'loss_3': -16.503807067871094, 'loss_4': 1.9035673141479492, 'epoch': 19.31}
{'loss': 0.0089, 'grad_norm': 4.395206451416016, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.0064852857030928135, 'loss_2': 0.002376556396484375, 'loss_3': -16.51885223388672, 'loss_4': 1.7431756258010864, 'epoch': 19.31}
{'loss': 0.0075, 'grad_norm': 4.907101154327393, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.004088662564754486, 'loss_2': 0.003406524658203125, 'loss_3': -16.445388793945312, 'loss_4': 1.807607889175415, 'epoch': 19.32}
{'loss': 0.0072, 'grad_norm': 5.3364763259887695, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.004869426600635052, 'loss_2': 0.0023040771484375, 'loss_3': -16.29021453857422, 'loss_4': 2.1160264015197754, 'epoch': 19.33}
{'loss': 0.0104, 'grad_norm': 5.430788516998291, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.006635786034166813, 'loss_2': 0.003772735595703125, 'loss_3': -16.202482223510742, 'loss_4': 2.09615421295166, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 10:45:52,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:52,538 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:07<31:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:45:59,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01055074017494917, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.267, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006017199717462063, 'eval_loss_2': 0.004533540457487106, 'eval_loss_3': -18.223770141601562, 'eval_loss_4': 1.5237455368041992, 'epoch': 19.33}
{'loss': 0.0173, 'grad_norm': 7.939780235290527, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.015224113129079342, 'loss_2': 0.002063751220703125, 'loss_3': -16.407983779907227, 'loss_4': 1.5283880233764648, 'epoch': 19.34}
{'loss': 0.0105, 'grad_norm': 4.670791149139404, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.004380917642265558, 'loss_2': 0.00612640380859375, 'loss_3': -16.430288314819336, 'loss_4': 1.2089636325836182, 'epoch': 19.34}
{'loss': 0.0111, 'grad_norm': 4.852474689483643, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.006125766783952713, 'loss_2': 0.00496673583984375, 'loss_3': -16.35491943359375, 'loss_4': 1.4533777236938477, 'epoch': 19.35}
{'loss': 0.0098, 'grad_norm': 5.118254661560059, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.004820273723453283, 'loss_2': 0.00493621826171875, 'loss_3': -16.480213165283203, 'loss_4': 1.6867444515228271, 'epoch': 19.35}
{'loss': 0.0132, 'grad_norm': 5.058536052703857, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.006995313800871372, 'loss_2': 0.0062408447265625, 'loss_3': -16.354156494140625, 'loss_4': 1.0623605251312256, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 10:45:59,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:45:59,890 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:14<31:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:07,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009805072098970413, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005805094726383686, 'eval_loss_2': 0.003999978303909302, 'eval_loss_3': -18.231613159179688, 'eval_loss_4': 1.682029366493225, 'epoch': 19.36}
{'loss': 0.0223, 'grad_norm': 6.1011762619018555, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.016459444537758827, 'loss_2': 0.005802154541015625, 'loss_3': -16.40496826171875, 'loss_4': 1.982008695602417, 'epoch': 19.37}
{'loss': 0.0074, 'grad_norm': 5.49284553527832, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.004737300798296928, 'loss_2': 0.0026454925537109375, 'loss_3': -16.294063568115234, 'loss_4': 2.198805332183838, 'epoch': 19.37}
{'loss': 0.0112, 'grad_norm': 4.91556978225708, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.005607039667665958, 'loss_2': 0.005615234375, 'loss_3': -16.35680389404297, 'loss_4': 1.952046275138855, 'epoch': 19.38}
{'loss': 0.0142, 'grad_norm': 6.213251113891602, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.01110968180000782, 'loss_2': 0.0030498504638671875, 'loss_3': -16.432191848754883, 'loss_4': 1.8983827829360962, 'epoch': 19.38}
{'loss': 0.0074, 'grad_norm': 5.176295280456543, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.0050009069964289665, 'loss_2': 0.002429962158203125, 'loss_3': -16.271678924560547, 'loss_4': 2.8462891578674316, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 10:46:07,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:07,232 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:21<31:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:14,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011204554699361324, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004641382489353418, 'eval_loss_2': 0.006563171744346619, 'eval_loss_3': -18.240034103393555, 'eval_loss_4': 1.79117751121521, 'epoch': 19.39}
{'loss': 0.0315, 'grad_norm': 9.889140129089355, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.02273974008858204, 'loss_2': 0.008758544921875, 'loss_3': -16.43462562561035, 'loss_4': 2.3534939289093018, 'epoch': 19.4}
{'loss': 0.0259, 'grad_norm': 8.078343391418457, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.01800404116511345, 'loss_2': 0.00785064697265625, 'loss_3': -16.165424346923828, 'loss_4': 1.7022391557693481, 'epoch': 19.4}
{'loss': 0.019, 'grad_norm': 7.388399600982666, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.009524339810013771, 'loss_2': 0.0094757080078125, 'loss_3': -16.252120971679688, 'loss_4': 2.3803868293762207, 'epoch': 19.41}
{'loss': 0.0157, 'grad_norm': 7.596800804138184, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.015438457950949669, 'loss_2': 0.0002722740173339844, 'loss_3': -16.26378631591797, 'loss_4': 1.5070886611938477, 'epoch': 19.41}
{'loss': 0.0136, 'grad_norm': 5.272251129150391, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.008197139948606491, 'loss_2': 0.005428314208984375, 'loss_3': -16.498851776123047, 'loss_4': 2.5510330200195312, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 10:46:14,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:14,576 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:29<31:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:21,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01129298284649849, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005086411722004414, 'eval_loss_2': 0.00620657205581665, 'eval_loss_3': -18.248966217041016, 'eval_loss_4': 1.9092395305633545, 'epoch': 19.42}
{'loss': 0.0116, 'grad_norm': 5.744847297668457, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.006847989745438099, 'loss_2': 0.004791259765625, 'loss_3': -16.420604705810547, 'loss_4': 1.9535400867462158, 'epoch': 19.42}
{'loss': 0.0118, 'grad_norm': 4.148776054382324, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.00454349908977747, 'loss_2': 0.007221221923828125, 'loss_3': -16.385440826416016, 'loss_4': 1.9469354152679443, 'epoch': 19.43}
{'loss': 0.008, 'grad_norm': 5.802123069763184, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.004988651257008314, 'loss_2': 0.00296783447265625, 'loss_3': -16.205209732055664, 'loss_4': 2.169891357421875, 'epoch': 19.44}
{'loss': 0.0058, 'grad_norm': 4.54777717590332, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.004875577054917812, 'loss_2': 0.0009307861328125, 'loss_3': -16.184192657470703, 'loss_4': 2.444026470184326, 'epoch': 19.44}
{'loss': 0.0052, 'grad_norm': 4.455272674560547, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.003820147132501006, 'loss_2': 0.00138092041015625, 'loss_3': -16.27381706237793, 'loss_4': 1.9613699913024902, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 10:46:21,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:21,915 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:36<31:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:29,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009191793389618397, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005550731904804707, 'eval_loss_2': 0.00364106148481369, 'eval_loss_3': -18.262971878051758, 'eval_loss_4': 2.056884765625, 'epoch': 19.45}
{'loss': 0.0121, 'grad_norm': 7.179989814758301, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.01068690326064825, 'loss_2': 0.0014162063598632812, 'loss_3': -16.44507598876953, 'loss_4': 2.7382187843322754, 'epoch': 19.45}
{'loss': 0.0073, 'grad_norm': 5.25996732711792, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.006426069885492325, 'loss_2': 0.0008549690246582031, 'loss_3': -16.37530517578125, 'loss_4': 2.5710227489471436, 'epoch': 19.46}
{'loss': 0.0057, 'grad_norm': 5.353949546813965, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.0054980916902422905, 'loss_2': 0.0001697540283203125, 'loss_3': -16.26795768737793, 'loss_4': 2.288017511367798, 'epoch': 19.47}
{'loss': 0.0136, 'grad_norm': 6.874202728271484, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.009095391258597374, 'loss_2': 0.004543304443359375, 'loss_3': -16.354347229003906, 'loss_4': 2.550312042236328, 'epoch': 19.47}
{'loss': 0.0081, 'grad_norm': 4.697862148284912, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.0037828038912266493, 'loss_2': 0.0042877197265625, 'loss_3': -16.367307662963867, 'loss_4': 2.1894724369049072, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 10:46:29,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:29,254 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:43<31:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:36,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009637635201215744, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.801, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006059031467884779, 'eval_loss_2': 0.0035786032676696777, 'eval_loss_3': -18.26305389404297, 'eval_loss_4': 2.1341376304626465, 'epoch': 19.48}
{'loss': 0.0146, 'grad_norm': 5.0879669189453125, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.01189439743757248, 'loss_2': 0.0027313232421875, 'loss_3': -16.2899169921875, 'loss_4': 2.515089988708496, 'epoch': 19.48}
{'loss': 0.0117, 'grad_norm': 4.908467769622803, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.005641954950988293, 'loss_2': 0.006072998046875, 'loss_3': -16.291109085083008, 'loss_4': 2.06643009185791, 'epoch': 19.49}
{'loss': 0.0178, 'grad_norm': 6.083154678344727, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.009216557256877422, 'loss_2': 0.00861358642578125, 'loss_3': -16.43545913696289, 'loss_4': 2.518261671066284, 'epoch': 19.49}
{'loss': 0.0072, 'grad_norm': 5.240444183349609, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.006571680773049593, 'loss_2': 0.0005917549133300781, 'loss_3': -16.380542755126953, 'loss_4': 2.3421192169189453, 'epoch': 19.5}
{'loss': 0.0193, 'grad_norm': 5.5872273445129395, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.010113772936165333, 'loss_2': 0.0091705322265625, 'loss_3': -16.424779891967773, 'loss_4': 3.089446544647217, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 10:46:36,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:36,604 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:51<31:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:43,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011661715805530548, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.103, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00698293000459671, 'eval_loss_2': 0.004678785800933838, 'eval_loss_3': -18.27988624572754, 'eval_loss_4': 2.209961175918579, 'epoch': 19.51}
{'loss': 0.0068, 'grad_norm': 4.9384050369262695, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.006148089654743671, 'loss_2': 0.0006608963012695312, 'loss_3': -16.383281707763672, 'loss_4': 1.944854974746704, 'epoch': 19.51}
{'loss': 0.014, 'grad_norm': 4.600266456604004, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.007222777232527733, 'loss_2': 0.00673675537109375, 'loss_3': -16.458219528198242, 'loss_4': 2.4423625469207764, 'epoch': 19.52}
{'loss': 0.0104, 'grad_norm': 4.6685333251953125, 'learning_rate': 1.05e-05, 'loss_1': 0.004631876014173031, 'loss_2': 0.0058135986328125, 'loss_3': -16.31682014465332, 'loss_4': 2.8274734020233154, 'epoch': 19.52}
{'loss': 0.0079, 'grad_norm': 4.496679782867432, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.005621777381747961, 'loss_2': 0.0023040771484375, 'loss_3': -16.40825653076172, 'loss_4': 2.7886102199554443, 'epoch': 19.53}
{'loss': 0.0119, 'grad_norm': 4.560460567474365, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.00648385239765048, 'loss_2': 0.00542449951171875, 'loss_3': -16.392690658569336, 'loss_4': 3.7008628845214844, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 10:46:43,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:43,952 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:22:58<31:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:51,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011594810523092747, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007068068720400333, 'eval_loss_2': 0.004526741802692413, 'eval_loss_3': -18.278221130371094, 'eval_loss_4': 2.2518675327301025, 'epoch': 19.53}
{'loss': 0.0122, 'grad_norm': 4.514556884765625, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.005955227185040712, 'loss_2': 0.0062103271484375, 'loss_3': -16.379749298095703, 'loss_4': 2.1155614852905273, 'epoch': 19.54}
{'loss': 0.006, 'grad_norm': 4.887640476226807, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.003192583564668894, 'loss_2': 0.002819061279296875, 'loss_3': -16.60540771484375, 'loss_4': 2.790602684020996, 'epoch': 19.55}
{'loss': 0.0075, 'grad_norm': 5.130819797515869, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.007087560370564461, 'loss_2': 0.00044727325439453125, 'loss_3': -16.536632537841797, 'loss_4': 2.5162391662597656, 'epoch': 19.55}
{'loss': 0.0086, 'grad_norm': 5.166513919830322, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.0051996950060129166, 'loss_2': 0.003391265869140625, 'loss_3': -16.176511764526367, 'loss_4': 2.4280929565429688, 'epoch': 19.56}
{'loss': 0.0075, 'grad_norm': 4.20042610168457, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.0034291029442101717, 'loss_2': 0.0040740966796875, 'loss_3': -16.305747985839844, 'loss_4': 2.0763120651245117, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 10:46:51,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:51,297 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:05<30:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:46:58,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01085466705262661, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.266, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0074450429528951645, 'eval_loss_2': 0.0034096240997314453, 'eval_loss_3': -18.28105354309082, 'eval_loss_4': 2.2054295539855957, 'epoch': 19.56}
{'loss': 0.0115, 'grad_norm': 5.840124130249023, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.011164108291268349, 'loss_2': 0.00030112266540527344, 'loss_3': -16.139808654785156, 'loss_4': 2.641242742538452, 'epoch': 19.57}
{'loss': 0.0117, 'grad_norm': 6.732980728149414, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.008566221222281456, 'loss_2': 0.0031261444091796875, 'loss_3': -16.358118057250977, 'loss_4': 2.5630314350128174, 'epoch': 19.58}
{'loss': 0.0105, 'grad_norm': 6.319435119628906, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.007607592269778252, 'loss_2': 0.00293731689453125, 'loss_3': -16.48908805847168, 'loss_4': 2.623631477355957, 'epoch': 19.58}
{'loss': 0.0065, 'grad_norm': 5.003127098083496, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.005295826122164726, 'loss_2': 0.001163482666015625, 'loss_3': -16.431312561035156, 'loss_4': 3.018965721130371, 'epoch': 19.59}
{'loss': 0.0046, 'grad_norm': 4.529026031494141, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.004321701359003782, 'loss_2': 0.0003104209899902344, 'loss_3': -16.39816665649414, 'loss_4': 2.7934365272521973, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 10:46:58,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:46:58,636 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:13<30:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:05,974 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010710347443819046, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007353951223194599, 'eval_loss_2': 0.0033563971519470215, 'eval_loss_3': -18.286659240722656, 'eval_loss_4': 1.9867641925811768, 'epoch': 19.59}
{'loss': 0.0059, 'grad_norm': 4.617433547973633, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.005159787833690643, 'loss_2': 0.0007448196411132812, 'loss_3': -16.342121124267578, 'loss_4': 2.1794164180755615, 'epoch': 19.6}
{'loss': 0.01, 'grad_norm': 4.568305492401123, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.004149905871599913, 'loss_2': 0.0058746337890625, 'loss_3': -16.41814613342285, 'loss_4': 1.9251327514648438, 'epoch': 19.6}
{'loss': 0.0071, 'grad_norm': 5.1033477783203125, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.006092454772442579, 'loss_2': 0.001041412353515625, 'loss_3': -16.258556365966797, 'loss_4': 2.0132906436920166, 'epoch': 19.61}
{'loss': 0.0098, 'grad_norm': 5.217339992523193, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.007974610663950443, 'loss_2': 0.0018062591552734375, 'loss_3': -16.32805633544922, 'loss_4': 1.8655741214752197, 'epoch': 19.62}
{'loss': 0.0137, 'grad_norm': 5.898151874542236, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.009542318060994148, 'loss_2': 0.00417327880859375, 'loss_3': -16.427181243896484, 'loss_4': 2.34666109085083, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 10:47:05,974 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:05,975 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:20<30:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:13,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011279093101620674, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007739568129181862, 'eval_loss_2': 0.0035395249724388123, 'eval_loss_3': -18.270164489746094, 'eval_loss_4': 1.8689444065093994, 'epoch': 19.62}
{'loss': 0.0141, 'grad_norm': 4.608699321746826, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.0061942208558321, 'loss_2': 0.007904052734375, 'loss_3': -16.38619613647461, 'loss_4': 2.31284236907959, 'epoch': 19.63}
{'loss': 0.0127, 'grad_norm': 4.43059778213501, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.005468007177114487, 'loss_2': 0.00724029541015625, 'loss_3': -16.32434844970703, 'loss_4': 2.117727756500244, 'epoch': 19.63}
{'loss': 0.0217, 'grad_norm': 6.818906307220459, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.010938314720988274, 'loss_2': 0.0107574462890625, 'loss_3': -16.32094955444336, 'loss_4': 1.7093195915222168, 'epoch': 19.64}
{'loss': 0.0183, 'grad_norm': 6.281773567199707, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.013222630135715008, 'loss_2': 0.005084991455078125, 'loss_3': -16.002479553222656, 'loss_4': 2.4262137413024902, 'epoch': 19.65}
{'loss': 0.0273, 'grad_norm': 9.858518600463867, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.023797878995537758, 'loss_2': 0.003509521484375, 'loss_3': -16.332584381103516, 'loss_4': 1.9768692255020142, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 10:47:13,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:13,319 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:27<30:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:20,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010255275294184685, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.481, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007554797921329737, 'eval_loss_2': 0.0027004778385162354, 'eval_loss_3': -18.2615909576416, 'eval_loss_4': 1.7735294103622437, 'epoch': 19.65}
{'loss': 0.0193, 'grad_norm': 6.923623085021973, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.015640459954738617, 'loss_2': 0.003688812255859375, 'loss_3': -16.411365509033203, 'loss_4': 2.5795013904571533, 'epoch': 19.66}
{'loss': 0.011, 'grad_norm': 5.1069793701171875, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.005858751945197582, 'loss_2': 0.00514984130859375, 'loss_3': -16.458099365234375, 'loss_4': 1.3142075538635254, 'epoch': 19.66}
{'loss': 0.0099, 'grad_norm': 4.815468788146973, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.006636475678533316, 'loss_2': 0.00330352783203125, 'loss_3': -16.352508544921875, 'loss_4': 1.7952630519866943, 'epoch': 19.67}
{'loss': 0.0171, 'grad_norm': 6.3068766593933105, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.011916699819266796, 'loss_2': 0.00519561767578125, 'loss_3': -16.323684692382812, 'loss_4': 2.9309701919555664, 'epoch': 19.67}
{'loss': 0.0171, 'grad_norm': 5.050168037414551, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.010938412509858608, 'loss_2': 0.00612640380859375, 'loss_3': -16.169082641601562, 'loss_4': 2.3784542083740234, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 10:47:20,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:20,671 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:35<30:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:28,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014838846400380135, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007796081248670816, 'eval_loss_2': 0.0070427656173706055, 'eval_loss_3': -18.250953674316406, 'eval_loss_4': 1.738992691040039, 'epoch': 19.68}
{'loss': 0.0288, 'grad_norm': 11.778264045715332, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.0199037604033947, 'loss_2': 0.00891876220703125, 'loss_3': -16.273475646972656, 'loss_4': 2.1583616733551025, 'epoch': 19.69}
{'loss': 0.0206, 'grad_norm': 5.460394859313965, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.008597368374466896, 'loss_2': 0.0119781494140625, 'loss_3': -16.187946319580078, 'loss_4': 3.0106818675994873, 'epoch': 19.69}
{'loss': 0.0069, 'grad_norm': 4.552886009216309, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.00236129155382514, 'loss_2': 0.00455474853515625, 'loss_3': -16.473506927490234, 'loss_4': 1.6782971620559692, 'epoch': 19.7}
{'loss': 0.0111, 'grad_norm': 7.148373126983643, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.00961982924491167, 'loss_2': 0.001491546630859375, 'loss_3': -16.435476303100586, 'loss_4': 1.5142980813980103, 'epoch': 19.7}
{'loss': 0.0183, 'grad_norm': 9.474143981933594, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.01492296438664198, 'loss_2': 0.003398895263671875, 'loss_3': -16.578514099121094, 'loss_4': 2.5789859294891357, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 10:47:28,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:28,017 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:42<30:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:35,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014756834134459496, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0076573253609240055, 'eval_loss_2': 0.007099509239196777, 'eval_loss_3': -18.244075775146484, 'eval_loss_4': 1.629301905632019, 'epoch': 19.71}
{'loss': 0.0143, 'grad_norm': 7.326730251312256, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.010472130961716175, 'loss_2': 0.0038242340087890625, 'loss_3': -16.28472900390625, 'loss_4': 2.330103635787964, 'epoch': 19.72}
{'loss': 0.0192, 'grad_norm': 6.2001214027404785, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.012817651964724064, 'loss_2': 0.006336212158203125, 'loss_3': -16.3029727935791, 'loss_4': 1.571916103363037, 'epoch': 19.72}
{'loss': 0.0067, 'grad_norm': 4.7044291496276855, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.005201784428209066, 'loss_2': 0.0015392303466796875, 'loss_3': -16.34869384765625, 'loss_4': 1.4826544523239136, 'epoch': 19.73}
{'loss': 0.0086, 'grad_norm': 5.344910621643066, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.005807941779494286, 'loss_2': 0.002758026123046875, 'loss_3': -16.195985794067383, 'loss_4': 1.9895912408828735, 'epoch': 19.73}
{'loss': 0.0084, 'grad_norm': 4.317633628845215, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.006272321566939354, 'loss_2': 0.0020809173583984375, 'loss_3': -16.221866607666016, 'loss_4': 1.6141775846481323, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 10:47:35,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:35,358 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:49<30:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:42,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012027205899357796, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008734703995287418, 'eval_loss_2': 0.0032925009727478027, 'eval_loss_3': -18.25326919555664, 'eval_loss_4': 1.618920087814331, 'epoch': 19.74}
{'loss': 0.0176, 'grad_norm': 5.423826217651367, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.006899295840412378, 'loss_2': 0.01073455810546875, 'loss_3': -16.440322875976562, 'loss_4': 2.5235118865966797, 'epoch': 19.74}
{'loss': 0.0155, 'grad_norm': 7.5145344734191895, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.014706575311720371, 'loss_2': 0.0007810592651367188, 'loss_3': -16.539979934692383, 'loss_4': 1.6317615509033203, 'epoch': 19.75}
{'loss': 0.014, 'grad_norm': 4.688820838928223, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.00563780264928937, 'loss_2': 0.00838470458984375, 'loss_3': -16.44268226623535, 'loss_4': 2.541938304901123, 'epoch': 19.76}
{'loss': 0.013, 'grad_norm': 4.776451110839844, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.006791653111577034, 'loss_2': 0.00616455078125, 'loss_3': -16.32952117919922, 'loss_4': 2.547355890274048, 'epoch': 19.76}
{'loss': 0.0105, 'grad_norm': 5.71040678024292, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.009825545363128185, 'loss_2': 0.0006723403930664062, 'loss_3': -16.331405639648438, 'loss_4': 1.7281134128570557, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 10:47:42,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:42,698 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:23:57<30:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:50,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010588638484477997, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008349134586751461, 'eval_loss_2': 0.002239502966403961, 'eval_loss_3': -18.25985336303711, 'eval_loss_4': 1.6338390111923218, 'epoch': 19.77}
{'loss': 0.0095, 'grad_norm': 4.3004865646362305, 'learning_rate': 1.025e-05, 'loss_1': 0.0066345371305942535, 'loss_2': 0.002910614013671875, 'loss_3': -16.4794921875, 'loss_4': 2.0431413650512695, 'epoch': 19.77}
{'loss': 0.0102, 'grad_norm': 4.905089378356934, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.004735733848065138, 'loss_2': 0.0054473876953125, 'loss_3': -16.324260711669922, 'loss_4': 1.6403895616531372, 'epoch': 19.78}
{'loss': 0.0167, 'grad_norm': 6.355181694030762, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.0158518198877573, 'loss_2': 0.0008373260498046875, 'loss_3': -16.423892974853516, 'loss_4': 2.1281864643096924, 'epoch': 19.78}
{'loss': 0.0134, 'grad_norm': 5.945659160614014, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.010607595555484295, 'loss_2': 0.00278472900390625, 'loss_3': -16.355072021484375, 'loss_4': 2.3343634605407715, 'epoch': 19.79}
{'loss': 0.0063, 'grad_norm': 4.80955696105957, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.00398362847045064, 'loss_2': 0.0023593902587890625, 'loss_3': -16.547719955444336, 'loss_4': 1.6967189311981201, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 10:47:50,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:50,041 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:04<30:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:47:57,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011109882034361362, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008989879861474037, 'eval_loss_2': 0.0021200031042099, 'eval_loss_3': -18.2586727142334, 'eval_loss_4': 1.569211721420288, 'epoch': 19.8}
{'loss': 0.0067, 'grad_norm': 4.967541694641113, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.006492924876511097, 'loss_2': 0.00023794174194335938, 'loss_3': -16.502471923828125, 'loss_4': 1.67380952835083, 'epoch': 19.8}
{'loss': 0.0054, 'grad_norm': 4.698002338409424, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.005340826231986284, 'loss_2': 3.49879264831543e-05, 'loss_3': -16.38982391357422, 'loss_4': 2.3155763149261475, 'epoch': 19.81}
{'loss': 0.0093, 'grad_norm': 5.217354774475098, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.006428221706300974, 'loss_2': 0.002895355224609375, 'loss_3': -16.431442260742188, 'loss_4': 1.110731840133667, 'epoch': 19.81}
{'loss': 0.0099, 'grad_norm': 5.601674556732178, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.007356897462159395, 'loss_2': 0.0025310516357421875, 'loss_3': -16.22232437133789, 'loss_4': 1.2930924892425537, 'epoch': 19.82}
{'loss': 0.0334, 'grad_norm': 12.524604797363281, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.03331759572029114, 'loss_2': 6.252527236938477e-05, 'loss_3': -16.30241584777832, 'loss_4': 2.178743839263916, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 10:47:57,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:47:57,398 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:11<30:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:04,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011972389183938503, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009045353159308434, 'eval_loss_2': 0.002927035093307495, 'eval_loss_3': -18.26068878173828, 'eval_loss_4': 1.5001133680343628, 'epoch': 19.83}
{'loss': 0.0091, 'grad_norm': 4.877634525299072, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.006384130567312241, 'loss_2': 0.0027484893798828125, 'loss_3': -16.482009887695312, 'loss_4': 2.378021478652954, 'epoch': 19.83}
{'loss': 0.0059, 'grad_norm': 5.181082248687744, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.003104810370132327, 'loss_2': 0.002803802490234375, 'loss_3': -16.3853816986084, 'loss_4': 2.046264410018921, 'epoch': 19.84}
{'loss': 0.0165, 'grad_norm': 7.806679725646973, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.01159281563013792, 'loss_2': 0.0049285888671875, 'loss_3': -16.352415084838867, 'loss_4': 1.6661217212677002, 'epoch': 19.84}
{'loss': 0.0184, 'grad_norm': 7.3643364906311035, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.01059397216886282, 'loss_2': 0.007793426513671875, 'loss_3': -16.396486282348633, 'loss_4': 1.7328070402145386, 'epoch': 19.85}
{'loss': 0.0135, 'grad_norm': 4.904157638549805, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.0056301006115973, 'loss_2': 0.00787353515625, 'loss_3': -16.333972930908203, 'loss_4': 2.320674419403076, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 10:48:04,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:04,749 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:19<30:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:12,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010700657963752747, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007924482226371765, 'eval_loss_2': 0.0027761757373809814, 'eval_loss_3': -18.255828857421875, 'eval_loss_4': 1.3965606689453125, 'epoch': 19.85}
{'loss': 0.0093, 'grad_norm': 5.163644790649414, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.008249184116721153, 'loss_2': 0.0010499954223632812, 'loss_3': -16.243165969848633, 'loss_4': 1.1151707172393799, 'epoch': 19.86}
{'loss': 0.0084, 'grad_norm': 5.096238613128662, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.007753524463623762, 'loss_2': 0.0006418228149414062, 'loss_3': -16.409177780151367, 'loss_4': 1.8704785108566284, 'epoch': 19.87}
{'loss': 0.0041, 'grad_norm': 4.419871807098389, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.002576769795268774, 'loss_2': 0.0015163421630859375, 'loss_3': -16.42022705078125, 'loss_4': 1.4012632369995117, 'epoch': 19.87}
{'loss': 0.0109, 'grad_norm': 4.307845592498779, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.003586186096072197, 'loss_2': 0.00733184814453125, 'loss_3': -16.453235626220703, 'loss_4': 1.1558101177215576, 'epoch': 19.88}
{'loss': 0.0167, 'grad_norm': 7.015763759613037, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.016366951167583466, 'loss_2': 0.0002856254577636719, 'loss_3': -16.2344970703125, 'loss_4': 2.4940640926361084, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 10:48:12,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:12,092 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:26<29:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:19,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010617430321872234, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007754528895020485, 'eval_loss_2': 0.002862900495529175, 'eval_loss_3': -18.259830474853516, 'eval_loss_4': 1.290212631225586, 'epoch': 19.88}
{'loss': 0.0258, 'grad_norm': 7.7509918212890625, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.019914982840418816, 'loss_2': 0.00585174560546875, 'loss_3': -16.380130767822266, 'loss_4': 1.9182394742965698, 'epoch': 19.89}
{'loss': 0.0103, 'grad_norm': 5.0528130531311035, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.00722538074478507, 'loss_2': 0.00304412841796875, 'loss_3': -16.230754852294922, 'loss_4': 2.0812506675720215, 'epoch': 19.9}
{'loss': 0.0071, 'grad_norm': 4.290952682495117, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.006869405973702669, 'loss_2': 0.00022971630096435547, 'loss_3': -16.432804107666016, 'loss_4': 1.7703462839126587, 'epoch': 19.9}
{'loss': 0.0097, 'grad_norm': 4.8599090576171875, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.0093594491481781, 'loss_2': 0.00031304359436035156, 'loss_3': -16.425682067871094, 'loss_4': 1.271353006362915, 'epoch': 19.91}
{'loss': 0.0107, 'grad_norm': 4.950409889221191, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.005384236574172974, 'loss_2': 0.005340576171875, 'loss_3': -16.47223663330078, 'loss_4': 1.530375599861145, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 10:48:19,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:19,427 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:33<29:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:26,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00982674304395914, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.447, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007860084064304829, 'eval_loss_2': 0.001966658979654312, 'eval_loss_3': -18.255203247070312, 'eval_loss_4': 0.9823915958404541, 'epoch': 19.91}
{'loss': 0.0108, 'grad_norm': 5.439284801483154, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.007061487063765526, 'loss_2': 0.00374603271484375, 'loss_3': -16.31214141845703, 'loss_4': 1.1735812425613403, 'epoch': 19.92}
{'loss': 0.0082, 'grad_norm': 5.965146541595459, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.008169414475560188, 'loss_2': 3.6776065826416016e-05, 'loss_3': -16.29668426513672, 'loss_4': 1.482163667678833, 'epoch': 19.92}
{'loss': 0.0073, 'grad_norm': 4.844869613647461, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.0030132962856441736, 'loss_2': 0.004299163818359375, 'loss_3': -16.30919647216797, 'loss_4': 1.1382479667663574, 'epoch': 19.93}
{'loss': 0.0133, 'grad_norm': 4.788426876068115, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.009639321826398373, 'loss_2': 0.003627777099609375, 'loss_3': -16.2633056640625, 'loss_4': 0.6892518997192383, 'epoch': 19.94}
{'loss': 0.0132, 'grad_norm': 9.845732688903809, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.01289256289601326, 'loss_2': 0.0002727508544921875, 'loss_3': -16.469058990478516, 'loss_4': 0.5366746783256531, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 10:48:26,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:26,764 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:41<29:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:48:34,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010227683931589127, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.564, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008010093122720718, 'eval_loss_2': 0.002217590808868408, 'eval_loss_3': -18.270048141479492, 'eval_loss_4': 0.6717649102210999, 'epoch': 19.94}
{'loss': 0.0087, 'grad_norm': 4.801012992858887, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.006597304251044989, 'loss_2': 0.0020904541015625, 'loss_3': -16.611543655395508, 'loss_4': 1.5538220405578613, 'epoch': 19.95}
{'loss': 0.0154, 'grad_norm': 6.263416767120361, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.013501782901585102, 'loss_2': 0.0018558502197265625, 'loss_3': -16.431209564208984, 'loss_4': 0.697137713432312, 'epoch': 19.95}
{'loss': 0.0077, 'grad_norm': 5.075130462646484, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.004793465603142977, 'loss_2': 0.00293731689453125, 'loss_3': -16.31114387512207, 'loss_4': 0.25910860300064087, 'epoch': 19.96}
{'loss': 0.0351, 'grad_norm': 12.754801750183105, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.03339449688792229, 'loss_2': 0.001712799072265625, 'loss_3': -16.445377349853516, 'loss_4': 0.23075921833515167, 'epoch': 19.97}
{'loss': 0.0172, 'grad_norm': 9.698136329650879, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.012171749025583267, 'loss_2': 0.005001068115234375, 'loss_3': -16.415624618530273, 'loss_4': 0.925075113773346, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 10:48:34,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:34,100 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:48<26:44,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 10:48:41,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010351145640015602, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.393, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007845084182918072, 'eval_loss_2': 0.002506062388420105, 'eval_loss_3': -18.254131317138672, 'eval_loss_4': 0.5845831632614136, 'epoch': 19.97}
{'loss': 0.0154, 'grad_norm': 5.3730974197387695, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.007796579971909523, 'loss_2': 0.007564544677734375, 'loss_3': -16.296051025390625, 'loss_4': 0.5254141688346863, 'epoch': 19.98}
{'loss': 0.0157, 'grad_norm': 8.06950569152832, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.015374216251075268, 'loss_2': 0.0002760887145996094, 'loss_3': -16.435693740844727, 'loss_4': 0.4470439553260803, 'epoch': 19.98}
{'loss': 0.008, 'grad_norm': 5.273840427398682, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.00479532964527607, 'loss_2': 0.0032024383544921875, 'loss_3': -16.11685562133789, 'loss_4': 0.3392760753631592, 'epoch': 19.99}
{'loss': 0.0103, 'grad_norm': 5.107039451599121, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.008726977743208408, 'loss_2': 0.0015411376953125, 'loss_3': -16.410314559936523, 'loss_4': 0.7326881885528564, 'epoch': 19.99}
{'loss': 0.0069, 'grad_norm': 5.805886745452881, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.0030952850356698036, 'loss_2': 0.003818511962890625, 'loss_3': -16.41011619567871, 'loss_4': 1.2782493829727173, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 10:48:41,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:41,101 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:24:55<29:10,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 10:48:48,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009826643392443657, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0072258468717336655, 'eval_loss_2': 0.0026007965207099915, 'eval_loss_3': -18.26247215270996, 'eval_loss_4': 0.7123111486434937, 'epoch': 20.0}
{'loss': 0.0289, 'grad_norm': 11.613998413085938, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.02655288577079773, 'loss_2': 0.0023403167724609375, 'loss_3': -16.32543182373047, 'loss_4': 1.3870694637298584, 'epoch': 20.01}
{'loss': 0.018, 'grad_norm': 9.551851272583008, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.01439660508185625, 'loss_2': 0.003570556640625, 'loss_3': -16.605966567993164, 'loss_4': 1.3783791065216064, 'epoch': 20.01}
{'loss': 0.0101, 'grad_norm': 4.838521957397461, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.005142714828252792, 'loss_2': 0.0049285888671875, 'loss_3': -16.41258430480957, 'loss_4': 1.7445578575134277, 'epoch': 20.02}
{'loss': 0.0163, 'grad_norm': 5.508217811584473, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.011738697998225689, 'loss_2': 0.004512786865234375, 'loss_3': -16.35592269897461, 'loss_4': 1.176607370376587, 'epoch': 20.02}
{'loss': 0.0276, 'grad_norm': 14.234219551086426, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.025798216462135315, 'loss_2': 0.0018367767333984375, 'loss_3': -16.293325424194336, 'loss_4': 1.6828408241271973, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 10:48:48,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:48,476 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:03<29:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:48:55,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009291327558457851, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006457305513322353, 'eval_loss_2': 0.002834022045135498, 'eval_loss_3': -18.264760971069336, 'eval_loss_4': 0.7361428141593933, 'epoch': 20.03}
{'loss': 0.0272, 'grad_norm': 10.067320823669434, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.023691456764936447, 'loss_2': 0.0034770965576171875, 'loss_3': -16.455219268798828, 'loss_4': 1.0410486459732056, 'epoch': 20.03}
{'loss': 0.0085, 'grad_norm': 4.650906085968018, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.005328994709998369, 'loss_2': 0.003173828125, 'loss_3': -16.47576141357422, 'loss_4': 1.144177794456482, 'epoch': 20.04}
{'loss': 0.017, 'grad_norm': 8.34688949584961, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.008071883581578732, 'loss_2': 0.0089263916015625, 'loss_3': -16.386272430419922, 'loss_4': 0.8034334182739258, 'epoch': 20.05}
{'loss': 0.0135, 'grad_norm': 4.356812000274658, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.005546169821172953, 'loss_2': 0.007904052734375, 'loss_3': -16.253028869628906, 'loss_4': 1.2193461656570435, 'epoch': 20.05}
{'loss': 0.0176, 'grad_norm': 6.397892951965332, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.014819487929344177, 'loss_2': 0.002735137939453125, 'loss_3': -16.34854507446289, 'loss_4': 1.4427047967910767, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 10:48:55,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:48:55,809 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:10<29:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:03,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01043612789362669, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00635220343247056, 'eval_loss_2': 0.0040839239954948425, 'eval_loss_3': -18.25371742248535, 'eval_loss_4': 0.631449818611145, 'epoch': 20.06}
{'loss': 0.0181, 'grad_norm': 5.277087688446045, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.011102627031505108, 'loss_2': 0.007007598876953125, 'loss_3': -16.376493453979492, 'loss_4': 0.9194295406341553, 'epoch': 20.06}
{'loss': 0.0123, 'grad_norm': 5.485499382019043, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.0064131123945117, 'loss_2': 0.005931854248046875, 'loss_3': -16.287078857421875, 'loss_4': 0.8452529907226562, 'epoch': 20.07}
{'loss': 0.0093, 'grad_norm': 4.8462910652160645, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.004127740394324064, 'loss_2': 0.005157470703125, 'loss_3': -16.486099243164062, 'loss_4': 1.4739420413970947, 'epoch': 20.08}
{'loss': 0.0145, 'grad_norm': 6.557914733886719, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.010626875795423985, 'loss_2': 0.0038604736328125, 'loss_3': -16.459514617919922, 'loss_4': 0.8953220844268799, 'epoch': 20.08}
{'loss': 0.0074, 'grad_norm': 4.752895355224609, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.006170219276100397, 'loss_2': 0.001190185546875, 'loss_3': -16.40946388244629, 'loss_4': 0.6771472692489624, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 10:49:03,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:03,143 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:17<29:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:10,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009312503039836884, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006518177688121796, 'eval_loss_2': 0.002794325351715088, 'eval_loss_3': -18.239492416381836, 'eval_loss_4': 0.49150627851486206, 'epoch': 20.09}
{'loss': 0.0126, 'grad_norm': 5.486016750335693, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.008010435849428177, 'loss_2': 0.00463104248046875, 'loss_3': -16.3784236907959, 'loss_4': 1.6023032665252686, 'epoch': 20.09}
{'loss': 0.0298, 'grad_norm': 13.273521423339844, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.022156089544296265, 'loss_2': 0.0076446533203125, 'loss_3': -16.415538787841797, 'loss_4': 1.4483989477157593, 'epoch': 20.1}
{'loss': 0.0129, 'grad_norm': 5.204323768615723, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.006313844583928585, 'loss_2': 0.006561279296875, 'loss_3': -16.281503677368164, 'loss_4': 0.4976934790611267, 'epoch': 20.1}
{'loss': 0.0119, 'grad_norm': 6.07684850692749, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.010473066940903664, 'loss_2': 0.0013818740844726562, 'loss_3': -16.387773513793945, 'loss_4': 0.43097972869873047, 'epoch': 20.11}
{'loss': 0.0185, 'grad_norm': 10.08193588256836, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.0131465382874012, 'loss_2': 0.00539398193359375, 'loss_3': -16.201950073242188, 'loss_4': 0.8695204257965088, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 10:49:10,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:10,478 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:25<29:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:17,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009420180693268776, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006438785698264837, 'eval_loss_2': 0.0029813945293426514, 'eval_loss_3': -18.235130310058594, 'eval_loss_4': 0.35590773820877075, 'epoch': 20.12}
{'loss': 0.0067, 'grad_norm': 4.693690776824951, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.005010778084397316, 'loss_2': 0.0016803741455078125, 'loss_3': -16.41823387145996, 'loss_4': 0.9769138693809509, 'epoch': 20.12}
{'loss': 0.0118, 'grad_norm': 4.878927707672119, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.006892997771501541, 'loss_2': 0.004878997802734375, 'loss_3': -16.25273895263672, 'loss_4': 0.25674259662628174, 'epoch': 20.13}
{'loss': 0.0117, 'grad_norm': 6.321264266967773, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.009782528504729271, 'loss_2': 0.001964569091796875, 'loss_3': -16.411033630371094, 'loss_4': 0.16741786897182465, 'epoch': 20.13}
{'loss': 0.0097, 'grad_norm': 5.009903430938721, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.009402481839060783, 'loss_2': 0.00032138824462890625, 'loss_3': -16.433595657348633, 'loss_4': 1.0709342956542969, 'epoch': 20.14}
{'loss': 0.0128, 'grad_norm': 6.1616950035095215, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.00779097992926836, 'loss_2': 0.00499725341796875, 'loss_3': -16.354740142822266, 'loss_4': 0.9288049340248108, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 10:49:17,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:17,814 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:32<29:46,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:49:25,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00965672917664051, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.666, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006213823799043894, 'eval_loss_2': 0.003442905843257904, 'eval_loss_3': -18.23301124572754, 'eval_loss_4': 0.2517808675765991, 'epoch': 20.15}
{'loss': 0.0051, 'grad_norm': 5.0953474044799805, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.004151185508817434, 'loss_2': 0.0009202957153320312, 'loss_3': -16.464801788330078, 'loss_4': 0.6172529458999634, 'epoch': 20.15}
{'loss': 0.0081, 'grad_norm': 4.605536937713623, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.0033713928423821926, 'loss_2': 0.00475311279296875, 'loss_3': -16.405302047729492, 'loss_4': 0.6777362823486328, 'epoch': 20.16}
{'loss': 0.0125, 'grad_norm': 5.658017158508301, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.008080445230007172, 'loss_2': 0.00439453125, 'loss_3': -16.304935455322266, 'loss_4': 0.48950695991516113, 'epoch': 20.16}
{'loss': 0.0303, 'grad_norm': 11.930767059326172, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.028459148481488228, 'loss_2': 0.001800537109375, 'loss_3': -16.291303634643555, 'loss_4': 0.5743873715400696, 'epoch': 20.17}
{'loss': 0.0448, 'grad_norm': 33.18415832519531, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.04183099791407585, 'loss_2': 0.0029239654541015625, 'loss_3': -16.432846069335938, 'loss_4': 0.9453808665275574, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 10:49:25,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:25,359 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:39<29:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:32,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0128956139087677, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00598648376762867, 'eval_loss_2': 0.00690913200378418, 'eval_loss_3': -18.2353572845459, 'eval_loss_4': 0.1720816195011139, 'epoch': 20.17}
{'loss': 0.0161, 'grad_norm': 6.745102405548096, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.008807807229459286, 'loss_2': 0.007274627685546875, 'loss_3': -16.43697166442871, 'loss_4': 0.4367872178554535, 'epoch': 20.18}
{'loss': 0.0125, 'grad_norm': 5.277318477630615, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.007318812422454357, 'loss_2': 0.00521087646484375, 'loss_3': -16.446218490600586, 'loss_4': 0.6755543351173401, 'epoch': 20.19}
{'loss': 0.0119, 'grad_norm': 5.460968017578125, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.01055984478443861, 'loss_2': 0.0013637542724609375, 'loss_3': -16.307720184326172, 'loss_4': -0.5336394906044006, 'epoch': 20.19}
{'loss': 0.017, 'grad_norm': 6.235169410705566, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.009850015863776207, 'loss_2': 0.00717926025390625, 'loss_3': -15.893177032470703, 'loss_4': 0.22059795260429382, 'epoch': 20.2}
{'loss': 0.0175, 'grad_norm': 4.879464149475098, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.006273640785366297, 'loss_2': 0.0111846923828125, 'loss_3': -16.563840866088867, 'loss_4': 0.4708031415939331, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 10:49:32,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:32,700 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:47<29:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:40,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012702343985438347, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005983470007777214, 'eval_loss_2': 0.006718873977661133, 'eval_loss_3': -18.236684799194336, 'eval_loss_4': 0.053929902613162994, 'epoch': 20.2}
{'loss': 0.015, 'grad_norm': 5.006237506866455, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.006564255803823471, 'loss_2': 0.00843048095703125, 'loss_3': -16.28660774230957, 'loss_4': 0.33351629972457886, 'epoch': 20.21}
{'loss': 0.0161, 'grad_norm': 5.242053508758545, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.005855586379766464, 'loss_2': 0.010223388671875, 'loss_3': -16.481826782226562, 'loss_4': 0.6804671287536621, 'epoch': 20.22}
{'loss': 0.0227, 'grad_norm': 5.199052810668945, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.0109651368111372, 'loss_2': 0.011688232421875, 'loss_3': -16.34191131591797, 'loss_4': -0.13255152106285095, 'epoch': 20.22}
{'loss': 0.0118, 'grad_norm': 6.569361209869385, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.009593568742275238, 'loss_2': 0.00222015380859375, 'loss_3': -16.2436580657959, 'loss_4': -0.12279742956161499, 'epoch': 20.23}
{'loss': 0.013, 'grad_norm': 4.544641017913818, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.006100067403167486, 'loss_2': 0.006908416748046875, 'loss_3': -16.365262985229492, 'loss_4': 0.6377744674682617, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 10:49:40,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:40,045 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:25:54<28:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:49:47,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008724245242774487, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006063271313905716, 'eval_loss_2': 0.002660974860191345, 'eval_loss_3': -18.2249698638916, 'eval_loss_4': -0.03142896667122841, 'epoch': 20.23}
{'loss': 0.027, 'grad_norm': 10.055346488952637, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.022493306547403336, 'loss_2': 0.004550933837890625, 'loss_3': -16.29378318786621, 'loss_4': -0.08035629987716675, 'epoch': 20.24}
{'loss': 0.0106, 'grad_norm': 5.157284736633301, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.006030777003616095, 'loss_2': 0.0045623779296875, 'loss_3': -16.45654296875, 'loss_4': 0.5926823019981384, 'epoch': 20.24}
{'loss': 0.0059, 'grad_norm': 4.728044033050537, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.0053959558717906475, 'loss_2': 0.0004639625549316406, 'loss_3': -16.330278396606445, 'loss_4': 0.45606935024261475, 'epoch': 20.25}
{'loss': 0.0209, 'grad_norm': 6.41010046005249, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.01223899144679308, 'loss_2': 0.00861358642578125, 'loss_3': -16.208778381347656, 'loss_4': 0.3715549111366272, 'epoch': 20.26}
{'loss': 0.0105, 'grad_norm': 4.627325057983398, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.005813871044665575, 'loss_2': 0.00469207763671875, 'loss_3': -16.696523666381836, 'loss_4': 0.15199658274650574, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 10:49:47,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:47,379 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:01<28:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:49:54,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01137835904955864, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.645, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.006277811247855425, 'eval_loss_2': 0.005100548267364502, 'eval_loss_3': -18.224306106567383, 'eval_loss_4': -0.006433553993701935, 'epoch': 20.26}
{'loss': 0.0096, 'grad_norm': 5.429542064666748, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.005891337059438229, 'loss_2': 0.00373077392578125, 'loss_3': -16.60063362121582, 'loss_4': 0.38002443313598633, 'epoch': 20.27}
{'loss': 0.0217, 'grad_norm': 6.543978691101074, 'learning_rate': 9.75e-06, 'loss_1': 0.012456013821065426, 'loss_2': 0.0092620849609375, 'loss_3': -16.324586868286133, 'loss_4': -0.43740493059158325, 'epoch': 20.27}
{'loss': 0.0106, 'grad_norm': 6.426978588104248, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.007749851793050766, 'loss_2': 0.0028228759765625, 'loss_3': -16.400352478027344, 'loss_4': 0.20443683862686157, 'epoch': 20.28}
{'loss': 0.0089, 'grad_norm': 6.466765403747559, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.006466202903538942, 'loss_2': 0.00247955322265625, 'loss_3': -16.40202522277832, 'loss_4': 0.5056901574134827, 'epoch': 20.28}
{'loss': 0.0096, 'grad_norm': 4.703004360198975, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.004371978808194399, 'loss_2': 0.00527191162109375, 'loss_3': -16.380577087402344, 'loss_4': 1.3556697368621826, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 10:49:54,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:49:54,709 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:09<28:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:02,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011854677461087704, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0068526556715369225, 'eval_loss_2': 0.005002021789550781, 'eval_loss_3': -18.207847595214844, 'eval_loss_4': 0.022113947197794914, 'epoch': 20.29}
{'loss': 0.0085, 'grad_norm': 5.9153008460998535, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.007526525296270847, 'loss_2': 0.000934600830078125, 'loss_3': -16.35082244873047, 'loss_4': 0.3321194648742676, 'epoch': 20.3}
{'loss': 0.0276, 'grad_norm': 15.398289680480957, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.0176702793687582, 'loss_2': 0.00997161865234375, 'loss_3': -16.43924331665039, 'loss_4': 0.4394344091415405, 'epoch': 20.3}
{'loss': 0.0176, 'grad_norm': 5.128960609436035, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.009567409753799438, 'loss_2': 0.00798797607421875, 'loss_3': -16.466373443603516, 'loss_4': 0.6675789952278137, 'epoch': 20.31}
{'loss': 0.0119, 'grad_norm': 4.647333145141602, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.005241280887275934, 'loss_2': 0.0066986083984375, 'loss_3': -16.407758712768555, 'loss_4': -0.11774319410324097, 'epoch': 20.31}
{'loss': 0.0112, 'grad_norm': 4.852232933044434, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.0033508308697491884, 'loss_2': 0.007808685302734375, 'loss_3': -16.400617599487305, 'loss_4': 0.8090757131576538, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 10:50:02,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:02,059 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:16<28:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:09,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009458131156861782, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006241208408027887, 'eval_loss_2': 0.0032169222831726074, 'eval_loss_3': -18.199172973632812, 'eval_loss_4': 0.1211695671081543, 'epoch': 20.32}
{'loss': 0.0296, 'grad_norm': 8.36982536315918, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.021367600187659264, 'loss_2': 0.0082244873046875, 'loss_3': -16.51598358154297, 'loss_4': -0.22686265408992767, 'epoch': 20.33}
{'loss': 0.0113, 'grad_norm': 5.96246862411499, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.010671162977814674, 'loss_2': 0.0006775856018066406, 'loss_3': -16.48670196533203, 'loss_4': 0.30503952503204346, 'epoch': 20.33}
{'loss': 0.0232, 'grad_norm': 8.507994651794434, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.018741996958851814, 'loss_2': 0.00443267822265625, 'loss_3': -16.329513549804688, 'loss_4': 0.08825153112411499, 'epoch': 20.34}
{'loss': 0.0146, 'grad_norm': 6.437982082366943, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.01401760708540678, 'loss_2': 0.0005846023559570312, 'loss_3': -16.289228439331055, 'loss_4': 0.7108830213546753, 'epoch': 20.34}
{'loss': 0.006, 'grad_norm': 4.288891792297363, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.005656778812408447, 'loss_2': 0.00036907196044921875, 'loss_3': -16.37444496154785, 'loss_4': 0.230730339884758, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 10:50:09,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:09,399 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:23<28:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:16,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013187725096940994, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00635397806763649, 'eval_loss_2': 0.006833747029304504, 'eval_loss_3': -18.21422004699707, 'eval_loss_4': 0.2288655787706375, 'epoch': 20.35}
{'loss': 0.0184, 'grad_norm': 7.267212390899658, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.015611663460731506, 'loss_2': 0.00278472900390625, 'loss_3': -16.66201400756836, 'loss_4': 0.6627650260925293, 'epoch': 20.35}
{'loss': 0.0574, 'grad_norm': 22.926971435546875, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.05323968455195427, 'loss_2': 0.004154205322265625, 'loss_3': -16.40337371826172, 'loss_4': 0.6420097947120667, 'epoch': 20.36}
{'loss': 0.0084, 'grad_norm': 5.354171276092529, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.0070908102206885815, 'loss_2': 0.001323699951171875, 'loss_3': -16.288639068603516, 'loss_4': 0.302869975566864, 'epoch': 20.37}
{'loss': 0.0107, 'grad_norm': 4.836632251739502, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.005514441058039665, 'loss_2': 0.00518035888671875, 'loss_3': -16.283878326416016, 'loss_4': 0.018204595893621445, 'epoch': 20.37}
{'loss': 0.0135, 'grad_norm': 7.773066520690918, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.010692569427192211, 'loss_2': 0.0027599334716796875, 'loss_3': -16.256244659423828, 'loss_4': 0.6079103946685791, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 10:50:16,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:16,737 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:31<28:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:24,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013972606509923935, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.574, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006641005165874958, 'eval_loss_2': 0.0073316022753715515, 'eval_loss_3': -18.212745666503906, 'eval_loss_4': 0.278768390417099, 'epoch': 20.38}
{'loss': 0.0093, 'grad_norm': 5.104907512664795, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.008870652876794338, 'loss_2': 0.00038695335388183594, 'loss_3': -16.338973999023438, 'loss_4': 0.9024275541305542, 'epoch': 20.38}
{'loss': 0.0154, 'grad_norm': 8.536925315856934, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.014513798989355564, 'loss_2': 0.0009083747863769531, 'loss_3': -16.352821350097656, 'loss_4': 0.8334593772888184, 'epoch': 20.39}
{'loss': 0.0098, 'grad_norm': 6.557181358337402, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.009009920060634613, 'loss_2': 0.0008344650268554688, 'loss_3': -16.56424331665039, 'loss_4': 0.7827794551849365, 'epoch': 20.4}
{'loss': 0.0097, 'grad_norm': 4.361115455627441, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.0038628396578133106, 'loss_2': 0.005832672119140625, 'loss_3': -16.29729461669922, 'loss_4': 0.5363094806671143, 'epoch': 20.4}
{'loss': 0.0043, 'grad_norm': 4.164734363555908, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.002833598293364048, 'loss_2': 0.0015125274658203125, 'loss_3': -16.340557098388672, 'loss_4': 0.3048049807548523, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 10:50:24,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:24,072 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:38<28:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:31,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011811187490820885, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.608, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00801561027765274, 'eval_loss_2': 0.0037955790758132935, 'eval_loss_3': -18.200580596923828, 'eval_loss_4': 0.281599223613739, 'epoch': 20.41}
{'loss': 0.0083, 'grad_norm': 5.2647881507873535, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.00714387372136116, 'loss_2': 0.00118255615234375, 'loss_3': -16.252981185913086, 'loss_4': -0.35248446464538574, 'epoch': 20.41}
{'loss': 0.0085, 'grad_norm': 5.149811744689941, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.0065468791872262955, 'loss_2': 0.0019741058349609375, 'loss_3': -16.438709259033203, 'loss_4': 0.2834925353527069, 'epoch': 20.42}
{'loss': 0.0067, 'grad_norm': 4.700427055358887, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.006087117828428745, 'loss_2': 0.0005731582641601562, 'loss_3': -16.68088150024414, 'loss_4': 0.3050168752670288, 'epoch': 20.42}
{'loss': 0.0101, 'grad_norm': 4.222133636474609, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.004611504264175892, 'loss_2': 0.00548553466796875, 'loss_3': -16.426597595214844, 'loss_4': 0.31001031398773193, 'epoch': 20.43}
{'loss': 0.0171, 'grad_norm': 9.342494010925293, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.01446420419961214, 'loss_2': 0.0026092529296875, 'loss_3': -16.34930419921875, 'loss_4': 0.660869836807251, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 10:50:31,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:31,408 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:45<28:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:38,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01295117661356926, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00898694433271885, 'eval_loss_2': 0.003964230418205261, 'eval_loss_3': -18.176498413085938, 'eval_loss_4': 0.25062596797943115, 'epoch': 20.44}
{'loss': 0.0094, 'grad_norm': 4.653390884399414, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.0038763380143791437, 'loss_2': 0.00551605224609375, 'loss_3': -16.543514251708984, 'loss_4': 0.48922455310821533, 'epoch': 20.44}
{'loss': 0.0103, 'grad_norm': 5.113500118255615, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.0037756820674985647, 'loss_2': 0.006504058837890625, 'loss_3': -16.288040161132812, 'loss_4': 0.33747896552085876, 'epoch': 20.45}
{'loss': 0.0124, 'grad_norm': 6.955863952636719, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.009311730042099953, 'loss_2': 0.00313568115234375, 'loss_3': -16.386507034301758, 'loss_4': 0.33563554286956787, 'epoch': 20.45}
{'loss': 0.0114, 'grad_norm': 4.617042064666748, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.004073011688888073, 'loss_2': 0.00728607177734375, 'loss_3': -16.606550216674805, 'loss_4': -0.010140709578990936, 'epoch': 20.46}
{'loss': 0.0268, 'grad_norm': 6.496194839477539, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.011774376966059208, 'loss_2': 0.0150604248046875, 'loss_3': -16.355424880981445, 'loss_4': -0.3451620638370514, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 10:50:38,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:38,747 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:26:53<28:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:46,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01156456209719181, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.522, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008110830560326576, 'eval_loss_2': 0.0034537315368652344, 'eval_loss_3': -18.179500579833984, 'eval_loss_4': 0.1439291387796402, 'epoch': 20.47}
{'loss': 0.0108, 'grad_norm': 5.398238182067871, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.008375630713999271, 'loss_2': 0.002391815185546875, 'loss_3': -16.248964309692383, 'loss_4': 0.28192704916000366, 'epoch': 20.47}
{'loss': 0.0153, 'grad_norm': 5.091630935668945, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.006757975090295076, 'loss_2': 0.00852203369140625, 'loss_3': -16.16747283935547, 'loss_4': 0.5700461864471436, 'epoch': 20.48}
{'loss': 0.0239, 'grad_norm': 9.981669425964355, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.018659189343452454, 'loss_2': 0.0052490234375, 'loss_3': -16.61666488647461, 'loss_4': 0.7542476058006287, 'epoch': 20.48}
{'loss': 0.0097, 'grad_norm': 13.638355255126953, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.005327253602445126, 'loss_2': 0.0044097900390625, 'loss_3': -16.42095184326172, 'loss_4': -0.27226486802101135, 'epoch': 20.49}
{'loss': 0.0141, 'grad_norm': 4.7510552406311035, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.007424531504511833, 'loss_2': 0.00666046142578125, 'loss_3': -16.474998474121094, 'loss_4': 0.023723691701889038, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 10:50:46,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:46,095 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:00<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:50:53,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01274360902607441, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008438276126980782, 'eval_loss_2': 0.004305332899093628, 'eval_loss_3': -18.174760818481445, 'eval_loss_4': 0.1409359574317932, 'epoch': 20.49}
{'loss': 0.0131, 'grad_norm': 5.0600104331970215, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.00581826688721776, 'loss_2': 0.00725555419921875, 'loss_3': -16.429882049560547, 'loss_4': 0.21419048309326172, 'epoch': 20.5}
{'loss': 0.0208, 'grad_norm': 7.253537178039551, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.01914903149008751, 'loss_2': 0.0016117095947265625, 'loss_3': -16.536746978759766, 'loss_4': 0.3146721124649048, 'epoch': 20.51}
{'loss': 0.0057, 'grad_norm': 4.611609935760498, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.005141803063452244, 'loss_2': 0.0005626678466796875, 'loss_3': -16.298126220703125, 'loss_4': 0.6505652666091919, 'epoch': 20.51}
{'loss': 0.0123, 'grad_norm': 4.9035468101501465, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.004351695533841848, 'loss_2': 0.0079193115234375, 'loss_3': -16.47857666015625, 'loss_4': 0.12260186672210693, 'epoch': 20.52}
{'loss': 0.0271, 'grad_norm': 12.614428520202637, 'learning_rate': 9.5e-06, 'loss_1': 0.025262491777539253, 'loss_2': 0.001873016357421875, 'loss_3': -16.549806594848633, 'loss_4': -0.01614387333393097, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 10:50:53,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:50:53,427 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:07<28:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:51:00,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014482631348073483, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.502, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008832946419715881, 'eval_loss_2': 0.005649685859680176, 'eval_loss_3': -18.185264587402344, 'eval_loss_4': 0.1498647779226303, 'epoch': 20.52}
{'loss': 0.007, 'grad_norm': 4.574130058288574, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.004308297298848629, 'loss_2': 0.002704620361328125, 'loss_3': -16.33998680114746, 'loss_4': -0.12135011702775955, 'epoch': 20.53}
{'loss': 0.0082, 'grad_norm': 4.508241653442383, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.0051094647496938705, 'loss_2': 0.0030841827392578125, 'loss_3': -16.484180450439453, 'loss_4': 0.6988223791122437, 'epoch': 20.53}
{'loss': 0.0132, 'grad_norm': 4.963855743408203, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.0038020669016987085, 'loss_2': 0.0093536376953125, 'loss_3': -16.42549705505371, 'loss_4': 0.2506141662597656, 'epoch': 20.54}
{'loss': 0.0184, 'grad_norm': 7.630730628967285, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.015669621527194977, 'loss_2': 0.002716064453125, 'loss_3': -16.283279418945312, 'loss_4': 0.38911134004592896, 'epoch': 20.55}
{'loss': 0.0068, 'grad_norm': 5.005215167999268, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.005788656882941723, 'loss_2': 0.001041412353515625, 'loss_3': -16.397541046142578, 'loss_4': -0.18763825297355652, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 10:51:00,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:00,754 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:15<27:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:08,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012479478493332863, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008352079428732395, 'eval_loss_2': 0.004127398133277893, 'eval_loss_3': -18.195777893066406, 'eval_loss_4': 0.0627724900841713, 'epoch': 20.55}
{'loss': 0.0095, 'grad_norm': 5.23097562789917, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.007868054322898388, 'loss_2': 0.0015888214111328125, 'loss_3': -16.49127960205078, 'loss_4': 0.3931595981121063, 'epoch': 20.56}
{'loss': 0.01, 'grad_norm': 4.813493251800537, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.004783636890351772, 'loss_2': 0.00521087646484375, 'loss_3': -16.575166702270508, 'loss_4': -0.04905945807695389, 'epoch': 20.56}
{'loss': 0.0149, 'grad_norm': 6.2130937576293945, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.010707062669098377, 'loss_2': 0.00423431396484375, 'loss_3': -16.3155517578125, 'loss_4': -0.23657654225826263, 'epoch': 20.57}
{'loss': 0.011, 'grad_norm': 5.400989532470703, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.007844244129955769, 'loss_2': 0.0031070709228515625, 'loss_3': -16.510080337524414, 'loss_4': 0.04533301293849945, 'epoch': 20.58}
{'loss': 0.0117, 'grad_norm': 4.872842788696289, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.0061760409735143185, 'loss_2': 0.00553131103515625, 'loss_3': -16.41129493713379, 'loss_4': 0.5258694887161255, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 10:51:08,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:08,095 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:22<27:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:15,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012293646112084389, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007622699253261089, 'eval_loss_2': 0.004670947790145874, 'eval_loss_3': -18.228378295898438, 'eval_loss_4': -0.004756334237754345, 'epoch': 20.58}
{'loss': 0.0243, 'grad_norm': 9.62575626373291, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.01659969426691532, 'loss_2': 0.0076904296875, 'loss_3': -16.482402801513672, 'loss_4': 0.31553930044174194, 'epoch': 20.59}
{'loss': 0.0095, 'grad_norm': 5.307245254516602, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.005541649181395769, 'loss_2': 0.00400543212890625, 'loss_3': -16.394676208496094, 'loss_4': -0.201515793800354, 'epoch': 20.59}
{'loss': 0.0221, 'grad_norm': 7.553201675415039, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.019985096529126167, 'loss_2': 0.00209808349609375, 'loss_3': -16.372413635253906, 'loss_4': 0.0855458676815033, 'epoch': 20.6}
{'loss': 0.0113, 'grad_norm': 6.684057712554932, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.010273866355419159, 'loss_2': 0.0009937286376953125, 'loss_3': -16.627904891967773, 'loss_4': 0.4494926333427429, 'epoch': 20.6}
{'loss': 0.0265, 'grad_norm': 7.862221717834473, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.01848781853914261, 'loss_2': 0.0079803466796875, 'loss_3': -16.643409729003906, 'loss_4': 0.7845747470855713, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 10:51:15,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:15,432 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:29<27:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:22,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011365515179932117, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006600987631827593, 'eval_loss_2': 0.004764527082443237, 'eval_loss_3': -18.235185623168945, 'eval_loss_4': 0.005345688201487064, 'epoch': 20.61}
{'loss': 0.0198, 'grad_norm': 8.761663436889648, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.01734238490462303, 'loss_2': 0.002410888671875, 'loss_3': -16.691396713256836, 'loss_4': 0.6014106273651123, 'epoch': 20.62}
{'loss': 0.0071, 'grad_norm': 4.696669578552246, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.005130130797624588, 'loss_2': 0.0019464492797851562, 'loss_3': -16.532367706298828, 'loss_4': -0.6992083191871643, 'epoch': 20.62}
{'loss': 0.0099, 'grad_norm': 4.4931111335754395, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.0051257191225886345, 'loss_2': 0.0047454833984375, 'loss_3': -16.213455200195312, 'loss_4': -0.49464529752731323, 'epoch': 20.63}
{'loss': 0.0094, 'grad_norm': 4.5980024337768555, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.008830931968986988, 'loss_2': 0.0005464553833007812, 'loss_3': -16.611007690429688, 'loss_4': -0.3097279965877533, 'epoch': 20.63}
{'loss': 0.0282, 'grad_norm': 8.167035102844238, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.020711328834295273, 'loss_2': 0.00750732421875, 'loss_3': -16.393030166625977, 'loss_4': 0.2985927164554596, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 10:51:22,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:22,778 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:37<27:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:30,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012150578200817108, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007403478026390076, 'eval_loss_2': 0.0047471001744270325, 'eval_loss_3': -18.257097244262695, 'eval_loss_4': -0.04173339903354645, 'epoch': 20.64}
{'loss': 0.0164, 'grad_norm': 10.101556777954102, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.014560498297214508, 'loss_2': 0.001804351806640625, 'loss_3': -16.067398071289062, 'loss_4': 0.5269896984100342, 'epoch': 20.65}
{'loss': 0.0143, 'grad_norm': 5.513523578643799, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.007411982864141464, 'loss_2': 0.006839752197265625, 'loss_3': -16.550331115722656, 'loss_4': 0.1891198456287384, 'epoch': 20.65}
{'loss': 0.0142, 'grad_norm': 4.904983997344971, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.006824565585702658, 'loss_2': 0.007350921630859375, 'loss_3': -16.455703735351562, 'loss_4': -0.13815459609031677, 'epoch': 20.66}
{'loss': 0.0067, 'grad_norm': 5.300025463104248, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.00656510004773736, 'loss_2': 9.310245513916016e-05, 'loss_3': -16.57239532470703, 'loss_4': 0.2050865888595581, 'epoch': 20.66}
{'loss': 0.0138, 'grad_norm': 5.303596496582031, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.007301335223019123, 'loss_2': 0.00650787353515625, 'loss_3': -16.582658767700195, 'loss_4': 0.5746434926986694, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 10:51:30,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:30,117 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:44<27:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:37,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012983284890651703, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0074955010786652565, 'eval_loss_2': 0.005487784743309021, 'eval_loss_3': -18.26078987121582, 'eval_loss_4': -0.08213984221220016, 'epoch': 20.67}
{'loss': 0.0108, 'grad_norm': 5.770576000213623, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.007073752582073212, 'loss_2': 0.003734588623046875, 'loss_3': -16.639530181884766, 'loss_4': -0.27374327182769775, 'epoch': 20.67}
{'loss': 0.0154, 'grad_norm': 5.572813987731934, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.00972308125346899, 'loss_2': 0.005634307861328125, 'loss_3': -16.50838279724121, 'loss_4': 0.07517099380493164, 'epoch': 20.68}
{'loss': 0.0168, 'grad_norm': 4.915531158447266, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.005730899982154369, 'loss_2': 0.0110626220703125, 'loss_3': -16.52013397216797, 'loss_4': -0.01930314302444458, 'epoch': 20.69}
{'loss': 0.014, 'grad_norm': 5.816690444946289, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.0101932967081666, 'loss_2': 0.003780364990234375, 'loss_3': -16.091001510620117, 'loss_4': 0.2783524990081787, 'epoch': 20.69}
{'loss': 0.0129, 'grad_norm': 4.388801574707031, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.004674483556300402, 'loss_2': 0.0082244873046875, 'loss_3': -16.59819984436035, 'loss_4': 0.5194303393363953, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 10:51:37,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:37,462 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:52<27:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:44,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012248815968632698, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.096, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008141996338963509, 'eval_loss_2': 0.0041068196296691895, 'eval_loss_3': -18.27562713623047, 'eval_loss_4': 0.019224591553211212, 'epoch': 20.7}
{'loss': 0.0139, 'grad_norm': 5.24826717376709, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.007815688848495483, 'loss_2': 0.00606536865234375, 'loss_3': -16.50356101989746, 'loss_4': 0.33509743213653564, 'epoch': 20.7}
{'loss': 0.0218, 'grad_norm': 10.917160034179688, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.016786586493253708, 'loss_2': 0.004985809326171875, 'loss_3': -16.53037452697754, 'loss_4': 0.7664124965667725, 'epoch': 20.71}
{'loss': 0.0276, 'grad_norm': 14.717292785644531, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.026663077995181084, 'loss_2': 0.0009045600891113281, 'loss_3': -16.501264572143555, 'loss_4': 0.45454949140548706, 'epoch': 20.72}
{'loss': 0.0133, 'grad_norm': 4.659873962402344, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.008064299821853638, 'loss_2': 0.0052642822265625, 'loss_3': -16.636310577392578, 'loss_4': -0.31691133975982666, 'epoch': 20.72}
{'loss': 0.01, 'grad_norm': 5.063652515411377, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.006993215065449476, 'loss_2': 0.0029773712158203125, 'loss_3': -16.465648651123047, 'loss_4': 0.5073859691619873, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 10:51:44,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:44,805 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:27:59<27:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:52,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011019762605428696, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.211, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007719454355537891, 'eval_loss_2': 0.003300309181213379, 'eval_loss_3': -18.279203414916992, 'eval_loss_4': 0.10900990664958954, 'epoch': 20.73}
{'loss': 0.0142, 'grad_norm': 6.391910076141357, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.013347349129617214, 'loss_2': 0.0008544921875, 'loss_3': -16.479650497436523, 'loss_4': 0.5262356996536255, 'epoch': 20.73}
{'loss': 0.009, 'grad_norm': 4.876526832580566, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.008059139363467693, 'loss_2': 0.0009737014770507812, 'loss_3': -16.423099517822266, 'loss_4': -0.15498700737953186, 'epoch': 20.74}
{'loss': 0.0181, 'grad_norm': 7.283431053161621, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.016662662848830223, 'loss_2': 0.0014324188232421875, 'loss_3': -16.25091552734375, 'loss_4': -0.3681837320327759, 'epoch': 20.74}
{'loss': 0.0052, 'grad_norm': 4.886436939239502, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.0044982475228607655, 'loss_2': 0.0007104873657226562, 'loss_3': -16.550960540771484, 'loss_4': 0.7094180583953857, 'epoch': 20.75}
{'loss': 0.0108, 'grad_norm': 4.3641276359558105, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.006554120685905218, 'loss_2': 0.00424957275390625, 'loss_3': -16.471294403076172, 'loss_4': 0.2891191244125366, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 10:51:52,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:52,149 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:06<27:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:51:59,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011571928858757019, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008194701746106148, 'eval_loss_2': 0.0033772289752960205, 'eval_loss_3': -18.273540496826172, 'eval_loss_4': 0.07326506823301315, 'epoch': 20.76}
{'loss': 0.0158, 'grad_norm': 6.342685699462891, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.014849906787276268, 'loss_2': 0.0009765625, 'loss_3': -16.245925903320312, 'loss_4': -0.19070971012115479, 'epoch': 20.76}
{'loss': 0.0065, 'grad_norm': 4.471333980560303, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.005277142859995365, 'loss_2': 0.0012149810791015625, 'loss_3': -16.578083038330078, 'loss_4': 0.970319390296936, 'epoch': 20.77}
{'loss': 0.0091, 'grad_norm': 4.877285957336426, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.0047296262346208096, 'loss_2': 0.004329681396484375, 'loss_3': -16.6175537109375, 'loss_4': 0.5730854272842407, 'epoch': 20.77}
{'loss': 0.0157, 'grad_norm': 6.378568172454834, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.012127884663641453, 'loss_2': 0.003551483154296875, 'loss_3': -16.244874954223633, 'loss_4': 0.2743893265724182, 'epoch': 20.78}
{'loss': 0.0168, 'grad_norm': 4.875906467437744, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.0073217423632740974, 'loss_2': 0.009429931640625, 'loss_3': -16.47127914428711, 'loss_4': 0.3710272014141083, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 10:51:59,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:51:59,491 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:14<27:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:06,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012441620230674744, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.925, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008075104095041752, 'eval_loss_2': 0.004366517066955566, 'eval_loss_3': -18.2775821685791, 'eval_loss_4': 0.03240632265806198, 'epoch': 20.78}
{'loss': 0.0147, 'grad_norm': 5.714698791503906, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.01251168642193079, 'loss_2': 0.002193450927734375, 'loss_3': -16.37303924560547, 'loss_4': -0.26279759407043457, 'epoch': 20.79}
{'loss': 0.0094, 'grad_norm': 4.709888458251953, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.006822529248893261, 'loss_2': 0.0026092529296875, 'loss_3': -16.540632247924805, 'loss_4': 0.32349446415901184, 'epoch': 20.8}
{'loss': 0.0101, 'grad_norm': 5.110470771789551, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.008962851017713547, 'loss_2': 0.0011548995971679688, 'loss_3': -16.354904174804688, 'loss_4': 0.3198624849319458, 'epoch': 20.8}
{'loss': 0.0101, 'grad_norm': 4.6485419273376465, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.007023093290627003, 'loss_2': 0.00304412841796875, 'loss_3': -16.48352813720703, 'loss_4': 0.5644943118095398, 'epoch': 20.81}
{'loss': 0.0084, 'grad_norm': 4.767066478729248, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.00708067137748003, 'loss_2': 0.0013341903686523438, 'loss_3': -16.475860595703125, 'loss_4': 0.0829993188381195, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 10:52:06,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:06,829 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:21<27:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:52:14,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012091567739844322, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.835, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007054096087813377, 'eval_loss_2': 0.005037471652030945, 'eval_loss_3': -18.280107498168945, 'eval_loss_4': 0.12823821604251862, 'epoch': 20.81}
{'loss': 0.0164, 'grad_norm': 5.3257575035095215, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.008600457571446896, 'loss_2': 0.00778961181640625, 'loss_3': -16.384723663330078, 'loss_4': 0.5224586129188538, 'epoch': 20.82}
{'loss': 0.0108, 'grad_norm': 5.302860260009766, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.0050886245444417, 'loss_2': 0.005710601806640625, 'loss_3': -16.491947174072266, 'loss_4': 0.6140602231025696, 'epoch': 20.83}
{'loss': 0.019, 'grad_norm': 7.7515788078308105, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.01817787066102028, 'loss_2': 0.0008211135864257812, 'loss_3': -16.37661361694336, 'loss_4': 0.26123252511024475, 'epoch': 20.83}
{'loss': 0.0135, 'grad_norm': 4.803560733795166, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.004399464000016451, 'loss_2': 0.00911712646484375, 'loss_3': -16.558963775634766, 'loss_4': 0.6087906360626221, 'epoch': 20.84}
{'loss': 0.0074, 'grad_norm': 4.874449253082275, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.005453300662338734, 'loss_2': 0.001941680908203125, 'loss_3': -16.39667510986328, 'loss_4': 0.19340839982032776, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 10:52:14,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:14,152 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:28<27:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:21,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009695533663034439, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.385, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006646614521741867, 'eval_loss_2': 0.003048919141292572, 'eval_loss_3': -18.2790470123291, 'eval_loss_4': 0.19410152733325958, 'epoch': 20.84}
{'loss': 0.0169, 'grad_norm': 5.235223770141602, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.009544983506202698, 'loss_2': 0.0073394775390625, 'loss_3': -16.40964126586914, 'loss_4': 0.09457780420780182, 'epoch': 20.85}
{'loss': 0.0086, 'grad_norm': 5.165388584136963, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.00782074499875307, 'loss_2': 0.0007495880126953125, 'loss_3': -16.396089553833008, 'loss_4': 0.6581177711486816, 'epoch': 20.85}
{'loss': 0.0199, 'grad_norm': 7.204480171203613, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.01800280250608921, 'loss_2': 0.001861572265625, 'loss_3': -16.541250228881836, 'loss_4': 0.5128055214881897, 'epoch': 20.86}
{'loss': 0.0152, 'grad_norm': 5.280428886413574, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.010501758195459843, 'loss_2': 0.00467681884765625, 'loss_3': -16.52524757385254, 'loss_4': 0.5429730415344238, 'epoch': 20.87}
{'loss': 0.0147, 'grad_norm': 6.999913215637207, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.011530286632478237, 'loss_2': 0.0031585693359375, 'loss_3': -16.52457046508789, 'loss_4': 0.6518765687942505, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 10:52:21,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:21,488 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:36<27:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:28,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008836492896080017, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005974590312689543, 'eval_loss_2': 0.002861902117729187, 'eval_loss_3': -18.27716827392578, 'eval_loss_4': 0.19146127998828888, 'epoch': 20.87}
{'loss': 0.007, 'grad_norm': 4.497886657714844, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.006517854984849691, 'loss_2': 0.000514984130859375, 'loss_3': -16.42886734008789, 'loss_4': -0.15825161337852478, 'epoch': 20.88}
{'loss': 0.0087, 'grad_norm': 4.732211112976074, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.006663273088634014, 'loss_2': 0.0020503997802734375, 'loss_3': -16.375383377075195, 'loss_4': 0.4479503929615021, 'epoch': 20.88}
{'loss': 0.0086, 'grad_norm': 4.939059257507324, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.006395938340574503, 'loss_2': 0.002227783203125, 'loss_3': -16.483718872070312, 'loss_4': 0.20697085559368134, 'epoch': 20.89}
{'loss': 0.0296, 'grad_norm': 7.439894676208496, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.021454710513353348, 'loss_2': 0.0081787109375, 'loss_3': -16.50708770751953, 'loss_4': 0.344328910112381, 'epoch': 20.9}
{'loss': 0.008, 'grad_norm': 5.615932941436768, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.007942620664834976, 'loss_2': 1.2874603271484375e-05, 'loss_3': -16.560333251953125, 'loss_4': -0.05794902890920639, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 10:52:28,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:28,824 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:43<26:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:36,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00831519439816475, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.39, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005656630732119083, 'eval_loss_2': 0.0026585645973682404, 'eval_loss_3': -18.28597640991211, 'eval_loss_4': 0.21083849668502808, 'epoch': 20.9}
{'loss': 0.0089, 'grad_norm': 5.213907718658447, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.0074216704815626144, 'loss_2': 0.0015096664428710938, 'loss_3': -16.431758880615234, 'loss_4': 0.0023040547966957092, 'epoch': 20.91}
{'loss': 0.0103, 'grad_norm': 5.668301105499268, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.006573207676410675, 'loss_2': 0.003681182861328125, 'loss_3': -16.666196823120117, 'loss_4': 0.3132220506668091, 'epoch': 20.91}
{'loss': 0.014, 'grad_norm': 5.610867500305176, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.011008361354470253, 'loss_2': 0.0030364990234375, 'loss_3': -16.45269012451172, 'loss_4': 0.43244868516921997, 'epoch': 20.92}
{'loss': 0.0073, 'grad_norm': 4.535667419433594, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.005292198155075312, 'loss_2': 0.0019989013671875, 'loss_3': -16.475378036499023, 'loss_4': 0.2987469434738159, 'epoch': 20.92}
{'loss': 0.0073, 'grad_norm': 4.840425968170166, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.005260816775262356, 'loss_2': 0.00201416015625, 'loss_3': -16.53333282470703, 'loss_4': 0.5595177412033081, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 10:52:36,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:36,160 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:50<26:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:43,501 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00847615860402584, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005655039567500353, 'eval_loss_2': 0.002821117639541626, 'eval_loss_3': -18.28227996826172, 'eval_loss_4': 0.1484895646572113, 'epoch': 20.93}
{'loss': 0.0156, 'grad_norm': 7.048844337463379, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.014553597196936607, 'loss_2': 0.0010690689086914062, 'loss_3': -16.4128475189209, 'loss_4': 0.6253705024719238, 'epoch': 20.94}
{'loss': 0.0198, 'grad_norm': 6.182621479034424, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.015853799879550934, 'loss_2': 0.003925323486328125, 'loss_3': -16.5311222076416, 'loss_4': 0.8634974956512451, 'epoch': 20.94}
{'loss': 0.0114, 'grad_norm': 4.814883232116699, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.009860748425126076, 'loss_2': 0.0015087127685546875, 'loss_3': -16.52889060974121, 'loss_4': 0.5177498459815979, 'epoch': 20.95}
{'loss': 0.0064, 'grad_norm': 4.895797252655029, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.005034897942095995, 'loss_2': 0.0013952255249023438, 'loss_3': -16.68960952758789, 'loss_4': 0.15056738257408142, 'epoch': 20.95}
{'loss': 0.0069, 'grad_norm': 5.1780104637146, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.006669005379080772, 'loss_2': 0.0002617835998535156, 'loss_3': -16.292831420898438, 'loss_4': 0.2313964068889618, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 10:52:43,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:43,501 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:28:58<26:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:52:50,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010144281201064587, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.733, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006568665616214275, 'eval_loss_2': 0.0035756155848503113, 'eval_loss_3': -18.285629272460938, 'eval_loss_4': -0.03299613296985626, 'epoch': 20.96}
{'loss': 0.0178, 'grad_norm': 6.030009746551514, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.016539867967367172, 'loss_2': 0.001308441162109375, 'loss_3': -16.595169067382812, 'loss_4': 0.05611500144004822, 'epoch': 20.97}
{'loss': 0.0067, 'grad_norm': 4.638336658477783, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.0063302181661129, 'loss_2': 0.0003345012664794922, 'loss_3': -16.434505462646484, 'loss_4': 1.0960748195648193, 'epoch': 20.97}
{'loss': 0.0139, 'grad_norm': 6.4769287109375, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.010437781922519207, 'loss_2': 0.003452301025390625, 'loss_3': -16.402482986450195, 'loss_4': 0.847928524017334, 'epoch': 20.98}
{'loss': 0.0155, 'grad_norm': 8.07807445526123, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.014845813624560833, 'loss_2': 0.0006289482116699219, 'loss_3': -16.367694854736328, 'loss_4': 0.04945245385169983, 'epoch': 20.98}
{'loss': 0.0131, 'grad_norm': 5.618607044219971, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.0101865753531456, 'loss_2': 0.002941131591796875, 'loss_3': -16.35727882385254, 'loss_4': 0.449917733669281, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 10:52:50,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:50,841 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:05<25:53,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 10:52:57,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011500817723572254, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006298287305980921, 'eval_loss_2': 0.005202531814575195, 'eval_loss_3': -18.282459259033203, 'eval_loss_4': -0.16089820861816406, 'epoch': 20.99}
{'loss': 0.0142, 'grad_norm': 5.210564136505127, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.007873553782701492, 'loss_2': 0.00634765625, 'loss_3': -16.43402099609375, 'loss_4': 0.9624255299568176, 'epoch': 20.99}
{'loss': 0.0024, 'grad_norm': 6.052597999572754, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.0016412794357165694, 'loss_2': 0.0007276535034179688, 'loss_3': -16.763593673706055, 'loss_4': -0.22919659316539764, 'epoch': 21.0}
{'loss': 0.0186, 'grad_norm': 5.011223793029785, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.010325112380087376, 'loss_2': 0.0083160400390625, 'loss_3': -16.490331649780273, 'loss_4': 0.39420661330223083, 'epoch': 21.01}
{'loss': 0.0138, 'grad_norm': 5.000556945800781, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.006503323093056679, 'loss_2': 0.00731658935546875, 'loss_3': -16.545602798461914, 'loss_4': 0.1937597692012787, 'epoch': 21.01}
{'loss': 0.0083, 'grad_norm': 4.4229350090026855, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.004596099257469177, 'loss_2': 0.0036754608154296875, 'loss_3': -16.74822235107422, 'loss_4': 1.0367395877838135, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 10:52:57,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:52:57,863 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:12<26:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:53:05,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010366746224462986, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006879334803670645, 'eval_loss_2': 0.0034874118864536285, 'eval_loss_3': -18.301164627075195, 'eval_loss_4': -0.19506625831127167, 'epoch': 21.02}
{'loss': 0.0084, 'grad_norm': 5.153716564178467, 'learning_rate': 9e-06, 'loss_1': 0.00791323184967041, 'loss_2': 0.0004916191101074219, 'loss_3': -16.61908721923828, 'loss_4': 0.25822269916534424, 'epoch': 21.02}
{'loss': 0.0141, 'grad_norm': 5.773293972015381, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.012108505703508854, 'loss_2': 0.001995086669921875, 'loss_3': -16.562259674072266, 'loss_4': -0.04577434062957764, 'epoch': 21.03}
{'loss': 0.0163, 'grad_norm': 5.629445552825928, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.008481122553348541, 'loss_2': 0.007843017578125, 'loss_3': -16.600784301757812, 'loss_4': 0.11444804817438126, 'epoch': 21.03}
{'loss': 0.0095, 'grad_norm': 4.706868648529053, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.006705374922603369, 'loss_2': 0.00278472900390625, 'loss_3': -16.29194450378418, 'loss_4': 0.43329674005508423, 'epoch': 21.04}
{'loss': 0.0223, 'grad_norm': 5.58034086227417, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.013575463555753231, 'loss_2': 0.008758544921875, 'loss_3': -16.43344497680664, 'loss_4': 0.4948715567588806, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 10:53:05,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:05,195 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:19<26:28,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:53:12,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009203100576996803, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006011868827044964, 'eval_loss_2': 0.003191232681274414, 'eval_loss_3': -18.318862915039062, 'eval_loss_4': -0.24962686002254486, 'epoch': 21.05}
{'loss': 0.015, 'grad_norm': 4.766204357147217, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.008272934705018997, 'loss_2': 0.00675201416015625, 'loss_3': -16.313373565673828, 'loss_4': 0.5210153460502625, 'epoch': 21.05}
{'loss': 0.019, 'grad_norm': 8.424298286437988, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.015985440462827682, 'loss_2': 0.003040313720703125, 'loss_3': -16.589622497558594, 'loss_4': 0.10266248881816864, 'epoch': 21.06}
{'loss': 0.0093, 'grad_norm': 4.931148052215576, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.005855982191860676, 'loss_2': 0.003452301025390625, 'loss_3': -16.66305160522461, 'loss_4': -0.23397260904312134, 'epoch': 21.06}
{'loss': 0.0143, 'grad_norm': 5.325621604919434, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.0074401660822331905, 'loss_2': 0.006824493408203125, 'loss_3': -16.555740356445312, 'loss_4': 0.051717378199100494, 'epoch': 21.07}
{'loss': 0.01, 'grad_norm': 4.978603839874268, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.005382974166423082, 'loss_2': 0.0045928955078125, 'loss_3': -16.62509536743164, 'loss_4': 0.01746852695941925, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 10:53:12,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:12,532 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:27<26:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:19,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008359959349036217, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.039, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005270860157907009, 'eval_loss_2': 0.0030891001224517822, 'eval_loss_3': -18.319169998168945, 'eval_loss_4': -0.21911562979221344, 'epoch': 21.08}
{'loss': 0.0089, 'grad_norm': 4.467823505401611, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.00540853850543499, 'loss_2': 0.0035190582275390625, 'loss_3': -16.323898315429688, 'loss_4': -0.13619156181812286, 'epoch': 21.08}
{'loss': 0.0104, 'grad_norm': 5.396459579467773, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.008908565156161785, 'loss_2': 0.0014514923095703125, 'loss_3': -16.572193145751953, 'loss_4': -0.7512843608856201, 'epoch': 21.09}
{'loss': 0.0035, 'grad_norm': 5.001380920410156, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.0034781352151185274, 'loss_2': 4.786252975463867e-05, 'loss_3': -16.490692138671875, 'loss_4': -0.18779070675373077, 'epoch': 21.09}
{'loss': 0.0088, 'grad_norm': 5.78425407409668, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.006987156346440315, 'loss_2': 0.0018024444580078125, 'loss_3': -16.574443817138672, 'loss_4': -0.0528552308678627, 'epoch': 21.1}
{'loss': 0.0101, 'grad_norm': 5.161729335784912, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.008319580927491188, 'loss_2': 0.0018138885498046875, 'loss_3': -16.461326599121094, 'loss_4': 0.0759798139333725, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 10:53:19,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:19,871 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:34<26:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:53:27,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008265810087323189, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.873, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005402686540037394, 'eval_loss_2': 0.0028631240129470825, 'eval_loss_3': -18.311481475830078, 'eval_loss_4': -0.08180466294288635, 'epoch': 21.1}
{'loss': 0.0201, 'grad_norm': 5.9925994873046875, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.014795380644500256, 'loss_2': 0.005306243896484375, 'loss_3': -16.591754913330078, 'loss_4': 0.5747485160827637, 'epoch': 21.11}
{'loss': 0.0369, 'grad_norm': 13.600720405578613, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.03630421683192253, 'loss_2': 0.0005526542663574219, 'loss_3': -16.415048599243164, 'loss_4': 0.28672271966934204, 'epoch': 21.12}
{'loss': 0.0136, 'grad_norm': 5.7463507652282715, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.009398793801665306, 'loss_2': 0.004169464111328125, 'loss_3': -16.274261474609375, 'loss_4': 0.958582878112793, 'epoch': 21.12}
{'loss': 0.0114, 'grad_norm': 5.5080389976501465, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.008487628772854805, 'loss_2': 0.0029144287109375, 'loss_3': -16.375511169433594, 'loss_4': 0.9536236524581909, 'epoch': 21.13}
{'loss': 0.0073, 'grad_norm': 4.320194244384766, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.0056859818287193775, 'loss_2': 0.00160980224609375, 'loss_3': -16.67401885986328, 'loss_4': 0.37720590829849243, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 10:53:27,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:27,221 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:38<26:22,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 10:53:31,019 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635
[INFO|configuration_utils.py:420] 2025-01-21 10:53:31,021 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635/config.json                                                                             
{'eval_loss': 0.00778567511588335, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.689, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0051221526227891445, 'eval_loss_2': 0.002663522958755493, 'eval_loss_3': -18.31297492980957, 'eval_loss_4': 0.05267844349145889, 'epoch': 21.13}
[INFO|modeling_utils.py:2988] 2025-01-21 10:53:31,506 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:53:31,507 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:53:31,507 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:53:32,515 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-1450] due to args.save_total_limit
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:43<29:10,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 10:53:36,150 >>
{'loss': 0.0098, 'grad_norm': 4.918382167816162, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.007453212980180979, 'loss_2': 0.002307891845703125, 'loss_3': -16.503250122070312, 'loss_4': -0.202676460146904, 'epoch': 21.14}
{'loss': 0.0053, 'grad_norm': 4.605908393859863, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.003962522838264704, 'loss_2': 0.00136566162109375, 'loss_3': -16.5534610748291, 'loss_4': 0.295930415391922, 'epoch': 21.15}
{'loss': 0.0116, 'grad_norm': 5.473428726196289, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.007959931157529354, 'loss_2': 0.00363922119140625, 'loss_3': -16.24649429321289, 'loss_4': 0.24529102444648743, 'epoch': 21.15}
{'loss': 0.0139, 'grad_norm': 6.1468024253845215, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.009624261409044266, 'loss_2': 0.00431060791015625, 'loss_3': -16.515579223632812, 'loss_4': 0.644029974937439, 'epoch': 21.16}
{'loss': 0.0173, 'grad_norm': 7.500341415405273, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.010963380336761475, 'loss_2': 0.0063629150390625, 'loss_3': -16.532392501831055, 'loss_4': 0.9776657223701477, 'epoch': 21.16}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:53:36,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:36,150 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:47<29:10,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 10:53:39,955 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640
[INFO|configuration_utils.py:420] 2025-01-21 10:53:39,956 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640/config.json                                                                             
{'eval_loss': 0.007737104315310717, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.234, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004705239087343216, 'eval_loss_2': 0.0030318647623062134, 'eval_loss_3': -18.289533615112305, 'eval_loss_4': 0.11416074633598328, 'epoch': 21.16}
[INFO|modeling_utils.py:2988] 2025-01-21 10:53:40,474 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:53:40,476 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:53:40,476 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:53:41,502 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3635] due to args.save_total_limit
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:52<29:39,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 10:53:45,134 >>
{'loss': 0.0089, 'grad_norm': 4.656034469604492, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.004654313437640667, 'loss_2': 0.004276275634765625, 'loss_3': -16.624338150024414, 'loss_4': 0.3284682035446167, 'epoch': 21.17}
{'loss': 0.009, 'grad_norm': 5.734182834625244, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.006417959462851286, 'loss_2': 0.002582550048828125, 'loss_3': -16.34640884399414, 'loss_4': 0.13114559650421143, 'epoch': 21.17}
{'loss': 0.0106, 'grad_norm': 6.118322372436523, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.010000728070735931, 'loss_2': 0.0006136894226074219, 'loss_3': -16.726686477661133, 'loss_4': 0.956947386264801, 'epoch': 21.18}
{'loss': 0.008, 'grad_norm': 4.850861072540283, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.003999942447990179, 'loss_2': 0.00399017333984375, 'loss_3': -16.39690589904785, 'loss_4': -0.10460525751113892, 'epoch': 21.19}
{'loss': 0.0098, 'grad_norm': 4.663723468780518, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.0056439358741045, 'loss_2': 0.0041351318359375, 'loss_3': -16.41715431213379, 'loss_4': 0.4511675238609314, 'epoch': 21.19}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:53:45,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:45,134 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:56<29:39,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 10:53:48,941 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645
[INFO|configuration_utils.py:420] 2025-01-21 10:53:48,942 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645/config.json                                                                             
{'eval_loss': 0.007386865094304085, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004287349060177803, 'eval_loss_2': 0.0030995160341262817, 'eval_loss_3': -18.271591186523438, 'eval_loss_4': 0.17478838562965393, 'epoch': 21.19}
[INFO|modeling_utils.py:2988] 2025-01-21 10:53:49,437 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:53:49,438 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:53:49,439 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:53:50,441 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3640] due to args.save_total_limit
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:01<29:34,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 10:53:54,080 >>
{'loss': 0.0103, 'grad_norm': 4.992538928985596, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.006781846284866333, 'loss_2': 0.003513336181640625, 'loss_3': -16.743595123291016, 'loss_4': 0.47718507051467896, 'epoch': 21.2}
{'loss': 0.0065, 'grad_norm': 5.472425937652588, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.005965547636151314, 'loss_2': 0.0005588531494140625, 'loss_3': -16.17780303955078, 'loss_4': 0.4665606915950775, 'epoch': 21.2}
{'loss': 0.0583, 'grad_norm': 21.895963668823242, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.05314701050519943, 'loss_2': 0.0051116943359375, 'loss_3': -16.443479537963867, 'loss_4': 0.3974534273147583, 'epoch': 21.21}
{'loss': 0.01, 'grad_norm': 4.631735801696777, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.009459460154175758, 'loss_2': 0.0005779266357421875, 'loss_3': -16.568435668945312, 'loss_4': 0.4503485858440399, 'epoch': 21.22}
{'loss': 0.0077, 'grad_norm': 4.865983963012695, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.00476501788944006, 'loss_2': 0.00295257568359375, 'loss_3': -16.526906967163086, 'loss_4': 0.7816680073738098, 'epoch': 21.22}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:53:54,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:53:54,080 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:05<29:34,  1.18s/it][INFO|trainer.py:3910] 2025-01-21 10:53:57,879 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650
[INFO|configuration_utils.py:420] 2025-01-21 10:53:57,880 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650/config.json                                                                             
{'eval_loss': 0.0073652565479278564, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.004537075292319059, 'eval_loss_2': 0.0028281807899475098, 'eval_loss_3': -18.257152557373047, 'eval_loss_4': 0.18051211535930634, 'epoch': 21.22}
[INFO|modeling_utils.py:2988] 2025-01-21 10:53:58,382 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 10:53:58,383 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 10:53:58,383 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 10:53:59,392 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3645] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:10<29:30,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 10:54:03,033 >>
{'loss': 0.0137, 'grad_norm': 5.5309367179870605, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.008976642042398453, 'loss_2': 0.004749298095703125, 'loss_3': -16.440807342529297, 'loss_4': 0.38932740688323975, 'epoch': 21.23}
{'loss': 0.0087, 'grad_norm': 4.790747165679932, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.006961788050830364, 'loss_2': 0.001705169677734375, 'loss_3': -16.30801010131836, 'loss_4': 0.27262669801712036, 'epoch': 21.23}
{'loss': 0.0108, 'grad_norm': 5.27548360824585, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.007796323858201504, 'loss_2': 0.003017425537109375, 'loss_3': -16.483898162841797, 'loss_4': 0.013021163642406464, 'epoch': 21.24}
{'loss': 0.0079, 'grad_norm': 5.167958736419678, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.006372930947691202, 'loss_2': 0.0015239715576171875, 'loss_3': -16.438217163085938, 'loss_4': 0.4591774344444275, 'epoch': 21.24}
{'loss': 0.0154, 'grad_norm': 6.85644006729126, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.013266378082334995, 'loss_2': 0.002166748046875, 'loss_3': -16.268844604492188, 'loss_4': 0.966396152973175, 'epoch': 21.25}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 10:54:03,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:03,034 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:17<26:31,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 10:54:10,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0076858289539813995, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.531, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.004372489172965288, 'eval_loss_2': 0.0033133402466773987, 'eval_loss_3': -18.223783493041992, 'eval_loss_4': 0.22330859303474426, 'epoch': 21.25}
{'loss': 0.0064, 'grad_norm': 5.013632297515869, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.004825497046113014, 'loss_2': 0.00157928466796875, 'loss_3': -16.584068298339844, 'loss_4': 0.800326406955719, 'epoch': 21.26}
{'loss': 0.0077, 'grad_norm': 4.570562362670898, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.00599287124350667, 'loss_2': 0.0016918182373046875, 'loss_3': -16.389116287231445, 'loss_4': 0.48492753505706787, 'epoch': 21.26}
{'loss': 0.0086, 'grad_norm': 4.580347537994385, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.0047780186869204044, 'loss_2': 0.003849029541015625, 'loss_3': -16.60307502746582, 'loss_4': 0.7767034769058228, 'epoch': 21.27}
{'loss': 0.0208, 'grad_norm': 14.157354354858398, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.020354915410280228, 'loss_2': 0.0003972053527832031, 'loss_3': -16.37857437133789, 'loss_4': 0.6379954218864441, 'epoch': 21.27}
{'loss': 0.0173, 'grad_norm': 6.073143005371094, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.009632245637476444, 'loss_2': 0.00769805908203125, 'loss_3': -16.321128845214844, 'loss_4': 0.3371162712574005, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 10:54:10,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:10,386 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:24<25:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:17,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009207066148519516, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005022960714995861, 'eval_loss_2': 0.00418410450220108, 'eval_loss_3': -18.204418182373047, 'eval_loss_4': 0.2520628273487091, 'epoch': 21.28}
{'loss': 0.0152, 'grad_norm': 5.985153675079346, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.008129478432238102, 'loss_2': 0.00711822509765625, 'loss_3': -16.532451629638672, 'loss_4': 0.3394450843334198, 'epoch': 21.28}
{'loss': 0.0265, 'grad_norm': 9.718507766723633, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.02180757001042366, 'loss_2': 0.004673004150390625, 'loss_3': -16.485271453857422, 'loss_4': 0.21858979761600494, 'epoch': 21.29}
{'loss': 0.0087, 'grad_norm': 4.908886432647705, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.007825717329978943, 'loss_2': 0.0008244514465332031, 'loss_3': -16.363571166992188, 'loss_4': 0.3015685975551605, 'epoch': 21.3}
{'loss': 0.0077, 'grad_norm': 4.695823669433594, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.005052056163549423, 'loss_2': 0.0026912689208984375, 'loss_3': -16.409839630126953, 'loss_4': 0.40987443923950195, 'epoch': 21.3}
{'loss': 0.0109, 'grad_norm': 4.656155109405518, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.005323090124875307, 'loss_2': 0.005580902099609375, 'loss_3': -16.485958099365234, 'loss_4': 0.4635360836982727, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 10:54:17,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:17,723 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:32<25:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:25,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010024413466453552, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005001283250749111, 'eval_loss_2': 0.0050231292843818665, 'eval_loss_3': -18.206575393676758, 'eval_loss_4': 0.3498978316783905, 'epoch': 21.31}
{'loss': 0.0144, 'grad_norm': 4.957213878631592, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.010436045937240124, 'loss_2': 0.00396728515625, 'loss_3': -16.50026512145996, 'loss_4': 1.0940535068511963, 'epoch': 21.31}
{'loss': 0.0148, 'grad_norm': 8.63905143737793, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.014250893145799637, 'loss_2': 0.0005931854248046875, 'loss_3': -16.57225799560547, 'loss_4': 0.3718761205673218, 'epoch': 21.32}
{'loss': 0.0079, 'grad_norm': 5.243945121765137, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.007822727784514427, 'loss_2': 8.738040924072266e-05, 'loss_3': -16.501422882080078, 'loss_4': 1.1204291582107544, 'epoch': 21.33}
{'loss': 0.0098, 'grad_norm': 4.8479204177856445, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.0034556614700704813, 'loss_2': 0.006366729736328125, 'loss_3': -16.550642013549805, 'loss_4': 0.5773709416389465, 'epoch': 21.33}
{'loss': 0.009, 'grad_norm': 5.325957298278809, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.0064484188333153725, 'loss_2': 0.0025157928466796875, 'loss_3': -16.147014617919922, 'loss_4': 0.2670162320137024, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 10:54:25,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:25,068 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:39<25:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:32,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009193849749863148, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005281639751046896, 'eval_loss_2': 0.003912210464477539, 'eval_loss_3': -18.190105438232422, 'eval_loss_4': 0.44700369238853455, 'epoch': 21.34}
{'loss': 0.0149, 'grad_norm': 7.5664262771606445, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.012255117297172546, 'loss_2': 0.002643585205078125, 'loss_3': -16.184913635253906, 'loss_4': 0.2769472301006317, 'epoch': 21.34}
{'loss': 0.0343, 'grad_norm': 13.399470329284668, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.028215043246746063, 'loss_2': 0.006084442138671875, 'loss_3': -16.671634674072266, 'loss_4': -0.00662955641746521, 'epoch': 21.35}
{'loss': 0.0092, 'grad_norm': 4.833410263061523, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.004868971183896065, 'loss_2': 0.00434112548828125, 'loss_3': -16.269756317138672, 'loss_4': 0.5342872738838196, 'epoch': 21.35}
{'loss': 0.0067, 'grad_norm': 5.479400157928467, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.0059887864626944065, 'loss_2': 0.0007524490356445312, 'loss_3': -16.333877563476562, 'loss_4': 0.916225790977478, 'epoch': 21.36}
{'loss': 0.0111, 'grad_norm': 4.702866554260254, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.002848053351044655, 'loss_2': 0.00826263427734375, 'loss_3': -16.461746215820312, 'loss_4': 1.1018296480178833, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 10:54:32,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:32,409 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:46<25:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:39,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009006360545754433, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005901704542338848, 'eval_loss_2': 0.003104656934738159, 'eval_loss_3': -18.178112030029297, 'eval_loss_4': 0.5704598426818848, 'epoch': 21.37}
{'loss': 0.007, 'grad_norm': 5.585511207580566, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.006934171076864004, 'loss_2': 8.857250213623047e-05, 'loss_3': -16.457763671875, 'loss_4': 1.149168848991394, 'epoch': 21.37}
{'loss': 0.0066, 'grad_norm': 4.402669429779053, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.0035083177499473095, 'loss_2': 0.003082275390625, 'loss_3': -16.475278854370117, 'loss_4': 0.9093217849731445, 'epoch': 21.38}
{'loss': 0.0147, 'grad_norm': 5.905482769012451, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.008348295465111732, 'loss_2': 0.006378173828125, 'loss_3': -16.762939453125, 'loss_4': 1.0439379215240479, 'epoch': 21.38}
{'loss': 0.0163, 'grad_norm': 5.840843200683594, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.010576735250651836, 'loss_2': 0.00576019287109375, 'loss_3': -16.281517028808594, 'loss_4': 0.15580233931541443, 'epoch': 21.39}
{'loss': 0.0122, 'grad_norm': 4.875526428222656, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.005907388869673014, 'loss_2': 0.006259918212890625, 'loss_3': -16.35387420654297, 'loss_4': 0.45477601885795593, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 10:54:39,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:39,755 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:54<25:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:47,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010815232060849667, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.569, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007477327715605497, 'eval_loss_2': 0.0033379048109054565, 'eval_loss_3': -18.1690673828125, 'eval_loss_4': 0.7038282155990601, 'epoch': 21.4}
{'loss': 0.008, 'grad_norm': 5.242010116577148, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.006927228067070246, 'loss_2': 0.0011138916015625, 'loss_3': -16.413360595703125, 'loss_4': 0.4974381625652313, 'epoch': 21.4}
{'loss': 0.0073, 'grad_norm': 4.997377872467041, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.006653599441051483, 'loss_2': 0.0006928443908691406, 'loss_3': -16.317169189453125, 'loss_4': 1.4905359745025635, 'epoch': 21.41}
{'loss': 0.0078, 'grad_norm': 5.097204685211182, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.005134005099534988, 'loss_2': 0.0026378631591796875, 'loss_3': -16.43749237060547, 'loss_4': 1.1044185161590576, 'epoch': 21.41}
{'loss': 0.0161, 'grad_norm': 6.945810317993164, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.01302149798721075, 'loss_2': 0.003093719482421875, 'loss_3': -16.316869735717773, 'loss_4': 1.2426950931549072, 'epoch': 21.42}
{'loss': 0.0099, 'grad_norm': 6.107244968414307, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.009150384925305843, 'loss_2': 0.0007910728454589844, 'loss_3': -16.5657901763916, 'loss_4': 1.0685425996780396, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 10:54:47,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:47,108 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:31:01<25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:54:54,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011933540925383568, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.965, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00710252532735467, 'eval_loss_2': 0.0048310160636901855, 'eval_loss_3': -18.18258285522461, 'eval_loss_4': 0.8120096921920776, 'epoch': 21.42}
{'loss': 0.0097, 'grad_norm': 6.244395732879639, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.009318381547927856, 'loss_2': 0.00036716461181640625, 'loss_3': -16.460323333740234, 'loss_4': 0.7514340281486511, 'epoch': 21.43}
{'loss': 0.0123, 'grad_norm': 5.931064605712891, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.007101474329829216, 'loss_2': 0.005218505859375, 'loss_3': -16.482301712036133, 'loss_4': 1.0915451049804688, 'epoch': 21.44}
{'loss': 0.0106, 'grad_norm': 5.625606060028076, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.008827552199363708, 'loss_2': 0.001773834228515625, 'loss_3': -16.23787498474121, 'loss_4': 0.6484705805778503, 'epoch': 21.44}
{'loss': 0.0087, 'grad_norm': 4.821399688720703, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.006556632928550243, 'loss_2': 0.002147674560546875, 'loss_3': -16.485177993774414, 'loss_4': 1.2076594829559326, 'epoch': 21.45}
{'loss': 0.0195, 'grad_norm': 9.532025337219238, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.015691062435507774, 'loss_2': 0.003826141357421875, 'loss_3': -16.505474090576172, 'loss_4': 1.423823356628418, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 10:54:54,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:54:54,460 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:09<25:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:01,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011622743681073189, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006812530569732189, 'eval_loss_2': 0.004810214042663574, 'eval_loss_3': -18.200027465820312, 'eval_loss_4': 0.8107745051383972, 'epoch': 21.45}
{'loss': 0.0148, 'grad_norm': 4.855958938598633, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.006789306178689003, 'loss_2': 0.00803375244140625, 'loss_3': -16.338829040527344, 'loss_4': 0.4050349295139313, 'epoch': 21.46}
{'loss': 0.0142, 'grad_norm': 8.035711288452148, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.013697970658540726, 'loss_2': 0.0004639625549316406, 'loss_3': -16.56329917907715, 'loss_4': 1.4171113967895508, 'epoch': 21.47}
{'loss': 0.0164, 'grad_norm': 9.105671882629395, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.012509888969361782, 'loss_2': 0.003902435302734375, 'loss_3': -16.591960906982422, 'loss_4': 0.9860570430755615, 'epoch': 21.47}
{'loss': 0.0109, 'grad_norm': 4.893012523651123, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.00585994403809309, 'loss_2': 0.005062103271484375, 'loss_3': -16.434097290039062, 'loss_4': 1.3195295333862305, 'epoch': 21.48}
{'loss': 0.0183, 'grad_norm': 7.78434419631958, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.014068689197301865, 'loss_2': 0.00423431396484375, 'loss_3': -16.48749542236328, 'loss_4': 1.0468614101409912, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 10:55:01,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:01,811 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:16<25:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:09,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01086476817727089, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0070082275196909904, 'eval_loss_2': 0.0038565397262573242, 'eval_loss_3': -18.191707611083984, 'eval_loss_4': 0.8218369483947754, 'epoch': 21.48}
{'loss': 0.0103, 'grad_norm': 5.560446262359619, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.008428187109529972, 'loss_2': 0.0018377304077148438, 'loss_3': -16.660446166992188, 'loss_4': 0.7035717964172363, 'epoch': 21.49}
{'loss': 0.0238, 'grad_norm': 6.503878593444824, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.021091913804411888, 'loss_2': 0.00272369384765625, 'loss_3': -16.517698287963867, 'loss_4': 1.1275190114974976, 'epoch': 21.49}
{'loss': 0.0107, 'grad_norm': 4.317610740661621, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0054759192280471325, 'loss_2': 0.0052032470703125, 'loss_3': -16.376399993896484, 'loss_4': 1.111570119857788, 'epoch': 21.5}
{'loss': 0.0112, 'grad_norm': 4.296432018280029, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.007707422133535147, 'loss_2': 0.00353240966796875, 'loss_3': -16.448684692382812, 'loss_4': 1.2076051235198975, 'epoch': 21.51}
{'loss': 0.0122, 'grad_norm': 4.555043697357178, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.0034526879899203777, 'loss_2': 0.0087890625, 'loss_3': -16.446311950683594, 'loss_4': 0.9504708051681519, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 10:55:09,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:09,154 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:23<25:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:16,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010484293103218079, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00680308835580945, 'eval_loss_2': 0.0036812052130699158, 'eval_loss_3': -18.211380004882812, 'eval_loss_4': 0.8444888591766357, 'epoch': 21.51}
{'loss': 0.0095, 'grad_norm': 13.235635757446289, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.008384413085877895, 'loss_2': 0.001132965087890625, 'loss_3': -16.5805606842041, 'loss_4': 1.7415410280227661, 'epoch': 21.52}
{'loss': 0.0088, 'grad_norm': 5.457170486450195, 'learning_rate': 8.5e-06, 'loss_1': 0.008535481989383698, 'loss_2': 0.0003066062927246094, 'loss_3': -16.5108699798584, 'loss_4': 1.5352964401245117, 'epoch': 21.52}
{'loss': 0.01, 'grad_norm': 4.413136959075928, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.0035352318082004786, 'loss_2': 0.006458282470703125, 'loss_3': -16.687822341918945, 'loss_4': 0.8526668548583984, 'epoch': 21.53}
{'loss': 0.0054, 'grad_norm': 4.688239097595215, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.00404986971989274, 'loss_2': 0.0013828277587890625, 'loss_3': -16.507640838623047, 'loss_4': 1.3880856037139893, 'epoch': 21.53}
{'loss': 0.0109, 'grad_norm': 5.217443943023682, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.00791188608855009, 'loss_2': 0.0030040740966796875, 'loss_3': -16.349035263061523, 'loss_4': 0.7354038953781128, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 10:55:16,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:16,507 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:31<25:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:23,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010698293335735798, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0064107151702046394, 'eval_loss_2': 0.0042875781655311584, 'eval_loss_3': -18.217952728271484, 'eval_loss_4': 0.9049003720283508, 'epoch': 21.54}
{'loss': 0.018, 'grad_norm': 8.108851432800293, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.014973724260926247, 'loss_2': 0.00299072265625, 'loss_3': -16.306495666503906, 'loss_4': 1.4968039989471436, 'epoch': 21.55}
{'loss': 0.0115, 'grad_norm': 4.933827877044678, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.005856738891452551, 'loss_2': 0.00560760498046875, 'loss_3': -16.452228546142578, 'loss_4': 1.3592770099639893, 'epoch': 21.55}
{'loss': 0.0077, 'grad_norm': 6.033077716827393, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.007627155166119337, 'loss_2': 2.574920654296875e-05, 'loss_3': -16.45536231994629, 'loss_4': 1.1818726062774658, 'epoch': 21.56}
{'loss': 0.0078, 'grad_norm': 4.780766010284424, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.0065589789301157, 'loss_2': 0.0011920928955078125, 'loss_3': -16.642051696777344, 'loss_4': -0.10935103893280029, 'epoch': 21.56}
{'loss': 0.013, 'grad_norm': 5.490826606750488, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.009630020707845688, 'loss_2': 0.00334930419921875, 'loss_3': -16.61063575744629, 'loss_4': 0.8342838287353516, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 10:55:23,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:23,862 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:38<25:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:31,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011468524113297462, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.495, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006359572988003492, 'eval_loss_2': 0.005108952522277832, 'eval_loss_3': -18.246044158935547, 'eval_loss_4': 0.9495671391487122, 'epoch': 21.57}
{'loss': 0.0271, 'grad_norm': 16.83172035217285, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.024403411895036697, 'loss_2': 0.0027313232421875, 'loss_3': -16.399890899658203, 'loss_4': 1.7481014728546143, 'epoch': 21.58}
{'loss': 0.0143, 'grad_norm': 5.088353633880615, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.007647419348359108, 'loss_2': 0.0066070556640625, 'loss_3': -16.506500244140625, 'loss_4': 0.6919755935668945, 'epoch': 21.58}
{'loss': 0.0163, 'grad_norm': 5.380434989929199, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.0085811922326684, 'loss_2': 0.00769805908203125, 'loss_3': -16.39822769165039, 'loss_4': 1.402411699295044, 'epoch': 21.59}
{'loss': 0.0088, 'grad_norm': 4.78665018081665, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.005166154354810715, 'loss_2': 0.003681182861328125, 'loss_3': -16.576644897460938, 'loss_4': 1.6338462829589844, 'epoch': 21.59}
{'loss': 0.0334, 'grad_norm': 6.525580883026123, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.02600936032831669, 'loss_2': 0.00737762451171875, 'loss_3': -16.400611877441406, 'loss_4': 1.0102893114089966, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 10:55:31,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:31,217 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:45<24:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:38,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009609433822333813, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005094829015433788, 'eval_loss_2': 0.004514604806900024, 'eval_loss_3': -18.273330688476562, 'eval_loss_4': 1.0198397636413574, 'epoch': 21.6}
{'loss': 0.0162, 'grad_norm': 5.951605319976807, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.011369951069355011, 'loss_2': 0.00478363037109375, 'loss_3': -16.402637481689453, 'loss_4': 1.1596286296844482, 'epoch': 21.6}
{'loss': 0.0072, 'grad_norm': 4.583253860473633, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.0057444097474217415, 'loss_2': 0.0014095306396484375, 'loss_3': -16.62408447265625, 'loss_4': 1.1258665323257446, 'epoch': 21.61}
{'loss': 0.0121, 'grad_norm': 4.692133903503418, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.0031732216011732817, 'loss_2': 0.00893402099609375, 'loss_3': -16.594432830810547, 'loss_4': 1.2867681980133057, 'epoch': 21.62}
{'loss': 0.012, 'grad_norm': 5.963651180267334, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.007928037084639072, 'loss_2': 0.00408935546875, 'loss_3': -16.441633224487305, 'loss_4': 0.7411043047904968, 'epoch': 21.62}
{'loss': 0.0066, 'grad_norm': 4.936500072479248, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.0042672790586948395, 'loss_2': 0.0023593902587890625, 'loss_3': -16.60906410217285, 'loss_4': 0.766507625579834, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 10:55:38,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:38,562 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:53<24:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:45,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008334273472428322, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005106070544570684, 'eval_loss_2': 0.00322820246219635, 'eval_loss_3': -18.274442672729492, 'eval_loss_4': 0.8918763399124146, 'epoch': 21.63}
{'loss': 0.0185, 'grad_norm': 4.998429775238037, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.011234364472329617, 'loss_2': 0.00730133056640625, 'loss_3': -16.38068389892578, 'loss_4': 1.015918493270874, 'epoch': 21.63}
{'loss': 0.0076, 'grad_norm': 4.419670104980469, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.0058702328242361546, 'loss_2': 0.00174713134765625, 'loss_3': -16.247085571289062, 'loss_4': 1.0687774419784546, 'epoch': 21.64}
{'loss': 0.0207, 'grad_norm': 7.420401096343994, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.018548738211393356, 'loss_2': 0.00218963623046875, 'loss_3': -16.29981803894043, 'loss_4': 1.5950565338134766, 'epoch': 21.65}
{'loss': 0.0088, 'grad_norm': 5.119206428527832, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.00556473433971405, 'loss_2': 0.00323486328125, 'loss_3': -16.413150787353516, 'loss_4': 1.2345294952392578, 'epoch': 21.65}
{'loss': 0.018, 'grad_norm': 4.850310802459717, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.008570259436964989, 'loss_2': 0.0094757080078125, 'loss_3': -16.508817672729492, 'loss_4': 0.9333111643791199, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 10:55:45,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:45,909 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:32:00<24:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:55:53,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008712975308299065, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0057616690173745155, 'eval_loss_2': 0.0029513053596019745, 'eval_loss_3': -18.28057098388672, 'eval_loss_4': 0.8254368305206299, 'epoch': 21.66}
{'loss': 0.0416, 'grad_norm': 18.558847427368164, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.040663592517375946, 'loss_2': 0.0009136199951171875, 'loss_3': -16.376371383666992, 'loss_4': 0.7000669240951538, 'epoch': 21.66}
{'loss': 0.0221, 'grad_norm': 8.006513595581055, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.018007216975092888, 'loss_2': 0.004070281982421875, 'loss_3': -16.310209274291992, 'loss_4': 1.025434970855713, 'epoch': 21.67}
{'loss': 0.0087, 'grad_norm': 5.171740531921387, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.008244853466749191, 'loss_2': 0.0004203319549560547, 'loss_3': -16.457542419433594, 'loss_4': 1.2500609159469604, 'epoch': 21.67}
{'loss': 0.0113, 'grad_norm': 8.916775703430176, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.010094162076711655, 'loss_2': 0.0011959075927734375, 'loss_3': -16.44849967956543, 'loss_4': 1.5958712100982666, 'epoch': 21.68}
{'loss': 0.0074, 'grad_norm': 4.142964839935303, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.004731030203402042, 'loss_2': 0.002685546875, 'loss_3': -16.535491943359375, 'loss_4': 0.6082265973091125, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 10:55:53,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:55:53,262 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:07<24:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:00,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008796648122370243, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.881, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005921625532209873, 'eval_loss_2': 0.00287502259016037, 'eval_loss_3': -18.269914627075195, 'eval_loss_4': 0.7650747299194336, 'epoch': 21.69}
{'loss': 0.0085, 'grad_norm': 4.66367769241333, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.007291879504919052, 'loss_2': 0.0012578964233398438, 'loss_3': -16.323720932006836, 'loss_4': 1.2699042558670044, 'epoch': 21.69}
{'loss': 0.007, 'grad_norm': 4.754355430603027, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.005690595600754023, 'loss_2': 0.0012989044189453125, 'loss_3': -16.645092010498047, 'loss_4': 1.0761358737945557, 'epoch': 21.7}
{'loss': 0.0094, 'grad_norm': 4.569632053375244, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.006106166634708643, 'loss_2': 0.003307342529296875, 'loss_3': -16.324190139770508, 'loss_4': 0.6962059736251831, 'epoch': 21.7}
{'loss': 0.0136, 'grad_norm': 4.30555534362793, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.005312097258865833, 'loss_2': 0.0082855224609375, 'loss_3': -16.58155632019043, 'loss_4': 0.7157919406890869, 'epoch': 21.71}
{'loss': 0.0094, 'grad_norm': 7.318490982055664, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.00904426071792841, 'loss_2': 0.000331878662109375, 'loss_3': -16.558399200439453, 'loss_4': 1.1935564279556274, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 10:56:00,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:00,616 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:15<24:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:07,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009366065263748169, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.002, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005752984434366226, 'eval_loss_2': 0.0036130808293819427, 'eval_loss_3': -18.247447967529297, 'eval_loss_4': 0.8134965896606445, 'epoch': 21.72}
{'loss': 0.0169, 'grad_norm': 5.4220733642578125, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.011411293409764767, 'loss_2': 0.00551605224609375, 'loss_3': -16.360240936279297, 'loss_4': 1.1988639831542969, 'epoch': 21.72}
{'loss': 0.0129, 'grad_norm': 4.668617248535156, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.007366967387497425, 'loss_2': 0.00555419921875, 'loss_3': -16.238393783569336, 'loss_4': 1.0546844005584717, 'epoch': 21.73}
{'loss': 0.016, 'grad_norm': 7.4347310066223145, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.013189910911023617, 'loss_2': 0.0028076171875, 'loss_3': -16.430355072021484, 'loss_4': 0.835453987121582, 'epoch': 21.73}
{'loss': 0.0148, 'grad_norm': 7.068609714508057, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.010988044552505016, 'loss_2': 0.0037689208984375, 'loss_3': -16.46375274658203, 'loss_4': 0.6581788063049316, 'epoch': 21.74}
{'loss': 0.0086, 'grad_norm': 4.6730194091796875, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.006626563612371683, 'loss_2': 0.001964569091796875, 'loss_3': -16.134658813476562, 'loss_4': 0.9274471402168274, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 10:56:07,967 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:07,967 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:22<24:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:15,333 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010410496965050697, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.312, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005915114656090736, 'eval_loss_2': 0.004495382308959961, 'eval_loss_3': -18.23518180847168, 'eval_loss_4': 1.0384221076965332, 'epoch': 21.74}
{'loss': 0.0137, 'grad_norm': 5.461045742034912, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.010963179171085358, 'loss_2': 0.002704620361328125, 'loss_3': -16.213239669799805, 'loss_4': 1.5008397102355957, 'epoch': 21.75}
{'loss': 0.0108, 'grad_norm': 5.260141849517822, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.009734834544360638, 'loss_2': 0.0011119842529296875, 'loss_3': -16.446989059448242, 'loss_4': 1.166550874710083, 'epoch': 21.76}
{'loss': 0.0078, 'grad_norm': 4.911754608154297, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.006321682594716549, 'loss_2': 0.001491546630859375, 'loss_3': -16.444730758666992, 'loss_4': 0.8869311809539795, 'epoch': 21.76}
{'loss': 0.0158, 'grad_norm': 5.445830345153809, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.010961492545902729, 'loss_2': 0.0048675537109375, 'loss_3': -16.09551429748535, 'loss_4': 1.3457920551300049, 'epoch': 21.77}
{'loss': 0.0128, 'grad_norm': 7.182259559631348, 'learning_rate': 8.25e-06, 'loss_1': 0.0111921401694417, 'loss_2': 0.0016269683837890625, 'loss_3': -16.432859420776367, 'loss_4': 1.384683609008789, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 10:56:15,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:15,333 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:29<24:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:22,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010201040655374527, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006031353026628494, 'eval_loss_2': 0.004169687628746033, 'eval_loss_3': -18.23062515258789, 'eval_loss_4': 1.1959141492843628, 'epoch': 21.77}
{'loss': 0.0083, 'grad_norm': 4.5614399909973145, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.007017933763563633, 'loss_2': 0.0013256072998046875, 'loss_3': -16.47714614868164, 'loss_4': 0.8376299738883972, 'epoch': 21.78}
{'loss': 0.0326, 'grad_norm': 10.64877700805664, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.024367285892367363, 'loss_2': 0.00823974609375, 'loss_3': -16.513885498046875, 'loss_4': 2.0362162590026855, 'epoch': 21.78}
{'loss': 0.0084, 'grad_norm': 4.68416166305542, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.0027737151831388474, 'loss_2': 0.0056610107421875, 'loss_3': -16.544933319091797, 'loss_4': 1.088304042816162, 'epoch': 21.79}
{'loss': 0.0212, 'grad_norm': 13.051055908203125, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.020113730803132057, 'loss_2': 0.0011148452758789062, 'loss_3': -16.163114547729492, 'loss_4': 1.70424485206604, 'epoch': 21.8}
{'loss': 0.0121, 'grad_norm': 5.271713733673096, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.009074902161955833, 'loss_2': 0.0030612945556640625, 'loss_3': -16.46526336669922, 'loss_4': 1.042966365814209, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 10:56:22,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:22,679 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:37<24:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:30,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009592190384864807, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006168694235384464, 'eval_loss_2': 0.0034234970808029175, 'eval_loss_3': -18.21797752380371, 'eval_loss_4': 1.4113779067993164, 'epoch': 21.8}
{'loss': 0.0064, 'grad_norm': 4.774371147155762, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.005532110575586557, 'loss_2': 0.0009131431579589844, 'loss_3': -16.318517684936523, 'loss_4': 1.8658370971679688, 'epoch': 21.81}
{'loss': 0.0087, 'grad_norm': 5.004112243652344, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.006820005364716053, 'loss_2': 0.0018377304077148438, 'loss_3': -16.208703994750977, 'loss_4': 2.223361015319824, 'epoch': 21.81}
{'loss': 0.0127, 'grad_norm': 4.989505767822266, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.008459254167973995, 'loss_2': 0.0042266845703125, 'loss_3': -16.454349517822266, 'loss_4': 1.810746431350708, 'epoch': 21.82}
{'loss': 0.0036, 'grad_norm': 4.806960105895996, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.0035775466822087765, 'loss_2': 1.4185905456542969e-05, 'loss_3': -16.352550506591797, 'loss_4': 1.6412739753723145, 'epoch': 21.83}
{'loss': 0.0124, 'grad_norm': 4.6893792152404785, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.0034801377914845943, 'loss_2': 0.0089263916015625, 'loss_3': -16.415449142456055, 'loss_4': 1.5940914154052734, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 10:56:30,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:30,031 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:44<24:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:37,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01059056632220745, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006215497385710478, 'eval_loss_2': 0.004375070333480835, 'eval_loss_3': -18.21864891052246, 'eval_loss_4': 1.535736083984375, 'epoch': 21.83}
{'loss': 0.0051, 'grad_norm': 5.287504196166992, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.004424670245498419, 'loss_2': 0.0006380081176757812, 'loss_3': -16.593936920166016, 'loss_4': 2.45542573928833, 'epoch': 21.84}
{'loss': 0.0147, 'grad_norm': 5.068369388580322, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.006027380935847759, 'loss_2': 0.00864410400390625, 'loss_3': -16.327178955078125, 'loss_4': 1.591033935546875, 'epoch': 21.84}
{'loss': 0.0148, 'grad_norm': 6.1726155281066895, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.011204342357814312, 'loss_2': 0.0035457611083984375, 'loss_3': -16.395488739013672, 'loss_4': 1.7741127014160156, 'epoch': 21.85}
{'loss': 0.0155, 'grad_norm': 7.448487281799316, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.013155590742826462, 'loss_2': 0.0023708343505859375, 'loss_3': -16.539966583251953, 'loss_4': 2.1411476135253906, 'epoch': 21.85}
{'loss': 0.0423, 'grad_norm': 22.144702911376953, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.03878200426697731, 'loss_2': 0.0035076141357421875, 'loss_3': -16.420312881469727, 'loss_4': 1.9689046144485474, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 10:56:37,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:37,373 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:51<24:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:44,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01041516661643982, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.842, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0058705792762339115, 'eval_loss_2': 0.004544585943222046, 'eval_loss_3': -18.227581024169922, 'eval_loss_4': 1.6454709768295288, 'epoch': 21.86}
{'loss': 0.0424, 'grad_norm': 11.603416442871094, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.02839086577296257, 'loss_2': 0.0140380859375, 'loss_3': -16.312084197998047, 'loss_4': 1.92033851146698, 'epoch': 21.87}
{'loss': 0.0062, 'grad_norm': 5.339161396026611, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.004929983988404274, 'loss_2': 0.0012359619140625, 'loss_3': -16.452739715576172, 'loss_4': 1.4686359167099, 'epoch': 21.87}
{'loss': 0.0079, 'grad_norm': 5.127316951751709, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.005744450259953737, 'loss_2': 0.002105712890625, 'loss_3': -16.360626220703125, 'loss_4': 2.26590895652771, 'epoch': 21.88}
{'loss': 0.0119, 'grad_norm': 5.257412910461426, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.006345156114548445, 'loss_2': 0.00559234619140625, 'loss_3': -16.399106979370117, 'loss_4': 1.730231761932373, 'epoch': 21.88}
{'loss': 0.0105, 'grad_norm': 4.809561729431152, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.005516561213880777, 'loss_2': 0.0049896240234375, 'loss_3': -16.440261840820312, 'loss_4': 1.796356439590454, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 10:56:44,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:44,711 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:32:59<24:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:52,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009587392210960388, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.432, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006018847227096558, 'eval_loss_2': 0.0035685449838638306, 'eval_loss_3': -18.214675903320312, 'eval_loss_4': 1.8018214702606201, 'epoch': 21.89}
{'loss': 0.0067, 'grad_norm': 5.027817726135254, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.004135610070079565, 'loss_2': 0.002567291259765625, 'loss_3': -16.34963035583496, 'loss_4': 1.9760223627090454, 'epoch': 21.9}
{'loss': 0.0039, 'grad_norm': 4.470157623291016, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0028726181481033564, 'loss_2': 0.0009899139404296875, 'loss_3': -16.509878158569336, 'loss_4': 1.989109754562378, 'epoch': 21.9}
{'loss': 0.011, 'grad_norm': 4.727838516235352, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.004877313040196896, 'loss_2': 0.0061187744140625, 'loss_3': -16.49471664428711, 'loss_4': 2.0005698204040527, 'epoch': 21.91}
{'loss': 0.0174, 'grad_norm': 9.864270210266113, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.016869420185685158, 'loss_2': 0.0005297660827636719, 'loss_3': -16.423179626464844, 'loss_4': 1.5913195610046387, 'epoch': 21.91}
{'loss': 0.008, 'grad_norm': 5.644519329071045, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.00641624303534627, 'loss_2': 0.0015783309936523438, 'loss_3': -16.412179946899414, 'loss_4': 2.2319998741149902, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 10:56:52,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:52,067 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:06<23:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:56:59,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009543615393340588, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006034298799932003, 'eval_loss_2': 0.0035093165934085846, 'eval_loss_3': -18.20897674560547, 'eval_loss_4': 2.019092082977295, 'epoch': 21.92}
{'loss': 0.0091, 'grad_norm': 4.88153076171875, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.007151808589696884, 'loss_2': 0.001979827880859375, 'loss_3': -16.331275939941406, 'loss_4': 1.3011761903762817, 'epoch': 21.92}
{'loss': 0.0109, 'grad_norm': 5.998281002044678, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.006815291475504637, 'loss_2': 0.00411224365234375, 'loss_3': -16.338655471801758, 'loss_4': 2.0565648078918457, 'epoch': 21.93}
{'loss': 0.0122, 'grad_norm': 5.549089431762695, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.009249634109437466, 'loss_2': 0.002941131591796875, 'loss_3': -16.431350708007812, 'loss_4': 2.101207733154297, 'epoch': 21.94}
{'loss': 0.0093, 'grad_norm': 4.237179756164551, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.009234150871634483, 'loss_2': 8.034706115722656e-05, 'loss_3': -16.328197479248047, 'loss_4': 2.975979804992676, 'epoch': 21.94}
{'loss': 0.0209, 'grad_norm': 7.667020320892334, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.011292317882180214, 'loss_2': 0.0096282958984375, 'loss_3': -16.33629035949707, 'loss_4': 1.9954462051391602, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 10:56:59,422 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:56:59,422 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:13<23:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:06,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012430140748620033, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005606977269053459, 'eval_loss_2': 0.006823163479566574, 'eval_loss_3': -18.19976043701172, 'eval_loss_4': 2.2035279273986816, 'epoch': 21.95}
{'loss': 0.0144, 'grad_norm': 7.234503269195557, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.009443878196179867, 'loss_2': 0.00499725341796875, 'loss_3': -16.419343948364258, 'loss_4': 2.055891990661621, 'epoch': 21.95}
{'loss': 0.009, 'grad_norm': 4.768113613128662, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.005219344515353441, 'loss_2': 0.00382232666015625, 'loss_3': -16.449573516845703, 'loss_4': 2.1671061515808105, 'epoch': 21.96}
{'loss': 0.0126, 'grad_norm': 4.943522930145264, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.004595503211021423, 'loss_2': 0.0080413818359375, 'loss_3': -16.450820922851562, 'loss_4': 2.0397140979766846, 'epoch': 21.97}
{'loss': 0.0126, 'grad_norm': 9.748920440673828, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.010003656148910522, 'loss_2': 0.0025482177734375, 'loss_3': -16.414642333984375, 'loss_4': 2.426553726196289, 'epoch': 21.97}
{'loss': 0.0083, 'grad_norm': 5.063616752624512, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.004091581329703331, 'loss_2': 0.0042266845703125, 'loss_3': -16.479141235351562, 'loss_4': 2.031404972076416, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 10:57:06,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:06,774 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:21<22:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 10:57:13,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012936502695083618, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006111144088208675, 'eval_loss_2': 0.006825357675552368, 'eval_loss_3': -18.199899673461914, 'eval_loss_4': 2.2547836303710938, 'epoch': 21.98}
{'loss': 0.0157, 'grad_norm': 6.241218090057373, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.011311664246022701, 'loss_2': 0.00435638427734375, 'loss_3': -16.41187858581543, 'loss_4': 2.1012749671936035, 'epoch': 21.98}
{'loss': 0.0051, 'grad_norm': 4.822058200836182, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.0046743894927203655, 'loss_2': 0.0004723072052001953, 'loss_3': -16.514312744140625, 'loss_4': 2.061330556869507, 'epoch': 21.99}
{'loss': 0.0049, 'grad_norm': 4.396673679351807, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.003605174832046032, 'loss_2': 0.0013179779052734375, 'loss_3': -16.495431900024414, 'loss_4': 1.1699039936065674, 'epoch': 21.99}
{'loss': 0.0059, 'grad_norm': 5.517003059387207, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.003552944166585803, 'loss_2': 0.002376556396484375, 'loss_3': -16.71142578125, 'loss_4': 2.278050184249878, 'epoch': 22.0}
{'loss': 0.0064, 'grad_norm': 4.7620697021484375, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.005282711703330278, 'loss_2': 0.0011234283447265625, 'loss_3': -16.507221221923828, 'loss_4': 2.6725025177001953, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 10:57:13,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:13,817 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:28<23:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 10:57:21,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010664300993084908, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006674217991530895, 'eval_loss_2': 0.003990083932876587, 'eval_loss_3': -18.182098388671875, 'eval_loss_4': 2.353353977203369, 'epoch': 22.01}
{'loss': 0.0204, 'grad_norm': 12.84008502960205, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.014413340017199516, 'loss_2': 0.00595855712890625, 'loss_3': -16.271459579467773, 'loss_4': 2.672565221786499, 'epoch': 22.01}
{'loss': 0.0063, 'grad_norm': 4.619902610778809, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.005032433196902275, 'loss_2': 0.0012264251708984375, 'loss_3': -16.411319732666016, 'loss_4': 2.2432937622070312, 'epoch': 22.02}
{'loss': 0.0179, 'grad_norm': 8.037559509277344, 'learning_rate': 8e-06, 'loss_1': 0.013036764226853848, 'loss_2': 0.0048370361328125, 'loss_3': -16.3563175201416, 'loss_4': 2.5519964694976807, 'epoch': 22.02}
{'loss': 0.0117, 'grad_norm': 4.619437217712402, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.008607178926467896, 'loss_2': 0.0031108856201171875, 'loss_3': -16.45002555847168, 'loss_4': 2.2399377822875977, 'epoch': 22.03}
{'loss': 0.0069, 'grad_norm': 4.6971588134765625, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.0038782560732215643, 'loss_2': 0.0030517578125, 'loss_3': -16.19976043701172, 'loss_4': 2.0462846755981445, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 10:57:21,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:21,159 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:35<23:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:28,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010192390531301498, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.994, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006670529954135418, 'eval_loss_2': 0.003521859645843506, 'eval_loss_3': -18.207944869995117, 'eval_loss_4': 2.4229085445404053, 'epoch': 22.03}
{'loss': 0.0146, 'grad_norm': 4.444228649139404, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.006090908776968718, 'loss_2': 0.008514404296875, 'loss_3': -16.323179244995117, 'loss_4': 2.5558905601501465, 'epoch': 22.04}
{'loss': 0.0087, 'grad_norm': 5.34325647354126, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.006118871737271547, 'loss_2': 0.002590179443359375, 'loss_3': -16.40976333618164, 'loss_4': 2.552593469619751, 'epoch': 22.05}
{'loss': 0.0204, 'grad_norm': 6.989439964294434, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.017562080174684525, 'loss_2': 0.002819061279296875, 'loss_3': -16.470157623291016, 'loss_4': 2.252352237701416, 'epoch': 22.05}
{'loss': 0.0093, 'grad_norm': 4.912847995758057, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.006757557392120361, 'loss_2': 0.002532958984375, 'loss_3': -16.31972885131836, 'loss_4': 2.3477468490600586, 'epoch': 22.06}
{'loss': 0.0096, 'grad_norm': 4.861269950866699, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.006154037546366453, 'loss_2': 0.00347900390625, 'loss_3': -16.187000274658203, 'loss_4': 2.6405751705169678, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 10:57:28,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:28,509 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:43<23:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:35,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009705571457743645, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.327, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.006516321562230587, 'eval_loss_2': 0.0031892508268356323, 'eval_loss_3': -18.218658447265625, 'eval_loss_4': 2.4925942420959473, 'epoch': 22.06}
{'loss': 0.0125, 'grad_norm': 5.19809103012085, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.0105130635201931, 'loss_2': 0.001953125, 'loss_3': -16.311355590820312, 'loss_4': 2.6713919639587402, 'epoch': 22.07}
{'loss': 0.0147, 'grad_norm': 6.588862419128418, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.013962175697088242, 'loss_2': 0.0006966590881347656, 'loss_3': -16.454864501953125, 'loss_4': 2.504080295562744, 'epoch': 22.08}
{'loss': 0.0105, 'grad_norm': 5.65239143371582, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.010297044180333614, 'loss_2': 0.00017940998077392578, 'loss_3': -16.466079711914062, 'loss_4': 2.934636354446411, 'epoch': 22.08}
{'loss': 0.0162, 'grad_norm': 7.442865371704102, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.01214278768748045, 'loss_2': 0.00403594970703125, 'loss_3': -16.220746994018555, 'loss_4': 2.437255859375, 'epoch': 22.09}
{'loss': 0.0195, 'grad_norm': 5.725912570953369, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.01372697576880455, 'loss_2': 0.0057830810546875, 'loss_3': -16.37348175048828, 'loss_4': 2.425283908843994, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 10:57:35,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:35,871 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:50<23:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:43,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009443030692636967, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.926, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006174103356897831, 'eval_loss_2': 0.0032689273357391357, 'eval_loss_3': -18.22103500366211, 'eval_loss_4': 2.4415154457092285, 'epoch': 22.09}
{'loss': 0.011, 'grad_norm': 4.9018235206604, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.004099588841199875, 'loss_2': 0.00688934326171875, 'loss_3': -16.559547424316406, 'loss_4': 2.446505069732666, 'epoch': 22.1}
{'loss': 0.0227, 'grad_norm': 10.765125274658203, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.011753018945455551, 'loss_2': 0.01096343994140625, 'loss_3': -16.484695434570312, 'loss_4': 2.407410144805908, 'epoch': 22.1}
{'loss': 0.0097, 'grad_norm': 4.298966884613037, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.004332666285336018, 'loss_2': 0.005367279052734375, 'loss_3': -16.451751708984375, 'loss_4': 2.375415325164795, 'epoch': 22.11}
{'loss': 0.0109, 'grad_norm': 7.745098114013672, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.01063661091029644, 'loss_2': 0.0002880096435546875, 'loss_3': -16.39857292175293, 'loss_4': 2.1353869438171387, 'epoch': 22.12}
{'loss': 0.0063, 'grad_norm': 4.251686096191406, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.0027415184304118156, 'loss_2': 0.00351715087890625, 'loss_3': -16.467716217041016, 'loss_4': 2.01259708404541, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 10:57:43,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:43,228 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:57<23:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:50,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010323895141482353, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006957126781344414, 'eval_loss_2': 0.0033667683601379395, 'eval_loss_3': -18.225543975830078, 'eval_loss_4': 2.3916964530944824, 'epoch': 22.12}
{'loss': 0.0133, 'grad_norm': 5.872364521026611, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.00995089765638113, 'loss_2': 0.003376007080078125, 'loss_3': -16.04451560974121, 'loss_4': 2.3976292610168457, 'epoch': 22.13}
{'loss': 0.0121, 'grad_norm': 4.665913105010986, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.006457202136516571, 'loss_2': 0.005641937255859375, 'loss_3': -16.51129150390625, 'loss_4': 2.534111738204956, 'epoch': 22.13}
{'loss': 0.0094, 'grad_norm': 5.29729700088501, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.008204104378819466, 'loss_2': 0.0011835098266601562, 'loss_3': -16.3981990814209, 'loss_4': 2.1801278591156006, 'epoch': 22.14}
{'loss': 0.0099, 'grad_norm': 5.924233913421631, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.009875299409031868, 'loss_2': 3.3736228942871094e-05, 'loss_3': -16.374608993530273, 'loss_4': 2.8092617988586426, 'epoch': 22.15}
{'loss': 0.0267, 'grad_norm': 9.321784973144531, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.020926490426063538, 'loss_2': 0.005767822265625, 'loss_3': -16.4710636138916, 'loss_4': 2.5126230716705322, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 10:57:50,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:50,579 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:05<23:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:57:57,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010045506060123444, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.097, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0069695040583610535, 'eval_loss_2': 0.00307600200176239, 'eval_loss_3': -18.246959686279297, 'eval_loss_4': 2.283642292022705, 'epoch': 22.15}
{'loss': 0.0199, 'grad_norm': 10.697981834411621, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.019246302545070648, 'loss_2': 0.0006494522094726562, 'loss_3': -16.485515594482422, 'loss_4': 1.7384986877441406, 'epoch': 22.16}
{'loss': 0.0101, 'grad_norm': 5.382230281829834, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.007382339797914028, 'loss_2': 0.0027561187744140625, 'loss_3': -16.413414001464844, 'loss_4': 1.6314058303833008, 'epoch': 22.16}
{'loss': 0.0059, 'grad_norm': 4.902951240539551, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.004935664124786854, 'loss_2': 0.0009975433349609375, 'loss_3': -16.375186920166016, 'loss_4': 2.1785788536071777, 'epoch': 22.17}
{'loss': 0.0073, 'grad_norm': 4.426238536834717, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.005379348527640104, 'loss_2': 0.0019283294677734375, 'loss_3': -16.39673614501953, 'loss_4': 2.458824634552002, 'epoch': 22.17}
{'loss': 0.0092, 'grad_norm': 5.371672630310059, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.00522300461307168, 'loss_2': 0.00397491455078125, 'loss_3': -16.3187255859375, 'loss_4': 2.642390727996826, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 10:57:57,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:57:57,932 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:12<23:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:05,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009994444437325, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007190372794866562, 'eval_loss_2': 0.0028040707111358643, 'eval_loss_3': -18.25858497619629, 'eval_loss_4': 2.166431427001953, 'epoch': 22.18}
{'loss': 0.0092, 'grad_norm': 5.647136688232422, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.006370393559336662, 'loss_2': 0.0028228759765625, 'loss_3': -16.395950317382812, 'loss_4': 2.6440892219543457, 'epoch': 22.19}
{'loss': 0.0102, 'grad_norm': 6.706768035888672, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.008977352641522884, 'loss_2': 0.0012340545654296875, 'loss_3': -16.260276794433594, 'loss_4': 3.317629337310791, 'epoch': 22.19}
{'loss': 0.0069, 'grad_norm': 4.322834014892578, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.005275372881442308, 'loss_2': 0.00162506103515625, 'loss_3': -16.375804901123047, 'loss_4': 2.2857182025909424, 'epoch': 22.2}
{'loss': 0.0288, 'grad_norm': 24.6984920501709, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.02758404240012169, 'loss_2': 0.001239776611328125, 'loss_3': -16.2987117767334, 'loss_4': 2.2063755989074707, 'epoch': 22.2}
{'loss': 0.0114, 'grad_norm': 5.696578502655029, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.007109035737812519, 'loss_2': 0.00432586669921875, 'loss_3': -16.370281219482422, 'loss_4': 2.5488696098327637, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 10:58:05,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:05,287 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:19<23:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:12,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011036469601094723, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.382, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007137313485145569, 'eval_loss_2': 0.0038991570472717285, 'eval_loss_3': -18.252620697021484, 'eval_loss_4': 2.138395071029663, 'epoch': 22.21}
{'loss': 0.0153, 'grad_norm': 6.007575035095215, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.011277037672698498, 'loss_2': 0.0040130615234375, 'loss_3': -16.47165298461914, 'loss_4': 2.4960408210754395, 'epoch': 22.22}
{'loss': 0.0123, 'grad_norm': 5.09119176864624, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.007938580587506294, 'loss_2': 0.00437164306640625, 'loss_3': -16.330175399780273, 'loss_4': 2.8721282482147217, 'epoch': 22.22}
{'loss': 0.0105, 'grad_norm': 5.709444522857666, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.006631453055888414, 'loss_2': 0.003826141357421875, 'loss_3': -16.50750732421875, 'loss_4': 2.2174718379974365, 'epoch': 22.23}
{'loss': 0.011, 'grad_norm': 5.157999515533447, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.006359925493597984, 'loss_2': 0.00461578369140625, 'loss_3': -16.506738662719727, 'loss_4': 2.6591367721557617, 'epoch': 22.23}
{'loss': 0.0115, 'grad_norm': 7.574718475341797, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.0101607171818614, 'loss_2': 0.0012912750244140625, 'loss_3': -16.450428009033203, 'loss_4': 2.7838306427001953, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 10:58:12,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:12,650 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:27<23:21,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 10:58:20,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01014640647917986, 'eval_runtime': 4.0191, 'eval_samples_per_second': 254.786, 'eval_steps_per_second': 3.981, 'eval_loss_1': 0.006834712810814381, 'eval_loss_2': 0.0033116936683654785, 'eval_loss_3': -18.262508392333984, 'eval_loss_4': 2.121699810028076, 'epoch': 22.24}
{'loss': 0.0131, 'grad_norm': 5.686141014099121, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.008968841284513474, 'loss_2': 0.0041046142578125, 'loss_3': -16.546703338623047, 'loss_4': 2.7944955825805664, 'epoch': 22.24}
{'loss': 0.0107, 'grad_norm': 4.9112701416015625, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.006934038829058409, 'loss_2': 0.003753662109375, 'loss_3': -16.394140243530273, 'loss_4': 2.0032472610473633, 'epoch': 22.25}
{'loss': 0.0117, 'grad_norm': 6.514063835144043, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.011190994642674923, 'loss_2': 0.000484466552734375, 'loss_3': -16.38823890686035, 'loss_4': 2.099195718765259, 'epoch': 22.26}
{'loss': 0.0121, 'grad_norm': 5.902092933654785, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.009932261891663074, 'loss_2': 0.002147674560546875, 'loss_3': -16.30767822265625, 'loss_4': 2.0457067489624023, 'epoch': 22.26}
{'loss': 0.0102, 'grad_norm': 5.340648174285889, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.006675297860056162, 'loss_2': 0.003482818603515625, 'loss_3': -16.38382911682129, 'loss_4': 2.0076494216918945, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 10:58:20,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:20,217 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:34<22:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:27,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009453734382987022, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.791, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006470917724072933, 'eval_loss_2': 0.002982817590236664, 'eval_loss_3': -18.266698837280273, 'eval_loss_4': 2.076317310333252, 'epoch': 22.27}
{'loss': 0.0204, 'grad_norm': 6.478196144104004, 'learning_rate': 7.75e-06, 'loss_1': 0.008265921846032143, 'loss_2': 0.0121002197265625, 'loss_3': -16.351016998291016, 'loss_4': 2.726796865463257, 'epoch': 22.27}
{'loss': 0.0179, 'grad_norm': 6.501729965209961, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.01407285314053297, 'loss_2': 0.003864288330078125, 'loss_3': -16.344379425048828, 'loss_4': 2.167457342147827, 'epoch': 22.28}
{'loss': 0.0087, 'grad_norm': 5.017579555511475, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.006578506901860237, 'loss_2': 0.0021266937255859375, 'loss_3': -16.584596633911133, 'loss_4': 2.2730162143707275, 'epoch': 22.28}
{'loss': 0.0272, 'grad_norm': 13.691827774047852, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.027046849951148033, 'loss_2': 0.00019025802612304688, 'loss_3': -16.228836059570312, 'loss_4': 2.279510974884033, 'epoch': 22.29}
{'loss': 0.011, 'grad_norm': 4.9430718421936035, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.0072690644301474094, 'loss_2': 0.00376129150390625, 'loss_3': -16.528514862060547, 'loss_4': 1.5091421604156494, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 10:58:27,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:27,572 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:42<22:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:34,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009813092648983002, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006802074611186981, 'eval_loss_2': 0.0030110180377960205, 'eval_loss_3': -18.267789840698242, 'eval_loss_4': 2.073551893234253, 'epoch': 22.3}
{'loss': 0.0101, 'grad_norm': 5.6200361251831055, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.006272467318922281, 'loss_2': 0.003856658935546875, 'loss_3': -16.20122528076172, 'loss_4': 1.8425374031066895, 'epoch': 22.3}
{'loss': 0.012, 'grad_norm': 6.749851703643799, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.00786407571285963, 'loss_2': 0.00412750244140625, 'loss_3': -16.493568420410156, 'loss_4': 2.7730889320373535, 'epoch': 22.31}
{'loss': 0.0083, 'grad_norm': 5.372706413269043, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.006322668399661779, 'loss_2': 0.002002716064453125, 'loss_3': -16.475360870361328, 'loss_4': 2.2855889797210693, 'epoch': 22.31}
{'loss': 0.0073, 'grad_norm': 4.184018135070801, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.005920463241636753, 'loss_2': 0.0013666152954101562, 'loss_3': -16.338212966918945, 'loss_4': 1.2775760889053345, 'epoch': 22.32}
{'loss': 0.0136, 'grad_norm': 5.4299445152282715, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.0117564108222723, 'loss_2': 0.0018863677978515625, 'loss_3': -16.504119873046875, 'loss_4': 2.083242177963257, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 10:58:34,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:34,934 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:49<22:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:42,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009931163862347603, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007389621809124947, 'eval_loss_2': 0.0025415420532226562, 'eval_loss_3': -18.274662017822266, 'eval_loss_4': 2.0673813819885254, 'epoch': 22.33}
{'loss': 0.0072, 'grad_norm': 5.211156368255615, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.0062116049230098724, 'loss_2': 0.000980377197265625, 'loss_3': -16.193058013916016, 'loss_4': 2.0552074909210205, 'epoch': 22.33}
{'loss': 0.0105, 'grad_norm': 5.663814544677734, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.008114712312817574, 'loss_2': 0.002368927001953125, 'loss_3': -16.567596435546875, 'loss_4': 1.473111867904663, 'epoch': 22.34}
{'loss': 0.022, 'grad_norm': 10.585824012756348, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.01895827054977417, 'loss_2': 0.003021240234375, 'loss_3': -16.406431198120117, 'loss_4': 2.747201442718506, 'epoch': 22.34}
{'loss': 0.0041, 'grad_norm': 4.277772426605225, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.004043704364448786, 'loss_2': 5.0187110900878906e-05, 'loss_3': -16.302780151367188, 'loss_4': 2.751176118850708, 'epoch': 22.35}
{'loss': 0.0083, 'grad_norm': 4.626235008239746, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.004394058603793383, 'loss_2': 0.0038604736328125, 'loss_3': -16.433313369750977, 'loss_4': 1.4240405559539795, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 10:58:42,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:42,285 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:56<22:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:49,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009903909638524055, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00698855658993125, 'eval_loss_2': 0.0029153525829315186, 'eval_loss_3': -18.273696899414062, 'eval_loss_4': 1.914526343345642, 'epoch': 22.35}
{'loss': 0.011, 'grad_norm': 4.8325018882751465, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.008664747700095177, 'loss_2': 0.0023040771484375, 'loss_3': -16.482295989990234, 'loss_4': 2.232775926589966, 'epoch': 22.36}
{'loss': 0.0093, 'grad_norm': 4.827717304229736, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.007348985876888037, 'loss_2': 0.0019130706787109375, 'loss_3': -16.428319931030273, 'loss_4': 1.8507766723632812, 'epoch': 22.37}
{'loss': 0.0139, 'grad_norm': 6.98739767074585, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.013097181916236877, 'loss_2': 0.00084686279296875, 'loss_3': -16.66429328918457, 'loss_4': 1.936093807220459, 'epoch': 22.37}
{'loss': 0.012, 'grad_norm': 6.825844764709473, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.009114696644246578, 'loss_2': 0.0029239654541015625, 'loss_3': -16.38654327392578, 'loss_4': 1.980102300643921, 'epoch': 22.38}
{'loss': 0.0117, 'grad_norm': 6.0241594314575195, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.007064639125019312, 'loss_2': 0.00461578369140625, 'loss_3': -16.278549194335938, 'loss_4': 1.7582111358642578, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 10:58:49,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:49,628 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:04<22:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:58:56,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009675052016973495, 'eval_runtime': 3.8208, 'eval_samples_per_second': 268.006, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.006528628058731556, 'eval_loss_2': 0.003146424889564514, 'eval_loss_3': -18.26845932006836, 'eval_loss_4': 1.7066903114318848, 'epoch': 22.38}
{'loss': 0.006, 'grad_norm': 4.973974704742432, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.005365218035876751, 'loss_2': 0.0006699562072753906, 'loss_3': -16.54488754272461, 'loss_4': 1.0790218114852905, 'epoch': 22.39}
{'loss': 0.0125, 'grad_norm': 5.178942680358887, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.008041758090257645, 'loss_2': 0.0044097900390625, 'loss_3': -16.61935043334961, 'loss_4': 1.0493583679199219, 'epoch': 22.4}
{'loss': 0.0175, 'grad_norm': 5.663175106048584, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.010996606200933456, 'loss_2': 0.00647735595703125, 'loss_3': -16.202117919921875, 'loss_4': 1.6919925212860107, 'epoch': 22.4}
{'loss': 0.005, 'grad_norm': 4.371696949005127, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.003959654364734888, 'loss_2': 0.00099945068359375, 'loss_3': -16.422452926635742, 'loss_4': 1.3480900526046753, 'epoch': 22.41}
{'loss': 0.0158, 'grad_norm': 7.770064353942871, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.008195767179131508, 'loss_2': 0.0076446533203125, 'loss_3': -16.2832088470459, 'loss_4': 1.3892135620117188, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 10:58:56,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:58:56,996 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:11<22:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:04,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010100556537508965, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006328296847641468, 'eval_loss_2': 0.003772258758544922, 'eval_loss_3': -18.27970314025879, 'eval_loss_4': 1.617629051208496, 'epoch': 22.41}
{'loss': 0.0108, 'grad_norm': 4.805139064788818, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.005418186541646719, 'loss_2': 0.00540924072265625, 'loss_3': -16.491064071655273, 'loss_4': 1.9817821979522705, 'epoch': 22.42}
{'loss': 0.0171, 'grad_norm': 4.465188026428223, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.004945091437548399, 'loss_2': 0.0121612548828125, 'loss_3': -16.464427947998047, 'loss_4': 1.4041612148284912, 'epoch': 22.42}
{'loss': 0.0137, 'grad_norm': 4.998730182647705, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.004758825991302729, 'loss_2': 0.00897216796875, 'loss_3': -16.380725860595703, 'loss_4': 2.042160987854004, 'epoch': 22.43}
{'loss': 0.0137, 'grad_norm': 5.55258846282959, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.005705400835722685, 'loss_2': 0.00795745849609375, 'loss_3': -16.45000457763672, 'loss_4': 2.152510643005371, 'epoch': 22.44}
{'loss': 0.0057, 'grad_norm': 6.0336737632751465, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.005563818849623203, 'loss_2': 0.00015103816986083984, 'loss_3': -16.39478874206543, 'loss_4': 2.1601979732513428, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 10:59:04,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:04,341 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:18<22:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:11,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008918531239032745, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006463662255555391, 'eval_loss_2': 0.0024548694491386414, 'eval_loss_3': -18.266862869262695, 'eval_loss_4': 1.6606526374816895, 'epoch': 22.44}
{'loss': 0.0059, 'grad_norm': 4.452263832092285, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0046806843020021915, 'loss_2': 0.0012645721435546875, 'loss_3': -16.424442291259766, 'loss_4': 1.6105493307113647, 'epoch': 22.45}
{'loss': 0.027, 'grad_norm': 12.886900901794434, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.0247177816927433, 'loss_2': 0.002269744873046875, 'loss_3': -16.618579864501953, 'loss_4': 1.2064363956451416, 'epoch': 22.45}
{'loss': 0.0077, 'grad_norm': 4.627002716064453, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.00459685642272234, 'loss_2': 0.0030670166015625, 'loss_3': -16.350399017333984, 'loss_4': 1.996964931488037, 'epoch': 22.46}
{'loss': 0.0154, 'grad_norm': 5.210636615753174, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.010150203481316566, 'loss_2': 0.0052642822265625, 'loss_3': -16.441110610961914, 'loss_4': 1.3345612287521362, 'epoch': 22.47}
{'loss': 0.0114, 'grad_norm': 6.175169944763184, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.009722142480313778, 'loss_2': 0.001651763916015625, 'loss_3': -16.343095779418945, 'loss_4': 2.007246971130371, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 10:59:11,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:11,691 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:26<22:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:19,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011360561475157738, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.22, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0061851502396166325, 'eval_loss_2': 0.005175411701202393, 'eval_loss_3': -18.271480560302734, 'eval_loss_4': 1.7345415353775024, 'epoch': 22.47}
{'loss': 0.02, 'grad_norm': 7.895326614379883, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.01540164090692997, 'loss_2': 0.00457763671875, 'loss_3': -16.422422409057617, 'loss_4': 1.592140793800354, 'epoch': 22.48}
{'loss': 0.0086, 'grad_norm': 4.878284454345703, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.0035292028915137053, 'loss_2': 0.005084991455078125, 'loss_3': -16.360551834106445, 'loss_4': 1.327040672302246, 'epoch': 22.48}
{'loss': 0.0101, 'grad_norm': 4.582645416259766, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.003782730083912611, 'loss_2': 0.0063018798828125, 'loss_3': -16.368391036987305, 'loss_4': 1.7125874757766724, 'epoch': 22.49}
{'loss': 0.0114, 'grad_norm': 4.748352527618408, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.007832413539290428, 'loss_2': 0.0036067962646484375, 'loss_3': -16.366046905517578, 'loss_4': 1.9927771091461182, 'epoch': 22.49}
{'loss': 0.0072, 'grad_norm': 4.519286155700684, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.004327572416514158, 'loss_2': 0.002880096435546875, 'loss_3': -16.476917266845703, 'loss_4': 1.3939988613128662, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 10:59:19,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:19,038 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:33<22:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:26,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011569518595933914, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005917686969041824, 'eval_loss_2': 0.00565183162689209, 'eval_loss_3': -18.260160446166992, 'eval_loss_4': 1.727536916732788, 'epoch': 22.5}
{'loss': 0.0119, 'grad_norm': 7.236576557159424, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.011863230727612972, 'loss_2': 4.1961669921875e-05, 'loss_3': -16.38176918029785, 'loss_4': 1.2643680572509766, 'epoch': 22.51}
{'loss': 0.0096, 'grad_norm': 4.500165939331055, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.00607172679156065, 'loss_2': 0.00353240966796875, 'loss_3': -16.196779251098633, 'loss_4': 1.5453237295150757, 'epoch': 22.51}
{'loss': 0.0075, 'grad_norm': 5.244650840759277, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.006873621139675379, 'loss_2': 0.0006246566772460938, 'loss_3': -16.565872192382812, 'loss_4': 1.9649453163146973, 'epoch': 22.52}
{'loss': 0.0255, 'grad_norm': 6.529747486114502, 'learning_rate': 7.5e-06, 'loss_1': 0.022164981812238693, 'loss_2': 0.00337982177734375, 'loss_3': -16.288509368896484, 'loss_4': 1.545525312423706, 'epoch': 22.52}
{'loss': 0.0138, 'grad_norm': 4.940037727355957, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.009961170144379139, 'loss_2': 0.0038299560546875, 'loss_3': -16.17435073852539, 'loss_4': 1.1526029109954834, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 10:59:26,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:26,386 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:40<22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:33,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010825874283909798, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.858, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006062747910618782, 'eval_loss_2': 0.004763126373291016, 'eval_loss_3': -18.25345230102539, 'eval_loss_4': 1.6841717958450317, 'epoch': 22.53}
{'loss': 0.0168, 'grad_norm': 4.460827827453613, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.005125480704009533, 'loss_2': 0.0116729736328125, 'loss_3': -16.280029296875, 'loss_4': 1.5568701028823853, 'epoch': 22.53}
{'loss': 0.0216, 'grad_norm': 5.036316394805908, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.010917027480900288, 'loss_2': 0.01068878173828125, 'loss_3': -16.375167846679688, 'loss_4': 1.874267578125, 'epoch': 22.54}
{'loss': 0.0086, 'grad_norm': 5.033544540405273, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.007408069912344217, 'loss_2': 0.0011749267578125, 'loss_3': -16.44093894958496, 'loss_4': 1.518744707107544, 'epoch': 22.55}
{'loss': 0.0192, 'grad_norm': 5.379582405090332, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.011061652563512325, 'loss_2': 0.008148193359375, 'loss_3': -16.43181610107422, 'loss_4': 1.9366376399993896, 'epoch': 22.55}
{'loss': 0.0084, 'grad_norm': 4.9134321212768555, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.004446686245501041, 'loss_2': 0.00392913818359375, 'loss_3': -16.40125274658203, 'loss_4': 1.7335888147354126, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 10:59:33,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:33,739 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:48<22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:41,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009342235513031483, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.883, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0059768082574009895, 'eval_loss_2': 0.003365427255630493, 'eval_loss_3': -18.253345489501953, 'eval_loss_4': 1.5792068243026733, 'epoch': 22.56}
{'loss': 0.0251, 'grad_norm': 9.877798080444336, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.021491946652531624, 'loss_2': 0.003559112548828125, 'loss_3': -16.52717399597168, 'loss_4': 0.9287636280059814, 'epoch': 22.56}
{'loss': 0.0119, 'grad_norm': 4.892677307128906, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.006330663338303566, 'loss_2': 0.00556182861328125, 'loss_3': -16.291208267211914, 'loss_4': 1.267275094985962, 'epoch': 22.57}
{'loss': 0.0088, 'grad_norm': 4.434074401855469, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.00590543495491147, 'loss_2': 0.0029296875, 'loss_3': -16.435317993164062, 'loss_4': 1.7947763204574585, 'epoch': 22.58}
{'loss': 0.0086, 'grad_norm': 4.4490966796875, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.00441754050552845, 'loss_2': 0.004150390625, 'loss_3': -16.465145111083984, 'loss_4': 1.3948171138763428, 'epoch': 22.58}
{'loss': 0.0123, 'grad_norm': 5.2236433029174805, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.007087095640599728, 'loss_2': 0.00525665283203125, 'loss_3': -16.20077133178711, 'loss_4': 1.4943046569824219, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 10:59:41,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:41,095 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:55<22:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:48,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010347526520490646, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.023, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0061515383422374725, 'eval_loss_2': 0.004195988178253174, 'eval_loss_3': -18.24274253845215, 'eval_loss_4': 1.5055515766143799, 'epoch': 22.59}
{'loss': 0.0087, 'grad_norm': 5.172117710113525, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.006189732346683741, 'loss_2': 0.0025463104248046875, 'loss_3': -16.316679000854492, 'loss_4': 1.4438512325286865, 'epoch': 22.59}
{'loss': 0.0182, 'grad_norm': 5.388645172119141, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.011508026160299778, 'loss_2': 0.0066680908203125, 'loss_3': -16.471778869628906, 'loss_4': 1.4775323867797852, 'epoch': 22.6}
{'loss': 0.0163, 'grad_norm': 4.422823429107666, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.004574127495288849, 'loss_2': 0.0117034912109375, 'loss_3': -16.44601058959961, 'loss_4': 1.72635018825531, 'epoch': 22.6}
{'loss': 0.0093, 'grad_norm': 4.857100486755371, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.005603665020316839, 'loss_2': 0.003650665283203125, 'loss_3': -16.5039005279541, 'loss_4': 1.6034579277038574, 'epoch': 22.61}
{'loss': 0.0224, 'grad_norm': 8.293659210205078, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.014512820169329643, 'loss_2': 0.00786590576171875, 'loss_3': -16.292991638183594, 'loss_4': 1.8366203308105469, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 10:59:48,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:48,454 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:36:03<21:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 10:59:55,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00980217382311821, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0061717224307358265, 'eval_loss_2': 0.0036304518580436707, 'eval_loss_3': -18.24431037902832, 'eval_loss_4': 1.5279676914215088, 'epoch': 22.62}
{'loss': 0.0101, 'grad_norm': 7.0118489265441895, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.00757581926882267, 'loss_2': 0.00249481201171875, 'loss_3': -16.33966064453125, 'loss_4': 1.2699968814849854, 'epoch': 22.62}
{'loss': 0.0161, 'grad_norm': 8.355195999145508, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.008412578143179417, 'loss_2': 0.00769805908203125, 'loss_3': -16.34418487548828, 'loss_4': 2.197317600250244, 'epoch': 22.63}
{'loss': 0.0179, 'grad_norm': 7.858613967895508, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.012464489787817001, 'loss_2': 0.005462646484375, 'loss_3': -16.613849639892578, 'loss_4': 1.6569006443023682, 'epoch': 22.63}
{'loss': 0.0095, 'grad_norm': 4.5764031410217285, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.007133867125958204, 'loss_2': 0.00238037109375, 'loss_3': -16.285812377929688, 'loss_4': 1.9006738662719727, 'epoch': 22.64}
{'loss': 0.012, 'grad_norm': 5.289231300354004, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.00675091752782464, 'loss_2': 0.0052032470703125, 'loss_3': -16.339126586914062, 'loss_4': 1.4764022827148438, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 10:59:55,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 10:59:55,811 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:10<21:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:03,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01006985455751419, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006767041981220245, 'eval_loss_2': 0.0033028125762939453, 'eval_loss_3': -18.242229461669922, 'eval_loss_4': 1.6109179258346558, 'epoch': 22.65}
{'loss': 0.0189, 'grad_norm': 5.857868194580078, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.016293002292513847, 'loss_2': 0.0025844573974609375, 'loss_3': -16.302776336669922, 'loss_4': 1.312936544418335, 'epoch': 22.65}
{'loss': 0.0071, 'grad_norm': 4.636815071105957, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.0035069785080850124, 'loss_2': 0.0036296844482421875, 'loss_3': -16.452856063842773, 'loss_4': 1.6087453365325928, 'epoch': 22.66}
{'loss': 0.0216, 'grad_norm': 5.873223304748535, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.014088083989918232, 'loss_2': 0.007476806640625, 'loss_3': -16.337966918945312, 'loss_4': 1.475913405418396, 'epoch': 22.66}
{'loss': 0.003, 'grad_norm': 4.204115867614746, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.0027973747346550226, 'loss_2': 0.00015854835510253906, 'loss_3': -16.44268798828125, 'loss_4': 1.319474458694458, 'epoch': 22.67}
{'loss': 0.0242, 'grad_norm': 7.9820733070373535, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.024169785901904106, 'loss_2': 3.8743019104003906e-05, 'loss_3': -16.392532348632812, 'loss_4': 1.591188669204712, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 11:00:03,167 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:03,167 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:17<21:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:10,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010398615151643753, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.854, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006936552934348583, 'eval_loss_2': 0.003462061285972595, 'eval_loss_3': -18.246826171875, 'eval_loss_4': 1.5728143453598022, 'epoch': 22.67}
{'loss': 0.0063, 'grad_norm': 4.883261203765869, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.004708184860646725, 'loss_2': 0.001598358154296875, 'loss_3': -16.25737190246582, 'loss_4': 1.7037644386291504, 'epoch': 22.68}
{'loss': 0.068, 'grad_norm': 13.43271541595459, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.06746978312730789, 'loss_2': 0.0005626678466796875, 'loss_3': -16.209016799926758, 'loss_4': 1.9983412027359009, 'epoch': 22.69}
{'loss': 0.0226, 'grad_norm': 12.225305557250977, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.021528780460357666, 'loss_2': 0.0010862350463867188, 'loss_3': -16.34833335876465, 'loss_4': 1.9394924640655518, 'epoch': 22.69}
{'loss': 0.0136, 'grad_norm': 5.925485610961914, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.009993331506848335, 'loss_2': 0.0036029815673828125, 'loss_3': -16.322494506835938, 'loss_4': 1.595317006111145, 'epoch': 22.7}
{'loss': 0.0105, 'grad_norm': 4.775808811187744, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.004147760104387999, 'loss_2': 0.00630950927734375, 'loss_3': -16.39029312133789, 'loss_4': 1.532280445098877, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 11:00:10,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:10,518 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:25<21:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:17,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009955085813999176, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.477, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0067521994933485985, 'eval_loss_2': 0.003202885389328003, 'eval_loss_3': -18.246183395385742, 'eval_loss_4': 1.4384926557540894, 'epoch': 22.7}
{'loss': 0.0077, 'grad_norm': 5.257339954376221, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.0069860247895121574, 'loss_2': 0.0006666183471679688, 'loss_3': -16.330373764038086, 'loss_4': 1.2148174047470093, 'epoch': 22.71}
{'loss': 0.0082, 'grad_norm': 5.265962600708008, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.004654556047171354, 'loss_2': 0.003570556640625, 'loss_3': -16.479778289794922, 'loss_4': 0.9958004355430603, 'epoch': 22.72}
{'loss': 0.0079, 'grad_norm': 4.738654136657715, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.005623229313641787, 'loss_2': 0.002246856689453125, 'loss_3': -16.51407241821289, 'loss_4': 0.7357577681541443, 'epoch': 22.72}
{'loss': 0.0035, 'grad_norm': 4.272393703460693, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.0031034459825605154, 'loss_2': 0.0003476142883300781, 'loss_3': -16.310007095336914, 'loss_4': 1.1431105136871338, 'epoch': 22.73}
{'loss': 0.0113, 'grad_norm': 5.1471781730651855, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.008166027255356312, 'loss_2': 0.00318145751953125, 'loss_3': -16.478775024414062, 'loss_4': 1.9324647188186646, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 11:00:17,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:17,875 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:32<21:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:25,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009986614808440208, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.949, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0065607717260718346, 'eval_loss_2': 0.0034258440136909485, 'eval_loss_3': -18.237518310546875, 'eval_loss_4': 1.3576334714889526, 'epoch': 22.73}
{'loss': 0.0237, 'grad_norm': 9.395437240600586, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.01678638346493244, 'loss_2': 0.006916046142578125, 'loss_3': -16.354368209838867, 'loss_4': 1.0492572784423828, 'epoch': 22.74}
{'loss': 0.0077, 'grad_norm': 4.60967493057251, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.0053585064597427845, 'loss_2': 0.002346038818359375, 'loss_3': -16.19425392150879, 'loss_4': 1.3168041706085205, 'epoch': 22.74}
{'loss': 0.0251, 'grad_norm': 11.505317687988281, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.016715582460165024, 'loss_2': 0.008392333984375, 'loss_3': -16.307918548583984, 'loss_4': 1.100973129272461, 'epoch': 22.75}
{'loss': 0.0106, 'grad_norm': 4.609257698059082, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.005775092169642448, 'loss_2': 0.00481414794921875, 'loss_3': -16.331247329711914, 'loss_4': 1.156839370727539, 'epoch': 22.76}
{'loss': 0.005, 'grad_norm': 4.687525749206543, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.0043261400423944, 'loss_2': 0.0006818771362304688, 'loss_3': -16.42013168334961, 'loss_4': 1.7813355922698975, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 11:00:25,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:25,227 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:39<21:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:32,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010284403339028358, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.821, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0066521260887384415, 'eval_loss_2': 0.003632277250289917, 'eval_loss_3': -18.23171043395996, 'eval_loss_4': 1.372529149055481, 'epoch': 22.76}
{'loss': 0.0103, 'grad_norm': 4.644430637359619, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.005038528237491846, 'loss_2': 0.0052642822265625, 'loss_3': -16.47842788696289, 'loss_4': 0.7328203916549683, 'epoch': 22.77}
{'loss': 0.0086, 'grad_norm': 6.192962169647217, 'learning_rate': 7.25e-06, 'loss_1': 0.004928127396851778, 'loss_2': 0.003711700439453125, 'loss_3': -16.54440689086914, 'loss_4': 1.715825080871582, 'epoch': 22.77}
{'loss': 0.0066, 'grad_norm': 4.641334533691406, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.004355900455266237, 'loss_2': 0.002262115478515625, 'loss_3': -16.325244903564453, 'loss_4': 1.5946056842803955, 'epoch': 22.78}
{'loss': 0.0063, 'grad_norm': 4.851652145385742, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.0042803967371582985, 'loss_2': 0.002002716064453125, 'loss_3': -16.444753646850586, 'loss_4': 1.8627300262451172, 'epoch': 22.78}
{'loss': 0.0091, 'grad_norm': 4.635070323944092, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.007131349295377731, 'loss_2': 0.0019369125366210938, 'loss_3': -16.26185417175293, 'loss_4': 1.6251251697540283, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 11:00:32,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:32,583 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:47<21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:39,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010158181190490723, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.762, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006241738796234131, 'eval_loss_2': 0.003916442394256592, 'eval_loss_3': -18.224594116210938, 'eval_loss_4': 1.3571832180023193, 'epoch': 22.79}
{'loss': 0.0218, 'grad_norm': 7.178273677825928, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.01641521416604519, 'loss_2': 0.005374908447265625, 'loss_3': -16.377248764038086, 'loss_4': 2.0820319652557373, 'epoch': 22.8}
{'loss': 0.0085, 'grad_norm': 5.05058479309082, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.007510644383728504, 'loss_2': 0.000988006591796875, 'loss_3': -16.48301887512207, 'loss_4': 1.0291500091552734, 'epoch': 22.8}
{'loss': 0.0131, 'grad_norm': 4.751057147979736, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.006657420191913843, 'loss_2': 0.00643157958984375, 'loss_3': -16.199832916259766, 'loss_4': 1.3739380836486816, 'epoch': 22.81}
{'loss': 0.0257, 'grad_norm': 7.54437780380249, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.017977159470319748, 'loss_2': 0.0077362060546875, 'loss_3': -16.327302932739258, 'loss_4': 0.9671283960342407, 'epoch': 22.81}
{'loss': 0.007, 'grad_norm': 5.331284523010254, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.00669153593480587, 'loss_2': 0.0002906322479248047, 'loss_3': -16.21293067932129, 'loss_4': 1.2834465503692627, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 11:00:39,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:39,940 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:54<21:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:47,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009461458772420883, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.801, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005199397914111614, 'eval_loss_2': 0.004262059926986694, 'eval_loss_3': -18.237632751464844, 'eval_loss_4': 1.3279119729995728, 'epoch': 22.82}
{'loss': 0.0196, 'grad_norm': 7.671999454498291, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.012369947507977486, 'loss_2': 0.00725555419921875, 'loss_3': -16.401599884033203, 'loss_4': 1.0710711479187012, 'epoch': 22.83}
{'loss': 0.0114, 'grad_norm': 5.375546455383301, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.0070564113557338715, 'loss_2': 0.00429534912109375, 'loss_3': -16.354164123535156, 'loss_4': 0.7910654544830322, 'epoch': 22.83}
{'loss': 0.004, 'grad_norm': 4.585197448730469, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.0034777657128870487, 'loss_2': 0.000545501708984375, 'loss_3': -16.508625030517578, 'loss_4': 1.6001802682876587, 'epoch': 22.84}
{'loss': 0.0124, 'grad_norm': 4.693343639373779, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.004246756434440613, 'loss_2': 0.00811004638671875, 'loss_3': -16.280866622924805, 'loss_4': 1.894059658050537, 'epoch': 22.84}
{'loss': 0.0101, 'grad_norm': 4.823907375335693, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.004816947039216757, 'loss_2': 0.00530242919921875, 'loss_3': -16.24884033203125, 'loss_4': 0.9680280089378357, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 11:00:47,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:47,296 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:37:01<21:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:00:54,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00913158431649208, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005205128341913223, 'eval_loss_2': 0.003926455974578857, 'eval_loss_3': -18.237924575805664, 'eval_loss_4': 1.3146346807479858, 'epoch': 22.85}
{'loss': 0.0094, 'grad_norm': 6.619466304779053, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.008975179865956306, 'loss_2': 0.0003771781921386719, 'loss_3': -16.31964683532715, 'loss_4': 1.6034711599349976, 'epoch': 22.85}
{'loss': 0.0076, 'grad_norm': 4.763330936431885, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.005701314192265272, 'loss_2': 0.0018672943115234375, 'loss_3': -16.439197540283203, 'loss_4': 1.3561387062072754, 'epoch': 22.86}
{'loss': 0.0099, 'grad_norm': 5.154007434844971, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.0074804541654884815, 'loss_2': 0.002376556396484375, 'loss_3': -16.06722640991211, 'loss_4': 1.0682846307754517, 'epoch': 22.87}
{'loss': 0.0096, 'grad_norm': 6.10325288772583, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.008987583220005035, 'loss_2': 0.000579833984375, 'loss_3': -16.323476791381836, 'loss_4': 1.564527988433838, 'epoch': 22.87}
{'loss': 0.0027, 'grad_norm': 4.349184513092041, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.0024574464187026024, 'loss_2': 0.0002903938293457031, 'loss_3': -16.385103225708008, 'loss_4': 0.8347658514976501, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 11:00:54,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:00:54,643 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:09<21:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:02,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008561602793633938, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.67, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004705450497567654, 'eval_loss_2': 0.003856152296066284, 'eval_loss_3': -18.226306915283203, 'eval_loss_4': 1.3368582725524902, 'epoch': 22.88}
{'loss': 0.0069, 'grad_norm': 4.450267314910889, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.0035603295546025038, 'loss_2': 0.0033512115478515625, 'loss_3': -16.533052444458008, 'loss_4': 1.2099716663360596, 'epoch': 22.88}
{'loss': 0.013, 'grad_norm': 6.390482425689697, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.00991247408092022, 'loss_2': 0.003082275390625, 'loss_3': -16.43457794189453, 'loss_4': 1.1845483779907227, 'epoch': 22.89}
{'loss': 0.0054, 'grad_norm': 4.621031761169434, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.0038216914981603622, 'loss_2': 0.00159454345703125, 'loss_3': -16.2003231048584, 'loss_4': 2.0183255672454834, 'epoch': 22.9}
{'loss': 0.009, 'grad_norm': 5.368048667907715, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.007715882267802954, 'loss_2': 0.0012464523315429688, 'loss_3': -16.51872444152832, 'loss_4': 1.5292418003082275, 'epoch': 22.9}
{'loss': 0.0119, 'grad_norm': 4.9100189208984375, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.00429685041308403, 'loss_2': 0.0075836181640625, 'loss_3': -16.408666610717773, 'loss_4': 1.7196916341781616, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 11:01:02,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:02,001 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:16<21:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:09,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008393138647079468, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004753975663334131, 'eval_loss_2': 0.0036391615867614746, 'eval_loss_3': -18.228729248046875, 'eval_loss_4': 1.320011019706726, 'epoch': 22.91}
{'loss': 0.0131, 'grad_norm': 6.848922252655029, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.012412512674927711, 'loss_2': 0.000675201416015625, 'loss_3': -16.398479461669922, 'loss_4': 1.3475602865219116, 'epoch': 22.91}
{'loss': 0.0152, 'grad_norm': 4.68535041809082, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.004584155045449734, 'loss_2': 0.01056671142578125, 'loss_3': -16.56686782836914, 'loss_4': 0.9574598670005798, 'epoch': 22.92}
{'loss': 0.0067, 'grad_norm': 5.317361831665039, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.006676357239484787, 'loss_2': 1.0013580322265625e-05, 'loss_3': -16.66205596923828, 'loss_4': 1.442539095878601, 'epoch': 22.92}
{'loss': 0.0172, 'grad_norm': 5.41278076171875, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.00821489468216896, 'loss_2': 0.009002685546875, 'loss_3': -16.35736656188965, 'loss_4': 1.7710224390029907, 'epoch': 22.93}
{'loss': 0.0057, 'grad_norm': 4.8377485275268555, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.005052851513028145, 'loss_2': 0.0006780624389648438, 'loss_3': -16.564273834228516, 'loss_4': 1.6187039613723755, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 11:01:09,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:09,347 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:23<20:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:16,699 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00840823445469141, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004873117431998253, 'eval_loss_2': 0.003535117954015732, 'eval_loss_3': -18.238109588623047, 'eval_loss_4': 1.3185017108917236, 'epoch': 22.94}
{'loss': 0.0128, 'grad_norm': 4.847063064575195, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.00577180739492178, 'loss_2': 0.00701141357421875, 'loss_3': -16.43788719177246, 'loss_4': 1.327155351638794, 'epoch': 22.94}
{'loss': 0.004, 'grad_norm': 4.464406490325928, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.0028980623465031385, 'loss_2': 0.00110626220703125, 'loss_3': -16.357786178588867, 'loss_4': 2.4864110946655273, 'epoch': 22.95}
{'loss': 0.0064, 'grad_norm': 4.773776054382324, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.0049159773625433445, 'loss_2': 0.001434326171875, 'loss_3': -16.50301170349121, 'loss_4': 1.3602337837219238, 'epoch': 22.95}
{'loss': 0.0103, 'grad_norm': 6.045540809631348, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.009490473195910454, 'loss_2': 0.0008106231689453125, 'loss_3': -16.42296600341797, 'loss_4': 0.30739825963974, 'epoch': 22.96}
{'loss': 0.0043, 'grad_norm': 4.690183162689209, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.003649527672678232, 'loss_2': 0.0006976127624511719, 'loss_3': -16.56265640258789, 'loss_4': 1.6185848712921143, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 11:01:16,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:16,700 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:31<20:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:01:24,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008291433565318584, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004637340549379587, 'eval_loss_2': 0.00365409255027771, 'eval_loss_3': -18.229595184326172, 'eval_loss_4': 1.3377617597579956, 'epoch': 22.97}
{'loss': 0.0274, 'grad_norm': 9.034784317016602, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.02286134660243988, 'loss_2': 0.0045166015625, 'loss_3': -16.55560302734375, 'loss_4': 1.3777731657028198, 'epoch': 22.97}
{'loss': 0.0076, 'grad_norm': 5.944409370422363, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.005940288305282593, 'loss_2': 0.0016193389892578125, 'loss_3': -16.208110809326172, 'loss_4': 1.3837134838104248, 'epoch': 22.98}
{'loss': 0.0138, 'grad_norm': 5.099604606628418, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.004702726844698191, 'loss_2': 0.0091400146484375, 'loss_3': -16.584138870239258, 'loss_4': 1.612215518951416, 'epoch': 22.98}
{'loss': 0.0068, 'grad_norm': 5.170052528381348, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.005279356613755226, 'loss_2': 0.00147247314453125, 'loss_3': -16.370168685913086, 'loss_4': 0.9894657135009766, 'epoch': 22.99}
{'loss': 0.0091, 'grad_norm': 4.964643478393555, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.002664691535755992, 'loss_2': 0.006481170654296875, 'loss_3': -16.366262435913086, 'loss_4': 1.4389657974243164, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 11:01:24,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:24,038 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:38<20:22,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:01:31,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00872325524687767, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.362, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.004579078406095505, 'eval_loss_2': 0.0041441768407821655, 'eval_loss_3': -18.230182647705078, 'eval_loss_4': 1.30519700050354, 'epoch': 22.99}
{'loss': 0.0059, 'grad_norm': 5.59515380859375, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.0009746645810082555, 'loss_2': 0.0049285888671875, 'loss_3': -16.268152236938477, 'loss_4': 1.4472304582595825, 'epoch': 23.0}
{'loss': 0.0071, 'grad_norm': 5.35818338394165, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.004625990521162748, 'loss_2': 0.002498626708984375, 'loss_3': -16.35043716430664, 'loss_4': 0.8805696368217468, 'epoch': 23.01}
{'loss': 0.0212, 'grad_norm': 9.44699764251709, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.018122747540473938, 'loss_2': 0.00311279296875, 'loss_3': -16.28277015686035, 'loss_4': 1.4933844804763794, 'epoch': 23.01}
{'loss': 0.0119, 'grad_norm': 4.521813869476318, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.004968621768057346, 'loss_2': 0.0069427490234375, 'loss_3': -16.167301177978516, 'loss_4': 1.616890788078308, 'epoch': 23.02}
{'loss': 0.0209, 'grad_norm': 7.909582614898682, 'learning_rate': 7e-06, 'loss_1': 0.012411129660904408, 'loss_2': 0.008514404296875, 'loss_3': -16.354768753051758, 'loss_4': 1.559665560722351, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 11:01:31,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:31,111 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:45<20:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:38,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008222559466958046, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.59, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004710057750344276, 'eval_loss_2': 0.0035125017166137695, 'eval_loss_3': -18.220720291137695, 'eval_loss_4': 1.3493742942810059, 'epoch': 23.02}
{'loss': 0.0137, 'grad_norm': 5.115131378173828, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.010209973901510239, 'loss_2': 0.0035305023193359375, 'loss_3': -16.58275604248047, 'loss_4': 1.1888659000396729, 'epoch': 23.03}
{'loss': 0.0474, 'grad_norm': 17.546600341796875, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.04462811350822449, 'loss_2': 0.0027313232421875, 'loss_3': -16.3610782623291, 'loss_4': 0.8866699934005737, 'epoch': 23.03}
{'loss': 0.0062, 'grad_norm': 4.994022846221924, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.003993993159383535, 'loss_2': 0.00217437744140625, 'loss_3': -16.541641235351562, 'loss_4': 2.428835391998291, 'epoch': 23.04}
{'loss': 0.007, 'grad_norm': 4.544094085693359, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.004011951852589846, 'loss_2': 0.0029582977294921875, 'loss_3': -16.328277587890625, 'loss_4': 0.9239754676818848, 'epoch': 23.05}
{'loss': 0.0059, 'grad_norm': 5.019916534423828, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.0037136038299649954, 'loss_2': 0.002216339111328125, 'loss_3': -16.271116256713867, 'loss_4': 1.8715038299560547, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 11:01:38,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:38,466 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:53<20:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:45,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007870245724916458, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.186, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00467130821198225, 'eval_loss_2': 0.0031989365816116333, 'eval_loss_3': -18.211666107177734, 'eval_loss_4': 1.4086476564407349, 'epoch': 23.05}
{'loss': 0.0086, 'grad_norm': 4.411337375640869, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.005491052754223347, 'loss_2': 0.0031032562255859375, 'loss_3': -16.459243774414062, 'loss_4': 0.5766311287879944, 'epoch': 23.06}
{'loss': 0.0124, 'grad_norm': 5.279449939727783, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.006027319934219122, 'loss_2': 0.006397247314453125, 'loss_3': -16.36336898803711, 'loss_4': 1.7842456102371216, 'epoch': 23.06}
{'loss': 0.0072, 'grad_norm': 4.519773006439209, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.006127979140728712, 'loss_2': 0.0011196136474609375, 'loss_3': -16.599411010742188, 'loss_4': 0.4325231611728668, 'epoch': 23.07}
{'loss': 0.0045, 'grad_norm': 4.681955814361572, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.0039575244300067425, 'loss_2': 0.000537872314453125, 'loss_3': -16.255592346191406, 'loss_4': 2.310567855834961, 'epoch': 23.08}
{'loss': 0.0072, 'grad_norm': 4.825644493103027, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.003714574035257101, 'loss_2': 0.003437042236328125, 'loss_3': -16.437841415405273, 'loss_4': 1.7343257665634155, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 11:01:45,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:45,817 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:38:00<20:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:01:53,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008447416126728058, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.331, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0048303971998393536, 'eval_loss_2': 0.003617018461227417, 'eval_loss_3': -18.200645446777344, 'eval_loss_4': 1.4971975088119507, 'epoch': 23.08}
{'loss': 0.0051, 'grad_norm': 4.902726173400879, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.0045304992236196995, 'loss_2': 0.0005307197570800781, 'loss_3': -16.61289405822754, 'loss_4': 1.3601922988891602, 'epoch': 23.09}
{'loss': 0.0079, 'grad_norm': 4.675681114196777, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.003730247961357236, 'loss_2': 0.004180908203125, 'loss_3': -16.392147064208984, 'loss_4': 1.9117753505706787, 'epoch': 23.09}
{'loss': 0.0087, 'grad_norm': 6.660900592803955, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.00812626164406538, 'loss_2': 0.0006012916564941406, 'loss_3': -16.560152053833008, 'loss_4': 2.0850653648376465, 'epoch': 23.1}
{'loss': 0.0079, 'grad_norm': 5.20029354095459, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.00526166707277298, 'loss_2': 0.0026874542236328125, 'loss_3': -16.497760772705078, 'loss_4': 1.8743531703948975, 'epoch': 23.1}
{'loss': 0.009, 'grad_norm': 4.9234771728515625, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.006063356529921293, 'loss_2': 0.0029430389404296875, 'loss_3': -16.38091278076172, 'loss_4': 1.6472303867340088, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 11:01:53,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:01:53,165 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:07<20:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:00,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008359203115105629, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005035090260207653, 'eval_loss_2': 0.0033241137862205505, 'eval_loss_3': -18.210590362548828, 'eval_loss_4': 1.5745553970336914, 'epoch': 23.11}
{'loss': 0.0118, 'grad_norm': 5.243192195892334, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.011420322582125664, 'loss_2': 0.0004220008850097656, 'loss_3': -16.41183853149414, 'loss_4': 1.744197130203247, 'epoch': 23.12}
{'loss': 0.0047, 'grad_norm': 4.658175468444824, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.00456409202888608, 'loss_2': 0.0001703500747680664, 'loss_3': -16.58206558227539, 'loss_4': 1.5891997814178467, 'epoch': 23.12}
{'loss': 0.0049, 'grad_norm': 3.810741901397705, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.0028185974806547165, 'loss_2': 0.002117156982421875, 'loss_3': -16.549489974975586, 'loss_4': 1.608775019645691, 'epoch': 23.13}
{'loss': 0.0265, 'grad_norm': 10.04204273223877, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.02340231090784073, 'loss_2': 0.00313568115234375, 'loss_3': -16.350723266601562, 'loss_4': 1.7213096618652344, 'epoch': 23.13}
{'loss': 0.0175, 'grad_norm': 10.912640571594238, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.015483873896300793, 'loss_2': 0.002048492431640625, 'loss_3': -16.25879669189453, 'loss_4': 1.2186540365219116, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 11:02:00,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:00,513 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:15<20:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:07,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008570355363190174, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005503055173903704, 'eval_loss_2': 0.003067299723625183, 'eval_loss_3': -18.208885192871094, 'eval_loss_4': 1.660955786705017, 'epoch': 23.14}
{'loss': 0.0373, 'grad_norm': 20.769248962402344, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.035461898893117905, 'loss_2': 0.0018749237060546875, 'loss_3': -16.21446990966797, 'loss_4': 1.7629042863845825, 'epoch': 23.15}
{'loss': 0.0072, 'grad_norm': 5.487000942230225, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.006788203492760658, 'loss_2': 0.0004544258117675781, 'loss_3': -16.431018829345703, 'loss_4': 2.069875717163086, 'epoch': 23.15}
{'loss': 0.0134, 'grad_norm': 10.850603103637695, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.013007229194045067, 'loss_2': 0.00039267539978027344, 'loss_3': -16.274925231933594, 'loss_4': 1.5493199825286865, 'epoch': 23.16}
{'loss': 0.0093, 'grad_norm': 5.646063804626465, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.006072813179343939, 'loss_2': 0.003192901611328125, 'loss_3': -16.410829544067383, 'loss_4': 2.1306962966918945, 'epoch': 23.16}
{'loss': 0.0201, 'grad_norm': 7.7121758460998535, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.015957362949848175, 'loss_2': 0.0041351318359375, 'loss_3': -16.267742156982422, 'loss_4': 1.3915482759475708, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 11:02:07,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:07,872 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:22<20:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:15,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008953835815191269, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.749, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005633350927382708, 'eval_loss_2': 0.0033204853534698486, 'eval_loss_3': -18.205219268798828, 'eval_loss_4': 1.6706900596618652, 'epoch': 23.17}
{'loss': 0.0197, 'grad_norm': 7.401156425476074, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.01729407347738743, 'loss_2': 0.00244903564453125, 'loss_3': -16.211349487304688, 'loss_4': 1.4524163007736206, 'epoch': 23.17}
{'loss': 0.0135, 'grad_norm': 6.641694068908691, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.011100894771516323, 'loss_2': 0.0024261474609375, 'loss_3': -16.674318313598633, 'loss_4': 1.2143805027008057, 'epoch': 23.18}
{'loss': 0.011, 'grad_norm': 6.090995788574219, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.008884739130735397, 'loss_2': 0.0020771026611328125, 'loss_3': -16.44019889831543, 'loss_4': 1.376587152481079, 'epoch': 23.19}
{'loss': 0.0122, 'grad_norm': 4.733532905578613, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.00694418977946043, 'loss_2': 0.0052642822265625, 'loss_3': -16.357879638671875, 'loss_4': 1.0634334087371826, 'epoch': 23.19}
{'loss': 0.0075, 'grad_norm': 4.219606399536133, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.0032372402492910624, 'loss_2': 0.004241943359375, 'loss_3': -16.566505432128906, 'loss_4': 0.9673998355865479, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 11:02:15,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:15,220 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:29<20:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:22,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009016819298267365, 'eval_runtime': 3.8192, 'eval_samples_per_second': 268.12, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.00560162216424942, 'eval_loss_2': 0.0034151971340179443, 'eval_loss_3': -18.222938537597656, 'eval_loss_4': 1.6308069229125977, 'epoch': 23.2}
{'loss': 0.0086, 'grad_norm': 5.790482521057129, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.006410088390111923, 'loss_2': 0.00218963623046875, 'loss_3': -16.498125076293945, 'loss_4': 1.2720333337783813, 'epoch': 23.2}
{'loss': 0.0078, 'grad_norm': 4.773358345031738, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.004266310948878527, 'loss_2': 0.0035247802734375, 'loss_3': -16.297924041748047, 'loss_4': 0.8922189474105835, 'epoch': 23.21}
{'loss': 0.014, 'grad_norm': 8.083261489868164, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.013482053764164448, 'loss_2': 0.0004706382751464844, 'loss_3': -16.456119537353516, 'loss_4': 1.848653793334961, 'epoch': 23.22}
{'loss': 0.01, 'grad_norm': 4.962374687194824, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.005134588573127985, 'loss_2': 0.004901885986328125, 'loss_3': -16.447660446166992, 'loss_4': 1.784558653831482, 'epoch': 23.22}
{'loss': 0.0139, 'grad_norm': 5.015233516693115, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.007853115908801556, 'loss_2': 0.006069183349609375, 'loss_3': -16.328262329101562, 'loss_4': 1.7175381183624268, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 11:02:22,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:22,587 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:37<20:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:29,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009511357173323631, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.974, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005727588199079037, 'eval_loss_2': 0.003783769905567169, 'eval_loss_3': -18.21485137939453, 'eval_loss_4': 1.5895931720733643, 'epoch': 23.23}
{'loss': 0.0128, 'grad_norm': 5.8955607414245605, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.005538817960768938, 'loss_2': 0.0072784423828125, 'loss_3': -16.37638282775879, 'loss_4': 1.766553282737732, 'epoch': 23.23}
{'loss': 0.0144, 'grad_norm': 9.132291793823242, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.013867809437215328, 'loss_2': 0.0004851818084716797, 'loss_3': -16.2266902923584, 'loss_4': 1.4581058025360107, 'epoch': 23.24}
{'loss': 0.0163, 'grad_norm': 8.054757118225098, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.011745954863727093, 'loss_2': 0.00452423095703125, 'loss_3': -16.36468505859375, 'loss_4': 1.0139122009277344, 'epoch': 23.24}
{'loss': 0.0143, 'grad_norm': 4.626028537750244, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.0032846785616129637, 'loss_2': 0.010986328125, 'loss_3': -16.46304702758789, 'loss_4': 1.5216567516326904, 'epoch': 23.25}
{'loss': 0.0094, 'grad_norm': 4.615789890289307, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.0066152093932032585, 'loss_2': 0.002735137939453125, 'loss_3': -16.555837631225586, 'loss_4': 1.8149771690368652, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 11:02:29,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:29,934 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:44<19:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:37,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008898833766579628, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.245, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005398733541369438, 'eval_loss_2': 0.00350010022521019, 'eval_loss_3': -18.218652725219727, 'eval_loss_4': 1.4832700490951538, 'epoch': 23.26}
{'loss': 0.0067, 'grad_norm': 5.050256729125977, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.006552648730576038, 'loss_2': 0.00010788440704345703, 'loss_3': -16.249595642089844, 'loss_4': 1.1352970600128174, 'epoch': 23.26}
{'loss': 0.0086, 'grad_norm': 4.33139181137085, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.0033852916676551104, 'loss_2': 0.005260467529296875, 'loss_3': -16.333736419677734, 'loss_4': 1.3346401453018188, 'epoch': 23.27}
{'loss': 0.0073, 'grad_norm': 4.7203369140625, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.004232532344758511, 'loss_2': 0.003055572509765625, 'loss_3': -16.239967346191406, 'loss_4': 1.0049118995666504, 'epoch': 23.27}
{'loss': 0.0139, 'grad_norm': 4.959197044372559, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.00840444304049015, 'loss_2': 0.005462646484375, 'loss_3': -16.415590286254883, 'loss_4': 2.1693167686462402, 'epoch': 23.28}
{'loss': 0.0395, 'grad_norm': 15.071332931518555, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.038330525159835815, 'loss_2': 0.001129150390625, 'loss_3': -16.43294334411621, 'loss_4': 0.6026667356491089, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 11:02:37,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:37,275 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:51<19:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:44,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009135216474533081, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006096449214965105, 'eval_loss_2': 0.0030387677252292633, 'eval_loss_3': -18.21575355529785, 'eval_loss_4': 1.3993548154830933, 'epoch': 23.28}
{'loss': 0.0079, 'grad_norm': 4.6499505043029785, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.006592432968318462, 'loss_2': 0.0013179779052734375, 'loss_3': -16.431228637695312, 'loss_4': 2.012558698654175, 'epoch': 23.29}
{'loss': 0.0118, 'grad_norm': 5.467438220977783, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.008289050310850143, 'loss_2': 0.00351715087890625, 'loss_3': -16.227453231811523, 'loss_4': 1.430054783821106, 'epoch': 23.3}
{'loss': 0.0094, 'grad_norm': 4.6506805419921875, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0059068878181278706, 'loss_2': 0.0034465789794921875, 'loss_3': -16.606170654296875, 'loss_4': 1.9053728580474854, 'epoch': 23.3}
{'loss': 0.0084, 'grad_norm': 4.248185157775879, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.004588852636516094, 'loss_2': 0.0038299560546875, 'loss_3': -16.510671615600586, 'loss_4': 1.9905178546905518, 'epoch': 23.31}
{'loss': 0.0207, 'grad_norm': 8.774518013000488, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.020363347604870796, 'loss_2': 0.0003609657287597656, 'loss_3': -16.28038787841797, 'loss_4': 1.6962186098098755, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 11:02:44,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:44,617 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:59<19:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:51,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009820698760449886, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005768000613898039, 'eval_loss_2': 0.004052698612213135, 'eval_loss_3': -18.21693229675293, 'eval_loss_4': 1.262244462966919, 'epoch': 23.31}
{'loss': 0.0098, 'grad_norm': 5.955486297607422, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.008630947209894657, 'loss_2': 0.0011625289916992188, 'loss_3': -16.342918395996094, 'loss_4': 1.4670586585998535, 'epoch': 23.32}
{'loss': 0.0082, 'grad_norm': 5.2220377922058105, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.008186781778931618, 'loss_2': 1.436471939086914e-05, 'loss_3': -16.582469940185547, 'loss_4': 1.633202075958252, 'epoch': 23.33}
{'loss': 0.0116, 'grad_norm': 4.531137943267822, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.004728637635707855, 'loss_2': 0.00689697265625, 'loss_3': -16.329402923583984, 'loss_4': 1.4363466501235962, 'epoch': 23.33}
{'loss': 0.0161, 'grad_norm': 4.939851760864258, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.005442023742944002, 'loss_2': 0.01068878173828125, 'loss_3': -16.55413055419922, 'loss_4': 1.281188726425171, 'epoch': 23.34}
{'loss': 0.0081, 'grad_norm': 4.8204426765441895, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.00533954706043005, 'loss_2': 0.0027828216552734375, 'loss_3': -16.290847778320312, 'loss_4': 1.56708824634552, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 11:02:51,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:51,965 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:06<19:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:02:59,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009045764803886414, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005140125751495361, 'eval_loss_2': 0.0039056390523910522, 'eval_loss_3': -18.2161808013916, 'eval_loss_4': 1.1845855712890625, 'epoch': 23.34}
{'loss': 0.006, 'grad_norm': 4.193264007568359, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.003206446301192045, 'loss_2': 0.002838134765625, 'loss_3': -16.20865249633789, 'loss_4': 0.8503684997558594, 'epoch': 23.35}
{'loss': 0.0085, 'grad_norm': 4.3915557861328125, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.004990036599338055, 'loss_2': 0.00348663330078125, 'loss_3': -16.272857666015625, 'loss_4': 1.1225147247314453, 'epoch': 23.35}
{'loss': 0.017, 'grad_norm': 5.158089637756348, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.00839192420244217, 'loss_2': 0.0085601806640625, 'loss_3': -16.365699768066406, 'loss_4': 1.3023405075073242, 'epoch': 23.36}
{'loss': 0.0151, 'grad_norm': 8.826233863830566, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.013461579568684101, 'loss_2': 0.001617431640625, 'loss_3': -16.240924835205078, 'loss_4': 1.5140525102615356, 'epoch': 23.37}
{'loss': 0.0052, 'grad_norm': 5.075819969177246, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.0032825565431267023, 'loss_2': 0.00194549560546875, 'loss_3': -16.50619888305664, 'loss_4': 0.9440004825592041, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 11:02:59,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:02:59,319 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:13<19:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:06,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00817784946411848, 'eval_runtime': 3.827, 'eval_samples_per_second': 267.572, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.004778209142386913, 'eval_loss_2': 0.0033996403217315674, 'eval_loss_3': -18.206558227539062, 'eval_loss_4': 1.1518751382827759, 'epoch': 23.37}
{'loss': 0.0072, 'grad_norm': 4.754999160766602, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.005557733122259378, 'loss_2': 0.0016345977783203125, 'loss_3': -16.403648376464844, 'loss_4': 0.42728859186172485, 'epoch': 23.38}
{'loss': 0.0187, 'grad_norm': 8.017159461975098, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.014794723130762577, 'loss_2': 0.003925323486328125, 'loss_3': -16.383522033691406, 'loss_4': 1.028531789779663, 'epoch': 23.38}
{'loss': 0.007, 'grad_norm': 5.467922687530518, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.005756080616265535, 'loss_2': 0.0012836456298828125, 'loss_3': -16.386465072631836, 'loss_4': 0.6325185298919678, 'epoch': 23.39}
{'loss': 0.0052, 'grad_norm': 5.022974967956543, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.0039036949165165424, 'loss_2': 0.0012607574462890625, 'loss_3': -16.546966552734375, 'loss_4': 1.4175821542739868, 'epoch': 23.4}
{'loss': 0.013, 'grad_norm': 4.840907096862793, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.008035578764975071, 'loss_2': 0.00499725341796875, 'loss_3': -16.353199005126953, 'loss_4': 0.7251065969467163, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 11:03:06,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:06,686 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:21<19:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:14,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008187901228666306, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.136, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004710507113486528, 'eval_loss_2': 0.0034773945808410645, 'eval_loss_3': -18.211444854736328, 'eval_loss_4': 1.1495208740234375, 'epoch': 23.4}
{'loss': 0.0116, 'grad_norm': 5.277607440948486, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.00916957389563322, 'loss_2': 0.0024242401123046875, 'loss_3': -16.494991302490234, 'loss_4': 1.3688123226165771, 'epoch': 23.41}
{'loss': 0.0066, 'grad_norm': 4.572810173034668, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.0036676800809800625, 'loss_2': 0.0029354095458984375, 'loss_3': -16.53643798828125, 'loss_4': 1.6488840579986572, 'epoch': 23.41}
{'loss': 0.0074, 'grad_norm': 4.478209972381592, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.0032165036536753178, 'loss_2': 0.00417327880859375, 'loss_3': -16.342727661132812, 'loss_4': 0.8840919733047485, 'epoch': 23.42}
{'loss': 0.0026, 'grad_norm': 4.57354736328125, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.002643351210281253, 'loss_2': 3.2186508178710938e-06, 'loss_3': -16.34539794921875, 'loss_4': 1.5432214736938477, 'epoch': 23.42}
{'loss': 0.0135, 'grad_norm': 8.668683052062988, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.00878752302378416, 'loss_2': 0.0047607421875, 'loss_3': -16.415199279785156, 'loss_4': 1.0810656547546387, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 11:03:14,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:14,039 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:28<19:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:21,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009216895326972008, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0051687429659068584, 'eval_loss_2': 0.004048153758049011, 'eval_loss_3': -18.20635414123535, 'eval_loss_4': 1.225037693977356, 'epoch': 23.43}
{'loss': 0.0085, 'grad_norm': 6.2673540115356445, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.00828019343316555, 'loss_2': 0.0002665519714355469, 'loss_3': -16.410907745361328, 'loss_4': 1.5987697839736938, 'epoch': 23.44}
{'loss': 0.0079, 'grad_norm': 5.484882831573486, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.007078193593770266, 'loss_2': 0.00079345703125, 'loss_3': -16.148054122924805, 'loss_4': 1.1144927740097046, 'epoch': 23.44}
{'loss': 0.0098, 'grad_norm': 4.451324939727783, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.004375281278043985, 'loss_2': 0.00537872314453125, 'loss_3': -16.466541290283203, 'loss_4': 1.2553126811981201, 'epoch': 23.45}
{'loss': 0.0171, 'grad_norm': 9.306047439575195, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.014932184480130672, 'loss_2': 0.00217437744140625, 'loss_3': -16.21289825439453, 'loss_4': 1.3119220733642578, 'epoch': 23.45}
{'loss': 0.0106, 'grad_norm': 5.838253974914551, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.009371837601065636, 'loss_2': 0.0011882781982421875, 'loss_3': -16.422128677368164, 'loss_4': 1.0192619562149048, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 11:03:21,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:21,383 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:35<19:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:28,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009719332680106163, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005413850769400597, 'eval_loss_2': 0.004305481910705566, 'eval_loss_3': -18.218067169189453, 'eval_loss_4': 1.2712854146957397, 'epoch': 23.46}
{'loss': 0.0202, 'grad_norm': 6.279844284057617, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.012098369188606739, 'loss_2': 0.0080718994140625, 'loss_3': -16.362186431884766, 'loss_4': 1.3064271211624146, 'epoch': 23.47}
{'loss': 0.0201, 'grad_norm': 4.671689987182617, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.014772649854421616, 'loss_2': 0.00536346435546875, 'loss_3': -16.312923431396484, 'loss_4': 0.9464465379714966, 'epoch': 23.47}
{'loss': 0.0172, 'grad_norm': 6.6773176193237305, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.009503141976892948, 'loss_2': 0.007648468017578125, 'loss_3': -16.347475051879883, 'loss_4': 1.116012692451477, 'epoch': 23.48}
{'loss': 0.0075, 'grad_norm': 4.785545825958252, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.006560607813298702, 'loss_2': 0.0009241104125976562, 'loss_3': -16.426393508911133, 'loss_4': 1.9284485578536987, 'epoch': 23.48}
{'loss': 0.0143, 'grad_norm': 6.293529033660889, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.010075296275317669, 'loss_2': 0.00424957275390625, 'loss_3': -16.17145538330078, 'loss_4': 2.003913402557373, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 11:03:28,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:28,736 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:43<19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:36,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008874206803739071, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005409459583461285, 'eval_loss_2': 0.0034647472202777863, 'eval_loss_3': -18.21794319152832, 'eval_loss_4': 1.2960562705993652, 'epoch': 23.49}
{'loss': 0.0086, 'grad_norm': 5.171972751617432, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.007402977906167507, 'loss_2': 0.0011806488037109375, 'loss_3': -16.307096481323242, 'loss_4': 1.0840187072753906, 'epoch': 23.49}
{'loss': 0.0155, 'grad_norm': 7.260643005371094, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.010050654411315918, 'loss_2': 0.00542449951171875, 'loss_3': -16.389062881469727, 'loss_4': 0.9350749850273132, 'epoch': 23.5}
{'loss': 0.011, 'grad_norm': 5.489016532897949, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.007069998420774937, 'loss_2': 0.003963470458984375, 'loss_3': -16.443546295166016, 'loss_4': 1.4869754314422607, 'epoch': 23.51}
{'loss': 0.0113, 'grad_norm': 6.974922180175781, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.006727081723511219, 'loss_2': 0.0045623779296875, 'loss_3': -16.348041534423828, 'loss_4': 1.4832825660705566, 'epoch': 23.51}
{'loss': 0.0091, 'grad_norm': 4.862008571624756, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.005828556139022112, 'loss_2': 0.00324249267578125, 'loss_3': -16.426376342773438, 'loss_4': 0.7142807245254517, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 11:03:36,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:36,080 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:50<19:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:43,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008420629426836967, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.062, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005319920834153891, 'eval_loss_2': 0.0031007081270217896, 'eval_loss_3': -18.224058151245117, 'eval_loss_4': 1.3367938995361328, 'epoch': 23.52}
{'loss': 0.0058, 'grad_norm': 4.995454788208008, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.004051273223012686, 'loss_2': 0.001743316650390625, 'loss_3': -16.21722984313965, 'loss_4': 1.8483366966247559, 'epoch': 23.52}
{'loss': 0.0108, 'grad_norm': 4.46627140045166, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.0034602961968630552, 'loss_2': 0.0073089599609375, 'loss_3': -16.57526397705078, 'loss_4': 1.4302071332931519, 'epoch': 23.53}
{'loss': 0.0061, 'grad_norm': 4.387115001678467, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.003203879576176405, 'loss_2': 0.00293731689453125, 'loss_3': -16.315113067626953, 'loss_4': 0.8828528523445129, 'epoch': 23.53}
{'loss': 0.0116, 'grad_norm': 7.895993709564209, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.007286986336112022, 'loss_2': 0.00431060791015625, 'loss_3': -16.31422233581543, 'loss_4': 1.6059961318969727, 'epoch': 23.54}
{'loss': 0.0045, 'grad_norm': 4.503600120544434, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.003262151265516877, 'loss_2': 0.0012035369873046875, 'loss_3': -16.532581329345703, 'loss_4': 1.4459331035614014, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 11:03:43,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:43,435 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:57<19:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:50,777 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00843866728246212, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.375, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004899671301245689, 'eval_loss_2': 0.0035389959812164307, 'eval_loss_3': -18.23422622680664, 'eval_loss_4': 1.4152090549468994, 'epoch': 23.55}
{'loss': 0.0317, 'grad_norm': 8.349798202514648, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.023599468171596527, 'loss_2': 0.008148193359375, 'loss_3': -16.54947280883789, 'loss_4': 1.6230618953704834, 'epoch': 23.55}
{'loss': 0.0081, 'grad_norm': 5.082852840423584, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.006917292717844248, 'loss_2': 0.001190185546875, 'loss_3': -16.249710083007812, 'loss_4': 1.658271074295044, 'epoch': 23.56}
{'loss': 0.0067, 'grad_norm': 6.100039958953857, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.005507706664502621, 'loss_2': 0.0012254714965820312, 'loss_3': -16.361692428588867, 'loss_4': 2.0547397136688232, 'epoch': 23.56}
{'loss': 0.0065, 'grad_norm': 4.580694198608398, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.004840386100113392, 'loss_2': 0.001667022705078125, 'loss_3': -16.332529067993164, 'loss_4': 0.7503129839897156, 'epoch': 23.57}
{'loss': 0.0078, 'grad_norm': 4.59536075592041, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.0038245373871177435, 'loss_2': 0.00396728515625, 'loss_3': -16.54475975036621, 'loss_4': 1.9717457294464111, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 11:03:50,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:50,778 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:05<19:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:03:58,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008829240687191486, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.304, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004831103142350912, 'eval_loss_2': 0.003998138010501862, 'eval_loss_3': -18.21475601196289, 'eval_loss_4': 1.4137073755264282, 'epoch': 23.58}
{'loss': 0.0239, 'grad_norm': 8.801674842834473, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.018623631447553635, 'loss_2': 0.0052642822265625, 'loss_3': -16.359811782836914, 'loss_4': 1.6390620470046997, 'epoch': 23.58}
{'loss': 0.0039, 'grad_norm': 4.621827602386475, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.0023269790690392256, 'loss_2': 0.0015888214111328125, 'loss_3': -16.361061096191406, 'loss_4': 1.3051644563674927, 'epoch': 23.59}
{'loss': 0.0123, 'grad_norm': 4.9866838455200195, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.007063473574817181, 'loss_2': 0.00521087646484375, 'loss_3': -16.457401275634766, 'loss_4': 1.7892584800720215, 'epoch': 23.59}
{'loss': 0.0105, 'grad_norm': 6.119140148162842, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.008355851285159588, 'loss_2': 0.002193450927734375, 'loss_3': -16.52413558959961, 'loss_4': 1.622108817100525, 'epoch': 23.6}
{'loss': 0.0051, 'grad_norm': 4.831580638885498, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.003921856638044119, 'loss_2': 0.0012264251708984375, 'loss_3': -16.619503021240234, 'loss_4': 1.1635282039642334, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 11:03:58,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:03:58,122 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:12<18:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:05,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00957659911364317, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005154112819582224, 'eval_loss_2': 0.004422485828399658, 'eval_loss_3': -18.20765495300293, 'eval_loss_4': 1.4154295921325684, 'epoch': 23.6}
{'loss': 0.0114, 'grad_norm': 5.374279499053955, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.011318420991301537, 'loss_2': 4.303455352783203e-05, 'loss_3': -16.38431739807129, 'loss_4': 1.587608814239502, 'epoch': 23.61}
{'loss': 0.0085, 'grad_norm': 5.033347129821777, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.006030054297298193, 'loss_2': 0.002483367919921875, 'loss_3': -16.14724349975586, 'loss_4': 0.9240885972976685, 'epoch': 23.62}
{'loss': 0.0069, 'grad_norm': 4.6361541748046875, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.004695933312177658, 'loss_2': 0.00217437744140625, 'loss_3': -16.44329833984375, 'loss_4': 0.9768173694610596, 'epoch': 23.62}
{'loss': 0.0064, 'grad_norm': 4.900874137878418, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.004273240454494953, 'loss_2': 0.0021266937255859375, 'loss_3': -16.363065719604492, 'loss_4': 1.5508216619491577, 'epoch': 23.63}
{'loss': 0.0086, 'grad_norm': 6.247409343719482, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.006839053239673376, 'loss_2': 0.0017385482788085938, 'loss_3': -16.428733825683594, 'loss_4': 1.4937798976898193, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 11:04:05,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:05,469 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:20<18:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:12,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010129967704415321, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005457447841763496, 'eval_loss_2': 0.004672519862651825, 'eval_loss_3': -18.198890686035156, 'eval_loss_4': 1.440335750579834, 'epoch': 23.63}
{'loss': 0.0048, 'grad_norm': 4.372641563415527, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.0037055036518722773, 'loss_2': 0.00110626220703125, 'loss_3': -16.48114776611328, 'loss_4': 1.2452609539031982, 'epoch': 23.64}
{'loss': 0.0087, 'grad_norm': 4.57298469543457, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.0037975136656314135, 'loss_2': 0.00487518310546875, 'loss_3': -16.390785217285156, 'loss_4': 1.6599905490875244, 'epoch': 23.65}
{'loss': 0.0423, 'grad_norm': 22.13123321533203, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.04179994761943817, 'loss_2': 0.0004622936248779297, 'loss_3': -16.135316848754883, 'loss_4': 1.228752613067627, 'epoch': 23.65}
{'loss': 0.0073, 'grad_norm': 4.37893533706665, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.0043409476056694984, 'loss_2': 0.0029163360595703125, 'loss_3': -16.381423950195312, 'loss_4': 2.2454419136047363, 'epoch': 23.66}
{'loss': 0.0096, 'grad_norm': 4.330877304077148, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.007364957127720118, 'loss_2': 0.002262115478515625, 'loss_3': -16.35633087158203, 'loss_4': 1.7018084526062012, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 11:04:12,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:12,822 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:27<18:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:20,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008867066353559494, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00532488152384758, 'eval_loss_2': 0.003542184829711914, 'eval_loss_3': -18.200904846191406, 'eval_loss_4': 1.5053588151931763, 'epoch': 23.66}
{'loss': 0.0186, 'grad_norm': 5.13381290435791, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.009892807342112064, 'loss_2': 0.0087127685546875, 'loss_3': -16.43444061279297, 'loss_4': 1.501703143119812, 'epoch': 23.67}
{'loss': 0.0051, 'grad_norm': 4.6632080078125, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.0029412026051431894, 'loss_2': 0.00218963623046875, 'loss_3': -16.30633544921875, 'loss_4': 1.741344928741455, 'epoch': 23.67}
{'loss': 0.0073, 'grad_norm': 4.7111287117004395, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.005609473213553429, 'loss_2': 0.001720428466796875, 'loss_3': -16.370563507080078, 'loss_4': 1.0161197185516357, 'epoch': 23.68}
{'loss': 0.0105, 'grad_norm': 5.516473293304443, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.008120465092360973, 'loss_2': 0.0023403167724609375, 'loss_3': -16.110702514648438, 'loss_4': 1.2515817880630493, 'epoch': 23.69}
{'loss': 0.0093, 'grad_norm': 4.9075026512146, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.006521112285554409, 'loss_2': 0.002777099609375, 'loss_3': -16.26618194580078, 'loss_4': 1.091799259185791, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 11:04:20,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:20,168 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:34<18:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:27,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008840013295412064, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.724, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.004815865773707628, 'eval_loss_2': 0.004024147987365723, 'eval_loss_3': -18.205360412597656, 'eval_loss_4': 1.5638021230697632, 'epoch': 23.69}
{'loss': 0.005, 'grad_norm': 4.559854507446289, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.004286003299057484, 'loss_2': 0.0007486343383789062, 'loss_3': -16.35340118408203, 'loss_4': 1.316145658493042, 'epoch': 23.7}
{'loss': 0.0117, 'grad_norm': 4.837299346923828, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.0072039454244077206, 'loss_2': 0.004489898681640625, 'loss_3': -16.42291259765625, 'loss_4': 2.1821043491363525, 'epoch': 23.7}
{'loss': 0.0168, 'grad_norm': 6.794607162475586, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.012001479975879192, 'loss_2': 0.0048370361328125, 'loss_3': -16.273406982421875, 'loss_4': 1.451843023300171, 'epoch': 23.71}
{'loss': 0.0099, 'grad_norm': 4.531116962432861, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.0026625655591487885, 'loss_2': 0.00725555419921875, 'loss_3': -16.335128784179688, 'loss_4': 1.7006304264068604, 'epoch': 23.72}
{'loss': 0.0066, 'grad_norm': 4.704610824584961, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.0037452776450663805, 'loss_2': 0.0028743743896484375, 'loss_3': -16.513612747192383, 'loss_4': 1.3154785633087158, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 11:04:27,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:27,525 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:42<18:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:34,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009257144294679165, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.035, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0047865575179457664, 'eval_loss_2': 0.0044705867767333984, 'eval_loss_3': -18.20763397216797, 'eval_loss_4': 1.6553560495376587, 'epoch': 23.72}
{'loss': 0.0039, 'grad_norm': 4.902716636657715, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.0034331222996115685, 'loss_2': 0.0004987716674804688, 'loss_3': -16.17253875732422, 'loss_4': 1.9031368494033813, 'epoch': 23.73}
{'loss': 0.0073, 'grad_norm': 6.9483866691589355, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.007128454744815826, 'loss_2': 0.00021314620971679688, 'loss_3': -16.395444869995117, 'loss_4': 1.069444179534912, 'epoch': 23.73}
{'loss': 0.0204, 'grad_norm': 11.257486343383789, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.020328084006905556, 'loss_2': 6.699562072753906e-05, 'loss_3': -15.99958610534668, 'loss_4': 1.9973833560943604, 'epoch': 23.74}
{'loss': 0.0065, 'grad_norm': 4.305283069610596, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.004555478226393461, 'loss_2': 0.0019207000732421875, 'loss_3': -16.4919376373291, 'loss_4': 1.2348780632019043, 'epoch': 23.74}
{'loss': 0.0123, 'grad_norm': 4.667041301727295, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.005178804509341717, 'loss_2': 0.00713348388671875, 'loss_3': -16.29058265686035, 'loss_4': 1.7275769710540771, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 11:04:34,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:34,878 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:49<18:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:42,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009287470951676369, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0043942867778241634, 'eval_loss_2': 0.004893183708190918, 'eval_loss_3': -18.19654083251953, 'eval_loss_4': 1.6164075136184692, 'epoch': 23.75}
{'loss': 0.0062, 'grad_norm': 5.110571384429932, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.0047904932871460915, 'loss_2': 0.0014324188232421875, 'loss_3': -16.300098419189453, 'loss_4': 1.9641560316085815, 'epoch': 23.76}
{'loss': 0.0077, 'grad_norm': 4.945910930633545, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.005297705996781588, 'loss_2': 0.0023784637451171875, 'loss_3': -16.13894271850586, 'loss_4': 1.9335813522338867, 'epoch': 23.76}
{'loss': 0.0115, 'grad_norm': 6.041741371154785, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.008288347162306309, 'loss_2': 0.003246307373046875, 'loss_3': -16.385089874267578, 'loss_4': 1.242356300354004, 'epoch': 23.77}
{'loss': 0.0096, 'grad_norm': 4.508424282073975, 'learning_rate': 6.25e-06, 'loss_1': 0.0028048017993569374, 'loss_2': 0.00679779052734375, 'loss_3': -16.439706802368164, 'loss_4': 1.4160499572753906, 'epoch': 23.77}
{'loss': 0.0114, 'grad_norm': 6.554556846618652, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.008557559922337532, 'loss_2': 0.00286865234375, 'loss_3': -16.456745147705078, 'loss_4': 1.2609965801239014, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 11:04:42,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:42,231 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:56<18:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:49,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008374275639653206, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0045076776295900345, 'eval_loss_2': 0.0038665980100631714, 'eval_loss_3': -18.19937515258789, 'eval_loss_4': 1.5637116432189941, 'epoch': 23.78}
{'loss': 0.0113, 'grad_norm': 4.781515121459961, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.006880513392388821, 'loss_2': 0.00438690185546875, 'loss_3': -16.34762954711914, 'loss_4': 1.860764980316162, 'epoch': 23.78}
{'loss': 0.0043, 'grad_norm': 4.993849277496338, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.004103830084204674, 'loss_2': 0.000171661376953125, 'loss_3': -16.172048568725586, 'loss_4': 1.1931179761886597, 'epoch': 23.79}
{'loss': 0.0147, 'grad_norm': 4.627716541290283, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.005306081380695105, 'loss_2': 0.009368896484375, 'loss_3': -16.462467193603516, 'loss_4': 1.7580833435058594, 'epoch': 23.8}
{'loss': 0.0179, 'grad_norm': 8.273418426513672, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.013173805549740791, 'loss_2': 0.0047149658203125, 'loss_3': -16.409461975097656, 'loss_4': 1.5309207439422607, 'epoch': 23.8}
{'loss': 0.0099, 'grad_norm': 4.75150728225708, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.006688439287245274, 'loss_2': 0.003200531005859375, 'loss_3': -16.4384822845459, 'loss_4': 1.9109197854995728, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 11:04:49,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:49,583 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:04<18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:04:56,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008475659415125847, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004552481696009636, 'eval_loss_2': 0.003923177719116211, 'eval_loss_3': -18.203685760498047, 'eval_loss_4': 1.544314980506897, 'epoch': 23.81}
{'loss': 0.0131, 'grad_norm': 8.73774528503418, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.008491880260407925, 'loss_2': 0.004634857177734375, 'loss_3': -16.481922149658203, 'loss_4': 1.873753547668457, 'epoch': 23.81}
{'loss': 0.0056, 'grad_norm': 4.5685296058654785, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.0037170308642089367, 'loss_2': 0.0018377304077148438, 'loss_3': -16.44200325012207, 'loss_4': 0.7945794463157654, 'epoch': 23.82}
{'loss': 0.0067, 'grad_norm': 5.5336079597473145, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.0038108094595372677, 'loss_2': 0.002849578857421875, 'loss_3': -16.39596939086914, 'loss_4': 0.8823914527893066, 'epoch': 23.83}
{'loss': 0.0216, 'grad_norm': 9.713923454284668, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.013289069756865501, 'loss_2': 0.008331298828125, 'loss_3': -16.32180404663086, 'loss_4': 1.9427025318145752, 'epoch': 23.83}
{'loss': 0.0142, 'grad_norm': 5.209497451782227, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.004024863243103027, 'loss_2': 0.01020050048828125, 'loss_3': -16.376882553100586, 'loss_4': 1.7352209091186523, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 11:04:56,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:04:56,932 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:11<18:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:04,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008595352992415428, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.936, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004899120889604092, 'eval_loss_2': 0.003696233034133911, 'eval_loss_3': -18.208221435546875, 'eval_loss_4': 1.5074548721313477, 'epoch': 23.84}
{'loss': 0.0035, 'grad_norm': 4.711923599243164, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.0033613231498748064, 'loss_2': 0.0001277923583984375, 'loss_3': -16.439645767211914, 'loss_4': 0.9839062690734863, 'epoch': 23.84}
{'loss': 0.0058, 'grad_norm': 4.752086162567139, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.003955308347940445, 'loss_2': 0.0018310546875, 'loss_3': -16.413911819458008, 'loss_4': 1.3014947175979614, 'epoch': 23.85}
{'loss': 0.0076, 'grad_norm': 4.971970081329346, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.007511068135499954, 'loss_2': 0.00012123584747314453, 'loss_3': -16.115718841552734, 'loss_4': 1.7964746952056885, 'epoch': 23.85}
{'loss': 0.0039, 'grad_norm': 4.584695816040039, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.0031223520636558533, 'loss_2': 0.0007772445678710938, 'loss_3': -16.472585678100586, 'loss_4': 1.4264631271362305, 'epoch': 23.86}
{'loss': 0.007, 'grad_norm': 4.401644229888916, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.003827161155641079, 'loss_2': 0.0031890869140625, 'loss_3': -16.344812393188477, 'loss_4': 1.5652613639831543, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 11:05:04,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:04,286 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:18<18:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:11,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008173903450369835, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004795512184500694, 'eval_loss_2': 0.0033783912658691406, 'eval_loss_3': -18.201683044433594, 'eval_loss_4': 1.4885032176971436, 'epoch': 23.87}
{'loss': 0.0047, 'grad_norm': 4.627902030944824, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.004382350016385317, 'loss_2': 0.00033354759216308594, 'loss_3': -16.430524826049805, 'loss_4': 1.217598557472229, 'epoch': 23.87}
{'loss': 0.0084, 'grad_norm': 4.62019157409668, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.0050528449937701225, 'loss_2': 0.003387451171875, 'loss_3': -16.33716583251953, 'loss_4': 1.4753820896148682, 'epoch': 23.88}
{'loss': 0.004, 'grad_norm': 4.622003078460693, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.001954448176547885, 'loss_2': 0.00200653076171875, 'loss_3': -16.45033073425293, 'loss_4': 1.198047399520874, 'epoch': 23.88}
{'loss': 0.009, 'grad_norm': 5.772299766540527, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.008607177995145321, 'loss_2': 0.0003833770751953125, 'loss_3': -16.362075805664062, 'loss_4': 0.7167428135871887, 'epoch': 23.89}
{'loss': 0.007, 'grad_norm': 3.892803192138672, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.002613131422549486, 'loss_2': 0.00443267822265625, 'loss_3': -16.480133056640625, 'loss_4': 0.8136188983917236, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 11:05:11,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:11,636 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:26<18:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:18,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008026672527194023, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00471752742305398, 'eval_loss_2': 0.0033091455698013306, 'eval_loss_3': -18.208576202392578, 'eval_loss_4': 1.454206109046936, 'epoch': 23.9}
{'loss': 0.0213, 'grad_norm': 11.43715763092041, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.01916157267987728, 'loss_2': 0.002094268798828125, 'loss_3': -16.442184448242188, 'loss_4': 1.1185381412506104, 'epoch': 23.9}
{'loss': 0.006, 'grad_norm': 4.554619789123535, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.005096763838082552, 'loss_2': 0.0008764266967773438, 'loss_3': -16.282339096069336, 'loss_4': 0.753800094127655, 'epoch': 23.91}
{'loss': 0.008, 'grad_norm': 4.846807956695557, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.0027851457707583904, 'loss_2': 0.005229949951171875, 'loss_3': -16.554744720458984, 'loss_4': 1.4983253479003906, 'epoch': 23.91}
{'loss': 0.0116, 'grad_norm': 6.241543292999268, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.011287827976047993, 'loss_2': 0.00027751922607421875, 'loss_3': -16.439050674438477, 'loss_4': 1.0169858932495117, 'epoch': 23.92}
{'loss': 0.0098, 'grad_norm': 6.562001705169678, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.00902895350009203, 'loss_2': 0.000743865966796875, 'loss_3': -16.28052520751953, 'loss_4': 1.1509811878204346, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 11:05:18,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:18,988 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:33<17:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:26,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008276419714093208, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004754738416522741, 'eval_loss_2': 0.0035216808319091797, 'eval_loss_3': -18.218231201171875, 'eval_loss_4': 1.4066051244735718, 'epoch': 23.92}
{'loss': 0.0071, 'grad_norm': 6.66361141204834, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.004498519469052553, 'loss_2': 0.002651214599609375, 'loss_3': -16.197025299072266, 'loss_4': 1.7110605239868164, 'epoch': 23.93}
{'loss': 0.0074, 'grad_norm': 4.871786594390869, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.004856093320995569, 'loss_2': 0.002536773681640625, 'loss_3': -16.488277435302734, 'loss_4': 1.3658908605575562, 'epoch': 23.94}
{'loss': 0.0131, 'grad_norm': 4.861931324005127, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.009041722863912582, 'loss_2': 0.0040740966796875, 'loss_3': -16.402694702148438, 'loss_4': 1.2918190956115723, 'epoch': 23.94}
{'loss': 0.0132, 'grad_norm': 4.595547676086426, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.007706777658313513, 'loss_2': 0.0055389404296875, 'loss_3': -16.386873245239258, 'loss_4': 1.8191466331481934, 'epoch': 23.95}
{'loss': 0.0063, 'grad_norm': 5.097636699676514, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.0038484912365674973, 'loss_2': 0.0024890899658203125, 'loss_3': -16.302326202392578, 'loss_4': 0.970490574836731, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 11:05:26,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:26,338 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:40<17:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:33,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008092222735285759, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004740117117762566, 'eval_loss_2': 0.0033521056175231934, 'eval_loss_3': -18.216846466064453, 'eval_loss_4': 1.3507789373397827, 'epoch': 23.95}
{'loss': 0.0105, 'grad_norm': 5.468894958496094, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.005671544000506401, 'loss_2': 0.004791259765625, 'loss_3': -16.369930267333984, 'loss_4': 1.822124719619751, 'epoch': 23.96}
{'loss': 0.0165, 'grad_norm': 5.291412830352783, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.00779316620901227, 'loss_2': 0.00872039794921875, 'loss_3': -16.376976013183594, 'loss_4': 1.1589984893798828, 'epoch': 23.97}
{'loss': 0.0109, 'grad_norm': 4.7482709884643555, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.007824113592505455, 'loss_2': 0.003055572509765625, 'loss_3': -16.44589614868164, 'loss_4': 1.154287338256836, 'epoch': 23.97}
{'loss': 0.0084, 'grad_norm': 5.004758834838867, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.008306478150188923, 'loss_2': 0.00012004375457763672, 'loss_3': -16.44074249267578, 'loss_4': 0.8705494999885559, 'epoch': 23.98}
{'loss': 0.0065, 'grad_norm': 4.514315605163574, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.0037087970413267612, 'loss_2': 0.002780914306640625, 'loss_3': -16.278589248657227, 'loss_4': 1.0763747692108154, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 11:05:33,685 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:33,685 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:47<17:03,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 11:05:40,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008019053377211094, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.295, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004726283717900515, 'eval_loss_2': 0.003292769193649292, 'eval_loss_3': -18.224557876586914, 'eval_loss_4': 1.2666473388671875, 'epoch': 23.98}
{'loss': 0.0109, 'grad_norm': 4.6944379806518555, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.006036939565092325, 'loss_2': 0.004863739013671875, 'loss_3': -16.345630645751953, 'loss_4': 1.1428531408309937, 'epoch': 23.99}
{'loss': 0.0248, 'grad_norm': 11.086207389831543, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.021622849628329277, 'loss_2': 0.0031337738037109375, 'loss_3': -16.39799690246582, 'loss_4': 1.4468146562576294, 'epoch': 23.99}
{'loss': 0.0073, 'grad_norm': 5.5918803215026855, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.0017977386014536023, 'loss_2': 0.005535125732421875, 'loss_3': -16.493518829345703, 'loss_4': 1.23206627368927, 'epoch': 24.0}
{'loss': 0.0071, 'grad_norm': 5.162150859832764, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.006887733470648527, 'loss_2': 0.00019681453704833984, 'loss_3': -16.129131317138672, 'loss_4': 1.465047836303711, 'epoch': 24.01}
{'loss': 0.0029, 'grad_norm': 4.204736232757568, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.002517326269298792, 'loss_2': 0.0004286766052246094, 'loss_3': -16.360849380493164, 'loss_4': 1.467673420906067, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 11:05:40,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:40,713 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:55<17:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:05:48,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007528678048402071, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.328, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.004479885101318359, 'eval_loss_2': 0.0030487924814224243, 'eval_loss_3': -18.22879409790039, 'eval_loss_4': 1.249938726425171, 'epoch': 24.01}
{'loss': 0.0151, 'grad_norm': 11.23159408569336, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.014199492521584034, 'loss_2': 0.0008945465087890625, 'loss_3': -16.305784225463867, 'loss_4': 1.5913814306259155, 'epoch': 24.02}
{'loss': 0.0305, 'grad_norm': 10.775928497314453, 'learning_rate': 6e-06, 'loss_1': 0.0300456490367651, 'loss_2': 0.0004506111145019531, 'loss_3': -16.6420955657959, 'loss_4': 0.8291215896606445, 'epoch': 24.02}
{'loss': 0.0097, 'grad_norm': 5.1562418937683105, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.007460379507392645, 'loss_2': 0.0022029876708984375, 'loss_3': -16.57619857788086, 'loss_4': 1.0635592937469482, 'epoch': 24.03}
{'loss': 0.0265, 'grad_norm': 10.115623474121094, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.024288440123200417, 'loss_2': 0.00223541259765625, 'loss_3': -16.6552734375, 'loss_4': 1.210557222366333, 'epoch': 24.03}
{'loss': 0.0094, 'grad_norm': 5.182868003845215, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.007369727827608585, 'loss_2': 0.0020294189453125, 'loss_3': -16.28274917602539, 'loss_4': 0.6875721216201782, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 11:05:48,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:48,084 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:42:02<17:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:05:55,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007641437463462353, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.362, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004693467170000076, 'eval_loss_2': 0.002947971224784851, 'eval_loss_3': -18.219533920288086, 'eval_loss_4': 1.3254902362823486, 'epoch': 24.04}
{'loss': 0.0061, 'grad_norm': 4.7812604904174805, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.005548686720430851, 'loss_2': 0.0005984306335449219, 'loss_3': -16.32621955871582, 'loss_4': 0.8673692941665649, 'epoch': 24.05}
{'loss': 0.0076, 'grad_norm': 5.2671403884887695, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.007481619715690613, 'loss_2': 0.00012350082397460938, 'loss_3': -16.275732040405273, 'loss_4': 1.3396210670471191, 'epoch': 24.05}
{'loss': 0.0041, 'grad_norm': 4.421157360076904, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.00399879552423954, 'loss_2': 0.00010633468627929688, 'loss_3': -16.35824203491211, 'loss_4': 1.1450490951538086, 'epoch': 24.06}
{'loss': 0.0092, 'grad_norm': 4.26777458190918, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.006645755376666784, 'loss_2': 0.002590179443359375, 'loss_3': -16.35595703125, 'loss_4': 1.1836025714874268, 'epoch': 24.06}
{'loss': 0.0153, 'grad_norm': 5.309735298156738, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.011176584288477898, 'loss_2': 0.0041046142578125, 'loss_3': -16.177078247070312, 'loss_4': 1.297080159187317, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 11:05:55,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:05:55,433 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:09<17:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:02,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007602545898407698, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004451039247214794, 'eval_loss_2': 0.003151506185531616, 'eval_loss_3': -18.216054916381836, 'eval_loss_4': 1.4226388931274414, 'epoch': 24.07}
{'loss': 0.0076, 'grad_norm': 4.293187141418457, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.003742367494851351, 'loss_2': 0.0038204193115234375, 'loss_3': -16.489206314086914, 'loss_4': 1.1837579011917114, 'epoch': 24.08}
{'loss': 0.0191, 'grad_norm': 5.158506870269775, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.00840599276125431, 'loss_2': 0.0107421875, 'loss_3': -16.214191436767578, 'loss_4': 0.567100465297699, 'epoch': 24.08}
{'loss': 0.0119, 'grad_norm': 5.216349124908447, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.0078261224552989, 'loss_2': 0.00409698486328125, 'loss_3': -16.29330062866211, 'loss_4': 1.1224757432937622, 'epoch': 24.09}
{'loss': 0.0067, 'grad_norm': 4.337784767150879, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.003751415992155671, 'loss_2': 0.002933502197265625, 'loss_3': -16.43253517150879, 'loss_4': 1.373550295829773, 'epoch': 24.09}
{'loss': 0.007, 'grad_norm': 4.780293941497803, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.005057032685726881, 'loss_2': 0.001911163330078125, 'loss_3': -16.255083084106445, 'loss_4': 1.3589372634887695, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 11:06:02,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:02,781 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:17<17:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:10,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007871424779295921, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.118, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004454946145415306, 'eval_loss_2': 0.0034164786338806152, 'eval_loss_3': -18.21988868713379, 'eval_loss_4': 1.5159188508987427, 'epoch': 24.1}
{'loss': 0.0117, 'grad_norm': 5.223349094390869, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.0061871642246842384, 'loss_2': 0.0054931640625, 'loss_3': -16.31277084350586, 'loss_4': 1.1891429424285889, 'epoch': 24.1}
{'loss': 0.0166, 'grad_norm': 5.414753437042236, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.01127871498465538, 'loss_2': 0.00530242919921875, 'loss_3': -16.263473510742188, 'loss_4': 1.4480396509170532, 'epoch': 24.11}
{'loss': 0.0084, 'grad_norm': 5.2208943367004395, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.007509278133511543, 'loss_2': 0.0009207725524902344, 'loss_3': -16.280529022216797, 'loss_4': 1.6260098218917847, 'epoch': 24.12}
{'loss': 0.0078, 'grad_norm': 4.868074417114258, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.006822554394602776, 'loss_2': 0.001026153564453125, 'loss_3': -16.528308868408203, 'loss_4': 1.9837796688079834, 'epoch': 24.12}
{'loss': 0.0089, 'grad_norm': 5.099374294281006, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.007910619489848614, 'loss_2': 0.0010271072387695312, 'loss_3': -16.43581771850586, 'loss_4': 1.0225309133529663, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 11:06:10,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:10,132 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:24<17:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:17,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007802409119904041, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.357, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004344950895756483, 'eval_loss_2': 0.0034574568271636963, 'eval_loss_3': -18.223222732543945, 'eval_loss_4': 1.6013092994689941, 'epoch': 24.13}
{'loss': 0.0098, 'grad_norm': 4.9297943115234375, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.007796484511345625, 'loss_2': 0.0019683837890625, 'loss_3': -16.354751586914062, 'loss_4': 1.2831798791885376, 'epoch': 24.13}
{'loss': 0.0064, 'grad_norm': 4.658810138702393, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.006119241937994957, 'loss_2': 0.0003039836883544922, 'loss_3': -16.465919494628906, 'loss_4': 1.5911376476287842, 'epoch': 24.14}
{'loss': 0.0129, 'grad_norm': 5.4407639503479, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.006371053867042065, 'loss_2': 0.00650787353515625, 'loss_3': -16.261180877685547, 'loss_4': 1.9180041551589966, 'epoch': 24.15}
{'loss': 0.005, 'grad_norm': 4.3664727210998535, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.002864600159227848, 'loss_2': 0.002124786376953125, 'loss_3': -16.417922973632812, 'loss_4': 2.4599266052246094, 'epoch': 24.15}
{'loss': 0.0429, 'grad_norm': 14.337791442871094, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.039192259311676025, 'loss_2': 0.0037384033203125, 'loss_3': -16.280452728271484, 'loss_4': 1.652491807937622, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 11:06:17,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:17,482 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:32<17:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:24,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860874354839325, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.531, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.004606530070304871, 'eval_loss_2': 0.004002213478088379, 'eval_loss_3': -18.233333587646484, 'eval_loss_4': 1.6477689743041992, 'epoch': 24.16}
{'loss': 0.0091, 'grad_norm': 4.031627178192139, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.004721055272966623, 'loss_2': 0.004344940185546875, 'loss_3': -16.483030319213867, 'loss_4': 1.4822440147399902, 'epoch': 24.16}
{'loss': 0.0075, 'grad_norm': 4.5051751136779785, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.0025822706520557404, 'loss_2': 0.004955291748046875, 'loss_3': -16.552879333496094, 'loss_4': 1.8006553649902344, 'epoch': 24.17}
{'loss': 0.0123, 'grad_norm': 4.7965922355651855, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.006736980751156807, 'loss_2': 0.005584716796875, 'loss_3': -16.430749893188477, 'loss_4': 1.4734725952148438, 'epoch': 24.17}
{'loss': 0.0083, 'grad_norm': 5.9953227043151855, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.007838742807507515, 'loss_2': 0.00041747093200683594, 'loss_3': -16.227127075195312, 'loss_4': 2.011061191558838, 'epoch': 24.18}
{'loss': 0.008, 'grad_norm': 4.983429908752441, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.007162136025726795, 'loss_2': 0.00081634521484375, 'loss_3': -16.199398040771484, 'loss_4': 1.8975239992141724, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 11:06:24,842 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:24,842 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:39<17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:32,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008396306075155735, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.618, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004508503247052431, 'eval_loss_2': 0.0038878023624420166, 'eval_loss_3': -18.2408504486084, 'eval_loss_4': 1.6158963441848755, 'epoch': 24.19}
{'loss': 0.0091, 'grad_norm': 5.566741466522217, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.008591040037572384, 'loss_2': 0.0005202293395996094, 'loss_3': -16.525680541992188, 'loss_4': 0.6010881662368774, 'epoch': 24.19}
{'loss': 0.0135, 'grad_norm': 9.078140258789062, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.011285879649221897, 'loss_2': 0.0022182464599609375, 'loss_3': -16.537425994873047, 'loss_4': 1.566314697265625, 'epoch': 24.2}
{'loss': 0.0034, 'grad_norm': 5.156264781951904, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.0025445029605180025, 'loss_2': 0.000904083251953125, 'loss_3': -16.362548828125, 'loss_4': 1.1725085973739624, 'epoch': 24.2}
{'loss': 0.0118, 'grad_norm': 5.18558406829834, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.006112400442361832, 'loss_2': 0.005706787109375, 'loss_3': -16.238365173339844, 'loss_4': 1.9117974042892456, 'epoch': 24.21}
{'loss': 0.016, 'grad_norm': 5.847395896911621, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.013894880190491676, 'loss_2': 0.002071380615234375, 'loss_3': -16.473491668701172, 'loss_4': 2.0485475063323975, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 11:06:32,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:32,203 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:46<17:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:39,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008075060322880745, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004673482850193977, 'eval_loss_2': 0.0034015774726867676, 'eval_loss_3': -18.252727508544922, 'eval_loss_4': 1.6075680255889893, 'epoch': 24.22}
{'loss': 0.0103, 'grad_norm': 6.043265342712402, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.009005224332213402, 'loss_2': 0.0013151168823242188, 'loss_3': -16.490232467651367, 'loss_4': 1.4041768312454224, 'epoch': 24.22}
{'loss': 0.0136, 'grad_norm': 5.368982315063477, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.009528405964374542, 'loss_2': 0.00411224365234375, 'loss_3': -16.489234924316406, 'loss_4': 1.7147831916809082, 'epoch': 24.23}
{'loss': 0.0058, 'grad_norm': 4.559850215911865, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.002566408831626177, 'loss_2': 0.003253936767578125, 'loss_3': -16.474123001098633, 'loss_4': 1.524542212486267, 'epoch': 24.23}
{'loss': 0.0134, 'grad_norm': 5.109731674194336, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.009535755962133408, 'loss_2': 0.00385284423828125, 'loss_3': -16.271564483642578, 'loss_4': 1.2285058498382568, 'epoch': 24.24}
{'loss': 0.0105, 'grad_norm': 5.481645107269287, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.008457320742309093, 'loss_2': 0.0020046234130859375, 'loss_3': -16.36562728881836, 'loss_4': 1.6763012409210205, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 11:06:39,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:39,559 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:54<17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:46,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00839364156126976, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.227, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004942540545016527, 'eval_loss_2': 0.0034511014819145203, 'eval_loss_3': -18.259078979492188, 'eval_loss_4': 1.584129810333252, 'epoch': 24.24}
{'loss': 0.0048, 'grad_norm': 4.626843452453613, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.004261082503944635, 'loss_2': 0.0005550384521484375, 'loss_3': -16.28144645690918, 'loss_4': 1.6513783931732178, 'epoch': 24.25}
{'loss': 0.0022, 'grad_norm': 4.615622520446777, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.0020383382216095924, 'loss_2': 0.00013136863708496094, 'loss_3': -16.505552291870117, 'loss_4': 1.6451690196990967, 'epoch': 24.26}
{'loss': 0.0127, 'grad_norm': 5.164623260498047, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.005361275747418404, 'loss_2': 0.007358551025390625, 'loss_3': -16.38584327697754, 'loss_4': 1.38454008102417, 'epoch': 24.26}
{'loss': 0.0047, 'grad_norm': 4.226728916168213, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.0023841229267418385, 'loss_2': 0.0023174285888671875, 'loss_3': -16.546546936035156, 'loss_4': 1.668837070465088, 'epoch': 24.27}
{'loss': 0.0105, 'grad_norm': 4.8937249183654785, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.005609799176454544, 'loss_2': 0.0049285888671875, 'loss_3': -16.19191551208496, 'loss_4': 1.91884183883667, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 11:06:46,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:46,908 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:43:01<16:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:06:54,256 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008715779520571232, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.949, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005273760762065649, 'eval_loss_2': 0.00344201922416687, 'eval_loss_3': -18.248167037963867, 'eval_loss_4': 1.6233012676239014, 'epoch': 24.27}
{'loss': 0.0074, 'grad_norm': 5.094120025634766, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.004582223016768694, 'loss_2': 0.0028553009033203125, 'loss_3': -16.204448699951172, 'loss_4': 1.651190996170044, 'epoch': 24.28}
{'loss': 0.0143, 'grad_norm': 6.2447309494018555, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.011451245285570621, 'loss_2': 0.00286865234375, 'loss_3': -16.361421585083008, 'loss_4': 1.2998669147491455, 'epoch': 24.28}
{'loss': 0.0184, 'grad_norm': 6.064187526702881, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.009837508201599121, 'loss_2': 0.008575439453125, 'loss_3': -16.295032501220703, 'loss_4': 1.5389196872711182, 'epoch': 24.29}
{'loss': 0.0065, 'grad_norm': 4.587127208709717, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.005170570220798254, 'loss_2': 0.0013751983642578125, 'loss_3': -16.433292388916016, 'loss_4': 2.459817409515381, 'epoch': 24.3}
{'loss': 0.0112, 'grad_norm': 5.215848445892334, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.009493081830441952, 'loss_2': 0.00170135498046875, 'loss_3': -16.314218521118164, 'loss_4': 1.2466905117034912, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 11:06:54,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:06:54,256 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:08<16:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:01,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008971353992819786, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005733223631978035, 'eval_loss_2': 0.003238130360841751, 'eval_loss_3': -18.240367889404297, 'eval_loss_4': 1.681945562362671, 'epoch': 24.3}
{'loss': 0.0054, 'grad_norm': 4.529601573944092, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.004515009466558695, 'loss_2': 0.0008645057678222656, 'loss_3': -16.32823371887207, 'loss_4': 2.0718297958374023, 'epoch': 24.31}
{'loss': 0.0091, 'grad_norm': 4.457289218902588, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.004390997812151909, 'loss_2': 0.0047454833984375, 'loss_3': -16.38265609741211, 'loss_4': 1.7835203409194946, 'epoch': 24.31}
{'loss': 0.0105, 'grad_norm': 6.8909478187561035, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.009760803543031216, 'loss_2': 0.0007658004760742188, 'loss_3': -16.349775314331055, 'loss_4': 1.1859188079833984, 'epoch': 24.32}
{'loss': 0.0076, 'grad_norm': 5.3365936279296875, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.0053204502910375595, 'loss_2': 0.002254486083984375, 'loss_3': -16.315185546875, 'loss_4': 1.2643427848815918, 'epoch': 24.33}
{'loss': 0.0129, 'grad_norm': 4.815278053283691, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.007003285456448793, 'loss_2': 0.00585174560546875, 'loss_3': -16.325136184692383, 'loss_4': 1.7890541553497314, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 11:07:01,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:01,602 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:16<16:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:08,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008759493008255959, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.567, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005884373094886541, 'eval_loss_2': 0.00287511944770813, 'eval_loss_3': -18.23180389404297, 'eval_loss_4': 1.7195298671722412, 'epoch': 24.33}
{'loss': 0.0045, 'grad_norm': 5.0530290603637695, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.004073715768754482, 'loss_2': 0.000461578369140625, 'loss_3': -16.404787063598633, 'loss_4': 2.3023078441619873, 'epoch': 24.34}
{'loss': 0.0117, 'grad_norm': 5.988002777099609, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.00814564898610115, 'loss_2': 0.003566741943359375, 'loss_3': -16.359956741333008, 'loss_4': 1.588584542274475, 'epoch': 24.34}
{'loss': 0.0212, 'grad_norm': 5.381377220153809, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.01794917695224285, 'loss_2': 0.0032520294189453125, 'loss_3': -16.243967056274414, 'loss_4': 1.3974485397338867, 'epoch': 24.35}
{'loss': 0.0088, 'grad_norm': 4.366870403289795, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.003405997296795249, 'loss_2': 0.00536346435546875, 'loss_3': -16.440052032470703, 'loss_4': 2.1681900024414062, 'epoch': 24.35}
{'loss': 0.0122, 'grad_norm': 6.272524833679199, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.010500822216272354, 'loss_2': 0.0016508102416992188, 'loss_3': -16.283641815185547, 'loss_4': 1.5851547718048096, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 11:07:08,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:08,966 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:23<17:09,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 11:07:16,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00840260274708271, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005639808252453804, 'eval_loss_2': 0.0027627944946289062, 'eval_loss_3': -18.214387893676758, 'eval_loss_4': 1.750331163406372, 'epoch': 24.36}
{'loss': 0.0063, 'grad_norm': 4.39497184753418, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.004044368397444487, 'loss_2': 0.0022125244140625, 'loss_3': -16.304187774658203, 'loss_4': 1.4683163166046143, 'epoch': 24.37}
{'loss': 0.0038, 'grad_norm': 4.500768184661865, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.0037719612009823322, 'loss_2': 4.9114227294921875e-05, 'loss_3': -16.262840270996094, 'loss_4': 1.2286403179168701, 'epoch': 24.37}
{'loss': 0.0327, 'grad_norm': 11.078025817871094, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.024613186717033386, 'loss_2': 0.008087158203125, 'loss_3': -16.498329162597656, 'loss_4': 1.9570574760437012, 'epoch': 24.38}
{'loss': 0.0204, 'grad_norm': 8.132121086120605, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.014670781791210175, 'loss_2': 0.005695343017578125, 'loss_3': -16.57501792907715, 'loss_4': 2.38826322555542, 'epoch': 24.38}
{'loss': 0.0092, 'grad_norm': 6.076211929321289, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.007160985376685858, 'loss_2': 0.0020389556884765625, 'loss_3': -16.319496154785156, 'loss_4': 1.0174837112426758, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 11:07:16,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:16,512 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:31<16:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:23,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00929558277130127, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005912004970014095, 'eval_loss_2': 0.0033835768699645996, 'eval_loss_3': -18.210702896118164, 'eval_loss_4': 1.7933130264282227, 'epoch': 24.39}
{'loss': 0.0044, 'grad_norm': 4.9523162841796875, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0031839092262089252, 'loss_2': 0.001209259033203125, 'loss_3': -16.380416870117188, 'loss_4': 2.0686545372009277, 'epoch': 24.4}
{'loss': 0.0075, 'grad_norm': 4.5632734298706055, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.00483587896451354, 'loss_2': 0.0026702880859375, 'loss_3': -16.319875717163086, 'loss_4': 1.5386879444122314, 'epoch': 24.4}
{'loss': 0.0063, 'grad_norm': 5.2763991355896, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.004838848020881414, 'loss_2': 0.00141143798828125, 'loss_3': -16.316375732421875, 'loss_4': 1.2360692024230957, 'epoch': 24.41}
{'loss': 0.009, 'grad_norm': 5.186985492706299, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.0073088956996798515, 'loss_2': 0.001674652099609375, 'loss_3': -16.395050048828125, 'loss_4': 1.7437680959701538, 'epoch': 24.41}
{'loss': 0.013, 'grad_norm': 6.480252265930176, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.01288396492600441, 'loss_2': 9.98377799987793e-05, 'loss_3': -16.241779327392578, 'loss_4': 1.6158989667892456, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 11:07:23,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:23,867 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:38<16:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:31,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009319212287664413, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006049688905477524, 'eval_loss_2': 0.0032695233821868896, 'eval_loss_3': -18.205488204956055, 'eval_loss_4': 1.7684962749481201, 'epoch': 24.42}
{'loss': 0.0085, 'grad_norm': 4.654543876647949, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.007915561087429523, 'loss_2': 0.0005893707275390625, 'loss_3': -16.487489700317383, 'loss_4': 2.0186991691589355, 'epoch': 24.42}
{'loss': 0.0136, 'grad_norm': 6.245265960693359, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.01195853017270565, 'loss_2': 0.0016345977783203125, 'loss_3': -16.342805862426758, 'loss_4': 1.272700548171997, 'epoch': 24.43}
{'loss': 0.0142, 'grad_norm': 5.8710761070251465, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.006993969436734915, 'loss_2': 0.007221221923828125, 'loss_3': -16.141502380371094, 'loss_4': 1.2567801475524902, 'epoch': 24.44}
{'loss': 0.0044, 'grad_norm': 4.388409614562988, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.0029824806842952967, 'loss_2': 0.001407623291015625, 'loss_3': -16.339759826660156, 'loss_4': 2.1220009326934814, 'epoch': 24.44}
{'loss': 0.028, 'grad_norm': 13.563363075256348, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.026387199759483337, 'loss_2': 0.0015773773193359375, 'loss_3': -16.247648239135742, 'loss_4': 1.5735077857971191, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 11:07:31,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:31,221 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:45<16:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:38,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0098807318136096, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0055515277199447155, 'eval_loss_2': 0.004329204559326172, 'eval_loss_3': -18.20895004272461, 'eval_loss_4': 1.7674185037612915, 'epoch': 24.45}
{'loss': 0.0066, 'grad_norm': 5.380690097808838, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.005758210085332394, 'loss_2': 0.0008139610290527344, 'loss_3': -16.20497703552246, 'loss_4': 1.3973207473754883, 'epoch': 24.45}
{'loss': 0.0151, 'grad_norm': 5.866860389709473, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.008048392832279205, 'loss_2': 0.00708770751953125, 'loss_3': -16.393295288085938, 'loss_4': 1.3878636360168457, 'epoch': 24.46}
{'loss': 0.0088, 'grad_norm': 4.581679821014404, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.004449254367500544, 'loss_2': 0.00433349609375, 'loss_3': -16.464370727539062, 'loss_4': 1.7056159973144531, 'epoch': 24.47}
{'loss': 0.0079, 'grad_norm': 5.181457042694092, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.006814563646912575, 'loss_2': 0.0011081695556640625, 'loss_3': -16.42923927307129, 'loss_4': 1.4554216861724854, 'epoch': 24.47}
{'loss': 0.0075, 'grad_norm': 4.469163417816162, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.004254788160324097, 'loss_2': 0.0032196044921875, 'loss_3': -16.372282028198242, 'loss_4': 2.0241243839263916, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 11:07:38,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:38,580 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:53<16:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:45,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009678374975919724, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.825, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005501073319464922, 'eval_loss_2': 0.004177302122116089, 'eval_loss_3': -18.208494186401367, 'eval_loss_4': 1.7605855464935303, 'epoch': 24.48}
{'loss': 0.0121, 'grad_norm': 6.88094425201416, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.006836303509771824, 'loss_2': 0.005279541015625, 'loss_3': -16.43480110168457, 'loss_4': 1.100701093673706, 'epoch': 24.48}
{'loss': 0.0207, 'grad_norm': 7.521603107452393, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.0182954128831625, 'loss_2': 0.0024013519287109375, 'loss_3': -16.40888786315918, 'loss_4': 1.3558342456817627, 'epoch': 24.49}
{'loss': 0.005, 'grad_norm': 4.640448570251465, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.002649220172315836, 'loss_2': 0.002307891845703125, 'loss_3': -16.415313720703125, 'loss_4': 1.975325107574463, 'epoch': 24.49}
{'loss': 0.0132, 'grad_norm': 5.154444694519043, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.005802714265882969, 'loss_2': 0.007366180419921875, 'loss_3': -16.468414306640625, 'loss_4': 1.5201053619384766, 'epoch': 24.5}
{'loss': 0.0099, 'grad_norm': 4.096372604370117, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.004746554885059595, 'loss_2': 0.00510406494140625, 'loss_3': -16.53992462158203, 'loss_4': 1.8751447200775146, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 11:07:45,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:45,934 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:44:00<16:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:07:53,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009812776930630207, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005738075822591782, 'eval_loss_2': 0.004074700176715851, 'eval_loss_3': -18.21411895751953, 'eval_loss_4': 1.6898635625839233, 'epoch': 24.51}
{'loss': 0.0141, 'grad_norm': 7.084618091583252, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.01083193439990282, 'loss_2': 0.00323486328125, 'loss_3': -16.400066375732422, 'loss_4': 1.6836854219436646, 'epoch': 24.51}
{'loss': 0.0059, 'grad_norm': 5.233109474182129, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.004436991177499294, 'loss_2': 0.0014190673828125, 'loss_3': -16.147781372070312, 'loss_4': 1.87428879737854, 'epoch': 24.52}
{'loss': 0.0104, 'grad_norm': 4.652284622192383, 'learning_rate': 5.5e-06, 'loss_1': 0.0058537679724395275, 'loss_2': 0.004566192626953125, 'loss_3': -16.346641540527344, 'loss_4': 1.9826202392578125, 'epoch': 24.52}
{'loss': 0.0855, 'grad_norm': 14.482587814331055, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.08443352580070496, 'loss_2': 0.00102996826171875, 'loss_3': -16.327804565429688, 'loss_4': 1.8774579763412476, 'epoch': 24.53}
{'loss': 0.0027, 'grad_norm': 4.441543102264404, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.002609811956062913, 'loss_2': 0.0001232624053955078, 'loss_3': -16.295379638671875, 'loss_4': 2.1140573024749756, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 11:07:53,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:07:53,295 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:07<16:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:00,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00974983349442482, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.31, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005693975370377302, 'eval_loss_2': 0.0040558576583862305, 'eval_loss_3': -18.219350814819336, 'eval_loss_4': 1.6616178750991821, 'epoch': 24.53}
{'loss': 0.0139, 'grad_norm': 5.212948799133301, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.01069549098610878, 'loss_2': 0.0032444000244140625, 'loss_3': -16.353164672851562, 'loss_4': 1.2235844135284424, 'epoch': 24.54}
{'loss': 0.0179, 'grad_norm': 7.916763782501221, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.015734443441033363, 'loss_2': 0.002178192138671875, 'loss_3': -16.51511573791504, 'loss_4': 1.5764672756195068, 'epoch': 24.55}
{'loss': 0.0231, 'grad_norm': 9.998119354248047, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.015895312651991844, 'loss_2': 0.00717926025390625, 'loss_3': -16.03542709350586, 'loss_4': 2.2513937950134277, 'epoch': 24.55}
{'loss': 0.0162, 'grad_norm': 6.441135406494141, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.010178632102906704, 'loss_2': 0.0060272216796875, 'loss_3': -16.397912979125977, 'loss_4': 0.7001219987869263, 'epoch': 24.56}
{'loss': 0.008, 'grad_norm': 5.521604537963867, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.00798084307461977, 'loss_2': 2.1338462829589844e-05, 'loss_3': -16.202428817749023, 'loss_4': 2.294008493423462, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 11:08:00,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:00,647 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:15<16:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:07,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00997411459684372, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.237, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006138487718999386, 'eval_loss_2': 0.003835625946521759, 'eval_loss_3': -18.21918296813965, 'eval_loss_4': 1.6758710145950317, 'epoch': 24.56}
{'loss': 0.009, 'grad_norm': 6.093621253967285, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.008211624808609486, 'loss_2': 0.0007495880126953125, 'loss_3': -16.390819549560547, 'loss_4': 1.118532657623291, 'epoch': 24.57}
{'loss': 0.007, 'grad_norm': 4.903148651123047, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.004871077369898558, 'loss_2': 0.0021038055419921875, 'loss_3': -16.438034057617188, 'loss_4': 1.8365681171417236, 'epoch': 24.58}
{'loss': 0.0128, 'grad_norm': 5.155012607574463, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.007183816749602556, 'loss_2': 0.005615234375, 'loss_3': -16.247909545898438, 'loss_4': 1.4318289756774902, 'epoch': 24.58}
{'loss': 0.0075, 'grad_norm': 5.130012512207031, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.006189099047333002, 'loss_2': 0.0013523101806640625, 'loss_3': -16.266712188720703, 'loss_4': 1.2048277854919434, 'epoch': 24.59}
{'loss': 0.0178, 'grad_norm': 13.661482810974121, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.014104807749390602, 'loss_2': 0.003711700439453125, 'loss_3': -16.373064041137695, 'loss_4': 1.5768858194351196, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 11:08:07,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:07,992 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:22<16:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:15,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010548291727900505, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.184, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006245763041079044, 'eval_loss_2': 0.004302527755498886, 'eval_loss_3': -18.216230392456055, 'eval_loss_4': 1.7649133205413818, 'epoch': 24.59}
{'loss': 0.0068, 'grad_norm': 5.219631195068359, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.004903868772089481, 'loss_2': 0.0018596649169921875, 'loss_3': -16.266956329345703, 'loss_4': 1.7696292400360107, 'epoch': 24.6}
{'loss': 0.0054, 'grad_norm': 4.9429497718811035, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.0037733695935457945, 'loss_2': 0.0016231536865234375, 'loss_3': -16.590652465820312, 'loss_4': 1.4283337593078613, 'epoch': 24.6}
{'loss': 0.0146, 'grad_norm': 5.4097208976745605, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.00478483596816659, 'loss_2': 0.0098114013671875, 'loss_3': -16.320133209228516, 'loss_4': 1.509950876235962, 'epoch': 24.61}
{'loss': 0.0218, 'grad_norm': 13.433956146240234, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.018848001956939697, 'loss_2': 0.0029754638671875, 'loss_3': -16.178312301635742, 'loss_4': 1.9304916858673096, 'epoch': 24.62}
{'loss': 0.0086, 'grad_norm': 4.6451592445373535, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.004225338809192181, 'loss_2': 0.00437164306640625, 'loss_3': -16.332504272460938, 'loss_4': 1.6314897537231445, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 11:08:15,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:15,346 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:29<15:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:22,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010569741949439049, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.06, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00592141505330801, 'eval_loss_2': 0.004648327827453613, 'eval_loss_3': -18.222877502441406, 'eval_loss_4': 1.8076889514923096, 'epoch': 24.62}
{'loss': 0.0153, 'grad_norm': 6.6646623611450195, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.013130431063473225, 'loss_2': 0.002178192138671875, 'loss_3': -16.421974182128906, 'loss_4': 1.7548408508300781, 'epoch': 24.63}
{'loss': 0.0089, 'grad_norm': 4.447521686553955, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.003223581239581108, 'loss_2': 0.005649566650390625, 'loss_3': -16.396493911743164, 'loss_4': 2.7827329635620117, 'epoch': 24.63}
{'loss': 0.0067, 'grad_norm': 4.91646671295166, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.004451413173228502, 'loss_2': 0.002239227294921875, 'loss_3': -16.287567138671875, 'loss_4': 2.0205984115600586, 'epoch': 24.64}
{'loss': 0.0204, 'grad_norm': 10.842026710510254, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.019383253529667854, 'loss_2': 0.00098419189453125, 'loss_3': -16.387645721435547, 'loss_4': 1.9024044275283813, 'epoch': 24.65}
{'loss': 0.0092, 'grad_norm': 6.570328235626221, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.008243654854595661, 'loss_2': 0.00099945068359375, 'loss_3': -16.421245574951172, 'loss_4': 2.140690803527832, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 11:08:22,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:22,698 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:37<15:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:30,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009451370686292648, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.624, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005837913602590561, 'eval_loss_2': 0.0036134570837020874, 'eval_loss_3': -18.240928649902344, 'eval_loss_4': 1.823530673980713, 'epoch': 24.65}
{'loss': 0.0039, 'grad_norm': 4.490679740905762, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.003792849136516452, 'loss_2': 0.00013709068298339844, 'loss_3': -16.452220916748047, 'loss_4': 1.414390206336975, 'epoch': 24.66}
{'loss': 0.0089, 'grad_norm': 4.538033485412598, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.004503216594457626, 'loss_2': 0.004375457763671875, 'loss_3': -16.432586669921875, 'loss_4': 2.1824791431427, 'epoch': 24.66}
{'loss': 0.0118, 'grad_norm': 5.127411365509033, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.006887528579682112, 'loss_2': 0.0048980712890625, 'loss_3': -16.368366241455078, 'loss_4': 1.883052945137024, 'epoch': 24.67}
{'loss': 0.0133, 'grad_norm': 7.022561073303223, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.00567381689324975, 'loss_2': 0.00766754150390625, 'loss_3': -16.40170669555664, 'loss_4': 1.3128567934036255, 'epoch': 24.67}
{'loss': 0.0083, 'grad_norm': 4.885758876800537, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.006073679309338331, 'loss_2': 0.002246856689453125, 'loss_3': -16.4920597076416, 'loss_4': 1.2227189540863037, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 11:08:30,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:30,052 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:44<15:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:37,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009667433798313141, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.321, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006142019759863615, 'eval_loss_2': 0.0035254135727882385, 'eval_loss_3': -18.237367630004883, 'eval_loss_4': 1.7856440544128418, 'epoch': 24.68}
{'loss': 0.0114, 'grad_norm': 8.083246231079102, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.010320800356566906, 'loss_2': 0.0010461807250976562, 'loss_3': -16.442838668823242, 'loss_4': 1.6233925819396973, 'epoch': 24.69}
{'loss': 0.0059, 'grad_norm': 5.80201530456543, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.005644199438393116, 'loss_2': 0.0002486705780029297, 'loss_3': -16.484201431274414, 'loss_4': 1.8622077703475952, 'epoch': 24.69}
{'loss': 0.0076, 'grad_norm': 4.670868396759033, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.00527258450165391, 'loss_2': 0.002292633056640625, 'loss_3': -16.417816162109375, 'loss_4': 1.3045761585235596, 'epoch': 24.7}
{'loss': 0.0106, 'grad_norm': 4.90582799911499, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.0062227146700024605, 'loss_2': 0.00439453125, 'loss_3': -16.31269073486328, 'loss_4': 1.8769804239273071, 'epoch': 24.7}
{'loss': 0.0085, 'grad_norm': 5.569824695587158, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.00846159178763628, 'loss_2': 6.204843521118164e-05, 'loss_3': -16.325485229492188, 'loss_4': 2.1128249168395996, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 11:08:37,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:37,397 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:51<15:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:44,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009780381806194782, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.333, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006063718814402819, 'eval_loss_2': 0.0037166625261306763, 'eval_loss_3': -18.235244750976562, 'eval_loss_4': 1.7487998008728027, 'epoch': 24.71}
{'loss': 0.0191, 'grad_norm': 7.593516826629639, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.014068648219108582, 'loss_2': 0.00501251220703125, 'loss_3': -16.30539321899414, 'loss_4': 1.6460325717926025, 'epoch': 24.72}
{'loss': 0.009, 'grad_norm': 5.14346170425415, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.005342832766473293, 'loss_2': 0.003696441650390625, 'loss_3': -16.51817512512207, 'loss_4': 2.0631916522979736, 'epoch': 24.72}
{'loss': 0.0044, 'grad_norm': 4.4108076095581055, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.0028015398420393467, 'loss_2': 0.0015621185302734375, 'loss_3': -16.275957107543945, 'loss_4': 1.933600902557373, 'epoch': 24.73}
{'loss': 0.0055, 'grad_norm': 4.432145595550537, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.004676490090787411, 'loss_2': 0.000774383544921875, 'loss_3': -16.697269439697266, 'loss_4': 2.281892776489258, 'epoch': 24.73}
{'loss': 0.0097, 'grad_norm': 4.968032360076904, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.004171669948846102, 'loss_2': 0.005558013916015625, 'loss_3': -16.268129348754883, 'loss_4': 1.789891004562378, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 11:08:44,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:44,750 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:59<15:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:52,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009531840682029724, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.245, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005769059062004089, 'eval_loss_2': 0.0037627816200256348, 'eval_loss_3': -18.234508514404297, 'eval_loss_4': 1.7220561504364014, 'epoch': 24.74}
{'loss': 0.004, 'grad_norm': 4.820394992828369, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.0032952206674963236, 'loss_2': 0.0006580352783203125, 'loss_3': -16.467927932739258, 'loss_4': 1.8335362672805786, 'epoch': 24.74}
{'loss': 0.005, 'grad_norm': 4.4277849197387695, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.0021704896353185177, 'loss_2': 0.0027923583984375, 'loss_3': -16.574663162231445, 'loss_4': 1.2909026145935059, 'epoch': 24.75}
{'loss': 0.0134, 'grad_norm': 6.224717140197754, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.011224348098039627, 'loss_2': 0.002197265625, 'loss_3': -16.446975708007812, 'loss_4': 1.6111210584640503, 'epoch': 24.76}
{'loss': 0.0109, 'grad_norm': 4.223997592926025, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.003595081390812993, 'loss_2': 0.00730133056640625, 'loss_3': -16.380634307861328, 'loss_4': 1.2807886600494385, 'epoch': 24.76}
{'loss': 0.0107, 'grad_norm': 5.510468482971191, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.005977807566523552, 'loss_2': 0.004764556884765625, 'loss_3': -16.437795639038086, 'loss_4': 2.3190133571624756, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 11:08:52,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:52,095 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:06<15:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:08:59,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009048541076481342, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005531539674848318, 'eval_loss_2': 0.0035170018672943115, 'eval_loss_3': -18.235166549682617, 'eval_loss_4': 1.7185264825820923, 'epoch': 24.77}
{'loss': 0.0154, 'grad_norm': 5.772151470184326, 'learning_rate': 5.25e-06, 'loss_1': 0.010824779979884624, 'loss_2': 0.004611968994140625, 'loss_3': -16.47734260559082, 'loss_4': 2.29988169670105, 'epoch': 24.77}
{'loss': 0.0093, 'grad_norm': 4.773199081420898, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.0038354676216840744, 'loss_2': 0.0054931640625, 'loss_3': -16.414653778076172, 'loss_4': 1.9218418598175049, 'epoch': 24.78}
{'loss': 0.0057, 'grad_norm': 4.6963582038879395, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.005434335675090551, 'loss_2': 0.00025463104248046875, 'loss_3': -16.435588836669922, 'loss_4': 2.0510025024414062, 'epoch': 24.78}
{'loss': 0.0114, 'grad_norm': 5.007493495941162, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.006359737832099199, 'loss_2': 0.005069732666015625, 'loss_3': -16.33885955810547, 'loss_4': 2.0129282474517822, 'epoch': 24.79}
{'loss': 0.0227, 'grad_norm': 19.4020938873291, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.0221816748380661, 'loss_2': 0.0005083084106445312, 'loss_3': -16.459272384643555, 'loss_4': 1.399293303489685, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 11:08:59,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:08:59,446 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:14<15:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:06,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00885709747672081, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.764, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00539011787623167, 'eval_loss_2': 0.003466978669166565, 'eval_loss_3': -18.239221572875977, 'eval_loss_4': 1.6659210920333862, 'epoch': 24.8}
{'loss': 0.0108, 'grad_norm': 7.174846649169922, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.010475103743374348, 'loss_2': 0.0003104209899902344, 'loss_3': -16.397762298583984, 'loss_4': 1.5217583179473877, 'epoch': 24.8}
{'loss': 0.0065, 'grad_norm': 4.723427772521973, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.003533037146553397, 'loss_2': 0.00298309326171875, 'loss_3': -16.55350685119629, 'loss_4': 1.6040449142456055, 'epoch': 24.81}
{'loss': 0.0073, 'grad_norm': 4.851760387420654, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.0052948989905416965, 'loss_2': 0.0019779205322265625, 'loss_3': -16.180255889892578, 'loss_4': 1.0097904205322266, 'epoch': 24.81}
{'loss': 0.0088, 'grad_norm': 4.578747749328613, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.005536364391446114, 'loss_2': 0.003299713134765625, 'loss_3': -16.318578720092773, 'loss_4': 1.6489651203155518, 'epoch': 24.82}
{'loss': 0.0118, 'grad_norm': 5.928143501281738, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.0051631079986691475, 'loss_2': 0.006622314453125, 'loss_3': -16.461956024169922, 'loss_4': 1.526624321937561, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 11:09:06,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:06,800 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:21<15:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:14,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00859472993761301, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.639, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005531886592507362, 'eval_loss_2': 0.0030628442764282227, 'eval_loss_3': -18.25012969970703, 'eval_loss_4': 1.6680892705917358, 'epoch': 24.83}
{'loss': 0.0155, 'grad_norm': 8.187906265258789, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.009754028171300888, 'loss_2': 0.0057830810546875, 'loss_3': -16.310951232910156, 'loss_4': 2.0285677909851074, 'epoch': 24.83}
{'loss': 0.0091, 'grad_norm': 4.670022487640381, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.007627121172845364, 'loss_2': 0.0014677047729492188, 'loss_3': -16.275371551513672, 'loss_4': 1.9942728281021118, 'epoch': 24.84}
{'loss': 0.0189, 'grad_norm': 9.485588073730469, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.012082306668162346, 'loss_2': 0.0068511962890625, 'loss_3': -16.074893951416016, 'loss_4': 1.30833101272583, 'epoch': 24.84}
{'loss': 0.009, 'grad_norm': 4.540843486785889, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.004706430248916149, 'loss_2': 0.004322052001953125, 'loss_3': -16.35592269897461, 'loss_4': 1.4521057605743408, 'epoch': 24.85}
{'loss': 0.0137, 'grad_norm': 5.792931079864502, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.010407722555100918, 'loss_2': 0.003269195556640625, 'loss_3': -16.480070114135742, 'loss_4': 1.954472541809082, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 11:09:14,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:14,166 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:28<15:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:21,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860796868801117, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0054024020209908485, 'eval_loss_2': 0.0032055675983428955, 'eval_loss_3': -18.253780364990234, 'eval_loss_4': 1.6707448959350586, 'epoch': 24.85}
{'loss': 0.0163, 'grad_norm': 5.08809232711792, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.01052003726363182, 'loss_2': 0.0057373046875, 'loss_3': -16.25623321533203, 'loss_4': 1.8763556480407715, 'epoch': 24.86}
{'loss': 0.007, 'grad_norm': 4.660739898681641, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.004672530572861433, 'loss_2': 0.00235748291015625, 'loss_3': -16.630653381347656, 'loss_4': 1.4817237854003906, 'epoch': 24.87}
{'loss': 0.0084, 'grad_norm': 5.983981132507324, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.00781923532485962, 'loss_2': 0.00054931640625, 'loss_3': -16.45261573791504, 'loss_4': 1.584539771080017, 'epoch': 24.87}
{'loss': 0.0097, 'grad_norm': 4.6931352615356445, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.003133739111945033, 'loss_2': 0.00653076171875, 'loss_3': -16.53356170654297, 'loss_4': 1.7315254211425781, 'epoch': 24.88}
{'loss': 0.0127, 'grad_norm': 6.399552345275879, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.008798937313258648, 'loss_2': 0.003864288330078125, 'loss_3': -16.428058624267578, 'loss_4': 1.3088449239730835, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 11:09:21,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:21,515 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:36<15:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:28,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008287123404443264, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005022919736802578, 'eval_loss_2': 0.003264203667640686, 'eval_loss_3': -18.24941062927246, 'eval_loss_4': 1.6823530197143555, 'epoch': 24.88}
{'loss': 0.0068, 'grad_norm': 4.836151599884033, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.005076225381344557, 'loss_2': 0.00171661376953125, 'loss_3': -16.526090621948242, 'loss_4': 1.4858546257019043, 'epoch': 24.89}
{'loss': 0.0103, 'grad_norm': 5.051535606384277, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.005741708446294069, 'loss_2': 0.0045928955078125, 'loss_3': -16.356931686401367, 'loss_4': 1.8146836757659912, 'epoch': 24.9}
{'loss': 0.0107, 'grad_norm': 5.259322643280029, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.008662926964461803, 'loss_2': 0.00208282470703125, 'loss_3': -16.263303756713867, 'loss_4': 2.18894100189209, 'epoch': 24.9}
{'loss': 0.0098, 'grad_norm': 5.161837577819824, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.005223119165748358, 'loss_2': 0.004611968994140625, 'loss_3': -16.466012954711914, 'loss_4': 1.9057085514068604, 'epoch': 24.91}
{'loss': 0.0079, 'grad_norm': 5.574219226837158, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.004957777447998524, 'loss_2': 0.002918243408203125, 'loss_3': -16.569271087646484, 'loss_4': 2.5288326740264893, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 11:09:28,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:28,865 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:43<15:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:36,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008779171854257584, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005245659500360489, 'eval_loss_2': 0.0035335123538970947, 'eval_loss_3': -18.252431869506836, 'eval_loss_4': 1.7017991542816162, 'epoch': 24.91}
{'loss': 0.0075, 'grad_norm': 4.7711873054504395, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.004060128703713417, 'loss_2': 0.0034332275390625, 'loss_3': -16.415691375732422, 'loss_4': 1.7498120069503784, 'epoch': 24.92}
{'loss': 0.0075, 'grad_norm': 4.741339683532715, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.005392681807279587, 'loss_2': 0.0021514892578125, 'loss_3': -16.59283447265625, 'loss_4': 0.7273067235946655, 'epoch': 24.92}
{'loss': 0.0074, 'grad_norm': 5.478843688964844, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.006403017323464155, 'loss_2': 0.0010318756103515625, 'loss_3': -16.329586029052734, 'loss_4': 2.161508798599243, 'epoch': 24.93}
{'loss': 0.0102, 'grad_norm': 4.610561847686768, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.0035591176711022854, 'loss_2': 0.006671905517578125, 'loss_3': -16.53594207763672, 'loss_4': 1.3316407203674316, 'epoch': 24.94}
{'loss': 0.0038, 'grad_norm': 4.473109245300293, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.0034076666925102472, 'loss_2': 0.0004096031188964844, 'loss_3': -16.35877799987793, 'loss_4': 1.4994257688522339, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 11:09:36,219 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:36,219 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:50<14:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:09:43,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00890600960701704, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005511428229510784, 'eval_loss_2': 0.003394581377506256, 'eval_loss_3': -18.255687713623047, 'eval_loss_4': 1.7211248874664307, 'epoch': 24.94}
{'loss': 0.007, 'grad_norm': 4.951619625091553, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.006163963582366705, 'loss_2': 0.0008726119995117188, 'loss_3': -16.330055236816406, 'loss_4': 1.4959803819656372, 'epoch': 24.95}
{'loss': 0.0093, 'grad_norm': 4.986618518829346, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.007695511914789677, 'loss_2': 0.001567840576171875, 'loss_3': -16.23756217956543, 'loss_4': 1.3281071186065674, 'epoch': 24.95}
{'loss': 0.0089, 'grad_norm': 4.4758195877075195, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.005114610772579908, 'loss_2': 0.0037631988525390625, 'loss_3': -16.36646270751953, 'loss_4': 1.535961389541626, 'epoch': 24.96}
{'loss': 0.0075, 'grad_norm': 4.492119312286377, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.0033631916157901287, 'loss_2': 0.004119873046875, 'loss_3': -16.616289138793945, 'loss_4': 1.408380389213562, 'epoch': 24.97}
{'loss': 0.0064, 'grad_norm': 5.349188327789307, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.0053214458748698235, 'loss_2': 0.0011157989501953125, 'loss_3': -16.439159393310547, 'loss_4': 1.6377143859863281, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 11:09:43,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:43,565 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:57<13:23,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:09:50,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009056597016751766, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.355, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005786679219454527, 'eval_loss_2': 0.0032699182629585266, 'eval_loss_3': -18.252321243286133, 'eval_loss_4': 1.687434434890747, 'epoch': 24.97}
{'loss': 0.0096, 'grad_norm': 5.011511325836182, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.00529413390904665, 'loss_2': 0.00429534912109375, 'loss_3': -16.365262985229492, 'loss_4': 1.6488507986068726, 'epoch': 24.98}
{'loss': 0.0072, 'grad_norm': 5.529271125793457, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.006542680319398642, 'loss_2': 0.0006923675537109375, 'loss_3': -16.53801727294922, 'loss_4': 1.6707004308700562, 'epoch': 24.98}
{'loss': 0.0139, 'grad_norm': 5.201544284820557, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.006691718474030495, 'loss_2': 0.0071868896484375, 'loss_3': -16.51171875, 'loss_4': 2.4135351181030273, 'epoch': 24.99}
{'loss': 0.0065, 'grad_norm': 4.673603057861328, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.004476040601730347, 'loss_2': 0.0020599365234375, 'loss_3': -16.605648040771484, 'loss_4': 1.2930800914764404, 'epoch': 24.99}
{'loss': 0.0037, 'grad_norm': 5.622925281524658, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0020857485942542553, 'loss_2': 0.0016450881958007812, 'loss_3': -16.175081253051758, 'loss_4': 2.954927444458008, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 11:09:50,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:50,570 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:46:05<14:36,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:09:57,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009382444433867931, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005878078285604715, 'eval_loss_2': 0.0035043656826019287, 'eval_loss_3': -18.253454208374023, 'eval_loss_4': 1.6490427255630493, 'epoch': 25.0}
{'loss': 0.0222, 'grad_norm': 8.256577491760254, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.01713499240577221, 'loss_2': 0.005092620849609375, 'loss_3': -16.344879150390625, 'loss_4': 1.4288346767425537, 'epoch': 25.01}
{'loss': 0.008, 'grad_norm': 5.400922775268555, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.007491183467209339, 'loss_2': 0.0004630088806152344, 'loss_3': -16.19622039794922, 'loss_4': 1.6277917623519897, 'epoch': 25.01}
{'loss': 0.0103, 'grad_norm': 5.026552677154541, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.005280493292957544, 'loss_2': 0.0049896240234375, 'loss_3': -16.23598289489746, 'loss_4': 1.9989674091339111, 'epoch': 25.02}
{'loss': 0.013, 'grad_norm': 8.150019645690918, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.012227218598127365, 'loss_2': 0.0007429122924804688, 'loss_3': -16.407814025878906, 'loss_4': 1.3254681825637817, 'epoch': 25.02}
{'loss': 0.0268, 'grad_norm': 9.145170211791992, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.023419653996825218, 'loss_2': 0.0033855438232421875, 'loss_3': -16.504899978637695, 'loss_4': 1.3241969347000122, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 11:09:57,970 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:09:57,971 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:12<14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:05,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009616302326321602, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.759, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006204353645443916, 'eval_loss_2': 0.0034119486808776855, 'eval_loss_3': -18.24580192565918, 'eval_loss_4': 1.642145037651062, 'epoch': 25.03}
{'loss': 0.0159, 'grad_norm': 7.482766628265381, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.0137129882350564, 'loss_2': 0.002170562744140625, 'loss_3': -16.634597778320312, 'loss_4': 0.7929562330245972, 'epoch': 25.03}
{'loss': 0.0065, 'grad_norm': 4.642987251281738, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.0039595444686710835, 'loss_2': 0.0025310516357421875, 'loss_3': -16.35517692565918, 'loss_4': 1.804598093032837, 'epoch': 25.04}
{'loss': 0.0081, 'grad_norm': 4.937158107757568, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.006858887150883675, 'loss_2': 0.00128173828125, 'loss_3': -16.378246307373047, 'loss_4': 1.258448600769043, 'epoch': 25.05}
{'loss': 0.0076, 'grad_norm': 4.516386985778809, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.006599468179047108, 'loss_2': 0.0009965896606445312, 'loss_3': -16.4232120513916, 'loss_4': 1.7091798782348633, 'epoch': 25.05}
{'loss': 0.014, 'grad_norm': 6.493203163146973, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.008748868480324745, 'loss_2': 0.005260467529296875, 'loss_3': -16.230552673339844, 'loss_4': 1.3414950370788574, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 11:10:05,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:05,326 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:19<14:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:12,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009172843769192696, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005800948943942785, 'eval_loss_2': 0.003371894359588623, 'eval_loss_3': -18.24651336669922, 'eval_loss_4': 1.6343598365783691, 'epoch': 25.06}
{'loss': 0.0108, 'grad_norm': 4.763667583465576, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.004222314804792404, 'loss_2': 0.00658416748046875, 'loss_3': -16.46571922302246, 'loss_4': 1.288877248764038, 'epoch': 25.06}
{'loss': 0.0084, 'grad_norm': 5.533832550048828, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.007856965065002441, 'loss_2': 0.0005359649658203125, 'loss_3': -16.413997650146484, 'loss_4': 1.519897699356079, 'epoch': 25.07}
{'loss': 0.0264, 'grad_norm': 10.565850257873535, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.02324860356748104, 'loss_2': 0.003154754638671875, 'loss_3': -16.24494743347168, 'loss_4': 1.4449388980865479, 'epoch': 25.08}
{'loss': 0.0042, 'grad_norm': 6.571309566497803, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.00293140416033566, 'loss_2': 0.0012540817260742188, 'loss_3': -16.34493637084961, 'loss_4': 1.430964469909668, 'epoch': 25.08}
{'loss': 0.0163, 'grad_norm': 5.107690334320068, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.00723863672465086, 'loss_2': 0.0090179443359375, 'loss_3': -16.487934112548828, 'loss_4': 1.546321988105774, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 11:10:12,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:12,686 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:27<14:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:20,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009694662876427174, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006032098550349474, 'eval_loss_2': 0.0036625638604164124, 'eval_loss_3': -18.24875259399414, 'eval_loss_4': 1.5934674739837646, 'epoch': 25.09}
{'loss': 0.0129, 'grad_norm': 5.5304412841796875, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.007433032151311636, 'loss_2': 0.00545501708984375, 'loss_3': -16.4231014251709, 'loss_4': 2.1753416061401367, 'epoch': 25.09}
{'loss': 0.0046, 'grad_norm': 4.4511942863464355, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.0031562510412186384, 'loss_2': 0.0014801025390625, 'loss_3': -16.544628143310547, 'loss_4': 2.4426910877227783, 'epoch': 25.1}
{'loss': 0.0053, 'grad_norm': 4.762345790863037, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.0028053910937160254, 'loss_2': 0.002544403076171875, 'loss_3': -16.445209503173828, 'loss_4': 1.7085249423980713, 'epoch': 25.1}
{'loss': 0.0145, 'grad_norm': 5.211369037628174, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.006584536284208298, 'loss_2': 0.007965087890625, 'loss_3': -16.234954833984375, 'loss_4': 1.421981692314148, 'epoch': 25.11}
{'loss': 0.0072, 'grad_norm': 4.314960479736328, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.005464690737426281, 'loss_2': 0.001758575439453125, 'loss_3': -16.39997100830078, 'loss_4': 2.205440044403076, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 11:10:20,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:20,041 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:34<14:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:27,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010418297722935677, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006532485596835613, 'eval_loss_2': 0.003885813057422638, 'eval_loss_3': -18.247838973999023, 'eval_loss_4': 1.5640559196472168, 'epoch': 25.12}
{'loss': 0.0033, 'grad_norm': 4.623132228851318, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.003165955189615488, 'loss_2': 0.00012099742889404297, 'loss_3': -16.335769653320312, 'loss_4': 1.1992053985595703, 'epoch': 25.12}
{'loss': 0.0081, 'grad_norm': 4.588313102722168, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.0023817350156605244, 'loss_2': 0.00574493408203125, 'loss_3': -16.474760055541992, 'loss_4': 1.4533815383911133, 'epoch': 25.13}
{'loss': 0.0101, 'grad_norm': 4.719810485839844, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.008696425706148148, 'loss_2': 0.0014476776123046875, 'loss_3': -16.62503433227539, 'loss_4': 1.2079896926879883, 'epoch': 25.13}
{'loss': 0.0063, 'grad_norm': 4.69620943069458, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.005315063986927271, 'loss_2': 0.0009531974792480469, 'loss_3': -16.31678581237793, 'loss_4': 1.4885823726654053, 'epoch': 25.14}
{'loss': 0.0077, 'grad_norm': 5.325409889221191, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.0075124590657651424, 'loss_2': 0.00014901161193847656, 'loss_3': -16.353904724121094, 'loss_4': 2.358793258666992, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 11:10:27,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:27,388 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:41<14:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:34,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009467735886573792, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.185, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006101095583289862, 'eval_loss_2': 0.0033666417002677917, 'eval_loss_3': -18.245891571044922, 'eval_loss_4': 1.5453566312789917, 'epoch': 25.15}
{'loss': 0.0057, 'grad_norm': 6.045032024383545, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.004115787334740162, 'loss_2': 0.001575469970703125, 'loss_3': -16.35140609741211, 'loss_4': 1.690669298171997, 'epoch': 25.15}
{'loss': 0.0087, 'grad_norm': 5.255824089050293, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.004074078984558582, 'loss_2': 0.00466156005859375, 'loss_3': -16.458541870117188, 'loss_4': 1.7533680200576782, 'epoch': 25.16}
{'loss': 0.0073, 'grad_norm': 4.527348041534424, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.004056486301124096, 'loss_2': 0.0031948089599609375, 'loss_3': -16.36094856262207, 'loss_4': 1.6068975925445557, 'epoch': 25.16}
{'loss': 0.0035, 'grad_norm': 4.795516490936279, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.002621942665427923, 'loss_2': 0.0008831024169921875, 'loss_3': -16.538230895996094, 'loss_4': 1.2798603773117065, 'epoch': 25.17}
{'loss': 0.0057, 'grad_norm': 4.363081455230713, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.004928466863930225, 'loss_2': 0.0007648468017578125, 'loss_3': -16.358936309814453, 'loss_4': 1.7616482973098755, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 11:10:34,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:34,753 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:49<14:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:42,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009416215121746063, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005691699683666229, 'eval_loss_2': 0.003724515438079834, 'eval_loss_3': -18.234477996826172, 'eval_loss_4': 1.5776183605194092, 'epoch': 25.17}
{'loss': 0.0053, 'grad_norm': 4.4571075439453125, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.002088986337184906, 'loss_2': 0.00323486328125, 'loss_3': -16.290756225585938, 'loss_4': 1.9457316398620605, 'epoch': 25.18}
{'loss': 0.0077, 'grad_norm': 5.107088565826416, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.004819804802536964, 'loss_2': 0.002880096435546875, 'loss_3': -16.184049606323242, 'loss_4': 1.5872583389282227, 'epoch': 25.19}
{'loss': 0.0084, 'grad_norm': 4.779504776000977, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.005137262400239706, 'loss_2': 0.0033111572265625, 'loss_3': -16.415771484375, 'loss_4': 1.2988905906677246, 'epoch': 25.19}
{'loss': 0.0053, 'grad_norm': 4.9192657470703125, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.004411408212035894, 'loss_2': 0.0009188652038574219, 'loss_3': -16.346309661865234, 'loss_4': 1.658597469329834, 'epoch': 25.2}
{'loss': 0.0126, 'grad_norm': 5.142444133758545, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.0067877317778766155, 'loss_2': 0.0058441162109375, 'loss_3': -16.553272247314453, 'loss_4': 0.8630716800689697, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 11:10:42,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:42,103 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:56<14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:49,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010618466883897781, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005388792138546705, 'eval_loss_2': 0.005229674279689789, 'eval_loss_3': -18.23422622680664, 'eval_loss_4': 1.6092263460159302, 'epoch': 25.2}
{'loss': 0.0082, 'grad_norm': 4.612829685211182, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.005175977945327759, 'loss_2': 0.0030422210693359375, 'loss_3': -16.157272338867188, 'loss_4': 1.907423496246338, 'epoch': 25.21}
{'loss': 0.0081, 'grad_norm': 4.528695583343506, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.0029266097117215395, 'loss_2': 0.00513458251953125, 'loss_3': -16.333858489990234, 'loss_4': 1.0854816436767578, 'epoch': 25.22}
{'loss': 0.0199, 'grad_norm': 8.289212226867676, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.012809131294488907, 'loss_2': 0.007080078125, 'loss_3': -16.330299377441406, 'loss_4': 1.1755495071411133, 'epoch': 25.22}
{'loss': 0.032, 'grad_norm': 7.292418956756592, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.02048701047897339, 'loss_2': 0.01149749755859375, 'loss_3': -15.966320037841797, 'loss_4': 1.0838996171951294, 'epoch': 25.23}
{'loss': 0.0053, 'grad_norm': 5.104804039001465, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.003804711392149329, 'loss_2': 0.001483917236328125, 'loss_3': -16.47259521484375, 'loss_4': 2.1044719219207764, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 11:10:49,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:49,454 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:47:04<14:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:10:56,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011197746731340885, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.005525350570678711, 'eval_loss_2': 0.0056723952293396, 'eval_loss_3': -18.232585906982422, 'eval_loss_4': 1.5599323511123657, 'epoch': 25.23}
{'loss': 0.0055, 'grad_norm': 4.2292070388793945, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.005096180364489555, 'loss_2': 0.00040340423583984375, 'loss_3': -16.252723693847656, 'loss_4': 0.8739585876464844, 'epoch': 25.24}
{'loss': 0.0111, 'grad_norm': 4.887417793273926, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.006265312898904085, 'loss_2': 0.0048065185546875, 'loss_3': -16.300525665283203, 'loss_4': 0.9610878229141235, 'epoch': 25.24}
{'loss': 0.0065, 'grad_norm': 5.180131912231445, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.006203196942806244, 'loss_2': 0.00034427642822265625, 'loss_3': -16.42165184020996, 'loss_4': 2.1319961547851562, 'epoch': 25.25}
{'loss': 0.0353, 'grad_norm': 10.003222465515137, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.026812484487891197, 'loss_2': 0.0084381103515625, 'loss_3': -16.29033660888672, 'loss_4': 2.077188491821289, 'epoch': 25.26}
{'loss': 0.0095, 'grad_norm': 5.651700496673584, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.008122503757476807, 'loss_2': 0.0013599395751953125, 'loss_3': -16.38842010498047, 'loss_4': 1.7131564617156982, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 11:10:56,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:10:56,809 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:11<14:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:04,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01034095324575901, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.203, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005497628822922707, 'eval_loss_2': 0.004843324422836304, 'eval_loss_3': -18.21805191040039, 'eval_loss_4': 1.5720937252044678, 'epoch': 25.26}
{'loss': 0.0084, 'grad_norm': 5.537796497344971, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.0073569961823523045, 'loss_2': 0.001007080078125, 'loss_3': -16.643260955810547, 'loss_4': 0.9026976823806763, 'epoch': 25.27}
{'loss': 0.0059, 'grad_norm': 4.509831428527832, 'learning_rate': 4.75e-06, 'loss_1': 0.005193243734538555, 'loss_2': 0.0006947517395019531, 'loss_3': -16.340421676635742, 'loss_4': 1.4256627559661865, 'epoch': 25.27}
{'loss': 0.0091, 'grad_norm': 5.294735431671143, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.007693103980273008, 'loss_2': 0.0014476776123046875, 'loss_3': -16.393733978271484, 'loss_4': 1.4196891784667969, 'epoch': 25.28}
{'loss': 0.0048, 'grad_norm': 4.257591247558594, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.0027457347605377436, 'loss_2': 0.002079010009765625, 'loss_3': -16.200000762939453, 'loss_4': 1.017850637435913, 'epoch': 25.28}
{'loss': 0.0129, 'grad_norm': 6.839662551879883, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.011596156284213066, 'loss_2': 0.0013332366943359375, 'loss_3': -16.32309341430664, 'loss_4': 1.3284485340118408, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 11:11:04,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:04,158 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:18<13:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:11,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009802112355828285, 'eval_runtime': 3.8409, 'eval_samples_per_second': 266.608, 'eval_steps_per_second': 4.166, 'eval_loss_1': 0.00519447959959507, 'eval_loss_2': 0.004607632756233215, 'eval_loss_3': -18.223514556884766, 'eval_loss_4': 1.645256757736206, 'epoch': 25.29}
{'loss': 0.0087, 'grad_norm': 5.450552463531494, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.007467796094715595, 'loss_2': 0.0012807846069335938, 'loss_3': -16.49976348876953, 'loss_4': 2.05513596534729, 'epoch': 25.3}
{'loss': 0.0037, 'grad_norm': 4.467015743255615, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.0028801094740629196, 'loss_2': 0.0008029937744140625, 'loss_3': -16.48366928100586, 'loss_4': 1.5747034549713135, 'epoch': 25.3}
{'loss': 0.0069, 'grad_norm': 5.29443359375, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.005932198837399483, 'loss_2': 0.0009822845458984375, 'loss_3': -16.353748321533203, 'loss_4': 1.1883432865142822, 'epoch': 25.31}
{'loss': 0.0187, 'grad_norm': 7.075249671936035, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.013820922933518887, 'loss_2': 0.0048675537109375, 'loss_3': -16.31519317626953, 'loss_4': 1.538285255432129, 'epoch': 25.31}
{'loss': 0.007, 'grad_norm': 5.0126118659973145, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.005902513861656189, 'loss_2': 0.0011072158813476562, 'loss_3': -16.352519989013672, 'loss_4': 1.9085056781768799, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 11:11:11,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:11,548 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:26<13:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:18,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008798308670520782, 'eval_runtime': 3.8348, 'eval_samples_per_second': 267.029, 'eval_steps_per_second': 4.172, 'eval_loss_1': 0.0046916864812374115, 'eval_loss_2': 0.004106622189283371, 'eval_loss_3': -18.21893882751465, 'eval_loss_4': 1.733314037322998, 'epoch': 25.32}
{'loss': 0.0025, 'grad_norm': 4.400707721710205, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.002123854588717222, 'loss_2': 0.0003743171691894531, 'loss_3': -16.33823013305664, 'loss_4': 2.041135787963867, 'epoch': 25.33}
{'loss': 0.0068, 'grad_norm': 4.753053665161133, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.0065851458348333836, 'loss_2': 0.00024890899658203125, 'loss_3': -16.476951599121094, 'loss_4': 1.6905690431594849, 'epoch': 25.33}
{'loss': 0.0097, 'grad_norm': 4.6483235359191895, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.004705738741904497, 'loss_2': 0.0050048828125, 'loss_3': -16.59670066833496, 'loss_4': 1.6636738777160645, 'epoch': 25.34}
{'loss': 0.0051, 'grad_norm': 4.511307716369629, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.0035873574670404196, 'loss_2': 0.001544952392578125, 'loss_3': -16.337818145751953, 'loss_4': 1.7219957113265991, 'epoch': 25.34}
{'loss': 0.0092, 'grad_norm': 4.656090259552002, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.0034428094513714314, 'loss_2': 0.005802154541015625, 'loss_3': -16.59246063232422, 'loss_4': 1.8069822788238525, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 11:11:18,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:18,930 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:33<13:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:26,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008651357144117355, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.22, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004798185080289841, 'eval_loss_2': 0.0038531720638275146, 'eval_loss_3': -18.221942901611328, 'eval_loss_4': 1.7715461254119873, 'epoch': 25.35}
{'loss': 0.0051, 'grad_norm': 4.133904933929443, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.0020559201948344707, 'loss_2': 0.0030307769775390625, 'loss_3': -16.354297637939453, 'loss_4': 1.936321496963501, 'epoch': 25.35}
{'loss': 0.0145, 'grad_norm': 6.03900671005249, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.012562275864183903, 'loss_2': 0.00193023681640625, 'loss_3': -16.466533660888672, 'loss_4': 1.6081979274749756, 'epoch': 25.36}
{'loss': 0.0056, 'grad_norm': 4.97828483581543, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.004766687285155058, 'loss_2': 0.0008087158203125, 'loss_3': -16.504913330078125, 'loss_4': 1.4746735095977783, 'epoch': 25.37}
{'loss': 0.013, 'grad_norm': 5.458146095275879, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.01214176882058382, 'loss_2': 0.0008907318115234375, 'loss_3': -16.336856842041016, 'loss_4': 1.3014565706253052, 'epoch': 25.37}
{'loss': 0.0098, 'grad_norm': 4.768951416015625, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.004173255525529385, 'loss_2': 0.00559234619140625, 'loss_3': -16.266807556152344, 'loss_4': 1.5185701847076416, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 11:11:26,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:26,279 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:40<13:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:33,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009165093302726746, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004695281386375427, 'eval_loss_2': 0.004469811916351318, 'eval_loss_3': -18.22141456604004, 'eval_loss_4': 1.7791804075241089, 'epoch': 25.38}
{'loss': 0.0256, 'grad_norm': 12.810832023620605, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.021614858880639076, 'loss_2': 0.0040283203125, 'loss_3': -16.38654899597168, 'loss_4': 1.6000924110412598, 'epoch': 25.38}
{'loss': 0.01, 'grad_norm': 6.242375373840332, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.008143886923789978, 'loss_2': 0.001861572265625, 'loss_3': -16.453332901000977, 'loss_4': 1.580604076385498, 'epoch': 25.39}
{'loss': 0.0104, 'grad_norm': 5.041689395904541, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.005380216054618359, 'loss_2': 0.004974365234375, 'loss_3': -16.36920928955078, 'loss_4': 2.0303196907043457, 'epoch': 25.4}
{'loss': 0.0071, 'grad_norm': 4.966121673583984, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.003523740218952298, 'loss_2': 0.003582000732421875, 'loss_3': -16.573810577392578, 'loss_4': 1.411910057067871, 'epoch': 25.4}
{'loss': 0.0115, 'grad_norm': 5.660318851470947, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.006230553612112999, 'loss_2': 0.00531768798828125, 'loss_3': -16.21985626220703, 'loss_4': 2.141235113143921, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 11:11:33,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:33,629 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:48<13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:40,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009107623249292374, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.205, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004933823831379414, 'eval_loss_2': 0.004173800349235535, 'eval_loss_3': -18.219892501831055, 'eval_loss_4': 1.7616386413574219, 'epoch': 25.41}
{'loss': 0.0101, 'grad_norm': 4.7866411209106445, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.0041062431409955025, 'loss_2': 0.005985260009765625, 'loss_3': -16.37356185913086, 'loss_4': 1.9671540260314941, 'epoch': 25.41}
{'loss': 0.0053, 'grad_norm': 4.660184383392334, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.0023988254833966494, 'loss_2': 0.002895355224609375, 'loss_3': -16.27672004699707, 'loss_4': 1.5675742626190186, 'epoch': 25.42}
{'loss': 0.0063, 'grad_norm': 4.627594470977783, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.0036574506666511297, 'loss_2': 0.0026397705078125, 'loss_3': -16.255207061767578, 'loss_4': 1.240789532661438, 'epoch': 25.42}
{'loss': 0.0094, 'grad_norm': 4.910572052001953, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.005117303226143122, 'loss_2': 0.0042724609375, 'loss_3': -16.448246002197266, 'loss_4': 1.8938839435577393, 'epoch': 25.43}
{'loss': 0.0108, 'grad_norm': 5.636512756347656, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.009709146805107594, 'loss_2': 0.0011005401611328125, 'loss_3': -16.53432846069336, 'loss_4': 1.5701231956481934, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 11:11:40,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:40,988 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:55<13:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:48,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00882045179605484, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005014932714402676, 'eval_loss_2': 0.00380551815032959, 'eval_loss_3': -18.21686363220215, 'eval_loss_4': 1.715893268585205, 'epoch': 25.44}
{'loss': 0.0118, 'grad_norm': 5.721155643463135, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.007869144901633263, 'loss_2': 0.003978729248046875, 'loss_3': -16.1900634765625, 'loss_4': 1.6677491664886475, 'epoch': 25.44}
{'loss': 0.0155, 'grad_norm': 8.362393379211426, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.011476419866085052, 'loss_2': 0.0040130615234375, 'loss_3': -16.391944885253906, 'loss_4': 1.6462281942367554, 'epoch': 25.45}
{'loss': 0.0107, 'grad_norm': 4.704822063446045, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.005656615365296602, 'loss_2': 0.005031585693359375, 'loss_3': -16.381084442138672, 'loss_4': 2.0567195415496826, 'epoch': 25.45}
{'loss': 0.0097, 'grad_norm': 5.114637851715088, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.0058581153862178326, 'loss_2': 0.00386810302734375, 'loss_3': -16.298133850097656, 'loss_4': 1.3868380784988403, 'epoch': 25.46}
{'loss': 0.0071, 'grad_norm': 4.501131534576416, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.0032086006831377745, 'loss_2': 0.003936767578125, 'loss_3': -16.45467758178711, 'loss_4': 2.481813669204712, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 11:11:48,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:48,335 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:48:02<13:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:11:55,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008565546944737434, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005120473448187113, 'eval_loss_2': 0.003445073962211609, 'eval_loss_3': -18.209716796875, 'eval_loss_4': 1.6937371492385864, 'epoch': 25.47}
{'loss': 0.0079, 'grad_norm': 5.222296237945557, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.006686934269964695, 'loss_2': 0.0012331008911132812, 'loss_3': -16.216035842895508, 'loss_4': 1.5894289016723633, 'epoch': 25.47}
{'loss': 0.0064, 'grad_norm': 4.6888885498046875, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.00406569242477417, 'loss_2': 0.0023441314697265625, 'loss_3': -16.26295280456543, 'loss_4': 1.3929264545440674, 'epoch': 25.48}
{'loss': 0.0082, 'grad_norm': 5.836856842041016, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.007867159321904182, 'loss_2': 0.0003452301025390625, 'loss_3': -16.378257751464844, 'loss_4': 1.4766385555267334, 'epoch': 25.48}
{'loss': 0.0053, 'grad_norm': 5.176238059997559, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.004249772522598505, 'loss_2': 0.001056671142578125, 'loss_3': -16.434125900268555, 'loss_4': 1.5711565017700195, 'epoch': 25.49}
{'loss': 0.0095, 'grad_norm': 4.385761737823486, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.004321502987295389, 'loss_2': 0.005161285400390625, 'loss_3': -16.185306549072266, 'loss_4': 2.540158748626709, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 11:11:55,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:11:55,695 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:10<13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:03,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008089147508144379, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.955, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004751897882670164, 'eval_loss_2': 0.0033372491598129272, 'eval_loss_3': -18.212976455688477, 'eval_loss_4': 1.7092106342315674, 'epoch': 25.49}
{'loss': 0.0103, 'grad_norm': 6.184122562408447, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.008149164728820324, 'loss_2': 0.0021228790283203125, 'loss_3': -16.271305084228516, 'loss_4': 2.0630311965942383, 'epoch': 25.5}
{'loss': 0.0074, 'grad_norm': 4.491086006164551, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.0033265918027609587, 'loss_2': 0.0040740966796875, 'loss_3': -16.41998291015625, 'loss_4': 2.1546499729156494, 'epoch': 25.51}
{'loss': 0.0129, 'grad_norm': 4.933332920074463, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.0048850649036467075, 'loss_2': 0.00801849365234375, 'loss_3': -16.383525848388672, 'loss_4': 1.8948924541473389, 'epoch': 25.51}
{'loss': 0.0152, 'grad_norm': 6.97483491897583, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.012448078021407127, 'loss_2': 0.002765655517578125, 'loss_3': -16.29961395263672, 'loss_4': 1.7843270301818848, 'epoch': 25.52}
{'loss': 0.005, 'grad_norm': 4.449936389923096, 'learning_rate': 4.5e-06, 'loss_1': 0.0033812399487942457, 'loss_2': 0.001667022705078125, 'loss_3': -16.528411865234375, 'loss_4': 2.0527377128601074, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 11:12:03,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:03,051 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:17<13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:10,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00882665254175663, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.02, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0050489092245697975, 'eval_loss_2': 0.003777742385864258, 'eval_loss_3': -18.20621681213379, 'eval_loss_4': 1.7971001863479614, 'epoch': 25.52}
{'loss': 0.0053, 'grad_norm': 4.428031921386719, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.0034420688170939684, 'loss_2': 0.0018215179443359375, 'loss_3': -16.47203254699707, 'loss_4': 2.5663607120513916, 'epoch': 25.53}
{'loss': 0.0132, 'grad_norm': 4.984236240386963, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.008059795945882797, 'loss_2': 0.00513458251953125, 'loss_3': -16.24443817138672, 'loss_4': 2.1360528469085693, 'epoch': 25.53}
{'loss': 0.0044, 'grad_norm': 4.231525421142578, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.0023645530454814434, 'loss_2': 0.0020122528076171875, 'loss_3': -16.393352508544922, 'loss_4': 2.318822145462036, 'epoch': 25.54}
{'loss': 0.0077, 'grad_norm': 4.694020748138428, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.002627248875796795, 'loss_2': 0.00504302978515625, 'loss_3': -16.350025177001953, 'loss_4': 1.4801054000854492, 'epoch': 25.55}
{'loss': 0.0048, 'grad_norm': 4.583181858062744, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.004301098175346851, 'loss_2': 0.0004622936248779297, 'loss_3': -16.397289276123047, 'loss_4': 1.8721524477005005, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 11:12:10,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:10,411 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:24<13:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:17,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008974658325314522, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005288438871502876, 'eval_loss_2': 0.0036862194538116455, 'eval_loss_3': -18.195680618286133, 'eval_loss_4': 1.8262678384780884, 'epoch': 25.55}
{'loss': 0.0095, 'grad_norm': 5.013903617858887, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.008140180259943008, 'loss_2': 0.00136566162109375, 'loss_3': -16.56832504272461, 'loss_4': 2.1929430961608887, 'epoch': 25.56}
{'loss': 0.0079, 'grad_norm': 5.208888053894043, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.006850594654679298, 'loss_2': 0.0010805130004882812, 'loss_3': -16.33761215209961, 'loss_4': 0.9203755259513855, 'epoch': 25.56}
{'loss': 0.0119, 'grad_norm': 4.538430690765381, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.0037441952154040337, 'loss_2': 0.00817108154296875, 'loss_3': -16.222875595092773, 'loss_4': 2.0324764251708984, 'epoch': 25.57}
{'loss': 0.0126, 'grad_norm': 5.581100940704346, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.005884692072868347, 'loss_2': 0.006725311279296875, 'loss_3': -16.214170455932617, 'loss_4': 0.7133688926696777, 'epoch': 25.58}
{'loss': 0.011, 'grad_norm': 4.945137977600098, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.004479921422898769, 'loss_2': 0.006557464599609375, 'loss_3': -16.210668563842773, 'loss_4': 2.2016077041625977, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 11:12:17,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:17,758 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:32<13:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:25,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008703081868588924, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005200608633458614, 'eval_loss_2': 0.00350247323513031, 'eval_loss_3': -18.186552047729492, 'eval_loss_4': 1.8420276641845703, 'epoch': 25.58}
{'loss': 0.0069, 'grad_norm': 4.832102298736572, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.0048777018673717976, 'loss_2': 0.002048492431640625, 'loss_3': -16.59089469909668, 'loss_4': 2.393486976623535, 'epoch': 25.59}
{'loss': 0.0055, 'grad_norm': 4.690702438354492, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.004543723538517952, 'loss_2': 0.0009098052978515625, 'loss_3': -16.534019470214844, 'loss_4': 1.0726122856140137, 'epoch': 25.59}
{'loss': 0.022, 'grad_norm': 12.203775405883789, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.01855604164302349, 'loss_2': 0.003475189208984375, 'loss_3': -16.369062423706055, 'loss_4': 1.6119343042373657, 'epoch': 25.6}
{'loss': 0.01, 'grad_norm': 5.437634468078613, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.007329266052693129, 'loss_2': 0.0026454925537109375, 'loss_3': -16.179492950439453, 'loss_4': 1.6176837682724, 'epoch': 25.6}
{'loss': 0.004, 'grad_norm': 4.8022332191467285, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.0037257203366607428, 'loss_2': 0.0002989768981933594, 'loss_3': -16.386207580566406, 'loss_4': 2.1126749515533447, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 11:12:25,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:25,105 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:39<12:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:32,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008938368409872055, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005691591650247574, 'eval_loss_2': 0.003246776759624481, 'eval_loss_3': -18.18575668334961, 'eval_loss_4': 1.8399169445037842, 'epoch': 25.61}
{'loss': 0.0082, 'grad_norm': 4.720367431640625, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.003911611158400774, 'loss_2': 0.004261016845703125, 'loss_3': -16.363666534423828, 'loss_4': 1.4936730861663818, 'epoch': 25.62}
{'loss': 0.0153, 'grad_norm': 5.563887119293213, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.004821646027266979, 'loss_2': 0.01043701171875, 'loss_3': -16.23421859741211, 'loss_4': 1.517677664756775, 'epoch': 25.62}
{'loss': 0.005, 'grad_norm': 4.27130651473999, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.004302501678466797, 'loss_2': 0.0007314682006835938, 'loss_3': -16.197853088378906, 'loss_4': 1.7473528385162354, 'epoch': 25.63}
{'loss': 0.0122, 'grad_norm': 4.534063339233398, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.0030708936974406242, 'loss_2': 0.00909423828125, 'loss_3': -16.226573944091797, 'loss_4': 1.8734453916549683, 'epoch': 25.63}
{'loss': 0.0105, 'grad_norm': 5.528400897979736, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.007282140664756298, 'loss_2': 0.00319671630859375, 'loss_3': -16.39359474182129, 'loss_4': 1.2907922267913818, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 11:12:32,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:32,460 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:47<12:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:39,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009043548256158829, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.708, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005722392350435257, 'eval_loss_2': 0.0033211559057235718, 'eval_loss_3': -18.181873321533203, 'eval_loss_4': 1.8044042587280273, 'epoch': 25.64}
{'loss': 0.0091, 'grad_norm': 5.158029079437256, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.0037210562732070684, 'loss_2': 0.005401611328125, 'loss_3': -16.312938690185547, 'loss_4': 2.0521490573883057, 'epoch': 25.65}
{'loss': 0.0327, 'grad_norm': 16.595190048217773, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.027742357924580574, 'loss_2': 0.0049591064453125, 'loss_3': -16.32859992980957, 'loss_4': 1.642480492591858, 'epoch': 25.65}
{'loss': 0.0191, 'grad_norm': 14.161625862121582, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.016865240409970284, 'loss_2': 0.002216339111328125, 'loss_3': -16.467750549316406, 'loss_4': 1.6710212230682373, 'epoch': 25.66}
{'loss': 0.0122, 'grad_norm': 5.781884670257568, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.009228797629475594, 'loss_2': 0.0030117034912109375, 'loss_3': -16.409744262695312, 'loss_4': 1.6658554077148438, 'epoch': 25.66}
{'loss': 0.0108, 'grad_norm': 5.435201644897461, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.00815306231379509, 'loss_2': 0.002643585205078125, 'loss_3': -16.2889404296875, 'loss_4': 1.9604377746582031, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 11:12:39,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:39,821 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:54<12:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:47,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008768415078520775, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0054312399588525295, 'eval_loss_2': 0.003337174654006958, 'eval_loss_3': -18.18240737915039, 'eval_loss_4': 1.7889976501464844, 'epoch': 25.67}
{'loss': 0.0039, 'grad_norm': 4.665894985198975, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.003767592366784811, 'loss_2': 0.00014841556549072266, 'loss_3': -16.548038482666016, 'loss_4': 2.462737560272217, 'epoch': 25.67}
{'loss': 0.0097, 'grad_norm': 4.409698963165283, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.0031733543146401644, 'loss_2': 0.006496429443359375, 'loss_3': -16.358932495117188, 'loss_4': 2.122776985168457, 'epoch': 25.68}
{'loss': 0.01, 'grad_norm': 5.227506637573242, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.005549307446926832, 'loss_2': 0.004413604736328125, 'loss_3': -16.304563522338867, 'loss_4': 2.5259134769439697, 'epoch': 25.69}
{'loss': 0.009, 'grad_norm': 4.622348308563232, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.00444784015417099, 'loss_2': 0.004558563232421875, 'loss_3': -16.419822692871094, 'loss_4': 1.0151209831237793, 'epoch': 25.69}
{'loss': 0.0127, 'grad_norm': 6.329198360443115, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.009525831788778305, 'loss_2': 0.0032176971435546875, 'loss_3': -16.493749618530273, 'loss_4': 1.834459662437439, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 11:12:47,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:47,158 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:49:01<12:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:12:54,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008953815326094627, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005531808361411095, 'eval_loss_2': 0.0034220069646835327, 'eval_loss_3': -18.186172485351562, 'eval_loss_4': 1.7704870700836182, 'epoch': 25.7}
{'loss': 0.0079, 'grad_norm': 4.7873687744140625, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.0032004520762711763, 'loss_2': 0.0047149658203125, 'loss_3': -16.414138793945312, 'loss_4': 1.7365262508392334, 'epoch': 25.7}
{'loss': 0.0159, 'grad_norm': 6.699939250946045, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.008281822316348553, 'loss_2': 0.00766754150390625, 'loss_3': -16.36096954345703, 'loss_4': 2.3981425762176514, 'epoch': 25.71}
{'loss': 0.0043, 'grad_norm': 4.959303379058838, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.004041512496769428, 'loss_2': 0.0002968311309814453, 'loss_3': -16.37561798095703, 'loss_4': 2.3886468410491943, 'epoch': 25.72}
{'loss': 0.0064, 'grad_norm': 4.353576183319092, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.0021135476417839527, 'loss_2': 0.00431060791015625, 'loss_3': -16.451332092285156, 'loss_4': 1.5270090103149414, 'epoch': 25.72}
{'loss': 0.0067, 'grad_norm': 5.257301330566406, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.006565605755895376, 'loss_2': 0.00014400482177734375, 'loss_3': -16.384845733642578, 'loss_4': 0.9306629300117493, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 11:12:54,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:12:54,504 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:09<12:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:01,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009167488664388657, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005503234453499317, 'eval_loss_2': 0.003664255142211914, 'eval_loss_3': -18.18056869506836, 'eval_loss_4': 1.7582957744598389, 'epoch': 25.73}
{'loss': 0.0133, 'grad_norm': 7.9825615882873535, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.01017819344997406, 'loss_2': 0.00315093994140625, 'loss_3': -16.168926239013672, 'loss_4': 1.9929322004318237, 'epoch': 25.73}
{'loss': 0.0152, 'grad_norm': 5.919332504272461, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.008457656018435955, 'loss_2': 0.0067596435546875, 'loss_3': -16.408245086669922, 'loss_4': 1.94301176071167, 'epoch': 25.74}
{'loss': 0.0114, 'grad_norm': 4.945204257965088, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.008256401866674423, 'loss_2': 0.0031261444091796875, 'loss_3': -16.21603012084961, 'loss_4': 1.5094398260116577, 'epoch': 25.74}
{'loss': 0.0051, 'grad_norm': 4.798793315887451, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.002501280978322029, 'loss_2': 0.002574920654296875, 'loss_3': -16.42295265197754, 'loss_4': 1.5839990377426147, 'epoch': 25.75}
{'loss': 0.0153, 'grad_norm': 4.869560718536377, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.0059482501819729805, 'loss_2': 0.0093841552734375, 'loss_3': -16.402986526489258, 'loss_4': 1.4304821491241455, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 11:13:01,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:01,848 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:16<12:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:09,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008950496092438698, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.927, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005223223939538002, 'eval_loss_2': 0.003727272152900696, 'eval_loss_3': -18.182170867919922, 'eval_loss_4': 1.789660930633545, 'epoch': 25.76}
{'loss': 0.0066, 'grad_norm': 4.327398300170898, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.004414602182805538, 'loss_2': 0.00213623046875, 'loss_3': -16.34177589416504, 'loss_4': 2.0358262062072754, 'epoch': 25.76}
{'loss': 0.0129, 'grad_norm': 5.978155612945557, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.01070380862802267, 'loss_2': 0.002227783203125, 'loss_3': -16.359695434570312, 'loss_4': 1.560849666595459, 'epoch': 25.77}
{'loss': 0.0157, 'grad_norm': 7.575895309448242, 'learning_rate': 4.25e-06, 'loss_1': 0.010758395306766033, 'loss_2': 0.0048980712890625, 'loss_3': -16.28276252746582, 'loss_4': 1.8874790668487549, 'epoch': 25.77}
{'loss': 0.0062, 'grad_norm': 5.212191581726074, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.0046918438747525215, 'loss_2': 0.001499176025390625, 'loss_3': -16.436845779418945, 'loss_4': 2.2072043418884277, 'epoch': 25.78}
{'loss': 0.0046, 'grad_norm': 4.659051418304443, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.003769985865801573, 'loss_2': 0.0008287429809570312, 'loss_3': -16.324390411376953, 'loss_4': 1.8723430633544922, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 11:13:09,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:09,201 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:23<12:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:16,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008488199673593044, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.42, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005012296140193939, 'eval_loss_2': 0.0034759044647216797, 'eval_loss_3': -18.18099594116211, 'eval_loss_4': 1.8314776420593262, 'epoch': 25.78}
{'loss': 0.0093, 'grad_norm': 4.6937336921691895, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.00506848469376564, 'loss_2': 0.004222869873046875, 'loss_3': -16.235734939575195, 'loss_4': 2.8611576557159424, 'epoch': 25.79}
{'loss': 0.0297, 'grad_norm': 16.814525604248047, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.029102688655257225, 'loss_2': 0.0006470680236816406, 'loss_3': -16.48874855041504, 'loss_4': 2.173604726791382, 'epoch': 25.8}
{'loss': 0.0046, 'grad_norm': 4.702286243438721, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.004312838893383741, 'loss_2': 0.00027942657470703125, 'loss_3': -16.41458511352539, 'loss_4': 1.7691582441329956, 'epoch': 25.8}
{'loss': 0.0082, 'grad_norm': 5.566493988037109, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.005115838255733252, 'loss_2': 0.0031032562255859375, 'loss_3': -16.462602615356445, 'loss_4': 2.665849208831787, 'epoch': 25.81}
{'loss': 0.0042, 'grad_norm': 4.387536525726318, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.0025391667149960995, 'loss_2': 0.0016279220581054688, 'loss_3': -16.45977020263672, 'loss_4': 2.0270142555236816, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 11:13:16,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:16,565 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:31<12:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:23,919 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008837414905428886, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.189, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005823655053973198, 'eval_loss_2': 0.0030137598514556885, 'eval_loss_3': -18.17483139038086, 'eval_loss_4': 1.9073848724365234, 'epoch': 25.81}
{'loss': 0.0062, 'grad_norm': 4.9852800369262695, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.0044302199967205524, 'loss_2': 0.001800537109375, 'loss_3': -16.378101348876953, 'loss_4': 1.9759914875030518, 'epoch': 25.82}
{'loss': 0.0165, 'grad_norm': 6.243265628814697, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.007503638043999672, 'loss_2': 0.009033203125, 'loss_3': -16.368431091308594, 'loss_4': 2.0878939628601074, 'epoch': 25.83}
{'loss': 0.0165, 'grad_norm': 5.129823684692383, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.00943687092512846, 'loss_2': 0.00704193115234375, 'loss_3': -16.47183609008789, 'loss_4': 2.038973808288574, 'epoch': 25.83}
{'loss': 0.0063, 'grad_norm': 5.245464324951172, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.005589949432760477, 'loss_2': 0.0007495880126953125, 'loss_3': -16.168336868286133, 'loss_4': 1.5132131576538086, 'epoch': 25.84}
{'loss': 0.0143, 'grad_norm': 5.445825099945068, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.005694634281098843, 'loss_2': 0.0086212158203125, 'loss_3': -16.29209327697754, 'loss_4': 2.243600368499756, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 11:13:23,919 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:23,919 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:38<12:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:31,269 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009600052610039711, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006492041517049074, 'eval_loss_2': 0.003108009696006775, 'eval_loss_3': -18.170413970947266, 'eval_loss_4': 1.938590407371521, 'epoch': 25.84}
{'loss': 0.0123, 'grad_norm': 4.45489501953125, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.005186867900192738, 'loss_2': 0.00711822509765625, 'loss_3': -16.22430419921875, 'loss_4': 2.301469326019287, 'epoch': 25.85}
{'loss': 0.0059, 'grad_norm': 4.903761863708496, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.0040881335735321045, 'loss_2': 0.0017833709716796875, 'loss_3': -16.488605499267578, 'loss_4': 1.9197320938110352, 'epoch': 25.85}
{'loss': 0.0067, 'grad_norm': 4.717066764831543, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.004564640577882528, 'loss_2': 0.00213623046875, 'loss_3': -16.173107147216797, 'loss_4': 2.0670108795166016, 'epoch': 25.86}
{'loss': 0.0062, 'grad_norm': 7.480826377868652, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.005545774009078741, 'loss_2': 0.0006313323974609375, 'loss_3': -16.415019989013672, 'loss_4': 1.7188831567764282, 'epoch': 25.87}
{'loss': 0.0129, 'grad_norm': 9.568687438964844, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.011333748698234558, 'loss_2': 0.001567840576171875, 'loss_3': -16.456472396850586, 'loss_4': 2.563478708267212, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 11:13:31,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:31,270 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:45<12:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:38,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009771010838449001, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.221, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00654592365026474, 'eval_loss_2': 0.003225088119506836, 'eval_loss_3': -18.17862319946289, 'eval_loss_4': 1.926798701286316, 'epoch': 25.87}
{'loss': 0.0092, 'grad_norm': 6.369268417358398, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.006451035849750042, 'loss_2': 0.002777099609375, 'loss_3': -16.402698516845703, 'loss_4': 1.3421646356582642, 'epoch': 25.88}
{'loss': 0.0144, 'grad_norm': 4.873321533203125, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.0047127255238592625, 'loss_2': 0.0097198486328125, 'loss_3': -16.408205032348633, 'loss_4': 1.9493308067321777, 'epoch': 25.88}
{'loss': 0.014, 'grad_norm': 6.626946926116943, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.009808252565562725, 'loss_2': 0.00414276123046875, 'loss_3': -16.229862213134766, 'loss_4': 1.8234524726867676, 'epoch': 25.89}
{'loss': 0.0253, 'grad_norm': 9.828447341918945, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.019073186442255974, 'loss_2': 0.00620269775390625, 'loss_3': -16.419322967529297, 'loss_4': 2.1327145099639893, 'epoch': 25.9}
{'loss': 0.0099, 'grad_norm': 5.534996032714844, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.0070018586702644825, 'loss_2': 0.0029125213623046875, 'loss_3': -16.266904830932617, 'loss_4': 2.053190231323242, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 11:13:38,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:38,624 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:49:53<12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:45,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009202869608998299, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005863940343260765, 'eval_loss_2': 0.0033389292657375336, 'eval_loss_3': -18.18596839904785, 'eval_loss_4': 1.8353192806243896, 'epoch': 25.9}
{'loss': 0.0099, 'grad_norm': 5.080915451049805, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.005039322189986706, 'loss_2': 0.00481414794921875, 'loss_3': -16.153715133666992, 'loss_4': 2.4230446815490723, 'epoch': 25.91}
{'loss': 0.016, 'grad_norm': 6.928814888000488, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.013058163225650787, 'loss_2': 0.002971649169921875, 'loss_3': -16.35993194580078, 'loss_4': 2.082899808883667, 'epoch': 25.91}
{'loss': 0.0047, 'grad_norm': 4.505417346954346, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.003996593412011862, 'loss_2': 0.0007319450378417969, 'loss_3': -16.258819580078125, 'loss_4': 2.0186891555786133, 'epoch': 25.92}
{'loss': 0.0229, 'grad_norm': 10.680054664611816, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.018967563286423683, 'loss_2': 0.0039005279541015625, 'loss_3': -16.281312942504883, 'loss_4': 1.5438969135284424, 'epoch': 25.92}
{'loss': 0.0062, 'grad_norm': 4.478207588195801, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.0026400855276733637, 'loss_2': 0.00360870361328125, 'loss_3': -16.080135345458984, 'loss_4': 2.136603355407715, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 11:13:45,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:45,984 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:50:00<12:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:13:53,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008847742341458797, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.74, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0057076504454016685, 'eval_loss_2': 0.003140091896057129, 'eval_loss_3': -18.18952178955078, 'eval_loss_4': 1.8104503154754639, 'epoch': 25.93}
{'loss': 0.0073, 'grad_norm': 5.111006736755371, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.005740987602621317, 'loss_2': 0.001529693603515625, 'loss_3': -16.299854278564453, 'loss_4': 2.414830446243286, 'epoch': 25.94}
{'loss': 0.0102, 'grad_norm': 5.6906328201293945, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.007625291123986244, 'loss_2': 0.0025272369384765625, 'loss_3': -16.289630889892578, 'loss_4': 1.2739297151565552, 'epoch': 25.94}
{'loss': 0.011, 'grad_norm': 5.173460960388184, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.006411729846149683, 'loss_2': 0.00457763671875, 'loss_3': -16.370342254638672, 'loss_4': 1.7823238372802734, 'epoch': 25.95}
{'loss': 0.0061, 'grad_norm': 5.194825172424316, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.0043767779134213924, 'loss_2': 0.00174713134765625, 'loss_3': -16.504295349121094, 'loss_4': 1.630556344985962, 'epoch': 25.95}
{'loss': 0.0088, 'grad_norm': 5.072684288024902, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.007214656565338373, 'loss_2': 0.0016021728515625, 'loss_3': -16.469497680664062, 'loss_4': 1.50728440284729, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 11:13:53,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:13:53,331 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:07<11:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:00,692 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008511942811310291, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.417, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005126220174133778, 'eval_loss_2': 0.0033857226371765137, 'eval_loss_3': -18.197582244873047, 'eval_loss_4': 1.7502652406692505, 'epoch': 25.96}
{'loss': 0.0062, 'grad_norm': 4.453271865844727, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.00366804376244545, 'loss_2': 0.0024967193603515625, 'loss_3': -16.296611785888672, 'loss_4': 1.3996862173080444, 'epoch': 25.97}
{'loss': 0.0231, 'grad_norm': 9.448531150817871, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.01745636574923992, 'loss_2': 0.00560760498046875, 'loss_3': -16.32645606994629, 'loss_4': 1.5557068586349487, 'epoch': 25.97}
{'loss': 0.0084, 'grad_norm': 4.339605331420898, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.0018624941585585475, 'loss_2': 0.006565093994140625, 'loss_3': -16.46323013305664, 'loss_4': 1.6667044162750244, 'epoch': 25.98}
{'loss': 0.0077, 'grad_norm': 4.917940139770508, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.005247610621154308, 'loss_2': 0.002471923828125, 'loss_3': -16.33017349243164, 'loss_4': 2.282822847366333, 'epoch': 25.98}
{'loss': 0.0079, 'grad_norm': 4.544414043426514, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.004388409201055765, 'loss_2': 0.003520965576171875, 'loss_3': -16.389362335205078, 'loss_4': 1.8414990901947021, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 11:14:00,692 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:00,692 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:14<11:32,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 11:14:07,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009158020839095116, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005385143682360649, 'eval_loss_2': 0.0037728771567344666, 'eval_loss_3': -18.19748878479004, 'eval_loss_4': 1.7769827842712402, 'epoch': 25.99}
{'loss': 0.0052, 'grad_norm': 4.812324047088623, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.0038257583510130644, 'loss_2': 0.0013875961303710938, 'loss_3': -16.68341064453125, 'loss_4': 1.967665195465088, 'epoch': 25.99}
{'loss': 0.0085, 'grad_norm': 8.385664939880371, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.005649622995406389, 'loss_2': 0.0028095245361328125, 'loss_3': -16.6173038482666, 'loss_4': 2.3167667388916016, 'epoch': 26.0}
{'loss': 0.0057, 'grad_norm': 4.832005023956299, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.0053382026962935925, 'loss_2': 0.00038051605224609375, 'loss_3': -16.23464584350586, 'loss_4': 2.050353765487671, 'epoch': 26.01}
{'loss': 0.0073, 'grad_norm': 4.4414591789245605, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.0026406561955809593, 'loss_2': 0.004650115966796875, 'loss_3': -16.369916915893555, 'loss_4': 2.139843463897705, 'epoch': 26.01}
{'loss': 0.0138, 'grad_norm': 6.574805736541748, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.013626370579004288, 'loss_2': 0.00016486644744873047, 'loss_3': -16.263317108154297, 'loss_4': 1.8944920301437378, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 11:14:07,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:07,742 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:22<11:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:15,104 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010092303156852722, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.788, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005427047610282898, 'eval_loss_2': 0.004665255546569824, 'eval_loss_3': -18.187726974487305, 'eval_loss_4': 1.8069305419921875, 'epoch': 26.02}
{'loss': 0.0042, 'grad_norm': 4.943968296051025, 'learning_rate': 4e-06, 'loss_1': 0.00393116706982255, 'loss_2': 0.0002617835998535156, 'loss_3': -16.225934982299805, 'loss_4': 1.0478366613388062, 'epoch': 26.02}
{'loss': 0.0065, 'grad_norm': 5.383553504943848, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.004920633975416422, 'loss_2': 0.0016002655029296875, 'loss_3': -16.18536949157715, 'loss_4': 2.0457446575164795, 'epoch': 26.03}
{'loss': 0.0071, 'grad_norm': 4.76231575012207, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.0034551394637674093, 'loss_2': 0.0036773681640625, 'loss_3': -16.29449462890625, 'loss_4': 1.45011305809021, 'epoch': 26.03}
{'loss': 0.0059, 'grad_norm': 4.296429634094238, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.001858046161942184, 'loss_2': 0.00406646728515625, 'loss_3': -16.333463668823242, 'loss_4': 1.733864665031433, 'epoch': 26.04}
{'loss': 0.0069, 'grad_norm': 4.431440353393555, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.003733214223757386, 'loss_2': 0.0031280517578125, 'loss_3': -16.253849029541016, 'loss_4': 1.723353385925293, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 11:14:15,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:15,104 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:29<11:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:22,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01054154708981514, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.096, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005145658273249865, 'eval_loss_2': 0.0053958892822265625, 'eval_loss_3': -18.192089080810547, 'eval_loss_4': 1.7915068864822388, 'epoch': 26.05}
{'loss': 0.0133, 'grad_norm': 7.553469181060791, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.011045260354876518, 'loss_2': 0.00223541259765625, 'loss_3': -16.284337997436523, 'loss_4': 1.4194614887237549, 'epoch': 26.05}
{'loss': 0.0156, 'grad_norm': 9.989555358886719, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.013981258496642113, 'loss_2': 0.001628875732421875, 'loss_3': -16.320741653442383, 'loss_4': 2.8693175315856934, 'epoch': 26.06}
{'loss': 0.0159, 'grad_norm': 6.590472221374512, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.009128925390541553, 'loss_2': 0.00677490234375, 'loss_3': -16.334754943847656, 'loss_4': 2.210071086883545, 'epoch': 26.06}
{'loss': 0.0086, 'grad_norm': 5.291922569274902, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.007558873388916254, 'loss_2': 0.0010004043579101562, 'loss_3': -16.2581844329834, 'loss_4': 1.8045196533203125, 'epoch': 26.07}
{'loss': 0.0098, 'grad_norm': 5.073780059814453, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.004544879775494337, 'loss_2': 0.00525665283203125, 'loss_3': -16.3813533782959, 'loss_4': 2.1948232650756836, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 11:14:22,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:22,449 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:37<11:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:29,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010379813611507416, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.254, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0051825279369950294, 'eval_loss_2': 0.005197286605834961, 'eval_loss_3': -18.1993465423584, 'eval_loss_4': 1.8046821355819702, 'epoch': 26.08}
{'loss': 0.0046, 'grad_norm': 4.523916721343994, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.003134010126814246, 'loss_2': 0.0014858245849609375, 'loss_3': -16.39437484741211, 'loss_4': 1.4200663566589355, 'epoch': 26.08}
{'loss': 0.0079, 'grad_norm': 4.594991683959961, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.0043592192232608795, 'loss_2': 0.003574371337890625, 'loss_3': -16.206707000732422, 'loss_4': 1.43742835521698, 'epoch': 26.09}
{'loss': 0.0118, 'grad_norm': 4.299808979034424, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.0050993491895496845, 'loss_2': 0.00670623779296875, 'loss_3': -16.36180877685547, 'loss_4': 2.2508528232574463, 'epoch': 26.09}
{'loss': 0.01, 'grad_norm': 5.229222297668457, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.007293056696653366, 'loss_2': 0.0026702880859375, 'loss_3': -16.298471450805664, 'loss_4': 1.6566495895385742, 'epoch': 26.1}
{'loss': 0.0128, 'grad_norm': 5.1970953941345215, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.0066894120536744595, 'loss_2': 0.0061187744140625, 'loss_3': -16.29340934753418, 'loss_4': 2.182366371154785, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 11:14:29,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:29,792 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:44<11:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:37,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008960170671343803, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.774, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00516278063878417, 'eval_loss_2': 0.003797389566898346, 'eval_loss_3': -18.201282501220703, 'eval_loss_4': 1.8016952276229858, 'epoch': 26.1}
{'loss': 0.0062, 'grad_norm': 4.286911487579346, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.0028003326151520014, 'loss_2': 0.00339508056640625, 'loss_3': -16.45299530029297, 'loss_4': 2.076817512512207, 'epoch': 26.11}
{'loss': 0.0132, 'grad_norm': 4.296164035797119, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.0017173481173813343, 'loss_2': 0.011444091796875, 'loss_3': -16.230201721191406, 'loss_4': 1.59579598903656, 'epoch': 26.12}
{'loss': 0.007, 'grad_norm': 4.871389865875244, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.0058629778213799, 'loss_2': 0.0011501312255859375, 'loss_3': -16.35778045654297, 'loss_4': 1.570756196975708, 'epoch': 26.12}
{'loss': 0.0112, 'grad_norm': 4.706433296203613, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.0045705451630055904, 'loss_2': 0.00662994384765625, 'loss_3': -16.18084144592285, 'loss_4': 2.344301223754883, 'epoch': 26.13}
{'loss': 0.0061, 'grad_norm': 5.381895542144775, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.004390727262943983, 'loss_2': 0.001697540283203125, 'loss_3': -16.375837326049805, 'loss_4': 1.5130099058151245, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 11:14:37,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:37,147 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:51<11:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:44,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860587414354086, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00519624724984169, 'eval_loss_2': 0.0034096278250217438, 'eval_loss_3': -18.205408096313477, 'eval_loss_4': 1.7215039730072021, 'epoch': 26.13}
{'loss': 0.0086, 'grad_norm': 4.949443817138672, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.0033482233993709087, 'loss_2': 0.005279541015625, 'loss_3': -16.39755630493164, 'loss_4': 1.722536325454712, 'epoch': 26.14}
{'loss': 0.0061, 'grad_norm': 4.956545829772949, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.0037960687186568975, 'loss_2': 0.002353668212890625, 'loss_3': -16.49737548828125, 'loss_4': 1.4451056718826294, 'epoch': 26.15}
{'loss': 0.0141, 'grad_norm': 6.753117561340332, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.007068838458508253, 'loss_2': 0.006988525390625, 'loss_3': -16.182790756225586, 'loss_4': 1.8300360441207886, 'epoch': 26.15}
{'loss': 0.0093, 'grad_norm': 5.304189682006836, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.006641139276325703, 'loss_2': 0.0026378631591796875, 'loss_3': -16.437816619873047, 'loss_4': 2.257760524749756, 'epoch': 26.16}
{'loss': 0.0071, 'grad_norm': 4.61032247543335, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.0018425144953653216, 'loss_2': 0.005218505859375, 'loss_3': -16.49665069580078, 'loss_4': 0.8678834438323975, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 11:14:44,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:44,489 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:50:59<11:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:51,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008588573895394802, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005167468450963497, 'eval_loss_2': 0.003421105444431305, 'eval_loss_3': -18.212467193603516, 'eval_loss_4': 1.5964583158493042, 'epoch': 26.16}
{'loss': 0.008, 'grad_norm': 5.309940338134766, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.005870428401976824, 'loss_2': 0.0020809173583984375, 'loss_3': -16.443328857421875, 'loss_4': 1.83560311794281, 'epoch': 26.17}
{'loss': 0.0087, 'grad_norm': 5.025383472442627, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.007487262133508921, 'loss_2': 0.0011873245239257812, 'loss_3': -16.099790573120117, 'loss_4': 1.5097600221633911, 'epoch': 26.17}
{'loss': 0.0088, 'grad_norm': 6.555911064147949, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.00579339312389493, 'loss_2': 0.0029926300048828125, 'loss_3': -16.290557861328125, 'loss_4': 1.3435351848602295, 'epoch': 26.18}
{'loss': 0.0128, 'grad_norm': 4.504902362823486, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.004596223589032888, 'loss_2': 0.0081634521484375, 'loss_3': -16.2764949798584, 'loss_4': 2.2833595275878906, 'epoch': 26.19}
{'loss': 0.0069, 'grad_norm': 4.938368320465088, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.006835141684859991, 'loss_2': 8.952617645263672e-05, 'loss_3': -16.311447143554688, 'loss_4': 1.2873780727386475, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 11:14:51,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:51,830 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:51:06<11:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:14:59,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008027887903153896, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.515, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005111909471452236, 'eval_loss_2': 0.00291597843170166, 'eval_loss_3': -18.22418212890625, 'eval_loss_4': 1.4973660707473755, 'epoch': 26.19}
{'loss': 0.0061, 'grad_norm': 4.700438499450684, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.0027679908089339733, 'loss_2': 0.00333404541015625, 'loss_3': -16.423377990722656, 'loss_4': 1.7890352010726929, 'epoch': 26.2}
{'loss': 0.0097, 'grad_norm': 4.640650272369385, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.002058678073808551, 'loss_2': 0.00763702392578125, 'loss_3': -16.371200561523438, 'loss_4': 1.6818199157714844, 'epoch': 26.2}
{'loss': 0.0038, 'grad_norm': 4.62846565246582, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.0033098270650953054, 'loss_2': 0.0005064010620117188, 'loss_3': -16.45561408996582, 'loss_4': 1.6644384860992432, 'epoch': 26.21}
{'loss': 0.0123, 'grad_norm': 4.551634788513184, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.004922681488096714, 'loss_2': 0.00737762451171875, 'loss_3': -16.381351470947266, 'loss_4': 2.3723621368408203, 'epoch': 26.22}
{'loss': 0.0105, 'grad_norm': 9.171303749084473, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.010179372504353523, 'loss_2': 0.0002918243408203125, 'loss_3': -16.561248779296875, 'loss_4': 0.9255882501602173, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 11:14:59,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:14:59,178 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:13<11:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:06,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007862505502998829, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005055082030594349, 'eval_loss_2': 0.00280742347240448, 'eval_loss_3': -18.223880767822266, 'eval_loss_4': 1.4309165477752686, 'epoch': 26.22}
{'loss': 0.0097, 'grad_norm': 5.722758769989014, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.009009676054120064, 'loss_2': 0.0006809234619140625, 'loss_3': -16.13096809387207, 'loss_4': 2.1541929244995117, 'epoch': 26.23}
{'loss': 0.0042, 'grad_norm': 4.5599493980407715, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.002261220244690776, 'loss_2': 0.0019092559814453125, 'loss_3': -16.268415451049805, 'loss_4': 1.295133352279663, 'epoch': 26.23}
{'loss': 0.0138, 'grad_norm': 5.970387935638428, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.011958248913288116, 'loss_2': 0.0018053054809570312, 'loss_3': -16.33658218383789, 'loss_4': 0.9849345684051514, 'epoch': 26.24}
{'loss': 0.0064, 'grad_norm': 4.872300624847412, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.0021080095320940018, 'loss_2': 0.004299163818359375, 'loss_3': -16.30097198486328, 'loss_4': 1.5377676486968994, 'epoch': 26.24}
{'loss': 0.0089, 'grad_norm': 5.152448654174805, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.005242738872766495, 'loss_2': 0.00362396240234375, 'loss_3': -16.533058166503906, 'loss_4': 1.1980949640274048, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 11:15:06,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:06,521 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:21<11:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:13,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0085938461124897, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005184140522032976, 'eval_loss_2': 0.0034097060561180115, 'eval_loss_3': -18.224802017211914, 'eval_loss_4': 1.4223339557647705, 'epoch': 26.25}
{'loss': 0.0126, 'grad_norm': 7.341899871826172, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.011752334423363209, 'loss_2': 0.0008335113525390625, 'loss_3': -16.26595687866211, 'loss_4': 1.279388666152954, 'epoch': 26.26}
{'loss': 0.0054, 'grad_norm': 4.835164546966553, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.005176431033760309, 'loss_2': 0.0002319812774658203, 'loss_3': -16.296737670898438, 'loss_4': 2.0292749404907227, 'epoch': 26.26}
{'loss': 0.0151, 'grad_norm': 6.751398086547852, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.011525587178766727, 'loss_2': 0.003597259521484375, 'loss_3': -16.306093215942383, 'loss_4': 1.7816767692565918, 'epoch': 26.27}
{'loss': 0.0089, 'grad_norm': 5.1874189376831055, 'learning_rate': 3.75e-06, 'loss_1': 0.005516977049410343, 'loss_2': 0.0033931732177734375, 'loss_3': -16.182863235473633, 'loss_4': 1.1922008991241455, 'epoch': 26.27}
{'loss': 0.0054, 'grad_norm': 4.8127217292785645, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.003707184689119458, 'loss_2': 0.0017070770263671875, 'loss_3': -16.315994262695312, 'loss_4': 1.5579349994659424, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 11:15:13,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:13,867 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:28<10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:21,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008862495422363281, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.382, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005239546298980713, 'eval_loss_2': 0.0036229491233825684, 'eval_loss_3': -18.231794357299805, 'eval_loss_4': 1.4821078777313232, 'epoch': 26.28}
{'loss': 0.0078, 'grad_norm': 5.669163703918457, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.0074729910120368, 'loss_2': 0.00030350685119628906, 'loss_3': -16.210586547851562, 'loss_4': 1.5078518390655518, 'epoch': 26.28}
{'loss': 0.0065, 'grad_norm': 4.818352699279785, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.004167100414633751, 'loss_2': 0.002307891845703125, 'loss_3': -16.05067253112793, 'loss_4': 0.6436752080917358, 'epoch': 26.29}
{'loss': 0.0192, 'grad_norm': 10.611393928527832, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.017673498019576073, 'loss_2': 0.0014896392822265625, 'loss_3': -16.351093292236328, 'loss_4': 1.739306926727295, 'epoch': 26.3}
{'loss': 0.0106, 'grad_norm': 4.500565528869629, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.004441259894520044, 'loss_2': 0.006153106689453125, 'loss_3': -16.21857452392578, 'loss_4': 2.0639376640319824, 'epoch': 26.3}
{'loss': 0.0146, 'grad_norm': 5.646876335144043, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.0069976747035980225, 'loss_2': 0.00765228271484375, 'loss_3': -16.051095962524414, 'loss_4': 1.7585961818695068, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 11:15:21,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:21,220 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:35<10:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:28,570 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008978261612355709, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005105806980282068, 'eval_loss_2': 0.0038724541664123535, 'eval_loss_3': -18.23383140563965, 'eval_loss_4': 1.5318373441696167, 'epoch': 26.31}
{'loss': 0.0127, 'grad_norm': 4.539058685302734, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.00484861945733428, 'loss_2': 0.007843017578125, 'loss_3': -16.46542739868164, 'loss_4': 1.1460092067718506, 'epoch': 26.31}
{'loss': 0.0204, 'grad_norm': 11.142888069152832, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.01842409372329712, 'loss_2': 0.00196075439453125, 'loss_3': -16.124969482421875, 'loss_4': 2.6598849296569824, 'epoch': 26.32}
{'loss': 0.0085, 'grad_norm': 5.0117411613464355, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.00587391946464777, 'loss_2': 0.002628326416015625, 'loss_3': -16.41971206665039, 'loss_4': 1.462034821510315, 'epoch': 26.33}
{'loss': 0.0066, 'grad_norm': 4.65244197845459, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.0025735748931765556, 'loss_2': 0.0039825439453125, 'loss_3': -16.358142852783203, 'loss_4': 1.9692412614822388, 'epoch': 26.33}
{'loss': 0.0052, 'grad_norm': 5.200968265533447, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.004054443910717964, 'loss_2': 0.00115203857421875, 'loss_3': -16.45404052734375, 'loss_4': 2.027775764465332, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 11:15:28,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:28,571 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:43<10:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:35,924 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008966544643044472, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005070933140814304, 'eval_loss_2': 0.0038956105709075928, 'eval_loss_3': -18.230667114257812, 'eval_loss_4': 1.5611793994903564, 'epoch': 26.34}
{'loss': 0.0024, 'grad_norm': 4.368810176849365, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0015194157604128122, 'loss_2': 0.0008349418640136719, 'loss_3': -16.466636657714844, 'loss_4': 1.3732635974884033, 'epoch': 26.34}
{'loss': 0.0048, 'grad_norm': 4.657108306884766, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.00456842128187418, 'loss_2': 0.00024700164794921875, 'loss_3': -16.43023681640625, 'loss_4': 1.8969430923461914, 'epoch': 26.35}
{'loss': 0.0113, 'grad_norm': 5.783266544342041, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.0066379099152982235, 'loss_2': 0.00463104248046875, 'loss_3': -16.445453643798828, 'loss_4': 2.212848663330078, 'epoch': 26.35}
{'loss': 0.0157, 'grad_norm': 7.088767051696777, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.01254600752145052, 'loss_2': 0.003124237060546875, 'loss_3': -16.40083885192871, 'loss_4': 2.3521246910095215, 'epoch': 26.36}
{'loss': 0.0349, 'grad_norm': 13.793832778930664, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.027964478358626366, 'loss_2': 0.0069427490234375, 'loss_3': -16.34359359741211, 'loss_4': 1.1600126028060913, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 11:15:35,924 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:35,924 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:50<10:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:43,278 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00936843641102314, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.759, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0050373682752251625, 'eval_loss_2': 0.004331067204475403, 'eval_loss_3': -18.231380462646484, 'eval_loss_4': 1.5543895959854126, 'epoch': 26.37}
{'loss': 0.0161, 'grad_norm': 8.316953659057617, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.011512262746691704, 'loss_2': 0.00457763671875, 'loss_3': -16.410938262939453, 'loss_4': 2.045752763748169, 'epoch': 26.37}
{'loss': 0.009, 'grad_norm': 4.546982288360596, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.005902957636862993, 'loss_2': 0.00313568115234375, 'loss_3': -16.394973754882812, 'loss_4': 1.9012820720672607, 'epoch': 26.38}
{'loss': 0.0132, 'grad_norm': 9.45186710357666, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.012296642176806927, 'loss_2': 0.000926971435546875, 'loss_3': -16.407073974609375, 'loss_4': 1.8296648263931274, 'epoch': 26.38}
{'loss': 0.0101, 'grad_norm': 5.184753894805908, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.005511478055268526, 'loss_2': 0.004573822021484375, 'loss_3': -16.157907485961914, 'loss_4': 1.097824215888977, 'epoch': 26.39}
{'loss': 0.0115, 'grad_norm': 7.206597328186035, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.010822511278092861, 'loss_2': 0.000720977783203125, 'loss_3': -16.2357177734375, 'loss_4': 2.225038766860962, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 11:15:43,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:43,279 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:51:57<10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:50,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009070630185306072, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.509, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00514345895498991, 'eval_loss_2': 0.003927171230316162, 'eval_loss_3': -18.224878311157227, 'eval_loss_4': 1.5630683898925781, 'epoch': 26.4}
{'loss': 0.0033, 'grad_norm': 4.662358283996582, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.0022901699412614107, 'loss_2': 0.0009794235229492188, 'loss_3': -16.38203239440918, 'loss_4': 1.988538384437561, 'epoch': 26.4}
{'loss': 0.0084, 'grad_norm': 6.527736663818359, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.006444766651839018, 'loss_2': 0.0019702911376953125, 'loss_3': -16.471939086914062, 'loss_4': 1.8592641353607178, 'epoch': 26.41}
{'loss': 0.0168, 'grad_norm': 7.563947677612305, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.013581652194261551, 'loss_2': 0.003192901611328125, 'loss_3': -16.424386978149414, 'loss_4': 1.8334652185440063, 'epoch': 26.41}
{'loss': 0.0185, 'grad_norm': 11.879366874694824, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.0178434606641531, 'loss_2': 0.0006074905395507812, 'loss_3': -16.520919799804688, 'loss_4': 1.5827972888946533, 'epoch': 26.42}
{'loss': 0.0059, 'grad_norm': 4.729678630828857, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0021502445451915264, 'loss_2': 0.003795623779296875, 'loss_3': -16.302806854248047, 'loss_4': 1.7979865074157715, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 11:15:50,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:50,625 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:05<10:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:15:57,977 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008013701066374779, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004782324656844139, 'eval_loss_2': 0.0032313764095306396, 'eval_loss_3': -18.226726531982422, 'eval_loss_4': 1.5588220357894897, 'epoch': 26.42}
{'loss': 0.0069, 'grad_norm': 5.77405309677124, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.004839905072003603, 'loss_2': 0.0020427703857421875, 'loss_3': -16.344573974609375, 'loss_4': 1.3405158519744873, 'epoch': 26.43}
{'loss': 0.0056, 'grad_norm': 4.837711811065674, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.004395896103233099, 'loss_2': 0.001224517822265625, 'loss_3': -16.212305068969727, 'loss_4': 1.6456873416900635, 'epoch': 26.44}
{'loss': 0.0133, 'grad_norm': 12.612675666809082, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.010323382914066315, 'loss_2': 0.002960205078125, 'loss_3': -16.268478393554688, 'loss_4': 1.6363948583602905, 'epoch': 26.44}
{'loss': 0.0067, 'grad_norm': 4.779541492462158, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.004125168547034264, 'loss_2': 0.0026092529296875, 'loss_3': -16.344083786010742, 'loss_4': 1.8747363090515137, 'epoch': 26.45}
{'loss': 0.0084, 'grad_norm': 6.268301010131836, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.008017430081963539, 'loss_2': 0.0004248619079589844, 'loss_3': -16.353633880615234, 'loss_4': 1.6203703880310059, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 11:15:57,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:15:57,977 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:12<10:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:05,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00772114610299468, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.378, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00475706672295928, 'eval_loss_2': 0.0029640793800354004, 'eval_loss_3': -18.22209930419922, 'eval_loss_4': 1.5317788124084473, 'epoch': 26.45}
{'loss': 0.0043, 'grad_norm': 4.4387078285217285, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.002467965707182884, 'loss_2': 0.0018720626831054688, 'loss_3': -16.29404640197754, 'loss_4': 1.8561513423919678, 'epoch': 26.46}
{'loss': 0.0071, 'grad_norm': 3.9661319255828857, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0027718779165297747, 'loss_2': 0.00437164306640625, 'loss_3': -16.442092895507812, 'loss_4': 1.2086389064788818, 'epoch': 26.47}
{'loss': 0.0053, 'grad_norm': 4.626862049102783, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.004425686784088612, 'loss_2': 0.0008649826049804688, 'loss_3': -16.265642166137695, 'loss_4': 1.675604224205017, 'epoch': 26.47}
{'loss': 0.0094, 'grad_norm': 5.416000843048096, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.006448862608522177, 'loss_2': 0.002933502197265625, 'loss_3': -16.42247772216797, 'loss_4': 2.003653049468994, 'epoch': 26.48}
{'loss': 0.0059, 'grad_norm': 5.03108024597168, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.0046553886495530605, 'loss_2': 0.0012578964233398438, 'loss_3': -16.367834091186523, 'loss_4': 1.543853759765625, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 11:16:05,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:05,318 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:19<10:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:16:12,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007767303381115198, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004753990564495325, 'eval_loss_2': 0.003013312816619873, 'eval_loss_3': -18.2255802154541, 'eval_loss_4': 1.5002055168151855, 'epoch': 26.48}
{'loss': 0.0077, 'grad_norm': 4.660856246948242, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.0029121837578713894, 'loss_2': 0.00473785400390625, 'loss_3': -16.528850555419922, 'loss_4': 1.565209150314331, 'epoch': 26.49}
{'loss': 0.0094, 'grad_norm': 5.841684818267822, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.007887586019933224, 'loss_2': 0.0014810562133789062, 'loss_3': -16.298812866210938, 'loss_4': 1.520876169204712, 'epoch': 26.49}
{'loss': 0.0107, 'grad_norm': 4.363834857940674, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.006713563110679388, 'loss_2': 0.00397491455078125, 'loss_3': -16.337562561035156, 'loss_4': 1.9938087463378906, 'epoch': 26.5}
{'loss': 0.0165, 'grad_norm': 5.111352920532227, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.009754315949976444, 'loss_2': 0.00672149658203125, 'loss_3': -16.49120330810547, 'loss_4': 1.9936407804489136, 'epoch': 26.51}
{'loss': 0.0039, 'grad_norm': 4.451996803283691, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.002770423423498869, 'loss_2': 0.001140594482421875, 'loss_3': -16.459064483642578, 'loss_4': 1.421201467514038, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 11:16:12,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:12,650 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:27<10:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:19,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008096650242805481, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0047980546951293945, 'eval_loss_2': 0.0032985955476760864, 'eval_loss_3': -18.224281311035156, 'eval_loss_4': 1.467389464378357, 'epoch': 26.51}
{'loss': 0.0098, 'grad_norm': 5.0490217208862305, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.005202185828238726, 'loss_2': 0.00455474853515625, 'loss_3': -16.301578521728516, 'loss_4': 1.4002584218978882, 'epoch': 26.52}
{'loss': 0.0037, 'grad_norm': 4.477651119232178, 'learning_rate': 3.5e-06, 'loss_1': 0.003526141634210944, 'loss_2': 0.00014030933380126953, 'loss_3': -16.29815673828125, 'loss_4': 1.43726646900177, 'epoch': 26.52}
{'loss': 0.012, 'grad_norm': 5.63059139251709, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.00961784552782774, 'loss_2': 0.002349853515625, 'loss_3': -16.514482498168945, 'loss_4': 1.6606148481369019, 'epoch': 26.53}
{'loss': 0.0032, 'grad_norm': 4.4641432762146, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.0026579988189041615, 'loss_2': 0.0005135536193847656, 'loss_3': -16.440872192382812, 'loss_4': 1.4982914924621582, 'epoch': 26.53}
{'loss': 0.0082, 'grad_norm': 6.72771692276001, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.007696969900280237, 'loss_2': 0.00045752525329589844, 'loss_3': -16.421356201171875, 'loss_4': 1.6271004676818848, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 11:16:19,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:19,993 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:34<10:20,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:16:27,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007963428273797035, 'eval_runtime': 4.0037, 'eval_samples_per_second': 255.762, 'eval_steps_per_second': 3.996, 'eval_loss_1': 0.004956611432135105, 'eval_loss_2': 0.0030068159103393555, 'eval_loss_3': -18.226551055908203, 'eval_loss_4': 1.4160542488098145, 'epoch': 26.54}
{'loss': 0.0045, 'grad_norm': 4.460332870483398, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.003178859129548073, 'loss_2': 0.001361846923828125, 'loss_3': -16.23744773864746, 'loss_4': 0.9050258994102478, 'epoch': 26.55}
{'loss': 0.0188, 'grad_norm': 8.166645050048828, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.015634039416909218, 'loss_2': 0.0032138824462890625, 'loss_3': -16.291494369506836, 'loss_4': 2.0127878189086914, 'epoch': 26.55}
{'loss': 0.0084, 'grad_norm': 5.776374816894531, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.0071926480159163475, 'loss_2': 0.0012331008911132812, 'loss_3': -16.564241409301758, 'loss_4': 1.196239709854126, 'epoch': 26.56}
{'loss': 0.0077, 'grad_norm': 4.784735679626465, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.004208661150187254, 'loss_2': 0.0034580230712890625, 'loss_3': -16.263553619384766, 'loss_4': 1.126523733139038, 'epoch': 26.56}
{'loss': 0.0079, 'grad_norm': 4.591883659362793, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.0036176741123199463, 'loss_2': 0.004238128662109375, 'loss_3': -16.465002059936523, 'loss_4': 1.583414077758789, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 11:16:27,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:27,535 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:42<10:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:34,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007886403240263462, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005106160417199135, 'eval_loss_2': 0.002780243754386902, 'eval_loss_3': -18.22723388671875, 'eval_loss_4': 1.4016304016113281, 'epoch': 26.57}
{'loss': 0.0101, 'grad_norm': 4.42025089263916, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.002726671053096652, 'loss_2': 0.007419586181640625, 'loss_3': -16.394628524780273, 'loss_4': 1.7094470262527466, 'epoch': 26.58}
{'loss': 0.0235, 'grad_norm': 11.164216995239258, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.021099647507071495, 'loss_2': 0.0023746490478515625, 'loss_3': -16.53666877746582, 'loss_4': 1.2023413181304932, 'epoch': 26.58}
{'loss': 0.0087, 'grad_norm': 5.178812503814697, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.006570221856236458, 'loss_2': 0.00213623046875, 'loss_3': -16.301834106445312, 'loss_4': 1.1882917881011963, 'epoch': 26.59}
{'loss': 0.0105, 'grad_norm': 6.104487895965576, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.008552909828722477, 'loss_2': 0.001964569091796875, 'loss_3': -16.410457611083984, 'loss_4': 1.6272106170654297, 'epoch': 26.59}
{'loss': 0.0075, 'grad_norm': 4.887359619140625, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.0038678068667650223, 'loss_2': 0.0036067962646484375, 'loss_3': -16.34455108642578, 'loss_4': 1.2601479291915894, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 11:16:34,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:34,885 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:49<10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:42,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007576046511530876, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.638, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004855959676206112, 'eval_loss_2': 0.002720087766647339, 'eval_loss_3': -18.226415634155273, 'eval_loss_4': 1.3849235773086548, 'epoch': 26.6}
{'loss': 0.0141, 'grad_norm': 6.02492094039917, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.008342178538441658, 'loss_2': 0.00572967529296875, 'loss_3': -16.36042594909668, 'loss_4': 1.8957771062850952, 'epoch': 26.6}
{'loss': 0.007, 'grad_norm': 4.643279552459717, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.003996600862592459, 'loss_2': 0.003032684326171875, 'loss_3': -16.118581771850586, 'loss_4': 1.759429693222046, 'epoch': 26.61}
{'loss': 0.0067, 'grad_norm': 4.330090522766113, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.005569037515670061, 'loss_2': 0.0011692047119140625, 'loss_3': -16.352474212646484, 'loss_4': 1.4780702590942383, 'epoch': 26.62}
{'loss': 0.0234, 'grad_norm': 7.54606819152832, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.016024785116314888, 'loss_2': 0.00739288330078125, 'loss_3': -16.542463302612305, 'loss_4': 1.4816222190856934, 'epoch': 26.62}
{'loss': 0.0049, 'grad_norm': 4.614588260650635, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.0045521981082856655, 'loss_2': 0.0003871917724609375, 'loss_3': -16.403629302978516, 'loss_4': 1.8525941371917725, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 11:16:42,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:42,235 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:52:56<09:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:49,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008227881044149399, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005227964371442795, 'eval_loss_2': 0.002999916672706604, 'eval_loss_3': -18.223236083984375, 'eval_loss_4': 1.33184015750885, 'epoch': 26.63}
{'loss': 0.0075, 'grad_norm': 4.836209774017334, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.003289977554231882, 'loss_2': 0.00421142578125, 'loss_3': -16.33161735534668, 'loss_4': 1.1497597694396973, 'epoch': 26.63}
{'loss': 0.0112, 'grad_norm': 4.749260902404785, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.0034520660992711782, 'loss_2': 0.007762908935546875, 'loss_3': -16.468408584594727, 'loss_4': 1.0131357908248901, 'epoch': 26.64}
{'loss': 0.0132, 'grad_norm': 4.849903583526611, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.004582983907312155, 'loss_2': 0.00860595703125, 'loss_3': -16.341880798339844, 'loss_4': 1.6785404682159424, 'epoch': 26.65}
{'loss': 0.0045, 'grad_norm': 4.340878009796143, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.004380696453154087, 'loss_2': 9.298324584960938e-05, 'loss_3': -16.322895050048828, 'loss_4': 1.0253539085388184, 'epoch': 26.65}
{'loss': 0.0121, 'grad_norm': 5.957010746002197, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.009174850769340992, 'loss_2': 0.0029621124267578125, 'loss_3': -16.328641891479492, 'loss_4': 2.0390710830688477, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 11:16:49,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:49,578 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:04<09:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:16:56,919 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008805125951766968, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.399, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005461701191961765, 'eval_loss_2': 0.003343425691127777, 'eval_loss_3': -18.215105056762695, 'eval_loss_4': 1.2914360761642456, 'epoch': 26.66}
{'loss': 0.0146, 'grad_norm': 6.8406853675842285, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.009774132631719112, 'loss_2': 0.00484466552734375, 'loss_3': -16.606647491455078, 'loss_4': 1.2102683782577515, 'epoch': 26.66}
{'loss': 0.0088, 'grad_norm': 5.255117893218994, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.006195329129695892, 'loss_2': 0.002651214599609375, 'loss_3': -16.392475128173828, 'loss_4': 0.33658939599990845, 'epoch': 26.67}
{'loss': 0.0072, 'grad_norm': 4.692964553833008, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.005267711356282234, 'loss_2': 0.00196075439453125, 'loss_3': -16.36756134033203, 'loss_4': 1.4707612991333008, 'epoch': 26.67}
{'loss': 0.006, 'grad_norm': 4.530471324920654, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.001990574412047863, 'loss_2': 0.0040130615234375, 'loss_3': -16.285911560058594, 'loss_4': 1.3611325025558472, 'epoch': 26.68}
{'loss': 0.0087, 'grad_norm': 4.891462802886963, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.0031783003360033035, 'loss_2': 0.0055084228515625, 'loss_3': -16.276607513427734, 'loss_4': 1.529888391494751, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 11:16:56,919 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:16:56,919 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:11<09:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:04,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008758307434618473, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.089, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00538547383621335, 'eval_loss_2': 0.0033728331327438354, 'eval_loss_3': -18.210372924804688, 'eval_loss_4': 1.2962416410446167, 'epoch': 26.69}
{'loss': 0.0059, 'grad_norm': 5.019698619842529, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.003985995892435312, 'loss_2': 0.0019054412841796875, 'loss_3': -16.29066276550293, 'loss_4': 1.293895959854126, 'epoch': 26.69}
{'loss': 0.0103, 'grad_norm': 4.481420040130615, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0035779536701738834, 'loss_2': 0.0067596435546875, 'loss_3': -16.32952880859375, 'loss_4': 0.5245004892349243, 'epoch': 26.7}
{'loss': 0.0223, 'grad_norm': 12.094097137451172, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.016354814171791077, 'loss_2': 0.005924224853515625, 'loss_3': -16.416717529296875, 'loss_4': 1.8620388507843018, 'epoch': 26.7}
{'loss': 0.0123, 'grad_norm': 6.575460433959961, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.011080367490649223, 'loss_2': 0.0012645721435546875, 'loss_3': -16.58386993408203, 'loss_4': 1.281832218170166, 'epoch': 26.71}
{'loss': 0.0123, 'grad_norm': 4.751523971557617, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.005716585088521242, 'loss_2': 0.00659942626953125, 'loss_3': -16.20673179626465, 'loss_4': 1.4738065004348755, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 11:17:04,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:04,264 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:18<09:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:11,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008035751059651375, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00487798685207963, 'eval_loss_2': 0.0031577646732330322, 'eval_loss_3': -18.20237922668457, 'eval_loss_4': 1.2971802949905396, 'epoch': 26.72}
{'loss': 0.0073, 'grad_norm': 4.860957622528076, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.0042572226375341415, 'loss_2': 0.003078460693359375, 'loss_3': -16.165613174438477, 'loss_4': 1.3530678749084473, 'epoch': 26.72}
{'loss': 0.0109, 'grad_norm': 4.742461204528809, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.007385865319520235, 'loss_2': 0.003475189208984375, 'loss_3': -16.233016967773438, 'loss_4': 0.5838837623596191, 'epoch': 26.73}
{'loss': 0.0076, 'grad_norm': 5.785503387451172, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.006839006207883358, 'loss_2': 0.0007996559143066406, 'loss_3': -16.374980926513672, 'loss_4': 1.4968644380569458, 'epoch': 26.73}
{'loss': 0.0046, 'grad_norm': 4.349620819091797, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.0026234688702970743, 'loss_2': 0.001956939697265625, 'loss_3': -16.5259952545166, 'loss_4': 1.9138816595077515, 'epoch': 26.74}
{'loss': 0.0098, 'grad_norm': 4.447834491729736, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.004634034354239702, 'loss_2': 0.00516510009765625, 'loss_3': -16.4820556640625, 'loss_4': 1.1773866415023804, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 11:17:11,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:11,608 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:26<09:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:18,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00826425850391388, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.444, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0045418282970786095, 'eval_loss_2': 0.0037224292755126953, 'eval_loss_3': -18.198270797729492, 'eval_loss_4': 1.3391714096069336, 'epoch': 26.74}
{'loss': 0.0212, 'grad_norm': 11.991192817687988, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.01815812848508358, 'loss_2': 0.003082275390625, 'loss_3': -16.159133911132812, 'loss_4': 1.4697962999343872, 'epoch': 26.75}
{'loss': 0.0028, 'grad_norm': 4.16070032119751, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.0020013845060020685, 'loss_2': 0.0007901191711425781, 'loss_3': -16.483991622924805, 'loss_4': 1.1578679084777832, 'epoch': 26.76}
{'loss': 0.0189, 'grad_norm': 6.211610794067383, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.011810136958956718, 'loss_2': 0.007080078125, 'loss_3': -16.292957305908203, 'loss_4': 1.2689452171325684, 'epoch': 26.76}
{'loss': 0.0086, 'grad_norm': 5.517709732055664, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.006663061212748289, 'loss_2': 0.0019016265869140625, 'loss_3': -16.205272674560547, 'loss_4': 1.7542331218719482, 'epoch': 26.77}
{'loss': 0.0199, 'grad_norm': 7.016348838806152, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.008591555058956146, 'loss_2': 0.011322021484375, 'loss_3': -16.260547637939453, 'loss_4': 1.534911870956421, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 11:17:18,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:18,962 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:33<09:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:26,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008688939735293388, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.167, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.0048548257909715176, 'eval_loss_2': 0.0038341134786605835, 'eval_loss_3': -18.20418357849121, 'eval_loss_4': 1.3705158233642578, 'epoch': 26.77}
{'loss': 0.0173, 'grad_norm': 10.315390586853027, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.016158444806933403, 'loss_2': 0.0011568069458007812, 'loss_3': -16.080060958862305, 'loss_4': 1.6987603902816772, 'epoch': 26.78}
{'loss': 0.0094, 'grad_norm': 4.755762100219727, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.002916337689384818, 'loss_2': 0.00644683837890625, 'loss_3': -16.342426300048828, 'loss_4': 1.5984504222869873, 'epoch': 26.78}
{'loss': 0.0144, 'grad_norm': 7.4987030029296875, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.012468471191823483, 'loss_2': 0.0019073486328125, 'loss_3': -16.534828186035156, 'loss_4': 1.463263750076294, 'epoch': 26.79}
{'loss': 0.0062, 'grad_norm': 4.920773983001709, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.002701649209484458, 'loss_2': 0.00347900390625, 'loss_3': -16.283538818359375, 'loss_4': 1.1872994899749756, 'epoch': 26.8}
{'loss': 0.0119, 'grad_norm': 4.424696445465088, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.007019508630037308, 'loss_2': 0.004913330078125, 'loss_3': -16.220176696777344, 'loss_4': 1.2545814514160156, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 11:17:26,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:26,322 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:40<09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:33,672 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008601665496826172, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.797, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00453095231205225, 'eval_loss_2': 0.004070714116096497, 'eval_loss_3': -18.204017639160156, 'eval_loss_4': 1.413909673690796, 'epoch': 26.8}
{'loss': 0.0164, 'grad_norm': 7.100093841552734, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.01613999903202057, 'loss_2': 0.0002541542053222656, 'loss_3': -16.372920989990234, 'loss_4': 1.3782390356063843, 'epoch': 26.81}
{'loss': 0.0307, 'grad_norm': 18.540678024291992, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.02717668190598488, 'loss_2': 0.003490447998046875, 'loss_3': -16.228775024414062, 'loss_4': 1.7083160877227783, 'epoch': 26.81}
{'loss': 0.0051, 'grad_norm': 4.911087989807129, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.0021908979397267103, 'loss_2': 0.002887725830078125, 'loss_3': -16.393033981323242, 'loss_4': 1.3760160207748413, 'epoch': 26.82}
{'loss': 0.0066, 'grad_norm': 4.839277744293213, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.006258070934563875, 'loss_2': 0.00030231475830078125, 'loss_3': -16.53466796875, 'loss_4': 1.5404469966888428, 'epoch': 26.83}
{'loss': 0.0022, 'grad_norm': 4.633280277252197, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.002047187415882945, 'loss_2': 0.0001995563507080078, 'loss_3': -16.518699645996094, 'loss_4': 1.2977831363677979, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 11:17:33,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:33,672 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:48<09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:41,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008651543408632278, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0047293188981711864, 'eval_loss_2': 0.003922224044799805, 'eval_loss_3': -18.204801559448242, 'eval_loss_4': 1.4416320323944092, 'epoch': 26.83}
{'loss': 0.0072, 'grad_norm': 5.366527557373047, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.005613085813820362, 'loss_2': 0.0016298294067382812, 'loss_3': -16.22218894958496, 'loss_4': 1.997117519378662, 'epoch': 26.84}
{'loss': 0.0066, 'grad_norm': 4.861672401428223, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.0035097268410027027, 'loss_2': 0.00311279296875, 'loss_3': -16.484779357910156, 'loss_4': 2.2482190132141113, 'epoch': 26.84}
{'loss': 0.003, 'grad_norm': 4.6475419998168945, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.002534773899242282, 'loss_2': 0.00047469139099121094, 'loss_3': -16.381149291992188, 'loss_4': 1.2658824920654297, 'epoch': 26.85}
{'loss': 0.0086, 'grad_norm': 4.445860862731934, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.002096055308356881, 'loss_2': 0.0064544677734375, 'loss_3': -16.461105346679688, 'loss_4': 1.567695140838623, 'epoch': 26.85}
{'loss': 0.0113, 'grad_norm': 5.908339500427246, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.007657269015908241, 'loss_2': 0.0036716461181640625, 'loss_3': -16.283607482910156, 'loss_4': 1.2300834655761719, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 11:17:41,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:41,018 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:53:55<09:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:48,365 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00828147679567337, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004778674338012934, 'eval_loss_2': 0.0035028010606765747, 'eval_loss_3': -18.203081130981445, 'eval_loss_4': 1.4780945777893066, 'epoch': 26.86}
{'loss': 0.0054, 'grad_norm': 4.381540775299072, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.0037699518725275993, 'loss_2': 0.001605987548828125, 'loss_3': -16.20589256286621, 'loss_4': 1.9037933349609375, 'epoch': 26.87}
{'loss': 0.0133, 'grad_norm': 6.731472492218018, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.010572457686066628, 'loss_2': 0.0027313232421875, 'loss_3': -16.208656311035156, 'loss_4': 1.3019485473632812, 'epoch': 26.87}
{'loss': 0.0108, 'grad_norm': 6.69541597366333, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.008290352299809456, 'loss_2': 0.0025043487548828125, 'loss_3': -16.264408111572266, 'loss_4': 1.627974510192871, 'epoch': 26.88}
{'loss': 0.0032, 'grad_norm': 4.495584487915039, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.00220046890899539, 'loss_2': 0.0009646415710449219, 'loss_3': -16.40829086303711, 'loss_4': 1.739457130432129, 'epoch': 26.88}
{'loss': 0.0098, 'grad_norm': 5.491171360015869, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.009087828919291496, 'loss_2': 0.0007562637329101562, 'loss_3': -16.481124877929688, 'loss_4': 1.832067847251892, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 11:17:48,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:48,365 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:54:02<09:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:17:55,705 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008513856679201126, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004939433187246323, 'eval_loss_2': 0.0035744234919548035, 'eval_loss_3': -18.200902938842773, 'eval_loss_4': 1.513363242149353, 'epoch': 26.89}
{'loss': 0.0111, 'grad_norm': 4.5653791427612305, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.002960499841719866, 'loss_2': 0.00811767578125, 'loss_3': -16.49944305419922, 'loss_4': 1.4306424856185913, 'epoch': 26.9}
{'loss': 0.0087, 'grad_norm': 4.6218695640563965, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.003115262370556593, 'loss_2': 0.00556182861328125, 'loss_3': -16.491710662841797, 'loss_4': 1.8233058452606201, 'epoch': 26.9}
{'loss': 0.0073, 'grad_norm': 4.950352191925049, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.004533243831247091, 'loss_2': 0.002811431884765625, 'loss_3': -16.299152374267578, 'loss_4': 1.1548551321029663, 'epoch': 26.91}
{'loss': 0.008, 'grad_norm': 5.575455188751221, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.00558685977011919, 'loss_2': 0.002414703369140625, 'loss_3': -16.298355102539062, 'loss_4': 1.4235713481903076, 'epoch': 26.91}
{'loss': 0.0099, 'grad_norm': 4.536048889160156, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.0024172768462449312, 'loss_2': 0.007450103759765625, 'loss_3': -16.49810791015625, 'loss_4': 1.4410456418991089, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 11:17:55,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:17:55,705 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:10<09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:03,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008845483884215355, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.498, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005144394002854824, 'eval_loss_2': 0.0037010908126831055, 'eval_loss_3': -18.204559326171875, 'eval_loss_4': 1.5350552797317505, 'epoch': 26.92}
{'loss': 0.0078, 'grad_norm': 4.044145107269287, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.002341129817068577, 'loss_2': 0.00543212890625, 'loss_3': -16.346485137939453, 'loss_4': 1.4637593030929565, 'epoch': 26.92}
{'loss': 0.0071, 'grad_norm': 4.405237197875977, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.004613740835338831, 'loss_2': 0.0024967193603515625, 'loss_3': -16.10504913330078, 'loss_4': 1.312704086303711, 'epoch': 26.93}
{'loss': 0.0055, 'grad_norm': 5.188465118408203, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.0031320666894316673, 'loss_2': 0.0023288726806640625, 'loss_3': -16.29424285888672, 'loss_4': 1.4050381183624268, 'epoch': 26.94}
{'loss': 0.0099, 'grad_norm': 5.135788917541504, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.003102724440395832, 'loss_2': 0.006832122802734375, 'loss_3': -16.345569610595703, 'loss_4': 1.169614553451538, 'epoch': 26.94}
{'loss': 0.0123, 'grad_norm': 7.3436503410339355, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.0117881428450346, 'loss_2': 0.0004830360412597656, 'loss_3': -16.27474594116211, 'loss_4': 1.8859386444091797, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 11:18:03,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:03,063 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:17<09:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:10,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009059229865670204, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.655, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005241939797997475, 'eval_loss_2': 0.0038172900676727295, 'eval_loss_3': -18.21053123474121, 'eval_loss_4': 1.52506685256958, 'epoch': 26.95}
{'loss': 0.0077, 'grad_norm': 5.029301643371582, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.003628798294812441, 'loss_2': 0.00406646728515625, 'loss_3': -16.4757022857666, 'loss_4': 1.2588834762573242, 'epoch': 26.95}
{'loss': 0.0049, 'grad_norm': 4.614632606506348, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.004084036685526371, 'loss_2': 0.0008478164672851562, 'loss_3': -16.3066463470459, 'loss_4': 1.7367899417877197, 'epoch': 26.96}
{'loss': 0.0085, 'grad_norm': 4.001340866088867, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.003523953026160598, 'loss_2': 0.0049285888671875, 'loss_3': -16.123733520507812, 'loss_4': 1.057944416999817, 'epoch': 26.97}
{'loss': 0.0097, 'grad_norm': 4.603992938995361, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.0043803672306239605, 'loss_2': 0.00530242919921875, 'loss_3': -16.532548904418945, 'loss_4': 1.1218761205673218, 'epoch': 26.97}
{'loss': 0.0091, 'grad_norm': 5.685207843780518, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.004231054801493883, 'loss_2': 0.00487518310546875, 'loss_3': -16.233257293701172, 'loss_4': 1.4833773374557495, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 11:18:10,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:10,418 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:24<08:22,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 11:18:17,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009549152106046677, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.241, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00548139913007617, 'eval_loss_2': 0.004067752510309219, 'eval_loss_3': -18.216676712036133, 'eval_loss_4': 1.4903677701950073, 'epoch': 26.98}
{'loss': 0.0088, 'grad_norm': 4.659535884857178, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.0038479994982481003, 'loss_2': 0.004985809326171875, 'loss_3': -16.48625946044922, 'loss_4': 1.64275062084198, 'epoch': 26.98}
{'loss': 0.0052, 'grad_norm': 5.040580749511719, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0047005703672766685, 'loss_2': 0.0004677772521972656, 'loss_3': -16.048423767089844, 'loss_4': 1.1318490505218506, 'epoch': 26.99}
{'loss': 0.0127, 'grad_norm': 6.74540376663208, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.007157519925385714, 'loss_2': 0.00556182861328125, 'loss_3': -16.320083618164062, 'loss_4': 1.5081732273101807, 'epoch': 26.99}
{'loss': 0.0012, 'grad_norm': 6.110705852508545, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.0007253485382534564, 'loss_2': 0.00047397613525390625, 'loss_3': -16.30823516845703, 'loss_4': 1.6517722606658936, 'epoch': 27.0}
{'loss': 0.0063, 'grad_norm': 5.452280044555664, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.004832017235457897, 'loss_2': 0.0015020370483398438, 'loss_3': -16.252273559570312, 'loss_4': 1.1788053512573242, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 11:18:17,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:17,445 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:32<08:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:18:24,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010317746549844742, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0053280615247786045, 'eval_loss_2': 0.004989683628082275, 'eval_loss_3': -18.222206115722656, 'eval_loss_4': 1.4839370250701904, 'epoch': 27.01}
{'loss': 0.0052, 'grad_norm': 4.199093818664551, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.0029750200919806957, 'loss_2': 0.00226593017578125, 'loss_3': -16.27478790283203, 'loss_4': 1.4951627254486084, 'epoch': 27.01}
{'loss': 0.006, 'grad_norm': 4.449566841125488, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.0021416996605694294, 'loss_2': 0.003875732421875, 'loss_3': -16.395950317382812, 'loss_4': 0.9901189804077148, 'epoch': 27.02}
{'loss': 0.0091, 'grad_norm': 6.327516555786133, 'learning_rate': 3e-06, 'loss_1': 0.007905804552137852, 'loss_2': 0.0012311935424804688, 'loss_3': -16.564773559570312, 'loss_4': 1.36720609664917, 'epoch': 27.02}
{'loss': 0.0187, 'grad_norm': 5.258701324462891, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.012153314426541328, 'loss_2': 0.00658416748046875, 'loss_3': -16.310009002685547, 'loss_4': 1.6046522855758667, 'epoch': 27.03}
{'loss': 0.0153, 'grad_norm': 8.187381744384766, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.009257752448320389, 'loss_2': 0.006092071533203125, 'loss_3': -16.324426651000977, 'loss_4': 1.6581380367279053, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 11:18:24,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:24,791 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:39<08:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:18:32,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011246876791119576, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0052671586163342, 'eval_loss_2': 0.005979716777801514, 'eval_loss_3': -18.219635009765625, 'eval_loss_4': 1.4779140949249268, 'epoch': 27.03}
{'loss': 0.0063, 'grad_norm': 4.608328819274902, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.002711202949285507, 'loss_2': 0.00360870361328125, 'loss_3': -16.3858699798584, 'loss_4': 1.6700067520141602, 'epoch': 27.04}
{'loss': 0.0042, 'grad_norm': 4.318081378936768, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.002245761454105377, 'loss_2': 0.001956939697265625, 'loss_3': -16.40243148803711, 'loss_4': 1.2912352085113525, 'epoch': 27.05}
{'loss': 0.0052, 'grad_norm': 4.419199466705322, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.004024956375360489, 'loss_2': 0.0011749267578125, 'loss_3': -16.505279541015625, 'loss_4': 1.7249993085861206, 'epoch': 27.05}
{'loss': 0.0056, 'grad_norm': 4.716376304626465, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.0050805481150746346, 'loss_2': 0.0005636215209960938, 'loss_3': -16.247962951660156, 'loss_4': 1.1567413806915283, 'epoch': 27.06}
{'loss': 0.0107, 'grad_norm': 6.110867023468018, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.006980403326451778, 'loss_2': 0.0037555694580078125, 'loss_3': -16.439538955688477, 'loss_4': 1.8700051307678223, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 11:18:32,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:32,133 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:46<08:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:39,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010653212666511536, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005232825409621, 'eval_loss_2': 0.005420386791229248, 'eval_loss_3': -18.226577758789062, 'eval_loss_4': 1.4746252298355103, 'epoch': 27.06}
{'loss': 0.0124, 'grad_norm': 7.8306169509887695, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.010851189494132996, 'loss_2': 0.0015964508056640625, 'loss_3': -16.28348159790039, 'loss_4': 1.1429635286331177, 'epoch': 27.07}
{'loss': 0.0043, 'grad_norm': 4.727293491363525, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.0031088506802916527, 'loss_2': 0.0012073516845703125, 'loss_3': -16.267581939697266, 'loss_4': 1.9497359991073608, 'epoch': 27.08}
{'loss': 0.0057, 'grad_norm': 4.654121398925781, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.0035899023059755564, 'loss_2': 0.002140045166015625, 'loss_3': -16.554861068725586, 'loss_4': 1.5988961458206177, 'epoch': 27.08}
{'loss': 0.0095, 'grad_norm': 5.299778461456299, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.008220274932682514, 'loss_2': 0.001232147216796875, 'loss_3': -16.29307746887207, 'loss_4': 1.8602643013000488, 'epoch': 27.09}
{'loss': 0.0055, 'grad_norm': 4.739865779876709, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.003721413901075721, 'loss_2': 0.001811981201171875, 'loss_3': -16.36907958984375, 'loss_4': 1.3831212520599365, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 11:18:39,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:39,482 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:54:54<08:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:46,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009791401214897633, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.46, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004986640997231007, 'eval_loss_2': 0.004804760217666626, 'eval_loss_3': -18.231204986572266, 'eval_loss_4': 1.4978636503219604, 'epoch': 27.09}
{'loss': 0.0065, 'grad_norm': 4.694382667541504, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.002195595297962427, 'loss_2': 0.00426483154296875, 'loss_3': -16.398719787597656, 'loss_4': 1.5352163314819336, 'epoch': 27.1}
{'loss': 0.0132, 'grad_norm': 4.766368389129639, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.006830716039985418, 'loss_2': 0.00634765625, 'loss_3': -16.048824310302734, 'loss_4': 1.8840502500534058, 'epoch': 27.1}
{'loss': 0.0128, 'grad_norm': 5.20546817779541, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.005727548152208328, 'loss_2': 0.007045745849609375, 'loss_3': -16.425321578979492, 'loss_4': 1.4317866563796997, 'epoch': 27.11}
{'loss': 0.0053, 'grad_norm': 4.3930745124816895, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.0014685881324112415, 'loss_2': 0.003826141357421875, 'loss_3': -16.296497344970703, 'loss_4': 1.6660643815994263, 'epoch': 27.12}
{'loss': 0.0116, 'grad_norm': 4.302262306213379, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.004255934618413448, 'loss_2': 0.007354736328125, 'loss_3': -16.54143524169922, 'loss_4': 1.2165076732635498, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 11:18:46,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:46,827 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:55:01<08:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:18:54,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00935981422662735, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.995, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004843779373914003, 'eval_loss_2': 0.004516035318374634, 'eval_loss_3': -18.226974487304688, 'eval_loss_4': 1.527165174484253, 'epoch': 27.12}
{'loss': 0.0079, 'grad_norm': 5.231472492218018, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.006754656787961721, 'loss_2': 0.0011272430419921875, 'loss_3': -16.185335159301758, 'loss_4': 1.6785516738891602, 'epoch': 27.13}
{'loss': 0.007, 'grad_norm': 5.205523490905762, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.005276882089674473, 'loss_2': 0.001678466796875, 'loss_3': -16.46009635925293, 'loss_4': 1.384589672088623, 'epoch': 27.13}
{'loss': 0.0071, 'grad_norm': 4.825153827667236, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.002995489165186882, 'loss_2': 0.004085540771484375, 'loss_3': -16.350749969482422, 'loss_4': 1.0448458194732666, 'epoch': 27.14}
{'loss': 0.0049, 'grad_norm': 4.550786972045898, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.0021914870012551546, 'loss_2': 0.0027313232421875, 'loss_3': -16.38323974609375, 'loss_4': 1.4619807004928589, 'epoch': 27.15}
{'loss': 0.0096, 'grad_norm': 6.639270782470703, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.007322811987251043, 'loss_2': 0.002239227294921875, 'loss_3': -16.120742797851562, 'loss_4': 1.601219654083252, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 11:18:54,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:18:54,170 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:08<08:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:01,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009186213836073875, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004607982002198696, 'eval_loss_2': 0.004578232765197754, 'eval_loss_3': -18.220783233642578, 'eval_loss_4': 1.5574367046356201, 'epoch': 27.15}
{'loss': 0.0071, 'grad_norm': 4.706136703491211, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.00522840628400445, 'loss_2': 0.00183868408203125, 'loss_3': -16.359580993652344, 'loss_4': 2.279575824737549, 'epoch': 27.16}
{'loss': 0.0122, 'grad_norm': 5.1180596351623535, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.0055177765898406506, 'loss_2': 0.0066680908203125, 'loss_3': -16.54009246826172, 'loss_4': 1.3627777099609375, 'epoch': 27.16}
{'loss': 0.0056, 'grad_norm': 4.3740997314453125, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.004381371196359396, 'loss_2': 0.001220703125, 'loss_3': -16.30712127685547, 'loss_4': 1.2498966455459595, 'epoch': 27.17}
{'loss': 0.0033, 'grad_norm': 4.150004863739014, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.003006407292559743, 'loss_2': 0.0002601146697998047, 'loss_3': -16.280729293823242, 'loss_4': 2.2529468536376953, 'epoch': 27.17}
{'loss': 0.0041, 'grad_norm': 4.537846565246582, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.0031331516802310944, 'loss_2': 0.0009679794311523438, 'loss_3': -16.2868709564209, 'loss_4': 1.4650115966796875, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 11:19:01,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:01,511 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:16<08:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:08,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008820033632218838, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.288, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004669173154979944, 'eval_loss_2': 0.004150860011577606, 'eval_loss_3': -18.21664810180664, 'eval_loss_4': 1.561049222946167, 'epoch': 27.18}
{'loss': 0.0055, 'grad_norm': 4.24429178237915, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.0031079822219908237, 'loss_2': 0.002422332763671875, 'loss_3': -16.30019187927246, 'loss_4': 2.3134357929229736, 'epoch': 27.19}
{'loss': 0.0035, 'grad_norm': 4.664513111114502, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.002622365951538086, 'loss_2': 0.0008368492126464844, 'loss_3': -16.475902557373047, 'loss_4': 1.636733055114746, 'epoch': 27.19}
{'loss': 0.0188, 'grad_norm': 7.659717082977295, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.015911171212792397, 'loss_2': 0.002864837646484375, 'loss_3': -16.256515502929688, 'loss_4': 1.53680419921875, 'epoch': 27.2}
{'loss': 0.0097, 'grad_norm': 4.691066265106201, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.007244810461997986, 'loss_2': 0.0025043487548828125, 'loss_3': -16.418134689331055, 'loss_4': 1.8776969909667969, 'epoch': 27.2}
{'loss': 0.0039, 'grad_norm': 4.276627540588379, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.0016547881532460451, 'loss_2': 0.0022563934326171875, 'loss_3': -16.254756927490234, 'loss_4': 1.4969383478164673, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 11:19:08,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:08,852 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:23<08:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:16,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008286871016025543, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004345291294157505, 'eval_loss_2': 0.003941580653190613, 'eval_loss_3': -18.214799880981445, 'eval_loss_4': 1.5134705305099487, 'epoch': 27.21}
{'loss': 0.0105, 'grad_norm': 5.193420886993408, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.0073000467382371426, 'loss_2': 0.003192901611328125, 'loss_3': -16.428119659423828, 'loss_4': 1.5746674537658691, 'epoch': 27.22}
{'loss': 0.0031, 'grad_norm': 4.3781328201293945, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.002405271865427494, 'loss_2': 0.0007171630859375, 'loss_3': -16.281967163085938, 'loss_4': 1.499985694885254, 'epoch': 27.22}
{'loss': 0.0128, 'grad_norm': 7.922844409942627, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.009466521441936493, 'loss_2': 0.0033779144287109375, 'loss_3': -16.356304168701172, 'loss_4': 2.058838367462158, 'epoch': 27.23}
{'loss': 0.0095, 'grad_norm': 5.292844772338867, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.004364873748272657, 'loss_2': 0.005161285400390625, 'loss_3': -16.522750854492188, 'loss_4': 1.282541036605835, 'epoch': 27.23}
{'loss': 0.0085, 'grad_norm': 5.263422966003418, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.007560180500149727, 'loss_2': 0.0008907318115234375, 'loss_3': -16.285810470581055, 'loss_4': 1.9955320358276367, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 11:19:16,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:16,201 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:30<08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:23,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008153840899467468, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.395, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.004372239112854004, 'eval_loss_2': 0.0037816017866134644, 'eval_loss_3': -18.220792770385742, 'eval_loss_4': 1.483485221862793, 'epoch': 27.24}
{'loss': 0.0028, 'grad_norm': 4.716532230377197, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.002290585311129689, 'loss_2': 0.0005526542663574219, 'loss_3': -16.304988861083984, 'loss_4': 1.577530860900879, 'epoch': 27.24}
{'loss': 0.0064, 'grad_norm': 4.877437114715576, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.0035473781172186136, 'loss_2': 0.0028076171875, 'loss_3': -16.49277114868164, 'loss_4': 1.005021333694458, 'epoch': 27.25}
{'loss': 0.0332, 'grad_norm': 17.10512351989746, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.03069857694208622, 'loss_2': 0.0025348663330078125, 'loss_3': -16.07416534423828, 'loss_4': 1.8459601402282715, 'epoch': 27.26}
{'loss': 0.0107, 'grad_norm': 4.4053215980529785, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.005430642981082201, 'loss_2': 0.00531768798828125, 'loss_3': -16.182342529296875, 'loss_4': 1.3650116920471191, 'epoch': 27.26}
{'loss': 0.0066, 'grad_norm': 5.3730082511901855, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.006578485947102308, 'loss_2': 5.2928924560546875e-05, 'loss_3': -16.425209045410156, 'loss_4': 1.3087456226348877, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 11:19:23,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:23,560 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:38<08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:30,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008212142623960972, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004438878037035465, 'eval_loss_2': 0.0037732645869255066, 'eval_loss_3': -18.218841552734375, 'eval_loss_4': 1.482839584350586, 'epoch': 27.27}
{'loss': 0.0081, 'grad_norm': 5.321478366851807, 'learning_rate': 2.75e-06, 'loss_1': 0.006109790876507759, 'loss_2': 0.00200653076171875, 'loss_3': -16.312759399414062, 'loss_4': 1.9374765157699585, 'epoch': 27.27}
{'loss': 0.0116, 'grad_norm': 6.868553161621094, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.00934363529086113, 'loss_2': 0.0022144317626953125, 'loss_3': -16.374866485595703, 'loss_4': 1.2494029998779297, 'epoch': 27.28}
{'loss': 0.0051, 'grad_norm': 4.319796562194824, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.003104357747361064, 'loss_2': 0.00202178955078125, 'loss_3': -16.1910343170166, 'loss_4': 1.9916292428970337, 'epoch': 27.28}
{'loss': 0.004, 'grad_norm': 4.699179649353027, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.0035127957817167044, 'loss_2': 0.0005168914794921875, 'loss_3': -16.202768325805664, 'loss_4': 1.1038501262664795, 'epoch': 27.29}
{'loss': 0.0067, 'grad_norm': 4.658078670501709, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.002945116488263011, 'loss_2': 0.003757476806640625, 'loss_3': -16.208984375, 'loss_4': 2.111255407333374, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 11:19:30,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:30,898 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:45<07:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:38,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008080513216555119, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0042301868088543415, 'eval_loss_2': 0.0038503259420394897, 'eval_loss_3': -18.217756271362305, 'eval_loss_4': 1.4492506980895996, 'epoch': 27.3}
{'loss': 0.0084, 'grad_norm': 5.649684906005859, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.005261790473014116, 'loss_2': 0.0031642913818359375, 'loss_3': -16.24060821533203, 'loss_4': 1.1627237796783447, 'epoch': 27.3}
{'loss': 0.0207, 'grad_norm': 9.321301460266113, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.01769772171974182, 'loss_2': 0.003032684326171875, 'loss_3': -16.450965881347656, 'loss_4': 1.7249348163604736, 'epoch': 27.31}
{'loss': 0.0071, 'grad_norm': 5.420645713806152, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.005605749320238829, 'loss_2': 0.0015201568603515625, 'loss_3': -16.16083526611328, 'loss_4': 2.1362195014953613, 'epoch': 27.31}
{'loss': 0.0095, 'grad_norm': 6.032722473144531, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.007082879543304443, 'loss_2': 0.0024013519287109375, 'loss_3': -16.42167854309082, 'loss_4': 1.6032384634017944, 'epoch': 27.32}
{'loss': 0.0122, 'grad_norm': 5.099552154541016, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.010234123095870018, 'loss_2': 0.0019197463989257812, 'loss_3': -16.19815444946289, 'loss_4': 2.0742392539978027, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 11:19:38,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:38,243 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:55:52<07:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:45,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007939409464597702, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004205536562949419, 'eval_loss_2': 0.0037338733673095703, 'eval_loss_3': -18.21625518798828, 'eval_loss_4': 1.429518699645996, 'epoch': 27.33}
{'loss': 0.0087, 'grad_norm': 5.29140043258667, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.007658088579773903, 'loss_2': 0.00109100341796875, 'loss_3': -16.293916702270508, 'loss_4': 1.6634232997894287, 'epoch': 27.33}
{'loss': 0.0092, 'grad_norm': 4.990673542022705, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.007960747927427292, 'loss_2': 0.0012874603271484375, 'loss_3': -16.19977569580078, 'loss_4': 1.6005582809448242, 'epoch': 27.34}
{'loss': 0.0088, 'grad_norm': 5.166540622711182, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.007884452119469643, 'loss_2': 0.0009140968322753906, 'loss_3': -16.412548065185547, 'loss_4': 1.301636815071106, 'epoch': 27.34}
{'loss': 0.0083, 'grad_norm': 4.6041083335876465, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.005461375694721937, 'loss_2': 0.00286102294921875, 'loss_3': -16.440839767456055, 'loss_4': 1.5533965826034546, 'epoch': 27.35}
{'loss': 0.0027, 'grad_norm': 4.805082321166992, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.002635690849274397, 'loss_2': 2.765655517578125e-05, 'loss_3': -16.28907585144043, 'loss_4': 1.1267094612121582, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 11:19:45,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:45,588 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:56:00<07:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:19:52,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008207429200410843, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.321, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004345663357526064, 'eval_loss_2': 0.0038617663085460663, 'eval_loss_3': -18.214733123779297, 'eval_loss_4': 1.4235621690750122, 'epoch': 27.35}
{'loss': 0.0071, 'grad_norm': 5.6341047286987305, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.003766421228647232, 'loss_2': 0.003299713134765625, 'loss_3': -16.323955535888672, 'loss_4': 0.9225299954414368, 'epoch': 27.36}
{'loss': 0.0057, 'grad_norm': 4.611926078796387, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.004438039381057024, 'loss_2': 0.0012683868408203125, 'loss_3': -16.328447341918945, 'loss_4': 1.4070568084716797, 'epoch': 27.37}
{'loss': 0.0093, 'grad_norm': 5.0753045082092285, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.005336202681064606, 'loss_2': 0.00391387939453125, 'loss_3': -16.31222152709961, 'loss_4': 1.691805362701416, 'epoch': 27.37}
{'loss': 0.009, 'grad_norm': 4.265117168426514, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.004320103209465742, 'loss_2': 0.004673004150390625, 'loss_3': -16.41439437866211, 'loss_4': 1.4355223178863525, 'epoch': 27.38}
{'loss': 0.0085, 'grad_norm': 4.69332218170166, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.0042467922903597355, 'loss_2': 0.0042266845703125, 'loss_3': -16.382314682006836, 'loss_4': 1.6791706085205078, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 11:19:52,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:19:52,933 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:56:07<07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:00,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008542345836758614, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.399, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004311802331358194, 'eval_loss_2': 0.0042305439710617065, 'eval_loss_3': -18.221546173095703, 'eval_loss_4': 1.4207332134246826, 'epoch': 27.38}
{'loss': 0.0077, 'grad_norm': 4.250817775726318, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.0033975220285356045, 'loss_2': 0.00426483154296875, 'loss_3': -16.42670440673828, 'loss_4': 0.8475089073181152, 'epoch': 27.39}
{'loss': 0.0091, 'grad_norm': 4.542038440704346, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.003453836776316166, 'loss_2': 0.00562286376953125, 'loss_3': -16.45095443725586, 'loss_4': 1.673036813735962, 'epoch': 27.4}
{'loss': 0.0134, 'grad_norm': 7.287815570831299, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.00948156975209713, 'loss_2': 0.0039520263671875, 'loss_3': -16.16794204711914, 'loss_4': 1.9065475463867188, 'epoch': 27.4}
{'loss': 0.0129, 'grad_norm': 7.28963041305542, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.009527817368507385, 'loss_2': 0.003391265869140625, 'loss_3': -16.078506469726562, 'loss_4': 1.3294155597686768, 'epoch': 27.41}
{'loss': 0.0068, 'grad_norm': 4.92333984375, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.004364788997918367, 'loss_2': 0.002422332763671875, 'loss_3': -16.307804107666016, 'loss_4': 1.4655570983886719, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 11:20:00,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:00,277 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:14<07:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:07,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00868540070950985, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.493, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004383896943181753, 'eval_loss_2': 0.004301503300666809, 'eval_loss_3': -18.220012664794922, 'eval_loss_4': 1.385865569114685, 'epoch': 27.41}
{'loss': 0.0181, 'grad_norm': 12.074653625488281, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.01327404472976923, 'loss_2': 0.00484466552734375, 'loss_3': -16.48652458190918, 'loss_4': 1.4814544916152954, 'epoch': 27.42}
{'loss': 0.0063, 'grad_norm': 4.371943950653076, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.005439540836960077, 'loss_2': 0.0008630752563476562, 'loss_3': -16.480480194091797, 'loss_4': 0.6986362338066101, 'epoch': 27.42}
{'loss': 0.0079, 'grad_norm': 5.653408050537109, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.007522401865571737, 'loss_2': 0.0003724098205566406, 'loss_3': -16.207962036132812, 'loss_4': 0.6114680171012878, 'epoch': 27.43}
{'loss': 0.0165, 'grad_norm': 10.5894193649292, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.015639033168554306, 'loss_2': 0.0008335113525390625, 'loss_3': -16.182785034179688, 'loss_4': 1.5060150623321533, 'epoch': 27.44}
{'loss': 0.007, 'grad_norm': 4.813009738922119, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.003629903309047222, 'loss_2': 0.0034046173095703125, 'loss_3': -16.41405487060547, 'loss_4': 1.318842887878418, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 11:20:07,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:07,626 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:22<07:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:14,969 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008795561268925667, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004266741219907999, 'eval_loss_2': 0.004528820514678955, 'eval_loss_3': -18.223556518554688, 'eval_loss_4': 1.3424521684646606, 'epoch': 27.44}
{'loss': 0.0039, 'grad_norm': 4.574099063873291, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.0023591520730406046, 'loss_2': 0.0015048980712890625, 'loss_3': -16.229778289794922, 'loss_4': 0.6521478891372681, 'epoch': 27.45}
{'loss': 0.0129, 'grad_norm': 5.516853332519531, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.007247062865644693, 'loss_2': 0.00562286376953125, 'loss_3': -16.30626678466797, 'loss_4': 1.5613000392913818, 'epoch': 27.45}
{'loss': 0.0058, 'grad_norm': 5.249278545379639, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.00491094496101141, 'loss_2': 0.0008649826049804688, 'loss_3': -16.473052978515625, 'loss_4': 1.4064629077911377, 'epoch': 27.46}
{'loss': 0.0218, 'grad_norm': 6.886044502258301, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.010527273640036583, 'loss_2': 0.0112457275390625, 'loss_3': -16.379573822021484, 'loss_4': 1.2859621047973633, 'epoch': 27.47}
{'loss': 0.014, 'grad_norm': 5.969347953796387, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.011133847758173943, 'loss_2': 0.002838134765625, 'loss_3': -16.550128936767578, 'loss_4': 2.128326177597046, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 11:20:14,969 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:14,969 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:29<07:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:22,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009284276515245438, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004337754100561142, 'eval_loss_2': 0.004946522414684296, 'eval_loss_3': -18.216516494750977, 'eval_loss_4': 1.3276517391204834, 'epoch': 27.47}
{'loss': 0.0073, 'grad_norm': 4.8815693855285645, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.006315384525805712, 'loss_2': 0.0009679794311523438, 'loss_3': -16.181621551513672, 'loss_4': 1.4781248569488525, 'epoch': 27.48}
{'loss': 0.0077, 'grad_norm': 5.253505706787109, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.0029660125728696585, 'loss_2': 0.0047149658203125, 'loss_3': -16.234989166259766, 'loss_4': 0.9770454168319702, 'epoch': 27.48}
{'loss': 0.007, 'grad_norm': 5.195967197418213, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.00556768337264657, 'loss_2': 0.0014629364013671875, 'loss_3': -16.260295867919922, 'loss_4': 1.5115766525268555, 'epoch': 27.49}
{'loss': 0.0031, 'grad_norm': 4.885031223297119, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.002784397918730974, 'loss_2': 0.0003085136413574219, 'loss_3': -16.45447540283203, 'loss_4': 1.434962272644043, 'epoch': 27.49}
{'loss': 0.0019, 'grad_norm': 4.749631881713867, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.001569479121826589, 'loss_2': 0.00032901763916015625, 'loss_3': -16.523059844970703, 'loss_4': 1.047159194946289, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 11:20:22,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:22,312 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:36<07:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:29,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010051821358501911, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00440738070756197, 'eval_loss_2': 0.005644440650939941, 'eval_loss_3': -18.219152450561523, 'eval_loss_4': 1.3380297422409058, 'epoch': 27.5}
{'loss': 0.0051, 'grad_norm': 4.992828369140625, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.004523748066276312, 'loss_2': 0.00057220458984375, 'loss_3': -16.118295669555664, 'loss_4': 1.816507339477539, 'epoch': 27.51}
{'loss': 0.0068, 'grad_norm': 4.633305072784424, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0021092684473842382, 'loss_2': 0.004730224609375, 'loss_3': -16.498382568359375, 'loss_4': 1.076369047164917, 'epoch': 27.51}
{'loss': 0.0081, 'grad_norm': 5.077423095703125, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.003892487147822976, 'loss_2': 0.00418853759765625, 'loss_3': -16.44642448425293, 'loss_4': 1.750732183456421, 'epoch': 27.52}
{'loss': 0.0111, 'grad_norm': 4.5889997482299805, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.0030649357941001654, 'loss_2': 0.00799560546875, 'loss_3': -16.267597198486328, 'loss_4': 1.5345404148101807, 'epoch': 27.52}
{'loss': 0.0086, 'grad_norm': 4.671375751495361, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.004413681570440531, 'loss_2': 0.004215240478515625, 'loss_3': -16.30895233154297, 'loss_4': 1.062307596206665, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 11:20:29,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:29,658 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:44<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:37,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010481367819011211, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00457112118601799, 'eval_loss_2': 0.005910247564315796, 'eval_loss_3': -18.210344314575195, 'eval_loss_4': 1.3698490858078003, 'epoch': 27.53}
{'loss': 0.0118, 'grad_norm': 5.8373799324035645, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.006316670682281256, 'loss_2': 0.00543975830078125, 'loss_3': -16.19866943359375, 'loss_4': 1.39518141746521, 'epoch': 27.53}
{'loss': 0.0053, 'grad_norm': 4.351968765258789, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.0035099938977509737, 'loss_2': 0.0017833709716796875, 'loss_3': -16.555465698242188, 'loss_4': 1.906151294708252, 'epoch': 27.54}
{'loss': 0.0042, 'grad_norm': 5.130288124084473, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.0024420092813670635, 'loss_2': 0.0017805099487304688, 'loss_3': -16.362892150878906, 'loss_4': 1.3862152099609375, 'epoch': 27.55}
{'loss': 0.0027, 'grad_norm': 4.780285358428955, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.0018824082799255848, 'loss_2': 0.0008096694946289062, 'loss_3': -16.39386749267578, 'loss_4': 1.2215783596038818, 'epoch': 27.55}
{'loss': 0.0072, 'grad_norm': 4.3751444816589355, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.003251960501074791, 'loss_2': 0.0039520263671875, 'loss_3': -16.374183654785156, 'loss_4': 2.1264472007751465, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 11:20:37,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:37,012 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:51<07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:44,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010139679536223412, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.509, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004652334842830896, 'eval_loss_2': 0.0054873451590538025, 'eval_loss_3': -18.20172882080078, 'eval_loss_4': 1.41928231716156, 'epoch': 27.56}
{'loss': 0.0071, 'grad_norm': 4.6280646324157715, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.002705825725570321, 'loss_2': 0.00437164306640625, 'loss_3': -16.407913208007812, 'loss_4': 1.4516862630844116, 'epoch': 27.56}
{'loss': 0.0168, 'grad_norm': 5.709438323974609, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.007753781042993069, 'loss_2': 0.0090179443359375, 'loss_3': -16.300256729125977, 'loss_4': 1.3437937498092651, 'epoch': 27.57}
{'loss': 0.0202, 'grad_norm': 5.873546123504639, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.011772182770073414, 'loss_2': 0.0084686279296875, 'loss_3': -16.09566879272461, 'loss_4': 1.5197168588638306, 'epoch': 27.58}
{'loss': 0.0169, 'grad_norm': 4.787901401519775, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.0063987975008785725, 'loss_2': 0.010498046875, 'loss_3': -16.369247436523438, 'loss_4': 2.071937084197998, 'epoch': 27.58}
{'loss': 0.0124, 'grad_norm': 4.628310203552246, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.004671088885515928, 'loss_2': 0.00768280029296875, 'loss_3': -16.427452087402344, 'loss_4': 1.1262850761413574, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 11:20:44,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:44,379 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:56:58<07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:51,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009567266330122948, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.627, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004480400588363409, 'eval_loss_2': 0.005086865276098251, 'eval_loss_3': -18.202409744262695, 'eval_loss_4': 1.455414056777954, 'epoch': 27.59}
{'loss': 0.004, 'grad_norm': 4.522605895996094, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.002152254804968834, 'loss_2': 0.0018672943115234375, 'loss_3': -16.189842224121094, 'loss_4': 1.717000126838684, 'epoch': 27.59}
{'loss': 0.009, 'grad_norm': 5.136296272277832, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.004324345849454403, 'loss_2': 0.00467681884765625, 'loss_3': -16.425907135009766, 'loss_4': 1.4971325397491455, 'epoch': 27.6}
{'loss': 0.0028, 'grad_norm': 4.176825046539307, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.00235424330458045, 'loss_2': 0.0004134178161621094, 'loss_3': -16.383174896240234, 'loss_4': 1.9683812856674194, 'epoch': 27.6}
{'loss': 0.0201, 'grad_norm': 5.810460090637207, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.006628808565437794, 'loss_2': 0.0135040283203125, 'loss_3': -16.22948455810547, 'loss_4': 1.2191108465194702, 'epoch': 27.61}
{'loss': 0.0115, 'grad_norm': 4.76811408996582, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.002731361659243703, 'loss_2': 0.00879669189453125, 'loss_3': -16.32726287841797, 'loss_4': 1.546018362045288, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 11:20:51,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:51,733 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:57:06<06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:20:59,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009210698306560516, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004741765558719635, 'eval_loss_2': 0.004468932747840881, 'eval_loss_3': -18.19860076904297, 'eval_loss_4': 1.4383808374404907, 'epoch': 27.62}
{'loss': 0.0044, 'grad_norm': 4.521026611328125, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.002609512535855174, 'loss_2': 0.00177001953125, 'loss_3': -16.237590789794922, 'loss_4': 1.6664832830429077, 'epoch': 27.62}
{'loss': 0.0037, 'grad_norm': 4.90078067779541, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0024269712157547474, 'loss_2': 0.0012903213500976562, 'loss_3': -16.29866600036621, 'loss_4': 1.1629858016967773, 'epoch': 27.63}
{'loss': 0.0071, 'grad_norm': 4.806801795959473, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.0038262715097516775, 'loss_2': 0.00328826904296875, 'loss_3': -16.314252853393555, 'loss_4': 1.5914103984832764, 'epoch': 27.63}
{'loss': 0.0056, 'grad_norm': 4.8650336265563965, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.002532327314838767, 'loss_2': 0.003040313720703125, 'loss_3': -16.3326416015625, 'loss_4': 0.9666052460670471, 'epoch': 27.64}
{'loss': 0.0099, 'grad_norm': 6.511916160583496, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.008107504807412624, 'loss_2': 0.0018329620361328125, 'loss_3': -16.268953323364258, 'loss_4': 1.7285277843475342, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 11:20:59,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:20:59,073 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:13<06:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:06,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008820554241538048, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004794893320649862, 'eval_loss_2': 0.004025660455226898, 'eval_loss_3': -18.198013305664062, 'eval_loss_4': 1.4357608556747437, 'epoch': 27.65}
{'loss': 0.0061, 'grad_norm': 4.159852504730225, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.002494542859494686, 'loss_2': 0.003604888916015625, 'loss_3': -16.303752899169922, 'loss_4': 1.2465332746505737, 'epoch': 27.65}
{'loss': 0.0077, 'grad_norm': 5.204235076904297, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.005793444346636534, 'loss_2': 0.001903533935546875, 'loss_3': -16.175640106201172, 'loss_4': 1.5424680709838867, 'epoch': 27.66}
{'loss': 0.0063, 'grad_norm': 4.604608535766602, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.003551764413714409, 'loss_2': 0.00276947021484375, 'loss_3': -16.192323684692383, 'loss_4': 1.612627387046814, 'epoch': 27.66}
{'loss': 0.0042, 'grad_norm': 4.275875568389893, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.0030677507165819407, 'loss_2': 0.0010976791381835938, 'loss_3': -16.32961654663086, 'loss_4': 1.1075266599655151, 'epoch': 27.67}
{'loss': 0.006, 'grad_norm': 4.9174957275390625, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.002382519654929638, 'loss_2': 0.003650665283203125, 'loss_3': -16.350238800048828, 'loss_4': 1.308656930923462, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 11:21:06,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:06,417 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:20<06:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:13,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008644314482808113, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.298, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004812495782971382, 'eval_loss_2': 0.003831818699836731, 'eval_loss_3': -18.20182228088379, 'eval_loss_4': 1.4455622434616089, 'epoch': 27.67}
{'loss': 0.0077, 'grad_norm': 4.31143856048584, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.001991887344047427, 'loss_2': 0.0056610107421875, 'loss_3': -16.530685424804688, 'loss_4': 1.7208733558654785, 'epoch': 27.68}
{'loss': 0.0053, 'grad_norm': 4.344223976135254, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.0028985533863306046, 'loss_2': 0.00238800048828125, 'loss_3': -16.39606285095215, 'loss_4': 1.8310229778289795, 'epoch': 27.69}
{'loss': 0.0056, 'grad_norm': 5.210963249206543, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.004914538934826851, 'loss_2': 0.000728607177734375, 'loss_3': -16.197956085205078, 'loss_4': 0.8369954824447632, 'epoch': 27.69}
{'loss': 0.0044, 'grad_norm': 4.1663970947265625, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.0024792293552309275, 'loss_2': 0.0019130706787109375, 'loss_3': -16.428037643432617, 'loss_4': 0.8737980127334595, 'epoch': 27.7}
{'loss': 0.0192, 'grad_norm': 11.97426986694336, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.017988407984375954, 'loss_2': 0.0012121200561523438, 'loss_3': -16.195329666137695, 'loss_4': 1.161766529083252, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 11:21:13,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:13,756 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:28<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:21,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008752807974815369, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00487123429775238, 'eval_loss_2': 0.0038815736770629883, 'eval_loss_3': -18.204561233520508, 'eval_loss_4': 1.4241673946380615, 'epoch': 27.7}
{'loss': 0.0077, 'grad_norm': 5.199923515319824, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.007053192704916, 'loss_2': 0.0006799697875976562, 'loss_3': -16.268463134765625, 'loss_4': 1.215916395187378, 'epoch': 27.71}
{'loss': 0.0084, 'grad_norm': 4.379318714141846, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.002189665799960494, 'loss_2': 0.00618743896484375, 'loss_3': -16.430639266967773, 'loss_4': 1.6596038341522217, 'epoch': 27.72}
{'loss': 0.004, 'grad_norm': 4.347793102264404, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.002978718839585781, 'loss_2': 0.001007080078125, 'loss_3': -16.410640716552734, 'loss_4': 1.4875860214233398, 'epoch': 27.72}
{'loss': 0.0075, 'grad_norm': 4.465206623077393, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0029806240927428007, 'loss_2': 0.004474639892578125, 'loss_3': -16.49048614501953, 'loss_4': 1.3901448249816895, 'epoch': 27.73}
{'loss': 0.004, 'grad_norm': 4.583911418914795, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.003987644799053669, 'loss_2': 5.0067901611328125e-06, 'loss_3': -16.479551315307617, 'loss_4': 0.7180302143096924, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 11:21:21,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:21,105 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:35<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:28,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00914560817182064, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.373, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005138819571584463, 'eval_loss_2': 0.00400678813457489, 'eval_loss_3': -18.206676483154297, 'eval_loss_4': 1.414148211479187, 'epoch': 27.73}
{'loss': 0.0104, 'grad_norm': 4.680326461791992, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.006100050173699856, 'loss_2': 0.004329681396484375, 'loss_3': -16.51842498779297, 'loss_4': 1.4174745082855225, 'epoch': 27.74}
{'loss': 0.0041, 'grad_norm': 4.662294387817383, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.0023866137489676476, 'loss_2': 0.0016689300537109375, 'loss_3': -16.42493438720703, 'loss_4': 2.1911332607269287, 'epoch': 27.74}
{'loss': 0.01, 'grad_norm': 4.8244242668151855, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.0022567319683730602, 'loss_2': 0.007740020751953125, 'loss_3': -16.23409652709961, 'loss_4': 1.247499704360962, 'epoch': 27.75}
{'loss': 0.0044, 'grad_norm': 5.638326168060303, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.0037346016615629196, 'loss_2': 0.0006322860717773438, 'loss_3': -16.571874618530273, 'loss_4': 1.2657127380371094, 'epoch': 27.76}
{'loss': 0.01, 'grad_norm': 11.609576225280762, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.008974849246442318, 'loss_2': 0.0010623931884765625, 'loss_3': -16.365427017211914, 'loss_4': 2.1812405586242676, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 11:21:28,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:28,460 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:43<06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:35,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009067922830581665, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.224, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004912518430501223, 'eval_loss_2': 0.00415540486574173, 'eval_loss_3': -18.20976448059082, 'eval_loss_4': 1.4458122253417969, 'epoch': 27.76}
{'loss': 0.0212, 'grad_norm': 7.629257678985596, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.020003043115139008, 'loss_2': 0.001220703125, 'loss_3': -16.44424057006836, 'loss_4': 1.8221441507339478, 'epoch': 27.77}
{'loss': 0.0051, 'grad_norm': 4.604066371917725, 'learning_rate': 2.25e-06, 'loss_1': 0.0025094870943576097, 'loss_2': 0.002567291259765625, 'loss_3': -16.226058959960938, 'loss_4': 1.5912444591522217, 'epoch': 27.77}
{'loss': 0.0036, 'grad_norm': 4.75253963470459, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.0030005848966538906, 'loss_2': 0.0006036758422851562, 'loss_3': -16.565879821777344, 'loss_4': 1.3774280548095703, 'epoch': 27.78}
{'loss': 0.0108, 'grad_norm': 5.209010601043701, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.0073126875795423985, 'loss_2': 0.00348663330078125, 'loss_3': -16.435043334960938, 'loss_4': 1.5045647621154785, 'epoch': 27.78}
{'loss': 0.0064, 'grad_norm': 4.784642696380615, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.003381631337106228, 'loss_2': 0.00299072265625, 'loss_3': -16.332138061523438, 'loss_4': 1.4704030752182007, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 11:21:35,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:35,807 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:50<06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:43,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009057105518877506, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004899010527879, 'eval_loss_2': 0.004158094525337219, 'eval_loss_3': -18.213619232177734, 'eval_loss_4': 1.438944935798645, 'epoch': 27.79}
{'loss': 0.0111, 'grad_norm': 7.76889181137085, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.007361281663179398, 'loss_2': 0.0037078857421875, 'loss_3': -16.35711097717285, 'loss_4': 2.519690990447998, 'epoch': 27.8}
{'loss': 0.0115, 'grad_norm': 6.7963643074035645, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.009624410420656204, 'loss_2': 0.0018863677978515625, 'loss_3': -16.40665054321289, 'loss_4': 1.7431410551071167, 'epoch': 27.8}
{'loss': 0.0049, 'grad_norm': 4.615096092224121, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.003619098337367177, 'loss_2': 0.001293182373046875, 'loss_3': -16.402544021606445, 'loss_4': 1.9408174753189087, 'epoch': 27.81}
{'loss': 0.0033, 'grad_norm': 4.409878730773926, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.0029932535253465176, 'loss_2': 0.00035381317138671875, 'loss_3': -16.446882247924805, 'loss_4': 1.0474650859832764, 'epoch': 27.81}
{'loss': 0.0061, 'grad_norm': 4.841057777404785, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.0025052065029740334, 'loss_2': 0.003631591796875, 'loss_3': -16.22091293334961, 'loss_4': 1.7475260496139526, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 11:21:43,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:43,153 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:57:57<06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:50,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00870940275490284, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004672260954976082, 'eval_loss_2': 0.004037141799926758, 'eval_loss_3': -18.213401794433594, 'eval_loss_4': 1.4384325742721558, 'epoch': 27.82}
{'loss': 0.005, 'grad_norm': 4.571990489959717, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.002923188731074333, 'loss_2': 0.0020294189453125, 'loss_3': -16.379560470581055, 'loss_4': 1.4482362270355225, 'epoch': 27.83}
{'loss': 0.004, 'grad_norm': 4.772294521331787, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.0035514121409505606, 'loss_2': 0.00048732757568359375, 'loss_3': -16.357990264892578, 'loss_4': 0.9169432520866394, 'epoch': 27.83}
{'loss': 0.0033, 'grad_norm': 4.438908100128174, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.002332382369786501, 'loss_2': 0.0009822845458984375, 'loss_3': -16.35642433166504, 'loss_4': 1.9779771566390991, 'epoch': 27.84}
{'loss': 0.0158, 'grad_norm': 8.847444534301758, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.010692537762224674, 'loss_2': 0.0051116943359375, 'loss_3': -16.34979248046875, 'loss_4': 1.1601405143737793, 'epoch': 27.84}
{'loss': 0.0053, 'grad_norm': 4.462149620056152, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.004470138344913721, 'loss_2': 0.0008482933044433594, 'loss_3': -16.460845947265625, 'loss_4': 1.4451961517333984, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 11:21:50,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:50,496 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:58:05<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:21:57,832 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0084889130666852, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0044732289388775826, 'eval_loss_2': 0.004015684127807617, 'eval_loss_3': -18.209861755371094, 'eval_loss_4': 1.4346530437469482, 'epoch': 27.85}
{'loss': 0.0072, 'grad_norm': 5.270312786102295, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.00670668575912714, 'loss_2': 0.0004987716674804688, 'loss_3': -16.36968994140625, 'loss_4': 1.6495928764343262, 'epoch': 27.85}
{'loss': 0.0047, 'grad_norm': 5.016685485839844, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.003149915486574173, 'loss_2': 0.0015506744384765625, 'loss_3': -16.344879150390625, 'loss_4': 1.164961338043213, 'epoch': 27.86}
{'loss': 0.006, 'grad_norm': 4.384191036224365, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.004516711924225092, 'loss_2': 0.0014963150024414062, 'loss_3': -16.441282272338867, 'loss_4': 1.5159151554107666, 'epoch': 27.87}
{'loss': 0.0079, 'grad_norm': 4.7491655349731445, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.0030552688986063004, 'loss_2': 0.0048675537109375, 'loss_3': -16.497522354125977, 'loss_4': 1.9495311975479126, 'epoch': 27.87}
{'loss': 0.0029, 'grad_norm': 4.437521457672119, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.0024843744467943907, 'loss_2': 0.00041961669921875, 'loss_3': -16.370731353759766, 'loss_4': 0.8045650124549866, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 11:21:57,832 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:21:57,832 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:12<06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:05,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008394178003072739, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004466136451810598, 'eval_loss_2': 0.003928042948246002, 'eval_loss_3': -18.205657958984375, 'eval_loss_4': 1.4306659698486328, 'epoch': 27.88}
{'loss': 0.005, 'grad_norm': 4.49668550491333, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.00293768965639174, 'loss_2': 0.002033233642578125, 'loss_3': -16.311904907226562, 'loss_4': 1.6749427318572998, 'epoch': 27.88}
{'loss': 0.0088, 'grad_norm': 4.827395915985107, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.004577867686748505, 'loss_2': 0.00417327880859375, 'loss_3': -16.374366760253906, 'loss_4': 1.6553456783294678, 'epoch': 27.89}
{'loss': 0.0133, 'grad_norm': 4.481632232666016, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.006846718955785036, 'loss_2': 0.006473541259765625, 'loss_3': -16.360132217407227, 'loss_4': 1.9045295715332031, 'epoch': 27.9}
{'loss': 0.0111, 'grad_norm': 5.986599922180176, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.009684370830655098, 'loss_2': 0.001445770263671875, 'loss_3': -16.27423667907715, 'loss_4': 1.2361524105072021, 'epoch': 27.9}
{'loss': 0.0109, 'grad_norm': 4.782325267791748, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.003596283495426178, 'loss_2': 0.0073089599609375, 'loss_3': -16.272472381591797, 'loss_4': 1.2740211486816406, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 11:22:05,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:05,175 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:19<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:12,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008694646880030632, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0045805745758116245, 'eval_loss_2': 0.004114072769880295, 'eval_loss_3': -18.212074279785156, 'eval_loss_4': 1.4151705503463745, 'epoch': 27.91}
{'loss': 0.0068, 'grad_norm': 4.96590518951416, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.006684544496238232, 'loss_2': 6.830692291259766e-05, 'loss_3': -16.16632843017578, 'loss_4': 1.6674493551254272, 'epoch': 27.91}
{'loss': 0.0084, 'grad_norm': 4.323878288269043, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.005199095234274864, 'loss_2': 0.003238677978515625, 'loss_3': -16.19579315185547, 'loss_4': 2.188035011291504, 'epoch': 27.92}
{'loss': 0.0209, 'grad_norm': 8.040181159973145, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.010293846018612385, 'loss_2': 0.01056671142578125, 'loss_3': -16.290393829345703, 'loss_4': 1.6209032535552979, 'epoch': 27.92}
{'loss': 0.0154, 'grad_norm': 5.600250244140625, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.013438962399959564, 'loss_2': 0.002010345458984375, 'loss_3': -16.359500885009766, 'loss_4': 1.9778445959091187, 'epoch': 27.93}
{'loss': 0.0102, 'grad_norm': 7.966970443725586, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.00910165160894394, 'loss_2': 0.001132965087890625, 'loss_3': -16.25072479248047, 'loss_4': 1.4719016551971436, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 11:22:12,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:12,533 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:27<06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:19,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008782601915299892, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004448510240763426, 'eval_loss_2': 0.004334092140197754, 'eval_loss_3': -18.208873748779297, 'eval_loss_4': 1.3948546648025513, 'epoch': 27.94}
{'loss': 0.0046, 'grad_norm': 4.951119422912598, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.00205882266163826, 'loss_2': 0.002574920654296875, 'loss_3': -16.456396102905273, 'loss_4': 1.045379877090454, 'epoch': 27.94}
{'loss': 0.006, 'grad_norm': 5.035617828369141, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.004412649665027857, 'loss_2': 0.0016117095947265625, 'loss_3': -16.392797470092773, 'loss_4': 1.2561737298965454, 'epoch': 27.95}
{'loss': 0.0114, 'grad_norm': 8.231584548950195, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.010391653515398502, 'loss_2': 0.0010089874267578125, 'loss_3': -16.360820770263672, 'loss_4': 1.4823274612426758, 'epoch': 27.95}
{'loss': 0.0073, 'grad_norm': 4.866501808166504, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.0035322082694619894, 'loss_2': 0.003757476806640625, 'loss_3': -16.271894454956055, 'loss_4': 1.5664138793945312, 'epoch': 27.96}
{'loss': 0.0111, 'grad_norm': 5.088540077209473, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.004981614649295807, 'loss_2': 0.006072998046875, 'loss_3': -16.40317726135254, 'loss_4': 0.9671091437339783, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 11:22:19,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:19,879 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:34<05:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:22:27,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008782021701335907, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004359267186373472, 'eval_loss_2': 0.0044227540493011475, 'eval_loss_3': -18.207059860229492, 'eval_loss_4': 1.384230613708496, 'epoch': 27.97}
{'loss': 0.0086, 'grad_norm': 4.210737228393555, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.002414790680631995, 'loss_2': 0.0061798095703125, 'loss_3': -16.21756362915039, 'loss_4': 1.1198227405548096, 'epoch': 27.97}
{'loss': 0.0095, 'grad_norm': 4.857900142669678, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.00482588168233633, 'loss_2': 0.00469970703125, 'loss_3': -16.175342559814453, 'loss_4': 1.3019349575042725, 'epoch': 27.98}
{'loss': 0.0065, 'grad_norm': 4.848586082458496, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.005531213711947203, 'loss_2': 0.0009355545043945312, 'loss_3': -16.40304183959961, 'loss_4': 1.3447072505950928, 'epoch': 27.98}
{'loss': 0.0085, 'grad_norm': 5.149851322174072, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.004538111388683319, 'loss_2': 0.003936767578125, 'loss_3': -16.34369659423828, 'loss_4': 2.039923667907715, 'epoch': 27.99}
{'loss': 0.0137, 'grad_norm': 7.503252029418945, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.009222357533872128, 'loss_2': 0.00452423095703125, 'loss_3': -16.17361068725586, 'loss_4': 1.2940669059753418, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 11:22:27,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:27,206 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:41<05:45,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 11:22:34,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008370466530323029, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004333594348281622, 'eval_loss_2': 0.0040368735790252686, 'eval_loss_3': -18.199615478515625, 'eval_loss_4': 1.375038743019104, 'epoch': 27.99}
{'loss': 0.0025, 'grad_norm': 5.417682647705078, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.001604375895112753, 'loss_2': 0.0008916854858398438, 'loss_3': -16.42885971069336, 'loss_4': 1.2194749116897583, 'epoch': 28.0}
{'loss': 0.021, 'grad_norm': 5.650146484375, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.019368328154087067, 'loss_2': 0.0016422271728515625, 'loss_3': -16.362703323364258, 'loss_4': 1.2437586784362793, 'epoch': 28.01}
{'loss': 0.0045, 'grad_norm': 4.4490766525268555, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.002735765650868416, 'loss_2': 0.0017843246459960938, 'loss_3': -16.467418670654297, 'loss_4': 1.2124969959259033, 'epoch': 28.01}
{'loss': 0.0129, 'grad_norm': 4.697929859161377, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.0032517332583665848, 'loss_2': 0.00969696044921875, 'loss_3': -16.563995361328125, 'loss_4': 1.7392923831939697, 'epoch': 28.02}
{'loss': 0.0113, 'grad_norm': 5.802947998046875, 'learning_rate': 2e-06, 'loss_1': 0.008370048366487026, 'loss_2': 0.0029430389404296875, 'loss_3': -16.454771041870117, 'loss_4': 1.0631754398345947, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 11:22:34,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:34,267 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:48<05:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:22:41,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00834602303802967, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00445869704708457, 'eval_loss_2': 0.0038873255252838135, 'eval_loss_3': -18.201637268066406, 'eval_loss_4': 1.3732571601867676, 'epoch': 28.02}
{'loss': 0.0073, 'grad_norm': 6.98206901550293, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.006247672718018293, 'loss_2': 0.0010814666748046875, 'loss_3': -16.383453369140625, 'loss_4': 1.6202303171157837, 'epoch': 28.03}
{'loss': 0.0063, 'grad_norm': 4.30056619644165, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.002614289056509733, 'loss_2': 0.003658294677734375, 'loss_3': -16.41562271118164, 'loss_4': 1.8238757848739624, 'epoch': 28.03}
{'loss': 0.0044, 'grad_norm': 4.526511192321777, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.002586123999208212, 'loss_2': 0.0018215179443359375, 'loss_3': -16.33038902282715, 'loss_4': 1.7628743648529053, 'epoch': 28.04}
{'loss': 0.0056, 'grad_norm': 4.46796178817749, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.002689814893528819, 'loss_2': 0.002918243408203125, 'loss_3': -16.299495697021484, 'loss_4': 1.1398701667785645, 'epoch': 28.05}
{'loss': 0.0096, 'grad_norm': 6.234741687774658, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.008695020340383053, 'loss_2': 0.0009164810180664062, 'loss_3': -16.397891998291016, 'loss_4': 1.4685167074203491, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 11:22:41,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:41,607 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:58:56<05:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:48,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008285488933324814, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004536758176982403, 'eval_loss_2': 0.0037487298250198364, 'eval_loss_3': -18.204259872436523, 'eval_loss_4': 1.3780403137207031, 'epoch': 28.05}
{'loss': 0.0127, 'grad_norm': 5.861618518829346, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.004673277959227562, 'loss_2': 0.0079803466796875, 'loss_3': -16.48665428161621, 'loss_4': 1.3420439958572388, 'epoch': 28.06}
{'loss': 0.0107, 'grad_norm': 5.595776557922363, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.004778850823640823, 'loss_2': 0.00591278076171875, 'loss_3': -16.39740562438965, 'loss_4': 0.9469804763793945, 'epoch': 28.06}
{'loss': 0.0088, 'grad_norm': 5.502356052398682, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.006187996361404657, 'loss_2': 0.002590179443359375, 'loss_3': -16.226696014404297, 'loss_4': 1.6371513605117798, 'epoch': 28.07}
{'loss': 0.0075, 'grad_norm': 4.765454292297363, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.005039358511567116, 'loss_2': 0.002483367919921875, 'loss_3': -16.32499885559082, 'loss_4': 2.0134201049804688, 'epoch': 28.08}
{'loss': 0.0042, 'grad_norm': 4.916075229644775, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.003152521327137947, 'loss_2': 0.001018524169921875, 'loss_3': -16.577451705932617, 'loss_4': 1.2992730140686035, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 11:22:48,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:48,959 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:59:03<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:22:56,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007998906075954437, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004392184317111969, 'eval_loss_2': 0.0036067217588424683, 'eval_loss_3': -18.205810546875, 'eval_loss_4': 1.376646876335144, 'epoch': 28.08}
{'loss': 0.0049, 'grad_norm': 4.557866096496582, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.004384696017950773, 'loss_2': 0.0004658699035644531, 'loss_3': -16.50613021850586, 'loss_4': 1.9648640155792236, 'epoch': 28.09}
{'loss': 0.0098, 'grad_norm': 6.862364768981934, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.008090229704976082, 'loss_2': 0.0017061233520507812, 'loss_3': -16.344322204589844, 'loss_4': 1.2608373165130615, 'epoch': 28.09}
{'loss': 0.0082, 'grad_norm': 4.395822525024414, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0023361577186733484, 'loss_2': 0.005840301513671875, 'loss_3': -16.46368408203125, 'loss_4': 1.3985061645507812, 'epoch': 28.1}
{'loss': 0.0081, 'grad_norm': 5.397785663604736, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.00807456485927105, 'loss_2': 5.704164505004883e-05, 'loss_3': -16.452056884765625, 'loss_4': 1.6122455596923828, 'epoch': 28.1}
{'loss': 0.0061, 'grad_norm': 5.0707855224609375, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.006052323151379824, 'loss_2': 2.3245811462402344e-05, 'loss_3': -16.31291961669922, 'loss_4': 1.474067211151123, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 11:22:56,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:22:56,306 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:10<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:03,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007822804152965546, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004286848474293947, 'eval_loss_2': 0.0035359561443328857, 'eval_loss_3': -18.205123901367188, 'eval_loss_4': 1.3671554327011108, 'epoch': 28.11}
{'loss': 0.0038, 'grad_norm': 4.841742038726807, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.00362759898416698, 'loss_2': 0.0001443624496459961, 'loss_3': -16.2253360748291, 'loss_4': 1.1460813283920288, 'epoch': 28.12}
{'loss': 0.005, 'grad_norm': 4.799108982086182, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.004672065377235413, 'loss_2': 0.0003662109375, 'loss_3': -16.21940040588379, 'loss_4': 1.5520747900009155, 'epoch': 28.12}
{'loss': 0.0095, 'grad_norm': 5.039525032043457, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.004301206674426794, 'loss_2': 0.0052337646484375, 'loss_3': -16.18287467956543, 'loss_4': 1.3542009592056274, 'epoch': 28.13}
{'loss': 0.0177, 'grad_norm': 9.825307846069336, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.013287106528878212, 'loss_2': 0.00440216064453125, 'loss_3': -16.4798641204834, 'loss_4': 1.0056207180023193, 'epoch': 28.13}
{'loss': 0.0067, 'grad_norm': 4.264346122741699, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.0034795196261256933, 'loss_2': 0.003253936767578125, 'loss_3': -16.46112823486328, 'loss_4': 1.7153496742248535, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 11:23:03,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:03,648 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:18<05:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:10,983 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007825862616300583, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004471536260098219, 'eval_loss_2': 0.0033543258905410767, 'eval_loss_3': -18.202449798583984, 'eval_loss_4': 1.348110318183899, 'epoch': 28.14}
{'loss': 0.0093, 'grad_norm': 5.110189914703369, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.0073823463171720505, 'loss_2': 0.001903533935546875, 'loss_3': -16.34699249267578, 'loss_4': 1.0030543804168701, 'epoch': 28.15}
{'loss': 0.0066, 'grad_norm': 5.50992488861084, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.006599039305001497, 'loss_2': 3.0875205993652344e-05, 'loss_3': -16.171703338623047, 'loss_4': 1.0126769542694092, 'epoch': 28.15}
{'loss': 0.009, 'grad_norm': 4.601027965545654, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.004924608860164881, 'loss_2': 0.00408172607421875, 'loss_3': -16.266197204589844, 'loss_4': 1.4374078512191772, 'epoch': 28.16}
{'loss': 0.0194, 'grad_norm': 7.683135032653809, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.01855573058128357, 'loss_2': 0.0008139610290527344, 'loss_3': -16.487632751464844, 'loss_4': 1.9734444618225098, 'epoch': 28.16}
{'loss': 0.0045, 'grad_norm': 4.847396373748779, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.002824427094310522, 'loss_2': 0.001667022705078125, 'loss_3': -16.510772705078125, 'loss_4': 1.6981205940246582, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 11:23:10,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:10,983 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:25<05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:18,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008017243817448616, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.987, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004513540770858526, 'eval_loss_2': 0.0035037025809288025, 'eval_loss_3': -18.19640350341797, 'eval_loss_4': 1.3469269275665283, 'epoch': 28.17}
{'loss': 0.0114, 'grad_norm': 4.628432750701904, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.0028830801602452993, 'loss_2': 0.0084686279296875, 'loss_3': -16.367351531982422, 'loss_4': 1.9303958415985107, 'epoch': 28.17}
{'loss': 0.0092, 'grad_norm': 5.736839294433594, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.006104163825511932, 'loss_2': 0.0030975341796875, 'loss_3': -16.55624771118164, 'loss_4': 1.4070065021514893, 'epoch': 28.18}
{'loss': 0.0076, 'grad_norm': 5.022718906402588, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.004468862898647785, 'loss_2': 0.0031585693359375, 'loss_3': -16.331241607666016, 'loss_4': 1.466724157333374, 'epoch': 28.19}
{'loss': 0.0062, 'grad_norm': 3.98301362991333, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.004250980447977781, 'loss_2': 0.001987457275390625, 'loss_3': -16.19912338256836, 'loss_4': 1.3259037733078003, 'epoch': 28.19}
{'loss': 0.0063, 'grad_norm': 5.092469215393066, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.00623236084356904, 'loss_2': 3.516674041748047e-05, 'loss_3': -16.291976928710938, 'loss_4': 1.470245599746704, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 11:23:18,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:18,322 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:32<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:25,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00793442502617836, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004193815402686596, 'eval_loss_2': 0.0037406086921691895, 'eval_loss_3': -18.194684982299805, 'eval_loss_4': 1.3577265739440918, 'epoch': 28.2}
{'loss': 0.0056, 'grad_norm': 4.404698848724365, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.002839429536834359, 'loss_2': 0.002788543701171875, 'loss_3': -16.25171661376953, 'loss_4': 1.644997000694275, 'epoch': 28.2}
{'loss': 0.0094, 'grad_norm': 4.617112159729004, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.003976725973188877, 'loss_2': 0.00540924072265625, 'loss_3': -16.604042053222656, 'loss_4': 1.2736387252807617, 'epoch': 28.21}
{'loss': 0.0115, 'grad_norm': 4.316435813903809, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.005181130487471819, 'loss_2': 0.00630950927734375, 'loss_3': -16.361576080322266, 'loss_4': 1.4755418300628662, 'epoch': 28.22}
{'loss': 0.0043, 'grad_norm': 4.78970193862915, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.002853470854461193, 'loss_2': 0.001434326171875, 'loss_3': -16.27273941040039, 'loss_4': 1.0707381963729858, 'epoch': 28.22}
{'loss': 0.0068, 'grad_norm': 5.002318859100342, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.004716178867965937, 'loss_2': 0.002086639404296875, 'loss_3': -16.306236267089844, 'loss_4': 1.5727667808532715, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 11:23:25,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:25,662 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:40<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:33,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00813827570527792, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.598, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004301553592085838, 'eval_loss_2': 0.003836721181869507, 'eval_loss_3': -18.194091796875, 'eval_loss_4': 1.3853429555892944, 'epoch': 28.23}
{'loss': 0.0026, 'grad_norm': 4.497591495513916, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.0010044892551377416, 'loss_2': 0.001605987548828125, 'loss_3': -16.533817291259766, 'loss_4': 1.576947808265686, 'epoch': 28.23}
{'loss': 0.009, 'grad_norm': 4.594399452209473, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.0032149269245564938, 'loss_2': 0.005828857421875, 'loss_3': -16.30690574645996, 'loss_4': 1.4565619230270386, 'epoch': 28.24}
{'loss': 0.0169, 'grad_norm': 5.269913196563721, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.009487640112638474, 'loss_2': 0.007389068603515625, 'loss_3': -16.44162368774414, 'loss_4': 1.7523975372314453, 'epoch': 28.24}
{'loss': 0.0032, 'grad_norm': 4.538177013397217, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.0020704541821032763, 'loss_2': 0.001148223876953125, 'loss_3': -16.39672088623047, 'loss_4': 1.2159335613250732, 'epoch': 28.25}
{'loss': 0.0086, 'grad_norm': 4.954017639160156, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.005344395060092211, 'loss_2': 0.00330352783203125, 'loss_3': -16.292551040649414, 'loss_4': 1.7334041595458984, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 11:23:33,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:33,016 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:47<05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:40,354 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008218619041144848, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.359, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004512215964496136, 'eval_loss_2': 0.003706403076648712, 'eval_loss_3': -18.192338943481445, 'eval_loss_4': 1.3910237550735474, 'epoch': 28.26}
{'loss': 0.029, 'grad_norm': 9.92272663116455, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.026559986174106598, 'loss_2': 0.0024585723876953125, 'loss_3': -16.398635864257812, 'loss_4': 1.485499620437622, 'epoch': 28.26}
{'loss': 0.0031, 'grad_norm': 3.9015212059020996, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.001753015210852027, 'loss_2': 0.001308441162109375, 'loss_3': -16.435653686523438, 'loss_4': 1.291654348373413, 'epoch': 28.27}
{'loss': 0.0088, 'grad_norm': 6.206793785095215, 'learning_rate': 1.75e-06, 'loss_1': 0.007564880885183811, 'loss_2': 0.001247406005859375, 'loss_3': -16.45517921447754, 'loss_4': 1.5851771831512451, 'epoch': 28.27}
{'loss': 0.0054, 'grad_norm': 5.162296295166016, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.00429494958370924, 'loss_2': 0.0011425018310546875, 'loss_3': -16.354719161987305, 'loss_4': 1.3827000856399536, 'epoch': 28.28}
{'loss': 0.0067, 'grad_norm': 4.5438103675842285, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.004127637017518282, 'loss_2': 0.0025787353515625, 'loss_3': -16.036605834960938, 'loss_4': 1.6590343713760376, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 11:23:40,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:40,354 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [1:59:54<05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:47,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008256671018898487, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.101, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00451932568103075, 'eval_loss_2': 0.003737345337867737, 'eval_loss_3': -18.190082550048828, 'eval_loss_4': 1.375961422920227, 'epoch': 28.28}
{'loss': 0.0085, 'grad_norm': 4.591354846954346, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.006035947240889072, 'loss_2': 0.00244140625, 'loss_3': -16.21277618408203, 'loss_4': 2.143315553665161, 'epoch': 28.29}
{'loss': 0.0044, 'grad_norm': 5.862742900848389, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.004096205811947584, 'loss_2': 0.00034546852111816406, 'loss_3': -16.36594009399414, 'loss_4': 1.888795256614685, 'epoch': 28.3}
{'loss': 0.0044, 'grad_norm': 4.48714542388916, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0031100844498723745, 'loss_2': 0.0013179779052734375, 'loss_3': -16.387611389160156, 'loss_4': 2.0397963523864746, 'epoch': 28.3}
{'loss': 0.0113, 'grad_norm': 4.661002159118652, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.005510413553565741, 'loss_2': 0.005764007568359375, 'loss_3': -16.216182708740234, 'loss_4': 1.335850477218628, 'epoch': 28.31}
{'loss': 0.0073, 'grad_norm': 5.95204496383667, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.006506560370326042, 'loss_2': 0.0007638931274414062, 'loss_3': -16.337860107421875, 'loss_4': 0.9903075695037842, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 11:23:47,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:47,693 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [2:00:02<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:23:55,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008091658353805542, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.316, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00442472193390131, 'eval_loss_2': 0.0036669373512268066, 'eval_loss_3': -18.191181182861328, 'eval_loss_4': 1.3558882474899292, 'epoch': 28.31}
{'loss': 0.0021, 'grad_norm': 4.742353439331055, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.0019136309856548905, 'loss_2': 0.00013959407806396484, 'loss_3': -16.416500091552734, 'loss_4': 1.3889423608779907, 'epoch': 28.32}
{'loss': 0.022, 'grad_norm': 15.074905395507812, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.015380006283521652, 'loss_2': 0.006618499755859375, 'loss_3': -16.274490356445312, 'loss_4': 2.0390796661376953, 'epoch': 28.33}
{'loss': 0.0052, 'grad_norm': 4.968443393707275, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.0037780797574669123, 'loss_2': 0.00142669677734375, 'loss_3': -16.369495391845703, 'loss_4': 0.8597972989082336, 'epoch': 28.33}
{'loss': 0.0089, 'grad_norm': 4.6236138343811035, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.004486439749598503, 'loss_2': 0.00441741943359375, 'loss_3': -16.343990325927734, 'loss_4': 1.1448712348937988, 'epoch': 28.34}
{'loss': 0.0039, 'grad_norm': 4.709589004516602, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0021875319071114063, 'loss_2': 0.0017490386962890625, 'loss_3': -16.338157653808594, 'loss_4': 1.643340826034546, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 11:23:55,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:23:55,035 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:09<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:02,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008507173508405685, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004808101337403059, 'eval_loss_2': 0.003699071705341339, 'eval_loss_3': -18.189773559570312, 'eval_loss_4': 1.3253177404403687, 'epoch': 28.34}
{'loss': 0.0069, 'grad_norm': 5.597718238830566, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.0053142583929002285, 'loss_2': 0.001575469970703125, 'loss_3': -16.2728328704834, 'loss_4': 1.7056775093078613, 'epoch': 28.35}
{'loss': 0.0058, 'grad_norm': 4.913689136505127, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.0037093614228069782, 'loss_2': 0.0020542144775390625, 'loss_3': -16.401798248291016, 'loss_4': 1.3107832670211792, 'epoch': 28.35}
{'loss': 0.0087, 'grad_norm': 4.751953601837158, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.005634230095893145, 'loss_2': 0.0030651092529296875, 'loss_3': -16.381624221801758, 'loss_4': 1.992485523223877, 'epoch': 28.36}
{'loss': 0.0035, 'grad_norm': 4.845135688781738, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.003135401289910078, 'loss_2': 0.00038814544677734375, 'loss_3': -16.45292854309082, 'loss_4': 1.4918323755264282, 'epoch': 28.37}
{'loss': 0.0066, 'grad_norm': 5.116108417510986, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.005686315707862377, 'loss_2': 0.0009007453918457031, 'loss_3': -16.200679779052734, 'loss_4': 1.2714993953704834, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 11:24:02,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:02,378 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:16<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:09,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0083908811211586, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.656, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004683270584791899, 'eval_loss_2': 0.003707610070705414, 'eval_loss_3': -18.193862915039062, 'eval_loss_4': 1.303317904472351, 'epoch': 28.37}
{'loss': 0.0101, 'grad_norm': 4.5845255851745605, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.0014195804251357913, 'loss_2': 0.008697509765625, 'loss_3': -16.46361541748047, 'loss_4': 0.9417529106140137, 'epoch': 28.38}
{'loss': 0.0033, 'grad_norm': 4.417376518249512, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0020561693236231804, 'loss_2': 0.0012683868408203125, 'loss_3': -16.474990844726562, 'loss_4': 1.3041648864746094, 'epoch': 28.38}
{'loss': 0.0137, 'grad_norm': 6.1253275871276855, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.007120637223124504, 'loss_2': 0.006542205810546875, 'loss_3': -16.12346839904785, 'loss_4': 1.5102546215057373, 'epoch': 28.39}
{'loss': 0.0061, 'grad_norm': 4.788657188415527, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.0018655284075066447, 'loss_2': 0.0042724609375, 'loss_3': -16.243839263916016, 'loss_4': 1.069067120552063, 'epoch': 28.4}
{'loss': 0.0059, 'grad_norm': 4.398075103759766, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.0033572635147720575, 'loss_2': 0.002574920654296875, 'loss_3': -16.328861236572266, 'loss_4': 1.904340147972107, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 11:24:09,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:09,731 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:24<04:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:17,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008241787552833557, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00443588150665164, 'eval_loss_2': 0.00380590558052063, 'eval_loss_3': -18.198604583740234, 'eval_loss_4': 1.2783946990966797, 'epoch': 28.4}
{'loss': 0.0158, 'grad_norm': 6.01646614074707, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.00917478371411562, 'loss_2': 0.006618499755859375, 'loss_3': -16.11834716796875, 'loss_4': 0.7206224203109741, 'epoch': 28.41}
{'loss': 0.0092, 'grad_norm': 4.290408611297607, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.003967439290136099, 'loss_2': 0.0052032470703125, 'loss_3': -16.402793884277344, 'loss_4': 1.455909252166748, 'epoch': 28.41}
{'loss': 0.0064, 'grad_norm': 4.441539287567139, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.0061364853754639626, 'loss_2': 0.00021648406982421875, 'loss_3': -16.295759201049805, 'loss_4': 1.1253982782363892, 'epoch': 28.42}
{'loss': 0.0036, 'grad_norm': 4.607255935668945, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.0023955085780471563, 'loss_2': 0.0011615753173828125, 'loss_3': -16.362991333007812, 'loss_4': 0.6238287091255188, 'epoch': 28.42}
{'loss': 0.0122, 'grad_norm': 8.06296157836914, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.007233812008053064, 'loss_2': 0.0049285888671875, 'loss_3': -16.32896614074707, 'loss_4': 1.3238017559051514, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 11:24:17,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:17,072 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:31<04:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:24:24,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008128872141242027, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.69, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00443223724141717, 'eval_loss_2': 0.003696635365486145, 'eval_loss_3': -18.200206756591797, 'eval_loss_4': 1.2586839199066162, 'epoch': 28.43}
{'loss': 0.0063, 'grad_norm': 5.150195121765137, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.004781907424330711, 'loss_2': 0.0015087127685546875, 'loss_3': -16.139934539794922, 'loss_4': 1.4480717182159424, 'epoch': 28.44}
{'loss': 0.0076, 'grad_norm': 4.4140167236328125, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.0028140610083937645, 'loss_2': 0.00479888916015625, 'loss_3': -16.381301879882812, 'loss_4': 1.3347079753875732, 'epoch': 28.44}
{'loss': 0.0107, 'grad_norm': 4.829194068908691, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.0023075721692293882, 'loss_2': 0.0084075927734375, 'loss_3': -16.18338394165039, 'loss_4': 2.0015406608581543, 'epoch': 28.45}
{'loss': 0.0076, 'grad_norm': 5.38156270980835, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.005127679090946913, 'loss_2': 0.00246429443359375, 'loss_3': -16.295209884643555, 'loss_4': 1.3549368381500244, 'epoch': 28.45}
{'loss': 0.0072, 'grad_norm': 5.001430511474609, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.006073113530874252, 'loss_2': 0.001140594482421875, 'loss_3': -16.359500885009766, 'loss_4': 0.8232864737510681, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 11:24:24,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:24,400 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:38<04:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:31,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008222637698054314, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.004487304482609034, 'eval_loss_2': 0.0037353336811065674, 'eval_loss_3': -18.20134925842285, 'eval_loss_4': 1.24467134475708, 'epoch': 28.46}
{'loss': 0.0036, 'grad_norm': 4.326874732971191, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.00173211470246315, 'loss_2': 0.00185394287109375, 'loss_3': -16.371318817138672, 'loss_4': 1.7023155689239502, 'epoch': 28.47}
{'loss': 0.0086, 'grad_norm': 4.9277191162109375, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.005382031202316284, 'loss_2': 0.003173828125, 'loss_3': -16.343046188354492, 'loss_4': 0.8608647584915161, 'epoch': 28.47}
{'loss': 0.0329, 'grad_norm': 10.992449760437012, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.028012949973344803, 'loss_2': 0.00487518310546875, 'loss_3': -16.081802368164062, 'loss_4': 1.260521411895752, 'epoch': 28.48}
{'loss': 0.0075, 'grad_norm': 4.6115312576293945, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.004233102779835463, 'loss_2': 0.003292083740234375, 'loss_3': -16.20853042602539, 'loss_4': 0.8919645547866821, 'epoch': 28.48}
{'loss': 0.0132, 'grad_norm': 5.421572208404541, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.009070737287402153, 'loss_2': 0.00414276123046875, 'loss_3': -16.29939079284668, 'loss_4': 1.2379944324493408, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 11:24:31,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:31,729 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:46<04:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:24:39,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008342364802956581, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.487, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.004498595371842384, 'eval_loss_2': 0.0038437694311141968, 'eval_loss_3': -18.203514099121094, 'eval_loss_4': 1.2455852031707764, 'epoch': 28.49}
{'loss': 0.0172, 'grad_norm': 6.967537879943848, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.014448797330260277, 'loss_2': 0.00273895263671875, 'loss_3': -16.35138702392578, 'loss_4': 1.5185155868530273, 'epoch': 28.49}
{'loss': 0.0031, 'grad_norm': 4.424177646636963, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0020309381652623415, 'loss_2': 0.00103759765625, 'loss_3': -16.407556533813477, 'loss_4': 1.216456651687622, 'epoch': 28.5}
{'loss': 0.0068, 'grad_norm': 4.008349418640137, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.0028137045446783304, 'loss_2': 0.00402069091796875, 'loss_3': -16.376567840576172, 'loss_4': 0.7255662083625793, 'epoch': 28.51}
{'loss': 0.0081, 'grad_norm': 4.417483329772949, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0025707921013236046, 'loss_2': 0.00555419921875, 'loss_3': -16.09259033203125, 'loss_4': 1.612253189086914, 'epoch': 28.51}
{'loss': 0.007, 'grad_norm': 4.898282051086426, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.004172563552856445, 'loss_2': 0.0028362274169921875, 'loss_3': -16.473337173461914, 'loss_4': 1.3072515726089478, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 11:24:39,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:39,060 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:00:53<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:46,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008514119312167168, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.004559768363833427, 'eval_loss_2': 0.00395435094833374, 'eval_loss_3': -18.206056594848633, 'eval_loss_4': 1.2460500001907349, 'epoch': 28.52}
{'loss': 0.0085, 'grad_norm': 5.1287617683410645, 'learning_rate': 1.5e-06, 'loss_1': 0.003957458306103945, 'loss_2': 0.004550933837890625, 'loss_3': -16.41611099243164, 'loss_4': 1.7655236721038818, 'epoch': 28.52}
{'loss': 0.0104, 'grad_norm': 5.270575523376465, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.005623525008559227, 'loss_2': 0.0048065185546875, 'loss_3': -16.19860076904297, 'loss_4': 1.2516436576843262, 'epoch': 28.53}
{'loss': 0.0046, 'grad_norm': 5.609577655792236, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.0040360610000789165, 'loss_2': 0.0005207061767578125, 'loss_3': -16.261838912963867, 'loss_4': 1.344893455505371, 'epoch': 28.53}
{'loss': 0.0099, 'grad_norm': 5.073765754699707, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.00446651317179203, 'loss_2': 0.00543975830078125, 'loss_3': -16.275970458984375, 'loss_4': 1.525557279586792, 'epoch': 28.54}
{'loss': 0.0067, 'grad_norm': 4.177534580230713, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.0028420614544302225, 'loss_2': 0.0038738250732421875, 'loss_3': -16.317092895507812, 'loss_4': 1.4661502838134766, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 11:24:46,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:46,402 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:01:00<04:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:24:53,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008718102239072323, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004695682320743799, 'eval_loss_2': 0.004022419452667236, 'eval_loss_3': -18.20503807067871, 'eval_loss_4': 1.2175265550613403, 'epoch': 28.55}
{'loss': 0.0043, 'grad_norm': 4.314443111419678, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.0032150873448699713, 'loss_2': 0.0010852813720703125, 'loss_3': -16.372852325439453, 'loss_4': 1.5059747695922852, 'epoch': 28.55}
{'loss': 0.0058, 'grad_norm': 4.277041912078857, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.002450394444167614, 'loss_2': 0.00339508056640625, 'loss_3': -16.37344741821289, 'loss_4': 1.1895132064819336, 'epoch': 28.56}
{'loss': 0.0048, 'grad_norm': 5.234907627105713, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.004156988114118576, 'loss_2': 0.0006480216979980469, 'loss_3': -16.25385284423828, 'loss_4': 1.261711597442627, 'epoch': 28.56}
{'loss': 0.0083, 'grad_norm': 4.422392845153809, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.0031185250263661146, 'loss_2': 0.00518798828125, 'loss_3': -16.323854446411133, 'loss_4': 1.2279926538467407, 'epoch': 28.57}
{'loss': 0.007, 'grad_norm': 4.901315212249756, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.0052407281473279, 'loss_2': 0.0017795562744140625, 'loss_3': -16.404170989990234, 'loss_4': 1.203776478767395, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 11:24:53,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:24:53,744 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:08<04:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:01,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008964382112026215, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0049199676141142845, 'eval_loss_2': 0.0040444135665893555, 'eval_loss_3': -18.201562881469727, 'eval_loss_4': 1.1872799396514893, 'epoch': 28.58}
{'loss': 0.0074, 'grad_norm': 4.354010105133057, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.002881778636947274, 'loss_2': 0.004547119140625, 'loss_3': -16.355602264404297, 'loss_4': 1.2153373956680298, 'epoch': 28.58}
{'loss': 0.0088, 'grad_norm': 4.260809898376465, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.0022355210967361927, 'loss_2': 0.00652313232421875, 'loss_3': -16.350860595703125, 'loss_4': 1.5927708148956299, 'epoch': 28.59}
{'loss': 0.0023, 'grad_norm': 4.121501922607422, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.0019319044658914208, 'loss_2': 0.00041484832763671875, 'loss_3': -16.336740493774414, 'loss_4': 1.8541972637176514, 'epoch': 28.59}
{'loss': 0.0076, 'grad_norm': 6.481117248535156, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.007215948309749365, 'loss_2': 0.00036263465881347656, 'loss_3': -16.26983642578125, 'loss_4': 0.5139293670654297, 'epoch': 28.6}
{'loss': 0.0042, 'grad_norm': 4.136247158050537, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.003956622909754515, 'loss_2': 0.000240325927734375, 'loss_3': -16.466022491455078, 'loss_4': 1.0212409496307373, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 11:25:01,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:01,083 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:15<04:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:08,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009145940653979778, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005018653813749552, 'eval_loss_2': 0.004127286374568939, 'eval_loss_3': -18.201065063476562, 'eval_loss_4': 1.1733384132385254, 'epoch': 28.6}
{'loss': 0.0072, 'grad_norm': 4.891118049621582, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.002467074431478977, 'loss_2': 0.00476837158203125, 'loss_3': -16.484189987182617, 'loss_4': 1.3921432495117188, 'epoch': 28.61}
{'loss': 0.0109, 'grad_norm': 4.658945560455322, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.003190485527738929, 'loss_2': 0.0077056884765625, 'loss_3': -16.21657371520996, 'loss_4': 1.275590181350708, 'epoch': 28.62}
{'loss': 0.0127, 'grad_norm': 5.270966529846191, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.006821874529123306, 'loss_2': 0.00592041015625, 'loss_3': -16.436077117919922, 'loss_4': 0.6078243255615234, 'epoch': 28.62}
{'loss': 0.0034, 'grad_norm': 4.387341499328613, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.002888902323320508, 'loss_2': 0.0005240440368652344, 'loss_3': -16.254934310913086, 'loss_4': 1.2840999364852905, 'epoch': 28.63}
{'loss': 0.0027, 'grad_norm': 4.899572372436523, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.0020998804830014706, 'loss_2': 0.0006079673767089844, 'loss_3': -16.332277297973633, 'loss_4': 1.1071441173553467, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 11:25:08,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:08,426 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:22<03:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:15,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00942224357277155, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005030752159655094, 'eval_loss_2': 0.004391491413116455, 'eval_loss_3': -18.198482513427734, 'eval_loss_4': 1.1541508436203003, 'epoch': 28.63}
{'loss': 0.0049, 'grad_norm': 4.758000373840332, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.0027975214179605246, 'loss_2': 0.0020771026611328125, 'loss_3': -16.296619415283203, 'loss_4': 1.0321274995803833, 'epoch': 28.64}
{'loss': 0.0028, 'grad_norm': 4.429253578186035, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.002601709682494402, 'loss_2': 0.00020933151245117188, 'loss_3': -16.4764347076416, 'loss_4': 1.4512395858764648, 'epoch': 28.65}
{'loss': 0.0073, 'grad_norm': 4.705917835235596, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.005131581332534552, 'loss_2': 0.0021514892578125, 'loss_3': -16.46176528930664, 'loss_4': 1.2611074447631836, 'epoch': 28.65}
{'loss': 0.0061, 'grad_norm': 5.189627170562744, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.004157303832471371, 'loss_2': 0.0019359588623046875, 'loss_3': -16.338748931884766, 'loss_4': 1.485893964767456, 'epoch': 28.66}
{'loss': 0.0064, 'grad_norm': 4.188077449798584, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.0035559164825826883, 'loss_2': 0.002838134765625, 'loss_3': -16.339237213134766, 'loss_4': 1.1932549476623535, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 11:25:15,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:15,761 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:30<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:23,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0093946922570467, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004920529201626778, 'eval_loss_2': 0.004474163055419922, 'eval_loss_3': -18.19565200805664, 'eval_loss_4': 1.132415771484375, 'epoch': 28.66}
{'loss': 0.0043, 'grad_norm': 4.666597843170166, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.003701286856085062, 'loss_2': 0.0005807876586914062, 'loss_3': -16.34955596923828, 'loss_4': 1.3847072124481201, 'epoch': 28.67}
{'loss': 0.0044, 'grad_norm': 4.804737567901611, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.002991889836266637, 'loss_2': 0.001377105712890625, 'loss_3': -16.32143783569336, 'loss_4': 1.48160982131958, 'epoch': 28.67}
{'loss': 0.0246, 'grad_norm': 8.110620498657227, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.018698491156101227, 'loss_2': 0.0058746337890625, 'loss_3': -16.214956283569336, 'loss_4': 1.9596730470657349, 'epoch': 28.68}
{'loss': 0.005, 'grad_norm': 4.535128116607666, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.0027718169149011374, 'loss_2': 0.0021915435791015625, 'loss_3': -16.43341827392578, 'loss_4': 0.8078731298446655, 'epoch': 28.69}
{'loss': 0.0063, 'grad_norm': 4.245717525482178, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.0022307143080979586, 'loss_2': 0.00405120849609375, 'loss_3': -16.253721237182617, 'loss_4': 0.7150759100914001, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 11:25:23,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:23,111 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:37<03:51,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 11:25:30,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00939568504691124, 'eval_runtime': 4.0197, 'eval_samples_per_second': 254.743, 'eval_steps_per_second': 3.98, 'eval_loss_1': 0.004769544582813978, 'eval_loss_2': 0.004626139998435974, 'eval_loss_3': -18.195802688598633, 'eval_loss_4': 1.122255563735962, 'epoch': 28.69}
{'loss': 0.0081, 'grad_norm': 4.501095294952393, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.005372832529246807, 'loss_2': 0.002777099609375, 'loss_3': -16.394174575805664, 'loss_4': 0.4579240083694458, 'epoch': 28.7}
{'loss': 0.0039, 'grad_norm': 4.288729667663574, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.0029459036886692047, 'loss_2': 0.0009169578552246094, 'loss_3': -16.447063446044922, 'loss_4': 0.8642656803131104, 'epoch': 28.7}
{'loss': 0.0111, 'grad_norm': 4.7242302894592285, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.003760396735742688, 'loss_2': 0.0073394775390625, 'loss_3': -16.313905715942383, 'loss_4': 0.7335334420204163, 'epoch': 28.71}
{'loss': 0.0066, 'grad_norm': 5.213919162750244, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.005649783182889223, 'loss_2': 0.0009145736694335938, 'loss_3': -16.361980438232422, 'loss_4': 1.2307860851287842, 'epoch': 28.72}
{'loss': 0.0075, 'grad_norm': 9.073978424072266, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.005339794792234898, 'loss_2': 0.002166748046875, 'loss_3': -16.166824340820312, 'loss_4': 0.8119744062423706, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 11:25:30,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:30,675 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:45<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:38,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009491896256804466, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.809, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.004819994326680899, 'eval_loss_2': 0.00467190146446228, 'eval_loss_3': -18.195077896118164, 'eval_loss_4': 1.1094316244125366, 'epoch': 28.72}
{'loss': 0.0158, 'grad_norm': 7.277548789978027, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.009610253386199474, 'loss_2': 0.006237030029296875, 'loss_3': -16.485919952392578, 'loss_4': 0.793983519077301, 'epoch': 28.73}
{'loss': 0.0107, 'grad_norm': 4.501831531524658, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.001783902058377862, 'loss_2': 0.008941650390625, 'loss_3': -16.551124572753906, 'loss_4': 1.3539941310882568, 'epoch': 28.73}
{'loss': 0.0052, 'grad_norm': 4.9169840812683105, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.005059875547885895, 'loss_2': 0.00012826919555664062, 'loss_3': -16.3301944732666, 'loss_4': 0.6255938410758972, 'epoch': 28.74}
{'loss': 0.0048, 'grad_norm': 4.472614288330078, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.0015587591333314776, 'loss_2': 0.003238677978515625, 'loss_3': -16.284961700439453, 'loss_4': 1.0700323581695557, 'epoch': 28.74}
{'loss': 0.0052, 'grad_norm': 5.094686031341553, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.003620401956140995, 'loss_2': 0.0015888214111328125, 'loss_3': -16.207508087158203, 'loss_4': 1.0748692750930786, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 11:25:38,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:38,019 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:01:52<03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:45,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009630456566810608, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.004976749885827303, 'eval_loss_2': 0.004653707146644592, 'eval_loss_3': -18.193845748901367, 'eval_loss_4': 1.100105881690979, 'epoch': 28.75}
{'loss': 0.0074, 'grad_norm': 4.973533630371094, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.0035423929803073406, 'loss_2': 0.0038585662841796875, 'loss_3': -16.479108810424805, 'loss_4': 0.8573751449584961, 'epoch': 28.76}
{'loss': 0.0091, 'grad_norm': 5.845556259155273, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0045218318700790405, 'loss_2': 0.004566192626953125, 'loss_3': -16.232677459716797, 'loss_4': 0.9580073356628418, 'epoch': 28.76}
{'loss': 0.0157, 'grad_norm': 10.105293273925781, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.014975566416978836, 'loss_2': 0.0007238388061523438, 'loss_3': -16.44424057006836, 'loss_4': 1.6861927509307861, 'epoch': 28.77}
{'loss': 0.0041, 'grad_norm': 4.829205513000488, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.0025212184991687536, 'loss_2': 0.0015325546264648438, 'loss_3': -16.458084106445312, 'loss_4': 0.813620388507843, 'epoch': 28.77}
{'loss': 0.0059, 'grad_norm': 5.126442909240723, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.003747067879885435, 'loss_2': 0.002109527587890625, 'loss_3': -16.32324981689453, 'loss_4': 1.5300980806350708, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 11:25:45,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:45,360 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:01:59<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:25:52,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009514435194432735, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0050135403871536255, 'eval_loss_2': 0.004500895738601685, 'eval_loss_3': -18.192981719970703, 'eval_loss_4': 1.0926765203475952, 'epoch': 28.78}
{'loss': 0.0082, 'grad_norm': 6.5461201667785645, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.007907799445092678, 'loss_2': 0.0002932548522949219, 'loss_3': -16.43557357788086, 'loss_4': 1.9387192726135254, 'epoch': 28.78}
{'loss': 0.0054, 'grad_norm': 4.693382263183594, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.0036832792684435844, 'loss_2': 0.0016918182373046875, 'loss_3': -16.328725814819336, 'loss_4': 1.3730800151824951, 'epoch': 28.79}
{'loss': 0.0048, 'grad_norm': 4.631645679473877, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.0023233050014823675, 'loss_2': 0.00243377685546875, 'loss_3': -16.46175765991211, 'loss_4': 0.650307297706604, 'epoch': 28.8}
{'loss': 0.0133, 'grad_norm': 5.193491458892822, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.005059136543422937, 'loss_2': 0.008209228515625, 'loss_3': -16.46941375732422, 'loss_4': 1.064518690109253, 'epoch': 28.8}
{'loss': 0.0108, 'grad_norm': 6.309690475463867, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.01007029041647911, 'loss_2': 0.0006923675537109375, 'loss_3': -16.2279052734375, 'loss_4': 1.5060055255889893, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 11:25:52,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:25:52,700 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:02:07<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:00,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009498956613242626, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005060649011284113, 'eval_loss_2': 0.004438307136297226, 'eval_loss_3': -18.192745208740234, 'eval_loss_4': 1.0829750299453735, 'epoch': 28.81}
{'loss': 0.0117, 'grad_norm': 5.44743537902832, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.008439754135906696, 'loss_2': 0.003231048583984375, 'loss_3': -16.222871780395508, 'loss_4': 1.5130535364151, 'epoch': 28.81}
{'loss': 0.0127, 'grad_norm': 10.470876693725586, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.009435317479074001, 'loss_2': 0.003265380859375, 'loss_3': -16.15174102783203, 'loss_4': 0.96728515625, 'epoch': 28.82}
{'loss': 0.0031, 'grad_norm': 4.500866889953613, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.0028982283547520638, 'loss_2': 0.0001766681671142578, 'loss_3': -16.30571937561035, 'loss_4': 0.722766637802124, 'epoch': 28.83}
{'loss': 0.0048, 'grad_norm': 4.780773162841797, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.0041485745459795, 'loss_2': 0.0006914138793945312, 'loss_3': -16.28957176208496, 'loss_4': 1.2868804931640625, 'epoch': 28.83}
{'loss': 0.0053, 'grad_norm': 4.210857391357422, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.002033074852079153, 'loss_2': 0.0033016204833984375, 'loss_3': -16.517742156982422, 'loss_4': 1.373005747795105, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 11:26:00,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:00,052 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:14<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:07,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009380023926496506, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005039732903242111, 'eval_loss_2': 0.0043402910232543945, 'eval_loss_3': -18.19059944152832, 'eval_loss_4': 1.08585524559021, 'epoch': 28.84}
{'loss': 0.0137, 'grad_norm': 7.230996608734131, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.010305077768862247, 'loss_2': 0.0034313201904296875, 'loss_3': -16.324913024902344, 'loss_4': 1.6837602853775024, 'epoch': 28.84}
{'loss': 0.0064, 'grad_norm': 4.687748908996582, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.003581632161512971, 'loss_2': 0.0028285980224609375, 'loss_3': -16.4466552734375, 'loss_4': 0.8350620865821838, 'epoch': 28.85}
{'loss': 0.0155, 'grad_norm': 6.069848537445068, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.008080693893134594, 'loss_2': 0.007404327392578125, 'loss_3': -16.093250274658203, 'loss_4': 0.9138333201408386, 'epoch': 28.85}
{'loss': 0.0035, 'grad_norm': 4.221644401550293, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.0020200000144541264, 'loss_2': 0.001438140869140625, 'loss_3': -16.473430633544922, 'loss_4': 0.9714709520339966, 'epoch': 28.86}
{'loss': 0.0106, 'grad_norm': 4.811995506286621, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.0035375480074435472, 'loss_2': 0.007099151611328125, 'loss_3': -16.238548278808594, 'loss_4': 1.014835000038147, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 11:26:07,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:07,395 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:21<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:14,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00936758890748024, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.59, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005003709811717272, 'eval_loss_2': 0.004363879561424255, 'eval_loss_3': -18.188121795654297, 'eval_loss_4': 1.1145099401474, 'epoch': 28.87}
{'loss': 0.0045, 'grad_norm': 4.50993537902832, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.0025386910419911146, 'loss_2': 0.0019435882568359375, 'loss_3': -16.412927627563477, 'loss_4': 1.1008274555206299, 'epoch': 28.87}
{'loss': 0.0081, 'grad_norm': 4.850191116333008, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.0034992576111108065, 'loss_2': 0.00455474853515625, 'loss_3': -16.11792755126953, 'loss_4': 1.286569356918335, 'epoch': 28.88}
{'loss': 0.0019, 'grad_norm': 4.343317985534668, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.0017306586960330606, 'loss_2': 0.0001761913299560547, 'loss_3': -16.263158798217773, 'loss_4': 0.9245436787605286, 'epoch': 28.88}
{'loss': 0.0102, 'grad_norm': 4.531138896942139, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.004383993335068226, 'loss_2': 0.005859375, 'loss_3': -16.21048355102539, 'loss_4': 0.5672200322151184, 'epoch': 28.89}
{'loss': 0.0121, 'grad_norm': 6.189828872680664, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.009756701067090034, 'loss_2': 0.0023517608642578125, 'loss_3': -16.269927978515625, 'loss_4': 1.017395257949829, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 11:26:14,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:14,748 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:29<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:22,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009281816892325878, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00492984289303422, 'eval_loss_2': 0.004351973533630371, 'eval_loss_3': -18.188251495361328, 'eval_loss_4': 1.136207938194275, 'epoch': 28.9}
{'loss': 0.004, 'grad_norm': 4.064093112945557, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.002814485924318433, 'loss_2': 0.0011358261108398438, 'loss_3': -16.38010597229004, 'loss_4': 1.4513027667999268, 'epoch': 28.9}
{'loss': 0.0049, 'grad_norm': 4.8768086433410645, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.004375280346721411, 'loss_2': 0.0004901885986328125, 'loss_3': -16.288379669189453, 'loss_4': 1.0038633346557617, 'epoch': 28.91}
{'loss': 0.0098, 'grad_norm': 6.9542670249938965, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.006885406095534563, 'loss_2': 0.0029315948486328125, 'loss_3': -16.286178588867188, 'loss_4': 1.0342875719070435, 'epoch': 28.91}
{'loss': 0.0047, 'grad_norm': 4.371363639831543, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.0017358100740239024, 'loss_2': 0.00296783447265625, 'loss_3': -16.39044952392578, 'loss_4': 1.2445597648620605, 'epoch': 28.92}
{'loss': 0.0044, 'grad_norm': 4.558558464050293, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.0020805252715945244, 'loss_2': 0.002353668212890625, 'loss_3': -16.32358169555664, 'loss_4': 1.3711543083190918, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 11:26:22,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:22,087 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:36<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:29,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009143628180027008, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.881, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004857905674725771, 'eval_loss_2': 0.004285722970962524, 'eval_loss_3': -18.18792152404785, 'eval_loss_4': 1.1441636085510254, 'epoch': 28.92}
{'loss': 0.0054, 'grad_norm': 5.191753387451172, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.0042753666639328, 'loss_2': 0.00116729736328125, 'loss_3': -16.144113540649414, 'loss_4': 1.6529936790466309, 'epoch': 28.93}
{'loss': 0.0063, 'grad_norm': 4.452203750610352, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.002043558517470956, 'loss_2': 0.0042266845703125, 'loss_3': -16.30651092529297, 'loss_4': 1.1172358989715576, 'epoch': 28.94}
{'loss': 0.006, 'grad_norm': 4.69594144821167, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.003073892556130886, 'loss_2': 0.0029544830322265625, 'loss_3': -16.350622177124023, 'loss_4': 0.5956705808639526, 'epoch': 28.94}
{'loss': 0.0066, 'grad_norm': 4.926580905914307, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.004749014042317867, 'loss_2': 0.0018892288208007812, 'loss_3': -16.460811614990234, 'loss_4': 1.8111159801483154, 'epoch': 28.95}
{'loss': 0.0109, 'grad_norm': 8.302573204040527, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.008230909705162048, 'loss_2': 0.002635955810546875, 'loss_3': -16.417667388916016, 'loss_4': 0.8307780623435974, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 11:26:29,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:29,431 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:43<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:36,775 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009211267344653606, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004900704137980938, 'eval_loss_2': 0.0043105632066726685, 'eval_loss_3': -18.188753128051758, 'eval_loss_4': 1.142677664756775, 'epoch': 28.95}
{'loss': 0.0098, 'grad_norm': 4.414568901062012, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.0043024769984185696, 'loss_2': 0.0055084228515625, 'loss_3': -16.3241024017334, 'loss_4': 0.33227109909057617, 'epoch': 28.96}
{'loss': 0.014, 'grad_norm': 7.901628494262695, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.011165420524775982, 'loss_2': 0.002834320068359375, 'loss_3': -16.312000274658203, 'loss_4': 0.9096101522445679, 'epoch': 28.97}
{'loss': 0.0096, 'grad_norm': 4.502751350402832, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.004401876125484705, 'loss_2': 0.00522613525390625, 'loss_3': -16.652263641357422, 'loss_4': 1.2901432514190674, 'epoch': 28.97}
{'loss': 0.0017, 'grad_norm': 4.615279674530029, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0013452472630888224, 'loss_2': 0.0003838539123535156, 'loss_3': -16.43414878845215, 'loss_4': 1.0126036405563354, 'epoch': 28.98}
{'loss': 0.0036, 'grad_norm': 4.716148853302002, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0027480728458613157, 'loss_2': 0.0008392333984375, 'loss_3': -16.392379760742188, 'loss_4': 0.8884077668190002, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 11:26:36,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:36,775 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:51<02:49,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 11:26:43,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009129566140472889, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.944, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004835438448935747, 'eval_loss_2': 0.0042941272258758545, 'eval_loss_3': -18.188396453857422, 'eval_loss_4': 1.1404454708099365, 'epoch': 28.98}
{'loss': 0.0091, 'grad_norm': 5.216057300567627, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.005313185043632984, 'loss_2': 0.003749847412109375, 'loss_3': -16.423019409179688, 'loss_4': 1.0923304557800293, 'epoch': 28.99}
{'loss': 0.0071, 'grad_norm': 4.69777774810791, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.0030063437297940254, 'loss_2': 0.0040740966796875, 'loss_3': -16.153697967529297, 'loss_4': 0.988345742225647, 'epoch': 28.99}
{'loss': 0.0296, 'grad_norm': 24.5845947265625, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.02870163321495056, 'loss_2': 0.0009012222290039062, 'loss_3': -16.24905776977539, 'loss_4': 1.5127090215682983, 'epoch': 29.0}
{'loss': 0.0055, 'grad_norm': 4.989760398864746, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.0046342043206095695, 'loss_2': 0.0008487701416015625, 'loss_3': -16.319290161132812, 'loss_4': 1.024898648262024, 'epoch': 29.01}
{'loss': 0.0063, 'grad_norm': 5.272006034851074, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.004592029843479395, 'loss_2': 0.001674652099609375, 'loss_3': -16.390766143798828, 'loss_4': 0.7051978707313538, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 11:26:43,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:43,813 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:02:58<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 11:26:51,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009176287800073624, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004880987107753754, 'eval_loss_2': 0.00429530069231987, 'eval_loss_3': -18.185100555419922, 'eval_loss_4': 1.138761281967163, 'epoch': 29.01}
{'loss': 0.0064, 'grad_norm': 4.782322883605957, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.004548768512904644, 'loss_2': 0.00188446044921875, 'loss_3': -16.23087501525879, 'loss_4': 0.8650249242782593, 'epoch': 29.02}
{'loss': 0.0057, 'grad_norm': 5.161349296569824, 'learning_rate': 1e-06, 'loss_1': 0.0035162067506462336, 'loss_2': 0.0021381378173828125, 'loss_3': -16.39352798461914, 'loss_4': 1.21718430519104, 'epoch': 29.02}
{'loss': 0.0063, 'grad_norm': 4.428410530090332, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.002185150980949402, 'loss_2': 0.00409698486328125, 'loss_3': -16.557815551757812, 'loss_4': 1.094597578048706, 'epoch': 29.03}
{'loss': 0.0076, 'grad_norm': 5.716756343841553, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.0071263848803937435, 'loss_2': 0.0005016326904296875, 'loss_3': -16.526823043823242, 'loss_4': 0.48635995388031006, 'epoch': 29.03}
{'loss': 0.008, 'grad_norm': 4.738702774047852, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.004039272200316191, 'loss_2': 0.0039215087890625, 'loss_3': -16.250919342041016, 'loss_4': 0.9140913486480713, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 11:26:51,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:51,164 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:03:05<02:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:26:58,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009026010520756245, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.506, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004793551750481129, 'eval_loss_2': 0.004232458770275116, 'eval_loss_3': -18.181293487548828, 'eval_loss_4': 1.13986337184906, 'epoch': 29.04}
{'loss': 0.0085, 'grad_norm': 4.685674667358398, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.003445744514465332, 'loss_2': 0.00506591796875, 'loss_3': -16.35524559020996, 'loss_4': 1.2853782176971436, 'epoch': 29.05}
{'loss': 0.0043, 'grad_norm': 4.743565559387207, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.0035042178351432085, 'loss_2': 0.0008115768432617188, 'loss_3': -16.337604522705078, 'loss_4': 1.1154353618621826, 'epoch': 29.05}
{'loss': 0.0091, 'grad_norm': 5.8119659423828125, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.005655377171933651, 'loss_2': 0.003459930419921875, 'loss_3': -16.37299346923828, 'loss_4': 0.9719007015228271, 'epoch': 29.06}
{'loss': 0.0092, 'grad_norm': 6.152472972869873, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.007252638228237629, 'loss_2': 0.0019378662109375, 'loss_3': -16.29405403137207, 'loss_4': 2.0744948387145996, 'epoch': 29.06}
{'loss': 0.0044, 'grad_norm': 4.495572566986084, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0023270954843610525, 'loss_2': 0.0020904541015625, 'loss_3': -16.367996215820312, 'loss_4': 1.1132566928863525, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 11:26:58,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:26:58,517 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:13<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:05,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009289028123021126, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004950420465320349, 'eval_loss_2': 0.00433860719203949, 'eval_loss_3': -18.17765235900879, 'eval_loss_4': 1.1407291889190674, 'epoch': 29.07}
{'loss': 0.0058, 'grad_norm': 5.315457344055176, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.004522598814219236, 'loss_2': 0.0012359619140625, 'loss_3': -16.387374877929688, 'loss_4': 0.8992391228675842, 'epoch': 29.08}
{'loss': 0.0022, 'grad_norm': 4.716911315917969, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.002101754769682884, 'loss_2': 0.00012242794036865234, 'loss_3': -16.40826988220215, 'loss_4': 1.333439588546753, 'epoch': 29.08}
{'loss': 0.011, 'grad_norm': 4.955015182495117, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.006886632647365332, 'loss_2': 0.00409698486328125, 'loss_3': -16.33708381652832, 'loss_4': 1.4672510623931885, 'epoch': 29.09}
{'loss': 0.0365, 'grad_norm': 17.213056564331055, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.031444989144802094, 'loss_2': 0.00501251220703125, 'loss_3': -16.438276290893555, 'loss_4': 1.040863275527954, 'epoch': 29.09}
{'loss': 0.0071, 'grad_norm': 5.785759925842285, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.005372744984924793, 'loss_2': 0.001705169677734375, 'loss_3': -16.201169967651367, 'loss_4': 1.1152567863464355, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 11:27:05,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:05,865 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:20<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:13,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009538335725665092, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0050902655348181725, 'eval_loss_2': 0.004448071122169495, 'eval_loss_3': -18.17323875427246, 'eval_loss_4': 1.1448673009872437, 'epoch': 29.1}
{'loss': 0.0028, 'grad_norm': 4.27462100982666, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.0023712334223091602, 'loss_2': 0.0004782676696777344, 'loss_3': -16.254465103149414, 'loss_4': 1.0908985137939453, 'epoch': 29.1}
{'loss': 0.0033, 'grad_norm': 4.815589904785156, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.002896198071539402, 'loss_2': 0.00040268898010253906, 'loss_3': -16.34516716003418, 'loss_4': 1.171851634979248, 'epoch': 29.11}
{'loss': 0.0151, 'grad_norm': 6.914069175720215, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.014323344454169273, 'loss_2': 0.0007696151733398438, 'loss_3': -16.287384033203125, 'loss_4': 1.0765342712402344, 'epoch': 29.12}
{'loss': 0.0137, 'grad_norm': 7.4820475578308105, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.007515945006161928, 'loss_2': 0.00623321533203125, 'loss_3': -16.397327423095703, 'loss_4': 1.1549115180969238, 'epoch': 29.12}
{'loss': 0.0078, 'grad_norm': 5.143831729888916, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.005806495901197195, 'loss_2': 0.0020046234130859375, 'loss_3': -16.240646362304688, 'loss_4': 1.3032336235046387, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 11:27:13,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:13,207 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:27<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:20,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00969298742711544, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.207, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005265990272164345, 'eval_loss_2': 0.004426997154951096, 'eval_loss_3': -18.172229766845703, 'eval_loss_4': 1.140326738357544, 'epoch': 29.13}
{'loss': 0.0099, 'grad_norm': 7.444820404052734, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.00807749480009079, 'loss_2': 0.0017795562744140625, 'loss_3': -16.172508239746094, 'loss_4': 0.8217065930366516, 'epoch': 29.13}
{'loss': 0.0031, 'grad_norm': 4.757770538330078, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.0019707102328538895, 'loss_2': 0.0011663436889648438, 'loss_3': -16.485145568847656, 'loss_4': 0.7654978036880493, 'epoch': 29.14}
{'loss': 0.0026, 'grad_norm': 4.149288177490234, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.0025750757195055485, 'loss_2': 4.9591064453125e-05, 'loss_3': -16.299007415771484, 'loss_4': 1.2663123607635498, 'epoch': 29.15}
{'loss': 0.0111, 'grad_norm': 4.662264347076416, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.005726569332182407, 'loss_2': 0.005382537841796875, 'loss_3': -16.378219604492188, 'loss_4': 1.1365920305252075, 'epoch': 29.15}
{'loss': 0.0056, 'grad_norm': 4.690443515777588, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0025478650350123644, 'loss_2': 0.00307464599609375, 'loss_3': -16.329002380371094, 'loss_4': 1.1466946601867676, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 11:27:20,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:20,549 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:35<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:27,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009644671343266964, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005232169758528471, 'eval_loss_2': 0.00441250205039978, 'eval_loss_3': -18.173715591430664, 'eval_loss_4': 1.1391352415084839, 'epoch': 29.16}
{'loss': 0.0078, 'grad_norm': 6.676781177520752, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.006602419074624777, 'loss_2': 0.001194000244140625, 'loss_3': -16.111852645874023, 'loss_4': 1.8033732175827026, 'epoch': 29.16}
{'loss': 0.0063, 'grad_norm': 4.458311080932617, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.0029811295680701733, 'loss_2': 0.00328826904296875, 'loss_3': -16.319438934326172, 'loss_4': 1.4521923065185547, 'epoch': 29.17}
{'loss': 0.0032, 'grad_norm': 4.409404754638672, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.002351186005398631, 'loss_2': 0.0008192062377929688, 'loss_3': -16.332975387573242, 'loss_4': 0.7135981321334839, 'epoch': 29.17}
{'loss': 0.0035, 'grad_norm': 4.159538269042969, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.0025896886363625526, 'loss_2': 0.0009579658508300781, 'loss_3': -16.488265991210938, 'loss_4': 0.8365106582641602, 'epoch': 29.18}
{'loss': 0.0079, 'grad_norm': 4.312255859375, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.0022569086868315935, 'loss_2': 0.00560760498046875, 'loss_3': -16.28158950805664, 'loss_4': 0.9652705788612366, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 11:27:27,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:27,886 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:42<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:35,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009707845747470856, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005373531021177769, 'eval_loss_2': 0.004334315657615662, 'eval_loss_3': -18.18033218383789, 'eval_loss_4': 1.1234736442565918, 'epoch': 29.19}
{'loss': 0.0121, 'grad_norm': 6.160987377166748, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.007552786264568567, 'loss_2': 0.00452423095703125, 'loss_3': -16.31207275390625, 'loss_4': 1.76656973361969, 'epoch': 29.19}
{'loss': 0.008, 'grad_norm': 6.496117115020752, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.004745864775031805, 'loss_2': 0.0032939910888671875, 'loss_3': -16.548818588256836, 'loss_4': 0.7469576001167297, 'epoch': 29.2}
{'loss': 0.0119, 'grad_norm': 4.4832539558410645, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.004542720969766378, 'loss_2': 0.00736236572265625, 'loss_3': -16.301822662353516, 'loss_4': 0.9783764481544495, 'epoch': 29.2}
{'loss': 0.0108, 'grad_norm': 4.292347431182861, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.004126725252717733, 'loss_2': 0.00670623779296875, 'loss_3': -16.252103805541992, 'loss_4': 1.0548334121704102, 'epoch': 29.21}
{'loss': 0.0069, 'grad_norm': 5.093724250793457, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.005809161812067032, 'loss_2': 0.001117706298828125, 'loss_3': -16.442384719848633, 'loss_4': 0.2661278247833252, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 11:27:35,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:35,240 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:49<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:42,582 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009806675836443901, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005444211885333061, 'eval_loss_2': 0.00436246395111084, 'eval_loss_3': -18.182771682739258, 'eval_loss_4': 1.108959436416626, 'epoch': 29.22}
{'loss': 0.0139, 'grad_norm': 5.199334144592285, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0059173558838665485, 'loss_2': 0.00799560546875, 'loss_3': -16.166791915893555, 'loss_4': 1.2512445449829102, 'epoch': 29.22}
{'loss': 0.0048, 'grad_norm': 4.9208292961120605, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.0018350520404055715, 'loss_2': 0.0029296875, 'loss_3': -16.226673126220703, 'loss_4': 1.428030252456665, 'epoch': 29.23}
{'loss': 0.0072, 'grad_norm': 6.395284652709961, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.006517734378576279, 'loss_2': 0.0006551742553710938, 'loss_3': -16.47400665283203, 'loss_4': 0.7920144200325012, 'epoch': 29.23}
{'loss': 0.0046, 'grad_norm': 4.378222942352295, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.0024912094231694937, 'loss_2': 0.002147674560546875, 'loss_3': -16.074750900268555, 'loss_4': 1.23575758934021, 'epoch': 29.24}
{'loss': 0.0073, 'grad_norm': 4.389845371246338, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.0026988056488335133, 'loss_2': 0.0045928955078125, 'loss_3': -16.261720657348633, 'loss_4': 1.461620807647705, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 11:27:42,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:42,582 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:03:57<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:49,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009788691066205502, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005404828581959009, 'eval_loss_2': 0.004383862018585205, 'eval_loss_3': -18.1838436126709, 'eval_loss_4': 1.101054310798645, 'epoch': 29.24}
{'loss': 0.0139, 'grad_norm': 7.923924446105957, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.011327235959470272, 'loss_2': 0.00252532958984375, 'loss_3': -16.301685333251953, 'loss_4': 0.718504786491394, 'epoch': 29.25}
{'loss': 0.021, 'grad_norm': 16.432870864868164, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.01783698983490467, 'loss_2': 0.00313568115234375, 'loss_3': -16.381628036499023, 'loss_4': 0.7965406179428101, 'epoch': 29.26}
{'loss': 0.0183, 'grad_norm': 7.6304779052734375, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.014588871039450169, 'loss_2': 0.0037078857421875, 'loss_3': -16.4440975189209, 'loss_4': 1.0461161136627197, 'epoch': 29.26}
{'loss': 0.0057, 'grad_norm': 4.3647141456604, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0032170491758733988, 'loss_2': 0.002452850341796875, 'loss_3': -16.331296920776367, 'loss_4': 1.094810128211975, 'epoch': 29.27}
{'loss': 0.0079, 'grad_norm': 4.577301025390625, 'learning_rate': 7.5e-07, 'loss_1': 0.0027348273433744907, 'loss_2': 0.005130767822265625, 'loss_3': -16.297000885009766, 'loss_4': 0.6639794111251831, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 11:27:49,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:49,928 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:04:04<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:27:57,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009696045890450478, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.735, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005314210895448923, 'eval_loss_2': 0.004381835460662842, 'eval_loss_3': -18.184715270996094, 'eval_loss_4': 1.093679666519165, 'epoch': 29.27}
{'loss': 0.0052, 'grad_norm': 5.193380832672119, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.0038584545254707336, 'loss_2': 0.00135040283203125, 'loss_3': -16.468875885009766, 'loss_4': 1.133028268814087, 'epoch': 29.28}
{'loss': 0.0059, 'grad_norm': 4.9294915199279785, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0038628331385552883, 'loss_2': 0.0020427703857421875, 'loss_3': -16.398542404174805, 'loss_4': 0.5474492311477661, 'epoch': 29.28}
{'loss': 0.0061, 'grad_norm': 4.950504779815674, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.005958547815680504, 'loss_2': 0.00010788440704345703, 'loss_3': -16.250640869140625, 'loss_4': 1.2562408447265625, 'epoch': 29.29}
{'loss': 0.0178, 'grad_norm': 10.127091407775879, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.010865486226975918, 'loss_2': 0.0069122314453125, 'loss_3': -16.298259735107422, 'loss_4': 0.9437958598136902, 'epoch': 29.3}
{'loss': 0.011, 'grad_norm': 5.027803421020508, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.010106952860951424, 'loss_2': 0.0009369850158691406, 'loss_3': -16.331912994384766, 'loss_4': 1.940618872642517, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 11:27:57,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:27:57,280 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:11<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:04,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009492921642959118, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.281, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00518098846077919, 'eval_loss_2': 0.0043119341135025024, 'eval_loss_3': -18.184131622314453, 'eval_loss_4': 1.0960396528244019, 'epoch': 29.3}
{'loss': 0.0055, 'grad_norm': 4.6580963134765625, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.0033173796255141497, 'loss_2': 0.002223968505859375, 'loss_3': -16.463653564453125, 'loss_4': 0.7553776502609253, 'epoch': 29.31}
{'loss': 0.004, 'grad_norm': 4.27341365814209, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.001316542737185955, 'loss_2': 0.002727508544921875, 'loss_3': -16.45328140258789, 'loss_4': 1.4075217247009277, 'epoch': 29.31}
{'loss': 0.0107, 'grad_norm': 7.96656608581543, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.008537482470273972, 'loss_2': 0.0021190643310546875, 'loss_3': -16.12636947631836, 'loss_4': 0.8789737820625305, 'epoch': 29.32}
{'loss': 0.0055, 'grad_norm': 4.071642875671387, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.0037151311989873648, 'loss_2': 0.001827239990234375, 'loss_3': -16.078845977783203, 'loss_4': 1.4798707962036133, 'epoch': 29.33}
{'loss': 0.007, 'grad_norm': 5.153242588043213, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.002057697856798768, 'loss_2': 0.00492095947265625, 'loss_3': -16.35311508178711, 'loss_4': 0.8248744010925293, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 11:28:04,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:04,621 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:19<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:11,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009315446019172668, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.79, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005046031903475523, 'eval_loss_2': 0.004269413650035858, 'eval_loss_3': -18.186168670654297, 'eval_loss_4': 1.0879462957382202, 'epoch': 29.33}
{'loss': 0.0093, 'grad_norm': 4.716159820556641, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.003698262618854642, 'loss_2': 0.00563812255859375, 'loss_3': -16.256359100341797, 'loss_4': 1.2009103298187256, 'epoch': 29.34}
{'loss': 0.0083, 'grad_norm': 7.382955074310303, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.008089698851108551, 'loss_2': 0.00016200542449951172, 'loss_3': -16.142934799194336, 'loss_4': 1.722575306892395, 'epoch': 29.34}
{'loss': 0.0048, 'grad_norm': 4.77062463760376, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.00427734712138772, 'loss_2': 0.0005502700805664062, 'loss_3': -16.370195388793945, 'loss_4': 1.4115756750106812, 'epoch': 29.35}
{'loss': 0.0081, 'grad_norm': 4.574418544769287, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.002543066395446658, 'loss_2': 0.0055084228515625, 'loss_3': -16.490768432617188, 'loss_4': 0.7394906282424927, 'epoch': 29.35}
{'loss': 0.0115, 'grad_norm': 5.12363338470459, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.005046513397246599, 'loss_2': 0.0064849853515625, 'loss_3': -16.11111068725586, 'loss_4': 0.6718710660934448, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 11:28:11,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:11,975 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:26<01:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:19,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009161978960037231, 'eval_runtime': 3.8222, 'eval_samples_per_second': 267.911, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.004914104472845793, 'eval_loss_2': 0.004247874021530151, 'eval_loss_3': -18.188207626342773, 'eval_loss_4': 1.0720679759979248, 'epoch': 29.36}
{'loss': 0.0159, 'grad_norm': 8.142261505126953, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.008612459525465965, 'loss_2': 0.007274627685546875, 'loss_3': -16.41518783569336, 'loss_4': 1.139096975326538, 'epoch': 29.37}
{'loss': 0.0034, 'grad_norm': 4.68827486038208, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0026591073255985975, 'loss_2': 0.0007114410400390625, 'loss_3': -16.264183044433594, 'loss_4': 0.9639977812767029, 'epoch': 29.37}
{'loss': 0.0088, 'grad_norm': 5.112847805023193, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.006449471227824688, 'loss_2': 0.0023956298828125, 'loss_3': -16.26675796508789, 'loss_4': 1.8724465370178223, 'epoch': 29.38}
{'loss': 0.0049, 'grad_norm': 5.005712985992432, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.0037595373578369617, 'loss_2': 0.0011606216430664062, 'loss_3': -16.35476303100586, 'loss_4': 1.0591115951538086, 'epoch': 29.38}
{'loss': 0.0057, 'grad_norm': 4.914524555206299, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.004786312580108643, 'loss_2': 0.0009121894836425781, 'loss_3': -16.261167526245117, 'loss_4': 0.8449967503547668, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 11:28:19,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:19,347 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:33<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:26,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009154969826340675, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00488758971914649, 'eval_loss_2': 0.004267379641532898, 'eval_loss_3': -18.19087791442871, 'eval_loss_4': 1.0612211227416992, 'epoch': 29.39}
{'loss': 0.0059, 'grad_norm': 4.512098789215088, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.003234072821214795, 'loss_2': 0.0026607513427734375, 'loss_3': -16.377079010009766, 'loss_4': 0.7353549003601074, 'epoch': 29.4}
{'loss': 0.0045, 'grad_norm': 4.425920009613037, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.0031680031679570675, 'loss_2': 0.001312255859375, 'loss_3': -16.257915496826172, 'loss_4': 1.6133631467819214, 'epoch': 29.4}
{'loss': 0.006, 'grad_norm': 4.7791242599487305, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.0035734849516302347, 'loss_2': 0.002410888671875, 'loss_3': -16.241558074951172, 'loss_4': 1.5853285789489746, 'epoch': 29.41}
{'loss': 0.0082, 'grad_norm': 4.882710933685303, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.005063571035861969, 'loss_2': 0.0031299591064453125, 'loss_3': -16.37569236755371, 'loss_4': 0.8010540008544922, 'epoch': 29.41}
{'loss': 0.0025, 'grad_norm': 4.912712574005127, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.002234140643849969, 'loss_2': 0.00027942657470703125, 'loss_3': -16.421369552612305, 'loss_4': 0.7090362310409546, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 11:28:26,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:26,690 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:41<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:34,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009180213324725628, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.266, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0048944829031825066, 'eval_loss_2': 0.004285730421543121, 'eval_loss_3': -18.193166732788086, 'eval_loss_4': 1.0484627485275269, 'epoch': 29.42}
{'loss': 0.0034, 'grad_norm': 4.360365390777588, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0027069232892245054, 'loss_2': 0.0007114410400390625, 'loss_3': -16.204133987426758, 'loss_4': 1.3751099109649658, 'epoch': 29.42}
{'loss': 0.008, 'grad_norm': 6.940985679626465, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.006821833085268736, 'loss_2': 0.0011348724365234375, 'loss_3': -16.289724349975586, 'loss_4': 1.2017383575439453, 'epoch': 29.43}
{'loss': 0.0096, 'grad_norm': 4.287634372711182, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.0020191739313304424, 'loss_2': 0.00756072998046875, 'loss_3': -16.373844146728516, 'loss_4': 0.9031409025192261, 'epoch': 29.44}
{'loss': 0.0042, 'grad_norm': 5.209384918212891, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.0028282329440116882, 'loss_2': 0.001407623291015625, 'loss_3': -16.355335235595703, 'loss_4': 0.893325686454773, 'epoch': 29.44}
{'loss': 0.0102, 'grad_norm': 4.505609512329102, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.003171163145452738, 'loss_2': 0.007049560546875, 'loss_3': -16.483463287353516, 'loss_4': 0.8986785411834717, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 11:28:34,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:34,027 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:48<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:41,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009128544479608536, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004830766469240189, 'eval_loss_2': 0.004297778010368347, 'eval_loss_3': -18.193092346191406, 'eval_loss_4': 1.0391005277633667, 'epoch': 29.45}
{'loss': 0.0029, 'grad_norm': 4.339343547821045, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0028837169520556927, 'loss_2': 4.661083221435547e-05, 'loss_3': -16.39578628540039, 'loss_4': 1.4246567487716675, 'epoch': 29.45}
{'loss': 0.0097, 'grad_norm': 5.9063520431518555, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.005909373983740807, 'loss_2': 0.003826141357421875, 'loss_3': -16.32918930053711, 'loss_4': 0.9567105770111084, 'epoch': 29.46}
{'loss': 0.0065, 'grad_norm': 4.879467487335205, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.0035365535877645016, 'loss_2': 0.002964019775390625, 'loss_3': -16.414264678955078, 'loss_4': 0.8402307629585266, 'epoch': 29.47}
{'loss': 0.0063, 'grad_norm': 4.268473148345947, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.003081920091062784, 'loss_2': 0.0031948089599609375, 'loss_3': -16.349044799804688, 'loss_4': 1.3848097324371338, 'epoch': 29.47}
{'loss': 0.007, 'grad_norm': 4.517467975616455, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.002539191860705614, 'loss_2': 0.00445556640625, 'loss_3': -16.27696990966797, 'loss_4': 0.9912337064743042, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 11:28:41,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:41,368 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:04:55<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:48,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00912039540708065, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004798842128366232, 'eval_loss_2': 0.004321552813053131, 'eval_loss_3': -18.19151496887207, 'eval_loss_4': 1.0320532321929932, 'epoch': 29.48}
{'loss': 0.0167, 'grad_norm': 7.383827209472656, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.010412284173071384, 'loss_2': 0.006317138671875, 'loss_3': -16.136314392089844, 'loss_4': 1.3304443359375, 'epoch': 29.48}
{'loss': 0.0053, 'grad_norm': 4.546534538269043, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.002773724030703306, 'loss_2': 0.00251007080078125, 'loss_3': -16.274023056030273, 'loss_4': 1.1726489067077637, 'epoch': 29.49}
{'loss': 0.0072, 'grad_norm': 4.381307125091553, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.004361653234809637, 'loss_2': 0.0028553009033203125, 'loss_3': -16.185909271240234, 'loss_4': 0.7837940454483032, 'epoch': 29.49}
{'loss': 0.0033, 'grad_norm': 4.651462554931641, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.003002497600391507, 'loss_2': 0.0003230571746826172, 'loss_3': -16.149288177490234, 'loss_4': 1.3646087646484375, 'epoch': 29.5}
{'loss': 0.0096, 'grad_norm': 4.665851593017578, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.004243563860654831, 'loss_2': 0.005329132080078125, 'loss_3': -16.324607849121094, 'loss_4': 0.6323876976966858, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 11:28:48,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:48,716 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:05:03<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:28:56,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009091288782656193, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004773840773850679, 'eval_loss_2': 0.004317447543144226, 'eval_loss_3': -18.190505981445312, 'eval_loss_4': 1.0407503843307495, 'epoch': 29.51}
{'loss': 0.0064, 'grad_norm': 5.12137508392334, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.0035346951335668564, 'loss_2': 0.0029125213623046875, 'loss_3': -16.265851974487305, 'loss_4': 0.9508994221687317, 'epoch': 29.51}
{'loss': 0.0036, 'grad_norm': 4.477573871612549, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0026527598965913057, 'loss_2': 0.0009069442749023438, 'loss_3': -16.3116397857666, 'loss_4': 0.48074832558631897, 'epoch': 29.52}
{'loss': 0.0041, 'grad_norm': 4.8783650398254395, 'learning_rate': 5e-07, 'loss_1': 0.002518795896321535, 'loss_2': 0.0016040802001953125, 'loss_3': -16.36070442199707, 'loss_4': 1.0304181575775146, 'epoch': 29.52}
{'loss': 0.0077, 'grad_norm': 5.242990970611572, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.0045670694671571255, 'loss_2': 0.0031566619873046875, 'loss_3': -16.217525482177734, 'loss_4': 1.124770164489746, 'epoch': 29.53}
{'loss': 0.004, 'grad_norm': 4.664971351623535, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0031206354033201933, 'loss_2': 0.0008754730224609375, 'loss_3': -16.338424682617188, 'loss_4': 1.606838583946228, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 11:28:56,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:28:56,074 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:10<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:03,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009088460355997086, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.789, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.004795226268470287, 'eval_loss_2': 0.004293233156204224, 'eval_loss_3': -18.189476013183594, 'eval_loss_4': 1.0470789670944214, 'epoch': 29.53}
{'loss': 0.0098, 'grad_norm': 5.355171203613281, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.003340348368510604, 'loss_2': 0.0064544677734375, 'loss_3': -16.217557907104492, 'loss_4': 1.1504156589508057, 'epoch': 29.54}
{'loss': 0.0107, 'grad_norm': 5.042137622833252, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.004822613205760717, 'loss_2': 0.005878448486328125, 'loss_3': -16.154037475585938, 'loss_4': 1.1570320129394531, 'epoch': 29.55}
{'loss': 0.0085, 'grad_norm': 4.766819477081299, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.003849494969472289, 'loss_2': 0.00469970703125, 'loss_3': -16.314294815063477, 'loss_4': 0.9939475059509277, 'epoch': 29.55}
{'loss': 0.0038, 'grad_norm': 4.130852699279785, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0014681172324344516, 'loss_2': 0.00229644775390625, 'loss_3': -16.35142707824707, 'loss_4': 1.5960571765899658, 'epoch': 29.56}
{'loss': 0.0025, 'grad_norm': 4.756248950958252, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.0023221459705382586, 'loss_2': 0.00021004676818847656, 'loss_3': -16.421825408935547, 'loss_4': 0.954810619354248, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 11:29:03,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:03,424 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:17<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:10,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0090892743319273, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.642, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004790021106600761, 'eval_loss_2': 0.004299253225326538, 'eval_loss_3': -18.188596725463867, 'eval_loss_4': 1.0527644157409668, 'epoch': 29.56}
{'loss': 0.003, 'grad_norm': 4.274266242980957, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0016101640649139881, 'loss_2': 0.0014286041259765625, 'loss_3': -16.512191772460938, 'loss_4': 1.113961935043335, 'epoch': 29.57}
{'loss': 0.0155, 'grad_norm': 5.65511417388916, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.007314420770853758, 'loss_2': 0.00820159912109375, 'loss_3': -16.136844635009766, 'loss_4': 1.4542052745819092, 'epoch': 29.58}
{'loss': 0.0221, 'grad_norm': 10.722064971923828, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.015718884766101837, 'loss_2': 0.006374359130859375, 'loss_3': -16.38381576538086, 'loss_4': 1.2633016109466553, 'epoch': 29.58}
{'loss': 0.0433, 'grad_norm': 14.201737403869629, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.0379117876291275, 'loss_2': 0.00534820556640625, 'loss_3': -16.174278259277344, 'loss_4': 1.3244097232818604, 'epoch': 29.59}
{'loss': 0.0111, 'grad_norm': 6.350248336791992, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.006507071200758219, 'loss_2': 0.00457763671875, 'loss_3': -16.28738021850586, 'loss_4': 0.6019291281700134, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 11:29:10,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:10,771 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:25<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:18,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009077745489776134, 'eval_runtime': 3.8266, 'eval_samples_per_second': 267.598, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.004799503367394209, 'eval_loss_2': 0.004278242588043213, 'eval_loss_3': -18.18724250793457, 'eval_loss_4': 1.0559794902801514, 'epoch': 29.59}
{'loss': 0.0067, 'grad_norm': 4.7620768547058105, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.003862124402076006, 'loss_2': 0.0028209686279296875, 'loss_3': -16.465396881103516, 'loss_4': 1.021270751953125, 'epoch': 29.6}
{'loss': 0.0055, 'grad_norm': 4.251013278961182, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.0025239125825464725, 'loss_2': 0.0029811859130859375, 'loss_3': -16.351577758789062, 'loss_4': 1.1888806819915771, 'epoch': 29.6}
{'loss': 0.0089, 'grad_norm': 4.870343208312988, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.003487473586574197, 'loss_2': 0.00542449951171875, 'loss_3': -16.305160522460938, 'loss_4': 1.100055456161499, 'epoch': 29.61}
{'loss': 0.0107, 'grad_norm': 7.00186014175415, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.008289868012070656, 'loss_2': 0.002407073974609375, 'loss_3': -16.46641731262207, 'loss_4': 1.6162680387496948, 'epoch': 29.62}
{'loss': 0.0108, 'grad_norm': 5.463199138641357, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.008342565968632698, 'loss_2': 0.002483367919921875, 'loss_3': -16.376976013183594, 'loss_4': 1.4463424682617188, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 11:29:18,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:18,141 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:32<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:25,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009063931182026863, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0047957031056284904, 'eval_loss_2': 0.004268229007720947, 'eval_loss_3': -18.187992095947266, 'eval_loss_4': 1.0550580024719238, 'epoch': 29.62}
{'loss': 0.0061, 'grad_norm': 4.792657852172852, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.004832046572118998, 'loss_2': 0.0012922286987304688, 'loss_3': -16.20958709716797, 'loss_4': 0.8553701043128967, 'epoch': 29.63}
{'loss': 0.0064, 'grad_norm': 4.434712886810303, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.002752783475443721, 'loss_2': 0.003681182861328125, 'loss_3': -16.23165512084961, 'loss_4': 1.7017223834991455, 'epoch': 29.63}
{'loss': 0.0078, 'grad_norm': 4.419307231903076, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.002865180838853121, 'loss_2': 0.0049285888671875, 'loss_3': -16.25151824951172, 'loss_4': 1.0821269750595093, 'epoch': 29.64}
{'loss': 0.0058, 'grad_norm': 4.488954544067383, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.004490528255701065, 'loss_2': 0.001346588134765625, 'loss_3': -16.173669815063477, 'loss_4': 1.915250539779663, 'epoch': 29.65}
{'loss': 0.0091, 'grad_norm': 4.586785793304443, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.004711570683866739, 'loss_2': 0.00437164306640625, 'loss_3': -16.278778076171875, 'loss_4': 1.11940336227417, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 11:29:25,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:25,474 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:40<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:32,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009025802835822105, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.458, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004752686712890863, 'eval_loss_2': 0.004273116588592529, 'eval_loss_3': -18.188791275024414, 'eval_loss_4': 1.0531195402145386, 'epoch': 29.65}
{'loss': 0.0064, 'grad_norm': 4.865333080291748, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.0035499020013958216, 'loss_2': 0.0028057098388671875, 'loss_3': -16.36910629272461, 'loss_4': 0.6575034260749817, 'epoch': 29.66}
{'loss': 0.0079, 'grad_norm': 4.623732089996338, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.0030623667407780886, 'loss_2': 0.00482177734375, 'loss_3': -16.232730865478516, 'loss_4': 1.5562653541564941, 'epoch': 29.66}
{'loss': 0.0104, 'grad_norm': 5.65724515914917, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.005161837674677372, 'loss_2': 0.005218505859375, 'loss_3': -16.209117889404297, 'loss_4': 1.164311408996582, 'epoch': 29.67}
{'loss': 0.0099, 'grad_norm': 4.979921817779541, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.002854677150025964, 'loss_2': 0.007049560546875, 'loss_3': -16.443584442138672, 'loss_4': 1.4440875053405762, 'epoch': 29.67}
{'loss': 0.0059, 'grad_norm': 4.578805923461914, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.004227376542985439, 'loss_2': 0.0016870498657226562, 'loss_3': -16.217670440673828, 'loss_4': 1.4288519620895386, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 11:29:32,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:32,843 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:47<00:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:40,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009033073671162128, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.269, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.004770507570356131, 'eval_loss_2': 0.004262566566467285, 'eval_loss_3': -18.188552856445312, 'eval_loss_4': 1.0517818927764893, 'epoch': 29.68}
{'loss': 0.0035, 'grad_norm': 4.938408851623535, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.002979111159220338, 'loss_2': 0.0004954338073730469, 'loss_3': -16.370906829833984, 'loss_4': 1.8963985443115234, 'epoch': 29.69}
{'loss': 0.0068, 'grad_norm': 4.398468971252441, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.0031282762065529823, 'loss_2': 0.00368499755859375, 'loss_3': -16.2690372467041, 'loss_4': 1.1098817586898804, 'epoch': 29.69}
{'loss': 0.007, 'grad_norm': 4.920698165893555, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.00531477527692914, 'loss_2': 0.001697540283203125, 'loss_3': -16.418197631835938, 'loss_4': 0.9901258945465088, 'epoch': 29.7}
{'loss': 0.0104, 'grad_norm': 6.1597394943237305, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.006444880273193121, 'loss_2': 0.003910064697265625, 'loss_3': -16.349252700805664, 'loss_4': 1.2863103151321411, 'epoch': 29.7}
{'loss': 0.0028, 'grad_norm': 4.533356189727783, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.002732238033786416, 'loss_2': 2.3245811462402344e-05, 'loss_3': -16.419702529907227, 'loss_4': 1.554250717163086, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 11:29:40,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:40,206 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:05:54<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:47,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009036864154040813, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004785026423633099, 'eval_loss_2': 0.004251837730407715, 'eval_loss_3': -18.18882942199707, 'eval_loss_4': 1.042900800704956, 'epoch': 29.71}
{'loss': 0.0108, 'grad_norm': 4.650859355926514, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.002186611294746399, 'loss_2': 0.0086212158203125, 'loss_3': -16.3984317779541, 'loss_4': 0.6160978078842163, 'epoch': 29.72}
{'loss': 0.0087, 'grad_norm': 4.64839506149292, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.005097457207739353, 'loss_2': 0.0036220550537109375, 'loss_3': -16.30217742919922, 'loss_4': 0.44063740968704224, 'epoch': 29.72}
{'loss': 0.003, 'grad_norm': 4.707458019256592, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.0022569899447262287, 'loss_2': 0.0007224082946777344, 'loss_3': -16.35032844543457, 'loss_4': 0.8286988139152527, 'epoch': 29.73}
{'loss': 0.0058, 'grad_norm': 5.1446213722229, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.004638947546482086, 'loss_2': 0.001155853271484375, 'loss_3': -16.137184143066406, 'loss_4': 0.6435112953186035, 'epoch': 29.73}
{'loss': 0.0046, 'grad_norm': 4.504274368286133, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.0039218938909471035, 'loss_2': 0.0006341934204101562, 'loss_3': -16.396778106689453, 'loss_4': 1.724900484085083, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 11:29:47,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:47,557 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:06:02<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:29:54,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008994132280349731, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.355, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.004772304557263851, 'eval_loss_2': 0.004221826791763306, 'eval_loss_3': -18.18977165222168, 'eval_loss_4': 1.0372929573059082, 'epoch': 29.74}
{'loss': 0.0066, 'grad_norm': 4.282968997955322, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.002852023346349597, 'loss_2': 0.003787994384765625, 'loss_3': -16.230125427246094, 'loss_4': 1.3049428462982178, 'epoch': 29.74}
{'loss': 0.0109, 'grad_norm': 7.366691589355469, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.01033828780055046, 'loss_2': 0.0005903244018554688, 'loss_3': -16.223209381103516, 'loss_4': 1.4145301580429077, 'epoch': 29.75}
{'loss': 0.0071, 'grad_norm': 4.901435375213623, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.005631201434880495, 'loss_2': 0.0014362335205078125, 'loss_3': -16.429014205932617, 'loss_4': 0.9573973417282104, 'epoch': 29.76}
{'loss': 0.0084, 'grad_norm': 5.075834274291992, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.005002717021852732, 'loss_2': 0.0033721923828125, 'loss_3': -16.294328689575195, 'loss_4': 1.2066154479980469, 'epoch': 29.76}
{'loss': 0.012, 'grad_norm': 5.1835713386535645, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.00794848520308733, 'loss_2': 0.0040283203125, 'loss_3': -16.29107093811035, 'loss_4': 1.4169604778289795, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 11:29:54,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:29:54,906 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:09<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:02,281 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008914068341255188, 'eval_runtime': 3.8193, 'eval_samples_per_second': 268.11, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.004731133580207825, 'eval_loss_2': 0.004182934761047363, 'eval_loss_3': -18.190532684326172, 'eval_loss_4': 1.033151626586914, 'epoch': 29.77}
{'loss': 0.0096, 'grad_norm': 4.901581764221191, 'learning_rate': 2.5e-07, 'loss_1': 0.003579661250114441, 'loss_2': 0.0060272216796875, 'loss_3': -16.137245178222656, 'loss_4': 0.5708853602409363, 'epoch': 29.77}
{'loss': 0.0253, 'grad_norm': 7.745947360992432, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.016238166019320488, 'loss_2': 0.0090789794921875, 'loss_3': -16.441631317138672, 'loss_4': 1.2808480262756348, 'epoch': 29.78}
{'loss': 0.0058, 'grad_norm': 4.255919456481934, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.0024243572261184454, 'loss_2': 0.0034008026123046875, 'loss_3': -16.346847534179688, 'loss_4': 0.9769619107246399, 'epoch': 29.78}
{'loss': 0.0079, 'grad_norm': 4.297637939453125, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.002753988839685917, 'loss_2': 0.00519561767578125, 'loss_3': -16.487531661987305, 'loss_4': 1.3795197010040283, 'epoch': 29.79}
{'loss': 0.0067, 'grad_norm': 5.487640857696533, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.00569477304816246, 'loss_2': 0.000988006591796875, 'loss_3': -16.21924591064453, 'loss_4': 1.1637206077575684, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 11:30:02,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:02,282 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:16<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:09,635 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008855309337377548, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.375, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.004688408225774765, 'eval_loss_2': 0.004166901111602783, 'eval_loss_3': -18.19046401977539, 'eval_loss_4': 1.0313551425933838, 'epoch': 29.8}
{'loss': 0.0049, 'grad_norm': 4.743520736694336, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.0036679909098893404, 'loss_2': 0.001190185546875, 'loss_3': -16.517515182495117, 'loss_4': 0.8718661665916443, 'epoch': 29.8}
{'loss': 0.0065, 'grad_norm': 4.8339738845825195, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.004642304964363575, 'loss_2': 0.0018138885498046875, 'loss_3': -16.370609283447266, 'loss_4': 1.039594292640686, 'epoch': 29.81}
{'loss': 0.0092, 'grad_norm': 4.460486888885498, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.0018460348946973681, 'loss_2': 0.00739288330078125, 'loss_3': -16.223751068115234, 'loss_4': 0.9611498117446899, 'epoch': 29.81}
{'loss': 0.005, 'grad_norm': 4.311509609222412, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0026563096325844526, 'loss_2': 0.0023097991943359375, 'loss_3': -16.368637084960938, 'loss_4': 1.5392401218414307, 'epoch': 29.82}
{'loss': 0.007, 'grad_norm': 5.172813415527344, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.006447649095207453, 'loss_2': 0.0005731582641601562, 'loss_3': -16.24657440185547, 'loss_4': 0.7400451302528381, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 11:30:09,635 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:09,636 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:24<00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:17,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008834296837449074, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.016, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.0046721938997507095, 'eval_loss_2': 0.004162102937698364, 'eval_loss_3': -18.191255569458008, 'eval_loss_4': 1.0298224687576294, 'epoch': 29.83}
{'loss': 0.0063, 'grad_norm': 5.123415946960449, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.005034282337874174, 'loss_2': 0.0012836456298828125, 'loss_3': -16.076183319091797, 'loss_4': 1.1604851484298706, 'epoch': 29.83}
{'loss': 0.0044, 'grad_norm': 4.711734771728516, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.003479968523606658, 'loss_2': 0.0009632110595703125, 'loss_3': -16.519752502441406, 'loss_4': 1.3362877368927002, 'epoch': 29.84}
{'loss': 0.0128, 'grad_norm': 8.439056396484375, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.008659032173454762, 'loss_2': 0.0041046142578125, 'loss_3': -16.428617477416992, 'loss_4': 0.8619891405105591, 'epoch': 29.84}
{'loss': 0.0093, 'grad_norm': 4.940171718597412, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.004573033656924963, 'loss_2': 0.004730224609375, 'loss_3': -16.29088592529297, 'loss_4': 0.5324667096138, 'epoch': 29.85}
{'loss': 0.0033, 'grad_norm': 4.4647722244262695, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.001647464232519269, 'loss_2': 0.0016450881958007812, 'loss_3': -16.503070831298828, 'loss_4': 1.1295742988586426, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 11:30:17,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:17,015 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:31<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:24,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008787521161139011, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004639783408492804, 'eval_loss_2': 0.004147738218307495, 'eval_loss_3': -18.19153594970703, 'eval_loss_4': 1.028537392616272, 'epoch': 29.85}
{'loss': 0.0112, 'grad_norm': 5.463008880615234, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.007286029867827892, 'loss_2': 0.00390625, 'loss_3': -16.164318084716797, 'loss_4': 0.18797366321086884, 'epoch': 29.86}
{'loss': 0.0096, 'grad_norm': 5.491759300231934, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.00894454400986433, 'loss_2': 0.0006880760192871094, 'loss_3': -16.335674285888672, 'loss_4': 1.6924703121185303, 'epoch': 29.87}
{'loss': 0.0053, 'grad_norm': 4.969006061553955, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.0035213162191212177, 'loss_2': 0.0018177032470703125, 'loss_3': -16.15274429321289, 'loss_4': 1.1169556379318237, 'epoch': 29.87}
{'loss': 0.0033, 'grad_norm': 4.656496524810791, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.0024806486908346415, 'loss_2': 0.0008602142333984375, 'loss_3': -16.070573806762695, 'loss_4': 1.118669033050537, 'epoch': 29.88}
{'loss': 0.0097, 'grad_norm': 4.485406398773193, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.00772341713309288, 'loss_2': 0.002025604248046875, 'loss_3': -16.282745361328125, 'loss_4': 1.191807746887207, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 11:30:24,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:24,349 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:38<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:31,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008778471499681473, 'eval_runtime': 3.8238, 'eval_samples_per_second': 267.8, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.004648256115615368, 'eval_loss_2': 0.00413021445274353, 'eval_loss_3': -18.191463470458984, 'eval_loss_4': 1.0270678997039795, 'epoch': 29.88}
{'loss': 0.0058, 'grad_norm': 5.048955917358398, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.0050321160815656185, 'loss_2': 0.0007905960083007812, 'loss_3': -16.336477279663086, 'loss_4': 0.7662955522537231, 'epoch': 29.89}
{'loss': 0.0065, 'grad_norm': 5.490320682525635, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.00554105406627059, 'loss_2': 0.000980377197265625, 'loss_3': -16.456256866455078, 'loss_4': 0.8013491630554199, 'epoch': 29.9}
{'loss': 0.0132, 'grad_norm': 9.212024688720703, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.010120231658220291, 'loss_2': 0.0030498504638671875, 'loss_3': -16.26103973388672, 'loss_4': 0.4175686240196228, 'epoch': 29.9}
{'loss': 0.0043, 'grad_norm': 4.775265693664551, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.0034648138098418713, 'loss_2': 0.0008058547973632812, 'loss_3': -16.379226684570312, 'loss_4': 1.110532522201538, 'epoch': 29.91}
{'loss': 0.0063, 'grad_norm': 4.180836200714111, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.0019156073685735464, 'loss_2': 0.00440216064453125, 'loss_3': -16.24603271484375, 'loss_4': 1.0047353506088257, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 11:30:31,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:31,715 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:46<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:39,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008836259134113789, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.216, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.004668255336582661, 'eval_loss_2': 0.004168003797531128, 'eval_loss_3': -18.19081687927246, 'eval_loss_4': 1.0254920721054077, 'epoch': 29.91}
{'loss': 0.0102, 'grad_norm': 5.562340259552002, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.0040185111574828625, 'loss_2': 0.00620269775390625, 'loss_3': -16.326383590698242, 'loss_4': 1.3174456357955933, 'epoch': 29.92}
{'loss': 0.0096, 'grad_norm': 5.322378158569336, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.007855835370719433, 'loss_2': 0.0017910003662109375, 'loss_3': -16.348573684692383, 'loss_4': 0.8480236530303955, 'epoch': 29.92}
{'loss': 0.0117, 'grad_norm': 5.299354076385498, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.007445711642503738, 'loss_2': 0.00429534912109375, 'loss_3': -16.372802734375, 'loss_4': 0.4842784106731415, 'epoch': 29.93}
{'loss': 0.0064, 'grad_norm': 4.814873218536377, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.003943498246371746, 'loss_2': 0.00241851806640625, 'loss_3': -16.256824493408203, 'loss_4': 1.7924968004226685, 'epoch': 29.94}
{'loss': 0.0139, 'grad_norm': 5.244299411773682, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.00522240437567234, 'loss_2': 0.0086669921875, 'loss_3': -16.470029830932617, 'loss_4': 1.1138386726379395, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 11:30:39,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:39,073 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:06:53<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 11:30:46,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008832864463329315, 'eval_runtime': 3.8173, 'eval_samples_per_second': 268.256, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.004663228988647461, 'eval_loss_2': 0.004169635474681854, 'eval_loss_3': -18.191083908081055, 'eval_loss_4': 1.0247939825057983, 'epoch': 29.94}
{'loss': 0.0052, 'grad_norm': 4.350366592407227, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.003034207969903946, 'loss_2': 0.00220489501953125, 'loss_3': -16.479633331298828, 'loss_4': 1.1339834928512573, 'epoch': 29.95}
{'loss': 0.0115, 'grad_norm': 6.312580585479736, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.006217163056135178, 'loss_2': 0.005306243896484375, 'loss_3': -16.44169807434082, 'loss_4': 0.5586142539978027, 'epoch': 29.95}
{'loss': 0.005, 'grad_norm': 4.625996112823486, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.004675428383052349, 'loss_2': 0.0003020763397216797, 'loss_3': -16.34960174560547, 'loss_4': 1.0269882678985596, 'epoch': 29.96}
{'loss': 0.0028, 'grad_norm': 4.817178249359131, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0025325051974505186, 'loss_2': 0.0002474784851074219, 'loss_3': -16.263137817382812, 'loss_4': 0.9207322001457214, 'epoch': 29.97}
{'loss': 0.0228, 'grad_norm': 9.218313217163086, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.01492221001535654, 'loss_2': 0.00792694091796875, 'loss_3': -16.270450592041016, 'loss_4': 1.3612768650054932, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 11:30:46,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:46,432 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:00<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 11:30:53,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00884520635008812, 'eval_runtime': 3.8347, 'eval_samples_per_second': 267.037, 'eval_steps_per_second': 4.172, 'eval_loss_1': 0.0046569593250751495, 'eval_loss_2': 0.00418824702501297, 'eval_loss_3': -18.19152069091797, 'eval_loss_4': 1.0255171060562134, 'epoch': 29.97}
{'loss': 0.0057, 'grad_norm': 5.295543670654297, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.004120637662708759, 'loss_2': 0.001598358154296875, 'loss_3': -16.25339126586914, 'loss_4': 0.7258126139640808, 'epoch': 29.98}
{'loss': 0.02, 'grad_norm': 6.692379951477051, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.013133443892002106, 'loss_2': 0.0069122314453125, 'loss_3': -16.30867576599121, 'loss_4': 1.6557276248931885, 'epoch': 29.98}
{'loss': 0.0072, 'grad_norm': 5.1590375900268555, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.004337664227932692, 'loss_2': 0.002902984619140625, 'loss_3': -16.143766403198242, 'loss_4': 1.4977730512619019, 'epoch': 29.99}
{'loss': 0.0042, 'grad_norm': 4.673305988311768, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.003010890679433942, 'loss_2': 0.0012054443359375, 'loss_3': -16.443862915039062, 'loss_4': 1.1821179389953613, 'epoch': 29.99}
{'loss': 0.008, 'grad_norm': 6.647449493408203, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.0036030428018420935, 'loss_2': 0.00437164306640625, 'loss_3': -16.24809455871582, 'loss_4': 0.5375163555145264, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 11:30:53,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:53,454 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:04<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 11:30:57,284 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.008856524713337421, 'eval_runtime': 3.8293, 'eval_samples_per_second': 267.414, 'eval_steps_per_second': 4.178, 'eval_loss_1': 0.0046696411445736885, 'eval_loss_2': 0.004186883568763733, 'eval_loss_3': -18.190914154052734, 'eval_loss_4': 1.025955319404602, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 11:30:57,284 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/checkpoint-3650 (score: 0.0073652565479278564).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:04<00:00,  1.48s/it]
{'train_runtime': 7625.4825, 'train_samples_per_second': 43.189, 'train_steps_per_second': 0.677, 'train_loss': 0.035261647494793186, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 11:30:57,375 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1
[INFO|configuration_utils.py:420] 2025-01-21 11:30:57,377 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 11:30:57,911 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 11:30:57,912 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 11:30:57,913 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg1/special_tokens_map.json
01/21/2025 11:30:57 - INFO - __main__ -   ***** Train results *****
01/21/2025 11:30:57 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:30:57 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 11:30:57 - INFO - __main__ -     train_loss = 0.035261647494793186
01/21/2025 11:30:57 - INFO - __main__ -     train_runtime = 7625.4825
01/21/2025 11:30:57 - INFO - __main__ -     train_samples_per_second = 43.189
01/21/2025 11:30:57 - INFO - __main__ -     train_steps_per_second = 0.677
01/21/2025 11:30:58 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 11:30:58,135 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 11:30:58,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 11:30:58,135 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.53it/s]
01/21/2025 11:31:01 - INFO - __main__ -   ***** Eval results *****
01/21/2025 11:31:01 - INFO - __main__ -     epoch = 30.0
01/21/2025 11:31:01 - INFO - __main__ -     eval_loss = 0.0073652565479278564
01/21/2025 11:31:01 - INFO - __main__ -     eval_loss_1 = 0.004537075292319059
01/21/2025 11:31:01 - INFO - __main__ -     eval_loss_2 = 0.0028281807899475098
01/21/2025 11:31:01 - INFO - __main__ -     eval_loss_3 = -18.257152557373047
01/21/2025 11:31:01 - INFO - __main__ -     eval_loss_4 = 0.18051211535930634
01/21/2025 11:31:01 - INFO - __main__ -     eval_runtime = 3.8142
01/21/2025 11:31:01 - INFO - __main__ -     eval_samples_per_second = 268.473
01/21/2025 11:31:01 - INFO - __main__ -     eval_steps_per_second = 4.195
