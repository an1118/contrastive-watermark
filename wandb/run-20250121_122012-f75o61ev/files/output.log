  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 12:20:12,963 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:05:45,  1.31it/s][INFO|trainer.py:4226] 2025-01-21 12:20:17,138 >>
{'loss': 3.5984, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.5215179920196533, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.9532, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.8699095249176025, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.9149, 'grad_norm': 127.5729751586914, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.846057653427124, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.3935, 'grad_norm': inf, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.3217058181762695, 'loss_2': 0.07177734375, 'loss_3': -14.021345138549805, 'loss_4': 8.547597885131836, 'epoch': 0.02}
{'loss': 3.7659, 'grad_norm': 126.89501190185547, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.6847381591796875, 'loss_2': 0.08111572265625, 'loss_3': -13.614644050598145, 'loss_4': 9.39505672454834, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:17,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:17,138 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:08<1:05:45,  1.31it/s][INFO|trainer.py:3910] 2025-01-21 12:20:20,946 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 12:20:20,948 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5/config.json                                                                               
{'eval_loss': 1.7054659128189087, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 1.640757441520691, 'eval_loss_2': 0.06470870971679688, 'eval_loss_3': -17.65029525756836, 'eval_loss_4': 7.828010559082031, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:21,433 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:21,434 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:21,434 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:34:35,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 12:20:25,877 >>
{'loss': 3.4474, 'grad_norm': 142.86614990234375, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.3806939125061035, 'loss_2': 0.06671142578125, 'loss_3': -13.919303894042969, 'loss_4': 8.180641174316406, 'epoch': 0.03}
{'loss': 3.0616, 'grad_norm': 131.51834106445312, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.004729747772217, 'loss_2': 0.05682373046875, 'loss_3': -14.228200912475586, 'loss_4': 8.390177726745605, 'epoch': 0.04}
{'loss': 2.7764, 'grad_norm': 121.05963134765625, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.7171547412872314, 'loss_2': 0.05926513671875, 'loss_3': -14.604543685913086, 'loss_4': 7.413125038146973, 'epoch': 0.05}
{'loss': 2.8123, 'grad_norm': 133.18807983398438, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.7567813396453857, 'loss_2': 0.05548095703125, 'loss_3': -14.705057144165039, 'loss_4': 7.94559907913208, 'epoch': 0.05}
{'loss': 2.5523, 'grad_norm': 134.72305297851562, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.502309560775757, 'loss_2': 0.049957275390625, 'loss_3': -14.95237922668457, 'loss_4': 7.6561431884765625, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:25,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:25,877 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:34:35,  1.10s/it][INFO|trainer.py:3910] 2025-01-21 12:20:29,662 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 12:20:29,664 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10/config.json                                                                              
{'eval_loss': 1.0008118152618408, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.618, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.9696143269538879, 'eval_loss_2': 0.031197547912597656, 'eval_loss_3': -17.9550724029541, 'eval_loss_4': 6.61863374710083, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:30,128 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:30,129 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:30,129 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:31,008 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:51,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:20:34,661 >>
{'loss': 2.0257, 'grad_norm': 112.4649658203125, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 1.9848370552062988, 'loss_2': 0.0408935546875, 'loss_3': -15.210580825805664, 'loss_4': 7.661241054534912, 'epoch': 0.06}
{'loss': 2.0013, 'grad_norm': 127.04595184326172, 'learning_rate': 2.994767441860465e-05, 'loss_1': 1.9726917743682861, 'loss_2': 0.0286407470703125, 'loss_3': -15.09331226348877, 'loss_4': 6.160436630249023, 'epoch': 0.07}
{'loss': 1.686, 'grad_norm': 129.86590576171875, 'learning_rate': 2.994186046511628e-05, 'loss_1': 1.6547714471817017, 'loss_2': 0.03125, 'loss_3': -14.945934295654297, 'loss_4': 6.232649326324463, 'epoch': 0.08}
{'loss': 1.5141, 'grad_norm': 110.04647064208984, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.5018986463546753, 'loss_2': 0.01224517822265625, 'loss_3': -15.289360046386719, 'loss_4': 5.72305965423584, 'epoch': 0.08}
{'loss': 1.3907, 'grad_norm': 104.9330825805664, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.382408857345581, 'loss_2': 0.0082550048828125, 'loss_3': -15.386155128479004, 'loss_4': 6.400455474853516, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:34,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:34,662 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:51,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:20:38,449 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 12:20:38,450 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15/config.json                                                                              
{'eval_loss': 0.4937700033187866, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.491, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.48815685510635376, 'eval_loss_2': 0.005613148212432861, 'eval_loss_3': -17.934707641601562, 'eval_loss_4': 5.4776997566223145, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:38,923 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:38,925 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:38,925 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:39,822 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:39:36,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:20:43,460 >>
{'loss': 1.4899, 'grad_norm': 114.03378295898438, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.477209448814392, 'loss_2': 0.0127105712890625, 'loss_3': -15.062915802001953, 'loss_4': 6.3029890060424805, 'epoch': 0.09}
{'loss': 1.5819, 'grad_norm': 115.24201965332031, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.5729525089263916, 'loss_2': 0.008941650390625, 'loss_3': -15.004816055297852, 'loss_4': 6.750063896179199, 'epoch': 0.1}
{'loss': 1.0782, 'grad_norm': 97.16627502441406, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.062028169631958, 'loss_2': 0.016204833984375, 'loss_3': -15.38288688659668, 'loss_4': 7.764004707336426, 'epoch': 0.1}
{'loss': 1.1565, 'grad_norm': 90.3216781616211, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.1460448503494263, 'loss_2': 0.0104217529296875, 'loss_3': -15.354567527770996, 'loss_4': 7.16440486907959, 'epoch': 0.11}
{'loss': 0.7787, 'grad_norm': 71.8256607055664, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 0.7566994428634644, 'loss_2': 0.02203369140625, 'loss_3': -15.590879440307617, 'loss_4': 6.443975448608398, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:43,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:43,460 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:39:36,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:20:47,253 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 12:20:47,255 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20/config.json                                                                              
{'eval_loss': 0.23453915119171143, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.22231163084506989, 'eval_loss_2': 0.012227535247802734, 'eval_loss_3': -17.884658813476562, 'eval_loss_4': 6.216297149658203, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:47,753 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:47,755 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:47,755 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:48,687 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:40:15,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:20:52,346 >>
{'loss': 0.7429, 'grad_norm': 76.9842529296875, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 0.7278957366943359, 'loss_2': 0.0149993896484375, 'loss_3': -15.221961975097656, 'loss_4': 6.17727518081665, 'epoch': 0.12}
{'loss': 0.5643, 'grad_norm': 69.95660400390625, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.5473971962928772, 'loss_2': 0.016876220703125, 'loss_3': -15.404959678649902, 'loss_4': 6.535011291503906, 'epoch': 0.13}
{'loss': 0.4601, 'grad_norm': 59.72670364379883, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.4492979943752289, 'loss_2': 0.01080322265625, 'loss_3': -15.181045532226562, 'loss_4': 5.526820659637451, 'epoch': 0.13}
{'loss': 0.649, 'grad_norm': 105.08207702636719, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.6306373476982117, 'loss_2': 0.0183868408203125, 'loss_3': -14.862594604492188, 'loss_4': 6.106417655944824, 'epoch': 0.14}
{'loss': 0.4758, 'grad_norm': 65.5482177734375, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.466641366481781, 'loss_2': 0.009185791015625, 'loss_3': -15.064192771911621, 'loss_4': 5.090986251831055, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:52,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:52,346 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:43<1:40:15,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:20:56,145 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 12:20:56,146 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25/config.json                                                                              
{'eval_loss': 0.14111340045928955, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.1354503184556961, 'eval_loss_2': 0.005663096904754639, 'eval_loss_3': -17.796167373657227, 'eval_loss_4': 5.433835029602051, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:56,646 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:56,647 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:56,647 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:57,536 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:48<1:40:06,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:21:01,208 >>
{'loss': 0.4186, 'grad_norm': 62.28441619873047, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.4115874469280243, 'loss_2': 0.00701141357421875, 'loss_3': -15.001155853271484, 'loss_4': 5.502899169921875, 'epoch': 0.15}
{'loss': 0.55, 'grad_norm': 63.96371841430664, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.5446300506591797, 'loss_2': 0.005336761474609375, 'loss_3': -14.74932861328125, 'loss_4': 6.236326694488525, 'epoch': 0.16}
{'loss': 0.3417, 'grad_norm': 57.29999542236328, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.33376801013946533, 'loss_2': 0.0078887939453125, 'loss_3': -14.982126235961914, 'loss_4': 5.220677852630615, 'epoch': 0.16}
{'loss': 0.4076, 'grad_norm': 52.44706726074219, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.4042034149169922, 'loss_2': 0.003391265869140625, 'loss_3': -14.886686325073242, 'loss_4': 4.827040672302246, 'epoch': 0.17}
{'loss': 0.2499, 'grad_norm': 51.925296783447266, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.23888824880123138, 'loss_2': 0.0109710693359375, 'loss_3': -14.849709510803223, 'loss_4': 5.777886390686035, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:01,208 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:01,208 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:52<1:40:06,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:21:05,015 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 12:21:05,016 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30/config.json                                                                              
{'eval_loss': 0.11205008625984192, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.1066504716873169, 'eval_loss_2': 0.005399614572525024, 'eval_loss_3': -17.805784225463867, 'eval_loss_4': 4.464974403381348, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:05,529 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:05,530 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:05,530 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:06,476 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:57<1:40:16,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:21:10,121 >>
{'loss': 0.4141, 'grad_norm': 64.8770523071289, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.4134904742240906, 'loss_2': 0.0006542205810546875, 'loss_3': -14.606781005859375, 'loss_4': 5.90866756439209, 'epoch': 0.18}
{'loss': 0.3837, 'grad_norm': 50.21125411987305, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.3724254369735718, 'loss_2': 0.01129150390625, 'loss_3': -14.605224609375, 'loss_4': 3.724186897277832, 'epoch': 0.19}
{'loss': 0.3254, 'grad_norm': 55.99240493774414, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.3208411931991577, 'loss_2': 0.00457763671875, 'loss_3': -14.735239028930664, 'loss_4': 3.4836983680725098, 'epoch': 0.19}
{'loss': 0.2846, 'grad_norm': 45.860076904296875, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.28112566471099854, 'loss_2': 0.00344085693359375, 'loss_3': -14.704042434692383, 'loss_4': 3.33200740814209, 'epoch': 0.2}
{'loss': 0.315, 'grad_norm': 51.97984313964844, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.3102406859397888, 'loss_2': 0.00473785400390625, 'loss_3': -14.550436019897461, 'loss_4': 3.6277146339416504, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:10,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:10,121 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:04<1:30:39,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:21:17,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.15147189795970917, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.668, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.14678886532783508, 'eval_loss_2': 0.0046830326318740845, 'eval_loss_3': -17.73073959350586, 'eval_loss_4': 3.4881844520568848, 'epoch': 0.2}
{'loss': 0.3013, 'grad_norm': 58.760440826416016, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.28918108344078064, 'loss_2': 0.0121612548828125, 'loss_3': -14.718254089355469, 'loss_4': 3.659977436065674, 'epoch': 0.21}
{'loss': 0.2559, 'grad_norm': 56.06131362915039, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.25397396087646484, 'loss_2': 0.0019435882568359375, 'loss_3': -14.578651428222656, 'loss_4': 3.3339366912841797, 'epoch': 0.22}
{'loss': 0.3467, 'grad_norm': 70.40304565429688, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.3455096185207367, 'loss_2': 0.0011692047119140625, 'loss_3': -14.650496482849121, 'loss_4': 3.530430793762207, 'epoch': 0.22}
{'loss': 0.2198, 'grad_norm': 45.858463287353516, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.21684375405311584, 'loss_2': 0.002986907958984375, 'loss_3': -14.76051139831543, 'loss_4': 2.338883399963379, 'epoch': 0.23}
{'loss': 0.2502, 'grad_norm': 40.9611930847168, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.2466851770877838, 'loss_2': 0.003509521484375, 'loss_3': -14.850469589233398, 'loss_4': 3.473839521408081, 'epoch': 0.23}
[INFO|trainer.py:4228] 2025-01-21 12:21:17,475 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:17,475 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:08<1:30:39,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:21:21,272 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40
[INFO|configuration_utils.py:420] 2025-01-21 12:21:21,274 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40/config.json                                                                              
{'eval_loss': 0.06769829988479614, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.06333950161933899, 'eval_loss_2': 0.004358798265457153, 'eval_loss_3': -17.949596405029297, 'eval_loss_4': 3.389796018600464, 'epoch': 0.23}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:21,765 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:21,767 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:21,767 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:22,657 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-30] due to args.save_total_limit
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:13<1:38:09,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:21:26,323 >>
{'loss': 0.2705, 'grad_norm': 52.43465805053711, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.26758381724357605, 'loss_2': 0.0029506683349609375, 'loss_3': -14.916232109069824, 'loss_4': 3.6514599323272705, 'epoch': 0.24}
{'loss': 0.2439, 'grad_norm': 47.16769027709961, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.23962005972862244, 'loss_2': 0.004302978515625, 'loss_3': -14.789978981018066, 'loss_4': 3.183778762817383, 'epoch': 0.24}
{'loss': 0.2953, 'grad_norm': 54.37947463989258, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.2918904721736908, 'loss_2': 0.00336456298828125, 'loss_3': -14.978361129760742, 'loss_4': 4.301934242248535, 'epoch': 0.25}
{'loss': 0.3922, 'grad_norm': 61.74760437011719, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.38779646158218384, 'loss_2': 0.00438690185546875, 'loss_3': -14.79724407196045, 'loss_4': 5.255705833435059, 'epoch': 0.26}
{'loss': 0.29, 'grad_norm': 60.73959732055664, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.28727856278419495, 'loss_2': 0.002727508544921875, 'loss_3': -14.996959686279297, 'loss_4': 4.948663234710693, 'epoch': 0.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:26,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:26,324 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:17<1:38:09,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:21:30,122 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 12:21:30,123 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45/config.json                                                                              
{'eval_loss': 0.06100229173898697, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.651, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.05099037289619446, 'eval_loss_2': 0.010011911392211914, 'eval_loss_3': -17.97726058959961, 'eval_loss_4': 3.741831064224243, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:30,616 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:30,617 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:30,617 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:31,515 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-40] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:22<1:39:15,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:21:35,170 >>
{'loss': 0.212, 'grad_norm': 34.95390319824219, 'learning_rate': 2.975e-05, 'loss_1': 0.1951722502708435, 'loss_2': 0.016876220703125, 'loss_3': -15.02451229095459, 'loss_4': 4.454110622406006, 'epoch': 0.27}
{'loss': 0.263, 'grad_norm': 45.94342041015625, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.254285991191864, 'loss_2': 0.00875091552734375, 'loss_3': -14.805532455444336, 'loss_4': 3.6947782039642334, 'epoch': 0.27}
{'loss': 0.3321, 'grad_norm': 53.738319396972656, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.3176594376564026, 'loss_2': 0.0144805908203125, 'loss_3': -14.601261138916016, 'loss_4': 3.22098970413208, 'epoch': 0.28}
{'loss': 0.3127, 'grad_norm': 65.14977264404297, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.30243125557899475, 'loss_2': 0.01027679443359375, 'loss_3': -14.74090576171875, 'loss_4': 3.546952247619629, 'epoch': 0.28}
{'loss': 0.2434, 'grad_norm': 44.26576614379883, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.2360614538192749, 'loss_2': 0.007373809814453125, 'loss_3': -14.63902473449707, 'loss_4': 2.0347957611083984, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:35,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:35,170 >>   Batch size = 64
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:26<1:39:15,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:21:38,971 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50
[INFO|configuration_utils.py:420] 2025-01-21 12:21:38,972 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50/config.json                                                                              
{'eval_loss': 0.05292297154664993, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.545, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.04723680764436722, 'eval_loss_2': 0.005686163902282715, 'eval_loss_3': -17.82501220703125, 'eval_loss_4': 2.2356598377227783, 'epoch': 0.29}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:39,462 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:39,463 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:39,463 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:40,406 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-45] due to args.save_total_limit
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:31<1:39:35,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:21:44,056 >>
{'loss': 0.1489, 'grad_norm': 32.17259979248047, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.14153194427490234, 'loss_2': 0.007335662841796875, 'loss_3': -14.812658309936523, 'loss_4': 2.3475914001464844, 'epoch': 0.3}
{'loss': 0.2044, 'grad_norm': 37.47513961791992, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.19539090991020203, 'loss_2': 0.0089874267578125, 'loss_3': -14.784891128540039, 'loss_4': 2.4253783226013184, 'epoch': 0.3}
{'loss': 0.1762, 'grad_norm': 34.366050720214844, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.17588680982589722, 'loss_2': 0.0002956390380859375, 'loss_3': -14.889983177185059, 'loss_4': 1.957441806793213, 'epoch': 0.31}
{'loss': 0.1944, 'grad_norm': 36.21132278442383, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.19292408227920532, 'loss_2': 0.001430511474609375, 'loss_3': -14.815906524658203, 'loss_4': 2.550092935562134, 'epoch': 0.31}
{'loss': 0.2175, 'grad_norm': 41.53261947631836, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.21178629994392395, 'loss_2': 0.0057220458984375, 'loss_3': -14.83119010925293, 'loss_4': 1.6538856029510498, 'epoch': 0.32}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:44,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:44,056 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:38<1:30:17,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:21:51,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05810107663273811, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.05478990823030472, 'eval_loss_2': 0.003311164677143097, 'eval_loss_3': -17.83740234375, 'eval_loss_4': 1.9623998403549194, 'epoch': 0.32}
{'loss': 0.1367, 'grad_norm': 31.926639556884766, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.1293315291404724, 'loss_2': 0.0073699951171875, 'loss_3': -15.088587760925293, 'loss_4': 1.5838403701782227, 'epoch': 0.33}
{'loss': 0.2009, 'grad_norm': 38.2699089050293, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.19779329001903534, 'loss_2': 0.00307464599609375, 'loss_3': -14.777883529663086, 'loss_4': 2.1497445106506348, 'epoch': 0.33}
{'loss': 0.1794, 'grad_norm': 40.40013885498047, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.17442317306995392, 'loss_2': 0.00501251220703125, 'loss_3': -14.741968154907227, 'loss_4': 1.6916139125823975, 'epoch': 0.34}
{'loss': 0.1897, 'grad_norm': 35.408729553222656, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.18096867203712463, 'loss_2': 0.00872039794921875, 'loss_3': -14.755351066589355, 'loss_4': 2.3760921955108643, 'epoch': 0.34}
{'loss': 0.1817, 'grad_norm': 47.737979888916016, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.17686308920383453, 'loss_2': 0.0048370361328125, 'loss_3': -14.762655258178711, 'loss_4': 2.399723768234253, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 12:21:51,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:51,419 >>   Batch size = 64
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:45<1:28:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:21:58,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06973367184400558, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.06468060612678528, 'eval_loss_2': 0.0050530582666397095, 'eval_loss_3': -17.830402374267578, 'eval_loss_4': 2.7864181995391846, 'epoch': 0.35}
{'loss': 0.2821, 'grad_norm': 51.15983581542969, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.27436551451683044, 'loss_2': 0.0077667236328125, 'loss_3': -14.688365936279297, 'loss_4': 2.4658167362213135, 'epoch': 0.35}
{'loss': 0.1848, 'grad_norm': 39.237457275390625, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.17956393957138062, 'loss_2': 0.00518798828125, 'loss_3': -14.866792678833008, 'loss_4': 3.0700573921203613, 'epoch': 0.36}
{'loss': 0.1538, 'grad_norm': 32.67876052856445, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.14460325241088867, 'loss_2': 0.00921630859375, 'loss_3': -14.834188461303711, 'loss_4': 2.514896869659424, 'epoch': 0.37}
{'loss': 0.1513, 'grad_norm': 30.55290985107422, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.1392381638288498, 'loss_2': 0.01202392578125, 'loss_3': -14.912360191345215, 'loss_4': 3.5677647590637207, 'epoch': 0.37}
{'loss': 0.2371, 'grad_norm': 38.23018264770508, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.2152397334575653, 'loss_2': 0.021881103515625, 'loss_3': -14.567325592041016, 'loss_4': 3.1757168769836426, 'epoch': 0.38}
[INFO|trainer.py:4228] 2025-01-21 12:21:58,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:58,781 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:53<1:28:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:06,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07212357223033905, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.06229620426893234, 'eval_loss_2': 0.009827375411987305, 'eval_loss_3': -17.871044158935547, 'eval_loss_4': 3.2710399627685547, 'epoch': 0.38}
{'loss': 0.1467, 'grad_norm': 35.398250579833984, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.1354655623435974, 'loss_2': 0.0112457275390625, 'loss_3': -14.922908782958984, 'loss_4': 3.4837069511413574, 'epoch': 0.38}
{'loss': 0.1565, 'grad_norm': 28.94120216369629, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.14562350511550903, 'loss_2': 0.01092529296875, 'loss_3': -14.874735832214355, 'loss_4': 3.8953404426574707, 'epoch': 0.39}
{'loss': 0.1681, 'grad_norm': 39.33821487426758, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.16648295521736145, 'loss_2': 0.0016460418701171875, 'loss_3': -14.879258155822754, 'loss_4': 3.020709991455078, 'epoch': 0.4}
{'loss': 0.177, 'grad_norm': 39.23455810546875, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.16519273817539215, 'loss_2': 0.0118255615234375, 'loss_3': -14.85603141784668, 'loss_4': 4.170849800109863, 'epoch': 0.4}
{'loss': 0.1231, 'grad_norm': 26.068471908569336, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.11699045449495316, 'loss_2': 0.006114959716796875, 'loss_3': -14.98085880279541, 'loss_4': 3.089846611022949, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 12:22:06,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:06,149 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:57<1:28:27,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:22:09,953 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70
[INFO|configuration_utils.py:420] 2025-01-21 12:22:09,954 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70/config.json                                                                              
{'eval_loss': 0.04444659501314163, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04115545004606247, 'eval_loss_2': 0.0032911449670791626, 'eval_loss_3': -17.995805740356445, 'eval_loss_4': 3.4639978408813477, 'epoch': 0.41}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:10,459 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:10,460 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:10,460 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:11,392 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-50] due to args.save_total_limit
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:02<1:37:49,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:22:15,067 >>
{'loss': 0.1546, 'grad_norm': 37.959896087646484, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.14471137523651123, 'loss_2': 0.009918212890625, 'loss_3': -15.164765357971191, 'loss_4': 4.181265830993652, 'epoch': 0.41}
{'loss': 0.2212, 'grad_norm': 53.413211822509766, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.21483716368675232, 'loss_2': 0.00634765625, 'loss_3': -14.809309959411621, 'loss_4': 4.024138927459717, 'epoch': 0.42}
{'loss': 0.1863, 'grad_norm': 37.8328971862793, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.1622210294008255, 'loss_2': 0.02410888671875, 'loss_3': -15.052117347717285, 'loss_4': 4.940051078796387, 'epoch': 0.42}
{'loss': 0.1341, 'grad_norm': 28.789941787719727, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.1270962506532669, 'loss_2': 0.006977081298828125, 'loss_3': -14.876697540283203, 'loss_4': 4.453989028930664, 'epoch': 0.43}
{'loss': 0.1175, 'grad_norm': 23.81769561767578, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.10943019390106201, 'loss_2': 0.008087158203125, 'loss_3': -15.1282320022583, 'loss_4': 4.6769633293151855, 'epoch': 0.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:15,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:15,067 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:29:40,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:22:22,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04993771016597748, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.04154370725154877, 'eval_loss_2': 0.008394002914428711, 'eval_loss_3': -17.98773765563965, 'eval_loss_4': 4.108114242553711, 'epoch': 0.44}
{'loss': 0.1276, 'grad_norm': 25.448841094970703, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.11577901989221573, 'loss_2': 0.0117950439453125, 'loss_3': -15.0850830078125, 'loss_4': 4.728455543518066, 'epoch': 0.44}
{'loss': 0.1732, 'grad_norm': 33.255584716796875, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.16116876900196075, 'loss_2': 0.01207733154296875, 'loss_3': -14.898686408996582, 'loss_4': 3.615084409713745, 'epoch': 0.45}
{'loss': 0.1926, 'grad_norm': 38.308719635009766, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.18961507081985474, 'loss_2': 0.002971649169921875, 'loss_3': -15.046502113342285, 'loss_4': 3.718137741088867, 'epoch': 0.45}
{'loss': 0.1539, 'grad_norm': 36.3925895690918, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.1532987803220749, 'loss_2': 0.0005645751953125, 'loss_3': -15.201433181762695, 'loss_4': 4.871697902679443, 'epoch': 0.46}
{'loss': 0.1482, 'grad_norm': 25.866971969604492, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.13717709481716156, 'loss_2': 0.01107025146484375, 'loss_3': -15.00026798248291, 'loss_4': 3.6244218349456787, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 12:22:22,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:22,424 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:16<1:28:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:29,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.047606296837329865, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03812510520219803, 'eval_loss_2': 0.009481191635131836, 'eval_loss_3': -18.055192947387695, 'eval_loss_4': 3.250095844268799, 'epoch': 0.47}
{'loss': 0.1399, 'grad_norm': 31.520484924316406, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.1332913041114807, 'loss_2': 0.006561279296875, 'loss_3': -15.341444969177246, 'loss_4': 4.012661933898926, 'epoch': 0.47}
{'loss': 0.2126, 'grad_norm': 42.502323150634766, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.19898748397827148, 'loss_2': 0.01360321044921875, 'loss_3': -15.005514144897461, 'loss_4': 3.298959255218506, 'epoch': 0.48}
{'loss': 0.1518, 'grad_norm': 33.1718635559082, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.14298078417778015, 'loss_2': 0.0087890625, 'loss_3': -15.370295524597168, 'loss_4': 2.8756473064422607, 'epoch': 0.48}
{'loss': 0.1674, 'grad_norm': 31.941871643066406, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.16257616877555847, 'loss_2': 0.004810333251953125, 'loss_3': -15.241955757141113, 'loss_4': 2.8848018646240234, 'epoch': 0.49}
{'loss': 0.1736, 'grad_norm': 33.58737564086914, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.16493239998817444, 'loss_2': 0.008636474609375, 'loss_3': -15.044036865234375, 'loss_4': 3.2594776153564453, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 12:22:29,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:29,792 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:28:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:37,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0506742000579834, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.021, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.04553326591849327, 'eval_loss_2': 0.005140930414199829, 'eval_loss_3': -18.11362648010254, 'eval_loss_4': 2.4185404777526855, 'epoch': 0.49}
{'loss': 0.1274, 'grad_norm': 25.988361358642578, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.12581011652946472, 'loss_2': 0.0015497207641601562, 'loss_3': -15.048969268798828, 'loss_4': 2.974177837371826, 'epoch': 0.5}
{'loss': 0.1064, 'grad_norm': 21.9936580657959, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.10333018749952316, 'loss_2': 0.0030879974365234375, 'loss_3': -15.182388305664062, 'loss_4': 3.1566219329833984, 'epoch': 0.51}
{'loss': 0.1417, 'grad_norm': 25.932424545288086, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.1312740594148636, 'loss_2': 0.010406494140625, 'loss_3': -15.00562858581543, 'loss_4': 2.101573944091797, 'epoch': 0.51}
{'loss': 0.2404, 'grad_norm': 40.91679000854492, 'learning_rate': 2.95e-05, 'loss_1': 0.23914562165737152, 'loss_2': 0.0012559890747070312, 'loss_3': -15.10489559173584, 'loss_4': 2.4028334617614746, 'epoch': 0.52}
{'loss': 0.0909, 'grad_norm': 21.932466506958008, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.0852433368563652, 'loss_2': 0.005615234375, 'loss_3': -15.43681526184082, 'loss_4': 2.0003156661987305, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 12:22:37,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:37,157 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:31<1:28:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:44,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05633866414427757, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.05243999883532524, 'eval_loss_2': 0.0038986653089523315, 'eval_loss_3': -18.141115188598633, 'eval_loss_4': 1.9017709493637085, 'epoch': 0.52}
{'loss': 0.1695, 'grad_norm': 46.36206817626953, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.16698907315731049, 'loss_2': 0.0024776458740234375, 'loss_3': -15.150038719177246, 'loss_4': 2.5240368843078613, 'epoch': 0.53}
{'loss': 0.1745, 'grad_norm': 36.61298370361328, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.1722279191017151, 'loss_2': 0.00225067138671875, 'loss_3': -15.27479076385498, 'loss_4': 2.4544806480407715, 'epoch': 0.53}
{'loss': 0.1682, 'grad_norm': 37.517799377441406, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.160853311419487, 'loss_2': 0.00739288330078125, 'loss_3': -15.291296005249023, 'loss_4': 2.1619598865509033, 'epoch': 0.54}
{'loss': 0.1882, 'grad_norm': 39.511714935302734, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.1826673150062561, 'loss_2': 0.00554656982421875, 'loss_3': -15.512767791748047, 'loss_4': 1.8992818593978882, 'epoch': 0.55}
{'loss': 0.2338, 'grad_norm': 33.9157829284668, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.2237587571144104, 'loss_2': 0.01004791259765625, 'loss_3': -15.335247039794922, 'loss_4': 2.3566224575042725, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 12:22:44,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:44,533 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:35<1:28:00,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:22:48,342 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95
[INFO|configuration_utils.py:420] 2025-01-21 12:22:48,343 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95/config.json                                                                              
{'eval_loss': 0.04304378852248192, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.034961216151714325, 'eval_loss_2': 0.008082568645477295, 'eval_loss_3': -18.28757095336914, 'eval_loss_4': 1.9642553329467773, 'epoch': 0.55}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:48,831 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:48,833 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:48,833 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:49,733 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-70] due to args.save_total_limit
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:40<1:36:48,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:22:53,379 >>
{'loss': 0.2602, 'grad_norm': 43.835018157958984, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.24709738790988922, 'loss_2': 0.013092041015625, 'loss_3': -15.52302360534668, 'loss_4': 2.5133490562438965, 'epoch': 0.56}
{'loss': 0.1847, 'grad_norm': 36.14945602416992, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.16680820286273956, 'loss_2': 0.01788330078125, 'loss_3': -15.246207237243652, 'loss_4': 2.26468825340271, 'epoch': 0.56}
{'loss': 0.2263, 'grad_norm': 37.75886154174805, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.2161305844783783, 'loss_2': 0.01016998291015625, 'loss_3': -15.429910659790039, 'loss_4': 2.4963247776031494, 'epoch': 0.57}
{'loss': 0.2133, 'grad_norm': 30.904680252075195, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.20723746716976166, 'loss_2': 0.00603485107421875, 'loss_3': -15.289039611816406, 'loss_4': 3.1144328117370605, 'epoch': 0.58}
{'loss': 0.3005, 'grad_norm': 47.593055725097656, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.2892725169658661, 'loss_2': 0.0111846923828125, 'loss_3': -15.447525978088379, 'loss_4': 3.290841579437256, 'epoch': 0.58}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:53,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:53,379 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:47<1:29:20,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:23:00,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04498744010925293, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.093, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.03658246621489525, 'eval_loss_2': 0.008404970169067383, 'eval_loss_3': -18.313007354736328, 'eval_loss_4': 1.7159866094589233, 'epoch': 0.58}
{'loss': 0.1442, 'grad_norm': 37.515464782714844, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.14023417234420776, 'loss_2': 0.003936767578125, 'loss_3': -15.381016731262207, 'loss_4': 2.648397922515869, 'epoch': 0.59}
{'loss': 0.1313, 'grad_norm': 25.658267974853516, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.1305919885635376, 'loss_2': 0.0007252693176269531, 'loss_3': -15.421655654907227, 'loss_4': 2.0133798122406006, 'epoch': 0.59}
{'loss': 0.2771, 'grad_norm': 41.77685546875, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.27604278922080994, 'loss_2': 0.0010204315185546875, 'loss_3': -15.201744079589844, 'loss_4': 2.9375791549682617, 'epoch': 0.6}
{'loss': 0.1651, 'grad_norm': 39.38137435913086, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.16091148555278778, 'loss_2': 0.0042266845703125, 'loss_3': -15.452741622924805, 'loss_4': 2.7251062393188477, 'epoch': 0.6}
{'loss': 0.2267, 'grad_norm': 49.055912017822266, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.21895350515842438, 'loss_2': 0.007762908935546875, 'loss_3': -15.589396476745605, 'loss_4': 2.528555393218994, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 12:23:00,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:00,755 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:51<1:29:20,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:23:04,565 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105
[INFO|configuration_utils.py:420] 2025-01-21 12:23:04,566 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105/config.json                                                                             
{'eval_loss': 0.03823190927505493, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.029628811404109, 'eval_loss_2': 0.008603096008300781, 'eval_loss_3': -18.261062622070312, 'eval_loss_4': 0.974941611289978, 'epoch': 0.61}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:05,029 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:05,030 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:05,030 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:05,972 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-95] due to args.save_total_limit
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:56<1:37:03,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:23:09,628 >>
{'loss': 0.1155, 'grad_norm': 26.613576889038086, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.10894979536533356, 'loss_2': 0.006572723388671875, 'loss_3': -15.492864608764648, 'loss_4': 1.4282499551773071, 'epoch': 0.62}
{'loss': 0.2636, 'grad_norm': 44.51301193237305, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.25539445877075195, 'loss_2': 0.0082244873046875, 'loss_3': -15.150506019592285, 'loss_4': 1.7605229616165161, 'epoch': 0.62}
{'loss': 0.122, 'grad_norm': 22.94878578186035, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.11927853524684906, 'loss_2': 0.00267791748046875, 'loss_3': -15.316825866699219, 'loss_4': 1.5797802209854126, 'epoch': 0.63}
{'loss': 0.084, 'grad_norm': 22.338973999023438, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.08043839037418365, 'loss_2': 0.00356292724609375, 'loss_3': -15.293859481811523, 'loss_4': 0.9857643842697144, 'epoch': 0.63}
{'loss': 0.1409, 'grad_norm': 31.792593002319336, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.13418960571289062, 'loss_2': 0.0067138671875, 'loss_3': -15.24478530883789, 'loss_4': 1.748776912689209, 'epoch': 0.64}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:09,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:09,628 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:04<1:29:07,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:23:16,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04257220774888992, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03753335401415825, 'eval_loss_2': 0.005038857460021973, 'eval_loss_3': -18.153364181518555, 'eval_loss_4': 1.13753342628479, 'epoch': 0.64}
{'loss': 0.3095, 'grad_norm': 46.352439880371094, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.30297622084617615, 'loss_2': 0.00652313232421875, 'loss_3': -15.253674507141113, 'loss_4': 1.8010921478271484, 'epoch': 0.65}
{'loss': 0.1705, 'grad_norm': 41.18124771118164, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.1574004590511322, 'loss_2': 0.013092041015625, 'loss_3': -15.121423721313477, 'loss_4': 2.205939292907715, 'epoch': 0.65}
{'loss': 0.1312, 'grad_norm': 22.77106285095215, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.11889536678791046, 'loss_2': 0.0123138427734375, 'loss_3': -15.322723388671875, 'loss_4': 1.367874264717102, 'epoch': 0.66}
{'loss': 0.1152, 'grad_norm': 24.12205696105957, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.11149632930755615, 'loss_2': 0.0037021636962890625, 'loss_3': -15.064146041870117, 'loss_4': 0.9487757682800293, 'epoch': 0.66}
{'loss': 0.082, 'grad_norm': 20.654321670532227, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.07522516697645187, 'loss_2': 0.006763458251953125, 'loss_3': -15.196359634399414, 'loss_4': 1.478905200958252, 'epoch': 0.67}
[INFO|trainer.py:4228] 2025-01-21 12:23:16,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:16,990 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:11<1:27:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:24,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.044547926634550095, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.874, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.03778766468167305, 'eval_loss_2': 0.006760265678167343, 'eval_loss_3': -18.15349006652832, 'eval_loss_4': 1.526228904724121, 'epoch': 0.67}
{'loss': 0.123, 'grad_norm': 19.462127685546875, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.11362260580062866, 'loss_2': 0.00936126708984375, 'loss_3': -15.131031036376953, 'loss_4': 2.365346670150757, 'epoch': 0.67}
{'loss': 0.1162, 'grad_norm': 20.188159942626953, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.11523047089576721, 'loss_2': 0.0010166168212890625, 'loss_3': -15.120166778564453, 'loss_4': 1.290921926498413, 'epoch': 0.68}
{'loss': 0.1091, 'grad_norm': 23.108034133911133, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.09712302684783936, 'loss_2': 0.011962890625, 'loss_3': -15.212581634521484, 'loss_4': 2.259434223175049, 'epoch': 0.69}
{'loss': 0.1236, 'grad_norm': 29.40268325805664, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.12201115489006042, 'loss_2': 0.0016050338745117188, 'loss_3': -15.219528198242188, 'loss_4': 2.297260046005249, 'epoch': 0.69}
{'loss': 0.0975, 'grad_norm': 21.105249404907227, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.09527125209569931, 'loss_2': 0.002254486083984375, 'loss_3': -15.11062240600586, 'loss_4': 2.0991923809051514, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 12:23:24,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:24,356 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:18<1:27:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:31,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05421026051044464, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.884, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.048860207200050354, 'eval_loss_2': 0.005350053310394287, 'eval_loss_3': -18.092004776000977, 'eval_loss_4': 2.223414182662964, 'epoch': 0.7}
{'loss': 0.0708, 'grad_norm': 20.81263542175293, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.07049766927957535, 'loss_2': 0.0002627372741699219, 'loss_3': -15.03690242767334, 'loss_4': 2.1209628582000732, 'epoch': 0.7}
{'loss': 0.1108, 'grad_norm': 28.720823287963867, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.10639398545026779, 'loss_2': 0.00444793701171875, 'loss_3': -15.07275676727295, 'loss_4': 2.670464038848877, 'epoch': 0.71}
{'loss': 0.1159, 'grad_norm': 31.91010284423828, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.1121864840388298, 'loss_2': 0.0036869049072265625, 'loss_3': -15.195175170898438, 'loss_4': 2.6435351371765137, 'epoch': 0.72}
{'loss': 0.0847, 'grad_norm': 20.59522819519043, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.07961112260818481, 'loss_2': 0.00504302978515625, 'loss_3': -15.289450645446777, 'loss_4': 2.0420351028442383, 'epoch': 0.72}
{'loss': 0.0769, 'grad_norm': 15.195518493652344, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.06405511498451233, 'loss_2': 0.01280975341796875, 'loss_3': -15.298876762390137, 'loss_4': 2.8305087089538574, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 12:23:31,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:31,732 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:26<1:27:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:39,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04361232370138168, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.031089866533875465, 'eval_loss_2': 0.012522459030151367, 'eval_loss_3': -18.170833587646484, 'eval_loss_4': 2.900036334991455, 'epoch': 0.73}
{'loss': 0.077, 'grad_norm': 18.00623893737793, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.06745659559965134, 'loss_2': 0.00955963134765625, 'loss_3': -15.340967178344727, 'loss_4': 2.9107093811035156, 'epoch': 0.73}
{'loss': 0.1056, 'grad_norm': 22.235971450805664, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.09209365397691727, 'loss_2': 0.01348876953125, 'loss_3': -15.416507720947266, 'loss_4': 3.110999584197998, 'epoch': 0.74}
{'loss': 0.2036, 'grad_norm': 35.825870513916016, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.19240428507328033, 'loss_2': 0.01116180419921875, 'loss_3': -15.225513458251953, 'loss_4': 3.5629959106445312, 'epoch': 0.74}
{'loss': 0.1214, 'grad_norm': 27.075265884399414, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.1145758330821991, 'loss_2': 0.00685882568359375, 'loss_3': -15.44143295288086, 'loss_4': 3.8372037410736084, 'epoch': 0.75}
{'loss': 0.1262, 'grad_norm': 20.668716430664062, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.11221430450677872, 'loss_2': 0.0139923095703125, 'loss_3': -15.369098663330078, 'loss_4': 3.5643277168273926, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 12:23:39,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:39,108 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:33<1:27:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:46,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0394204705953598, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.030231133103370667, 'eval_loss_2': 0.009189337491989136, 'eval_loss_3': -18.26982307434082, 'eval_loss_4': 3.53967547416687, 'epoch': 0.76}
{'loss': 0.1866, 'grad_norm': 46.79868698120117, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.16630218923091888, 'loss_2': 0.020294189453125, 'loss_3': -15.41104507446289, 'loss_4': 3.6542584896087646, 'epoch': 0.76}
{'loss': 0.1482, 'grad_norm': 29.420305252075195, 'learning_rate': 2.925e-05, 'loss_1': 0.13639044761657715, 'loss_2': 0.01184844970703125, 'loss_3': -15.487422943115234, 'loss_4': 3.745651960372925, 'epoch': 0.77}
{'loss': 0.1959, 'grad_norm': 32.26197814941406, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.17845900356769562, 'loss_2': 0.0174560546875, 'loss_3': -15.330150604248047, 'loss_4': 3.530069351196289, 'epoch': 0.77}
{'loss': 0.109, 'grad_norm': 26.825443267822266, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.1015084981918335, 'loss_2': 0.0074920654296875, 'loss_3': -15.519842147827148, 'loss_4': 3.7007150650024414, 'epoch': 0.78}
{'loss': 0.1621, 'grad_norm': 30.64972686767578, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.1456231325864792, 'loss_2': 0.0164642333984375, 'loss_3': -15.426305770874023, 'loss_4': 3.512150287628174, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 12:23:46,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:46,471 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:37<1:27:10,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:23:50,294 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135
[INFO|configuration_utils.py:420] 2025-01-21 12:23:50,296 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135/config.json                                                                             
{'eval_loss': 0.037733208388090134, 'eval_runtime': 3.8222, 'eval_samples_per_second': 267.906, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.031427156180143356, 'eval_loss_2': 0.006306052207946777, 'eval_loss_3': -18.31060791015625, 'eval_loss_4': 3.1036386489868164, 'epoch': 0.78}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:50,800 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:50,802 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:50,802 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:51,736 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-105] due to args.save_total_limit
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:42<1:36:16,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:23:55,373 >>
{'loss': 0.1051, 'grad_norm': 26.212034225463867, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.0945349782705307, 'loss_2': 0.0106048583984375, 'loss_3': -15.643781661987305, 'loss_4': 3.8654723167419434, 'epoch': 0.79}
{'loss': 0.1462, 'grad_norm': 31.177610397338867, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.14446449279785156, 'loss_2': 0.001689910888671875, 'loss_3': -15.522064208984375, 'loss_4': 3.51505708694458, 'epoch': 0.8}
{'loss': 0.1057, 'grad_norm': 25.91216468811035, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.10424264520406723, 'loss_2': 0.001483917236328125, 'loss_3': -15.526355743408203, 'loss_4': 2.947338581085205, 'epoch': 0.8}
{'loss': 0.0475, 'grad_norm': 11.1333646774292, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.046691104769706726, 'loss_2': 0.0007867813110351562, 'loss_3': -15.486276626586914, 'loss_4': 2.8588881492614746, 'epoch': 0.81}
{'loss': 0.0565, 'grad_norm': 13.706280708312988, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.04720870405435562, 'loss_2': 0.0093231201171875, 'loss_3': -15.457374572753906, 'loss_4': 2.889312505722046, 'epoch': 0.81}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:55,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:55,373 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:49<1:28:25,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:24:02,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.046324148774147034, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.03804315626621246, 'eval_loss_2': 0.00828099250793457, 'eval_loss_3': -18.274585723876953, 'eval_loss_4': 2.5736522674560547, 'epoch': 0.81}
{'loss': 0.0643, 'grad_norm': 15.535296440124512, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.05976010486483574, 'loss_2': 0.0045166015625, 'loss_3': -15.369155883789062, 'loss_4': 2.276535749435425, 'epoch': 0.82}
{'loss': 0.0883, 'grad_norm': 19.6817569732666, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.08757711201906204, 'loss_2': 0.0006933212280273438, 'loss_3': -15.458017349243164, 'loss_4': 2.930783748626709, 'epoch': 0.83}
{'loss': 0.0603, 'grad_norm': 15.945751190185547, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.059092890471220016, 'loss_2': 0.0011768341064453125, 'loss_3': -15.28531551361084, 'loss_4': 2.4365813732147217, 'epoch': 0.83}
{'loss': 0.1349, 'grad_norm': 26.512807846069336, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.1324702948331833, 'loss_2': 0.002384185791015625, 'loss_3': -15.515336036682129, 'loss_4': 2.3728950023651123, 'epoch': 0.84}
{'loss': 0.0986, 'grad_norm': 22.324420928955078, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.09382665902376175, 'loss_2': 0.0048065185546875, 'loss_3': -15.408287048339844, 'loss_4': 2.8782808780670166, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 12:24:02,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:02,730 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:57<1:27:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:10,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05247236043214798, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.048450715839862823, 'eval_loss_2': 0.004021644592285156, 'eval_loss_3': -18.21883773803711, 'eval_loss_4': 2.4305293560028076, 'epoch': 0.84}
{'loss': 0.1163, 'grad_norm': 29.491477966308594, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.10744484513998032, 'loss_2': 0.00890350341796875, 'loss_3': -15.391583442687988, 'loss_4': 1.8617606163024902, 'epoch': 0.85}
{'loss': 0.1246, 'grad_norm': 30.574748992919922, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.12128962576389313, 'loss_2': 0.003322601318359375, 'loss_3': -15.116974830627441, 'loss_4': 2.2720301151275635, 'epoch': 0.85}
{'loss': 0.1102, 'grad_norm': 31.526662826538086, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.10959599167108536, 'loss_2': 0.0006122589111328125, 'loss_3': -15.249183654785156, 'loss_4': 2.598820686340332, 'epoch': 0.86}
{'loss': 0.0914, 'grad_norm': 23.574636459350586, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.09021957963705063, 'loss_2': 0.0011463165283203125, 'loss_3': -15.130135536193848, 'loss_4': 2.243504047393799, 'epoch': 0.87}
{'loss': 0.0892, 'grad_norm': 21.885826110839844, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.08264176547527313, 'loss_2': 0.00658416748046875, 'loss_3': -15.250038146972656, 'loss_4': 1.9099326133728027, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 12:24:10,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:10,086 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:04<1:26:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:17,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08517000079154968, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.265, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.07376096397638321, 'eval_loss_2': 0.01140904426574707, 'eval_loss_3': -18.091007232666016, 'eval_loss_4': 2.31718111038208, 'epoch': 0.87}
{'loss': 0.0741, 'grad_norm': 15.70174503326416, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.056093428283929825, 'loss_2': 0.0180511474609375, 'loss_3': -15.307615280151367, 'loss_4': 2.134127616882324, 'epoch': 0.88}
{'loss': 0.1425, 'grad_norm': 30.1793155670166, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.11947707086801529, 'loss_2': 0.022979736328125, 'loss_3': -15.32422924041748, 'loss_4': 2.0292365550994873, 'epoch': 0.88}
{'loss': 0.3139, 'grad_norm': 65.89519500732422, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.3047063648700714, 'loss_2': 0.0092315673828125, 'loss_3': -15.035780906677246, 'loss_4': 2.2650303840637207, 'epoch': 0.89}
{'loss': 0.2257, 'grad_norm': 45.33121871948242, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.21019147336483002, 'loss_2': 0.0154876708984375, 'loss_3': -14.849499702453613, 'loss_4': 2.1586737632751465, 'epoch': 0.9}
{'loss': 0.1349, 'grad_norm': 27.21982765197754, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.11892955005168915, 'loss_2': 0.0160064697265625, 'loss_3': -15.242951393127441, 'loss_4': 2.5072665214538574, 'epoch': 0.9}
[INFO|trainer.py:4228] 2025-01-21 12:24:17,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:17,432 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:11<1:26:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:24,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.057608820497989655, 'eval_runtime': 3.8312, 'eval_samples_per_second': 267.277, 'eval_steps_per_second': 4.176, 'eval_loss_1': 0.04748652130365372, 'eval_loss_2': 0.010122299194335938, 'eval_loss_3': -18.120441436767578, 'eval_loss_4': 2.2044425010681152, 'epoch': 0.9}
{'loss': 0.0744, 'grad_norm': 15.203357696533203, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.06358607858419418, 'loss_2': 0.0108184814453125, 'loss_3': -15.279194831848145, 'loss_4': 1.798822283744812, 'epoch': 0.91}
{'loss': 0.1544, 'grad_norm': 30.774982452392578, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.14519521594047546, 'loss_2': 0.0092315673828125, 'loss_3': -15.18283748626709, 'loss_4': 2.5931196212768555, 'epoch': 0.91}
{'loss': 0.1609, 'grad_norm': 33.71444320678711, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.1554243117570877, 'loss_2': 0.005474090576171875, 'loss_3': -15.279930114746094, 'loss_4': 2.7171759605407715, 'epoch': 0.92}
{'loss': 0.1119, 'grad_norm': 27.8464298248291, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.11134766042232513, 'loss_2': 0.0005502700805664062, 'loss_3': -15.2066068649292, 'loss_4': 2.5585100650787354, 'epoch': 0.92}
{'loss': 0.0853, 'grad_norm': 24.270116806030273, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.07438840717077255, 'loss_2': 0.010955810546875, 'loss_3': -15.312297821044922, 'loss_4': 2.843200206756592, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 12:24:24,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:24,817 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:15<1:26:49,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:24:28,628 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160
[INFO|configuration_utils.py:420] 2025-01-21 12:24:28,630 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160/config.json                                                                             
{'eval_loss': 0.03307121992111206, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.76, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.024686872959136963, 'eval_loss_2': 0.008384346961975098, 'eval_loss_3': -18.19016456604004, 'eval_loss_4': 2.4918415546417236, 'epoch': 0.93}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:29,137 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:29,139 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:29,139 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:30,070 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-135] due to args.save_total_limit
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:20<1:35:49,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:24:33,708 >>
{'loss': 0.1281, 'grad_norm': 30.552932739257812, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.1103411316871643, 'loss_2': 0.0178070068359375, 'loss_3': -14.98649787902832, 'loss_4': 3.063321590423584, 'epoch': 0.94}
{'loss': 0.0656, 'grad_norm': 13.519746780395508, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.055711984634399414, 'loss_2': 0.0098419189453125, 'loss_3': -15.289276123046875, 'loss_4': 2.757251024246216, 'epoch': 0.94}
{'loss': 0.1156, 'grad_norm': 28.69721221923828, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.10854941606521606, 'loss_2': 0.00704193115234375, 'loss_3': -15.328261375427246, 'loss_4': 2.5499753952026367, 'epoch': 0.95}
{'loss': 0.0613, 'grad_norm': 26.944942474365234, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.057385627180337906, 'loss_2': 0.003875732421875, 'loss_3': -15.332143783569336, 'loss_4': 2.94173002243042, 'epoch': 0.95}
{'loss': 0.1113, 'grad_norm': 26.411945343017578, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.09888499230146408, 'loss_2': 0.012420654296875, 'loss_3': -15.068538665771484, 'loss_4': 2.6819400787353516, 'epoch': 0.96}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:33,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:33,708 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:24<1:35:49,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:24:37,511 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165
[INFO|configuration_utils.py:420] 2025-01-21 12:24:37,513 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165/config.json                                                                             
{'eval_loss': 0.026746995747089386, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02336154319345951, 'eval_loss_2': 0.003385450690984726, 'eval_loss_3': -18.233673095703125, 'eval_loss_4': 1.8798766136169434, 'epoch': 0.96}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:38,028 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:38,029 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:38,029 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:38,952 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-160] due to args.save_total_limit
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:29<1:37:11,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:24:42,602 >>
{'loss': 0.166, 'grad_norm': 34.39460372924805, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.1629953533411026, 'loss_2': 0.0029888153076171875, 'loss_3': -15.296279907226562, 'loss_4': 2.668978214263916, 'epoch': 0.97}
{'loss': 0.0907, 'grad_norm': 17.644332885742188, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.08043134212493896, 'loss_2': 0.01023101806640625, 'loss_3': -15.506933212280273, 'loss_4': 2.5743191242218018, 'epoch': 0.97}
{'loss': 0.0728, 'grad_norm': 17.670454025268555, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.06762344390153885, 'loss_2': 0.00513458251953125, 'loss_3': -15.274815559387207, 'loss_4': 2.5018129348754883, 'epoch': 0.98}
{'loss': 0.1676, 'grad_norm': 34.747501373291016, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.16543549299240112, 'loss_2': 0.0021381378173828125, 'loss_3': -15.136924743652344, 'loss_4': 1.7883011102676392, 'epoch': 0.98}
{'loss': 0.1753, 'grad_norm': 31.629854202270508, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.17053145170211792, 'loss_2': 0.0048065185546875, 'loss_3': -15.360374450683594, 'loss_4': 2.4490973949432373, 'epoch': 0.99}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:42,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:42,603 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:33<1:37:11,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:24:46,407 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170
[INFO|configuration_utils.py:420] 2025-01-21 12:24:46,408 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170/config.json                                                                             
{'eval_loss': 0.025694789364933968, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.26, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.022172586992383003, 'eval_loss_2': 0.0035222023725509644, 'eval_loss_3': -18.210378646850586, 'eval_loss_4': 1.2775601148605347, 'epoch': 0.99}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:46,909 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:46,911 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:46,911 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:47,829 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-165] due to args.save_total_limit
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:38<1:34:45,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:24:51,165 >>
{'loss': 0.0515, 'grad_norm': 11.281770706176758, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.05005207285284996, 'loss_2': 0.001399993896484375, 'loss_3': -15.362070083618164, 'loss_4': 1.0926588773727417, 'epoch': 0.99}
{'loss': 0.0516, 'grad_norm': 22.18379783630371, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.037925586104393005, 'loss_2': 0.01364898681640625, 'loss_3': -15.418536186218262, 'loss_4': 3.189206838607788, 'epoch': 1.0}
{'loss': 0.0744, 'grad_norm': 16.58525848388672, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.0706619843840599, 'loss_2': 0.00373077392578125, 'loss_3': -15.369525909423828, 'loss_4': 1.9155182838439941, 'epoch': 1.01}
{'loss': 0.1141, 'grad_norm': 30.71416664123535, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.11045901477336884, 'loss_2': 0.003597259521484375, 'loss_3': -15.317289352416992, 'loss_4': 2.103825807571411, 'epoch': 1.01}
{'loss': 0.1077, 'grad_norm': 35.481239318847656, 'learning_rate': 2.9e-05, 'loss_1': 0.0960366353392601, 'loss_2': 0.01171112060546875, 'loss_3': -15.583107948303223, 'loss_4': 1.922487735748291, 'epoch': 1.02}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:51,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:51,165 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:45<1:27:39,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:24:58,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03768044710159302, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03233468160033226, 'eval_loss_2': 0.005345761775970459, 'eval_loss_3': -18.132061004638672, 'eval_loss_4': 1.237027645111084, 'epoch': 1.02}
{'loss': 0.1047, 'grad_norm': 41.287696838378906, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.0996565893292427, 'loss_2': 0.0050048828125, 'loss_3': -15.363670349121094, 'loss_4': 2.172393798828125, 'epoch': 1.02}
{'loss': 0.0823, 'grad_norm': 16.760656356811523, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.0796683207154274, 'loss_2': 0.0026035308837890625, 'loss_3': -15.578411102294922, 'loss_4': 1.4676567316055298, 'epoch': 1.03}
{'loss': 0.1236, 'grad_norm': 24.041393280029297, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.12132317572832108, 'loss_2': 0.002254486083984375, 'loss_3': -15.713153839111328, 'loss_4': 1.7874116897583008, 'epoch': 1.03}
{'loss': 0.108, 'grad_norm': 28.852596282958984, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.10454162210226059, 'loss_2': 0.0034351348876953125, 'loss_3': -15.346577644348145, 'loss_4': 1.1775970458984375, 'epoch': 1.04}
{'loss': 0.1383, 'grad_norm': 29.5922908782959, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.13794343173503876, 'loss_2': 0.00037288665771484375, 'loss_3': -15.199461936950684, 'loss_4': 1.1428148746490479, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 12:24:58,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:58,522 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:52<1:26:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:05,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0449184849858284, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0422058030962944, 'eval_loss_2': 0.0027126818895339966, 'eval_loss_3': -18.04380989074707, 'eval_loss_4': 1.1242005825042725, 'epoch': 1.05}
{'loss': 0.0745, 'grad_norm': 15.67823600769043, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.06809607893228531, 'loss_2': 0.006374359130859375, 'loss_3': -15.627899169921875, 'loss_4': 1.500005841255188, 'epoch': 1.05}
{'loss': 0.1022, 'grad_norm': 25.63661766052246, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.0951744019985199, 'loss_2': 0.00698089599609375, 'loss_3': -15.744054794311523, 'loss_4': 1.59360671043396, 'epoch': 1.06}
{'loss': 0.1104, 'grad_norm': 26.892484664916992, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.10223010182380676, 'loss_2': 0.008148193359375, 'loss_3': -15.399553298950195, 'loss_4': 0.9380933046340942, 'epoch': 1.06}
{'loss': 0.1006, 'grad_norm': 26.691478729248047, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.09824821352958679, 'loss_2': 0.0023193359375, 'loss_3': -15.244123458862305, 'loss_4': 1.2650223970413208, 'epoch': 1.07}
{'loss': 0.0824, 'grad_norm': 26.80211639404297, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.06940549612045288, 'loss_2': 0.01300048828125, 'loss_3': -15.218611717224121, 'loss_4': 1.1523823738098145, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 12:25:05,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:05,864 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:00<1:26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:13,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027630828320980072, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0250331349670887, 'eval_loss_2': 0.0025976896286010742, 'eval_loss_3': -18.210445404052734, 'eval_loss_4': 0.9872587323188782, 'epoch': 1.08}
{'loss': 0.1837, 'grad_norm': 34.00642776489258, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.1822575032711029, 'loss_2': 0.0014295578002929688, 'loss_3': -15.481010437011719, 'loss_4': 1.1796236038208008, 'epoch': 1.08}
{'loss': 0.0845, 'grad_norm': 15.490242004394531, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.07760337740182877, 'loss_2': 0.0068511962890625, 'loss_3': -15.436095237731934, 'loss_4': 1.2784173488616943, 'epoch': 1.09}
{'loss': 0.1517, 'grad_norm': 34.16335678100586, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.14564068615436554, 'loss_2': 0.006015777587890625, 'loss_3': -15.283042907714844, 'loss_4': 1.3248403072357178, 'epoch': 1.09}
{'loss': 0.1439, 'grad_norm': 20.692977905273438, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.13841089606285095, 'loss_2': 0.00547027587890625, 'loss_3': -15.36479377746582, 'loss_4': 1.4279762506484985, 'epoch': 1.1}
{'loss': 0.081, 'grad_norm': 17.519695281982422, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.07154185324907303, 'loss_2': 0.00942230224609375, 'loss_3': -15.413687705993652, 'loss_4': 1.9747941493988037, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 12:25:13,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:13,220 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:07<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:20,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028980426490306854, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.101, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.023084277287125587, 'eval_loss_2': 0.005896151065826416, 'eval_loss_3': -18.29559326171875, 'eval_loss_4': 1.710042953491211, 'epoch': 1.1}
{'loss': 0.1453, 'grad_norm': 34.92041778564453, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.1354658007621765, 'loss_2': 0.009796142578125, 'loss_3': -15.609830856323242, 'loss_4': 2.17920184135437, 'epoch': 1.11}
{'loss': 0.0958, 'grad_norm': 24.537446975708008, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.09432413429021835, 'loss_2': 0.0014705657958984375, 'loss_3': -15.548322677612305, 'loss_4': 2.720552444458008, 'epoch': 1.12}
{'loss': 0.1898, 'grad_norm': 44.96018600463867, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.18620353937149048, 'loss_2': 0.00360107421875, 'loss_3': -15.55910873413086, 'loss_4': 2.1096081733703613, 'epoch': 1.12}
{'loss': 0.1098, 'grad_norm': 21.816591262817383, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.1009913980960846, 'loss_2': 0.0087738037109375, 'loss_3': -15.502041816711426, 'loss_4': 1.4454185962677002, 'epoch': 1.13}
{'loss': 0.1002, 'grad_norm': 18.401409149169922, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.0883035957813263, 'loss_2': 0.0118865966796875, 'loss_3': -15.469963073730469, 'loss_4': 1.9682583808898926, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 12:25:20,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:20,580 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:15<1:26:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:27,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02860281616449356, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.024089625105261803, 'eval_loss_2': 0.004513189196586609, 'eval_loss_3': -18.235157012939453, 'eval_loss_4': 1.7255710363388062, 'epoch': 1.13}
{'loss': 0.099, 'grad_norm': 18.91263198852539, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.09146003425121307, 'loss_2': 0.00754547119140625, 'loss_3': -15.257255554199219, 'loss_4': 1.8829712867736816, 'epoch': 1.14}
{'loss': 0.0578, 'grad_norm': 15.410786628723145, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.05507807061076164, 'loss_2': 0.0027618408203125, 'loss_3': -15.349007606506348, 'loss_4': 1.6245927810668945, 'epoch': 1.15}
{'loss': 0.1349, 'grad_norm': 28.515138626098633, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.13221357762813568, 'loss_2': 0.002643585205078125, 'loss_3': -15.586729049682617, 'loss_4': 2.104579210281372, 'epoch': 1.15}
{'loss': 0.1327, 'grad_norm': 25.397972106933594, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.12656475603580475, 'loss_2': 0.00614166259765625, 'loss_3': -15.27121353149414, 'loss_4': 2.1595911979675293, 'epoch': 1.16}
{'loss': 0.075, 'grad_norm': 16.89906120300293, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.07007288932800293, 'loss_2': 0.004924774169921875, 'loss_3': -15.327051162719727, 'loss_4': 2.396796226501465, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 12:25:27,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:27,944 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:22<1:25:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:35,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04752629995346069, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04284316301345825, 'eval_loss_2': 0.004683136940002441, 'eval_loss_3': -18.132347106933594, 'eval_loss_4': 2.000852584838867, 'epoch': 1.16}
{'loss': 0.0559, 'grad_norm': 14.81938362121582, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.05047009140253067, 'loss_2': 0.00540924072265625, 'loss_3': -15.345630645751953, 'loss_4': 1.9811758995056152, 'epoch': 1.17}
{'loss': 0.1116, 'grad_norm': 30.41786003112793, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.10803484916687012, 'loss_2': 0.00357818603515625, 'loss_3': -15.399121284484863, 'loss_4': 2.5301012992858887, 'epoch': 1.17}
{'loss': 0.0488, 'grad_norm': 15.510310173034668, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.04841573163866997, 'loss_2': 0.0003981590270996094, 'loss_3': -15.33992862701416, 'loss_4': 2.4145572185516357, 'epoch': 1.18}
{'loss': 0.146, 'grad_norm': 33.713279724121094, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.14485135674476624, 'loss_2': 0.001155853271484375, 'loss_3': -15.416632652282715, 'loss_4': 2.544307231903076, 'epoch': 1.19}
{'loss': 0.1146, 'grad_norm': 26.912006378173828, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.11320023238658905, 'loss_2': 0.001422882080078125, 'loss_3': -15.370036125183105, 'loss_4': 1.9070045948028564, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 12:25:35,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:35,300 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:29<1:25:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:42,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04063033312559128, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.036115631461143494, 'eval_loss_2': 0.004514701664447784, 'eval_loss_3': -18.14472198486328, 'eval_loss_4': 1.8629908561706543, 'epoch': 1.19}
{'loss': 0.1057, 'grad_norm': 24.627281188964844, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.10431130975484848, 'loss_2': 0.001373291015625, 'loss_3': -15.410492897033691, 'loss_4': 1.9524321556091309, 'epoch': 1.2}
{'loss': 0.1325, 'grad_norm': 24.666975021362305, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.13153724372386932, 'loss_2': 0.0009737014770507812, 'loss_3': -15.371548652648926, 'loss_4': 2.253204584121704, 'epoch': 1.2}
{'loss': 0.0837, 'grad_norm': 19.882083892822266, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.08000055700540543, 'loss_2': 0.0037078857421875, 'loss_3': -15.47042179107666, 'loss_4': 2.0133607387542725, 'epoch': 1.21}
{'loss': 0.1169, 'grad_norm': 25.988332748413086, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.10882546752691269, 'loss_2': 0.0080718994140625, 'loss_3': -15.330949783325195, 'loss_4': 1.8889373540878296, 'epoch': 1.22}
{'loss': 0.2305, 'grad_norm': 35.58507537841797, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.21982476115226746, 'loss_2': 0.0106353759765625, 'loss_3': -15.384417533874512, 'loss_4': 2.111856698989868, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 12:25:42,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:42,660 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:37<1:25:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:50,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037917494773864746, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.03295835852622986, 'eval_loss_2': 0.004959136247634888, 'eval_loss_3': -18.169647216796875, 'eval_loss_4': 2.0855278968811035, 'epoch': 1.22}
{'loss': 0.1368, 'grad_norm': 28.370393753051758, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.12971609830856323, 'loss_2': 0.00710296630859375, 'loss_3': -15.435307502746582, 'loss_4': 1.339523434638977, 'epoch': 1.23}
{'loss': 0.1523, 'grad_norm': 34.719017028808594, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.14773806929588318, 'loss_2': 0.0045166015625, 'loss_3': -15.635499000549316, 'loss_4': 2.4842886924743652, 'epoch': 1.23}
{'loss': 0.0732, 'grad_norm': 12.690872192382812, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.06202863156795502, 'loss_2': 0.01116180419921875, 'loss_3': -15.348237037658691, 'loss_4': 2.426938056945801, 'epoch': 1.24}
{'loss': 0.0653, 'grad_norm': 15.76041316986084, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.056951072067022324, 'loss_2': 0.00836944580078125, 'loss_3': -15.657671928405762, 'loss_4': 2.496701717376709, 'epoch': 1.24}
{'loss': 0.0696, 'grad_norm': 14.05666732788086, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.06143872067332268, 'loss_2': 0.0081939697265625, 'loss_3': -15.377761840820312, 'loss_4': 2.5492520332336426, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 12:25:50,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:50,036 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:44<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:57,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039362821727991104, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.412, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.03248664736747742, 'eval_loss_2': 0.006876170635223389, 'eval_loss_3': -18.192947387695312, 'eval_loss_4': 2.7792153358459473, 'epoch': 1.25}
{'loss': 0.0612, 'grad_norm': 14.170577049255371, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.05596295744180679, 'loss_2': 0.00525665283203125, 'loss_3': -15.527079582214355, 'loss_4': 2.284296989440918, 'epoch': 1.26}
{'loss': 0.0656, 'grad_norm': 17.97039031982422, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.05991525575518608, 'loss_2': 0.0056610107421875, 'loss_3': -15.550642013549805, 'loss_4': 3.0746307373046875, 'epoch': 1.26}
{'loss': 0.1212, 'grad_norm': 22.861495971679688, 'learning_rate': 2.875e-05, 'loss_1': 0.11983327567577362, 'loss_2': 0.001392364501953125, 'loss_3': -15.336767196655273, 'loss_4': 2.772761344909668, 'epoch': 1.27}
{'loss': 0.0827, 'grad_norm': 25.813535690307617, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.07985018193721771, 'loss_2': 0.0028476715087890625, 'loss_3': -15.646467208862305, 'loss_4': 3.0513381958007812, 'epoch': 1.27}
{'loss': 0.0565, 'grad_norm': 15.918243408203125, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.0545031875371933, 'loss_2': 0.0019683837890625, 'loss_3': -15.555654525756836, 'loss_4': 3.071373462677002, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 12:25:57,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:57,409 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:51<1:25:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:04,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028625447303056717, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.843, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.024611087515950203, 'eval_loss_2': 0.004014357924461365, 'eval_loss_3': -18.231569290161133, 'eval_loss_4': 2.8405556678771973, 'epoch': 1.28}
{'loss': 0.0652, 'grad_norm': 14.750242233276367, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.056861866265535355, 'loss_2': 0.008331298828125, 'loss_3': -15.654119491577148, 'loss_4': 1.7737195491790771, 'epoch': 1.28}
{'loss': 0.0907, 'grad_norm': 20.78836441040039, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.0878588855266571, 'loss_2': 0.00279998779296875, 'loss_3': -15.444856643676758, 'loss_4': 2.8306691646575928, 'epoch': 1.29}
{'loss': 0.1266, 'grad_norm': 29.261707305908203, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.12414015829563141, 'loss_2': 0.00247955322265625, 'loss_3': -15.663312911987305, 'loss_4': 3.036877155303955, 'epoch': 1.3}
{'loss': 0.042, 'grad_norm': 10.053886413574219, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.041759368032217026, 'loss_2': 0.00028228759765625, 'loss_3': -15.480409622192383, 'loss_4': 2.586540699005127, 'epoch': 1.3}
{'loss': 0.0936, 'grad_norm': 25.415555953979492, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.08913824707269669, 'loss_2': 0.004505157470703125, 'loss_3': -15.366791725158691, 'loss_4': 2.711322784423828, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 12:26:04,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:04,778 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [05:59<1:25:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:12,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02699815109372139, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.32, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.023140326142311096, 'eval_loss_2': 0.003857821226119995, 'eval_loss_3': -18.23558235168457, 'eval_loss_4': 2.4958243370056152, 'epoch': 1.31}
{'loss': 0.0315, 'grad_norm': 8.719894409179688, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.03089439868927002, 'loss_2': 0.0005559921264648438, 'loss_3': -15.623857498168945, 'loss_4': 2.340977668762207, 'epoch': 1.31}
{'loss': 0.1438, 'grad_norm': 37.50809860229492, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.14256848394870758, 'loss_2': 0.0012111663818359375, 'loss_3': -15.61280632019043, 'loss_4': 3.1404523849487305, 'epoch': 1.32}
{'loss': 0.0565, 'grad_norm': 11.403773307800293, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.04750116169452667, 'loss_2': 0.009002685546875, 'loss_3': -15.520696640014648, 'loss_4': 1.8566782474517822, 'epoch': 1.33}
{'loss': 0.0664, 'grad_norm': 21.652111053466797, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.05987425521016121, 'loss_2': 0.006496429443359375, 'loss_3': -15.636242866516113, 'loss_4': 2.856130838394165, 'epoch': 1.33}
{'loss': 0.0649, 'grad_norm': 10.866399765014648, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.054791856557130814, 'loss_2': 0.01015472412109375, 'loss_3': -15.487990379333496, 'loss_4': 1.944408655166626, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 12:26:12,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:12,162 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:06<1:25:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:19,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038661375641822815, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.587, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.03403289243578911, 'eval_loss_2': 0.004628479480743408, 'eval_loss_3': -18.121353149414062, 'eval_loss_4': 2.2363264560699463, 'epoch': 1.34}
{'loss': 0.0806, 'grad_norm': 21.91060447692871, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.07836247235536575, 'loss_2': 0.0022411346435546875, 'loss_3': -15.496686935424805, 'loss_4': 2.2964935302734375, 'epoch': 1.34}
{'loss': 0.0772, 'grad_norm': 20.01083755493164, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.07465539872646332, 'loss_2': 0.0025177001953125, 'loss_3': -15.313629150390625, 'loss_4': 2.070478677749634, 'epoch': 1.35}
{'loss': 0.0996, 'grad_norm': 25.787538528442383, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.09474948793649673, 'loss_2': 0.0048065185546875, 'loss_3': -15.301227569580078, 'loss_4': 2.2315685749053955, 'epoch': 1.35}
{'loss': 0.0668, 'grad_norm': 15.537576675415039, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.06219083070755005, 'loss_2': 0.0045928955078125, 'loss_3': -15.647518157958984, 'loss_4': 2.414728879928589, 'epoch': 1.36}
{'loss': 0.1361, 'grad_norm': 28.866456985473633, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.1295064240694046, 'loss_2': 0.006591796875, 'loss_3': -15.232470512390137, 'loss_4': 2.0021770000457764, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 12:26:19,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:19,539 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:13<1:25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:26,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04346568137407303, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.612, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.039825208485126495, 'eval_loss_2': 0.003640472888946533, 'eval_loss_3': -18.136503219604492, 'eval_loss_4': 1.9734632968902588, 'epoch': 1.37}
{'loss': 0.0684, 'grad_norm': 27.20071029663086, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.06805232167243958, 'loss_2': 0.00031566619873046875, 'loss_3': -15.456634521484375, 'loss_4': 1.7857578992843628, 'epoch': 1.37}
{'loss': 0.0869, 'grad_norm': 21.89531707763672, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.08049874752759933, 'loss_2': 0.0063934326171875, 'loss_3': -15.411138534545898, 'loss_4': 2.33803653717041, 'epoch': 1.38}
{'loss': 0.0514, 'grad_norm': 14.695684432983398, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.04795961081981659, 'loss_2': 0.0034332275390625, 'loss_3': -15.53702163696289, 'loss_4': 1.9109668731689453, 'epoch': 1.38}
{'loss': 0.0817, 'grad_norm': 19.660442352294922, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.07668721675872803, 'loss_2': 0.0050201416015625, 'loss_3': -15.425992965698242, 'loss_4': 2.348027229309082, 'epoch': 1.39}
{'loss': 0.0841, 'grad_norm': 19.468978881835938, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.07566151767969131, 'loss_2': 0.008392333984375, 'loss_3': -15.649627685546875, 'loss_4': 1.989180326461792, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 12:26:26,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:26,912 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:21<1:25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:34,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033714063465595245, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.508, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.03039701282978058, 'eval_loss_2': 0.0033170506358146667, 'eval_loss_3': -18.231443405151367, 'eval_loss_4': 1.7695591449737549, 'epoch': 1.4}
{'loss': 0.0685, 'grad_norm': 13.557442665100098, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.06756497174501419, 'loss_2': 0.0009784698486328125, 'loss_3': -15.644538879394531, 'loss_4': 2.042454957962036, 'epoch': 1.4}
{'loss': 0.0635, 'grad_norm': 14.526070594787598, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.06030460074543953, 'loss_2': 0.003215789794921875, 'loss_3': -15.610122680664062, 'loss_4': 1.8363360166549683, 'epoch': 1.41}
{'loss': 0.0813, 'grad_norm': 16.51080894470215, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.0776752382516861, 'loss_2': 0.00360107421875, 'loss_3': -15.599154472351074, 'loss_4': 2.3439979553222656, 'epoch': 1.41}
{'loss': 0.0493, 'grad_norm': 14.75092601776123, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.04353957995772362, 'loss_2': 0.005718231201171875, 'loss_3': -15.474129676818848, 'loss_4': 1.273881435394287, 'epoch': 1.42}
{'loss': 0.044, 'grad_norm': 11.264866828918457, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.03838640823960304, 'loss_2': 0.00565338134765625, 'loss_3': -15.408358573913574, 'loss_4': 0.8588578701019287, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 12:26:34,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:34,289 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:28<1:25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:41,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026189731433987617, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.568, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.02182747796177864, 'eval_loss_2': 0.004362255334854126, 'eval_loss_3': -18.265743255615234, 'eval_loss_4': 1.0259759426116943, 'epoch': 1.42}
{'loss': 0.0756, 'grad_norm': 18.63481330871582, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.072403684258461, 'loss_2': 0.00323486328125, 'loss_3': -15.643899917602539, 'loss_4': 1.7078098058700562, 'epoch': 1.43}
{'loss': 0.1535, 'grad_norm': 35.0123176574707, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.14530400931835175, 'loss_2': 0.0081939697265625, 'loss_3': -15.380560874938965, 'loss_4': 1.46137535572052, 'epoch': 1.44}
{'loss': 0.1976, 'grad_norm': 38.33341979980469, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.19380757212638855, 'loss_2': 0.003787994384765625, 'loss_3': -15.050359725952148, 'loss_4': 1.3090351819992065, 'epoch': 1.44}
{'loss': 0.0451, 'grad_norm': 9.858563423156738, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.0404842346906662, 'loss_2': 0.0045928955078125, 'loss_3': -15.439298629760742, 'loss_4': 0.8983273506164551, 'epoch': 1.45}
{'loss': 0.0922, 'grad_norm': 20.181241989135742, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.07835911959409714, 'loss_2': 0.0138092041015625, 'loss_3': -15.391800880432129, 'loss_4': 0.6259098649024963, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 12:26:41,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:41,660 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:36<1:25:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:49,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029379848390817642, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.423, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.022754080593585968, 'eval_loss_2': 0.006625771522521973, 'eval_loss_3': -18.262001037597656, 'eval_loss_4': 0.6265661120414734, 'epoch': 1.45}
{'loss': 0.1113, 'grad_norm': 26.939071655273438, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.10840997099876404, 'loss_2': 0.002895355224609375, 'loss_3': -15.265593528747559, 'loss_4': 1.7145793437957764, 'epoch': 1.46}
{'loss': 0.0595, 'grad_norm': 13.465600967407227, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.05886681750416756, 'loss_2': 0.0006465911865234375, 'loss_3': -15.520811080932617, 'loss_4': 1.066447138786316, 'epoch': 1.47}
{'loss': 0.0611, 'grad_norm': 13.728594779968262, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.052220363169908524, 'loss_2': 0.00884246826171875, 'loss_3': -15.548355102539062, 'loss_4': 0.8073456287384033, 'epoch': 1.47}
{'loss': 0.1578, 'grad_norm': 35.52384567260742, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.15382802486419678, 'loss_2': 0.00400543212890625, 'loss_3': -15.349246978759766, 'loss_4': 1.379986047744751, 'epoch': 1.48}
{'loss': 0.0419, 'grad_norm': 11.282163619995117, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.0356987901031971, 'loss_2': 0.006195068359375, 'loss_3': -15.555656433105469, 'loss_4': 0.5372123122215271, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 12:26:49,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:49,035 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:43<1:25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:56,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030018581077456474, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.631, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.02417778968811035, 'eval_loss_2': 0.005840793251991272, 'eval_loss_3': -18.25653076171875, 'eval_loss_4': 0.5300106406211853, 'epoch': 1.48}
{'loss': 0.0489, 'grad_norm': 14.173442840576172, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.043570224195718765, 'loss_2': 0.0053558349609375, 'loss_3': -15.70098876953125, 'loss_4': 0.8127124309539795, 'epoch': 1.49}
{'loss': 0.0398, 'grad_norm': 8.415165901184082, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.03122442215681076, 'loss_2': 0.00860595703125, 'loss_3': -15.371298789978027, 'loss_4': 1.0920268297195435, 'epoch': 1.49}
{'loss': 0.0665, 'grad_norm': 15.878825187683105, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.06364866346120834, 'loss_2': 0.00286865234375, 'loss_3': -15.520498275756836, 'loss_4': 0.32616275548934937, 'epoch': 1.5}
{'loss': 0.1298, 'grad_norm': 33.205474853515625, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.11618930846452713, 'loss_2': 0.01357269287109375, 'loss_3': -15.259675025939941, 'loss_4': 1.0292978286743164, 'epoch': 1.51}
{'loss': 0.1424, 'grad_norm': 34.051658630371094, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.1265123188495636, 'loss_2': 0.0159149169921875, 'loss_3': -15.385242462158203, 'loss_4': 1.3599014282226562, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 12:26:56,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:56,406 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:50<1:24:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:03,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029387755319476128, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.022929947823286057, 'eval_loss_2': 0.006457805633544922, 'eval_loss_3': -18.28309440612793, 'eval_loss_4': 0.3751665949821472, 'epoch': 1.51}
{'loss': 0.0609, 'grad_norm': 17.392221450805664, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.055550191551446915, 'loss_2': 0.0053863525390625, 'loss_3': -15.23143196105957, 'loss_4': 1.128148078918457, 'epoch': 1.52}
{'loss': 0.0507, 'grad_norm': 23.916093826293945, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.05071502551436424, 'loss_2': 2.562999725341797e-06, 'loss_3': -15.36256217956543, 'loss_4': 0.35810670256614685, 'epoch': 1.52}
{'loss': 0.1062, 'grad_norm': 30.82135772705078, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.10523512959480286, 'loss_2': 0.0010089874267578125, 'loss_3': -15.323592185974121, 'loss_4': 0.749189019203186, 'epoch': 1.53}
{'loss': 0.0511, 'grad_norm': 16.300600051879883, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.045036353170871735, 'loss_2': 0.00603485107421875, 'loss_3': -15.192564964294434, 'loss_4': 0.23989874124526978, 'epoch': 1.53}
{'loss': 0.0421, 'grad_norm': 11.13723373413086, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.03893676772713661, 'loss_2': 0.003192901611328125, 'loss_3': -15.320556640625, 'loss_4': -0.19281625747680664, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 12:27:03,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:03,770 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [06:58<1:24:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:11,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03099757432937622, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.026288269087672234, 'eval_loss_2': 0.004709303379058838, 'eval_loss_3': -18.22099494934082, 'eval_loss_4': 0.23477624356746674, 'epoch': 1.54}
{'loss': 0.0776, 'grad_norm': 24.772933959960938, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.07695496082305908, 'loss_2': 0.0006799697875976562, 'loss_3': -15.298633575439453, 'loss_4': 0.7634106874465942, 'epoch': 1.55}
{'loss': 0.0806, 'grad_norm': 22.34136199951172, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.08055172115564346, 'loss_2': 5.340576171875e-05, 'loss_3': -15.128204345703125, 'loss_4': 0.9117881059646606, 'epoch': 1.55}
{'loss': 0.082, 'grad_norm': 27.068675994873047, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.07342499494552612, 'loss_2': 0.00860595703125, 'loss_3': -15.403948783874512, 'loss_4': 0.13508476316928864, 'epoch': 1.56}
{'loss': 0.0731, 'grad_norm': 31.912446975708008, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.0678563192486763, 'loss_2': 0.005237579345703125, 'loss_3': -15.256702423095703, 'loss_4': 0.8678445219993591, 'epoch': 1.56}
{'loss': 0.111, 'grad_norm': 27.390947341918945, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.11038047075271606, 'loss_2': 0.000579833984375, 'loss_3': -15.446945190429688, 'loss_4': 0.6107991337776184, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 12:27:11,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:11,132 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:05<1:24:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:18,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.054172977805137634, 'eval_runtime': 3.8215, 'eval_samples_per_second': 267.958, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.04989247024059296, 'eval_loss_2': 0.004280507564544678, 'eval_loss_3': -18.07439422607422, 'eval_loss_4': 0.7302121520042419, 'epoch': 1.57}
{'loss': 0.0546, 'grad_norm': 18.039579391479492, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.05144765228033066, 'loss_2': 0.00315093994140625, 'loss_3': -15.263898849487305, 'loss_4': 0.5416106581687927, 'epoch': 1.58}
{'loss': 0.0971, 'grad_norm': 26.657733917236328, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.0809420570731163, 'loss_2': 0.01611328125, 'loss_3': -15.470148086547852, 'loss_4': 0.847740650177002, 'epoch': 1.58}
{'loss': 0.0857, 'grad_norm': 27.90003204345703, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.07848840206861496, 'loss_2': 0.007236480712890625, 'loss_3': -15.425759315490723, 'loss_4': 1.4694089889526367, 'epoch': 1.59}
{'loss': 0.0784, 'grad_norm': 15.401021003723145, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.07098966836929321, 'loss_2': 0.00738525390625, 'loss_3': -15.465014457702637, 'loss_4': 1.0174802541732788, 'epoch': 1.59}
{'loss': 0.181, 'grad_norm': 34.17335510253906, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.16934366524219513, 'loss_2': 0.0116119384765625, 'loss_3': -15.203906059265137, 'loss_4': 1.2925137281417847, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 12:27:18,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:18,504 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:12<1:24:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:25,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08397287130355835, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.07077378779649734, 'eval_loss_2': 0.013199090957641602, 'eval_loss_3': -17.99813461303711, 'eval_loss_4': 1.5889458656311035, 'epoch': 1.6}
{'loss': 0.0882, 'grad_norm': 25.213592529296875, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.08158017694950104, 'loss_2': 0.006622314453125, 'loss_3': -15.348155975341797, 'loss_4': 1.5827429294586182, 'epoch': 1.6}
{'loss': 0.1241, 'grad_norm': 28.04124641418457, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.10647902637720108, 'loss_2': 0.0176239013671875, 'loss_3': -15.275551795959473, 'loss_4': 1.588749885559082, 'epoch': 1.61}
{'loss': 0.0987, 'grad_norm': 21.840848922729492, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.09105604141950607, 'loss_2': 0.0076904296875, 'loss_3': -15.259811401367188, 'loss_4': 1.6885724067687988, 'epoch': 1.62}
{'loss': 0.0946, 'grad_norm': 18.13591957092285, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.089545838534832, 'loss_2': 0.0050811767578125, 'loss_3': -15.278068542480469, 'loss_4': 1.7766458988189697, 'epoch': 1.62}
{'loss': 0.0696, 'grad_norm': 14.82064437866211, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.0660831555724144, 'loss_2': 0.00351715087890625, 'loss_3': -15.545393943786621, 'loss_4': 2.37109375, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 12:27:25,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:25,877 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:20<1:24:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:33,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02997046709060669, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.847, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02623724937438965, 'eval_loss_2': 0.003733217716217041, 'eval_loss_3': -18.240575790405273, 'eval_loss_4': 2.180804491043091, 'epoch': 1.63}
{'loss': 0.0502, 'grad_norm': 12.565876007080078, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.0480145625770092, 'loss_2': 0.002185821533203125, 'loss_3': -15.681869506835938, 'loss_4': 2.431410074234009, 'epoch': 1.63}
{'loss': 0.0844, 'grad_norm': 26.43071937561035, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.08410745114088058, 'loss_2': 0.00026416778564453125, 'loss_3': -15.469767570495605, 'loss_4': 2.802809953689575, 'epoch': 1.64}
{'loss': 0.1304, 'grad_norm': 25.036710739135742, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.1100916638970375, 'loss_2': 0.02032470703125, 'loss_3': -15.489466667175293, 'loss_4': 2.7438790798187256, 'epoch': 1.65}
{'loss': 0.1062, 'grad_norm': 28.559614181518555, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.09700801968574524, 'loss_2': 0.009185791015625, 'loss_3': -15.542047500610352, 'loss_4': 3.8287100791931152, 'epoch': 1.65}
{'loss': 0.0885, 'grad_norm': 19.501840591430664, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.07925332337617874, 'loss_2': 0.00925445556640625, 'loss_3': -15.4225492477417, 'loss_4': 3.6803622245788574, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 12:27:33,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:33,248 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:27<1:24:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:40,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03764782100915909, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.534, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.023333167657256126, 'eval_loss_2': 0.014314651489257812, 'eval_loss_3': -18.322044372558594, 'eval_loss_4': 3.6617493629455566, 'epoch': 1.66}
{'loss': 0.0899, 'grad_norm': 19.484827041625977, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.07833902537822723, 'loss_2': 0.01153564453125, 'loss_3': -15.60844612121582, 'loss_4': 4.700676918029785, 'epoch': 1.66}
{'loss': 0.0838, 'grad_norm': 20.675369262695312, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.07399220019578934, 'loss_2': 0.0098419189453125, 'loss_3': -15.597415924072266, 'loss_4': 4.015340328216553, 'epoch': 1.67}
{'loss': 0.113, 'grad_norm': 30.848997116088867, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.1014544740319252, 'loss_2': 0.011505126953125, 'loss_3': -15.67282772064209, 'loss_4': 4.3129401206970215, 'epoch': 1.67}
{'loss': 0.1306, 'grad_norm': 31.62917137145996, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.1242254450917244, 'loss_2': 0.00640869140625, 'loss_3': -15.646125793457031, 'loss_4': 4.829128265380859, 'epoch': 1.68}
{'loss': 0.0758, 'grad_norm': 16.810455322265625, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.06283833086490631, 'loss_2': 0.01293182373046875, 'loss_3': -15.80384635925293, 'loss_4': 4.131002426147461, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 12:27:40,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:40,623 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:31<1:24:34,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:27:44,435 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290
[INFO|configuration_utils.py:420] 2025-01-21 12:27:44,436 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290/config.json                                                                             
{'eval_loss': 0.02556893788278103, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.734, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02212459407746792, 'eval_loss_2': 0.0034443438053131104, 'eval_loss_3': -18.32596778869629, 'eval_loss_4': 3.7350306510925293, 'epoch': 1.69}
[INFO|modeling_utils.py:2988] 2025-01-21 12:27:44,907 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:27:44,908 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:27:44,909 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:27:45,767 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-170] due to args.save_total_limit
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:36<1:32:42,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:27:49,414 >>
{'loss': 0.1113, 'grad_norm': 27.07667350769043, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.10815821588039398, 'loss_2': 0.0030975341796875, 'loss_3': -15.719903945922852, 'loss_4': 4.289976596832275, 'epoch': 1.69}
{'loss': 0.0849, 'grad_norm': 29.748567581176758, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.0799509808421135, 'loss_2': 0.0049591064453125, 'loss_3': -15.695270538330078, 'loss_4': 4.2709150314331055, 'epoch': 1.7}
{'loss': 0.1959, 'grad_norm': 38.643516540527344, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.19239407777786255, 'loss_2': 0.0035400390625, 'loss_3': -15.597752571105957, 'loss_4': 3.7421796321868896, 'epoch': 1.7}
{'loss': 0.1442, 'grad_norm': 21.30445098876953, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.14370538294315338, 'loss_2': 0.0004696846008300781, 'loss_3': -15.647518157958984, 'loss_4': 3.3493051528930664, 'epoch': 1.71}
{'loss': 0.136, 'grad_norm': 23.22669219970703, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.12437985092401505, 'loss_2': 0.0116119384765625, 'loss_3': -15.421850204467773, 'loss_4': 3.422854423522949, 'epoch': 1.72}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:27:49,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:49,414 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:44<1:26:54,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 12:27:56,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031304262578487396, 'eval_runtime': 4.0122, 'eval_samples_per_second': 255.224, 'eval_steps_per_second': 3.988, 'eval_loss_1': 0.02806856483221054, 'eval_loss_2': 0.0032356977462768555, 'eval_loss_3': -18.307716369628906, 'eval_loss_4': 3.0832314491271973, 'epoch': 1.72}
{'loss': 0.0689, 'grad_norm': 14.343689918518066, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.06385999917984009, 'loss_2': 0.00507354736328125, 'loss_3': -15.630045890808105, 'loss_4': 3.0240018367767334, 'epoch': 1.72}
{'loss': 0.0743, 'grad_norm': 23.55016326904297, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.07284867018461227, 'loss_2': 0.00141143798828125, 'loss_3': -15.601746559143066, 'loss_4': 2.8317906856536865, 'epoch': 1.73}
{'loss': 0.0549, 'grad_norm': 15.931443214416504, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.050737738609313965, 'loss_2': 0.00414276123046875, 'loss_3': -15.382993698120117, 'loss_4': 2.742736339569092, 'epoch': 1.73}
{'loss': 0.117, 'grad_norm': 28.17698097229004, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.10680382698774338, 'loss_2': 0.01023101806640625, 'loss_3': -15.5890474319458, 'loss_4': 3.0289316177368164, 'epoch': 1.74}
{'loss': 0.0729, 'grad_norm': 15.488930702209473, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.06475166976451874, 'loss_2': 0.0081024169921875, 'loss_3': -15.62171745300293, 'loss_4': 2.804706573486328, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 12:27:56,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:56,982 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:51<1:24:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:04,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03938755393028259, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.025191154330968857, 'eval_loss_2': 0.014196395874023438, 'eval_loss_3': -18.327587127685547, 'eval_loss_4': 2.656482219696045, 'epoch': 1.74}
{'loss': 0.1068, 'grad_norm': 33.94395446777344, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.09159840643405914, 'loss_2': 0.0151824951171875, 'loss_3': -15.629376411437988, 'loss_4': 2.758301019668579, 'epoch': 1.75}
{'loss': 0.0499, 'grad_norm': 11.040384292602539, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.04415280371904373, 'loss_2': 0.0057220458984375, 'loss_3': -15.578310012817383, 'loss_4': 2.7567784786224365, 'epoch': 1.76}
{'loss': 0.063, 'grad_norm': 18.031288146972656, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.04917919635772705, 'loss_2': 0.01381683349609375, 'loss_3': -15.64588451385498, 'loss_4': 2.925187349319458, 'epoch': 1.76}
{'loss': 0.083, 'grad_norm': 16.698575973510742, 'learning_rate': 2.825e-05, 'loss_1': 0.07425467669963837, 'loss_2': 0.0087890625, 'loss_3': -15.344209671020508, 'loss_4': 2.779402732849121, 'epoch': 1.77}
{'loss': 0.1405, 'grad_norm': 33.502655029296875, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.14018528163433075, 'loss_2': 0.0003173351287841797, 'loss_3': -15.684837341308594, 'loss_4': 2.834411144256592, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 12:28:04,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:04,325 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:55<1:24:28,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:28:08,127 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305
[INFO|configuration_utils.py:420] 2025-01-21 12:28:08,128 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305/config.json                                                                             
{'eval_loss': 0.02518879622220993, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.021635940298438072, 'eval_loss_2': 0.003552854061126709, 'eval_loss_3': -18.32676124572754, 'eval_loss_4': 2.312443733215332, 'epoch': 1.77}
[INFO|modeling_utils.py:2988] 2025-01-21 12:28:08,613 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:28:08,615 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:28:08,615 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:28:09,537 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-290] due to args.save_total_limit
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:00<1:32:53,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:28:13,186 >>
{'loss': 0.0726, 'grad_norm': 26.48996353149414, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.06633118540048599, 'loss_2': 0.00626373291015625, 'loss_3': -15.568124771118164, 'loss_4': 2.831686496734619, 'epoch': 1.78}
{'loss': 0.0685, 'grad_norm': 17.512723922729492, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.06759106367826462, 'loss_2': 0.0009388923645019531, 'loss_3': -15.621360778808594, 'loss_4': 2.20330810546875, 'epoch': 1.78}
{'loss': 0.0801, 'grad_norm': 19.51883888244629, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.06979712843894958, 'loss_2': 0.01029205322265625, 'loss_3': -15.53859806060791, 'loss_4': 2.220604658126831, 'epoch': 1.79}
{'loss': 0.0897, 'grad_norm': 21.613893508911133, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.07973233610391617, 'loss_2': 0.00998687744140625, 'loss_3': -15.805135726928711, 'loss_4': 1.9194602966308594, 'epoch': 1.8}
{'loss': 0.0555, 'grad_norm': 12.928093910217285, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.045288849622011185, 'loss_2': 0.0101776123046875, 'loss_3': -15.749127388000488, 'loss_4': 1.8258615732192993, 'epoch': 1.8}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:28:13,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:13,187 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:04<1:32:53,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:28:16,994 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310
[INFO|configuration_utils.py:420] 2025-01-21 12:28:16,995 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310/config.json                                                                             
{'eval_loss': 0.024437658488750458, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02012704871594906, 'eval_loss_2': 0.00431060791015625, 'eval_loss_3': -18.26953125, 'eval_loss_4': 1.9384173154830933, 'epoch': 1.8}
[INFO|modeling_utils.py:2988] 2025-01-21 12:28:17,489 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:28:17,490 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:28:17,490 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:28:18,416 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-305] due to args.save_total_limit
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:09<1:34:16,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:28:22,064 >>
{'loss': 0.0464, 'grad_norm': 13.366082191467285, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.039856549352407455, 'loss_2': 0.00655364990234375, 'loss_3': -15.62271785736084, 'loss_4': 1.984190821647644, 'epoch': 1.81}
{'loss': 0.0464, 'grad_norm': 12.539724349975586, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.03990580886602402, 'loss_2': 0.00650787353515625, 'loss_3': -15.774358749389648, 'loss_4': 1.612828016281128, 'epoch': 1.81}
{'loss': 0.0489, 'grad_norm': 10.730351448059082, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.045504871755838394, 'loss_2': 0.00336456298828125, 'loss_3': -15.330440521240234, 'loss_4': 1.7796239852905273, 'epoch': 1.82}
{'loss': 0.041, 'grad_norm': 12.175639152526855, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.03678135946393013, 'loss_2': 0.00421905517578125, 'loss_3': -15.834571838378906, 'loss_4': 1.7915449142456055, 'epoch': 1.83}
{'loss': 0.0819, 'grad_norm': 19.37942886352539, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.07731623947620392, 'loss_2': 0.00463104248046875, 'loss_3': -15.713783264160156, 'loss_4': 1.5398463010787964, 'epoch': 1.83}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:28:22,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:22,064 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:16<1:25:29,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:28:29,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02826550230383873, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.022140920162200928, 'eval_loss_2': 0.006124585866928101, 'eval_loss_3': -18.202054977416992, 'eval_loss_4': 1.6219606399536133, 'epoch': 1.83}
{'loss': 0.0516, 'grad_norm': 13.186717987060547, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.037421662360429764, 'loss_2': 0.0142059326171875, 'loss_3': -15.858475685119629, 'loss_4': 2.1730871200561523, 'epoch': 1.84}
{'loss': 0.1011, 'grad_norm': 21.046977996826172, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.08614721149206161, 'loss_2': 0.0149993896484375, 'loss_3': -15.551246643066406, 'loss_4': 2.208789825439453, 'epoch': 1.84}
{'loss': 0.0488, 'grad_norm': 10.820568084716797, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.04054825007915497, 'loss_2': 0.008209228515625, 'loss_3': -15.51282024383545, 'loss_4': 1.4494082927703857, 'epoch': 1.85}
{'loss': 0.0677, 'grad_norm': 17.61910629272461, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.06140843778848648, 'loss_2': 0.006305694580078125, 'loss_3': -15.404180526733398, 'loss_4': 1.8604085445404053, 'epoch': 1.85}
{'loss': 0.0703, 'grad_norm': 16.95698356628418, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.06691735982894897, 'loss_2': 0.003376007080078125, 'loss_3': -15.37480354309082, 'loss_4': 1.4523394107818604, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 12:28:29,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:29,409 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:23<1:24:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:36,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028927940875291824, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.667, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.023432528600096703, 'eval_loss_2': 0.005495414137840271, 'eval_loss_3': -18.203916549682617, 'eval_loss_4': 1.2872198820114136, 'epoch': 1.86}
{'loss': 0.0273, 'grad_norm': 6.539639472961426, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.0185098834335804, 'loss_2': 0.0088348388671875, 'loss_3': -15.489846229553223, 'loss_4': 0.9246593117713928, 'epoch': 1.87}
{'loss': 0.0541, 'grad_norm': 14.963329315185547, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.05132436752319336, 'loss_2': 0.0027904510498046875, 'loss_3': -15.641315460205078, 'loss_4': 1.4562230110168457, 'epoch': 1.87}
{'loss': 0.0738, 'grad_norm': 18.824758529663086, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.06812025606632233, 'loss_2': 0.0056915283203125, 'loss_3': -15.357505798339844, 'loss_4': 1.0395095348358154, 'epoch': 1.88}
{'loss': 0.215, 'grad_norm': 36.59412384033203, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.2062467485666275, 'loss_2': 0.00870513916015625, 'loss_3': -15.499863624572754, 'loss_4': 1.658738613128662, 'epoch': 1.88}
{'loss': 0.0285, 'grad_norm': 7.739480972290039, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.02375020645558834, 'loss_2': 0.004756927490234375, 'loss_3': -15.735530853271484, 'loss_4': 1.3035602569580078, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 12:28:36,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:36,771 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:31<1:23:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:44,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03062392584979534, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.023007972165942192, 'eval_loss_2': 0.007615953683853149, 'eval_loss_3': -18.18490982055664, 'eval_loss_4': 1.3889597654342651, 'epoch': 1.89}
{'loss': 0.0565, 'grad_norm': 13.706992149353027, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.04707403853535652, 'loss_2': 0.0093994140625, 'loss_3': -15.397518157958984, 'loss_4': 1.9046881198883057, 'epoch': 1.9}
{'loss': 0.0501, 'grad_norm': 20.26246452331543, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.047040533274412155, 'loss_2': 0.003063201904296875, 'loss_3': -15.371786117553711, 'loss_4': 1.558420181274414, 'epoch': 1.9}
{'loss': 0.0467, 'grad_norm': 14.64387035369873, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.043644990772008896, 'loss_2': 0.0030670166015625, 'loss_3': -15.584342956542969, 'loss_4': 1.631810188293457, 'epoch': 1.91}
{'loss': 0.0344, 'grad_norm': 10.130934715270996, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.0278567336499691, 'loss_2': 0.006504058837890625, 'loss_3': -15.704627990722656, 'loss_4': 1.0730171203613281, 'epoch': 1.91}
{'loss': 0.065, 'grad_norm': 20.30803871154785, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.059766657650470734, 'loss_2': 0.005252838134765625, 'loss_3': -15.396419525146484, 'loss_4': 1.2951843738555908, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 12:28:44,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:44,127 >>   Batch size = 64
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:38<1:23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:51,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02962486632168293, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.314, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.023825712502002716, 'eval_loss_2': 0.005799159407615662, 'eval_loss_3': -18.120698928833008, 'eval_loss_4': 1.3413348197937012, 'epoch': 1.92}
{'loss': 0.0363, 'grad_norm': 10.882980346679688, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.031393516808748245, 'loss_2': 0.0048675537109375, 'loss_3': -15.44272232055664, 'loss_4': 1.578387975692749, 'epoch': 1.92}
{'loss': 0.0467, 'grad_norm': 12.513459205627441, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.04206554591655731, 'loss_2': 0.00463104248046875, 'loss_3': -15.431930541992188, 'loss_4': 1.4345905780792236, 'epoch': 1.93}
{'loss': 0.094, 'grad_norm': 18.937255859375, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.08900211751461029, 'loss_2': 0.005001068115234375, 'loss_3': -15.401400566101074, 'loss_4': 1.2662997245788574, 'epoch': 1.94}
{'loss': 0.0356, 'grad_norm': 9.42232894897461, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.03159506246447563, 'loss_2': 0.0040130615234375, 'loss_3': -15.523150444030762, 'loss_4': 1.2247774600982666, 'epoch': 1.94}
{'loss': 0.0618, 'grad_norm': 17.46578598022461, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.058973245322704315, 'loss_2': 0.002788543701171875, 'loss_3': -15.428250312805176, 'loss_4': 1.2092797756195068, 'epoch': 1.95}
[INFO|trainer.py:4228] 2025-01-21 12:28:51,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:51,473 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:45<1:23:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:58,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031166331842541695, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.026766253635287285, 'eval_loss_2': 0.004400074481964111, 'eval_loss_3': -18.1029109954834, 'eval_loss_4': 1.068344235420227, 'epoch': 1.95}
{'loss': 0.035, 'grad_norm': 9.581335067749023, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.03289172425866127, 'loss_2': 0.0020599365234375, 'loss_3': -15.555076599121094, 'loss_4': 1.0597648620605469, 'epoch': 1.95}
{'loss': 0.0568, 'grad_norm': 18.33086395263672, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.056598808616399765, 'loss_2': 0.00019979476928710938, 'loss_3': -15.406774520874023, 'loss_4': 0.7253265976905823, 'epoch': 1.96}
{'loss': 0.0617, 'grad_norm': 17.117643356323242, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.057759903371334076, 'loss_2': 0.00392913818359375, 'loss_3': -15.461453437805176, 'loss_4': 0.900648295879364, 'epoch': 1.97}
{'loss': 0.0696, 'grad_norm': 17.366012573242188, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.06079886853694916, 'loss_2': 0.00885009765625, 'loss_3': -15.521774291992188, 'loss_4': 1.3871103525161743, 'epoch': 1.97}
{'loss': 0.03, 'grad_norm': 6.774979114532471, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.020454347133636475, 'loss_2': 0.00957489013671875, 'loss_3': -15.405950546264648, 'loss_4': 0.9232394099235535, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 12:28:58,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:58,825 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:52<1:18:24,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 12:29:05,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04231718182563782, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0368770956993103, 'eval_loss_2': 0.005440086126327515, 'eval_loss_3': -18.08029556274414, 'eval_loss_4': 0.7951453924179077, 'epoch': 1.98}
{'loss': 0.037, 'grad_norm': 10.147307395935059, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.03470609709620476, 'loss_2': 0.002338409423828125, 'loss_3': -15.569015502929688, 'loss_4': 0.9373268485069275, 'epoch': 1.98}
{'loss': 0.0678, 'grad_norm': 18.27068519592285, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.06244513764977455, 'loss_2': 0.005306243896484375, 'loss_3': -15.444637298583984, 'loss_4': 1.079664945602417, 'epoch': 1.99}
{'loss': 0.1218, 'grad_norm': 42.130008697509766, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.1168874129652977, 'loss_2': 0.0048828125, 'loss_3': -15.684755325317383, 'loss_4': 0.6779892444610596, 'epoch': 1.99}
{'loss': 0.0494, 'grad_norm': 14.1022310256958, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.038861025124788284, 'loss_2': 0.010528564453125, 'loss_3': -15.530797004699707, 'loss_4': 1.2455583810806274, 'epoch': 2.0}
{'loss': 0.0541, 'grad_norm': 14.822686195373535, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.044479552656412125, 'loss_2': 0.0096588134765625, 'loss_3': -15.680317878723145, 'loss_4': 0.5245230197906494, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 12:29:05,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:05,859 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:00<1:22:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:29:13,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05545008182525635, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.709, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.04359853267669678, 'eval_loss_2': 0.01185154914855957, 'eval_loss_3': -18.089969635009766, 'eval_loss_4': 0.6506848335266113, 'epoch': 2.01}
{'loss': 0.0637, 'grad_norm': 14.015350341796875, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.056369274854660034, 'loss_2': 0.00733184814453125, 'loss_3': -15.469100952148438, 'loss_4': 0.5661588907241821, 'epoch': 2.01}
{'loss': 0.0489, 'grad_norm': 15.124410629272461, 'learning_rate': 2.8e-05, 'loss_1': 0.03957677260041237, 'loss_2': 0.00927734375, 'loss_3': -15.501335144042969, 'loss_4': 0.7552688717842102, 'epoch': 2.02}
{'loss': 0.1667, 'grad_norm': 44.27490234375, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.1566224992275238, 'loss_2': 0.01007843017578125, 'loss_3': -15.334829330444336, 'loss_4': 0.8046000003814697, 'epoch': 2.02}
{'loss': 0.0431, 'grad_norm': 13.413655281066895, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.03122059628367424, 'loss_2': 0.0118560791015625, 'loss_3': -15.229110717773438, 'loss_4': 0.3440454602241516, 'epoch': 2.03}
{'loss': 0.0679, 'grad_norm': 22.07230567932129, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.061487436294555664, 'loss_2': 0.006435394287109375, 'loss_3': -15.363405227661133, 'loss_4': 0.9966466426849365, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 12:29:13,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:13,201 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:07<1:23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:20,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05194924399256706, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.493, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.045814257115125656, 'eval_loss_2': 0.006134986877441406, 'eval_loss_3': -18.054058074951172, 'eval_loss_4': 0.9100631475448608, 'epoch': 2.03}
{'loss': 0.034, 'grad_norm': 9.287840843200684, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.030091386288404465, 'loss_2': 0.003887176513671875, 'loss_3': -15.296209335327148, 'loss_4': 0.6899667978286743, 'epoch': 2.04}
{'loss': 0.0787, 'grad_norm': 21.2271671295166, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.06353487074375153, 'loss_2': 0.01520538330078125, 'loss_3': -15.389921188354492, 'loss_4': 1.3477320671081543, 'epoch': 2.05}
{'loss': 0.0522, 'grad_norm': 13.183975219726562, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.03672626614570618, 'loss_2': 0.01546478271484375, 'loss_3': -15.096820831298828, 'loss_4': 0.5025429725646973, 'epoch': 2.05}
{'loss': 0.081, 'grad_norm': 19.498126983642578, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.05688159540295601, 'loss_2': 0.02410888671875, 'loss_3': -15.539373397827148, 'loss_4': 1.2085323333740234, 'epoch': 2.06}
{'loss': 0.0463, 'grad_norm': 8.582935333251953, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.02804999053478241, 'loss_2': 0.018280029296875, 'loss_3': -15.453422546386719, 'loss_4': 1.1528091430664062, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 12:29:20,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:20,559 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:14<1:23:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:27,912 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05184636265039444, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.021, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.03137669712305069, 'eval_loss_2': 0.02046966552734375, 'eval_loss_3': -18.092700958251953, 'eval_loss_4': 1.2125060558319092, 'epoch': 2.06}
{'loss': 0.089, 'grad_norm': 18.824378967285156, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.07283481955528259, 'loss_2': 0.0161590576171875, 'loss_3': -15.441974639892578, 'loss_4': 1.4320950508117676, 'epoch': 2.07}
{'loss': 0.0823, 'grad_norm': 29.928516387939453, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.0662289410829544, 'loss_2': 0.0160675048828125, 'loss_3': -15.543041229248047, 'loss_4': 1.108100175857544, 'epoch': 2.08}
{'loss': 0.0677, 'grad_norm': 12.389986991882324, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.0469445176422596, 'loss_2': 0.020721435546875, 'loss_3': -15.555500984191895, 'loss_4': 1.7358100414276123, 'epoch': 2.08}
{'loss': 0.0554, 'grad_norm': 10.554020881652832, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.03596402704715729, 'loss_2': 0.0194091796875, 'loss_3': -15.386799812316895, 'loss_4': 1.7678210735321045, 'epoch': 2.09}
{'loss': 0.0509, 'grad_norm': 12.814109802246094, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.03378983959555626, 'loss_2': 0.01715087890625, 'loss_3': -15.433034896850586, 'loss_4': 1.4411967992782593, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 12:29:27,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:27,913 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:22<1:23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:35,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03309004008769989, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.224, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02972029149532318, 'eval_loss_2': 0.003369748592376709, 'eval_loss_3': -18.086090087890625, 'eval_loss_4': 1.4067444801330566, 'epoch': 2.09}
{'loss': 0.0502, 'grad_norm': 14.621025085449219, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.043715402483940125, 'loss_2': 0.006450653076171875, 'loss_3': -15.600696563720703, 'loss_4': 1.648835301399231, 'epoch': 2.1}
{'loss': 0.0682, 'grad_norm': 23.324487686157227, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.06704568862915039, 'loss_2': 0.0011997222900390625, 'loss_3': -15.425049781799316, 'loss_4': 1.4381736516952515, 'epoch': 2.1}
{'loss': 0.0609, 'grad_norm': 18.847179412841797, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.04958682134747505, 'loss_2': 0.01126861572265625, 'loss_3': -15.392717361450195, 'loss_4': 1.6471303701400757, 'epoch': 2.11}
{'loss': 0.0567, 'grad_norm': 21.127317428588867, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.04274642467498779, 'loss_2': 0.01396942138671875, 'loss_3': -15.541306495666504, 'loss_4': 1.3804835081100464, 'epoch': 2.12}
{'loss': 0.0482, 'grad_norm': 9.357950210571289, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.0274717528373003, 'loss_2': 0.0207672119140625, 'loss_3': -15.242582321166992, 'loss_4': 1.0078001022338867, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 12:29:35,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:35,267 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:29<1:22:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:42,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04335904121398926, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.029579874128103256, 'eval_loss_2': 0.013779163360595703, 'eval_loss_3': -18.095443725585938, 'eval_loss_4': 1.3822531700134277, 'epoch': 2.12}
{'loss': 0.0506, 'grad_norm': 8.726133346557617, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.03358421102166176, 'loss_2': 0.0169830322265625, 'loss_3': -15.285504341125488, 'loss_4': 0.9236805438995361, 'epoch': 2.13}
{'loss': 0.0349, 'grad_norm': 9.603230476379395, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.031240345910191536, 'loss_2': 0.003681182861328125, 'loss_3': -15.765127182006836, 'loss_4': 1.3898637294769287, 'epoch': 2.13}
{'loss': 0.0455, 'grad_norm': 11.500082969665527, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.043130919337272644, 'loss_2': 0.00238037109375, 'loss_3': -15.642351150512695, 'loss_4': 1.8621468544006348, 'epoch': 2.14}
{'loss': 0.0642, 'grad_norm': 26.68353271484375, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.06129677593708038, 'loss_2': 0.0029087066650390625, 'loss_3': -15.597692489624023, 'loss_4': 1.6741724014282227, 'epoch': 2.15}
{'loss': 0.0618, 'grad_norm': 22.053678512573242, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.05404404550790787, 'loss_2': 0.007781982421875, 'loss_3': -15.356269836425781, 'loss_4': 1.6754388809204102, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 12:29:42,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:42,613 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:37<1:22:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:49,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03637154400348663, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02909715659916401, 'eval_loss_2': 0.0072743892669677734, 'eval_loss_3': -18.083568572998047, 'eval_loss_4': 1.2024163007736206, 'epoch': 2.15}
{'loss': 0.0273, 'grad_norm': 9.249216079711914, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.026320884004235268, 'loss_2': 0.0010128021240234375, 'loss_3': -15.57166576385498, 'loss_4': 0.9786403775215149, 'epoch': 2.16}
{'loss': 0.2617, 'grad_norm': 31.178651809692383, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.25853684544563293, 'loss_2': 0.00312042236328125, 'loss_3': -14.878150939941406, 'loss_4': 1.038515567779541, 'epoch': 2.16}
{'loss': 0.0383, 'grad_norm': 9.278725624084473, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.028664518147706985, 'loss_2': 0.009674072265625, 'loss_3': -15.512787818908691, 'loss_4': 0.8851726055145264, 'epoch': 2.17}
{'loss': 0.0513, 'grad_norm': 11.911471366882324, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.047163087874650955, 'loss_2': 0.004131317138671875, 'loss_3': -15.480986595153809, 'loss_4': 0.7957019209861755, 'epoch': 2.17}
{'loss': 0.0371, 'grad_norm': 16.153182983398438, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.035924699157476425, 'loss_2': 0.0011425018310546875, 'loss_3': -15.410572052001953, 'loss_4': 1.123313069343567, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 12:29:49,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:49,968 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:44<1:22:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:57,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03771762549877167, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.472, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.03435884788632393, 'eval_loss_2': 0.003358781337738037, 'eval_loss_3': -18.04046630859375, 'eval_loss_4': 0.6132440567016602, 'epoch': 2.18}
{'loss': 0.0918, 'grad_norm': 48.54631805419922, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.08143382519483566, 'loss_2': 0.01032257080078125, 'loss_3': -15.17453670501709, 'loss_4': 0.30141231417655945, 'epoch': 2.19}
{'loss': 0.0457, 'grad_norm': 12.718613624572754, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.04425716772675514, 'loss_2': 0.00148773193359375, 'loss_3': -15.278739929199219, 'loss_4': 0.564895510673523, 'epoch': 2.19}
{'loss': 0.0321, 'grad_norm': 9.081830024719238, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.027710428461432457, 'loss_2': 0.0044097900390625, 'loss_3': -15.442593574523926, 'loss_4': 0.6903676986694336, 'epoch': 2.2}
{'loss': 0.035, 'grad_norm': 10.435813903808594, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.03391583636403084, 'loss_2': 0.0010852813720703125, 'loss_3': -15.357141494750977, 'loss_4': 0.07552114129066467, 'epoch': 2.2}
{'loss': 0.0391, 'grad_norm': 9.219409942626953, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.026415254920721054, 'loss_2': 0.0126953125, 'loss_3': -15.240777969360352, 'loss_4': -0.2842991054058075, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 12:29:57,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:57,330 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:51<1:22:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:04,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02874055504798889, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.024371523410081863, 'eval_loss_2': 0.004369031637907028, 'eval_loss_3': -18.11116600036621, 'eval_loss_4': -0.16861799359321594, 'epoch': 2.21}
{'loss': 0.0964, 'grad_norm': 17.383996963500977, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.09575158357620239, 'loss_2': 0.0006799697875976562, 'loss_3': -15.49030876159668, 'loss_4': 0.3304691016674042, 'epoch': 2.22}
{'loss': 0.0537, 'grad_norm': 10.62590217590332, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.0403045117855072, 'loss_2': 0.01342010498046875, 'loss_3': -15.27937126159668, 'loss_4': -0.4584944248199463, 'epoch': 2.22}
{'loss': 0.1354, 'grad_norm': 26.09438133239746, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.13534943759441376, 'loss_2': 9.393692016601562e-05, 'loss_3': -15.28426456451416, 'loss_4': -0.2869582176208496, 'epoch': 2.23}
{'loss': 0.0346, 'grad_norm': 9.419416427612305, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.03177628666162491, 'loss_2': 0.0028667449951171875, 'loss_3': -15.626337051391602, 'loss_4': 0.17043600976467133, 'epoch': 2.23}
{'loss': 0.0571, 'grad_norm': 12.492998123168945, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.05103157460689545, 'loss_2': 0.00604248046875, 'loss_3': -15.366031646728516, 'loss_4': -0.4164099097251892, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 12:30:04,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:04,680 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:59<1:22:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:12,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025060582906007767, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.020378610119223595, 'eval_loss_2': 0.004681974649429321, 'eval_loss_3': -18.118221282958984, 'eval_loss_4': -0.037456899881362915, 'epoch': 2.24}
{'loss': 0.041, 'grad_norm': 11.451645851135254, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.03947411850094795, 'loss_2': 0.0015354156494140625, 'loss_3': -15.39357852935791, 'loss_4': -0.07558958232402802, 'epoch': 2.24}
{'loss': 0.1203, 'grad_norm': 19.21955108642578, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.1163967102766037, 'loss_2': 0.003879547119140625, 'loss_3': -15.518598556518555, 'loss_4': 0.17545899748802185, 'epoch': 2.25}
{'loss': 0.0417, 'grad_norm': 11.709634780883789, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.034280117601156235, 'loss_2': 0.00740814208984375, 'loss_3': -15.348506927490234, 'loss_4': 0.4948461651802063, 'epoch': 2.26}
{'loss': 0.0706, 'grad_norm': 18.979843139648438, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.06432308256626129, 'loss_2': 0.0062408447265625, 'loss_3': -15.226007461547852, 'loss_4': 0.763719916343689, 'epoch': 2.26}
{'loss': 0.0318, 'grad_norm': 8.545733451843262, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.027167411521077156, 'loss_2': 0.004589080810546875, 'loss_3': -15.295265197753906, 'loss_4': 0.5104973912239075, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 12:30:12,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:12,034 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:06<1:22:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:19,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03016243875026703, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.151, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.025308918207883835, 'eval_loss_2': 0.004853520542383194, 'eval_loss_3': -18.052635192871094, 'eval_loss_4': 0.4395275115966797, 'epoch': 2.27}
{'loss': 0.0387, 'grad_norm': 10.878607749938965, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.0340140238404274, 'loss_2': 0.0046539306640625, 'loss_3': -15.43609619140625, 'loss_4': 0.31377407908439636, 'epoch': 2.27}
{'loss': 0.033, 'grad_norm': 10.921099662780762, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.03146021068096161, 'loss_2': 0.0014972686767578125, 'loss_3': -15.283170700073242, 'loss_4': 0.4764629304409027, 'epoch': 2.28}
{'loss': 0.024, 'grad_norm': 8.799942970275879, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.023491667583584785, 'loss_2': 0.0004730224609375, 'loss_3': -15.418996810913086, 'loss_4': 0.5923171043395996, 'epoch': 2.28}
{'loss': 0.077, 'grad_norm': 21.31833267211914, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.07556501030921936, 'loss_2': 0.0014142990112304688, 'loss_3': -15.464781761169434, 'loss_4': 0.6672663688659668, 'epoch': 2.29}
{'loss': 0.0351, 'grad_norm': 13.37228012084961, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.03215572610497475, 'loss_2': 0.00293731689453125, 'loss_3': -15.340822219848633, 'loss_4': 0.5015239715576172, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 12:30:19,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:19,387 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:13<1:22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:26,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.040354423224925995, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.03484337776899338, 'eval_loss_2': 0.005511045455932617, 'eval_loss_3': -18.03135108947754, 'eval_loss_4': 0.9117558002471924, 'epoch': 2.3}
{'loss': 0.1392, 'grad_norm': 34.053436279296875, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.13907141983509064, 'loss_2': 9.715557098388672e-05, 'loss_3': -15.207740783691406, 'loss_4': 0.9838275909423828, 'epoch': 2.3}
{'loss': 0.0302, 'grad_norm': 9.49514102935791, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.02105695568025112, 'loss_2': 0.0091094970703125, 'loss_3': -15.364458084106445, 'loss_4': 0.6240600347518921, 'epoch': 2.31}
{'loss': 0.0329, 'grad_norm': 11.878883361816406, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.024408740922808647, 'loss_2': 0.0084991455078125, 'loss_3': -15.231498718261719, 'loss_4': 1.3689943552017212, 'epoch': 2.31}
{'loss': 0.1096, 'grad_norm': 20.51227569580078, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.10232096165418625, 'loss_2': 0.007259368896484375, 'loss_3': -15.200915336608887, 'loss_4': 1.6656932830810547, 'epoch': 2.32}
{'loss': 0.0483, 'grad_norm': 19.774259567260742, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.04215972125530243, 'loss_2': 0.006134033203125, 'loss_3': -15.180545806884766, 'loss_4': 1.502225637435913, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 12:30:26,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:26,739 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:21<1:22:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:34,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03197462856769562, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.739, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02700669690966606, 'eval_loss_2': 0.004967927932739258, 'eval_loss_3': -18.08441734313965, 'eval_loss_4': 1.3960769176483154, 'epoch': 2.33}
{'loss': 0.0736, 'grad_norm': 16.554548263549805, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.07214531302452087, 'loss_2': 0.0014123916625976562, 'loss_3': -15.466161727905273, 'loss_4': 1.6373951435089111, 'epoch': 2.33}
{'loss': 0.0464, 'grad_norm': 23.10727310180664, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.046368323266506195, 'loss_2': 1.7642974853515625e-05, 'loss_3': -15.506528854370117, 'loss_4': 1.560650110244751, 'epoch': 2.34}
{'loss': 0.0484, 'grad_norm': 13.406074523925781, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.04289757460355759, 'loss_2': 0.00545501708984375, 'loss_3': -15.436437606811523, 'loss_4': 1.1794099807739258, 'epoch': 2.34}
{'loss': 0.0432, 'grad_norm': 13.514500617980957, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.04035294055938721, 'loss_2': 0.002811431884765625, 'loss_3': -15.424930572509766, 'loss_4': 1.670857310295105, 'epoch': 2.35}
{'loss': 0.0391, 'grad_norm': 12.648041725158691, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.02713276632130146, 'loss_2': 0.011932373046875, 'loss_3': -15.507211685180664, 'loss_4': 1.8787996768951416, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 12:30:34,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:34,107 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:28<1:22:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:41,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03736567497253418, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.747, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0300370454788208, 'eval_loss_2': 0.007328629493713379, 'eval_loss_3': -18.141881942749023, 'eval_loss_4': 1.5266215801239014, 'epoch': 2.35}
{'loss': 0.0267, 'grad_norm': 7.053183078765869, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.020815066993236542, 'loss_2': 0.005889892578125, 'loss_3': -15.48704719543457, 'loss_4': 1.9578405618667603, 'epoch': 2.36}
{'loss': 0.0431, 'grad_norm': 8.693620681762695, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.03819107636809349, 'loss_2': 0.00487518310546875, 'loss_3': -15.66539192199707, 'loss_4': 1.1307291984558105, 'epoch': 2.37}
{'loss': 0.0591, 'grad_norm': 15.405399322509766, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.0552864745259285, 'loss_2': 0.003772735595703125, 'loss_3': -15.49626350402832, 'loss_4': 1.4771579504013062, 'epoch': 2.37}
{'loss': 0.0589, 'grad_norm': 13.078761100769043, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.05482680723071098, 'loss_2': 0.0040283203125, 'loss_3': -15.370659828186035, 'loss_4': 2.1149990558624268, 'epoch': 2.38}
{'loss': 0.0644, 'grad_norm': 23.88192367553711, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.06251803785562515, 'loss_2': 0.0018768310546875, 'loss_3': -15.539517402648926, 'loss_4': 2.1045408248901367, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 12:30:41,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:41,461 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:35<1:22:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:48,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035059377551078796, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.029309527948498726, 'eval_loss_2': 0.00574985146522522, 'eval_loss_3': -18.19316864013672, 'eval_loss_4': 1.6780517101287842, 'epoch': 2.38}
{'loss': 0.0853, 'grad_norm': 19.095298767089844, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.07954937219619751, 'loss_2': 0.00571441650390625, 'loss_3': -15.342874526977539, 'loss_4': 2.426879644393921, 'epoch': 2.39}
{'loss': 0.1363, 'grad_norm': 32.033966064453125, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.12785053253173828, 'loss_2': 0.0084228515625, 'loss_3': -15.35699462890625, 'loss_4': 2.157825469970703, 'epoch': 2.4}
{'loss': 0.0371, 'grad_norm': 8.210640907287598, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.030717432498931885, 'loss_2': 0.00641632080078125, 'loss_3': -15.603732109069824, 'loss_4': 1.376739501953125, 'epoch': 2.4}
{'loss': 0.0913, 'grad_norm': 23.137434005737305, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.07659918069839478, 'loss_2': 0.01470947265625, 'loss_3': -15.238256454467773, 'loss_4': 1.5139520168304443, 'epoch': 2.41}
{'loss': 0.0869, 'grad_norm': 18.549591064453125, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.07929525524377823, 'loss_2': 0.00765228271484375, 'loss_3': -15.470490455627441, 'loss_4': 1.7283647060394287, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 12:30:48,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:48,811 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:43<1:22:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:56,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028731346130371094, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.024954140186309814, 'eval_loss_2': 0.0037772059440612793, 'eval_loss_3': -18.232702255249023, 'eval_loss_4': 1.2424920797348022, 'epoch': 2.41}
{'loss': 0.0385, 'grad_norm': 10.86717700958252, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.035469237715005875, 'loss_2': 0.003063201904296875, 'loss_3': -15.598892211914062, 'loss_4': 1.2133742570877075, 'epoch': 2.42}
{'loss': 0.0602, 'grad_norm': 17.22932243347168, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.05599427968263626, 'loss_2': 0.00421142578125, 'loss_3': -15.48012638092041, 'loss_4': 1.4331634044647217, 'epoch': 2.42}
{'loss': 0.047, 'grad_norm': 13.710551261901855, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.04015336185693741, 'loss_2': 0.006839752197265625, 'loss_3': -15.62309455871582, 'loss_4': 0.8652417659759521, 'epoch': 2.43}
{'loss': 0.0483, 'grad_norm': 10.99009895324707, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.03558081015944481, 'loss_2': 0.0127410888671875, 'loss_3': -15.687641143798828, 'loss_4': 1.396780014038086, 'epoch': 2.44}
{'loss': 0.0519, 'grad_norm': 13.455217361450195, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.040804386138916016, 'loss_2': 0.01107025146484375, 'loss_3': -15.602581977844238, 'loss_4': 0.9950114488601685, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 12:30:56,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:56,173 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:50<1:21:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:03,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04521763697266579, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.293, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.035891059786081314, 'eval_loss_2': 0.009326577186584473, 'eval_loss_3': -18.190515518188477, 'eval_loss_4': 0.9156942963600159, 'epoch': 2.44}
{'loss': 0.0416, 'grad_norm': 15.263103485107422, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.0358663946390152, 'loss_2': 0.00571441650390625, 'loss_3': -15.367680549621582, 'loss_4': 1.2499661445617676, 'epoch': 2.45}
{'loss': 0.0342, 'grad_norm': 6.293672561645508, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.024606721475720406, 'loss_2': 0.00963592529296875, 'loss_3': -15.635749816894531, 'loss_4': 1.1755930185317993, 'epoch': 2.45}
{'loss': 0.0471, 'grad_norm': 11.600025177001953, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.044216323643922806, 'loss_2': 0.002895355224609375, 'loss_3': -15.565439224243164, 'loss_4': 0.32650816440582275, 'epoch': 2.46}
{'loss': 0.1162, 'grad_norm': 23.230531692504883, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.11399537324905396, 'loss_2': 0.00222015380859375, 'loss_3': -15.265201568603516, 'loss_4': 1.533210039138794, 'epoch': 2.47}
{'loss': 0.0692, 'grad_norm': 27.698158264160156, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.06303023546934128, 'loss_2': 0.006153106689453125, 'loss_3': -15.290444374084473, 'loss_4': 1.4636263847351074, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 12:31:03,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:03,523 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:57<1:21:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:10,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0766894668340683, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.07092307507991791, 'eval_loss_2': 0.005766391754150391, 'eval_loss_3': -18.06622314453125, 'eval_loss_4': 1.6488064527511597, 'epoch': 2.47}
{'loss': 0.0321, 'grad_norm': 10.515350341796875, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.029456954449415207, 'loss_2': 0.0026493072509765625, 'loss_3': -15.358874320983887, 'loss_4': 1.4076203107833862, 'epoch': 2.48}
{'loss': 0.0975, 'grad_norm': 26.583560943603516, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.0947318747639656, 'loss_2': 0.0027313232421875, 'loss_3': -15.239798545837402, 'loss_4': 2.326575756072998, 'epoch': 2.48}
{'loss': 0.044, 'grad_norm': 11.288399696350098, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.04083569720387459, 'loss_2': 0.0031452178955078125, 'loss_3': -15.35849666595459, 'loss_4': 1.7583284378051758, 'epoch': 2.49}
{'loss': 0.0623, 'grad_norm': 13.223457336425781, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.058016587048769, 'loss_2': 0.00431060791015625, 'loss_3': -15.396329879760742, 'loss_4': 1.6939775943756104, 'epoch': 2.49}
{'loss': 0.0844, 'grad_norm': 22.57223129272461, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.08378570526838303, 'loss_2': 0.000591278076171875, 'loss_3': -15.365720748901367, 'loss_4': 2.028209686279297, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 12:31:10,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:10,872 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:05<1:21:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:18,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034163497388362885, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.536, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.02989731729030609, 'eval_loss_2': 0.004266180098056793, 'eval_loss_3': -18.19500160217285, 'eval_loss_4': 2.0011587142944336, 'epoch': 2.5}
{'loss': 0.0289, 'grad_norm': 8.456157684326172, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.027955880388617516, 'loss_2': 0.0009031295776367188, 'loss_3': -15.628012657165527, 'loss_4': 2.5179572105407715, 'epoch': 2.51}
{'loss': 0.0347, 'grad_norm': 12.822905540466309, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.03220275789499283, 'loss_2': 0.0025348663330078125, 'loss_3': -15.51368522644043, 'loss_4': 1.6762781143188477, 'epoch': 2.51}
{'loss': 0.0472, 'grad_norm': 10.889201164245605, 'learning_rate': 2.75e-05, 'loss_1': 0.04001453518867493, 'loss_2': 0.00719451904296875, 'loss_3': -15.380725860595703, 'loss_4': 2.2244229316711426, 'epoch': 2.52}
{'loss': 0.1338, 'grad_norm': 40.45111083984375, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.12722843885421753, 'loss_2': 0.006572723388671875, 'loss_3': -15.277957916259766, 'loss_4': 2.9933042526245117, 'epoch': 2.52}
{'loss': 0.0672, 'grad_norm': 17.238452911376953, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.06669459491968155, 'loss_2': 0.0004944801330566406, 'loss_3': -15.34936809539795, 'loss_4': 1.4479527473449707, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 12:31:18,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:18,245 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:12<1:21:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:25,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026601159945130348, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02133362740278244, 'eval_loss_2': 0.005267530679702759, 'eval_loss_3': -18.27623748779297, 'eval_loss_4': 2.4302616119384766, 'epoch': 2.53}
{'loss': 0.0937, 'grad_norm': 30.689346313476562, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.09033794701099396, 'loss_2': 0.0033130645751953125, 'loss_3': -15.462193489074707, 'loss_4': 2.8182992935180664, 'epoch': 2.53}
{'loss': 0.1027, 'grad_norm': 34.54551315307617, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.10120534896850586, 'loss_2': 0.001537322998046875, 'loss_3': -15.558375358581543, 'loss_4': 3.96138858795166, 'epoch': 2.54}
{'loss': 0.1443, 'grad_norm': 33.32028579711914, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.13876290619373322, 'loss_2': 0.00556182861328125, 'loss_3': -15.565410614013672, 'loss_4': 3.6191904544830322, 'epoch': 2.55}
{'loss': 0.1291, 'grad_norm': 20.254457473754883, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.12116114795207977, 'loss_2': 0.00789642333984375, 'loss_3': -15.57845687866211, 'loss_4': 3.4720957279205322, 'epoch': 2.55}
{'loss': 0.0781, 'grad_norm': 19.379932403564453, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.07134012877941132, 'loss_2': 0.0067901611328125, 'loss_3': -15.531184196472168, 'loss_4': 3.4464316368103027, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 12:31:25,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:25,613 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:20<1:21:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:32,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028846222907304764, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.023285169154405594, 'eval_loss_2': 0.00556105375289917, 'eval_loss_3': -18.317960739135742, 'eval_loss_4': 2.517037868499756, 'epoch': 2.56}
{'loss': 0.1318, 'grad_norm': 30.153362274169922, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.13136930763721466, 'loss_2': 0.00039386749267578125, 'loss_3': -15.589037895202637, 'loss_4': 3.457397937774658, 'epoch': 2.56}
{'loss': 0.1291, 'grad_norm': 25.777559280395508, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.11863570660352707, 'loss_2': 0.010498046875, 'loss_3': -15.427820205688477, 'loss_4': 3.5177533626556396, 'epoch': 2.57}
{'loss': 0.1004, 'grad_norm': 18.13698959350586, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.08355977386236191, 'loss_2': 0.016845703125, 'loss_3': -15.635406494140625, 'loss_4': 1.7638143301010132, 'epoch': 2.58}
{'loss': 0.1455, 'grad_norm': 29.151296615600586, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.13692927360534668, 'loss_2': 0.00860595703125, 'loss_3': -15.545876502990723, 'loss_4': 2.604109764099121, 'epoch': 2.58}
{'loss': 0.128, 'grad_norm': 34.30035400390625, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.12765251100063324, 'loss_2': 0.00034546852111816406, 'loss_3': -15.574323654174805, 'loss_4': 1.2551195621490479, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 12:31:32,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:32,973 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:27<1:21:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:40,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032591260969638824, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.696, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.023174801841378212, 'eval_loss_2': 0.009416460990905762, 'eval_loss_3': -18.214658737182617, 'eval_loss_4': 1.0510567426681519, 'epoch': 2.59}
{'loss': 0.0593, 'grad_norm': 14.518256187438965, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.04724757745862007, 'loss_2': 0.012054443359375, 'loss_3': -15.535576820373535, 'loss_4': 1.4387686252593994, 'epoch': 2.59}
{'loss': 0.0647, 'grad_norm': 19.856164932250977, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.06083071604371071, 'loss_2': 0.00390625, 'loss_3': -15.440725326538086, 'loss_4': 0.6847244501113892, 'epoch': 2.6}
{'loss': 0.0491, 'grad_norm': 11.914628982543945, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.042320821434259415, 'loss_2': 0.00681304931640625, 'loss_3': -15.519081115722656, 'loss_4': 1.2423133850097656, 'epoch': 2.6}
{'loss': 0.0658, 'grad_norm': 17.825592041015625, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.06531206518411636, 'loss_2': 0.0005025863647460938, 'loss_3': -15.514946937561035, 'loss_4': 0.7952116131782532, 'epoch': 2.61}
{'loss': 0.1582, 'grad_norm': 26.807174682617188, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.1553569883108139, 'loss_2': 0.002864837646484375, 'loss_3': -15.488290786743164, 'loss_4': 1.8181054592132568, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 12:31:40,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:40,338 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:34<1:21:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:47,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1060713529586792, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.10216774791479111, 'eval_loss_2': 0.003903597593307495, 'eval_loss_3': -17.91455078125, 'eval_loss_4': 1.6518081426620483, 'epoch': 2.62}
{'loss': 0.0586, 'grad_norm': 15.658032417297363, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.0581887923181057, 'loss_2': 0.0004258155822753906, 'loss_3': -15.569769859313965, 'loss_4': 1.2113240957260132, 'epoch': 2.62}
{'loss': 0.1583, 'grad_norm': 40.156917572021484, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.15169744193553925, 'loss_2': 0.00655364990234375, 'loss_3': -15.396627426147461, 'loss_4': 1.750346064567566, 'epoch': 2.63}
{'loss': 0.2351, 'grad_norm': 55.15053939819336, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.23033171892166138, 'loss_2': 0.004730224609375, 'loss_3': -15.307022094726562, 'loss_4': 2.492030620574951, 'epoch': 2.63}
{'loss': 0.0822, 'grad_norm': 19.76396942138672, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.07289320230484009, 'loss_2': 0.0093536376953125, 'loss_3': -15.559915542602539, 'loss_4': 2.2377517223358154, 'epoch': 2.64}
{'loss': 0.0544, 'grad_norm': 15.534167289733887, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.05424514785408974, 'loss_2': 0.0001404285430908203, 'loss_3': -15.341878890991211, 'loss_4': 1.39837646484375, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 12:31:47,699 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:47,699 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:42<1:21:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:55,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.098001629114151, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.09337599575519562, 'eval_loss_2': 0.00462564080953598, 'eval_loss_3': -17.91567039489746, 'eval_loss_4': 1.6980159282684326, 'epoch': 2.65}
{'loss': 0.0605, 'grad_norm': 10.784119606018066, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.04900680109858513, 'loss_2': 0.011444091796875, 'loss_3': -15.554269790649414, 'loss_4': 1.5417966842651367, 'epoch': 2.65}
{'loss': 0.0518, 'grad_norm': 11.72327995300293, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.04708816111087799, 'loss_2': 0.004669189453125, 'loss_3': -15.53576374053955, 'loss_4': 1.4697206020355225, 'epoch': 2.66}
{'loss': 0.0586, 'grad_norm': 23.024398803710938, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.057294052094221115, 'loss_2': 0.00133514404296875, 'loss_3': -15.457355499267578, 'loss_4': 1.749902367591858, 'epoch': 2.66}
{'loss': 0.0665, 'grad_norm': 13.680546760559082, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.05656319856643677, 'loss_2': 0.009979248046875, 'loss_3': -15.529703140258789, 'loss_4': 1.5544949769973755, 'epoch': 2.67}
{'loss': 0.1141, 'grad_norm': 29.742050170898438, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.10403838753700256, 'loss_2': 0.0100860595703125, 'loss_3': -15.55993366241455, 'loss_4': 1.7974717617034912, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 12:31:55,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:55,054 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:49<1:21:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:02,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028308238834142685, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.839, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02470889501273632, 'eval_loss_2': 0.0035993456840515137, 'eval_loss_3': -18.134597778320312, 'eval_loss_4': 1.6685285568237305, 'epoch': 2.67}
{'loss': 0.0462, 'grad_norm': 9.904696464538574, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.03368467837572098, 'loss_2': 0.0125579833984375, 'loss_3': -15.385122299194336, 'loss_4': 1.7273433208465576, 'epoch': 2.68}
{'loss': 0.0491, 'grad_norm': 14.60183048248291, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.047776058316230774, 'loss_2': 0.0012788772583007812, 'loss_3': -15.677000999450684, 'loss_4': 1.971611499786377, 'epoch': 2.69}
{'loss': 0.0316, 'grad_norm': 7.680757522583008, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.024868231266736984, 'loss_2': 0.0067596435546875, 'loss_3': -15.579291343688965, 'loss_4': 1.7442573308944702, 'epoch': 2.69}
{'loss': 0.1401, 'grad_norm': 26.001140594482422, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.12387951463460922, 'loss_2': 0.01617431640625, 'loss_3': -15.719813346862793, 'loss_4': 2.683664321899414, 'epoch': 2.7}
{'loss': 0.0765, 'grad_norm': 23.599933624267578, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.07044056057929993, 'loss_2': 0.0060577392578125, 'loss_3': -15.560964584350586, 'loss_4': 2.40484619140625, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 12:32:02,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:02,416 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:56<1:21:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:09,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02791009098291397, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020167941227555275, 'eval_loss_2': 0.007742151618003845, 'eval_loss_3': -18.209014892578125, 'eval_loss_4': 2.4859514236450195, 'epoch': 2.7}
{'loss': 0.0589, 'grad_norm': 11.812138557434082, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.04845082387328148, 'loss_2': 0.0104827880859375, 'loss_3': -15.566123962402344, 'loss_4': 2.6339776515960693, 'epoch': 2.71}
{'loss': 0.0427, 'grad_norm': 12.12230396270752, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.034784819930791855, 'loss_2': 0.0078887939453125, 'loss_3': -15.630302429199219, 'loss_4': 3.131707191467285, 'epoch': 2.72}
{'loss': 0.0753, 'grad_norm': 17.564559936523438, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.07271477580070496, 'loss_2': 0.00262451171875, 'loss_3': -15.514333724975586, 'loss_4': 2.870480537414551, 'epoch': 2.72}
{'loss': 0.0648, 'grad_norm': 25.568500518798828, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.06359070539474487, 'loss_2': 0.0012531280517578125, 'loss_3': -15.698974609375, 'loss_4': 3.0223000049591064, 'epoch': 2.73}
{'loss': 0.0593, 'grad_norm': 20.545156478881836, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.05759090185165405, 'loss_2': 0.0017147064208984375, 'loss_3': -15.893543243408203, 'loss_4': 2.8582890033721924, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 12:32:09,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:09,771 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [12:00<1:21:15,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:32:13,575 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470
[INFO|configuration_utils.py:420] 2025-01-21 12:32:13,576 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470/config.json                                                                             
{'eval_loss': 0.023429762572050095, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.315, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01974468119442463, 'eval_loss_2': 0.003685079514980316, 'eval_loss_3': -18.203113555908203, 'eval_loss_4': 2.6397833824157715, 'epoch': 2.73}
[INFO|modeling_utils.py:2988] 2025-01-21 12:32:14,068 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:32:14,070 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:32:14,070 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:32:15,001 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-310] due to args.save_total_limit
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:05<1:29:34,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:32:18,631 >>
{'loss': 0.2937, 'grad_norm': 35.80388641357422, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.2900811433792114, 'loss_2': 0.003631591796875, 'loss_3': -15.412860870361328, 'loss_4': 3.8312110900878906, 'epoch': 2.74}
{'loss': 0.0601, 'grad_norm': 23.898313522338867, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.05930602550506592, 'loss_2': 0.0008187294006347656, 'loss_3': -15.59870433807373, 'loss_4': 3.1478052139282227, 'epoch': 2.74}
{'loss': 0.0448, 'grad_norm': 10.834122657775879, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.04362783581018448, 'loss_2': 0.0011806488037109375, 'loss_3': -15.84075927734375, 'loss_4': 3.1601150035858154, 'epoch': 2.75}
{'loss': 0.0707, 'grad_norm': 16.595321655273438, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.06735967099666595, 'loss_2': 0.0032939910888671875, 'loss_3': -15.656198501586914, 'loss_4': 2.331172466278076, 'epoch': 2.76}
{'loss': 0.0623, 'grad_norm': 15.586109161376953, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.060240574181079865, 'loss_2': 0.00208282470703125, 'loss_3': -15.791208267211914, 'loss_4': 2.2779459953308105, 'epoch': 2.76}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:32:18,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:18,631 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:09<1:29:34,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:32:22,429 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475
[INFO|configuration_utils.py:420] 2025-01-21 12:32:22,430 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475/config.json                                                                             
{'eval_loss': 0.022467633709311485, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01823844574391842, 'eval_loss_2': 0.004229187965393066, 'eval_loss_3': -18.133893966674805, 'eval_loss_4': 2.3290600776672363, 'epoch': 2.76}
[INFO|modeling_utils.py:2988] 2025-01-21 12:32:22,928 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:32:22,930 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:32:22,930 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:32:23,851 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-470] due to args.save_total_limit
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:14<1:30:51,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:32:27,483 >>
{'loss': 0.1131, 'grad_norm': 38.0272216796875, 'learning_rate': 2.725e-05, 'loss_1': 0.10714898258447647, 'loss_2': 0.005962371826171875, 'loss_3': -15.762712478637695, 'loss_4': 2.415980100631714, 'epoch': 2.77}
{'loss': 0.0666, 'grad_norm': 19.39452362060547, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.06316407769918442, 'loss_2': 0.003398895263671875, 'loss_3': -15.727906227111816, 'loss_4': 2.914020299911499, 'epoch': 2.77}
{'loss': 0.0631, 'grad_norm': 14.296894073486328, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.05768251419067383, 'loss_2': 0.0053863525390625, 'loss_3': -15.767706871032715, 'loss_4': 2.8130481243133545, 'epoch': 2.78}
{'loss': 0.0493, 'grad_norm': 13.547456741333008, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.0459548719227314, 'loss_2': 0.0033054351806640625, 'loss_3': -15.537214279174805, 'loss_4': 2.466407537460327, 'epoch': 2.78}
{'loss': 0.0753, 'grad_norm': 33.51227569580078, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.07447587698698044, 'loss_2': 0.0008740425109863281, 'loss_3': -15.784907341003418, 'loss_4': 2.1106889247894287, 'epoch': 2.79}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:32:27,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:27,483 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:21<1:22:30,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:32:34,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033422499895095825, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.377, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.028245892375707626, 'eval_loss_2': 0.0051766037940979, 'eval_loss_3': -18.12095069885254, 'eval_loss_4': 2.0587987899780273, 'epoch': 2.79}
{'loss': 0.0841, 'grad_norm': 21.163429260253906, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.07789315283298492, 'loss_2': 0.00620269775390625, 'loss_3': -15.656058311462402, 'loss_4': 1.9207451343536377, 'epoch': 2.8}
{'loss': 0.034, 'grad_norm': 9.681245803833008, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.03377076983451843, 'loss_2': 0.00022339820861816406, 'loss_3': -15.604066848754883, 'loss_4': 2.145987033843994, 'epoch': 2.8}
{'loss': 0.0555, 'grad_norm': 14.151830673217773, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.04938104376196861, 'loss_2': 0.006134033203125, 'loss_3': -15.749002456665039, 'loss_4': 2.4266343116760254, 'epoch': 2.81}
{'loss': 0.1675, 'grad_norm': 26.129901885986328, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.1646346151828766, 'loss_2': 0.0028285980224609375, 'loss_3': -15.502941131591797, 'loss_4': 2.9523072242736816, 'epoch': 2.81}
{'loss': 0.0675, 'grad_norm': 18.193410873413086, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.06479604542255402, 'loss_2': 0.00270843505859375, 'loss_3': -15.80640983581543, 'loss_4': 2.2630510330200195, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 12:32:34,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:34,828 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:29<1:21:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:42,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03772825747728348, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.033875174820423126, 'eval_loss_2': 0.0038530826568603516, 'eval_loss_3': -18.07654571533203, 'eval_loss_4': 2.2583882808685303, 'epoch': 2.82}
{'loss': 0.0671, 'grad_norm': 21.861833572387695, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.06347152590751648, 'loss_2': 0.003635406494140625, 'loss_3': -15.822254180908203, 'loss_4': 2.6717019081115723, 'epoch': 2.83}
{'loss': 0.081, 'grad_norm': 22.939311981201172, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.06587888300418854, 'loss_2': 0.01509857177734375, 'loss_3': -15.61237621307373, 'loss_4': 2.4285573959350586, 'epoch': 2.83}
{'loss': 0.0236, 'grad_norm': 8.564961433410645, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.019482508301734924, 'loss_2': 0.0041351318359375, 'loss_3': -15.96552848815918, 'loss_4': 2.2441420555114746, 'epoch': 2.84}
{'loss': 0.0557, 'grad_norm': 14.507734298706055, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.05367514118552208, 'loss_2': 0.0019931793212890625, 'loss_3': -15.807561874389648, 'loss_4': 1.9041143655776978, 'epoch': 2.84}
{'loss': 0.0394, 'grad_norm': 12.589130401611328, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.03299408778548241, 'loss_2': 0.00638580322265625, 'loss_3': -15.93146800994873, 'loss_4': 2.379084825515747, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 12:32:42,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:42,178 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:36<1:20:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:49,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023459747433662415, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020237162709236145, 'eval_loss_2': 0.0032225847244262695, 'eval_loss_3': -18.146709442138672, 'eval_loss_4': 2.291950225830078, 'epoch': 2.85}
{'loss': 0.0921, 'grad_norm': 34.243839263916016, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.0870686024427414, 'loss_2': 0.00498199462890625, 'loss_3': -15.799232482910156, 'loss_4': 2.4965243339538574, 'epoch': 2.85}
{'loss': 0.0266, 'grad_norm': 8.243947982788086, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.025006407871842384, 'loss_2': 0.0016231536865234375, 'loss_3': -15.840224266052246, 'loss_4': 2.3717427253723145, 'epoch': 2.86}
{'loss': 0.0717, 'grad_norm': 33.24513626098633, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.06488890200853348, 'loss_2': 0.0068206787109375, 'loss_3': -15.785782814025879, 'loss_4': 2.5202646255493164, 'epoch': 2.87}
{'loss': 0.0618, 'grad_norm': 21.177776336669922, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.05576474964618683, 'loss_2': 0.006053924560546875, 'loss_3': -15.662412643432617, 'loss_4': 2.2558188438415527, 'epoch': 2.87}
{'loss': 0.0303, 'grad_norm': 7.885343551635742, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.02362869307398796, 'loss_2': 0.00666046142578125, 'loss_3': -15.716466903686523, 'loss_4': 2.862837791442871, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 12:32:49,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:49,528 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:40<1:20:48,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:32:53,334 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495
[INFO|configuration_utils.py:420] 2025-01-21 12:32:53,336 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495/config.json                                                                             
{'eval_loss': 0.018386464565992355, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015573647804558277, 'eval_loss_2': 0.002812817692756653, 'eval_loss_3': -18.203441619873047, 'eval_loss_4': 2.450211524963379, 'epoch': 2.88}
[INFO|modeling_utils.py:2988] 2025-01-21 12:32:53,830 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:32:53,831 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:32:53,831 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:32:54,748 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-475] due to args.save_total_limit
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:45<1:29:08,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:32:58,395 >>
{'loss': 0.0495, 'grad_norm': 14.866913795471191, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.0430159866809845, 'loss_2': 0.0065155029296875, 'loss_3': -15.774998664855957, 'loss_4': 2.4034931659698486, 'epoch': 2.88}
{'loss': 0.0543, 'grad_norm': 14.64854907989502, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.048755060881376266, 'loss_2': 0.005535125732421875, 'loss_3': -15.92399787902832, 'loss_4': 2.6261229515075684, 'epoch': 2.89}
{'loss': 0.0558, 'grad_norm': 17.26189422607422, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.049469251185655594, 'loss_2': 0.006320953369140625, 'loss_3': -15.93326473236084, 'loss_4': 2.9572627544403076, 'epoch': 2.9}
{'loss': 0.0263, 'grad_norm': 8.252439498901367, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.021401608362793922, 'loss_2': 0.0048675537109375, 'loss_3': -15.922769546508789, 'loss_4': 3.0277462005615234, 'epoch': 2.9}
{'loss': 0.0601, 'grad_norm': 26.402572631835938, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.05944020301103592, 'loss_2': 0.0006289482116699219, 'loss_3': -15.789300918579102, 'loss_4': 3.129206895828247, 'epoch': 2.91}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:32:58,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:58,395 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:52<1:21:54,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:33:05,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021479614078998566, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01709176041185856, 'eval_loss_2': 0.004387855529785156, 'eval_loss_3': -18.28436279296875, 'eval_loss_4': 2.53741717338562, 'epoch': 2.91}
{'loss': 0.0643, 'grad_norm': 26.21222686767578, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.054994162172079086, 'loss_2': 0.0092926025390625, 'loss_3': -15.750753402709961, 'loss_4': 3.0052685737609863, 'epoch': 2.91}
{'loss': 0.0461, 'grad_norm': 16.289777755737305, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.03847661241889, 'loss_2': 0.00757598876953125, 'loss_3': -15.824479103088379, 'loss_4': 3.358381748199463, 'epoch': 2.92}
{'loss': 0.0366, 'grad_norm': 11.846778869628906, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.03392256796360016, 'loss_2': 0.0027008056640625, 'loss_3': -15.827432632446289, 'loss_4': 2.0978293418884277, 'epoch': 2.92}
{'loss': 0.0433, 'grad_norm': 9.619282722473145, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.037659987807273865, 'loss_2': 0.005672454833984375, 'loss_3': -15.896444320678711, 'loss_4': 2.5285472869873047, 'epoch': 2.93}
{'loss': 0.0295, 'grad_norm': 6.722276210784912, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.02288220450282097, 'loss_2': 0.006591796875, 'loss_3': -15.70965576171875, 'loss_4': 2.1124110221862793, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 12:33:05,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:05,736 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [13:00<1:20:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:13,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02280004695057869, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.857, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01891035959124565, 'eval_loss_2': 0.0038896873593330383, 'eval_loss_3': -18.261823654174805, 'eval_loss_4': 1.8852251768112183, 'epoch': 2.94}
{'loss': 0.0371, 'grad_norm': 10.6842679977417, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.03277641534805298, 'loss_2': 0.00433349609375, 'loss_3': -15.64220142364502, 'loss_4': 1.9684852361679077, 'epoch': 2.94}
{'loss': 0.0348, 'grad_norm': 14.937545776367188, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.031208563596010208, 'loss_2': 0.003589630126953125, 'loss_3': -15.599069595336914, 'loss_4': 2.183901309967041, 'epoch': 2.95}
{'loss': 0.0471, 'grad_norm': 24.22649574279785, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.047103725373744965, 'loss_2': 4.0531158447265625e-06, 'loss_3': -15.951094627380371, 'loss_4': 1.994369626045227, 'epoch': 2.95}
{'loss': 0.0227, 'grad_norm': 10.077495574951172, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.020618850365281105, 'loss_2': 0.0020656585693359375, 'loss_3': -15.890506744384766, 'loss_4': 1.0545332431793213, 'epoch': 2.96}
{'loss': 0.0575, 'grad_norm': 22.542081832885742, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.054991211742162704, 'loss_2': 0.002532958984375, 'loss_3': -15.696298599243164, 'loss_4': 1.6115933656692505, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 12:33:13,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:13,073 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:07<1:19:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:33:20,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022225506603717804, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01780296303331852, 'eval_loss_2': 0.004422545433044434, 'eval_loss_3': -18.26608657836914, 'eval_loss_4': 1.0450091361999512, 'epoch': 2.97}
{'loss': 0.0422, 'grad_norm': 11.238080024719238, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.03629916161298752, 'loss_2': 0.00592803955078125, 'loss_3': -15.678421974182129, 'loss_4': 1.3886486291885376, 'epoch': 2.97}
{'loss': 0.0312, 'grad_norm': 9.99250602722168, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.02699345164000988, 'loss_2': 0.00423431396484375, 'loss_3': -15.70647144317627, 'loss_4': 1.2523075342178345, 'epoch': 2.98}
{'loss': 0.0591, 'grad_norm': 18.567298889160156, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.05422326177358627, 'loss_2': 0.004848480224609375, 'loss_3': -15.780471801757812, 'loss_4': 1.2600901126861572, 'epoch': 2.98}
{'loss': 0.0489, 'grad_norm': 12.344504356384277, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.04343043267726898, 'loss_2': 0.00548553466796875, 'loss_3': -15.669698715209961, 'loss_4': 0.71455979347229, 'epoch': 2.99}
{'loss': 0.0518, 'grad_norm': 15.13620376586914, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.049803055822849274, 'loss_2': 0.00196075439453125, 'loss_3': -15.687288284301758, 'loss_4': 0.5035366415977478, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 12:33:20,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:20,403 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:14<1:18:37,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:33:27,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02190512605011463, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.438, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01749180443584919, 'eval_loss_2': 0.004413321614265442, 'eval_loss_3': -18.193998336791992, 'eval_loss_4': 0.5202492475509644, 'epoch': 2.99}
{'loss': 0.0092, 'grad_norm': 6.662014961242676, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.005239452235400677, 'loss_2': 0.003936767578125, 'loss_3': -16.0137996673584, 'loss_4': 0.7062472105026245, 'epoch': 3.0}
{'loss': 0.032, 'grad_norm': 8.688618659973145, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.029628770425915718, 'loss_2': 0.0023555755615234375, 'loss_3': -15.559130668640137, 'loss_4': 0.4497595429420471, 'epoch': 3.01}
{'loss': 0.0317, 'grad_norm': 7.992827415466309, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.020662685856223106, 'loss_2': 0.01103973388671875, 'loss_3': -15.689594268798828, 'loss_4': 0.2854881286621094, 'epoch': 3.01}
{'loss': 0.0498, 'grad_norm': 13.397372245788574, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.0496247336268425, 'loss_2': 0.0002200603485107422, 'loss_3': -15.822864532470703, 'loss_4': 0.29604941606521606, 'epoch': 3.02}
{'loss': 0.0945, 'grad_norm': 18.907987594604492, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.08738616853952408, 'loss_2': 0.00714111328125, 'loss_3': -15.737581253051758, 'loss_4': -0.2643207609653473, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 12:33:27,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:27,463 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:21<1:19:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:33:34,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027594536542892456, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.803, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021034328266978264, 'eval_loss_2': 0.006560206413269043, 'eval_loss_3': -18.166006088256836, 'eval_loss_4': -0.055248845368623734, 'epoch': 3.02}
{'loss': 0.06, 'grad_norm': 16.461278915405273, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.05535042658448219, 'loss_2': 0.00467681884765625, 'loss_3': -15.57495403289795, 'loss_4': 0.32245659828186035, 'epoch': 3.03}
{'loss': 0.0474, 'grad_norm': 21.478843688964844, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.04665733128786087, 'loss_2': 0.00078582763671875, 'loss_3': -15.793724060058594, 'loss_4': -0.48571568727493286, 'epoch': 3.03}
{'loss': 0.0327, 'grad_norm': 10.405252456665039, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.03136572241783142, 'loss_2': 0.00136566162109375, 'loss_3': -15.733745574951172, 'loss_4': 0.3492104113101959, 'epoch': 3.04}
{'loss': 0.0237, 'grad_norm': 6.946709632873535, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.02134633995592594, 'loss_2': 0.00238037109375, 'loss_3': -15.868186950683594, 'loss_4': -0.024354353547096252, 'epoch': 3.05}
{'loss': 0.0383, 'grad_norm': 9.089506149291992, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.030144356191158295, 'loss_2': 0.0081787109375, 'loss_3': -15.805566787719727, 'loss_4': 0.2715795040130615, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 12:33:34,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:34,799 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:29<1:20:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:42,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03758787363767624, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.029303666204214096, 'eval_loss_2': 0.008284211158752441, 'eval_loss_3': -18.114946365356445, 'eval_loss_4': 0.06811261922121048, 'epoch': 3.05}
{'loss': 0.1134, 'grad_norm': 29.146800994873047, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.10854525864124298, 'loss_2': 0.0048675537109375, 'loss_3': -15.842256546020508, 'loss_4': 0.6723976135253906, 'epoch': 3.06}
{'loss': 0.0371, 'grad_norm': 10.11091423034668, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.028544168919324875, 'loss_2': 0.008544921875, 'loss_3': -15.70881462097168, 'loss_4': 0.055381231009960175, 'epoch': 3.06}
{'loss': 0.1187, 'grad_norm': 29.097415924072266, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.09977048635482788, 'loss_2': 0.018890380859375, 'loss_3': -15.878446578979492, 'loss_4': 0.49706050753593445, 'epoch': 3.07}
{'loss': 0.0344, 'grad_norm': 9.189546585083008, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.029534421861171722, 'loss_2': 0.00490570068359375, 'loss_3': -15.763976097106934, 'loss_4': 0.37631312012672424, 'epoch': 3.08}
{'loss': 0.0269, 'grad_norm': 9.434686660766602, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.026024602353572845, 'loss_2': 0.000873565673828125, 'loss_3': -15.624262809753418, 'loss_4': 0.34297889471054077, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 12:33:42,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:42,143 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:36<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:49,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.060140904039144516, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.055600911378860474, 'eval_loss_2': 0.004539988934993744, 'eval_loss_3': -18.008766174316406, 'eval_loss_4': 0.772452712059021, 'epoch': 3.08}
{'loss': 0.1102, 'grad_norm': 30.82484245300293, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.1094297245144844, 'loss_2': 0.0007829666137695312, 'loss_3': -15.92108154296875, 'loss_4': 0.845482587814331, 'epoch': 3.09}
{'loss': 0.0258, 'grad_norm': 6.509884357452393, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.01748117431998253, 'loss_2': 0.00833892822265625, 'loss_3': -15.739846229553223, 'loss_4': 0.6468430757522583, 'epoch': 3.09}
{'loss': 0.0518, 'grad_norm': 13.233651161193848, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.043118856847286224, 'loss_2': 0.00872802734375, 'loss_3': -15.861650466918945, 'loss_4': 0.527484118938446, 'epoch': 3.1}
{'loss': 0.0386, 'grad_norm': 12.89294719696045, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.033177707344293594, 'loss_2': 0.005401611328125, 'loss_3': -15.651227951049805, 'loss_4': 0.7575008273124695, 'epoch': 3.1}
{'loss': 0.045, 'grad_norm': 13.844069480895996, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.038898926228284836, 'loss_2': 0.00611114501953125, 'loss_3': -15.59316349029541, 'loss_4': 0.8894185423851013, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 12:33:49,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:49,484 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:43<1:20:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:56,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06428248435258865, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.944, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.05898977443575859, 'eval_loss_2': 0.005292713642120361, 'eval_loss_3': -18.021800994873047, 'eval_loss_4': 1.2531689405441284, 'epoch': 3.11}
{'loss': 0.0661, 'grad_norm': 27.4423770904541, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.06502118706703186, 'loss_2': 0.00103759765625, 'loss_3': -15.646240234375, 'loss_4': 1.4295616149902344, 'epoch': 3.12}
{'loss': 0.0332, 'grad_norm': 22.651084899902344, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.030377458781003952, 'loss_2': 0.0028018951416015625, 'loss_3': -15.946551322937012, 'loss_4': 0.5230242609977722, 'epoch': 3.12}
{'loss': 0.0376, 'grad_norm': 10.927846908569336, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.03304522857069969, 'loss_2': 0.00458526611328125, 'loss_3': -15.688827514648438, 'loss_4': 1.061800479888916, 'epoch': 3.13}
{'loss': 0.0298, 'grad_norm': 9.09797477722168, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.02753610536456108, 'loss_2': 0.0022602081298828125, 'loss_3': -15.754692077636719, 'loss_4': 0.8546932935714722, 'epoch': 3.13}
{'loss': 0.0259, 'grad_norm': 7.548411846160889, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.022627510130405426, 'loss_2': 0.003246307373046875, 'loss_3': -15.795047760009766, 'loss_4': 0.6043050289154053, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 12:33:56,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:56,846 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:51<1:19:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:04,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0227733813226223, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.018133368343114853, 'eval_loss_2': 0.004640012979507446, 'eval_loss_3': -18.229427337646484, 'eval_loss_4': 1.2703295946121216, 'epoch': 3.14}
{'loss': 0.034, 'grad_norm': 10.419257164001465, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.025199322029948235, 'loss_2': 0.00882720947265625, 'loss_3': -15.730707168579102, 'loss_4': 1.0453838109970093, 'epoch': 3.15}
{'loss': 0.0325, 'grad_norm': 12.422225952148438, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.03224090859293938, 'loss_2': 0.000286102294921875, 'loss_3': -15.988525390625, 'loss_4': 1.7254388332366943, 'epoch': 3.15}
{'loss': 0.0248, 'grad_norm': 7.502842903137207, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.021006256341934204, 'loss_2': 0.0038051605224609375, 'loss_3': -15.903860092163086, 'loss_4': 1.670079231262207, 'epoch': 3.16}
{'loss': 0.0333, 'grad_norm': 10.587150573730469, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.02905392087996006, 'loss_2': 0.004215240478515625, 'loss_3': -15.8124418258667, 'loss_4': 1.8598425388336182, 'epoch': 3.16}
{'loss': 0.0411, 'grad_norm': 8.210433959960938, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.02637450210750103, 'loss_2': 0.0147705078125, 'loss_3': -16.015663146972656, 'loss_4': 1.8041692972183228, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 12:34:04,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:04,200 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:58<1:19:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:11,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030865192413330078, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.017738820984959602, 'eval_loss_2': 0.013126373291015625, 'eval_loss_3': -18.292613983154297, 'eval_loss_4': 1.874224305152893, 'epoch': 3.17}
{'loss': 0.0826, 'grad_norm': 25.72290802001953, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.07233431935310364, 'loss_2': 0.01024627685546875, 'loss_3': -16.060775756835938, 'loss_4': 1.881650447845459, 'epoch': 3.17}
{'loss': 0.0538, 'grad_norm': 11.904875755310059, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.03724195063114166, 'loss_2': 0.01654052734375, 'loss_3': -15.624646186828613, 'loss_4': 2.0989744663238525, 'epoch': 3.18}
{'loss': 0.039, 'grad_norm': 6.618220329284668, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.026936274021863937, 'loss_2': 0.0120391845703125, 'loss_3': -15.767370223999023, 'loss_4': 2.285416603088379, 'epoch': 3.19}
{'loss': 0.0402, 'grad_norm': 13.584156036376953, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.03343350440263748, 'loss_2': 0.00681304931640625, 'loss_3': -15.928485870361328, 'loss_4': 1.4758270978927612, 'epoch': 3.19}
{'loss': 0.0465, 'grad_norm': 14.2686185836792, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.042910996824502945, 'loss_2': 0.003566741943359375, 'loss_3': -16.03973388671875, 'loss_4': 2.355226516723633, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 12:34:11,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:11,556 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:05<1:19:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:18,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021886836737394333, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.37, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01764632575213909, 'eval_loss_2': 0.004240512847900391, 'eval_loss_3': -18.358795166015625, 'eval_loss_4': 1.731961727142334, 'epoch': 3.2}
{'loss': 0.0437, 'grad_norm': 14.874648094177246, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.04171905294060707, 'loss_2': 0.0019388198852539062, 'loss_3': -15.786331176757812, 'loss_4': 2.4486513137817383, 'epoch': 3.2}
{'loss': 0.0492, 'grad_norm': 14.660359382629395, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.04772697016596794, 'loss_2': 0.0014753341674804688, 'loss_3': -15.82763385772705, 'loss_4': 2.4386579990386963, 'epoch': 3.21}
{'loss': 0.0252, 'grad_norm': 5.952298164367676, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.014823692850768566, 'loss_2': 0.0103302001953125, 'loss_3': -15.917551040649414, 'loss_4': 1.656630516052246, 'epoch': 3.22}
{'loss': 0.0499, 'grad_norm': 22.049840927124023, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.049208078533411026, 'loss_2': 0.0007381439208984375, 'loss_3': -15.983321189880371, 'loss_4': 2.1559276580810547, 'epoch': 3.22}
{'loss': 0.0394, 'grad_norm': 17.32413101196289, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.037281472235918045, 'loss_2': 0.002079010009765625, 'loss_3': -15.823177337646484, 'loss_4': 1.6143648624420166, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 12:34:18,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:18,910 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:13<1:19:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:26,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020864594727754593, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01747322268784046, 'eval_loss_2': 0.003391370177268982, 'eval_loss_3': -18.315576553344727, 'eval_loss_4': 1.7190622091293335, 'epoch': 3.23}
{'loss': 0.0407, 'grad_norm': 11.66971492767334, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.04027764871716499, 'loss_2': 0.0003886222839355469, 'loss_3': -15.594772338867188, 'loss_4': 2.170942783355713, 'epoch': 3.23}
{'loss': 0.0379, 'grad_norm': 12.196314811706543, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.037262216210365295, 'loss_2': 0.0006537437438964844, 'loss_3': -16.059301376342773, 'loss_4': 1.959139108657837, 'epoch': 3.24}
{'loss': 0.0317, 'grad_norm': 10.607671737670898, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.029751626774668694, 'loss_2': 0.001987457275390625, 'loss_3': -16.01769256591797, 'loss_4': 2.059324264526367, 'epoch': 3.24}
{'loss': 0.0481, 'grad_norm': 14.082446098327637, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.04454002156853676, 'loss_2': 0.0035247802734375, 'loss_3': -15.724366188049316, 'loss_4': 1.5756529569625854, 'epoch': 3.25}
{'loss': 0.0288, 'grad_norm': 6.852209091186523, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.01898065023124218, 'loss_2': 0.0098419189453125, 'loss_3': -15.860901832580566, 'loss_4': 2.4516103267669678, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 12:34:26,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:26,272 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:20<1:19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:33,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028789624571800232, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.362, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017830058932304382, 'eval_loss_2': 0.01095956563949585, 'eval_loss_3': -18.303056716918945, 'eval_loss_4': 1.7018773555755615, 'epoch': 3.26}
{'loss': 0.0605, 'grad_norm': 12.386126518249512, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.042672522366046906, 'loss_2': 0.017852783203125, 'loss_3': -15.937092781066895, 'loss_4': 1.7104425430297852, 'epoch': 3.26}
{'loss': 0.0412, 'grad_norm': 10.922317504882812, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.03405030071735382, 'loss_2': 0.0071258544921875, 'loss_3': -15.847732543945312, 'loss_4': 1.3895081281661987, 'epoch': 3.27}
{'loss': 0.0546, 'grad_norm': 17.96949005126953, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.04990985244512558, 'loss_2': 0.00464630126953125, 'loss_3': -15.88602352142334, 'loss_4': 1.871748447418213, 'epoch': 3.27}
{'loss': 0.0483, 'grad_norm': 13.926279067993164, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.03679339215159416, 'loss_2': 0.0114898681640625, 'loss_3': -15.825563430786133, 'loss_4': 1.4688663482666016, 'epoch': 3.28}
{'loss': 0.0586, 'grad_norm': 12.990806579589844, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.0536247156560421, 'loss_2': 0.00498199462890625, 'loss_3': -15.681848526000977, 'loss_4': 1.7805835008621216, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 12:34:33,622 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:33,622 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:28<1:19:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:40,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022601163014769554, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.758, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.019631952047348022, 'eval_loss_2': 0.002969212830066681, 'eval_loss_3': -18.266939163208008, 'eval_loss_4': 1.7110679149627686, 'epoch': 3.28}
{'loss': 0.0445, 'grad_norm': 19.720108032226562, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.04437190294265747, 'loss_2': 0.00013148784637451172, 'loss_3': -15.542001724243164, 'loss_4': 1.5896087884902954, 'epoch': 3.29}
{'loss': 0.1198, 'grad_norm': 27.339994430541992, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.11872414499521255, 'loss_2': 0.0010585784912109375, 'loss_3': -15.648653030395508, 'loss_4': 1.561739444732666, 'epoch': 3.3}
{'loss': 0.0255, 'grad_norm': 7.248290061950684, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.020307110622525215, 'loss_2': 0.00518035888671875, 'loss_3': -15.68216323852539, 'loss_4': 1.670183777809143, 'epoch': 3.3}
{'loss': 0.0332, 'grad_norm': 10.523956298828125, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.026743508875370026, 'loss_2': 0.0064239501953125, 'loss_3': -15.944541931152344, 'loss_4': 1.916742205619812, 'epoch': 3.31}
{'loss': 0.0372, 'grad_norm': 10.403865814208984, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.031181929633021355, 'loss_2': 0.005985260009765625, 'loss_3': -15.521966934204102, 'loss_4': 1.6654239892959595, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 12:34:40,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:40,978 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:35<1:19:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:48,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024479251354932785, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01923389360308647, 'eval_loss_2': 0.0052453577518463135, 'eval_loss_3': -18.236547470092773, 'eval_loss_4': 1.6927753686904907, 'epoch': 3.31}
{'loss': 0.0355, 'grad_norm': 11.233123779296875, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.03371534124016762, 'loss_2': 0.0017633438110351562, 'loss_3': -15.616612434387207, 'loss_4': 1.7081842422485352, 'epoch': 3.32}
{'loss': 0.0378, 'grad_norm': 11.781373023986816, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.03362967073917389, 'loss_2': 0.004138946533203125, 'loss_3': -15.914632797241211, 'loss_4': 1.6217771768569946, 'epoch': 3.33}
{'loss': 0.0317, 'grad_norm': 9.619035720825195, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.029785946011543274, 'loss_2': 0.001926422119140625, 'loss_3': -15.73869800567627, 'loss_4': 1.6826810836791992, 'epoch': 3.33}
{'loss': 0.0799, 'grad_norm': 25.202577590942383, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.07114959508180618, 'loss_2': 0.0087432861328125, 'loss_3': -15.867164611816406, 'loss_4': 1.4001154899597168, 'epoch': 3.34}
{'loss': 0.0909, 'grad_norm': 26.939401626586914, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.08932312577962875, 'loss_2': 0.0016193389892578125, 'loss_3': -15.902752876281738, 'loss_4': 1.6385328769683838, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 12:34:48,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:48,329 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:42<1:19:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:55,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023544562980532646, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02018051967024803, 'eval_loss_2': 0.0033640414476394653, 'eval_loss_3': -18.261592864990234, 'eval_loss_4': 1.500395655632019, 'epoch': 3.34}
{'loss': 0.0995, 'grad_norm': 19.05746078491211, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.08851654082536697, 'loss_2': 0.0110321044921875, 'loss_3': -15.843091011047363, 'loss_4': 1.0746878385543823, 'epoch': 3.35}
{'loss': 0.0389, 'grad_norm': 9.918808937072754, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.035735007375478745, 'loss_2': 0.0031585693359375, 'loss_3': -15.666955947875977, 'loss_4': 1.423417091369629, 'epoch': 3.35}
{'loss': 0.0422, 'grad_norm': 10.340964317321777, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.03909853473305702, 'loss_2': 0.0030975341796875, 'loss_3': -15.6353759765625, 'loss_4': 1.09767746925354, 'epoch': 3.36}
{'loss': 0.0667, 'grad_norm': 17.148193359375, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.06299857050180435, 'loss_2': 0.0037212371826171875, 'loss_3': -15.734257698059082, 'loss_4': 1.4630556106567383, 'epoch': 3.37}
{'loss': 0.0568, 'grad_norm': 13.032045364379883, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.05417207255959511, 'loss_2': 0.0026340484619140625, 'loss_3': -15.83522891998291, 'loss_4': 1.7816537618637085, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 12:34:55,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:55,675 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:50<1:19:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:03,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02365255355834961, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018357576802372932, 'eval_loss_2': 0.005294978618621826, 'eval_loss_3': -18.306251525878906, 'eval_loss_4': 1.3359413146972656, 'epoch': 3.37}
{'loss': 0.079, 'grad_norm': 25.2077579498291, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.0776015892624855, 'loss_2': 0.0014190673828125, 'loss_3': -15.81270694732666, 'loss_4': 1.294435977935791, 'epoch': 3.38}
{'loss': 0.133, 'grad_norm': 34.7981071472168, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.12405138462781906, 'loss_2': 0.0089569091796875, 'loss_3': -15.724750518798828, 'loss_4': 1.4727736711502075, 'epoch': 3.38}
{'loss': 0.1132, 'grad_norm': 35.217323303222656, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.09643012285232544, 'loss_2': 0.016815185546875, 'loss_3': -15.512657165527344, 'loss_4': 1.4996057748794556, 'epoch': 3.39}
{'loss': 0.0443, 'grad_norm': 8.022582054138184, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.03164612129330635, 'loss_2': 0.0126800537109375, 'loss_3': -15.832462310791016, 'loss_4': 1.4168713092803955, 'epoch': 3.4}
{'loss': 0.0324, 'grad_norm': 8.778806686401367, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.025362826883792877, 'loss_2': 0.007053375244140625, 'loss_3': -15.896537780761719, 'loss_4': 1.5681592226028442, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 12:35:03,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:03,018 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:57<1:19:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:10,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0231802798807621, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018126266077160835, 'eval_loss_2': 0.005054011940956116, 'eval_loss_3': -18.29395866394043, 'eval_loss_4': 1.5002555847167969, 'epoch': 3.4}
{'loss': 0.0548, 'grad_norm': 10.881010055541992, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.03929714486002922, 'loss_2': 0.0154876708984375, 'loss_3': -15.837663650512695, 'loss_4': 0.9213014245033264, 'epoch': 3.41}
{'loss': 0.0586, 'grad_norm': 17.096925735473633, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.05586521327495575, 'loss_2': 0.00275421142578125, 'loss_3': -15.812654495239258, 'loss_4': 1.1551353931427002, 'epoch': 3.41}
{'loss': 0.0806, 'grad_norm': 22.202966690063477, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.07829689979553223, 'loss_2': 0.0022563934326171875, 'loss_3': -15.805747985839844, 'loss_4': 1.2013949155807495, 'epoch': 3.42}
{'loss': 0.1308, 'grad_norm': 23.959331512451172, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.1279314160346985, 'loss_2': 0.00286102294921875, 'loss_3': -15.749822616577148, 'loss_4': 1.9687496423721313, 'epoch': 3.42}
{'loss': 0.0269, 'grad_norm': 6.561877250671387, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.02068967930972576, 'loss_2': 0.006259918212890625, 'loss_3': -15.785125732421875, 'loss_4': 1.656842589378357, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 12:35:10,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:10,360 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:04<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:17,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030349191278219223, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.358, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.019950924441218376, 'eval_loss_2': 0.010398268699645996, 'eval_loss_3': -18.273469924926758, 'eval_loss_4': 1.80263352394104, 'epoch': 3.43}
{'loss': 0.1028, 'grad_norm': 29.313703536987305, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.09888564050197601, 'loss_2': 0.0038814544677734375, 'loss_3': -16.070615768432617, 'loss_4': 1.9634191989898682, 'epoch': 3.44}
{'loss': 0.0452, 'grad_norm': 9.395079612731934, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.03641027212142944, 'loss_2': 0.0087432861328125, 'loss_3': -15.829825401306152, 'loss_4': 1.5452817678451538, 'epoch': 3.44}
{'loss': 0.039, 'grad_norm': 10.036785125732422, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.028296705335378647, 'loss_2': 0.01068115234375, 'loss_3': -15.912145614624023, 'loss_4': 1.6654438972473145, 'epoch': 3.45}
{'loss': 0.0334, 'grad_norm': 11.013842582702637, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.029103685170412064, 'loss_2': 0.00431060791015625, 'loss_3': -15.588403701782227, 'loss_4': 1.6175310611724854, 'epoch': 3.45}
{'loss': 0.0303, 'grad_norm': 7.677297592163086, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.019168494269251823, 'loss_2': 0.01108551025390625, 'loss_3': -15.772089004516602, 'loss_4': 1.9279453754425049, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 12:35:17,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:17,709 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:12<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:25,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03072318807244301, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.886, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.027089199051260948, 'eval_loss_2': 0.0036339908838272095, 'eval_loss_3': -18.24077796936035, 'eval_loss_4': 1.8759771585464478, 'epoch': 3.46}
{'loss': 0.0657, 'grad_norm': 17.5382022857666, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.06054826080799103, 'loss_2': 0.005138397216796875, 'loss_3': -15.868766784667969, 'loss_4': 1.2759685516357422, 'epoch': 3.47}
{'loss': 0.0374, 'grad_norm': 8.952956199645996, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.033690787851810455, 'loss_2': 0.003665924072265625, 'loss_3': -15.780116081237793, 'loss_4': 1.8993498086929321, 'epoch': 3.47}
{'loss': 0.0577, 'grad_norm': 14.014091491699219, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.05251549929380417, 'loss_2': 0.0052032470703125, 'loss_3': -15.878296852111816, 'loss_4': 2.2135281562805176, 'epoch': 3.48}
{'loss': 0.0515, 'grad_norm': 12.522154808044434, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.04050597921013832, 'loss_2': 0.01099395751953125, 'loss_3': -15.879554748535156, 'loss_4': 1.902748703956604, 'epoch': 3.48}
{'loss': 0.0294, 'grad_norm': 8.677123069763184, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.02010766975581646, 'loss_2': 0.00931549072265625, 'loss_3': -15.814311981201172, 'loss_4': 1.6517852544784546, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 12:35:25,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:25,065 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:19<1:18:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:32,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03506608307361603, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.028957268223166466, 'eval_loss_2': 0.00610882043838501, 'eval_loss_3': -18.23772430419922, 'eval_loss_4': 1.8395254611968994, 'epoch': 3.49}
{'loss': 0.0324, 'grad_norm': 8.028992652893066, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.021781673654913902, 'loss_2': 0.010589599609375, 'loss_3': -15.826663970947266, 'loss_4': 1.3753259181976318, 'epoch': 3.49}
{'loss': 0.0369, 'grad_norm': 11.163450241088867, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.03634016960859299, 'loss_2': 0.0005421638488769531, 'loss_3': -15.95238971710205, 'loss_4': 1.2571934461593628, 'epoch': 3.5}
{'loss': 0.0384, 'grad_norm': 9.268919944763184, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.03376265987753868, 'loss_2': 0.0046844482421875, 'loss_3': -15.759042739868164, 'loss_4': 1.4257315397262573, 'epoch': 3.51}
{'loss': 0.0257, 'grad_norm': 9.680710792541504, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.02533372864127159, 'loss_2': 0.0003306865692138672, 'loss_3': -15.639213562011719, 'loss_4': 1.7561440467834473, 'epoch': 3.51}
{'loss': 0.0168, 'grad_norm': 7.247613906860352, 'learning_rate': 2.65e-05, 'loss_1': 0.01619124971330166, 'loss_2': 0.0006532669067382812, 'loss_3': -15.686053276062012, 'loss_4': 1.7096500396728516, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 12:35:32,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:32,420 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:26<1:18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:39,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029427409172058105, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.391, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.025748789310455322, 'eval_loss_2': 0.003678619861602783, 'eval_loss_3': -18.220762252807617, 'eval_loss_4': 1.9129974842071533, 'epoch': 3.52}
{'loss': 0.0369, 'grad_norm': 12.632397651672363, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.036192186176776886, 'loss_2': 0.0006623268127441406, 'loss_3': -15.719707489013672, 'loss_4': 1.5545353889465332, 'epoch': 3.52}
{'loss': 0.0468, 'grad_norm': 13.106973648071289, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.03871840983629227, 'loss_2': 0.00807952880859375, 'loss_3': -15.789199829101562, 'loss_4': 2.186089515686035, 'epoch': 3.53}
{'loss': 0.0347, 'grad_norm': 7.497751235961914, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.030165232717990875, 'loss_2': 0.004547119140625, 'loss_3': -15.834266662597656, 'loss_4': 1.8811841011047363, 'epoch': 3.53}
{'loss': 0.0395, 'grad_norm': 10.430662155151367, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.037836164236068726, 'loss_2': 0.0017118453979492188, 'loss_3': -15.599156379699707, 'loss_4': 2.0285744667053223, 'epoch': 3.54}
{'loss': 0.1514, 'grad_norm': 39.08399200439453, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.1473548710346222, 'loss_2': 0.004077911376953125, 'loss_3': -15.506649017333984, 'loss_4': 2.584625244140625, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 12:35:39,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:39,788 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:34<1:18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:47,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0257750041782856, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.835, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.018738901242613792, 'eval_loss_2': 0.007036104798316956, 'eval_loss_3': -18.26405143737793, 'eval_loss_4': 2.27066707611084, 'epoch': 3.55}
{'loss': 0.0376, 'grad_norm': 10.637045860290527, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.029528770595788956, 'loss_2': 0.008087158203125, 'loss_3': -16.00799560546875, 'loss_4': 2.309861421585083, 'epoch': 3.55}
{'loss': 0.0621, 'grad_norm': 13.935393333435059, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.05561979115009308, 'loss_2': 0.00644683837890625, 'loss_3': -15.625129699707031, 'loss_4': 3.034003734588623, 'epoch': 3.56}
{'loss': 0.0404, 'grad_norm': 9.587745666503906, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.0318293422460556, 'loss_2': 0.008544921875, 'loss_3': -15.60057258605957, 'loss_4': 2.676354169845581, 'epoch': 3.56}
{'loss': 0.044, 'grad_norm': 14.238595008850098, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.03981267660856247, 'loss_2': 0.004161834716796875, 'loss_3': -15.640701293945312, 'loss_4': 2.4330902099609375, 'epoch': 3.57}
{'loss': 0.0246, 'grad_norm': 7.66996955871582, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.019869858399033546, 'loss_2': 0.00473785400390625, 'loss_3': -15.763270378112793, 'loss_4': 2.316354751586914, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 12:35:47,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:47,154 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:41<1:18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:54,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02755218744277954, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.76, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02388053946197033, 'eval_loss_2': 0.0036716461181640625, 'eval_loss_3': -18.21193504333496, 'eval_loss_4': 2.6107265949249268, 'epoch': 3.58}
{'loss': 0.0649, 'grad_norm': 22.534645080566406, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.06344357132911682, 'loss_2': 0.0014162063598632812, 'loss_3': -15.759444236755371, 'loss_4': 2.774679183959961, 'epoch': 3.58}
{'loss': 0.0259, 'grad_norm': 6.377208709716797, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.01724952459335327, 'loss_2': 0.00860595703125, 'loss_3': -15.70975112915039, 'loss_4': 2.2887423038482666, 'epoch': 3.59}
{'loss': 0.0719, 'grad_norm': 25.7362060546875, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.06786864250898361, 'loss_2': 0.00406646728515625, 'loss_3': -15.840003967285156, 'loss_4': 1.8811882734298706, 'epoch': 3.59}
{'loss': 0.0435, 'grad_norm': 13.269686698913574, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.029038161039352417, 'loss_2': 0.014495849609375, 'loss_3': -15.805440902709961, 'loss_4': 2.361011028289795, 'epoch': 3.6}
{'loss': 0.0274, 'grad_norm': 5.59099006652832, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.01288134977221489, 'loss_2': 0.01450347900390625, 'loss_3': -15.927041053771973, 'loss_4': 1.62666916847229, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 12:35:54,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:54,520 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:48<1:18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:01,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036186475306749344, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.416, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.02687658555805683, 'eval_loss_2': 0.009309887886047363, 'eval_loss_3': -18.17885971069336, 'eval_loss_4': 2.6028623580932617, 'epoch': 3.6}
{'loss': 0.0332, 'grad_norm': 7.021697521209717, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.026530796661973, 'loss_2': 0.00670623779296875, 'loss_3': -15.676630020141602, 'loss_4': 2.391948938369751, 'epoch': 3.61}
{'loss': 0.0502, 'grad_norm': 16.44801139831543, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.038133878260850906, 'loss_2': 0.01203155517578125, 'loss_3': -16.05413246154785, 'loss_4': 2.941102981567383, 'epoch': 3.62}
{'loss': 0.0584, 'grad_norm': 14.296000480651855, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.049075596034526825, 'loss_2': 0.0093231201171875, 'loss_3': -15.609173774719238, 'loss_4': 2.5326523780822754, 'epoch': 3.62}
{'loss': 0.0436, 'grad_norm': 11.712617874145508, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.03382737934589386, 'loss_2': 0.00972747802734375, 'loss_3': -15.556375503540039, 'loss_4': 2.457149028778076, 'epoch': 3.63}
{'loss': 0.1045, 'grad_norm': 20.67675018310547, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.10399618744850159, 'loss_2': 0.0004830360412597656, 'loss_3': -15.708521842956543, 'loss_4': 2.2547249794006348, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 12:36:01,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:01,897 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:56<1:18:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:09,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03932088613510132, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03255802392959595, 'eval_loss_2': 0.006762862205505371, 'eval_loss_3': -18.12637710571289, 'eval_loss_4': 2.529578685760498, 'epoch': 3.63}
{'loss': 0.0477, 'grad_norm': 14.888837814331055, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.032754894345998764, 'loss_2': 0.01496124267578125, 'loss_3': -15.769514083862305, 'loss_4': 2.4736924171447754, 'epoch': 3.64}
{'loss': 0.0774, 'grad_norm': 18.663320541381836, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.0629914179444313, 'loss_2': 0.014434814453125, 'loss_3': -15.758654594421387, 'loss_4': 2.4696784019470215, 'epoch': 3.65}
{'loss': 0.0581, 'grad_norm': 20.477737426757812, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.04504763334989548, 'loss_2': 0.013031005859375, 'loss_3': -15.652571678161621, 'loss_4': 2.0214905738830566, 'epoch': 3.65}
{'loss': 0.0663, 'grad_norm': 54.29600143432617, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.0580744631588459, 'loss_2': 0.0081939697265625, 'loss_3': -15.633811950683594, 'loss_4': 2.800288200378418, 'epoch': 3.66}
{'loss': 0.0986, 'grad_norm': 28.217979431152344, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.09001247584819794, 'loss_2': 0.00856781005859375, 'loss_3': -15.69722843170166, 'loss_4': 2.682065010070801, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 12:36:09,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:09,260 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:03<1:20:02,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:36:16,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.057794004678726196, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.05047145485877991, 'eval_loss_2': 0.007322549819946289, 'eval_loss_3': -18.05791664123535, 'eval_loss_4': 2.549266815185547, 'epoch': 3.66}
{'loss': 0.0973, 'grad_norm': 14.355415344238281, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.09120705723762512, 'loss_2': 0.00614166259765625, 'loss_3': -15.6477632522583, 'loss_4': 2.6090314388275146, 'epoch': 3.67}
{'loss': 0.053, 'grad_norm': 17.518884658813477, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.04811151325702667, 'loss_2': 0.00484466552734375, 'loss_3': -15.749374389648438, 'loss_4': 2.2567436695098877, 'epoch': 3.67}
{'loss': 0.141, 'grad_norm': 34.42757797241211, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.13053739070892334, 'loss_2': 0.0104827880859375, 'loss_3': -15.579222679138184, 'loss_4': 2.5354299545288086, 'epoch': 3.68}
{'loss': 0.1128, 'grad_norm': 27.11419105529785, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.10132775455713272, 'loss_2': 0.0114898681640625, 'loss_3': -15.86060619354248, 'loss_4': 2.473546028137207, 'epoch': 3.69}
{'loss': 0.0252, 'grad_norm': 6.798346996307373, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.021836115047335625, 'loss_2': 0.0033893585205078125, 'loss_3': -15.658473014831543, 'loss_4': 2.887760877609253, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 12:36:16,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:16,823 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:11<1:18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:24,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.048997703939676285, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.041, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.04453402757644653, 'eval_loss_2': 0.004463672637939453, 'eval_loss_3': -18.12822914123535, 'eval_loss_4': 2.8201587200164795, 'epoch': 3.69}
{'loss': 0.0432, 'grad_norm': 16.509809494018555, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.042759306728839874, 'loss_2': 0.0004372596740722656, 'loss_3': -15.661540985107422, 'loss_4': 2.545891046524048, 'epoch': 3.7}
{'loss': 0.0347, 'grad_norm': 9.306867599487305, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.029223795980215073, 'loss_2': 0.005523681640625, 'loss_3': -15.7237548828125, 'loss_4': 2.9751877784729004, 'epoch': 3.7}
{'loss': 0.1659, 'grad_norm': 26.578157424926758, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.15524594485759735, 'loss_2': 0.01061248779296875, 'loss_3': -15.556230545043945, 'loss_4': 2.77276611328125, 'epoch': 3.71}
{'loss': 0.0789, 'grad_norm': 14.670134544372559, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.058061789721250534, 'loss_2': 0.02081298828125, 'loss_3': -15.621969223022461, 'loss_4': 2.3102216720581055, 'epoch': 3.72}
{'loss': 0.0905, 'grad_norm': 30.937503814697266, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.07964066416025162, 'loss_2': 0.0108489990234375, 'loss_3': -15.761661529541016, 'loss_4': 3.216374397277832, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 12:36:24,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:24,182 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:18<1:18:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:31,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042023152112960815, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.225, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.02813265100121498, 'eval_loss_2': 0.013890504837036133, 'eval_loss_3': -18.22707176208496, 'eval_loss_4': 2.8549227714538574, 'epoch': 3.72}
{'loss': 0.0601, 'grad_norm': 12.008304595947266, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.03983468562364578, 'loss_2': 0.020263671875, 'loss_3': -15.94986343383789, 'loss_4': 2.4579498767852783, 'epoch': 3.73}
{'loss': 0.0486, 'grad_norm': 16.560163497924805, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.03376388922333717, 'loss_2': 0.0148468017578125, 'loss_3': -15.968441009521484, 'loss_4': 2.854628086090088, 'epoch': 3.73}
{'loss': 0.0519, 'grad_norm': 13.998733520507812, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.046755239367485046, 'loss_2': 0.00518035888671875, 'loss_3': -15.858392715454102, 'loss_4': 3.0624442100524902, 'epoch': 3.74}
{'loss': 0.0375, 'grad_norm': 6.362914085388184, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.019997157156467438, 'loss_2': 0.017547607421875, 'loss_3': -16.04083251953125, 'loss_4': 2.730745315551758, 'epoch': 3.74}
{'loss': 0.0822, 'grad_norm': 46.02153396606445, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.0740947350859642, 'loss_2': 0.00811004638671875, 'loss_3': -15.752676010131836, 'loss_4': 2.733502149581909, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 12:36:31,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:31,562 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:26<1:18:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:38,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027092136442661285, 'eval_runtime': 3.8188, 'eval_samples_per_second': 268.146, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.0218679029494524, 'eval_loss_2': 0.005224235355854034, 'eval_loss_3': -18.28200340270996, 'eval_loss_4': 2.8070759773254395, 'epoch': 3.75}
{'loss': 0.0268, 'grad_norm': 9.587667465209961, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.025908267125487328, 'loss_2': 0.000904083251953125, 'loss_3': -15.630849838256836, 'loss_4': 3.1436429023742676, 'epoch': 3.76}
{'loss': 0.0228, 'grad_norm': 6.493919372558594, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.021750615909695625, 'loss_2': 0.0010280609130859375, 'loss_3': -15.911516189575195, 'loss_4': 2.4086925983428955, 'epoch': 3.76}
{'loss': 0.0627, 'grad_norm': 17.096078872680664, 'learning_rate': 2.625e-05, 'loss_1': 0.053784824907779694, 'loss_2': 0.0089569091796875, 'loss_3': -15.95426082611084, 'loss_4': 3.1437416076660156, 'epoch': 3.77}
{'loss': 0.0456, 'grad_norm': 8.594141006469727, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.028037600219249725, 'loss_2': 0.0175323486328125, 'loss_3': -15.693918228149414, 'loss_4': 2.853442668914795, 'epoch': 3.77}
{'loss': 0.0551, 'grad_norm': 11.779922485351562, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.0332380048930645, 'loss_2': 0.0218658447265625, 'loss_3': -16.215072631835938, 'loss_4': 3.1787643432617188, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 12:36:38,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:38,940 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:33<1:18:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:46,314 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03324318677186966, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.659, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01599908620119095, 'eval_loss_2': 0.01724410057067871, 'eval_loss_3': -18.35358428955078, 'eval_loss_4': 2.7698023319244385, 'epoch': 3.78}
{'loss': 0.0591, 'grad_norm': 17.666364669799805, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.03925248607993126, 'loss_2': 0.019866943359375, 'loss_3': -15.915815353393555, 'loss_4': 2.7264795303344727, 'epoch': 3.78}
{'loss': 0.0706, 'grad_norm': 14.010518074035645, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.04945393651723862, 'loss_2': 0.021148681640625, 'loss_3': -15.76923942565918, 'loss_4': 2.935458183288574, 'epoch': 3.79}
{'loss': 0.0458, 'grad_norm': 24.125431060791016, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.029180793091654778, 'loss_2': 0.0166015625, 'loss_3': -15.857001304626465, 'loss_4': 2.8570845127105713, 'epoch': 3.8}
{'loss': 0.0684, 'grad_norm': 17.025705337524414, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.05116523429751396, 'loss_2': 0.0172119140625, 'loss_3': -15.705486297607422, 'loss_4': 3.373065233230591, 'epoch': 3.8}
{'loss': 0.0456, 'grad_norm': 13.815213203430176, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.03679058700799942, 'loss_2': 0.00885009765625, 'loss_3': -15.764766693115234, 'loss_4': 3.3261725902557373, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 12:36:46,314 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:46,314 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:40<1:18:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:53,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025957364588975906, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.257, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.015616437420248985, 'eval_loss_2': 0.01034092903137207, 'eval_loss_3': -18.377225875854492, 'eval_loss_4': 2.5445590019226074, 'epoch': 3.81}
{'loss': 0.0409, 'grad_norm': 11.465041160583496, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.026244157925248146, 'loss_2': 0.01461029052734375, 'loss_3': -15.847307205200195, 'loss_4': 2.9459335803985596, 'epoch': 3.81}
{'loss': 0.0263, 'grad_norm': 7.874730587005615, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.02133353240787983, 'loss_2': 0.00492095947265625, 'loss_3': -15.837583541870117, 'loss_4': 2.1790390014648438, 'epoch': 3.82}
{'loss': 0.0361, 'grad_norm': 13.689338684082031, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.03444139286875725, 'loss_2': 0.00164794921875, 'loss_3': -15.524948120117188, 'loss_4': 2.1358816623687744, 'epoch': 3.83}
{'loss': 0.0306, 'grad_norm': 8.310797691345215, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.024241631850600243, 'loss_2': 0.0063934326171875, 'loss_3': -15.877421379089355, 'loss_4': 2.047769546508789, 'epoch': 3.83}
{'loss': 0.0521, 'grad_norm': 27.6832332611084, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.04612789303064346, 'loss_2': 0.005939483642578125, 'loss_3': -15.833972930908203, 'loss_4': 1.6737637519836426, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 12:36:53,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:53,691 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:48<1:18:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:01,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02475098893046379, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.548, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.017250994220376015, 'eval_loss_2': 0.007499992847442627, 'eval_loss_3': -18.31500244140625, 'eval_loss_4': 1.7863349914550781, 'epoch': 3.84}
{'loss': 0.0525, 'grad_norm': 14.511533737182617, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.04627164453268051, 'loss_2': 0.006183624267578125, 'loss_3': -15.94069766998291, 'loss_4': 2.004096508026123, 'epoch': 3.84}
{'loss': 0.0681, 'grad_norm': 16.375089645385742, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.052445631474256516, 'loss_2': 0.0156402587890625, 'loss_3': -15.638957977294922, 'loss_4': 1.7147754430770874, 'epoch': 3.85}
{'loss': 0.0232, 'grad_norm': 7.3752875328063965, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.01897183060646057, 'loss_2': 0.00420379638671875, 'loss_3': -15.875532150268555, 'loss_4': 1.9712238311767578, 'epoch': 3.85}
{'loss': 0.0345, 'grad_norm': 10.183229446411133, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.022534342482686043, 'loss_2': 0.0119171142578125, 'loss_3': -15.851869583129883, 'loss_4': 1.4482909440994263, 'epoch': 3.86}
{'loss': 0.1083, 'grad_norm': 17.440263748168945, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.09154333919286728, 'loss_2': 0.0167083740234375, 'loss_3': -15.750418663024902, 'loss_4': 1.4486918449401855, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 12:37:01,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:01,071 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:55<1:17:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:08,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04094218462705612, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.363, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.03054138273000717, 'eval_loss_2': 0.01040080189704895, 'eval_loss_3': -18.208345413208008, 'eval_loss_4': 1.7183622121810913, 'epoch': 3.87}
{'loss': 0.026, 'grad_norm': 6.078617572784424, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.017410531640052795, 'loss_2': 0.00860595703125, 'loss_3': -15.839430809020996, 'loss_4': 2.184953451156616, 'epoch': 3.87}
{'loss': 0.0166, 'grad_norm': 6.523344039916992, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.013328582048416138, 'loss_2': 0.003292083740234375, 'loss_3': -15.821802139282227, 'loss_4': 1.7511606216430664, 'epoch': 3.88}
{'loss': 0.0271, 'grad_norm': 7.336569786071777, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.02193768322467804, 'loss_2': 0.00514984130859375, 'loss_3': -15.840028762817383, 'loss_4': 1.6246721744537354, 'epoch': 3.88}
{'loss': 0.033, 'grad_norm': 9.307059288024902, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.02276645042002201, 'loss_2': 0.0102386474609375, 'loss_3': -15.945335388183594, 'loss_4': 2.09808349609375, 'epoch': 3.89}
{'loss': 0.0325, 'grad_norm': 7.924638748168945, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.024314898997545242, 'loss_2': 0.0081939697265625, 'loss_3': -15.87451457977295, 'loss_4': 1.7657660245895386, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 12:37:08,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:08,444 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:02<1:17:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:15,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05459500476717949, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.831, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.04354311153292656, 'eval_loss_2': 0.01105189323425293, 'eval_loss_3': -18.114580154418945, 'eval_loss_4': 1.8672572374343872, 'epoch': 3.9}
{'loss': 0.024, 'grad_norm': 6.8862433433532715, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.01644762232899666, 'loss_2': 0.007534027099609375, 'loss_3': -15.666006088256836, 'loss_4': 1.8232866525650024, 'epoch': 3.9}
{'loss': 0.0356, 'grad_norm': 7.342940330505371, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.019421584904193878, 'loss_2': 0.016204833984375, 'loss_3': -15.897035598754883, 'loss_4': 1.9745192527770996, 'epoch': 3.91}
{'loss': 0.0683, 'grad_norm': 11.169624328613281, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.05278503894805908, 'loss_2': 0.0155181884765625, 'loss_3': -15.822622299194336, 'loss_4': 1.713054895401001, 'epoch': 3.91}
{'loss': 0.0362, 'grad_norm': 26.052772521972656, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.03422880917787552, 'loss_2': 0.0019989013671875, 'loss_3': -15.634176254272461, 'loss_4': 1.1472272872924805, 'epoch': 3.92}
{'loss': 0.0195, 'grad_norm': 5.952702522277832, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.014755792915821075, 'loss_2': 0.004787445068359375, 'loss_3': -15.689996719360352, 'loss_4': 1.8229575157165527, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 12:37:15,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:15,805 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:10<1:17:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:23,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05838236212730408, 'eval_runtime': 3.8196, 'eval_samples_per_second': 268.091, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.05152875557541847, 'eval_loss_2': 0.006853610277175903, 'eval_loss_3': -18.091876983642578, 'eval_loss_4': 1.6072814464569092, 'epoch': 3.92}
{'loss': 0.0632, 'grad_norm': 16.603384017944336, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.050414249300956726, 'loss_2': 0.012786865234375, 'loss_3': -15.82520866394043, 'loss_4': 1.5092686414718628, 'epoch': 3.93}
{'loss': 0.0448, 'grad_norm': 14.19448184967041, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.039159342646598816, 'loss_2': 0.0056610107421875, 'loss_3': -15.839527130126953, 'loss_4': 1.7536089420318604, 'epoch': 3.94}
{'loss': 0.0218, 'grad_norm': 7.0645623207092285, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.017816003412008286, 'loss_2': 0.0039825439453125, 'loss_3': -15.964075088500977, 'loss_4': 1.3133091926574707, 'epoch': 3.94}
{'loss': 0.0498, 'grad_norm': 29.80705451965332, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.047799088060855865, 'loss_2': 0.0019664764404296875, 'loss_3': -15.49039363861084, 'loss_4': 1.0668710470199585, 'epoch': 3.95}
{'loss': 0.0466, 'grad_norm': 12.532540321350098, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.03395737335085869, 'loss_2': 0.01264190673828125, 'loss_3': -15.919952392578125, 'loss_4': 1.5891714096069336, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 12:37:23,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:23,186 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:17<1:17:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:30,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.052453864365816116, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.277, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.04063449800014496, 'eval_loss_2': 0.01181936264038086, 'eval_loss_3': -18.14337158203125, 'eval_loss_4': 1.1703542470932007, 'epoch': 3.95}
{'loss': 0.0512, 'grad_norm': 10.905998229980469, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.040809355676174164, 'loss_2': 0.0103912353515625, 'loss_3': -15.648054122924805, 'loss_4': 1.368545651435852, 'epoch': 3.96}
{'loss': 0.0584, 'grad_norm': 26.906864166259766, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.05023961514234543, 'loss_2': 0.00817108154296875, 'loss_3': -15.734293937683105, 'loss_4': 1.4598757028579712, 'epoch': 3.97}
{'loss': 0.0251, 'grad_norm': 6.37412166595459, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.012290525250136852, 'loss_2': 0.01280975341796875, 'loss_3': -15.804448127746582, 'loss_4': 0.6803591251373291, 'epoch': 3.97}
{'loss': 0.0421, 'grad_norm': 13.817893981933594, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.026182275265455246, 'loss_2': 0.015960693359375, 'loss_3': -15.940302848815918, 'loss_4': 0.917820930480957, 'epoch': 3.98}
{'loss': 0.0641, 'grad_norm': 18.959877014160156, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.049496840685606, 'loss_2': 0.0146026611328125, 'loss_3': -15.623029708862305, 'loss_4': 1.5022743940353394, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 12:37:30,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:30,560 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:24<1:14:22,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 12:37:37,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028839634731411934, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.512, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.021660078316926956, 'eval_loss_2': 0.007179558277130127, 'eval_loss_3': -18.249652862548828, 'eval_loss_4': 1.1762967109680176, 'epoch': 3.98}
{'loss': 0.0532, 'grad_norm': 18.4932918548584, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.043182190507650375, 'loss_2': 0.0100555419921875, 'loss_3': -15.667878150939941, 'loss_4': 1.146278738975525, 'epoch': 3.99}
{'loss': 0.0432, 'grad_norm': 13.158122062683105, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.036431293934583664, 'loss_2': 0.0067901611328125, 'loss_3': -15.786436080932617, 'loss_4': 1.4584975242614746, 'epoch': 3.99}
{'loss': 0.0179, 'grad_norm': 9.467391967773438, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.014202664606273174, 'loss_2': 0.0037326812744140625, 'loss_3': -15.526629447937012, 'loss_4': 2.006054162979126, 'epoch': 4.0}
{'loss': 0.0175, 'grad_norm': 5.137807846069336, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.012046733871102333, 'loss_2': 0.005481719970703125, 'loss_3': -15.699337005615234, 'loss_4': 1.5030399560928345, 'epoch': 4.01}
{'loss': 0.0627, 'grad_norm': 17.673320770263672, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.057522352784872055, 'loss_2': 0.0052032470703125, 'loss_3': -16.030704498291016, 'loss_4': 1.693739652633667, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 12:37:37,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:37,613 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:32<1:17:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:44,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02102973684668541, 'eval_runtime': 3.821, 'eval_samples_per_second': 267.994, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.017407115548849106, 'eval_loss_2': 0.0036226212978363037, 'eval_loss_3': -18.355953216552734, 'eval_loss_4': 1.3789101839065552, 'epoch': 4.01}
{'loss': 0.0707, 'grad_norm': 16.83066749572754, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.062060896307229996, 'loss_2': 0.0086517333984375, 'loss_3': -15.763311386108398, 'loss_4': 1.8113312721252441, 'epoch': 4.02}
{'loss': 0.0471, 'grad_norm': 13.83784008026123, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.042913343757390976, 'loss_2': 0.00415802001953125, 'loss_3': -15.78258991241455, 'loss_4': 1.7208974361419678, 'epoch': 4.02}
{'loss': 0.036, 'grad_norm': 11.200583457946777, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.033936724066734314, 'loss_2': 0.0020599365234375, 'loss_3': -15.6575288772583, 'loss_4': 1.3581864833831787, 'epoch': 4.03}
{'loss': 0.0653, 'grad_norm': 18.814186096191406, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.060855213552713394, 'loss_2': 0.0044403076171875, 'loss_3': -15.91687297821045, 'loss_4': 2.0039377212524414, 'epoch': 4.03}
{'loss': 0.022, 'grad_norm': 7.3321919441223145, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.020606569945812225, 'loss_2': 0.0013980865478515625, 'loss_3': -15.867107391357422, 'loss_4': 1.7800469398498535, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 12:37:44,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:44,995 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:39<1:17:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:52,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02356567606329918, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.261, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.01833888329565525, 'eval_loss_2': 0.005226790904998779, 'eval_loss_3': -18.32240867614746, 'eval_loss_4': 1.5269631147384644, 'epoch': 4.04}
{'loss': 0.0634, 'grad_norm': 15.676494598388672, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.0592043399810791, 'loss_2': 0.00421905517578125, 'loss_3': -15.870927810668945, 'loss_4': 2.4190735816955566, 'epoch': 4.05}
{'loss': 0.0458, 'grad_norm': 11.892618179321289, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.03817705065011978, 'loss_2': 0.00760650634765625, 'loss_3': -15.98548698425293, 'loss_4': 2.3837504386901855, 'epoch': 4.05}
{'loss': 0.0397, 'grad_norm': 7.37857723236084, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.028050923720002174, 'loss_2': 0.0116119384765625, 'loss_3': -15.755006790161133, 'loss_4': 1.8110560178756714, 'epoch': 4.06}
{'loss': 0.0272, 'grad_norm': 8.724105834960938, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.020736023783683777, 'loss_2': 0.006443023681640625, 'loss_3': -15.995972633361816, 'loss_4': 1.874635934829712, 'epoch': 4.06}
{'loss': 0.0542, 'grad_norm': 17.736433029174805, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.04855630174279213, 'loss_2': 0.005626678466796875, 'loss_3': -15.986053466796875, 'loss_4': 1.384491205215454, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 12:37:52,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:52,368 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:46<1:17:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:59,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02772681973874569, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.55, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.019727399572730064, 'eval_loss_2': 0.007999420166015625, 'eval_loss_3': -18.30012321472168, 'eval_loss_4': 1.416027545928955, 'epoch': 4.07}
{'loss': 0.022, 'grad_norm': 7.415997505187988, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.018277090042829514, 'loss_2': 0.0036773681640625, 'loss_3': -15.86639404296875, 'loss_4': 1.9983270168304443, 'epoch': 4.08}
{'loss': 0.0424, 'grad_norm': 10.531917572021484, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.03809871897101402, 'loss_2': 0.004302978515625, 'loss_3': -15.793899536132812, 'loss_4': 1.9142184257507324, 'epoch': 4.08}
{'loss': 0.0577, 'grad_norm': 16.700714111328125, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.05113859847187996, 'loss_2': 0.00652313232421875, 'loss_3': -15.803447723388672, 'loss_4': 0.7668935656547546, 'epoch': 4.09}
{'loss': 0.0305, 'grad_norm': 8.71706485748291, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.027674194425344467, 'loss_2': 0.0028533935546875, 'loss_3': -15.727262496948242, 'loss_4': 1.1364144086837769, 'epoch': 4.09}
{'loss': 0.0201, 'grad_norm': 7.546415328979492, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.01675874926149845, 'loss_2': 0.00330352783203125, 'loss_3': -15.919814109802246, 'loss_4': 1.337990641593933, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 12:37:59,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:59,742 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:54<1:17:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:07,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02768663503229618, 'eval_runtime': 3.8247, 'eval_samples_per_second': 267.733, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.023916902020573616, 'eval_loss_2': 0.0037697330117225647, 'eval_loss_3': -18.182518005371094, 'eval_loss_4': 1.2363300323486328, 'epoch': 4.1}
{'loss': 0.0465, 'grad_norm': 12.223834991455078, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.046371158212423325, 'loss_2': 0.00010263919830322266, 'loss_3': -15.891687393188477, 'loss_4': 1.2849105596542358, 'epoch': 4.1}
{'loss': 0.0181, 'grad_norm': 6.863616466522217, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.017673922702670097, 'loss_2': 0.0004372596740722656, 'loss_3': -15.95058822631836, 'loss_4': 1.2418421506881714, 'epoch': 4.11}
{'loss': 0.0375, 'grad_norm': 11.050621032714844, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.03197876736521721, 'loss_2': 0.00548553466796875, 'loss_3': -16.066503524780273, 'loss_4': 1.7981163263320923, 'epoch': 4.12}
{'loss': 0.04, 'grad_norm': 10.404690742492676, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.034263767302036285, 'loss_2': 0.00576019287109375, 'loss_3': -16.040611267089844, 'loss_4': 1.0719265937805176, 'epoch': 4.12}
{'loss': 0.0257, 'grad_norm': 9.951828002929688, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.024706754833459854, 'loss_2': 0.0009450912475585938, 'loss_3': -16.050193786621094, 'loss_4': 1.5493531227111816, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 12:38:07,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:07,119 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:01<1:17:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:14,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031206194311380386, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.027984920889139175, 'eval_loss_2': 0.003221273422241211, 'eval_loss_3': -18.178958892822266, 'eval_loss_4': 1.1697509288787842, 'epoch': 4.13}
{'loss': 0.0285, 'grad_norm': 8.172500610351562, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.028480064123868942, 'loss_2': 6.759166717529297e-05, 'loss_3': -15.838395118713379, 'loss_4': 1.1354808807373047, 'epoch': 4.13}
{'loss': 0.0863, 'grad_norm': 26.257545471191406, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.0758398100733757, 'loss_2': 0.01049041748046875, 'loss_3': -16.208927154541016, 'loss_4': 2.199228286743164, 'epoch': 4.14}
{'loss': 0.1099, 'grad_norm': 31.495397567749023, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.10002004355192184, 'loss_2': 0.0098724365234375, 'loss_3': -15.77966594696045, 'loss_4': 1.1939899921417236, 'epoch': 4.15}
{'loss': 0.0333, 'grad_norm': 8.951934814453125, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.026526087895035744, 'loss_2': 0.0067901611328125, 'loss_3': -15.857076644897461, 'loss_4': 1.5020010471343994, 'epoch': 4.15}
{'loss': 0.0291, 'grad_norm': 10.934552192687988, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.02311037853360176, 'loss_2': 0.0059814453125, 'loss_3': -15.976341247558594, 'loss_4': 1.597523808479309, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 12:38:14,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:14,480 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:08<1:16:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:21,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029809728264808655, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.77, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.022462867200374603, 'eval_loss_2': 0.0073468685150146484, 'eval_loss_3': -18.21169090270996, 'eval_loss_4': 1.2312337160110474, 'epoch': 4.16}
{'loss': 0.0317, 'grad_norm': 8.869427680969238, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.0279245488345623, 'loss_2': 0.003810882568359375, 'loss_3': -15.99002742767334, 'loss_4': 1.134406328201294, 'epoch': 4.16}
{'loss': 0.0315, 'grad_norm': 13.938419342041016, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.023963874205946922, 'loss_2': 0.007534027099609375, 'loss_3': -15.95389175415039, 'loss_4': 1.4197094440460205, 'epoch': 4.17}
{'loss': 0.0235, 'grad_norm': 6.757741451263428, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.015519775450229645, 'loss_2': 0.008026123046875, 'loss_3': -15.96031379699707, 'loss_4': 1.4964170455932617, 'epoch': 4.17}
{'loss': 0.0298, 'grad_norm': 11.653864860534668, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.025624655187129974, 'loss_2': 0.00421142578125, 'loss_3': -16.00149917602539, 'loss_4': 1.6600157022476196, 'epoch': 4.18}
{'loss': 0.0177, 'grad_norm': 6.182618141174316, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.012234286405146122, 'loss_2': 0.0054931640625, 'loss_3': -16.18206024169922, 'loss_4': 1.3483576774597168, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 12:38:21,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:21,843 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:16<1:17:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:29,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024604996666312218, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.376, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.014539560303092003, 'eval_loss_2': 0.010065436363220215, 'eval_loss_3': -18.283798217773438, 'eval_loss_4': 1.5283657312393188, 'epoch': 4.19}
{'loss': 0.0591, 'grad_norm': 18.9344425201416, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.04885479435324669, 'loss_2': 0.010223388671875, 'loss_3': -15.88848876953125, 'loss_4': 1.984934687614441, 'epoch': 4.19}
{'loss': 0.0294, 'grad_norm': 6.536633491516113, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.01899178884923458, 'loss_2': 0.0103607177734375, 'loss_3': -15.99338436126709, 'loss_4': 2.0449657440185547, 'epoch': 4.2}
{'loss': 0.0494, 'grad_norm': 9.643570899963379, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.03018289990723133, 'loss_2': 0.019256591796875, 'loss_3': -16.024913787841797, 'loss_4': 1.9880049228668213, 'epoch': 4.2}
{'loss': 0.1201, 'grad_norm': 19.58932876586914, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.10258205980062485, 'loss_2': 0.017486572265625, 'loss_3': -16.001056671142578, 'loss_4': 2.6160459518432617, 'epoch': 4.21}
{'loss': 0.0328, 'grad_norm': 6.196885108947754, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.015917373821139336, 'loss_2': 0.01690673828125, 'loss_3': -15.850770950317383, 'loss_4': 2.306779384613037, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 12:38:29,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:29,221 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:23<1:16:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:36,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02518612891435623, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.422, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.013677425682544708, 'eval_loss_2': 0.011508703231811523, 'eval_loss_3': -18.306333541870117, 'eval_loss_4': 1.9097485542297363, 'epoch': 4.22}
{'loss': 0.0528, 'grad_norm': 14.686517715454102, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.041773341596126556, 'loss_2': 0.0110321044921875, 'loss_3': -16.11546516418457, 'loss_4': 1.8440154790878296, 'epoch': 4.22}
{'loss': 0.046, 'grad_norm': 17.00972557067871, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.04456759989261627, 'loss_2': 0.0014801025390625, 'loss_3': -15.87498664855957, 'loss_4': 2.6691341400146484, 'epoch': 4.23}
{'loss': 0.0415, 'grad_norm': 20.950071334838867, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.03219000622630119, 'loss_2': 0.0093536376953125, 'loss_3': -16.012041091918945, 'loss_4': 2.3232688903808594, 'epoch': 4.23}
{'loss': 0.054, 'grad_norm': 17.270931243896484, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.052107442170381546, 'loss_2': 0.0018444061279296875, 'loss_3': -16.045364379882812, 'loss_4': 2.9428870677948, 'epoch': 4.24}
{'loss': 0.0213, 'grad_norm': 11.968048095703125, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.02041512168943882, 'loss_2': 0.0008854866027832031, 'loss_3': -15.94904613494873, 'loss_4': 2.1279892921447754, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 12:38:36,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:36,592 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:31<1:16:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:43,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019377456977963448, 'eval_runtime': 3.8307, 'eval_samples_per_second': 267.313, 'eval_steps_per_second': 4.177, 'eval_loss_1': 0.015223877504467964, 'eval_loss_2': 0.004153579473495483, 'eval_loss_3': -18.310346603393555, 'eval_loss_4': 2.1345787048339844, 'epoch': 4.24}
{'loss': 0.0223, 'grad_norm': 8.81134033203125, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.021948594599962234, 'loss_2': 0.0003552436828613281, 'loss_3': -16.110727310180664, 'loss_4': 2.730818271636963, 'epoch': 4.25}
{'loss': 0.0224, 'grad_norm': 6.156836986541748, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.013402441516518593, 'loss_2': 0.009002685546875, 'loss_3': -16.112571716308594, 'loss_4': 1.9599276781082153, 'epoch': 4.26}
{'loss': 0.03, 'grad_norm': 7.596776008605957, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.019774582237005234, 'loss_2': 0.0102081298828125, 'loss_3': -15.862627983093262, 'loss_4': 2.699608325958252, 'epoch': 4.26}
{'loss': 0.0311, 'grad_norm': 12.812621116638184, 'learning_rate': 2.575e-05, 'loss_1': 0.026212388649582863, 'loss_2': 0.004878997802734375, 'loss_3': -15.853447914123535, 'loss_4': 2.068081855773926, 'epoch': 4.27}
{'loss': 0.0146, 'grad_norm': 6.211928844451904, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.01370301190763712, 'loss_2': 0.00092315673828125, 'loss_3': -16.087926864624023, 'loss_4': 1.838958978652954, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 12:38:43,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:43,978 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:38<1:16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:51,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02655874937772751, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.9, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015805117785930634, 'eval_loss_2': 0.010753631591796875, 'eval_loss_3': -18.267108917236328, 'eval_loss_4': 2.015826940536499, 'epoch': 4.27}
{'loss': 0.0411, 'grad_norm': 10.882408142089844, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.027102945372462273, 'loss_2': 0.0139617919921875, 'loss_3': -16.105125427246094, 'loss_4': 2.4316372871398926, 'epoch': 4.28}
{'loss': 0.0402, 'grad_norm': 14.415063858032227, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.02878589741885662, 'loss_2': 0.0114593505859375, 'loss_3': -15.860383987426758, 'loss_4': 2.655001640319824, 'epoch': 4.28}
{'loss': 0.0315, 'grad_norm': 11.063691139221191, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.022578679025173187, 'loss_2': 0.00890350341796875, 'loss_3': -16.000621795654297, 'loss_4': 1.6339292526245117, 'epoch': 4.29}
{'loss': 0.0375, 'grad_norm': 9.34262466430664, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.032152265310287476, 'loss_2': 0.0053863525390625, 'loss_3': -15.901028633117676, 'loss_4': 2.3698039054870605, 'epoch': 4.3}
{'loss': 0.0277, 'grad_norm': 7.478370189666748, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.018708880990743637, 'loss_2': 0.00897216796875, 'loss_3': -15.982739448547363, 'loss_4': 1.5929169654846191, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 12:38:51,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:51,341 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:45<1:16:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:58,692 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020794175565242767, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.703, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015513144433498383, 'eval_loss_2': 0.005281031131744385, 'eval_loss_3': -18.267711639404297, 'eval_loss_4': 1.5921473503112793, 'epoch': 4.3}
{'loss': 0.0239, 'grad_norm': 8.719123840332031, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.022718047723174095, 'loss_2': 0.0011920928955078125, 'loss_3': -15.914247512817383, 'loss_4': 1.802765130996704, 'epoch': 4.31}
{'loss': 0.0211, 'grad_norm': 7.7055864334106445, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.019314909353852272, 'loss_2': 0.0018253326416015625, 'loss_3': -16.02933692932129, 'loss_4': 1.5077019929885864, 'epoch': 4.31}
{'loss': 0.0215, 'grad_norm': 7.277259826660156, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.019362816587090492, 'loss_2': 0.0020961761474609375, 'loss_3': -15.532570838928223, 'loss_4': 1.7689756155014038, 'epoch': 4.32}
{'loss': 0.0305, 'grad_norm': 6.9859299659729, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.017411453649401665, 'loss_2': 0.0130615234375, 'loss_3': -16.18537139892578, 'loss_4': 1.5775691270828247, 'epoch': 4.33}
{'loss': 0.0285, 'grad_norm': 9.476445198059082, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.02231472358107567, 'loss_2': 0.006137847900390625, 'loss_3': -15.727865219116211, 'loss_4': 1.2543892860412598, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 12:38:58,692 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:58,692 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:53<1:16:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:06,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02193492278456688, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.169, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014696895144879818, 'eval_loss_2': 0.007238030433654785, 'eval_loss_3': -18.270164489746094, 'eval_loss_4': 1.08743417263031, 'epoch': 4.33}
{'loss': 0.0546, 'grad_norm': 14.449564933776855, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.039739008992910385, 'loss_2': 0.0148162841796875, 'loss_3': -15.784149169921875, 'loss_4': 0.9419981241226196, 'epoch': 4.34}
{'loss': 0.0251, 'grad_norm': 7.028387069702148, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.01813891902565956, 'loss_2': 0.00698089599609375, 'loss_3': -15.964420318603516, 'loss_4': 1.2728025913238525, 'epoch': 4.34}
{'loss': 0.0351, 'grad_norm': 10.1536283493042, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.026161495596170425, 'loss_2': 0.0088958740234375, 'loss_3': -16.014774322509766, 'loss_4': 1.32698392868042, 'epoch': 4.35}
{'loss': 0.0582, 'grad_norm': 14.252487182617188, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.050580721348524094, 'loss_2': 0.007617950439453125, 'loss_3': -15.661800384521484, 'loss_4': 0.9024459719657898, 'epoch': 4.35}
{'loss': 0.0231, 'grad_norm': 8.279258728027344, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.01788417249917984, 'loss_2': 0.00518035888671875, 'loss_3': -15.829256057739258, 'loss_4': 1.352975845336914, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 12:39:06,046 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:06,046 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:00<1:16:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:13,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019182227551937103, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014630517922341824, 'eval_loss_2': 0.004551708698272705, 'eval_loss_3': -18.302274703979492, 'eval_loss_4': 0.7665032148361206, 'epoch': 4.36}
{'loss': 0.034, 'grad_norm': 8.627924919128418, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.0264581311494112, 'loss_2': 0.0075531005859375, 'loss_3': -15.986494064331055, 'loss_4': 1.5126709938049316, 'epoch': 4.37}
{'loss': 0.022, 'grad_norm': 5.84622049331665, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.015851112082600594, 'loss_2': 0.0061798095703125, 'loss_3': -16.117557525634766, 'loss_4': 0.9834442138671875, 'epoch': 4.37}
{'loss': 0.0341, 'grad_norm': 12.362776756286621, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.026681268587708473, 'loss_2': 0.007419586181640625, 'loss_3': -16.012908935546875, 'loss_4': 0.603690505027771, 'epoch': 4.38}
{'loss': 0.0521, 'grad_norm': 12.646220207214355, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.04145408049225807, 'loss_2': 0.0106658935546875, 'loss_3': -15.971687316894531, 'loss_4': 0.4776923656463623, 'epoch': 4.38}
{'loss': 0.0474, 'grad_norm': 13.078512191772461, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.041740935295820236, 'loss_2': 0.00563812255859375, 'loss_3': -15.97935676574707, 'loss_4': 1.0764567852020264, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 12:39:13,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:13,401 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:04<1:16:18,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:39:17,212 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755
[INFO|configuration_utils.py:420] 2025-01-21 12:39:17,213 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755/config.json                                                                             
{'eval_loss': 0.018142016604542732, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.783, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.014625299721956253, 'eval_loss_2': 0.0035167187452316284, 'eval_loss_3': -18.32176971435547, 'eval_loss_4': 0.7173669338226318, 'epoch': 4.39}
[INFO|modeling_utils.py:2988] 2025-01-21 12:39:17,723 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:39:17,724 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:39:17,725 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:39:18,644 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-495] due to args.save_total_limit
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:09<1:24:16,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:39:22,289 >>
{'loss': 0.0425, 'grad_norm': 9.343671798706055, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.03838260471820831, 'loss_2': 0.0041046142578125, 'loss_3': -15.945809364318848, 'loss_4': 0.260466068983078, 'epoch': 4.4}
{'loss': 0.0541, 'grad_norm': 11.91554069519043, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.052569735795259476, 'loss_2': 0.0014820098876953125, 'loss_3': -16.17125701904297, 'loss_4': 1.0232242345809937, 'epoch': 4.4}
{'loss': 0.0329, 'grad_norm': 9.564785957336426, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.03260356932878494, 'loss_2': 0.00033283233642578125, 'loss_3': -16.039522171020508, 'loss_4': 0.5242098569869995, 'epoch': 4.41}
{'loss': 0.0679, 'grad_norm': 18.831573486328125, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.05707439407706261, 'loss_2': 0.01081085205078125, 'loss_3': -16.062850952148438, 'loss_4': 0.39205804467201233, 'epoch': 4.41}
{'loss': 0.0539, 'grad_norm': 13.126139640808105, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.04823031276464462, 'loss_2': 0.00568389892578125, 'loss_3': -15.932479858398438, 'loss_4': 0.7847791314125061, 'epoch': 4.42}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:39:22,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:22,289 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:16<1:17:24,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:39:29,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027658894658088684, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0174991637468338, 'eval_loss_2': 0.010159730911254883, 'eval_loss_3': -18.291454315185547, 'eval_loss_4': 0.8446938991546631, 'epoch': 4.42}
{'loss': 0.0417, 'grad_norm': 8.260269165039062, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.031135229393839836, 'loss_2': 0.01061248779296875, 'loss_3': -15.983255386352539, 'loss_4': 0.8982169032096863, 'epoch': 4.42}
{'loss': 0.041, 'grad_norm': 11.722273826599121, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.033771950751543045, 'loss_2': 0.0072021484375, 'loss_3': -15.973716735839844, 'loss_4': 0.8118379712104797, 'epoch': 4.43}
{'loss': 0.0438, 'grad_norm': 13.507554054260254, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.029781002551317215, 'loss_2': 0.01398468017578125, 'loss_3': -16.006032943725586, 'loss_4': 0.8228453397750854, 'epoch': 4.44}
{'loss': 0.0461, 'grad_norm': 15.079022407531738, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.040770094841718674, 'loss_2': 0.00534820556640625, 'loss_3': -16.0146484375, 'loss_4': 0.8287827968597412, 'epoch': 4.44}
{'loss': 0.0213, 'grad_norm': 5.841409206390381, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.01442720927298069, 'loss_2': 0.00682830810546875, 'loss_3': -15.92923641204834, 'loss_4': 1.0957547426223755, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 12:39:29,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:29,642 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:24<1:16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:36,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022989992052316666, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.020390037447214127, 'eval_loss_2': 0.0025999508798122406, 'eval_loss_3': -18.241907119750977, 'eval_loss_4': 1.0169488191604614, 'epoch': 4.45}
{'loss': 0.0543, 'grad_norm': 13.820313453674316, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.052215974777936935, 'loss_2': 0.002124786376953125, 'loss_3': -15.966150283813477, 'loss_4': 1.010455846786499, 'epoch': 4.45}
{'loss': 0.1068, 'grad_norm': 27.623241424560547, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.10205129534006119, 'loss_2': 0.0047454833984375, 'loss_3': -15.914119720458984, 'loss_4': 0.691436767578125, 'epoch': 4.46}
{'loss': 0.0429, 'grad_norm': 8.347979545593262, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.026619816198945045, 'loss_2': 0.016265869140625, 'loss_3': -15.975833892822266, 'loss_4': 0.5922043323516846, 'epoch': 4.47}
{'loss': 0.0289, 'grad_norm': 6.849788188934326, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.02313319593667984, 'loss_2': 0.00580596923828125, 'loss_3': -15.945535659790039, 'loss_4': 0.4428502321243286, 'epoch': 4.47}
{'loss': 0.0109, 'grad_norm': 5.524442672729492, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.008738062344491482, 'loss_2': 0.0021514892578125, 'loss_3': -15.9398193359375, 'loss_4': 1.1122140884399414, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 12:39:36,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:36,981 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:31<1:15:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:44,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024881113320589066, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017973411828279495, 'eval_loss_2': 0.00690770149230957, 'eval_loss_3': -18.261598587036133, 'eval_loss_4': 0.9705579876899719, 'epoch': 4.48}
{'loss': 0.0815, 'grad_norm': 13.150093078613281, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.07116484642028809, 'loss_2': 0.0103607177734375, 'loss_3': -15.673604011535645, 'loss_4': 0.5770314931869507, 'epoch': 4.48}
{'loss': 0.0247, 'grad_norm': 11.445701599121094, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.021451881155371666, 'loss_2': 0.00321197509765625, 'loss_3': -15.946504592895508, 'loss_4': 1.0019179582595825, 'epoch': 4.49}
{'loss': 0.0417, 'grad_norm': 15.13851261138916, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.038300007581710815, 'loss_2': 0.0033931732177734375, 'loss_3': -15.682708740234375, 'loss_4': 0.8506884574890137, 'epoch': 4.49}
{'loss': 0.0248, 'grad_norm': 7.22772741317749, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.018296027556061745, 'loss_2': 0.006504058837890625, 'loss_3': -15.866792678833008, 'loss_4': 0.8160795569419861, 'epoch': 4.5}
{'loss': 0.0422, 'grad_norm': 20.72723960876465, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.042218081653118134, 'loss_2': 3.2782554626464844e-06, 'loss_3': -15.757071495056152, 'loss_4': 0.7282041311264038, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 12:39:44,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:44,324 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:38<1:15:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:51,664 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01939036324620247, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.55, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01596282795071602, 'eval_loss_2': 0.00342753529548645, 'eval_loss_3': -18.280994415283203, 'eval_loss_4': 0.7727068662643433, 'epoch': 4.51}
{'loss': 0.0223, 'grad_norm': 5.8257670402526855, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.012817681767046452, 'loss_2': 0.0094757080078125, 'loss_3': -15.929938316345215, 'loss_4': 1.000392198562622, 'epoch': 4.51}
{'loss': 0.0246, 'grad_norm': 7.181848526000977, 'learning_rate': 2.55e-05, 'loss_1': 0.019605325534939766, 'loss_2': 0.00499725341796875, 'loss_3': -16.0963134765625, 'loss_4': 0.6614347100257874, 'epoch': 4.52}
{'loss': 0.0217, 'grad_norm': 8.796464920043945, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.016477350145578384, 'loss_2': 0.005260467529296875, 'loss_3': -15.987383842468262, 'loss_4': 0.38934192061424255, 'epoch': 4.52}
{'loss': 0.2235, 'grad_norm': 34.51529312133789, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.22269535064697266, 'loss_2': 0.0008134841918945312, 'loss_3': -15.57426929473877, 'loss_4': 0.7723450064659119, 'epoch': 4.53}
{'loss': 0.0335, 'grad_norm': 9.505630493164062, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.02670380286872387, 'loss_2': 0.00684356689453125, 'loss_3': -15.704305648803711, 'loss_4': 0.7811048030853271, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 12:39:51,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:51,664 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:46<1:15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:59,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019381746649742126, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.54, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015877587720751762, 'eval_loss_2': 0.003504157066345215, 'eval_loss_3': -18.281349182128906, 'eval_loss_4': 0.5433686375617981, 'epoch': 4.53}
{'loss': 0.0441, 'grad_norm': 14.117779731750488, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.041639167815446854, 'loss_2': 0.00250244140625, 'loss_3': -15.944589614868164, 'loss_4': 0.29308459162712097, 'epoch': 4.54}
{'loss': 0.038, 'grad_norm': 9.758255004882812, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.03221198916435242, 'loss_2': 0.005756378173828125, 'loss_3': -15.898531913757324, 'loss_4': 0.864617645740509, 'epoch': 4.55}
{'loss': 0.0243, 'grad_norm': 7.077280044555664, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.014172065071761608, 'loss_2': 0.010101318359375, 'loss_3': -15.872825622558594, 'loss_4': 0.3678375780582428, 'epoch': 4.55}
{'loss': 0.0435, 'grad_norm': 12.773028373718262, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.0327867828309536, 'loss_2': 0.01074981689453125, 'loss_3': -16.190357208251953, 'loss_4': 0.959496021270752, 'epoch': 4.56}
{'loss': 0.0325, 'grad_norm': 12.812941551208496, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.030509455129504204, 'loss_2': 0.00196075439453125, 'loss_3': -15.782851219177246, 'loss_4': 0.5671012997627258, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 12:39:59,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:59,010 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:53<1:15:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:06,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019379854202270508, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014928534626960754, 'eval_loss_2': 0.004451319575309753, 'eval_loss_3': -18.312759399414062, 'eval_loss_4': 0.8192868232727051, 'epoch': 4.56}
{'loss': 0.0258, 'grad_norm': 9.437466621398926, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.021985899657011032, 'loss_2': 0.0038127899169921875, 'loss_3': -16.080923080444336, 'loss_4': 0.6659808158874512, 'epoch': 4.57}
{'loss': 0.0157, 'grad_norm': 6.685665130615234, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.011779455468058586, 'loss_2': 0.0039215087890625, 'loss_3': -16.037525177001953, 'loss_4': 1.0816233158111572, 'epoch': 4.58}
{'loss': 0.0217, 'grad_norm': 11.487236976623535, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.019844627007842064, 'loss_2': 0.0018062591552734375, 'loss_3': -16.243366241455078, 'loss_4': 0.8659793138504028, 'epoch': 4.58}
{'loss': 0.0656, 'grad_norm': 22.30390167236328, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.05785490572452545, 'loss_2': 0.00772857666015625, 'loss_3': -16.107542037963867, 'loss_4': 1.704471230506897, 'epoch': 4.59}
{'loss': 0.0278, 'grad_norm': 7.7666449546813965, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.026249492540955544, 'loss_2': 0.0015926361083984375, 'loss_3': -16.0958194732666, 'loss_4': 1.4623371362686157, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 12:40:06,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:06,364 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [20:00<1:15:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:13,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019244197756052017, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01514691486954689, 'eval_loss_2': 0.004097282886505127, 'eval_loss_3': -18.31076431274414, 'eval_loss_4': 1.2231422662734985, 'epoch': 4.59}
{'loss': 0.0547, 'grad_norm': 22.377357482910156, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.043557506054639816, 'loss_2': 0.01110076904296875, 'loss_3': -16.141767501831055, 'loss_4': 1.7873064279556274, 'epoch': 4.6}
{'loss': 0.0167, 'grad_norm': 6.614649772644043, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.01618117466568947, 'loss_2': 0.000476837158203125, 'loss_3': -16.013648986816406, 'loss_4': 1.5301405191421509, 'epoch': 4.6}
{'loss': 0.0295, 'grad_norm': 9.063880920410156, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.022967200726270676, 'loss_2': 0.00655364990234375, 'loss_3': -16.159814834594727, 'loss_4': 0.8423209190368652, 'epoch': 4.61}
{'loss': 0.0186, 'grad_norm': 5.462393283843994, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.00979732908308506, 'loss_2': 0.00876617431640625, 'loss_3': -16.066476821899414, 'loss_4': 1.3922598361968994, 'epoch': 4.62}
{'loss': 0.0234, 'grad_norm': 8.198531150817871, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.023072903975844383, 'loss_2': 0.0003495216369628906, 'loss_3': -16.18849754333496, 'loss_4': 1.8936570882797241, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 12:40:13,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:13,709 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:08<1:15:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:21,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020862698554992676, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017408045008778572, 'eval_loss_2': 0.0034546516835689545, 'eval_loss_3': -18.291349411010742, 'eval_loss_4': 1.4773002862930298, 'epoch': 4.62}
{'loss': 0.0216, 'grad_norm': 8.403157234191895, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.017799722030758858, 'loss_2': 0.003841400146484375, 'loss_3': -16.064083099365234, 'loss_4': 1.6521267890930176, 'epoch': 4.63}
{'loss': 0.022, 'grad_norm': 9.474403381347656, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.021545683965086937, 'loss_2': 0.0004949569702148438, 'loss_3': -16.021556854248047, 'loss_4': 1.461901068687439, 'epoch': 4.63}
{'loss': 0.0301, 'grad_norm': 10.11546802520752, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.027495622634887695, 'loss_2': 0.0025653839111328125, 'loss_3': -16.083459854125977, 'loss_4': 1.698216199874878, 'epoch': 4.64}
{'loss': 0.0157, 'grad_norm': 6.512239933013916, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.013434750027954578, 'loss_2': 0.0022373199462890625, 'loss_3': -15.981653213500977, 'loss_4': 1.797368049621582, 'epoch': 4.65}
{'loss': 0.0287, 'grad_norm': 7.375857353210449, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.019873471930623055, 'loss_2': 0.0088348388671875, 'loss_3': -16.169416427612305, 'loss_4': 1.391085147857666, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 12:40:21,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:21,056 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:15<1:15:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:28,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021555468440055847, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017364181578159332, 'eval_loss_2': 0.004191286861896515, 'eval_loss_3': -18.315967559814453, 'eval_loss_4': 1.6387794017791748, 'epoch': 4.65}
{'loss': 0.0198, 'grad_norm': 7.262240409851074, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.019657958298921585, 'loss_2': 0.00016570091247558594, 'loss_3': -16.08758544921875, 'loss_4': 1.08238685131073, 'epoch': 4.66}
{'loss': 0.0563, 'grad_norm': 14.0446138381958, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.05019413307309151, 'loss_2': 0.006084442138671875, 'loss_3': -16.13223648071289, 'loss_4': 1.741468906402588, 'epoch': 4.66}
{'loss': 0.0212, 'grad_norm': 7.083219528198242, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.018231645226478577, 'loss_2': 0.00301361083984375, 'loss_3': -16.271066665649414, 'loss_4': 1.8837119340896606, 'epoch': 4.67}
{'loss': 0.0216, 'grad_norm': 6.348553657531738, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.01394846010953188, 'loss_2': 0.00769805908203125, 'loss_3': -16.155284881591797, 'loss_4': 1.643683671951294, 'epoch': 4.67}
{'loss': 0.1098, 'grad_norm': 13.698973655700684, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.10361966490745544, 'loss_2': 0.00620269775390625, 'loss_3': -15.762645721435547, 'loss_4': 1.8641363382339478, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 12:40:28,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:28,408 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:22<1:15:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:35,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019900061190128326, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015778647735714912, 'eval_loss_2': 0.004121415317058563, 'eval_loss_3': -18.293710708618164, 'eval_loss_4': 1.5910136699676514, 'epoch': 4.68}
{'loss': 0.0276, 'grad_norm': 8.838629722595215, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.026357552036643028, 'loss_2': 0.001247406005859375, 'loss_3': -15.944219589233398, 'loss_4': 1.8795363903045654, 'epoch': 4.69}
{'loss': 0.023, 'grad_norm': 5.858124256134033, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.014143177308142185, 'loss_2': 0.00885009765625, 'loss_3': -15.849872589111328, 'loss_4': 1.7019927501678467, 'epoch': 4.69}
{'loss': 0.0273, 'grad_norm': 6.581929683685303, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.01806149259209633, 'loss_2': 0.0092010498046875, 'loss_3': -16.06912612915039, 'loss_4': 1.5520695447921753, 'epoch': 4.7}
{'loss': 0.0406, 'grad_norm': 9.430007934570312, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.030490269884467125, 'loss_2': 0.01007843017578125, 'loss_3': -16.11362648010254, 'loss_4': 2.1268084049224854, 'epoch': 4.7}
{'loss': 0.0442, 'grad_norm': 15.72776985168457, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.04335533827543259, 'loss_2': 0.0008759498596191406, 'loss_3': -16.154346466064453, 'loss_4': 1.1436066627502441, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 12:40:35,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:35,761 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:30<1:15:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:43,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020726405084133148, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.245, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015557311475276947, 'eval_loss_2': 0.005169093608856201, 'eval_loss_3': -18.255353927612305, 'eval_loss_4': 1.3503092527389526, 'epoch': 4.71}
{'loss': 0.0399, 'grad_norm': 12.055435180664062, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.03253593295812607, 'loss_2': 0.007354736328125, 'loss_3': -15.916231155395508, 'loss_4': 1.2174351215362549, 'epoch': 4.72}
{'loss': 0.0408, 'grad_norm': 13.4222993850708, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.03732921555638313, 'loss_2': 0.003505706787109375, 'loss_3': -16.1624813079834, 'loss_4': 1.35097336769104, 'epoch': 4.72}
{'loss': 0.0319, 'grad_norm': 10.901275634765625, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.026081671938300133, 'loss_2': 0.005832672119140625, 'loss_3': -16.132110595703125, 'loss_4': 1.4958065748214722, 'epoch': 4.73}
{'loss': 0.0238, 'grad_norm': 9.597834587097168, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.023388072848320007, 'loss_2': 0.000438690185546875, 'loss_3': -15.955660820007324, 'loss_4': 1.1030080318450928, 'epoch': 4.73}
{'loss': 0.02, 'grad_norm': 8.267606735229492, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.01887102797627449, 'loss_2': 0.0011234283447265625, 'loss_3': -16.017351150512695, 'loss_4': 0.9755730032920837, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 12:40:43,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:43,114 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:37<1:15:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:50,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024821937084197998, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.019768772646784782, 'eval_loss_2': 0.005053162574768066, 'eval_loss_3': -18.250919342041016, 'eval_loss_4': 1.0963106155395508, 'epoch': 4.74}
{'loss': 0.047, 'grad_norm': 24.306034088134766, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.0396423265337944, 'loss_2': 0.007366180419921875, 'loss_3': -16.01947784423828, 'loss_4': 1.4510385990142822, 'epoch': 4.74}
{'loss': 0.0284, 'grad_norm': 6.474941730499268, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.017647869884967804, 'loss_2': 0.010711669921875, 'loss_3': -16.130882263183594, 'loss_4': 0.9842586517333984, 'epoch': 4.75}
{'loss': 0.024, 'grad_norm': 8.648446083068848, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.017653102055191994, 'loss_2': 0.006317138671875, 'loss_3': -16.04037094116211, 'loss_4': 1.3090698719024658, 'epoch': 4.76}
{'loss': 0.0319, 'grad_norm': 8.482147216796875, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.028052734211087227, 'loss_2': 0.0038909912109375, 'loss_3': -16.04134178161621, 'loss_4': 0.9633787274360657, 'epoch': 4.76}
{'loss': 0.0425, 'grad_norm': 12.26434326171875, 'learning_rate': 2.525e-05, 'loss_1': 0.031094912439584732, 'loss_2': 0.01143646240234375, 'loss_3': -15.979660034179688, 'loss_4': 1.168626308441162, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 12:40:50,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:50,468 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:44<1:14:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:57,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02607458271086216, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02190142311155796, 'eval_loss_2': 0.004173159599304199, 'eval_loss_3': -18.280241012573242, 'eval_loss_4': 0.9987233877182007, 'epoch': 4.77}
{'loss': 0.042, 'grad_norm': 12.148113250732422, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.033163633197546005, 'loss_2': 0.008819580078125, 'loss_3': -15.934328079223633, 'loss_4': 0.41330182552337646, 'epoch': 4.77}
{'loss': 0.0228, 'grad_norm': 6.7820868492126465, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.015348897315561771, 'loss_2': 0.0074920654296875, 'loss_3': -16.14773178100586, 'loss_4': 0.7671817541122437, 'epoch': 4.78}
{'loss': 0.0542, 'grad_norm': 19.81751251220703, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.050526976585388184, 'loss_2': 0.00366973876953125, 'loss_3': -15.994150161743164, 'loss_4': 1.4910223484039307, 'epoch': 4.78}
{'loss': 0.0386, 'grad_norm': 12.699437141418457, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.031128304079174995, 'loss_2': 0.00749969482421875, 'loss_3': -16.168039321899414, 'loss_4': 0.7059968113899231, 'epoch': 4.79}
{'loss': 0.0536, 'grad_norm': 23.508241653442383, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.051615580916404724, 'loss_2': 0.00194549560546875, 'loss_3': -15.86519718170166, 'loss_4': 0.8908894062042236, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 12:40:57,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:57,816 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:52<1:14:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:05,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03253590315580368, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01921497844159603, 'eval_loss_2': 0.0133209228515625, 'eval_loss_3': -18.27794647216797, 'eval_loss_4': 0.9348119497299194, 'epoch': 4.8}
{'loss': 0.0311, 'grad_norm': 8.224220275878906, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.02261853963136673, 'loss_2': 0.00844573974609375, 'loss_3': -15.997587203979492, 'loss_4': 0.7715561389923096, 'epoch': 4.8}
{'loss': 0.082, 'grad_norm': 22.544822692871094, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.06361599266529083, 'loss_2': 0.018402099609375, 'loss_3': -16.00367546081543, 'loss_4': 1.3966968059539795, 'epoch': 4.81}
{'loss': 0.0554, 'grad_norm': 12.449956893920898, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.039343368262052536, 'loss_2': 0.01605224609375, 'loss_3': -16.001163482666016, 'loss_4': 1.011223316192627, 'epoch': 4.81}
{'loss': 0.0725, 'grad_norm': 17.965980529785156, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.05733094736933708, 'loss_2': 0.01519775390625, 'loss_3': -15.9960298538208, 'loss_4': 1.2724130153656006, 'epoch': 4.82}
{'loss': 0.0468, 'grad_norm': 10.153818130493164, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.03398217260837555, 'loss_2': 0.0128173828125, 'loss_3': -15.956396102905273, 'loss_4': 1.1808888912200928, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 12:41:05,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:05,151 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:59<1:14:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:12,494 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0379885658621788, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.024730585515499115, 'eval_loss_2': 0.013257980346679688, 'eval_loss_3': -18.209613800048828, 'eval_loss_4': 0.9991258978843689, 'epoch': 4.83}
{'loss': 0.0386, 'grad_norm': 14.4253511428833, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.022423546761274338, 'loss_2': 0.016204833984375, 'loss_3': -16.03191375732422, 'loss_4': 1.0433214902877808, 'epoch': 4.83}
{'loss': 0.0278, 'grad_norm': 9.459444999694824, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.026750726625323296, 'loss_2': 0.0010986328125, 'loss_3': -16.13046646118164, 'loss_4': 1.1117334365844727, 'epoch': 4.84}
{'loss': 0.0999, 'grad_norm': 38.00955581665039, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.085906021296978, 'loss_2': 0.01395416259765625, 'loss_3': -15.819866180419922, 'loss_4': 0.9157052636146545, 'epoch': 4.84}
{'loss': 0.0363, 'grad_norm': 11.326208114624023, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.03154819831252098, 'loss_2': 0.00472259521484375, 'loss_3': -15.984285354614258, 'loss_4': 0.9201539754867554, 'epoch': 4.85}
{'loss': 0.0522, 'grad_norm': 17.405319213867188, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.0501878447830677, 'loss_2': 0.002025604248046875, 'loss_3': -15.919276237487793, 'loss_4': 1.093522310256958, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 12:41:12,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:12,495 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:06<1:14:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:19,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034740786999464035, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02903030440211296, 'eval_loss_2': 0.005710482597351074, 'eval_loss_3': -18.160245895385742, 'eval_loss_4': 1.028633952140808, 'epoch': 4.85}
{'loss': 0.0375, 'grad_norm': 10.576408386230469, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.0355517715215683, 'loss_2': 0.001934051513671875, 'loss_3': -16.051668167114258, 'loss_4': 0.9438688158988953, 'epoch': 4.86}
{'loss': 0.0572, 'grad_norm': 16.36313819885254, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.05267714336514473, 'loss_2': 0.00447845458984375, 'loss_3': -16.009876251220703, 'loss_4': 0.9780441522598267, 'epoch': 4.87}
{'loss': 0.0606, 'grad_norm': 12.624629020690918, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.060137487947940826, 'loss_2': 0.0005049705505371094, 'loss_3': -15.788656234741211, 'loss_4': 1.0200210809707642, 'epoch': 4.87}
{'loss': 0.0298, 'grad_norm': 9.081417083740234, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.024920938536524773, 'loss_2': 0.0049285888671875, 'loss_3': -16.024354934692383, 'loss_4': 0.7282576560974121, 'epoch': 4.88}
{'loss': 0.032, 'grad_norm': 6.196141242980957, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.02163008227944374, 'loss_2': 0.0103912353515625, 'loss_3': -15.927022933959961, 'loss_4': 0.9080564975738525, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 12:41:19,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:19,839 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:14<1:14:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:27,196 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03954363614320755, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.885, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0354621484875679, 'eval_loss_2': 0.0040814876556396484, 'eval_loss_3': -18.103029251098633, 'eval_loss_4': 1.0788646936416626, 'epoch': 4.88}
{'loss': 0.0503, 'grad_norm': 18.44839859008789, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.04520535096526146, 'loss_2': 0.00513458251953125, 'loss_3': -15.912240982055664, 'loss_4': 1.1135181188583374, 'epoch': 4.89}
{'loss': 0.0203, 'grad_norm': 6.307353496551514, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.016773350536823273, 'loss_2': 0.003559112548828125, 'loss_3': -16.04132652282715, 'loss_4': 1.0016553401947021, 'epoch': 4.9}
{'loss': 0.0192, 'grad_norm': 6.7575883865356445, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.018333764746785164, 'loss_2': 0.0008392333984375, 'loss_3': -16.09819793701172, 'loss_4': 1.0680582523345947, 'epoch': 4.9}
{'loss': 0.0325, 'grad_norm': 10.092536926269531, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.02746320702135563, 'loss_2': 0.005035400390625, 'loss_3': -16.05868911743164, 'loss_4': 0.7836453914642334, 'epoch': 4.91}
{'loss': 0.0287, 'grad_norm': 11.263094902038574, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.027321260422468185, 'loss_2': 0.0013561248779296875, 'loss_3': -15.986795425415039, 'loss_4': 1.0847405195236206, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 12:41:27,196 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:27,196 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:21<1:14:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:34,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03492698073387146, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.030261248350143433, 'eval_loss_2': 0.004665732383728027, 'eval_loss_3': -18.119945526123047, 'eval_loss_4': 1.0723918676376343, 'epoch': 4.91}
{'loss': 0.0336, 'grad_norm': 12.062921524047852, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.025917891412973404, 'loss_2': 0.0076446533203125, 'loss_3': -15.880681991577148, 'loss_4': 0.7773720026016235, 'epoch': 4.92}
{'loss': 0.0643, 'grad_norm': 19.275705337524414, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.06361066550016403, 'loss_2': 0.0007047653198242188, 'loss_3': -16.030302047729492, 'loss_4': 0.9361200332641602, 'epoch': 4.92}
{'loss': 0.0299, 'grad_norm': 15.057038307189941, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.02555433288216591, 'loss_2': 0.00434112548828125, 'loss_3': -16.115938186645508, 'loss_4': 1.1058162450790405, 'epoch': 4.93}
{'loss': 0.0405, 'grad_norm': 12.520737648010254, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.03529880940914154, 'loss_2': 0.005218505859375, 'loss_3': -16.216041564941406, 'loss_4': 0.6914454698562622, 'epoch': 4.94}
{'loss': 0.0244, 'grad_norm': 8.599451065063477, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.022138118743896484, 'loss_2': 0.0022754669189453125, 'loss_3': -15.870637893676758, 'loss_4': 0.7308072447776794, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 12:41:34,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:34,542 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:28<1:14:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:41,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027379628270864487, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.779, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.022092485800385475, 'eval_loss_2': 0.005287140607833862, 'eval_loss_3': -18.210878372192383, 'eval_loss_4': 0.9537490010261536, 'epoch': 4.94}
{'loss': 0.0385, 'grad_norm': 11.400103569030762, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.0272048432379961, 'loss_2': 0.0112762451171875, 'loss_3': -16.106164932250977, 'loss_4': 1.2714402675628662, 'epoch': 4.95}
{'loss': 0.0326, 'grad_norm': 8.836115837097168, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.027289314195513725, 'loss_2': 0.0053558349609375, 'loss_3': -15.926673889160156, 'loss_4': 0.9334050416946411, 'epoch': 4.95}
{'loss': 0.0138, 'grad_norm': 8.770597457885742, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.013450047001242638, 'loss_2': 0.0003478527069091797, 'loss_3': -16.168575286865234, 'loss_4': 0.4187944829463959, 'epoch': 4.96}
{'loss': 0.0422, 'grad_norm': 20.501651763916016, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.0409923754632473, 'loss_2': 0.001224517822265625, 'loss_3': -15.939262390136719, 'loss_4': 0.9143041372299194, 'epoch': 4.97}
{'loss': 0.0277, 'grad_norm': 9.640009880065918, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.021285509690642357, 'loss_2': 0.00638580322265625, 'loss_3': -16.203956604003906, 'loss_4': 0.5262850522994995, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 12:41:41,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:41,897 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:35<1:06:52,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 12:41:48,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023598093539476395, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018858367577195168, 'eval_loss_2': 0.004739724099636078, 'eval_loss_3': -18.294734954833984, 'eval_loss_4': 0.9829395413398743, 'epoch': 4.97}
{'loss': 0.0655, 'grad_norm': 16.964496612548828, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.059712883085012436, 'loss_2': 0.00574493408203125, 'loss_3': -16.0897159576416, 'loss_4': 0.5041211843490601, 'epoch': 4.98}
{'loss': 0.0638, 'grad_norm': 20.58850860595703, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.05748625472187996, 'loss_2': 0.00635528564453125, 'loss_3': -16.298187255859375, 'loss_4': 1.136712670326233, 'epoch': 4.98}
{'loss': 0.0419, 'grad_norm': 12.418397903442383, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.03679334744811058, 'loss_2': 0.005153656005859375, 'loss_3': -16.15558433532715, 'loss_4': 0.8730818033218384, 'epoch': 4.99}
{'loss': 0.0267, 'grad_norm': 6.872686386108398, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.025268279016017914, 'loss_2': 0.001415252685546875, 'loss_3': -16.17657470703125, 'loss_4': 1.5746405124664307, 'epoch': 4.99}
{'loss': 0.0183, 'grad_norm': 8.744635581970215, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.015859082341194153, 'loss_2': 0.00246429443359375, 'loss_3': -16.196508407592773, 'loss_4': 0.8997708559036255, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 12:41:48,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:48,892 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:43<1:13:15,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:41:56,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024206701666116714, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.020437484607100487, 'eval_loss_2': 0.003769218921661377, 'eval_loss_3': -18.321155548095703, 'eval_loss_4': 0.9146870374679565, 'epoch': 5.0}
{'loss': 0.0498, 'grad_norm': 10.375385284423828, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.04480345919728279, 'loss_2': 0.004985809326171875, 'loss_3': -16.041685104370117, 'loss_4': 1.2755094766616821, 'epoch': 5.01}
{'loss': 0.0326, 'grad_norm': 8.218949317932129, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.023158499971032143, 'loss_2': 0.009490966796875, 'loss_3': -16.331344604492188, 'loss_4': 1.1591458320617676, 'epoch': 5.01}
{'loss': 0.0462, 'grad_norm': 10.09653091430664, 'learning_rate': 2.5e-05, 'loss_1': 0.04109984263777733, 'loss_2': 0.005107879638671875, 'loss_3': -16.33749008178711, 'loss_4': 0.7870073318481445, 'epoch': 5.02}
{'loss': 0.0402, 'grad_norm': 10.559356689453125, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.03087001107633114, 'loss_2': 0.0093536376953125, 'loss_3': -15.98468017578125, 'loss_4': 0.9135164022445679, 'epoch': 5.02}
{'loss': 0.024, 'grad_norm': 7.513443946838379, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.021132463589310646, 'loss_2': 0.002899169921875, 'loss_3': -16.36359214782715, 'loss_4': 0.596690833568573, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 12:41:56,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:56,282 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:50<1:14:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:03,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018452972173690796, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015390576794743538, 'eval_loss_2': 0.0030623972415924072, 'eval_loss_3': -18.32118797302246, 'eval_loss_4': 0.4788069427013397, 'epoch': 5.03}
{'loss': 0.0412, 'grad_norm': 11.501792907714844, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.03916159272193909, 'loss_2': 0.0020294189453125, 'loss_3': -16.098535537719727, 'loss_4': 0.37541571259498596, 'epoch': 5.03}
{'loss': 0.0269, 'grad_norm': 6.940279006958008, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.025992998853325844, 'loss_2': 0.0009126663208007812, 'loss_3': -16.099910736083984, 'loss_4': -0.10899505019187927, 'epoch': 5.04}
{'loss': 0.039, 'grad_norm': 9.05006217956543, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.02870950847864151, 'loss_2': 0.01031494140625, 'loss_3': -16.123964309692383, 'loss_4': 0.5821753144264221, 'epoch': 5.05}
{'loss': 0.0681, 'grad_norm': 9.141406059265137, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.06617631018161774, 'loss_2': 0.0018825531005859375, 'loss_3': -16.184539794921875, 'loss_4': 0.86420738697052, 'epoch': 5.05}
{'loss': 0.0355, 'grad_norm': 10.224153518676758, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.03189089894294739, 'loss_2': 0.00362396240234375, 'loss_3': -16.049150466918945, 'loss_4': 0.3697677552700043, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 12:42:03,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:03,630 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:58<1:14:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:10,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019401172176003456, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016053104773163795, 'eval_loss_2': 0.0033480674028396606, 'eval_loss_3': -18.323772430419922, 'eval_loss_4': 0.15110868215560913, 'epoch': 5.06}
{'loss': 0.0336, 'grad_norm': 9.170853614807129, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.032881252467632294, 'loss_2': 0.0006875991821289062, 'loss_3': -16.057613372802734, 'loss_4': 0.4770694077014923, 'epoch': 5.06}
{'loss': 0.0382, 'grad_norm': 8.436113357543945, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.03483803570270538, 'loss_2': 0.0033512115478515625, 'loss_3': -15.881402969360352, 'loss_4': -0.26409995555877686, 'epoch': 5.07}
{'loss': 0.0695, 'grad_norm': 40.26697540283203, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.06286802887916565, 'loss_2': 0.006656646728515625, 'loss_3': -16.07940101623535, 'loss_4': -0.23540112376213074, 'epoch': 5.08}
{'loss': 0.0549, 'grad_norm': 11.961163520812988, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.047063786536455154, 'loss_2': 0.00778961181640625, 'loss_3': -16.22718620300293, 'loss_4': -0.40646782517433167, 'epoch': 5.08}
{'loss': 0.0276, 'grad_norm': 8.972676277160645, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.023145170882344246, 'loss_2': 0.0044097900390625, 'loss_3': -16.0877742767334, 'loss_4': -0.023240238428115845, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 12:42:10,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:10,978 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:05<1:14:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:18,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019891291856765747, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.243, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01449927780777216, 'eval_loss_2': 0.005392014980316162, 'eval_loss_3': -18.32799530029297, 'eval_loss_4': 0.03405632823705673, 'epoch': 5.09}
{'loss': 0.0468, 'grad_norm': 14.203845977783203, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.039328522980213165, 'loss_2': 0.0074462890625, 'loss_3': -16.103099822998047, 'loss_4': 0.10826864093542099, 'epoch': 5.09}
{'loss': 0.0225, 'grad_norm': 7.650789260864258, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.02056550234556198, 'loss_2': 0.0019588470458984375, 'loss_3': -16.102340698242188, 'loss_4': -0.04192856699228287, 'epoch': 5.1}
{'loss': 0.0795, 'grad_norm': 22.250425338745117, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.07750073820352554, 'loss_2': 0.0019502639770507812, 'loss_3': -15.934043884277344, 'loss_4': 0.19768306612968445, 'epoch': 5.1}
{'loss': 0.0213, 'grad_norm': 6.559138774871826, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.020856419578194618, 'loss_2': 0.00047206878662109375, 'loss_3': -15.929831504821777, 'loss_4': -0.2839442193508148, 'epoch': 5.11}
{'loss': 0.0301, 'grad_norm': 11.727258682250977, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.026158422231674194, 'loss_2': 0.003978729248046875, 'loss_3': -16.205156326293945, 'loss_4': 0.016562752425670624, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 12:42:18,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:18,323 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:12<1:13:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:25,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021455910056829453, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01424124650657177, 'eval_loss_2': 0.007214665412902832, 'eval_loss_3': -18.295482635498047, 'eval_loss_4': 0.11141513288021088, 'epoch': 5.12}
{'loss': 0.0358, 'grad_norm': 13.150909423828125, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.030747126787900925, 'loss_2': 0.00506591796875, 'loss_3': -15.937545776367188, 'loss_4': 0.5019752383232117, 'epoch': 5.12}
{'loss': 0.0507, 'grad_norm': 15.260771751403809, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.049012210220098495, 'loss_2': 0.0016679763793945312, 'loss_3': -16.21112632751465, 'loss_4': 0.014278173446655273, 'epoch': 5.13}
{'loss': 0.0482, 'grad_norm': 14.134530067443848, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.03362774848937988, 'loss_2': 0.0145721435546875, 'loss_3': -15.808418273925781, 'loss_4': 0.34458550810813904, 'epoch': 5.13}
{'loss': 0.1675, 'grad_norm': 26.792224884033203, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.15222643315792084, 'loss_2': 0.0153045654296875, 'loss_3': -15.887985229492188, 'loss_4': 0.7930946350097656, 'epoch': 5.14}
{'loss': 0.0565, 'grad_norm': 15.855155944824219, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.041503023356199265, 'loss_2': 0.015045166015625, 'loss_3': -16.034202575683594, 'loss_4': -0.1985062062740326, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 12:42:25,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:25,668 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:20<1:13:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:33,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03151167929172516, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01460685208439827, 'eval_loss_2': 0.016904830932617188, 'eval_loss_3': -18.266193389892578, 'eval_loss_4': 0.37189781665802, 'epoch': 5.15}
{'loss': 0.0527, 'grad_norm': 10.905413627624512, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.0326169915497303, 'loss_2': 0.0201263427734375, 'loss_3': -16.11501121520996, 'loss_4': 0.13531088829040527, 'epoch': 5.15}
{'loss': 0.0533, 'grad_norm': 15.962868690490723, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.03953557461500168, 'loss_2': 0.0137481689453125, 'loss_3': -16.2436466217041, 'loss_4': 0.24295133352279663, 'epoch': 5.16}
{'loss': 0.0417, 'grad_norm': 10.325254440307617, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.024157339707016945, 'loss_2': 0.01751708984375, 'loss_3': -15.91588020324707, 'loss_4': 0.23309196531772614, 'epoch': 5.16}
{'loss': 0.0403, 'grad_norm': 6.926324844360352, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.021295759826898575, 'loss_2': 0.01898193359375, 'loss_3': -16.07277488708496, 'loss_4': 0.7943674325942993, 'epoch': 5.17}
{'loss': 0.0234, 'grad_norm': 5.248073101043701, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.016015997156500816, 'loss_2': 0.00738525390625, 'loss_3': -15.994125366210938, 'loss_4': -0.002744220197200775, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 12:42:33,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:33,018 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:27<1:13:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:40,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027073318138718605, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.184, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017599040642380714, 'eval_loss_2': 0.00947427749633789, 'eval_loss_3': -18.19344711303711, 'eval_loss_4': 0.5999097228050232, 'epoch': 5.17}
{'loss': 0.0304, 'grad_norm': 7.10122537612915, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.018586723133921623, 'loss_2': 0.01177978515625, 'loss_3': -16.007022857666016, 'loss_4': 0.44821274280548096, 'epoch': 5.18}
{'loss': 0.0422, 'grad_norm': 13.89759635925293, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.039784468710422516, 'loss_2': 0.0024566650390625, 'loss_3': -15.964201927185059, 'loss_4': 1.0911178588867188, 'epoch': 5.19}
{'loss': 0.0232, 'grad_norm': 9.170546531677246, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.022776208817958832, 'loss_2': 0.0004210472106933594, 'loss_3': -15.817424774169922, 'loss_4': 1.006096363067627, 'epoch': 5.19}
{'loss': 0.0162, 'grad_norm': 6.072453022003174, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.01447337120771408, 'loss_2': 0.001739501953125, 'loss_3': -15.916053771972656, 'loss_4': 0.6424823999404907, 'epoch': 5.2}
{'loss': 0.0278, 'grad_norm': 7.508254051208496, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.019921334460377693, 'loss_2': 0.0079193115234375, 'loss_3': -15.914034843444824, 'loss_4': 0.4596974849700928, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 12:42:40,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:40,365 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:34<1:13:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:47,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02343318983912468, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.677, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.020092394202947617, 'eval_loss_2': 0.003340795636177063, 'eval_loss_3': -18.171812057495117, 'eval_loss_4': 0.77916020154953, 'epoch': 5.2}
{'loss': 0.0257, 'grad_norm': 9.701272964477539, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.02528696320950985, 'loss_2': 0.00042366981506347656, 'loss_3': -15.850854873657227, 'loss_4': 1.0375174283981323, 'epoch': 5.21}
{'loss': 0.148, 'grad_norm': 36.88238525390625, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.14157934486865997, 'loss_2': 0.006443023681640625, 'loss_3': -15.932924270629883, 'loss_4': 1.0026755332946777, 'epoch': 5.22}
{'loss': 0.0309, 'grad_norm': 8.976448059082031, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.028148364275693893, 'loss_2': 0.00279998779296875, 'loss_3': -15.79748821258545, 'loss_4': 1.051802158355713, 'epoch': 5.22}
{'loss': 0.0509, 'grad_norm': 14.555804252624512, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.047420989722013474, 'loss_2': 0.003429412841796875, 'loss_3': -15.904425621032715, 'loss_4': 0.9397600889205933, 'epoch': 5.23}
{'loss': 0.1258, 'grad_norm': 22.6263484954834, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.11895452439785004, 'loss_2': 0.0068206787109375, 'loss_3': -15.978997230529785, 'loss_4': 0.8674536943435669, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 12:42:47,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:47,725 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:42<1:13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:55,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020463265478610992, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017275281250476837, 'eval_loss_2': 0.0031879842281341553, 'eval_loss_3': -18.20879554748535, 'eval_loss_4': 0.9512197971343994, 'epoch': 5.23}
{'loss': 0.0185, 'grad_norm': 6.008251667022705, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.0115591399371624, 'loss_2': 0.006893157958984375, 'loss_3': -16.0789794921875, 'loss_4': 1.0538129806518555, 'epoch': 5.24}
{'loss': 0.0642, 'grad_norm': 14.613834381103516, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.054366983473300934, 'loss_2': 0.00981903076171875, 'loss_3': -16.033462524414062, 'loss_4': 0.7685848474502563, 'epoch': 5.24}
{'loss': 0.0207, 'grad_norm': 6.748078346252441, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.012539028190076351, 'loss_2': 0.0081787109375, 'loss_3': -16.14756965637207, 'loss_4': 0.9863322377204895, 'epoch': 5.25}
{'loss': 0.0426, 'grad_norm': 12.189437866210938, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.03830927610397339, 'loss_2': 0.00428009033203125, 'loss_3': -15.883230209350586, 'loss_4': 0.7924094796180725, 'epoch': 5.26}
{'loss': 0.0333, 'grad_norm': 7.254333019256592, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.027280408889055252, 'loss_2': 0.00597381591796875, 'loss_3': -16.09689712524414, 'loss_4': 0.9076068997383118, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 12:42:55,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:55,072 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:49<1:13:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:02,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020248496904969215, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.017089517787098885, 'eval_loss_2': 0.003158979117870331, 'eval_loss_3': -18.214221954345703, 'eval_loss_4': 0.9566881060600281, 'epoch': 5.26}
{'loss': 0.0345, 'grad_norm': 7.9637451171875, 'learning_rate': 2.475e-05, 'loss_1': 0.029041675850749016, 'loss_2': 0.0054931640625, 'loss_3': -16.04221534729004, 'loss_4': 0.37623143196105957, 'epoch': 5.27}
{'loss': 0.0354, 'grad_norm': 13.360332489013672, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.03365550935268402, 'loss_2': 0.00174713134765625, 'loss_3': -16.085731506347656, 'loss_4': 1.4364086389541626, 'epoch': 5.27}
{'loss': 0.0209, 'grad_norm': 6.571743488311768, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.018091188743710518, 'loss_2': 0.0027713775634765625, 'loss_3': -15.9982328414917, 'loss_4': 1.315761923789978, 'epoch': 5.28}
{'loss': 0.0573, 'grad_norm': 13.791115760803223, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.04881846904754639, 'loss_2': 0.008453369140625, 'loss_3': -15.88003158569336, 'loss_4': 0.8494092226028442, 'epoch': 5.28}
{'loss': 0.0455, 'grad_norm': 15.752578735351562, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.0350952073931694, 'loss_2': 0.0103759765625, 'loss_3': -15.9827299118042, 'loss_4': 1.6324656009674072, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 12:43:02,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:02,415 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:56<1:13:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:09,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02029750496149063, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.152, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.016789652407169342, 'eval_loss_2': 0.003507852554321289, 'eval_loss_3': -18.25225257873535, 'eval_loss_4': 1.1792954206466675, 'epoch': 5.29}
{'loss': 0.0314, 'grad_norm': 7.4844770431518555, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.022164160385727882, 'loss_2': 0.00921630859375, 'loss_3': -16.069931030273438, 'loss_4': 1.4239503145217896, 'epoch': 5.3}
{'loss': 0.0579, 'grad_norm': 21.39365005493164, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.05640236660838127, 'loss_2': 0.0015459060668945312, 'loss_3': -15.88811206817627, 'loss_4': 1.3403046131134033, 'epoch': 5.3}
{'loss': 0.0293, 'grad_norm': 6.694352626800537, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.025577619671821594, 'loss_2': 0.0037078857421875, 'loss_3': -15.96458625793457, 'loss_4': 1.4725474119186401, 'epoch': 5.31}
{'loss': 0.0367, 'grad_norm': 11.270362854003906, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.03634737804532051, 'loss_2': 0.0003666877746582031, 'loss_3': -16.041637420654297, 'loss_4': 1.1847047805786133, 'epoch': 5.31}
{'loss': 0.0215, 'grad_norm': 7.235116004943848, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.019848819822072983, 'loss_2': 0.00167083740234375, 'loss_3': -16.066274642944336, 'loss_4': 1.063119649887085, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 12:43:09,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:09,764 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:04<1:13:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:17,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018835395574569702, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.347, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015780029818415642, 'eval_loss_2': 0.003055363893508911, 'eval_loss_3': -18.256912231445312, 'eval_loss_4': 1.389391303062439, 'epoch': 5.32}
{'loss': 0.0288, 'grad_norm': 8.896279335021973, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.02819993905723095, 'loss_2': 0.0005750656127929688, 'loss_3': -16.18271255493164, 'loss_4': 1.413337230682373, 'epoch': 5.33}
{'loss': 0.0202, 'grad_norm': 5.874094009399414, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.017165616154670715, 'loss_2': 0.003009796142578125, 'loss_3': -16.140710830688477, 'loss_4': 1.6535251140594482, 'epoch': 5.33}
{'loss': 0.0351, 'grad_norm': 7.329952716827393, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.02723318710923195, 'loss_2': 0.00787353515625, 'loss_3': -16.01103973388672, 'loss_4': 1.483086347579956, 'epoch': 5.34}
{'loss': 0.0689, 'grad_norm': 17.442073822021484, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.060092099010944366, 'loss_2': 0.0087890625, 'loss_3': -16.077266693115234, 'loss_4': 1.406955361366272, 'epoch': 5.34}
{'loss': 0.0472, 'grad_norm': 15.0264892578125, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.044868141412734985, 'loss_2': 0.002323150634765625, 'loss_3': -15.960649490356445, 'loss_4': 1.4478834867477417, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 12:43:17,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:17,110 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:11<1:13:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:24,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024018649011850357, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.835, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.018828842788934708, 'eval_loss_2': 0.005189806222915649, 'eval_loss_3': -18.306259155273438, 'eval_loss_4': 1.568074345588684, 'epoch': 5.35}
{'loss': 0.039, 'grad_norm': 9.66602897644043, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.03541375696659088, 'loss_2': 0.00360107421875, 'loss_3': -16.29269027709961, 'loss_4': 1.7905783653259277, 'epoch': 5.35}
{'loss': 0.0647, 'grad_norm': 16.850284576416016, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.061805374920368195, 'loss_2': 0.00286102294921875, 'loss_3': -16.10327911376953, 'loss_4': 1.6140077114105225, 'epoch': 5.36}
{'loss': 0.0459, 'grad_norm': 14.928608894348145, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.04553554207086563, 'loss_2': 0.0003533363342285156, 'loss_3': -16.046422958374023, 'loss_4': 2.0045371055603027, 'epoch': 5.37}
{'loss': 0.0263, 'grad_norm': 7.219022274017334, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.02214720845222473, 'loss_2': 0.004119873046875, 'loss_3': -16.081520080566406, 'loss_4': 1.6765022277832031, 'epoch': 5.37}
{'loss': 0.1232, 'grad_norm': 23.475923538208008, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.11598889529705048, 'loss_2': 0.0072174072265625, 'loss_3': -16.08553695678711, 'loss_4': 1.722680687904358, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 12:43:24,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:24,465 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:18<1:13:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:31,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0233287550508976, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.879, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.019577300176024437, 'eval_loss_2': 0.0037514567375183105, 'eval_loss_3': -18.32783317565918, 'eval_loss_4': 1.9085333347320557, 'epoch': 5.38}
{'loss': 0.0254, 'grad_norm': 7.153819561004639, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.02470134012401104, 'loss_2': 0.0006589889526367188, 'loss_3': -16.058618545532227, 'loss_4': 1.861756682395935, 'epoch': 5.38}
{'loss': 0.04, 'grad_norm': 10.841984748840332, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.03904027119278908, 'loss_2': 0.0009431838989257812, 'loss_3': -15.920125961303711, 'loss_4': 1.9615931510925293, 'epoch': 5.39}
{'loss': 0.0516, 'grad_norm': 12.795549392700195, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.049964774399995804, 'loss_2': 0.0016460418701171875, 'loss_3': -16.017234802246094, 'loss_4': 2.081270217895508, 'epoch': 5.4}
{'loss': 0.0727, 'grad_norm': 20.618099212646484, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.0724652037024498, 'loss_2': 0.0002694129943847656, 'loss_3': -16.143653869628906, 'loss_4': 1.8463516235351562, 'epoch': 5.4}
{'loss': 0.0921, 'grad_norm': 22.206823348999023, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.08639049530029297, 'loss_2': 0.005725860595703125, 'loss_3': -16.25185775756836, 'loss_4': 3.063284397125244, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 12:43:31,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:31,822 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:26<1:13:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:39,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026229998096823692, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.020375672727823257, 'eval_loss_2': 0.005854323506355286, 'eval_loss_3': -18.316125869750977, 'eval_loss_4': 1.983837604522705, 'epoch': 5.41}
{'loss': 0.101, 'grad_norm': 20.585405349731445, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.09970559179782867, 'loss_2': 0.0013074874877929688, 'loss_3': -15.887899398803711, 'loss_4': 1.886405110359192, 'epoch': 5.41}
{'loss': 0.0462, 'grad_norm': 18.180145263671875, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.04192991927266121, 'loss_2': 0.00429534912109375, 'loss_3': -16.1251220703125, 'loss_4': 1.9807884693145752, 'epoch': 5.42}
{'loss': 0.0444, 'grad_norm': 10.2459135055542, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.037118490785360336, 'loss_2': 0.007320404052734375, 'loss_3': -16.07792854309082, 'loss_4': 1.6937912702560425, 'epoch': 5.42}
{'loss': 0.0457, 'grad_norm': 11.991430282592773, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.03862736374139786, 'loss_2': 0.007053375244140625, 'loss_3': -16.1163330078125, 'loss_4': 2.130162239074707, 'epoch': 5.43}
{'loss': 0.0451, 'grad_norm': 10.362320899963379, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.03977438434958458, 'loss_2': 0.005367279052734375, 'loss_3': -16.071266174316406, 'loss_4': 1.962843656539917, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 12:43:39,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:39,179 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:33<1:13:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:46,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022137504070997238, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.718, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017625100910663605, 'eval_loss_2': 0.004512399435043335, 'eval_loss_3': -18.293472290039062, 'eval_loss_4': 1.9833958148956299, 'epoch': 5.44}
{'loss': 0.0179, 'grad_norm': 6.346065998077393, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.015768492594361305, 'loss_2': 0.00211334228515625, 'loss_3': -16.005130767822266, 'loss_4': 2.045772075653076, 'epoch': 5.44}
{'loss': 0.0326, 'grad_norm': 8.521919250488281, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.027522632852196693, 'loss_2': 0.0051116943359375, 'loss_3': -16.156339645385742, 'loss_4': 2.155951499938965, 'epoch': 5.45}
{'loss': 0.0488, 'grad_norm': 14.825334548950195, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.04305137321352959, 'loss_2': 0.00569915771484375, 'loss_3': -16.077617645263672, 'loss_4': 1.804490089416504, 'epoch': 5.45}
{'loss': 0.0691, 'grad_norm': 17.28904914855957, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.06341809779405594, 'loss_2': 0.00567626953125, 'loss_3': -15.952720642089844, 'loss_4': 2.160398244857788, 'epoch': 5.46}
{'loss': 0.0258, 'grad_norm': 6.691808223724365, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.02149544283747673, 'loss_2': 0.0042724609375, 'loss_3': -16.19216537475586, 'loss_4': 2.2595982551574707, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 12:43:46,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:46,536 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:40<1:13:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:53,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020293500274419785, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01646258868277073, 'eval_loss_2': 0.0038309097290039062, 'eval_loss_3': -18.274202346801758, 'eval_loss_4': 1.8904039859771729, 'epoch': 5.47}
{'loss': 0.0301, 'grad_norm': 9.459512710571289, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.025033704936504364, 'loss_2': 0.005035400390625, 'loss_3': -15.66395378112793, 'loss_4': 1.8704692125320435, 'epoch': 5.47}
{'loss': 0.0184, 'grad_norm': 7.514884948730469, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.017245814204216003, 'loss_2': 0.001163482666015625, 'loss_3': -16.118091583251953, 'loss_4': 1.820891261100769, 'epoch': 5.48}
{'loss': 0.0283, 'grad_norm': 10.92727279663086, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.026027044281363487, 'loss_2': 0.002269744873046875, 'loss_3': -16.15961456298828, 'loss_4': 1.8893572092056274, 'epoch': 5.48}
{'loss': 0.0217, 'grad_norm': 7.893413066864014, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.020944997668266296, 'loss_2': 0.000728607177734375, 'loss_3': -16.18399429321289, 'loss_4': 2.046562433242798, 'epoch': 5.49}
{'loss': 0.0402, 'grad_norm': 11.050129890441895, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.03140973672270775, 'loss_2': 0.00875091552734375, 'loss_3': -16.0899658203125, 'loss_4': 1.848230242729187, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 12:43:53,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:53,904 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:48<1:13:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:01,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021704193204641342, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017111975699663162, 'eval_loss_2': 0.00459221750497818, 'eval_loss_3': -18.25303840637207, 'eval_loss_4': 1.7107563018798828, 'epoch': 5.49}
{'loss': 0.0177, 'grad_norm': 5.889415264129639, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.012320737354457378, 'loss_2': 0.005367279052734375, 'loss_3': -16.281131744384766, 'loss_4': 1.7590034008026123, 'epoch': 5.5}
{'loss': 0.0415, 'grad_norm': 10.372331619262695, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.036006420850753784, 'loss_2': 0.005542755126953125, 'loss_3': -16.019182205200195, 'loss_4': 1.5113959312438965, 'epoch': 5.51}
{'loss': 0.0317, 'grad_norm': 9.060376167297363, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.026768654584884644, 'loss_2': 0.004974365234375, 'loss_3': -15.851966857910156, 'loss_4': 1.069009780883789, 'epoch': 5.51}
{'loss': 0.0487, 'grad_norm': 17.328563690185547, 'learning_rate': 2.45e-05, 'loss_1': 0.04376669600605965, 'loss_2': 0.00498199462890625, 'loss_3': -15.907356262207031, 'loss_4': 1.4423046112060547, 'epoch': 5.52}
{'loss': 0.0739, 'grad_norm': 17.42685317993164, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.07148436456918716, 'loss_2': 0.002437591552734375, 'loss_3': -15.98806095123291, 'loss_4': 1.755713701248169, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 12:44:01,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:01,261 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:55<1:12:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:08,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021663468331098557, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01644633337855339, 'eval_loss_2': 0.005217134952545166, 'eval_loss_3': -18.247886657714844, 'eval_loss_4': 1.624232530593872, 'epoch': 5.52}
{'loss': 0.0726, 'grad_norm': 22.385540008544922, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.06260289251804352, 'loss_2': 0.00995635986328125, 'loss_3': -16.04121208190918, 'loss_4': 1.8778433799743652, 'epoch': 5.53}
{'loss': 0.0236, 'grad_norm': 7.521218776702881, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.020402222871780396, 'loss_2': 0.003177642822265625, 'loss_3': -15.985052108764648, 'loss_4': 1.2888293266296387, 'epoch': 5.53}
{'loss': 0.035, 'grad_norm': 18.006877899169922, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.02765829861164093, 'loss_2': 0.00733184814453125, 'loss_3': -15.99051284790039, 'loss_4': 1.6357109546661377, 'epoch': 5.54}
{'loss': 0.0322, 'grad_norm': 10.673064231872559, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.031839773058891296, 'loss_2': 0.0003876686096191406, 'loss_3': -15.861544609069824, 'loss_4': 1.2286062240600586, 'epoch': 5.55}
{'loss': 0.02, 'grad_norm': 7.029873371124268, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.015446723438799381, 'loss_2': 0.00457763671875, 'loss_3': -16.320646286010742, 'loss_4': 1.4652522802352905, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 12:44:08,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:08,619 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:03<1:12:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:15,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021834803745150566, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017307870090007782, 'eval_loss_2': 0.004526935517787933, 'eval_loss_3': -18.216022491455078, 'eval_loss_4': 1.4282182455062866, 'epoch': 5.55}
{'loss': 0.0128, 'grad_norm': 5.104575157165527, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.010332276113331318, 'loss_2': 0.0024585723876953125, 'loss_3': -15.994155883789062, 'loss_4': 1.460119366645813, 'epoch': 5.56}
{'loss': 0.0457, 'grad_norm': 16.30415153503418, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.04145380109548569, 'loss_2': 0.00424957275390625, 'loss_3': -16.030445098876953, 'loss_4': 1.0981776714324951, 'epoch': 5.56}
{'loss': 0.0197, 'grad_norm': 7.73080587387085, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.017993487417697906, 'loss_2': 0.0016632080078125, 'loss_3': -16.07704734802246, 'loss_4': 1.3459432125091553, 'epoch': 5.57}
{'loss': 0.0298, 'grad_norm': 11.21076774597168, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.025505894795060158, 'loss_2': 0.00433349609375, 'loss_3': -16.101505279541016, 'loss_4': 1.2697718143463135, 'epoch': 5.58}
{'loss': 0.0359, 'grad_norm': 7.989236831665039, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.024710027500987053, 'loss_2': 0.011199951171875, 'loss_3': -16.093833923339844, 'loss_4': 1.4836461544036865, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 12:44:15,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:15,973 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:10<1:12:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:23,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023914575576782227, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.020067855715751648, 'eval_loss_2': 0.0038467198610305786, 'eval_loss_3': -18.170616149902344, 'eval_loss_4': 1.1033751964569092, 'epoch': 5.58}
{'loss': 0.0289, 'grad_norm': 8.069427490234375, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.02141406200826168, 'loss_2': 0.007488250732421875, 'loss_3': -16.0999755859375, 'loss_4': 0.755776584148407, 'epoch': 5.59}
{'loss': 0.0347, 'grad_norm': 11.081341743469238, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.03061896562576294, 'loss_2': 0.004077911376953125, 'loss_3': -15.925043106079102, 'loss_4': 0.9964650869369507, 'epoch': 5.59}
{'loss': 0.0493, 'grad_norm': 11.461135864257812, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.04651714488863945, 'loss_2': 0.0027561187744140625, 'loss_3': -15.922118186950684, 'loss_4': 0.8214741349220276, 'epoch': 5.6}
{'loss': 0.0247, 'grad_norm': 8.601449012756348, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.020254526287317276, 'loss_2': 0.00449371337890625, 'loss_3': -16.102367401123047, 'loss_4': 1.135839819908142, 'epoch': 5.6}
{'loss': 0.0396, 'grad_norm': 13.048698425292969, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.03725133836269379, 'loss_2': 0.002368927001953125, 'loss_3': -16.058059692382812, 'loss_4': 0.8069724440574646, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 12:44:23,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:23,320 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:17<1:12:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:30,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024577602744102478, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.020660879090428352, 'eval_loss_2': 0.003916725516319275, 'eval_loss_3': -18.14413070678711, 'eval_loss_4': 0.8715560436248779, 'epoch': 5.61}
{'loss': 0.0435, 'grad_norm': 17.85614776611328, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.03959030658006668, 'loss_2': 0.003910064697265625, 'loss_3': -15.999381065368652, 'loss_4': 1.0700453519821167, 'epoch': 5.62}
{'loss': 0.0417, 'grad_norm': 16.0804443359375, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.03155624121427536, 'loss_2': 0.0101776123046875, 'loss_3': -16.23213768005371, 'loss_4': 1.071001648902893, 'epoch': 5.62}
{'loss': 0.0409, 'grad_norm': 13.564105033874512, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.03949867933988571, 'loss_2': 0.0014476776123046875, 'loss_3': -16.07049560546875, 'loss_4': 0.9252723455429077, 'epoch': 5.63}
{'loss': 0.0264, 'grad_norm': 7.109614849090576, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.014096032828092575, 'loss_2': 0.01235198974609375, 'loss_3': -16.24090576171875, 'loss_4': 0.7312110662460327, 'epoch': 5.63}
{'loss': 0.0316, 'grad_norm': 12.1453275680542, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.029195528477430344, 'loss_2': 0.00244903564453125, 'loss_3': -16.121562957763672, 'loss_4': 0.1395917534828186, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 12:44:30,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:30,662 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:25<1:13:23,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:44:38,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022224415093660355, 'eval_runtime': 3.9899, 'eval_samples_per_second': 256.65, 'eval_steps_per_second': 4.01, 'eval_loss_1': 0.017030736431479454, 'eval_loss_2': 0.00519368052482605, 'eval_loss_3': -18.17749786376953, 'eval_loss_4': 0.6433658003807068, 'epoch': 5.64}
{'loss': 0.0371, 'grad_norm': 11.738765716552734, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.029522869735956192, 'loss_2': 0.007556915283203125, 'loss_3': -16.066247940063477, 'loss_4': 0.6246284246444702, 'epoch': 5.65}
{'loss': 0.0377, 'grad_norm': 14.207383155822754, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.02656468003988266, 'loss_2': 0.011138916015625, 'loss_3': -16.093399047851562, 'loss_4': 0.7122070789337158, 'epoch': 5.65}
{'loss': 0.0341, 'grad_norm': 10.861372947692871, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.03335493430495262, 'loss_2': 0.0007266998291015625, 'loss_3': -16.163394927978516, 'loss_4': 0.7713642120361328, 'epoch': 5.66}
{'loss': 0.0345, 'grad_norm': 14.540167808532715, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.033014021813869476, 'loss_2': 0.0014400482177734375, 'loss_3': -15.968172073364258, 'loss_4': 0.34052199125289917, 'epoch': 5.66}
{'loss': 0.0203, 'grad_norm': 7.100864887237549, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.01988418586552143, 'loss_2': 0.00038814544677734375, 'loss_3': -16.021257400512695, 'loss_4': 0.8597423434257507, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 12:44:38,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:38,200 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:32<1:12:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:45,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020171061158180237, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.016816839575767517, 'eval_loss_2': 0.0033542215824127197, 'eval_loss_3': -18.181066513061523, 'eval_loss_4': 0.6564831733703613, 'epoch': 5.67}
{'loss': 0.0468, 'grad_norm': 23.10788345336914, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.045181576162576675, 'loss_2': 0.00157928466796875, 'loss_3': -16.124923706054688, 'loss_4': 0.34499216079711914, 'epoch': 5.67}
{'loss': 0.0331, 'grad_norm': 15.144051551818848, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.032919421792030334, 'loss_2': 0.00013399124145507812, 'loss_3': -16.24814224243164, 'loss_4': 0.5110158324241638, 'epoch': 5.68}
{'loss': 0.0808, 'grad_norm': 19.890640258789062, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.07085151970386505, 'loss_2': 0.00998687744140625, 'loss_3': -16.13231658935547, 'loss_4': 0.5484493970870972, 'epoch': 5.69}
{'loss': 0.0465, 'grad_norm': 13.975034713745117, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.040394753217697144, 'loss_2': 0.00614166259765625, 'loss_3': -16.175045013427734, 'loss_4': 0.585308313369751, 'epoch': 5.69}
{'loss': 0.0479, 'grad_norm': 11.995463371276855, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.042751312255859375, 'loss_2': 0.00518035888671875, 'loss_3': -16.109851837158203, 'loss_4': 0.7468852996826172, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 12:44:45,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:45,550 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:39<1:12:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:52,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025204602628946304, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.348, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.01947975531220436, 'eval_loss_2': 0.005724847316741943, 'eval_loss_3': -18.15852928161621, 'eval_loss_4': 0.824379026889801, 'epoch': 5.7}
{'loss': 0.0218, 'grad_norm': 5.627134799957275, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.011844783090054989, 'loss_2': 0.0099334716796875, 'loss_3': -16.257572174072266, 'loss_4': 0.5143096446990967, 'epoch': 5.7}
{'loss': 0.052, 'grad_norm': 12.60855770111084, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.042630959302186966, 'loss_2': 0.00937652587890625, 'loss_3': -16.22074317932129, 'loss_4': 0.8189878463745117, 'epoch': 5.71}
{'loss': 0.0444, 'grad_norm': 14.569128036499023, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.03614246845245361, 'loss_2': 0.00823211669921875, 'loss_3': -15.815887451171875, 'loss_4': 0.7550801038742065, 'epoch': 5.72}
{'loss': 0.022, 'grad_norm': 7.239724636077881, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.02191166765987873, 'loss_2': 0.00010788440704345703, 'loss_3': -16.027128219604492, 'loss_4': 0.8251907825469971, 'epoch': 5.72}
{'loss': 0.0811, 'grad_norm': 22.804250717163086, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.07979700714349747, 'loss_2': 0.0012969970703125, 'loss_3': -16.056076049804688, 'loss_4': 1.1069879531860352, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 12:44:52,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:52,923 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:47<1:12:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:00,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021862931549549103, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017490176483988762, 'eval_loss_2': 0.004372753202915192, 'eval_loss_3': -18.124210357666016, 'eval_loss_4': 1.2444199323654175, 'epoch': 5.73}
{'loss': 0.0401, 'grad_norm': 13.859230995178223, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.03416560962796211, 'loss_2': 0.00595855712890625, 'loss_3': -16.053489685058594, 'loss_4': 1.3387254476547241, 'epoch': 5.73}
{'loss': 0.0137, 'grad_norm': 5.953313827514648, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.010571083053946495, 'loss_2': 0.00311279296875, 'loss_3': -16.027780532836914, 'loss_4': 1.1454172134399414, 'epoch': 5.74}
{'loss': 0.0135, 'grad_norm': 5.575557708740234, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.009011270478367805, 'loss_2': 0.0044708251953125, 'loss_3': -16.110485076904297, 'loss_4': 1.2862756252288818, 'epoch': 5.74}
{'loss': 0.0279, 'grad_norm': 10.562432289123535, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.02576315961778164, 'loss_2': 0.002124786376953125, 'loss_3': -16.072555541992188, 'loss_4': 1.4312554597854614, 'epoch': 5.75}
{'loss': 0.0309, 'grad_norm': 14.462657928466797, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.029300827533006668, 'loss_2': 0.0016298294067382812, 'loss_3': -16.008342742919922, 'loss_4': 1.642876148223877, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 12:45:00,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:00,275 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:54<1:12:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:07,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026872668415308, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02231157012283802, 'eval_loss_2': 0.004561096429824829, 'eval_loss_3': -18.125568389892578, 'eval_loss_4': 1.893589735031128, 'epoch': 5.76}
{'loss': 0.0282, 'grad_norm': 9.373917579650879, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.027205899357795715, 'loss_2': 0.0009822845458984375, 'loss_3': -16.056846618652344, 'loss_4': 1.719184398651123, 'epoch': 5.76}
{'loss': 0.0433, 'grad_norm': 9.341684341430664, 'learning_rate': 2.425e-05, 'loss_1': 0.03883151337504387, 'loss_2': 0.00450897216796875, 'loss_3': -16.087617874145508, 'loss_4': 1.6271483898162842, 'epoch': 5.77}
{'loss': 0.0261, 'grad_norm': 5.867033958435059, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.014260703697800636, 'loss_2': 0.01187896728515625, 'loss_3': -16.120698928833008, 'loss_4': 1.670216679573059, 'epoch': 5.77}
{'loss': 0.0481, 'grad_norm': 13.384218215942383, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.030473150312900543, 'loss_2': 0.017669677734375, 'loss_3': -16.070388793945312, 'loss_4': 2.0821948051452637, 'epoch': 5.78}
{'loss': 0.0578, 'grad_norm': 16.259267807006836, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.04689706489443779, 'loss_2': 0.01087188720703125, 'loss_3': -16.09982681274414, 'loss_4': 2.0275769233703613, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 12:45:07,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:07,634 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:02<1:12:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:14,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029703453183174133, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.023470833897590637, 'eval_loss_2': 0.006232619285583496, 'eval_loss_3': -18.181753158569336, 'eval_loss_4': 2.2328569889068604, 'epoch': 5.78}
{'loss': 0.0452, 'grad_norm': 18.11522674560547, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.03962594270706177, 'loss_2': 0.00556182861328125, 'loss_3': -16.16942596435547, 'loss_4': 2.3121228218078613, 'epoch': 5.79}
{'loss': 0.0236, 'grad_norm': 9.141557693481445, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.023539841175079346, 'loss_2': 4.464387893676758e-05, 'loss_3': -16.05392074584961, 'loss_4': 2.3156564235687256, 'epoch': 5.8}
{'loss': 0.0408, 'grad_norm': 11.725176811218262, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.039851222187280655, 'loss_2': 0.0009622573852539062, 'loss_3': -16.051443099975586, 'loss_4': 2.4110922813415527, 'epoch': 5.8}
{'loss': 0.0311, 'grad_norm': 7.9121928215026855, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.024649331346154213, 'loss_2': 0.006488800048828125, 'loss_3': -16.054828643798828, 'loss_4': 2.189516067504883, 'epoch': 5.81}
{'loss': 0.0493, 'grad_norm': 14.710241317749023, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.040739506483078, 'loss_2': 0.0085296630859375, 'loss_3': -16.084754943847656, 'loss_4': 2.5300025939941406, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 12:45:14,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:14,996 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:09<1:11:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:22,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027504028752446175, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.022007539868354797, 'eval_loss_2': 0.005496487021446228, 'eval_loss_3': -18.208858489990234, 'eval_loss_4': 2.6167426109313965, 'epoch': 5.81}
{'loss': 0.0573, 'grad_norm': 21.58383560180664, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.049278441816568375, 'loss_2': 0.0079803466796875, 'loss_3': -16.118576049804688, 'loss_4': 1.8608014583587646, 'epoch': 5.82}
{'loss': 0.059, 'grad_norm': 21.78925895690918, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.0495227575302124, 'loss_2': 0.00945281982421875, 'loss_3': -16.083362579345703, 'loss_4': 2.80686354637146, 'epoch': 5.83}
{'loss': 0.0423, 'grad_norm': 11.98192024230957, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.030367551371455193, 'loss_2': 0.01190185546875, 'loss_3': -16.105695724487305, 'loss_4': 2.54948091506958, 'epoch': 5.83}
{'loss': 0.0435, 'grad_norm': 9.352226257324219, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.03682626783847809, 'loss_2': 0.00670623779296875, 'loss_3': -16.263212203979492, 'loss_4': 2.6164777278900146, 'epoch': 5.84}
{'loss': 0.0359, 'grad_norm': 9.460021018981934, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.02270333468914032, 'loss_2': 0.01323699951171875, 'loss_3': -16.10438346862793, 'loss_4': 2.807403564453125, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 12:45:22,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:22,352 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:16<1:11:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:29,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0267260130494833, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.020343391224741936, 'eval_loss_2': 0.0063826218247413635, 'eval_loss_3': -18.245973587036133, 'eval_loss_4': 2.779205799102783, 'epoch': 5.84}
{'loss': 0.0398, 'grad_norm': 13.852363586425781, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.03895286098122597, 'loss_2': 0.0008459091186523438, 'loss_3': -15.989267349243164, 'loss_4': 2.5500025749206543, 'epoch': 5.85}
{'loss': 0.0349, 'grad_norm': 10.281784057617188, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.031618352979421616, 'loss_2': 0.0032806396484375, 'loss_3': -16.00484848022461, 'loss_4': 2.7715697288513184, 'epoch': 5.85}
{'loss': 0.0585, 'grad_norm': 15.877799034118652, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.045220617204904556, 'loss_2': 0.0132904052734375, 'loss_3': -16.270824432373047, 'loss_4': 2.6566643714904785, 'epoch': 5.86}
{'loss': 0.0253, 'grad_norm': 7.002950668334961, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.023816019296646118, 'loss_2': 0.001453399658203125, 'loss_3': -15.999133110046387, 'loss_4': 2.5532386302948, 'epoch': 5.87}
{'loss': 0.0297, 'grad_norm': 7.86628532409668, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.024229994043707848, 'loss_2': 0.00542449951171875, 'loss_3': -16.003108978271484, 'loss_4': 2.502126693725586, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 12:45:29,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:29,709 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:24<1:11:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:37,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018265701830387115, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01428195834159851, 'eval_loss_2': 0.003983743488788605, 'eval_loss_3': -18.251514434814453, 'eval_loss_4': 2.7027904987335205, 'epoch': 5.87}
{'loss': 0.0285, 'grad_norm': 10.637171745300293, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.025550875812768936, 'loss_2': 0.002986907958984375, 'loss_3': -16.20946502685547, 'loss_4': 2.6073408126831055, 'epoch': 5.88}
{'loss': 0.0409, 'grad_norm': 17.38170051574707, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.03576820716261864, 'loss_2': 0.00508880615234375, 'loss_3': -15.959599494934082, 'loss_4': 2.770136833190918, 'epoch': 5.88}
{'loss': 0.0299, 'grad_norm': 8.608412742614746, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.026095865294337273, 'loss_2': 0.0037689208984375, 'loss_3': -16.105249404907227, 'loss_4': 2.1138758659362793, 'epoch': 5.89}
{'loss': 0.0795, 'grad_norm': 22.515254974365234, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.07731928676366806, 'loss_2': 0.002185821533203125, 'loss_3': -16.089244842529297, 'loss_4': 2.409151077270508, 'epoch': 5.9}
{'loss': 0.0688, 'grad_norm': 24.031124114990234, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.061277370899915695, 'loss_2': 0.00754547119140625, 'loss_3': -16.12813377380371, 'loss_4': 2.4685635566711426, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 12:45:37,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:37,076 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:27<1:11:51,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:45:40,876 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015
[INFO|configuration_utils.py:420] 2025-01-21 12:45:40,877 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015/config.json                                                                            
{'eval_loss': 0.017205186188220978, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.576, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01245546992868185, 'eval_loss_2': 0.004749715328216553, 'eval_loss_3': -18.217683792114258, 'eval_loss_4': 2.493781566619873, 'epoch': 5.9}
[INFO|modeling_utils.py:2988] 2025-01-21 12:45:41,364 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:45:41,366 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:45:41,366 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:45:42,324 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-755] due to args.save_total_limit
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:33<1:19:21,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:45:45,968 >>
{'loss': 0.0348, 'grad_norm': 8.808256149291992, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.026554333046078682, 'loss_2': 0.00823211669921875, 'loss_3': -15.970104217529297, 'loss_4': 2.035444736480713, 'epoch': 5.91}
{'loss': 0.0475, 'grad_norm': 19.56719207763672, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.04178868234157562, 'loss_2': 0.00566864013671875, 'loss_3': -16.090574264526367, 'loss_4': 2.42435884475708, 'epoch': 5.91}
{'loss': 0.0338, 'grad_norm': 10.208319664001465, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.026909735053777695, 'loss_2': 0.00691986083984375, 'loss_3': -16.26136016845703, 'loss_4': 2.303670883178711, 'epoch': 5.92}
{'loss': 0.0383, 'grad_norm': 13.237773895263672, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.0380762480199337, 'loss_2': 0.00023353099822998047, 'loss_3': -16.207983016967773, 'loss_4': 1.6837388277053833, 'epoch': 5.92}
{'loss': 0.0569, 'grad_norm': 17.73826026916504, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.04958401247859001, 'loss_2': 0.00734710693359375, 'loss_3': -15.848773956298828, 'loss_4': 2.292146682739258, 'epoch': 5.93}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:45:45,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:45,968 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:40<1:12:53,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:45:53,317 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018629983067512512, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011532499454915524, 'eval_loss_2': 0.007097482681274414, 'eval_loss_3': -18.2481689453125, 'eval_loss_4': 2.412987470626831, 'epoch': 5.93}
{'loss': 0.131, 'grad_norm': 14.991147994995117, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.12902075052261353, 'loss_2': 0.002025604248046875, 'loss_3': -15.851938247680664, 'loss_4': 2.4865496158599854, 'epoch': 5.94}
{'loss': 0.0439, 'grad_norm': 16.2239933013916, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.04150675982236862, 'loss_2': 0.002349853515625, 'loss_3': -16.202598571777344, 'loss_4': 2.342996597290039, 'epoch': 5.94}
{'loss': 0.0401, 'grad_norm': 16.30636215209961, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.02773439884185791, 'loss_2': 0.0123291015625, 'loss_3': -15.853842735290527, 'loss_4': 1.8864412307739258, 'epoch': 5.95}
{'loss': 0.029, 'grad_norm': 7.58353328704834, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.02148752473294735, 'loss_2': 0.007476806640625, 'loss_3': -15.968704223632812, 'loss_4': 2.328258991241455, 'epoch': 5.95}
{'loss': 0.0303, 'grad_norm': 6.961555004119873, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.018978137522935867, 'loss_2': 0.01129150390625, 'loss_3': -16.174833297729492, 'loss_4': 2.80403733253479, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 12:45:53,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:53,317 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:47<1:11:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:00,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023015830665826797, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.952, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013537230901420116, 'eval_loss_2': 0.009478598833084106, 'eval_loss_3': -18.23664665222168, 'eval_loss_4': 2.5766401290893555, 'epoch': 5.96}
{'loss': 0.0528, 'grad_norm': 15.69721794128418, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.04892958328127861, 'loss_2': 0.00388336181640625, 'loss_3': -15.95114517211914, 'loss_4': 2.423401355743408, 'epoch': 5.97}
{'loss': 0.0378, 'grad_norm': 12.410327911376953, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.029679765924811363, 'loss_2': 0.0081634521484375, 'loss_3': -16.11882972717285, 'loss_4': 2.7414495944976807, 'epoch': 5.97}
{'loss': 0.0294, 'grad_norm': 8.295604705810547, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.019202157855033875, 'loss_2': 0.0102386474609375, 'loss_3': -16.01755142211914, 'loss_4': 2.1683125495910645, 'epoch': 5.98}
{'loss': 0.025, 'grad_norm': 8.31279182434082, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.020835034549236298, 'loss_2': 0.0041351318359375, 'loss_3': -16.086103439331055, 'loss_4': 2.215768337249756, 'epoch': 5.98}
{'loss': 0.0194, 'grad_norm': 6.4726667404174805, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.014198236167430878, 'loss_2': 0.005168914794921875, 'loss_3': -16.125415802001953, 'loss_4': 2.307769298553467, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 12:46:00,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:00,668 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:54<1:09:25,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 12:46:07,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01796910911798477, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.791, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013680718839168549, 'eval_loss_2': 0.004288390278816223, 'eval_loss_3': -18.24527931213379, 'eval_loss_4': 2.6576266288757324, 'epoch': 5.99}
{'loss': 0.0155, 'grad_norm': 6.7835235595703125, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.013893969357013702, 'loss_2': 0.0016450881958007812, 'loss_3': -16.10893440246582, 'loss_4': 2.728093385696411, 'epoch': 5.99}
{'loss': 0.009, 'grad_norm': 7.494998931884766, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.008788235485553741, 'loss_2': 0.00017833709716796875, 'loss_3': -15.823022842407227, 'loss_4': 1.9506734609603882, 'epoch': 6.0}
{'loss': 0.0307, 'grad_norm': 6.126830101013184, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.015779294073581696, 'loss_2': 0.0149078369140625, 'loss_3': -16.004262924194336, 'loss_4': 2.4523935317993164, 'epoch': 6.01}
{'loss': 0.0313, 'grad_norm': 11.71243953704834, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.022479187697172165, 'loss_2': 0.0087738037109375, 'loss_3': -16.038734436035156, 'loss_4': 3.2380645275115967, 'epoch': 6.01}
{'loss': 0.0245, 'grad_norm': 10.532427787780762, 'learning_rate': 2.4e-05, 'loss_1': 0.021449577063322067, 'loss_2': 0.003040313720703125, 'loss_3': -16.1378173828125, 'loss_4': 2.7154037952423096, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 12:46:07,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:07,705 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:02<1:10:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:46:15,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022778218612074852, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013633914291858673, 'eval_loss_2': 0.009144306182861328, 'eval_loss_3': -18.246929168701172, 'eval_loss_4': 2.6829757690429688, 'epoch': 6.02}
{'loss': 0.0315, 'grad_norm': 11.32394027709961, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.022503385320305824, 'loss_2': 0.0090179443359375, 'loss_3': -16.08489990234375, 'loss_4': 2.6264028549194336, 'epoch': 6.02}
{'loss': 0.0289, 'grad_norm': 6.341151237487793, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.015542656183242798, 'loss_2': 0.01334381103515625, 'loss_3': -16.074617385864258, 'loss_4': 2.5845093727111816, 'epoch': 6.03}
{'loss': 0.0252, 'grad_norm': 7.790165901184082, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.01932668499648571, 'loss_2': 0.00592041015625, 'loss_3': -16.00762176513672, 'loss_4': 2.945552110671997, 'epoch': 6.03}
{'loss': 0.0168, 'grad_norm': 5.058923244476318, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.007290403824299574, 'loss_2': 0.009521484375, 'loss_3': -15.927335739135742, 'loss_4': 2.0929386615753174, 'epoch': 6.04}
{'loss': 0.0455, 'grad_norm': 21.9296817779541, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.03900814428925514, 'loss_2': 0.00650787353515625, 'loss_3': -15.998615264892578, 'loss_4': 2.1579346656799316, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 12:46:15,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:15,050 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:05<1:10:53,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 12:46:18,848 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040
[INFO|configuration_utils.py:420] 2025-01-21 12:46:18,850 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040/config.json                                                                            
{'eval_loss': 0.016259614378213882, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.717, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012299817986786366, 'eval_loss_2': 0.0039597973227500916, 'eval_loss_3': -18.234928131103516, 'eval_loss_4': 2.249377965927124, 'epoch': 6.05}
[INFO|modeling_utils.py:2988] 2025-01-21 12:46:19,327 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:46:19,328 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:46:19,329 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:46:20,278 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1015] due to args.save_total_limit
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:10<1:18:34,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:46:23,911 >>
{'loss': 0.0125, 'grad_norm': 5.161705493927002, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.0108193876221776, 'loss_2': 0.001682281494140625, 'loss_3': -15.94821548461914, 'loss_4': 2.0366787910461426, 'epoch': 6.05}
{'loss': 0.0349, 'grad_norm': 17.6741886138916, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.03445480763912201, 'loss_2': 0.00041365623474121094, 'loss_3': -16.10763168334961, 'loss_4': 2.49631667137146, 'epoch': 6.06}
{'loss': 0.0124, 'grad_norm': 5.293352127075195, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.009223380126059055, 'loss_2': 0.0031909942626953125, 'loss_3': -15.984908103942871, 'loss_4': 1.5367248058319092, 'epoch': 6.06}
{'loss': 0.039, 'grad_norm': 12.158985137939453, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.03451452776789665, 'loss_2': 0.004528045654296875, 'loss_3': -15.969053268432617, 'loss_4': 1.9876880645751953, 'epoch': 6.07}
{'loss': 0.0471, 'grad_norm': 19.986520767211914, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.04410772770643234, 'loss_2': 0.0030002593994140625, 'loss_3': -15.847326278686523, 'loss_4': 2.163487195968628, 'epoch': 6.08}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:46:23,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:23,911 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:18<1:12:16,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:46:31,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019864551723003387, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.997, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011874190531671047, 'eval_loss_2': 0.007990360260009766, 'eval_loss_3': -18.297119140625, 'eval_loss_4': 1.7482699155807495, 'epoch': 6.08}
{'loss': 0.0364, 'grad_norm': 13.72716236114502, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.0312087032943964, 'loss_2': 0.00516510009765625, 'loss_3': -16.001707077026367, 'loss_4': 1.5686269998550415, 'epoch': 6.08}
{'loss': 0.0135, 'grad_norm': 6.007827281951904, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.012645076960325241, 'loss_2': 0.0008592605590820312, 'loss_3': -16.094066619873047, 'loss_4': 1.8403034210205078, 'epoch': 6.09}
{'loss': 0.0493, 'grad_norm': 15.706110954284668, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.04362527281045914, 'loss_2': 0.00563812255859375, 'loss_3': -15.876287460327148, 'loss_4': 1.676931619644165, 'epoch': 6.09}
{'loss': 0.0344, 'grad_norm': 11.982248306274414, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.018513744696974754, 'loss_2': 0.01593017578125, 'loss_3': -16.05193519592285, 'loss_4': 1.8366763591766357, 'epoch': 6.1}
{'loss': 0.0337, 'grad_norm': 11.616105079650879, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.030514957383275032, 'loss_2': 0.003170013427734375, 'loss_3': -15.824928283691406, 'loss_4': 1.354557991027832, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 12:46:31,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:31,247 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:25<1:11:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:38,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02298947423696518, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013134440407156944, 'eval_loss_2': 0.009855031967163086, 'eval_loss_3': -18.31684112548828, 'eval_loss_4': 1.541215419769287, 'epoch': 6.1}
{'loss': 0.0304, 'grad_norm': 8.526619911193848, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.022246064618229866, 'loss_2': 0.0081329345703125, 'loss_3': -15.767236709594727, 'loss_4': 1.8469704389572144, 'epoch': 6.11}
{'loss': 0.0699, 'grad_norm': 16.872644424438477, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.061432912945747375, 'loss_2': 0.0084228515625, 'loss_3': -16.103134155273438, 'loss_4': 1.430239200592041, 'epoch': 6.12}
{'loss': 0.0259, 'grad_norm': 16.779861450195312, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.025545677170157433, 'loss_2': 0.0003631114959716797, 'loss_3': -16.093263626098633, 'loss_4': 1.9372591972351074, 'epoch': 6.12}
{'loss': 0.0678, 'grad_norm': 20.469324111938477, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.058545976877212524, 'loss_2': 0.0092926025390625, 'loss_3': -16.000255584716797, 'loss_4': 2.1906065940856934, 'epoch': 6.13}
{'loss': 0.0282, 'grad_norm': 8.407577514648438, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.01970083639025688, 'loss_2': 0.008514404296875, 'loss_3': -16.135372161865234, 'loss_4': 2.1667587757110596, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 12:46:38,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:38,588 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:32<1:10:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:45,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019004259258508682, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.694, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01335311308503151, 'eval_loss_2': 0.005651146173477173, 'eval_loss_3': -18.290298461914062, 'eval_loss_4': 1.8082611560821533, 'epoch': 6.13}
{'loss': 0.0427, 'grad_norm': 16.08155059814453, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.03884132206439972, 'loss_2': 0.0038623809814453125, 'loss_3': -16.017208099365234, 'loss_4': 2.0033442974090576, 'epoch': 6.14}
{'loss': 0.0393, 'grad_norm': 10.548774719238281, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.03072335384786129, 'loss_2': 0.0085906982421875, 'loss_3': -15.966328620910645, 'loss_4': 1.8515385389328003, 'epoch': 6.15}
{'loss': 0.0152, 'grad_norm': 6.512203693389893, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.013699251227080822, 'loss_2': 0.0015306472778320312, 'loss_3': -16.02386474609375, 'loss_4': 1.8074458837509155, 'epoch': 6.15}
{'loss': 0.0271, 'grad_norm': 14.79747486114502, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.025151340290904045, 'loss_2': 0.001926422119140625, 'loss_3': -16.333942413330078, 'loss_4': 1.8661808967590332, 'epoch': 6.16}
{'loss': 0.0263, 'grad_norm': 7.255709171295166, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.023061633110046387, 'loss_2': 0.00327301025390625, 'loss_3': -15.931136131286621, 'loss_4': 1.433903694152832, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 12:46:45,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:45,932 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:40<1:10:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:53,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022432977333664894, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014997223392128944, 'eval_loss_2': 0.00743575394153595, 'eval_loss_3': -18.242963790893555, 'eval_loss_4': 2.154632568359375, 'epoch': 6.16}
{'loss': 0.0526, 'grad_norm': 19.17902374267578, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.04950055852532387, 'loss_2': 0.003093719482421875, 'loss_3': -15.91788387298584, 'loss_4': 2.0201950073242188, 'epoch': 6.17}
{'loss': 0.0452, 'grad_norm': 16.143386840820312, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.04139989987015724, 'loss_2': 0.00380706787109375, 'loss_3': -15.997933387756348, 'loss_4': 1.6640676259994507, 'epoch': 6.17}
{'loss': 0.0414, 'grad_norm': 10.500160217285156, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.024493902921676636, 'loss_2': 0.0169219970703125, 'loss_3': -16.001893997192383, 'loss_4': 2.0928330421447754, 'epoch': 6.18}
{'loss': 0.0329, 'grad_norm': 11.483641624450684, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.025110505521297455, 'loss_2': 0.0077972412109375, 'loss_3': -16.121843338012695, 'loss_4': 2.208916187286377, 'epoch': 6.19}
{'loss': 0.0338, 'grad_norm': 10.320290565490723, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.022594034671783447, 'loss_2': 0.01117706298828125, 'loss_3': -15.935758590698242, 'loss_4': 2.139648675918579, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 12:46:53,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:53,280 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:47<1:10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:00,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031311944127082825, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.796, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021433783695101738, 'eval_loss_2': 0.009878158569335938, 'eval_loss_3': -18.24798583984375, 'eval_loss_4': 2.4159445762634277, 'epoch': 6.19}
{'loss': 0.0303, 'grad_norm': 9.612881660461426, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.021803611889481544, 'loss_2': 0.0085296630859375, 'loss_3': -15.812368392944336, 'loss_4': 2.019937515258789, 'epoch': 6.2}
{'loss': 0.0295, 'grad_norm': 7.167186737060547, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.020149221643805504, 'loss_2': 0.00933074951171875, 'loss_3': -16.208633422851562, 'loss_4': 2.440147876739502, 'epoch': 6.2}
{'loss': 0.0382, 'grad_norm': 9.945381164550781, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.027159277349710464, 'loss_2': 0.01099395751953125, 'loss_3': -16.27470588684082, 'loss_4': 2.0339860916137695, 'epoch': 6.21}
{'loss': 0.0424, 'grad_norm': 13.68813705444336, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.03757131099700928, 'loss_2': 0.0048065185546875, 'loss_3': -15.9922513961792, 'loss_4': 2.7105255126953125, 'epoch': 6.22}
{'loss': 0.0522, 'grad_norm': 15.255788803100586, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.050119683146476746, 'loss_2': 0.0020313262939453125, 'loss_3': -16.09111213684082, 'loss_4': 2.4507715702056885, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 12:47:00,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:00,624 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:55<1:10:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:07,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0216364823281765, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01663922891020775, 'eval_loss_2': 0.00499725341796875, 'eval_loss_3': -18.258892059326172, 'eval_loss_4': 2.5271763801574707, 'epoch': 6.22}
{'loss': 0.0227, 'grad_norm': 8.090339660644531, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.020118722692131996, 'loss_2': 0.0026302337646484375, 'loss_3': -15.947357177734375, 'loss_4': 2.1760635375976562, 'epoch': 6.23}
{'loss': 0.0231, 'grad_norm': 7.020036220550537, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.019790444523096085, 'loss_2': 0.0032825469970703125, 'loss_3': -16.038618087768555, 'loss_4': 2.879483938217163, 'epoch': 6.23}
{'loss': 0.0171, 'grad_norm': 5.6764326095581055, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.011156793683767319, 'loss_2': 0.00594329833984375, 'loss_3': -16.191368103027344, 'loss_4': 2.334731101989746, 'epoch': 6.24}
{'loss': 0.0364, 'grad_norm': 8.378693580627441, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.03350020945072174, 'loss_2': 0.0029048919677734375, 'loss_3': -15.988704681396484, 'loss_4': 2.325463056564331, 'epoch': 6.24}
{'loss': 0.0256, 'grad_norm': 9.705256462097168, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.025516286492347717, 'loss_2': 8.380413055419922e-05, 'loss_3': -15.98292350769043, 'loss_4': 2.0358242988586426, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 12:47:07,971 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:07,971 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [27:02<1:10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:15,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02336745522916317, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.726, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015697767958045006, 'eval_loss_2': 0.007669687271118164, 'eval_loss_3': -18.270750045776367, 'eval_loss_4': 2.4482157230377197, 'epoch': 6.25}
{'loss': 0.0329, 'grad_norm': 9.319649696350098, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.02860771119594574, 'loss_2': 0.0042572021484375, 'loss_3': -16.17888832092285, 'loss_4': 2.582094669342041, 'epoch': 6.26}
{'loss': 0.0343, 'grad_norm': 12.516676902770996, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.029416706413030624, 'loss_2': 0.00492095947265625, 'loss_3': -15.853556632995605, 'loss_4': 2.4770658016204834, 'epoch': 6.26}
{'loss': 0.0373, 'grad_norm': 12.827767372131348, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.028675109148025513, 'loss_2': 0.00861358642578125, 'loss_3': -16.030162811279297, 'loss_4': 2.5392069816589355, 'epoch': 6.27}
{'loss': 0.0109, 'grad_norm': 5.5829081535339355, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.007410764694213867, 'loss_2': 0.003536224365234375, 'loss_3': -16.137840270996094, 'loss_4': 1.9671533107757568, 'epoch': 6.27}
{'loss': 0.0191, 'grad_norm': 5.780454635620117, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.013683774508535862, 'loss_2': 0.00543975830078125, 'loss_3': -16.13175392150879, 'loss_4': 2.3270809650421143, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 12:47:15,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:15,322 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:09<1:10:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:22,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018976865336298943, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.509, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01586487516760826, 'eval_loss_2': 0.0031119883060455322, 'eval_loss_3': -18.242509841918945, 'eval_loss_4': 2.2136850357055664, 'epoch': 6.28}
{'loss': 0.0172, 'grad_norm': 6.084457874298096, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.011008825153112411, 'loss_2': 0.0061492919921875, 'loss_3': -16.205705642700195, 'loss_4': 1.869141697883606, 'epoch': 6.28}
{'loss': 0.0184, 'grad_norm': 7.300543308258057, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.017686104401946068, 'loss_2': 0.000728607177734375, 'loss_3': -16.248023986816406, 'loss_4': 1.945585012435913, 'epoch': 6.29}
{'loss': 0.0287, 'grad_norm': 11.737309455871582, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.021417194977402687, 'loss_2': 0.00727081298828125, 'loss_3': -16.14653968811035, 'loss_4': 2.0509696006774902, 'epoch': 6.3}
{'loss': 0.0206, 'grad_norm': 8.519587516784668, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.019906295463442802, 'loss_2': 0.0006456375122070312, 'loss_3': -16.092586517333984, 'loss_4': 2.0561113357543945, 'epoch': 6.3}
{'loss': 0.0448, 'grad_norm': 15.166259765625, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.04185107350349426, 'loss_2': 0.0029392242431640625, 'loss_3': -16.28638458251953, 'loss_4': 2.3925561904907227, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 12:47:22,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:22,662 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:17<1:10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:30,000 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021768230944871902, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01805809512734413, 'eval_loss_2': 0.003710135817527771, 'eval_loss_3': -18.200239181518555, 'eval_loss_4': 1.9968633651733398, 'epoch': 6.31}
{'loss': 0.0425, 'grad_norm': 14.728375434875488, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.04079023748636246, 'loss_2': 0.0017547607421875, 'loss_3': -16.221729278564453, 'loss_4': 2.180342197418213, 'epoch': 6.31}
{'loss': 0.0282, 'grad_norm': 10.949616432189941, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.019087394699454308, 'loss_2': 0.0090789794921875, 'loss_3': -16.08800506591797, 'loss_4': 2.693612575531006, 'epoch': 6.32}
{'loss': 0.0428, 'grad_norm': 16.214569091796875, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.04199612885713577, 'loss_2': 0.0008134841918945312, 'loss_3': -15.876785278320312, 'loss_4': 1.8042327165603638, 'epoch': 6.33}
{'loss': 0.0208, 'grad_norm': 7.024247169494629, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.014884887263178825, 'loss_2': 0.005878448486328125, 'loss_3': -16.192319869995117, 'loss_4': 1.945127010345459, 'epoch': 6.33}
{'loss': 0.0196, 'grad_norm': 6.304567813873291, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.01686754636466503, 'loss_2': 0.002685546875, 'loss_3': -15.960139274597168, 'loss_4': 2.162848949432373, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 12:47:30,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:30,001 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:24<1:10:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:37,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026337599381804466, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.788, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02011963352560997, 'eval_loss_2': 0.006217963993549347, 'eval_loss_3': -18.149639129638672, 'eval_loss_4': 1.8854191303253174, 'epoch': 6.34}
{'loss': 0.0313, 'grad_norm': 11.51833438873291, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.02562168426811695, 'loss_2': 0.005706787109375, 'loss_3': -16.14664077758789, 'loss_4': 1.6275370121002197, 'epoch': 6.34}
{'loss': 0.0125, 'grad_norm': 8.460652351379395, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.010233785957098007, 'loss_2': 0.00228118896484375, 'loss_3': -15.97248363494873, 'loss_4': 1.6396729946136475, 'epoch': 6.35}
{'loss': 0.0126, 'grad_norm': 6.725705623626709, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.011941195465624332, 'loss_2': 0.0006923675537109375, 'loss_3': -16.068859100341797, 'loss_4': 1.7450916767120361, 'epoch': 6.35}
{'loss': 0.0147, 'grad_norm': 7.104715347290039, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.012163299135863781, 'loss_2': 0.002490997314453125, 'loss_3': -15.962776184082031, 'loss_4': 1.6606745719909668, 'epoch': 6.36}
{'loss': 0.0188, 'grad_norm': 6.842365741729736, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.01777595467865467, 'loss_2': 0.0010509490966796875, 'loss_3': -15.980629920959473, 'loss_4': 1.4728286266326904, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 12:47:37,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:37,357 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:31<1:10:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:44,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022768931463360786, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.597, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019148588180541992, 'eval_loss_2': 0.003620341420173645, 'eval_loss_3': -18.18080711364746, 'eval_loss_4': 1.7373313903808594, 'epoch': 6.37}
{'loss': 0.0238, 'grad_norm': 14.78050422668457, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.022348199039697647, 'loss_2': 0.0014095306396484375, 'loss_3': -15.898758888244629, 'loss_4': 1.9116427898406982, 'epoch': 6.37}
{'loss': 0.0181, 'grad_norm': 5.4411749839782715, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.009449923411011696, 'loss_2': 0.0086517333984375, 'loss_3': -16.109439849853516, 'loss_4': 1.8221344947814941, 'epoch': 6.38}
{'loss': 0.0141, 'grad_norm': 5.519938945770264, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.009515827521681786, 'loss_2': 0.00455474853515625, 'loss_3': -16.038131713867188, 'loss_4': 1.3929370641708374, 'epoch': 6.38}
{'loss': 0.0283, 'grad_norm': 8.494558334350586, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.01953323744237423, 'loss_2': 0.008758544921875, 'loss_3': -16.04472541809082, 'loss_4': 1.159143090248108, 'epoch': 6.39}
{'loss': 0.0322, 'grad_norm': 7.572341442108154, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.017220469191670418, 'loss_2': 0.01495361328125, 'loss_3': -15.99259090423584, 'loss_4': 0.7454959154129028, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 12:47:44,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:44,701 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:39<1:10:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:52,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024994710460305214, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01874423958361149, 'eval_loss_2': 0.006250470876693726, 'eval_loss_3': -18.14484405517578, 'eval_loss_4': 1.5158236026763916, 'epoch': 6.4}
{'loss': 0.0199, 'grad_norm': 8.554426193237305, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.017834443598985672, 'loss_2': 0.002044677734375, 'loss_3': -15.908069610595703, 'loss_4': 1.7038345336914062, 'epoch': 6.4}
{'loss': 0.036, 'grad_norm': 13.584868431091309, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.035123247653245926, 'loss_2': 0.000873565673828125, 'loss_3': -16.156755447387695, 'loss_4': 1.8847821950912476, 'epoch': 6.41}
{'loss': 0.0533, 'grad_norm': 20.527902603149414, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.05311916396021843, 'loss_2': 0.00014269351959228516, 'loss_3': -15.776409149169922, 'loss_4': 1.4669220447540283, 'epoch': 6.41}
{'loss': 0.0229, 'grad_norm': 8.709360122680664, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.0218106247484684, 'loss_2': 0.0010395050048828125, 'loss_3': -16.032461166381836, 'loss_4': 1.4590058326721191, 'epoch': 6.42}
{'loss': 0.0386, 'grad_norm': 14.435609817504883, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.033376120030879974, 'loss_2': 0.00521087646484375, 'loss_3': -15.986166954040527, 'loss_4': 1.6572507619857788, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 12:47:52,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:52,053 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:46<1:10:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:59,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028286246582865715, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.020347803831100464, 'eval_loss_2': 0.0079384446144104, 'eval_loss_3': -18.122739791870117, 'eval_loss_4': 1.7517155408859253, 'epoch': 6.42}
{'loss': 0.02, 'grad_norm': 7.08348274230957, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.018778201192617416, 'loss_2': 0.0012426376342773438, 'loss_3': -16.081735610961914, 'loss_4': 1.9965606927871704, 'epoch': 6.43}
{'loss': 0.0326, 'grad_norm': 10.119044303894043, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.022939350455999374, 'loss_2': 0.0096588134765625, 'loss_3': -16.21844482421875, 'loss_4': 1.6943626403808594, 'epoch': 6.44}
{'loss': 0.037, 'grad_norm': 9.909530639648438, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.03085167706012726, 'loss_2': 0.006160736083984375, 'loss_3': -16.0384521484375, 'loss_4': 1.7962924242019653, 'epoch': 6.44}
{'loss': 0.0407, 'grad_norm': 9.072298049926758, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.028568381443619728, 'loss_2': 0.01214599609375, 'loss_3': -16.09100341796875, 'loss_4': 1.7462472915649414, 'epoch': 6.45}
{'loss': 0.0227, 'grad_norm': 8.740029335021973, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.020307494327425957, 'loss_2': 0.002429962158203125, 'loss_3': -16.13300132751465, 'loss_4': 1.4346165657043457, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 12:47:59,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:59,403 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:53<1:10:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:06,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023392044007778168, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01939193159341812, 'eval_loss_2': 0.004000112414360046, 'eval_loss_3': -18.165199279785156, 'eval_loss_4': 1.7505717277526855, 'epoch': 6.45}
{'loss': 0.0306, 'grad_norm': 8.764508247375488, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.02322966232895851, 'loss_2': 0.007415771484375, 'loss_3': -15.888148307800293, 'loss_4': 1.8079016208648682, 'epoch': 6.46}
{'loss': 0.0272, 'grad_norm': 15.320939064025879, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.0254491176456213, 'loss_2': 0.0017414093017578125, 'loss_3': -16.010961532592773, 'loss_4': 1.7275879383087158, 'epoch': 6.47}
{'loss': 0.0286, 'grad_norm': 6.399127960205078, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.016543768346309662, 'loss_2': 0.0121002197265625, 'loss_3': -15.874288558959961, 'loss_4': 1.6651101112365723, 'epoch': 6.47}
{'loss': 0.0319, 'grad_norm': 7.626840114593506, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.03015144355595112, 'loss_2': 0.00177001953125, 'loss_3': -16.11507225036621, 'loss_4': 1.3468923568725586, 'epoch': 6.48}
{'loss': 0.0225, 'grad_norm': 12.1848783493042, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.021322743967175484, 'loss_2': 0.0011463165283203125, 'loss_3': -16.108638763427734, 'loss_4': 1.3883118629455566, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 12:48:06,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:06,754 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [28:01<1:09:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:14,113 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01859283819794655, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.773, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01527286134660244, 'eval_loss_2': 0.003319978713989258, 'eval_loss_3': -18.17676544189453, 'eval_loss_4': 1.497715711593628, 'epoch': 6.48}
{'loss': 0.014, 'grad_norm': 5.454423427581787, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.012217761017382145, 'loss_2': 0.0017480850219726562, 'loss_3': -16.15680503845215, 'loss_4': 1.444636583328247, 'epoch': 6.49}
{'loss': 0.0237, 'grad_norm': 5.972532749176025, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.015332706272602081, 'loss_2': 0.00832366943359375, 'loss_3': -16.013397216796875, 'loss_4': 1.3243998289108276, 'epoch': 6.49}
{'loss': 0.0297, 'grad_norm': 7.878301620483398, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.025013191625475883, 'loss_2': 0.004680633544921875, 'loss_3': -16.08565902709961, 'loss_4': 1.3821332454681396, 'epoch': 6.5}
{'loss': 0.012, 'grad_norm': 5.826717376708984, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.011385641992092133, 'loss_2': 0.0005769729614257812, 'loss_3': -16.197837829589844, 'loss_4': 1.5725090503692627, 'epoch': 6.51}
{'loss': 0.0235, 'grad_norm': 8.517569541931152, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.02035052701830864, 'loss_2': 0.0031185150146484375, 'loss_3': -15.93516731262207, 'loss_4': 0.6681035757064819, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 12:48:14,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:14,113 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:08<1:09:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:21,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020365621894598007, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0164193045347929, 'eval_loss_2': 0.003946319222450256, 'eval_loss_3': -18.145374298095703, 'eval_loss_4': 1.3377763032913208, 'epoch': 6.51}
{'loss': 0.0337, 'grad_norm': 18.979900360107422, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.03275523707270622, 'loss_2': 0.000965118408203125, 'loss_3': -15.890344619750977, 'loss_4': 1.9171282052993774, 'epoch': 6.52}
{'loss': 0.038, 'grad_norm': 14.37578010559082, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.034074537456035614, 'loss_2': 0.00392913818359375, 'loss_3': -16.103759765625, 'loss_4': 1.0799839496612549, 'epoch': 6.52}
{'loss': 0.0186, 'grad_norm': 7.522809982299805, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.015637245029211044, 'loss_2': 0.0029468536376953125, 'loss_3': -16.04305648803711, 'loss_4': 1.0445573329925537, 'epoch': 6.53}
{'loss': 0.0405, 'grad_norm': 10.51938533782959, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.036117542535066605, 'loss_2': 0.004390716552734375, 'loss_3': -16.036205291748047, 'loss_4': 0.9802088141441345, 'epoch': 6.53}
{'loss': 0.0201, 'grad_norm': 6.427972316741943, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.017490319907665253, 'loss_2': 0.002590179443359375, 'loss_3': -16.01279067993164, 'loss_4': 1.2949548959732056, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 12:48:21,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:21,468 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:15<1:09:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:28,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03202328830957413, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.185, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.02735821157693863, 'eval_loss_2': 0.004665076732635498, 'eval_loss_3': -18.083480834960938, 'eval_loss_4': 1.5330255031585693, 'epoch': 6.54}
{'loss': 0.0287, 'grad_norm': 7.675126075744629, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.02648518607020378, 'loss_2': 0.002216339111328125, 'loss_3': -15.945589065551758, 'loss_4': 1.166297435760498, 'epoch': 6.55}
{'loss': 0.04, 'grad_norm': 12.375367164611816, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.03811812773346901, 'loss_2': 0.0019168853759765625, 'loss_3': -15.82620620727539, 'loss_4': 1.2183215618133545, 'epoch': 6.55}
{'loss': 0.0464, 'grad_norm': 14.619885444641113, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.0340680293738842, 'loss_2': 0.012359619140625, 'loss_3': -16.002906799316406, 'loss_4': 1.2776315212249756, 'epoch': 6.56}
{'loss': 0.0406, 'grad_norm': 18.39873504638672, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.03934858739376068, 'loss_2': 0.001216888427734375, 'loss_3': -15.920112609863281, 'loss_4': 1.8511619567871094, 'epoch': 6.56}
{'loss': 0.0427, 'grad_norm': 9.198298454284668, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.027548426762223244, 'loss_2': 0.01515960693359375, 'loss_3': -16.042261123657227, 'loss_4': 1.5441083908081055, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 12:48:28,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:28,818 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:23<1:09:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:36,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04790443181991577, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03942767158150673, 'eval_loss_2': 0.00847676768898964, 'eval_loss_3': -18.058197021484375, 'eval_loss_4': 1.9395147562026978, 'epoch': 6.57}
{'loss': 0.0406, 'grad_norm': 8.242281913757324, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.028046580031514168, 'loss_2': 0.012542724609375, 'loss_3': -15.91568374633789, 'loss_4': 1.6592330932617188, 'epoch': 6.58}
{'loss': 0.0584, 'grad_norm': 12.860546112060547, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.04381993040442467, 'loss_2': 0.01456451416015625, 'loss_3': -16.033315658569336, 'loss_4': 1.6933602094650269, 'epoch': 6.58}
{'loss': 0.033, 'grad_norm': 7.409536361694336, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.018646469339728355, 'loss_2': 0.014373779296875, 'loss_3': -16.124446868896484, 'loss_4': 2.052990436553955, 'epoch': 6.59}
{'loss': 0.0916, 'grad_norm': 26.636398315429688, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.07739895582199097, 'loss_2': 0.01419830322265625, 'loss_3': -15.731517791748047, 'loss_4': 1.6581459045410156, 'epoch': 6.59}
{'loss': 0.053, 'grad_norm': 13.657206535339355, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.04624602943658829, 'loss_2': 0.00670623779296875, 'loss_3': -15.976754188537598, 'loss_4': 1.9389541149139404, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 12:48:36,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:36,170 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:30<1:09:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:43,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04796525835990906, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.04064446687698364, 'eval_loss_2': 0.007320791482925415, 'eval_loss_3': -18.0816707611084, 'eval_loss_4': 2.1681950092315674, 'epoch': 6.6}
{'loss': 0.0379, 'grad_norm': 10.830156326293945, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.03123466484248638, 'loss_2': 0.00667572021484375, 'loss_3': -16.165632247924805, 'loss_4': 1.7426159381866455, 'epoch': 6.6}
{'loss': 0.0314, 'grad_norm': 9.746198654174805, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.027260437607765198, 'loss_2': 0.004119873046875, 'loss_3': -16.095232009887695, 'loss_4': 1.5660873651504517, 'epoch': 6.61}
{'loss': 0.0412, 'grad_norm': 9.795913696289062, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.033451858907938004, 'loss_2': 0.007755279541015625, 'loss_3': -15.773735046386719, 'loss_4': 1.8303667306900024, 'epoch': 6.62}
{'loss': 0.0164, 'grad_norm': 6.582449913024902, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.01547001302242279, 'loss_2': 0.0009126663208007812, 'loss_3': -16.156932830810547, 'loss_4': 1.7765216827392578, 'epoch': 6.62}
{'loss': 0.0715, 'grad_norm': 24.951316833496094, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.06427820026874542, 'loss_2': 0.007183074951171875, 'loss_3': -15.956095695495605, 'loss_4': 2.0223135948181152, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 12:48:43,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:43,526 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:37<1:09:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:50,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024335887283086777, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.020539937540888786, 'eval_loss_2': 0.0037959516048431396, 'eval_loss_3': -18.185832977294922, 'eval_loss_4': 1.9883685111999512, 'epoch': 6.63}
{'loss': 0.0657, 'grad_norm': 18.59722900390625, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.05786353349685669, 'loss_2': 0.007843017578125, 'loss_3': -15.945243835449219, 'loss_4': 1.5347665548324585, 'epoch': 6.63}
{'loss': 0.0357, 'grad_norm': 8.402156829833984, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.032346274703741074, 'loss_2': 0.00334930419921875, 'loss_3': -16.1633243560791, 'loss_4': 2.0577008724212646, 'epoch': 6.64}
{'loss': 0.035, 'grad_norm': 9.297663688659668, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.028516367077827454, 'loss_2': 0.006473541259765625, 'loss_3': -16.031875610351562, 'loss_4': 1.7513611316680908, 'epoch': 6.65}
{'loss': 0.1958, 'grad_norm': 16.30093002319336, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.19085855782032013, 'loss_2': 0.00492095947265625, 'loss_3': -15.63970947265625, 'loss_4': 2.1363563537597656, 'epoch': 6.65}
{'loss': 0.0318, 'grad_norm': 9.870867729187012, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.03011486865580082, 'loss_2': 0.00164031982421875, 'loss_3': -16.098575592041016, 'loss_4': 2.432941436767578, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 12:48:50,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:50,886 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:45<1:09:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:58,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01811925321817398, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01389711257070303, 'eval_loss_2': 0.0042221397161483765, 'eval_loss_3': -18.22129249572754, 'eval_loss_4': 2.055295705795288, 'epoch': 6.66}
{'loss': 0.0403, 'grad_norm': 13.097474098205566, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.03880178928375244, 'loss_2': 0.0014934539794921875, 'loss_3': -16.17593002319336, 'loss_4': 1.9008058309555054, 'epoch': 6.66}
{'loss': 0.0345, 'grad_norm': 10.075287818908691, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.03159228339791298, 'loss_2': 0.0028629302978515625, 'loss_3': -16.06106185913086, 'loss_4': 2.3227431774139404, 'epoch': 6.67}
{'loss': 0.0221, 'grad_norm': 5.151524543762207, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.010656515136361122, 'loss_2': 0.011444091796875, 'loss_3': -16.199115753173828, 'loss_4': 2.140044927597046, 'epoch': 6.67}
{'loss': 0.0307, 'grad_norm': 22.46352767944336, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.02707183174788952, 'loss_2': 0.0036468505859375, 'loss_3': -16.07016944885254, 'loss_4': 2.7068140506744385, 'epoch': 6.68}
{'loss': 0.0366, 'grad_norm': 11.065114974975586, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.033532366156578064, 'loss_2': 0.003086090087890625, 'loss_3': -16.282207489013672, 'loss_4': 2.200237274169922, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 12:48:58,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:58,239 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:52<1:09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:05,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017831388860940933, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.556, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012836875393986702, 'eval_loss_2': 0.004994511604309082, 'eval_loss_3': -18.270326614379883, 'eval_loss_4': 2.236938238143921, 'epoch': 6.69}
{'loss': 0.0469, 'grad_norm': 12.208730697631836, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.04082147404551506, 'loss_2': 0.0061187744140625, 'loss_3': -16.221378326416016, 'loss_4': 3.5028486251831055, 'epoch': 6.69}
{'loss': 0.0648, 'grad_norm': 20.537216186523438, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.05897862836718559, 'loss_2': 0.005855560302734375, 'loss_3': -16.138465881347656, 'loss_4': 3.643033504486084, 'epoch': 6.7}
{'loss': 0.0304, 'grad_norm': 16.2646484375, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.029307657852768898, 'loss_2': 0.00104522705078125, 'loss_3': -16.04805564880371, 'loss_4': 2.6443395614624023, 'epoch': 6.7}
{'loss': 0.0553, 'grad_norm': 19.42891502380371, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.051837168633937836, 'loss_2': 0.00341796875, 'loss_3': -16.039777755737305, 'loss_4': 3.6259407997131348, 'epoch': 6.71}
{'loss': 0.0566, 'grad_norm': 18.172353744506836, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.05225794389843941, 'loss_2': 0.00432586669921875, 'loss_3': -16.120468139648438, 'loss_4': 2.8927769660949707, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 12:49:05,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:05,590 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [28:59<1:09:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:12,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01835533231496811, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0139515595510602, 'eval_loss_2': 0.004403773695230484, 'eval_loss_3': -18.25714111328125, 'eval_loss_4': 2.047663450241089, 'epoch': 6.72}
{'loss': 0.0235, 'grad_norm': 10.029526710510254, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.018321344628930092, 'loss_2': 0.0052032470703125, 'loss_3': -15.97730541229248, 'loss_4': 2.247466802597046, 'epoch': 6.72}
{'loss': 0.0195, 'grad_norm': 7.508047103881836, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.01723940670490265, 'loss_2': 0.0022220611572265625, 'loss_3': -16.095243453979492, 'loss_4': 2.336866617202759, 'epoch': 6.73}
{'loss': 0.1285, 'grad_norm': 21.788789749145508, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.12797299027442932, 'loss_2': 0.0005331039428710938, 'loss_3': -16.19207763671875, 'loss_4': 2.619546413421631, 'epoch': 6.73}
{'loss': 0.1215, 'grad_norm': 26.579761505126953, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.11548507213592529, 'loss_2': 0.0059967041015625, 'loss_3': -16.15713119506836, 'loss_4': 2.0216856002807617, 'epoch': 6.74}
{'loss': 0.0311, 'grad_norm': 10.191912651062012, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.029209017753601074, 'loss_2': 0.001865386962890625, 'loss_3': -16.197998046875, 'loss_4': 2.341495990753174, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 12:49:12,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:12,932 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:07<1:09:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:20,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02025233395397663, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.729, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013453527353703976, 'eval_loss_2': 0.006798803806304932, 'eval_loss_3': -18.240785598754883, 'eval_loss_4': 1.456099033355713, 'epoch': 6.74}
{'loss': 0.0201, 'grad_norm': 6.012054920196533, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.012913770973682404, 'loss_2': 0.007213592529296875, 'loss_3': -16.339059829711914, 'loss_4': 1.6982409954071045, 'epoch': 6.75}
{'loss': 0.0401, 'grad_norm': 11.884021759033203, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.03771323710680008, 'loss_2': 0.0023956298828125, 'loss_3': -16.02703857421875, 'loss_4': 1.5257138013839722, 'epoch': 6.76}
{'loss': 0.0393, 'grad_norm': 12.107338905334473, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.03625304251909256, 'loss_2': 0.0030574798583984375, 'loss_3': -16.101566314697266, 'loss_4': 1.694826602935791, 'epoch': 6.76}
{'loss': 0.0251, 'grad_norm': 12.623388290405273, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.023960214108228683, 'loss_2': 0.0011873245239257812, 'loss_3': -16.039297103881836, 'loss_4': 1.3165853023529053, 'epoch': 6.77}
{'loss': 0.0425, 'grad_norm': 15.114846229553223, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.038117628544569016, 'loss_2': 0.004364013671875, 'loss_3': -16.288686752319336, 'loss_4': 1.5270328521728516, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 12:49:20,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:20,270 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:14<1:08:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:27,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01796116679906845, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014170045033097267, 'eval_loss_2': 0.003791123628616333, 'eval_loss_3': -18.201473236083984, 'eval_loss_4': 1.1432998180389404, 'epoch': 6.77}
{'loss': 0.0311, 'grad_norm': 12.088920593261719, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.030974918976426125, 'loss_2': 0.00015783309936523438, 'loss_3': -16.149316787719727, 'loss_4': 1.3070868253707886, 'epoch': 6.78}
{'loss': 0.025, 'grad_norm': 6.933382511138916, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.0200912244617939, 'loss_2': 0.004913330078125, 'loss_3': -16.244007110595703, 'loss_4': 1.3190914392471313, 'epoch': 6.78}
{'loss': 0.0236, 'grad_norm': 7.867685317993164, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.02229703590273857, 'loss_2': 0.0013399124145507812, 'loss_3': -16.18217658996582, 'loss_4': 1.2735611200332642, 'epoch': 6.79}
{'loss': 0.0188, 'grad_norm': 6.928164958953857, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.012524645775556564, 'loss_2': 0.0063018798828125, 'loss_3': -16.165742874145508, 'loss_4': 0.7727817296981812, 'epoch': 6.8}
{'loss': 0.0194, 'grad_norm': 6.699112892150879, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.01578027382493019, 'loss_2': 0.0036163330078125, 'loss_3': -16.156753540039062, 'loss_4': 1.4701781272888184, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 12:49:27,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:27,605 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:22<1:08:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:34,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016801634803414345, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012995341792702675, 'eval_loss_2': 0.00380629301071167, 'eval_loss_3': -18.19292449951172, 'eval_loss_4': 1.1746002435684204, 'epoch': 6.8}
{'loss': 0.0292, 'grad_norm': 9.118223190307617, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.02780921570956707, 'loss_2': 0.00140380859375, 'loss_3': -16.371782302856445, 'loss_4': 1.3693082332611084, 'epoch': 6.81}
{'loss': 0.0194, 'grad_norm': 6.5218071937561035, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.017940282821655273, 'loss_2': 0.0014286041259765625, 'loss_3': -16.37582015991211, 'loss_4': 1.0088772773742676, 'epoch': 6.81}
{'loss': 0.0343, 'grad_norm': 7.791053771972656, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.030753152444958687, 'loss_2': 0.003513336181640625, 'loss_3': -16.291635513305664, 'loss_4': 1.9094089269638062, 'epoch': 6.82}
{'loss': 0.0336, 'grad_norm': 16.885438919067383, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.02624470368027687, 'loss_2': 0.007354736328125, 'loss_3': -16.340574264526367, 'loss_4': 1.3763103485107422, 'epoch': 6.83}
{'loss': 0.0209, 'grad_norm': 7.200318336486816, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.014810980297625065, 'loss_2': 0.00606536865234375, 'loss_3': -16.32819175720215, 'loss_4': 1.3834342956542969, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 12:49:34,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:34,954 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:29<1:08:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:42,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02080933377146721, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.475, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011867444030940533, 'eval_loss_2': 0.008941888809204102, 'eval_loss_3': -18.208940505981445, 'eval_loss_4': 1.4527268409729004, 'epoch': 6.83}
{'loss': 0.039, 'grad_norm': 10.216085433959961, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.03431950509548187, 'loss_2': 0.00469207763671875, 'loss_3': -16.284809112548828, 'loss_4': 1.5399205684661865, 'epoch': 6.84}
{'loss': 0.0211, 'grad_norm': 6.832237720489502, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.015321656130254269, 'loss_2': 0.00576019287109375, 'loss_3': -16.30304718017578, 'loss_4': 1.4823342561721802, 'epoch': 6.84}
{'loss': 0.0279, 'grad_norm': 10.636967658996582, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.023124827072024345, 'loss_2': 0.00482177734375, 'loss_3': -16.430923461914062, 'loss_4': 1.796604037284851, 'epoch': 6.85}
{'loss': 0.0336, 'grad_norm': 9.840076446533203, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.0275658518075943, 'loss_2': 0.0059967041015625, 'loss_3': -16.030445098876953, 'loss_4': 1.9500033855438232, 'epoch': 6.85}
{'loss': 0.0152, 'grad_norm': 5.48093843460083, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.010576467029750347, 'loss_2': 0.00460052490234375, 'loss_3': -16.215824127197266, 'loss_4': 1.7767252922058105, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 12:49:42,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:42,311 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:33<1:08:53,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:49:46,114 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180
[INFO|configuration_utils.py:420] 2025-01-21 12:49:46,116 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180/config.json                                                                            
{'eval_loss': 0.014707226306200027, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010416191071271896, 'eval_loss_2': 0.004291035234928131, 'eval_loss_3': -18.22261619567871, 'eval_loss_4': 1.5701144933700562, 'epoch': 6.86}
[INFO|modeling_utils.py:2988] 2025-01-21 12:49:46,597 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:49:46,598 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:49:46,598 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:49:47,535 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1040] due to args.save_total_limit
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:38<1:16:00,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:49:51,172 >>
{'loss': 0.0364, 'grad_norm': 18.191452026367188, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.03581250086426735, 'loss_2': 0.0005664825439453125, 'loss_3': -16.128707885742188, 'loss_4': 1.7263858318328857, 'epoch': 6.87}
{'loss': 0.0519, 'grad_norm': 18.9586181640625, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.042373575270175934, 'loss_2': 0.0095062255859375, 'loss_3': -16.315475463867188, 'loss_4': 1.8008203506469727, 'epoch': 6.87}
{'loss': 0.0217, 'grad_norm': 6.747226238250732, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.015267154201865196, 'loss_2': 0.0063934326171875, 'loss_3': -16.50875473022461, 'loss_4': 1.7458255290985107, 'epoch': 6.88}
{'loss': 0.0274, 'grad_norm': 6.800239562988281, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.01944209635257721, 'loss_2': 0.007965087890625, 'loss_3': -16.259159088134766, 'loss_4': 1.052815556526184, 'epoch': 6.88}
{'loss': 0.033, 'grad_norm': 8.47783374786377, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.025589440017938614, 'loss_2': 0.007415771484375, 'loss_3': -16.324687957763672, 'loss_4': 1.2128446102142334, 'epoch': 6.89}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:49:51,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:51,172 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:45<1:09:53,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:49:58,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01638762652873993, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009580060839653015, 'eval_loss_2': 0.006807565689086914, 'eval_loss_3': -18.220182418823242, 'eval_loss_4': 1.5687909126281738, 'epoch': 6.89}
{'loss': 0.0614, 'grad_norm': 23.25222396850586, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.05787786468863487, 'loss_2': 0.003566741943359375, 'loss_3': -16.415987014770508, 'loss_4': 1.9129638671875, 'epoch': 6.9}
{'loss': 0.0107, 'grad_norm': 4.931739807128906, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.008832220919430256, 'loss_2': 0.0018796920776367188, 'loss_3': -16.260318756103516, 'loss_4': 1.6226972341537476, 'epoch': 6.9}
{'loss': 0.0196, 'grad_norm': 7.438557147979736, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.01825103722512722, 'loss_2': 0.0013866424560546875, 'loss_3': -16.106788635253906, 'loss_4': 1.4268040657043457, 'epoch': 6.91}
{'loss': 0.0178, 'grad_norm': 9.724077224731445, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.016375187784433365, 'loss_2': 0.00146484375, 'loss_3': -16.330947875976562, 'loss_4': 1.2872459888458252, 'epoch': 6.91}
{'loss': 0.0338, 'grad_norm': 10.939979553222656, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.029622552916407585, 'loss_2': 0.00418853759765625, 'loss_3': -16.19955825805664, 'loss_4': 1.6871006488800049, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 12:49:58,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:58,519 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:52<1:08:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:05,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016011809930205345, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.585, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010695911012589931, 'eval_loss_2': 0.005315899848937988, 'eval_loss_3': -18.253116607666016, 'eval_loss_4': 1.310934066772461, 'epoch': 6.92}
{'loss': 0.0208, 'grad_norm': 6.991982460021973, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.018195169046521187, 'loss_2': 0.0025653839111328125, 'loss_3': -16.26974105834961, 'loss_4': 1.7066669464111328, 'epoch': 6.92}
{'loss': 0.0308, 'grad_norm': 15.519610404968262, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.02946946583688259, 'loss_2': 0.0012912750244140625, 'loss_3': -15.79540729522705, 'loss_4': 1.1628421545028687, 'epoch': 6.93}
{'loss': 0.0183, 'grad_norm': 5.924931049346924, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.01074070855975151, 'loss_2': 0.00757598876953125, 'loss_3': -16.205062866210938, 'loss_4': 1.5918385982513428, 'epoch': 6.94}
{'loss': 0.0212, 'grad_norm': 5.661678314208984, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.014546365477144718, 'loss_2': 0.0066986083984375, 'loss_3': -16.18889808654785, 'loss_4': 1.398823618888855, 'epoch': 6.94}
{'loss': 0.0169, 'grad_norm': 6.6338934898376465, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.012354420498013496, 'loss_2': 0.00457763671875, 'loss_3': -16.150115966796875, 'loss_4': 1.916858196258545, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 12:50:05,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:05,861 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [30:00<1:08:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:13,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015354778617620468, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.281, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011116230860352516, 'eval_loss_2': 0.004238545894622803, 'eval_loss_3': -18.283870697021484, 'eval_loss_4': 1.1964426040649414, 'epoch': 6.95}
{'loss': 0.0158, 'grad_norm': 6.105047702789307, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.01193180587142706, 'loss_2': 0.00386810302734375, 'loss_3': -16.33460235595703, 'loss_4': 2.05668306350708, 'epoch': 6.95}
{'loss': 0.0254, 'grad_norm': 9.766977310180664, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.020785139873623848, 'loss_2': 0.00457000732421875, 'loss_3': -16.247135162353516, 'loss_4': 1.242538571357727, 'epoch': 6.96}
{'loss': 0.0366, 'grad_norm': 10.416085243225098, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.029582306742668152, 'loss_2': 0.006988525390625, 'loss_3': -16.26406478881836, 'loss_4': 2.0828773975372314, 'epoch': 6.97}
{'loss': 0.0221, 'grad_norm': 6.671510696411133, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.01777416095137596, 'loss_2': 0.00434112548828125, 'loss_3': -16.07958221435547, 'loss_4': 2.3284482955932617, 'epoch': 6.97}
{'loss': 0.0183, 'grad_norm': 6.501357555389404, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.016906429082155228, 'loss_2': 0.0014019012451171875, 'loss_3': -15.98775863647461, 'loss_4': 1.568239450454712, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 12:50:13,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:13,207 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:07<1:04:27,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 12:50:20,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015315819531679153, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.877, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010963472537696362, 'eval_loss_2': 0.004352346062660217, 'eval_loss_3': -18.276012420654297, 'eval_loss_4': 0.9224562048912048, 'epoch': 6.98}
{'loss': 0.0185, 'grad_norm': 7.379431247711182, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.017214875668287277, 'loss_2': 0.00127410888671875, 'loss_3': -16.127384185791016, 'loss_4': 1.5067365169525146, 'epoch': 6.98}
{'loss': 0.0407, 'grad_norm': 10.25075626373291, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.033601414412260056, 'loss_2': 0.0071258544921875, 'loss_3': -16.094329833984375, 'loss_4': 1.205614447593689, 'epoch': 6.99}
{'loss': 0.0351, 'grad_norm': 12.785283088684082, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.03316808491945267, 'loss_2': 0.0019235610961914062, 'loss_3': -16.131839752197266, 'loss_4': 1.309635877609253, 'epoch': 6.99}
{'loss': 0.0103, 'grad_norm': 6.663084506988525, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.009599548764526844, 'loss_2': 0.0006895065307617188, 'loss_3': -16.041311264038086, 'loss_4': 1.4728960990905762, 'epoch': 7.0}
{'loss': 0.0225, 'grad_norm': 6.659943103790283, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.016346514225006104, 'loss_2': 0.00615692138671875, 'loss_3': -16.15283966064453, 'loss_4': 0.6045563220977783, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 12:50:20,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:20,249 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:14<1:07:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:50:27,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018917858600616455, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012792469002306461, 'eval_loss_2': 0.006125390529632568, 'eval_loss_3': -18.237855911254883, 'eval_loss_4': 0.6280542016029358, 'epoch': 7.01}
{'loss': 0.0332, 'grad_norm': 10.517512321472168, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.03106536529958248, 'loss_2': 0.0021152496337890625, 'loss_3': -16.03609848022461, 'loss_4': 0.675430417060852, 'epoch': 7.01}
{'loss': 0.0324, 'grad_norm': 7.457343101501465, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.020579731091856956, 'loss_2': 0.0118560791015625, 'loss_3': -16.053150177001953, 'loss_4': 1.018934726715088, 'epoch': 7.02}
{'loss': 0.0186, 'grad_norm': 7.626062393188477, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.01773671619594097, 'loss_2': 0.0008206367492675781, 'loss_3': -16.058225631713867, 'loss_4': 0.485032856464386, 'epoch': 7.02}
{'loss': 0.0242, 'grad_norm': 8.384344100952148, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.019457265734672546, 'loss_2': 0.00476837158203125, 'loss_3': -15.920906066894531, 'loss_4': 0.4036185145378113, 'epoch': 7.03}
{'loss': 0.0294, 'grad_norm': 9.351709365844727, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.023885464295744896, 'loss_2': 0.005523681640625, 'loss_3': -16.04198455810547, 'loss_4': -0.07110647857189178, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 12:50:27,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:27,585 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:22<1:08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:34,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02164217084646225, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014548455365002155, 'eval_loss_2': 0.007093712687492371, 'eval_loss_3': -18.261743545532227, 'eval_loss_4': 0.494449257850647, 'epoch': 7.03}
{'loss': 0.0231, 'grad_norm': 5.976516246795654, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.01609176956117153, 'loss_2': 0.007022857666015625, 'loss_3': -15.990506172180176, 'loss_4': 0.9342336058616638, 'epoch': 7.04}
{'loss': 0.0194, 'grad_norm': 7.036223411560059, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.016252152621746063, 'loss_2': 0.00311279296875, 'loss_3': -16.1992130279541, 'loss_4': 0.4087072014808655, 'epoch': 7.05}
{'loss': 0.0402, 'grad_norm': 10.118677139282227, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.039401162415742874, 'loss_2': 0.0007648468017578125, 'loss_3': -16.401771545410156, 'loss_4': 1.0179554224014282, 'epoch': 7.05}
{'loss': 0.016, 'grad_norm': 5.9194207191467285, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.015811387449502945, 'loss_2': 0.00015163421630859375, 'loss_3': -16.050188064575195, 'loss_4': 0.7387449145317078, 'epoch': 7.06}
{'loss': 0.0349, 'grad_norm': 12.466197967529297, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.030738357454538345, 'loss_2': 0.004169464111328125, 'loss_3': -16.28473663330078, 'loss_4': 1.3005154132843018, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 12:50:34,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:34,939 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:29<1:08:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:42,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02257571555674076, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014222600497305393, 'eval_loss_2': 0.008353114128112793, 'eval_loss_3': -18.245159149169922, 'eval_loss_4': 0.8733862042427063, 'epoch': 7.06}
{'loss': 0.021, 'grad_norm': 7.08787727355957, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.01758035644888878, 'loss_2': 0.003437042236328125, 'loss_3': -16.224464416503906, 'loss_4': 1.3521530628204346, 'epoch': 7.07}
{'loss': 0.0467, 'grad_norm': 10.22767448425293, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.03135086968541145, 'loss_2': 0.0153961181640625, 'loss_3': -16.093502044677734, 'loss_4': 1.6017963886260986, 'epoch': 7.08}
{'loss': 0.0289, 'grad_norm': 8.397536277770996, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.022885339334607124, 'loss_2': 0.00598907470703125, 'loss_3': -16.10479164123535, 'loss_4': 0.849870502948761, 'epoch': 7.08}
{'loss': 0.0347, 'grad_norm': 10.761120796203613, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.02595999836921692, 'loss_2': 0.0087890625, 'loss_3': -16.222957611083984, 'loss_4': 0.8943735361099243, 'epoch': 7.09}
{'loss': 0.0491, 'grad_norm': 28.076526641845703, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.04008255898952484, 'loss_2': 0.009033203125, 'loss_3': -16.323009490966797, 'loss_4': 1.3999998569488525, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 12:50:42,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:42,285 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:36<1:08:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:49,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02376352995634079, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.701, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01679997891187668, 'eval_loss_2': 0.006963551044464111, 'eval_loss_3': -18.232500076293945, 'eval_loss_4': 1.0532307624816895, 'epoch': 7.09}
{'loss': 0.0229, 'grad_norm': 7.618172645568848, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.019680187106132507, 'loss_2': 0.003223419189453125, 'loss_3': -16.148788452148438, 'loss_4': 1.0135078430175781, 'epoch': 7.1}
{'loss': 0.0319, 'grad_norm': 9.100665092468262, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.026298169046640396, 'loss_2': 0.005649566650390625, 'loss_3': -16.079917907714844, 'loss_4': 1.3259217739105225, 'epoch': 7.1}
{'loss': 0.0351, 'grad_norm': 7.024369239807129, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.022829780355095863, 'loss_2': 0.012298583984375, 'loss_3': -16.10564422607422, 'loss_4': 1.029529333114624, 'epoch': 7.11}
{'loss': 0.1793, 'grad_norm': 20.136293411254883, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.17632149159908295, 'loss_2': 0.00299072265625, 'loss_3': -16.132150650024414, 'loss_4': 1.445258617401123, 'epoch': 7.12}
{'loss': 0.0268, 'grad_norm': 6.989116191864014, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.018638838082551956, 'loss_2': 0.008209228515625, 'loss_3': -16.169965744018555, 'loss_4': 1.647033452987671, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 12:50:49,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:49,646 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:44<1:08:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:57,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02167518436908722, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.605, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.017689302563667297, 'eval_loss_2': 0.003985881805419922, 'eval_loss_3': -18.251625061035156, 'eval_loss_4': 1.311095952987671, 'epoch': 7.12}
{'loss': 0.0265, 'grad_norm': 8.0112886428833, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.0199433621019125, 'loss_2': 0.006595611572265625, 'loss_3': -16.095674514770508, 'loss_4': 1.641087532043457, 'epoch': 7.13}
{'loss': 0.0325, 'grad_norm': 10.686086654663086, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.030565891414880753, 'loss_2': 0.001964569091796875, 'loss_3': -16.17068099975586, 'loss_4': 1.75053071975708, 'epoch': 7.13}
{'loss': 0.0382, 'grad_norm': 15.214088439941406, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.03200257569551468, 'loss_2': 0.0062103271484375, 'loss_3': -16.033449172973633, 'loss_4': 0.9117461442947388, 'epoch': 7.14}
{'loss': 0.0137, 'grad_norm': 5.2691121101379395, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.009171765297651291, 'loss_2': 0.00457000732421875, 'loss_3': -16.324810028076172, 'loss_4': 1.6032419204711914, 'epoch': 7.15}
{'loss': 0.0309, 'grad_norm': 8.780585289001465, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.025349102914333344, 'loss_2': 0.0055694580078125, 'loss_3': -16.080780029296875, 'loss_4': 1.1799631118774414, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 12:50:57,013 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:57,013 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:51<1:08:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:04,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022660210728645325, 'eval_runtime': 3.821, 'eval_samples_per_second': 267.996, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.014694111421704292, 'eval_loss_2': 0.007966101169586182, 'eval_loss_3': -18.259052276611328, 'eval_loss_4': 1.5091843605041504, 'epoch': 7.15}
{'loss': 0.0214, 'grad_norm': 8.614433288574219, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.017934687435626984, 'loss_2': 0.0034847259521484375, 'loss_3': -16.246301651000977, 'loss_4': 1.6858723163604736, 'epoch': 7.16}
{'loss': 0.0253, 'grad_norm': 6.997902870178223, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.019479161128401756, 'loss_2': 0.005786895751953125, 'loss_3': -15.96150016784668, 'loss_4': 1.9110419750213623, 'epoch': 7.16}
{'loss': 0.0422, 'grad_norm': 9.859552383422852, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.0278974249958992, 'loss_2': 0.0142669677734375, 'loss_3': -16.276784896850586, 'loss_4': 1.65651273727417, 'epoch': 7.17}
{'loss': 0.0249, 'grad_norm': 5.772627353668213, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.01700889691710472, 'loss_2': 0.0078887939453125, 'loss_3': -16.23766326904297, 'loss_4': 1.8845465183258057, 'epoch': 7.17}
{'loss': 0.0186, 'grad_norm': 6.849270343780518, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.017600132152438164, 'loss_2': 0.00098419189453125, 'loss_3': -16.340120315551758, 'loss_4': 1.7384750843048096, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 12:51:04,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:04,386 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:58<1:08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:11,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017181139439344406, 'eval_runtime': 3.831, 'eval_samples_per_second': 267.296, 'eval_steps_per_second': 4.177, 'eval_loss_1': 0.013943452388048172, 'eval_loss_2': 0.003237687051296234, 'eval_loss_3': -18.2745304107666, 'eval_loss_4': 1.6344702243804932, 'epoch': 7.18}
{'loss': 0.0204, 'grad_norm': 7.2609171867370605, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.016212841495871544, 'loss_2': 0.00421905517578125, 'loss_3': -16.224262237548828, 'loss_4': 1.564470887184143, 'epoch': 7.19}
{'loss': 0.1277, 'grad_norm': 22.838626861572266, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.12432541698217392, 'loss_2': 0.00333404541015625, 'loss_3': -15.87838363647461, 'loss_4': 1.187981128692627, 'epoch': 7.19}
{'loss': 0.0472, 'grad_norm': 11.860010147094727, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.04271940514445305, 'loss_2': 0.004482269287109375, 'loss_3': -16.20241928100586, 'loss_4': 1.917999505996704, 'epoch': 7.2}
{'loss': 0.0216, 'grad_norm': 7.1436052322387695, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.01818825490772724, 'loss_2': 0.003398895263671875, 'loss_3': -16.148365020751953, 'loss_4': 2.0809473991394043, 'epoch': 7.2}
{'loss': 0.031, 'grad_norm': 8.220966339111328, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.02373831532895565, 'loss_2': 0.007232666015625, 'loss_3': -16.15616226196289, 'loss_4': 1.8394170999526978, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 12:51:11,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:11,772 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:06<1:07:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:19,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01669793762266636, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.608, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011295835487544537, 'eval_loss_2': 0.005402103066444397, 'eval_loss_3': -18.294511795043945, 'eval_loss_4': 1.5027555227279663, 'epoch': 7.21}
{'loss': 0.0239, 'grad_norm': 8.991565704345703, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.022391656413674355, 'loss_2': 0.0015497207641601562, 'loss_3': -16.082918167114258, 'loss_4': 1.7759294509887695, 'epoch': 7.22}
{'loss': 0.064, 'grad_norm': 16.50358772277832, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.04885827749967575, 'loss_2': 0.015106201171875, 'loss_3': -16.2576961517334, 'loss_4': 1.6237151622772217, 'epoch': 7.22}
{'loss': 0.0154, 'grad_norm': 6.189645767211914, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.01327104028314352, 'loss_2': 0.002109527587890625, 'loss_3': -16.191192626953125, 'loss_4': 1.738026738166809, 'epoch': 7.23}
{'loss': 0.0499, 'grad_norm': 15.460477828979492, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.04540153592824936, 'loss_2': 0.004482269287109375, 'loss_3': -16.167917251586914, 'loss_4': 1.61092209815979, 'epoch': 7.23}
{'loss': 0.0593, 'grad_norm': 28.301193237304688, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.04877107962965965, 'loss_2': 0.01053619384765625, 'loss_3': -16.214336395263672, 'loss_4': 1.368973970413208, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 12:51:19,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:19,134 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:13<1:07:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:26,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01572546921670437, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01070124376565218, 'eval_loss_2': 0.005024224519729614, 'eval_loss_3': -18.30674171447754, 'eval_loss_4': 1.2828221321105957, 'epoch': 7.24}
{'loss': 0.0426, 'grad_norm': 16.968013763427734, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.034700460731983185, 'loss_2': 0.007904052734375, 'loss_3': -16.171737670898438, 'loss_4': 1.0296449661254883, 'epoch': 7.24}
{'loss': 0.035, 'grad_norm': 7.2331624031066895, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.023172970861196518, 'loss_2': 0.0118408203125, 'loss_3': -16.13608169555664, 'loss_4': 1.8599069118499756, 'epoch': 7.25}
{'loss': 0.0218, 'grad_norm': 6.947648525238037, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.018265513703227043, 'loss_2': 0.003490447998046875, 'loss_3': -16.49087142944336, 'loss_4': 1.6323575973510742, 'epoch': 7.26}
{'loss': 0.0082, 'grad_norm': 4.81035852432251, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.0069511281326413155, 'loss_2': 0.0012750625610351562, 'loss_3': -16.349143981933594, 'loss_4': 1.3687117099761963, 'epoch': 7.26}
{'loss': 0.038, 'grad_norm': 13.30661392211914, 'learning_rate': 2.275e-05, 'loss_1': 0.037748709321022034, 'loss_2': 0.0002467632293701172, 'loss_3': -16.136764526367188, 'loss_4': 1.5907038450241089, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 12:51:26,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:26,497 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:20<1:07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:33,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019445737823843956, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013251562602818012, 'eval_loss_2': 0.006194174289703369, 'eval_loss_3': -18.27121353149414, 'eval_loss_4': 1.0359787940979004, 'epoch': 7.27}
{'loss': 0.037, 'grad_norm': 10.661687850952148, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.03011241927742958, 'loss_2': 0.00685882568359375, 'loss_3': -16.267404556274414, 'loss_4': 1.4749807119369507, 'epoch': 7.27}
{'loss': 0.0226, 'grad_norm': 7.144028663635254, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.020663278177380562, 'loss_2': 0.0019388198852539062, 'loss_3': -16.198991775512695, 'loss_4': 1.755050778388977, 'epoch': 7.28}
{'loss': 0.0215, 'grad_norm': 5.53673791885376, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.010821491479873657, 'loss_2': 0.0106964111328125, 'loss_3': -16.295177459716797, 'loss_4': 0.6499367952346802, 'epoch': 7.28}
{'loss': 0.1088, 'grad_norm': 19.85001564025879, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.09525041282176971, 'loss_2': 0.0135955810546875, 'loss_3': -16.375308990478516, 'loss_4': 1.233483910560608, 'epoch': 7.29}
{'loss': 0.0369, 'grad_norm': 9.619213104248047, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.02743414044380188, 'loss_2': 0.0095062255859375, 'loss_3': -16.372455596923828, 'loss_4': 1.508895993232727, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 12:51:33,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:33,855 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:28<1:07:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:41,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02547609806060791, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.465, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.019146500155329704, 'eval_loss_2': 0.006329596042633057, 'eval_loss_3': -18.229982376098633, 'eval_loss_4': 0.8434261679649353, 'epoch': 7.3}
{'loss': 0.0312, 'grad_norm': 7.052613735198975, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.025683999061584473, 'loss_2': 0.005504608154296875, 'loss_3': -16.18988037109375, 'loss_4': 1.3376414775848389, 'epoch': 7.3}
{'loss': 0.0604, 'grad_norm': 10.575220108032227, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.04834457114338875, 'loss_2': 0.012054443359375, 'loss_3': -16.094776153564453, 'loss_4': 0.6534632444381714, 'epoch': 7.31}
{'loss': 0.0686, 'grad_norm': 15.299869537353516, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.06565794348716736, 'loss_2': 0.002902984619140625, 'loss_3': -16.269432067871094, 'loss_4': 0.9013805389404297, 'epoch': 7.31}
{'loss': 0.0176, 'grad_norm': 7.832364559173584, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.017553256824612617, 'loss_2': 2.944469451904297e-05, 'loss_3': -16.210041046142578, 'loss_4': 0.902836263179779, 'epoch': 7.32}
{'loss': 0.0281, 'grad_norm': 9.910477638244629, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.02757297456264496, 'loss_2': 0.000537872314453125, 'loss_3': -16.15256118774414, 'loss_4': 0.7295568585395813, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 12:51:41,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:41,225 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:35<1:07:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:48,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02991309203207493, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.025501709431409836, 'eval_loss_2': 0.004411384463310242, 'eval_loss_3': -18.169586181640625, 'eval_loss_4': 0.5165693163871765, 'epoch': 7.33}
{'loss': 0.0833, 'grad_norm': 11.095223426818848, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.07248380035161972, 'loss_2': 0.01085662841796875, 'loss_3': -16.462919235229492, 'loss_4': 1.111402988433838, 'epoch': 7.33}
{'loss': 0.078, 'grad_norm': 24.242273330688477, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.07435774803161621, 'loss_2': 0.003650665283203125, 'loss_3': -16.333297729492188, 'loss_4': 0.7551196813583374, 'epoch': 7.34}
{'loss': 0.0172, 'grad_norm': 7.12974214553833, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.01652306690812111, 'loss_2': 0.0006456375122070312, 'loss_3': -16.24234390258789, 'loss_4': 0.243851900100708, 'epoch': 7.34}
{'loss': 0.0295, 'grad_norm': 7.063941478729248, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.01708952523767948, 'loss_2': 0.0124359130859375, 'loss_3': -16.36292266845703, 'loss_4': 0.6713787913322449, 'epoch': 7.35}
{'loss': 0.0337, 'grad_norm': 10.334705352783203, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.02826285921037197, 'loss_2': 0.00542449951171875, 'loss_3': -16.229412078857422, 'loss_4': 1.0134130716323853, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 12:51:48,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:48,588 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:43<1:07:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:55,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030298421159386635, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.024003934115171432, 'eval_loss_2': 0.0062944889068603516, 'eval_loss_3': -18.16685676574707, 'eval_loss_4': 0.3921644389629364, 'epoch': 7.35}
{'loss': 0.042, 'grad_norm': 10.54762077331543, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.0337032824754715, 'loss_2': 0.0082550048828125, 'loss_3': -16.2220458984375, 'loss_4': 0.6451996564865112, 'epoch': 7.36}
{'loss': 0.0234, 'grad_norm': 8.57909870147705, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.02189664915204048, 'loss_2': 0.0015506744384765625, 'loss_3': -16.055118560791016, 'loss_4': 0.5561851263046265, 'epoch': 7.37}
{'loss': 0.0235, 'grad_norm': 52.804901123046875, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.021556872874498367, 'loss_2': 0.0019073486328125, 'loss_3': -16.143970489501953, 'loss_4': 0.7274155616760254, 'epoch': 7.37}
{'loss': 0.0184, 'grad_norm': 7.813024520874023, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.016613738611340523, 'loss_2': 0.0018062591552734375, 'loss_3': -16.24736785888672, 'loss_4': 0.794506847858429, 'epoch': 7.38}
{'loss': 0.0362, 'grad_norm': 14.704156875610352, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.03317703306674957, 'loss_2': 0.0030689239501953125, 'loss_3': -16.174114227294922, 'loss_4': 0.7640928626060486, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 12:51:55,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:55,941 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:50<1:07:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:03,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023121098056435585, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.781, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0200410895049572, 'eval_loss_2': 0.003080010414123535, 'eval_loss_3': -18.162607192993164, 'eval_loss_4': 0.4120142161846161, 'epoch': 7.38}
{'loss': 0.0287, 'grad_norm': 7.041418552398682, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.02103189378976822, 'loss_2': 0.007659912109375, 'loss_3': -16.156917572021484, 'loss_4': 0.8125817179679871, 'epoch': 7.39}
{'loss': 0.0206, 'grad_norm': 5.348449230194092, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.0129168089479208, 'loss_2': 0.00772857666015625, 'loss_3': -16.41452980041504, 'loss_4': 0.468017578125, 'epoch': 7.4}
{'loss': 0.0177, 'grad_norm': 5.285497665405273, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.008906513452529907, 'loss_2': 0.0088348388671875, 'loss_3': -16.28961944580078, 'loss_4': 0.5895704030990601, 'epoch': 7.4}
{'loss': 0.0122, 'grad_norm': 5.549811840057373, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.010104984045028687, 'loss_2': 0.0021419525146484375, 'loss_3': -16.01273536682129, 'loss_4': 0.862642765045166, 'epoch': 7.41}
{'loss': 0.0186, 'grad_norm': 5.916141510009766, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.014723473228514194, 'loss_2': 0.0038299560546875, 'loss_3': -16.046401977539062, 'loss_4': 0.34280097484588623, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 12:52:03,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:03,296 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:57<1:07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:10,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016848713159561157, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013775207102298737, 'eval_loss_2': 0.0030735060572624207, 'eval_loss_3': -18.21296501159668, 'eval_loss_4': 0.32415854930877686, 'epoch': 7.41}
{'loss': 0.0322, 'grad_norm': 8.604222297668457, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.029244093224406242, 'loss_2': 0.002971649169921875, 'loss_3': -16.01746368408203, 'loss_4': 0.7976031303405762, 'epoch': 7.42}
{'loss': 0.0175, 'grad_norm': 8.011363983154297, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.014901098795235157, 'loss_2': 0.002613067626953125, 'loss_3': -16.001365661621094, 'loss_4': 0.25138622522354126, 'epoch': 7.42}
{'loss': 0.0207, 'grad_norm': 6.158681869506836, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.011409648694097996, 'loss_2': 0.009246826171875, 'loss_3': -16.0260009765625, 'loss_4': 0.7771316766738892, 'epoch': 7.43}
{'loss': 0.0223, 'grad_norm': 7.6590704917907715, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.01468274649232626, 'loss_2': 0.0076446533203125, 'loss_3': -16.05637550354004, 'loss_4': 0.3189162313938141, 'epoch': 7.44}
{'loss': 0.0257, 'grad_norm': 6.04560661315918, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.014947101473808289, 'loss_2': 0.01070404052734375, 'loss_3': -16.082286834716797, 'loss_4': 0.274036705493927, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 12:52:10,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:10,651 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:05<1:07:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:18,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02005787566304207, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.416, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011996465735137463, 'eval_loss_2': 0.008061408996582031, 'eval_loss_3': -18.224746704101562, 'eval_loss_4': -0.07992582768201828, 'epoch': 7.44}
{'loss': 0.0367, 'grad_norm': 9.06005573272705, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.029098980128765106, 'loss_2': 0.007617950439453125, 'loss_3': -15.941482543945312, 'loss_4': 0.2287888526916504, 'epoch': 7.45}
{'loss': 0.0276, 'grad_norm': 6.969762802124023, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.01796802133321762, 'loss_2': 0.0096588134765625, 'loss_3': -16.23185920715332, 'loss_4': 0.5966172218322754, 'epoch': 7.45}
{'loss': 0.01, 'grad_norm': 5.5784783363342285, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.00863982830196619, 'loss_2': 0.0013561248779296875, 'loss_3': -16.29463768005371, 'loss_4': -0.18925227224826813, 'epoch': 7.46}
{'loss': 0.0398, 'grad_norm': 14.607133865356445, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.036075837910175323, 'loss_2': 0.0037078857421875, 'loss_3': -16.19761848449707, 'loss_4': 0.5546838045120239, 'epoch': 7.47}
{'loss': 0.0197, 'grad_norm': 7.822632312774658, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.018884344026446342, 'loss_2': 0.0008363723754882812, 'loss_3': -15.973057746887207, 'loss_4': 0.44933855533599854, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 12:52:18,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:18,015 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:12<1:07:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:25,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018950195983052254, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.819, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.014869768172502518, 'eval_loss_2': 0.004080429673194885, 'eval_loss_3': -18.200279235839844, 'eval_loss_4': -0.15137675404548645, 'epoch': 7.47}
{'loss': 0.0254, 'grad_norm': 7.950993061065674, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.017251761630177498, 'loss_2': 0.0081329345703125, 'loss_3': -16.117992401123047, 'loss_4': 0.1912151277065277, 'epoch': 7.48}
{'loss': 0.0187, 'grad_norm': 6.558422088623047, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.012745089828968048, 'loss_2': 0.0059051513671875, 'loss_3': -16.31148910522461, 'loss_4': 0.16667500138282776, 'epoch': 7.48}
{'loss': 0.0164, 'grad_norm': 5.235663414001465, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.011175365187227726, 'loss_2': 0.00518798828125, 'loss_3': -16.278480529785156, 'loss_4': -0.006663143634796143, 'epoch': 7.49}
{'loss': 0.0166, 'grad_norm': 6.091653347015381, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.013464626856148243, 'loss_2': 0.003108978271484375, 'loss_3': -16.106456756591797, 'loss_4': 0.015001282095909119, 'epoch': 7.49}
{'loss': 0.0238, 'grad_norm': 7.207910537719727, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.017543623223900795, 'loss_2': 0.00621795654296875, 'loss_3': -16.070119857788086, 'loss_4': 0.3340550661087036, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 12:52:25,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:25,377 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:19<1:06:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:32,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021951980888843536, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.017216332256793976, 'eval_loss_2': 0.0047356486320495605, 'eval_loss_3': -18.171337127685547, 'eval_loss_4': -0.2284892201423645, 'epoch': 7.5}
{'loss': 0.0245, 'grad_norm': 7.14300012588501, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.011923935264348984, 'loss_2': 0.01261138916015625, 'loss_3': -16.31727409362793, 'loss_4': -0.22132770717144012, 'epoch': 7.51}
{'loss': 0.0169, 'grad_norm': 5.327184677124023, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.013124147430062294, 'loss_2': 0.00376129150390625, 'loss_3': -16.13266372680664, 'loss_4': 0.13356760144233704, 'epoch': 7.51}
{'loss': 0.0313, 'grad_norm': 9.657402038574219, 'learning_rate': 2.25e-05, 'loss_1': 0.0257639791816473, 'loss_2': 0.00556182861328125, 'loss_3': -16.203155517578125, 'loss_4': -0.07809081673622131, 'epoch': 7.52}
{'loss': 0.0334, 'grad_norm': 10.739326477050781, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.028064990416169167, 'loss_2': 0.00530242919921875, 'loss_3': -16.062772750854492, 'loss_4': 0.25000429153442383, 'epoch': 7.52}
{'loss': 0.0137, 'grad_norm': 5.916629314422607, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.011133511550724506, 'loss_2': 0.002521514892578125, 'loss_3': -16.20751190185547, 'loss_4': 0.08418373763561249, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 12:52:32,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:32,730 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:27<1:06:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:40,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022338202223181725, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01971409283578396, 'eval_loss_2': 0.002624109387397766, 'eval_loss_3': -18.1739501953125, 'eval_loss_4': -0.4737619161605835, 'epoch': 7.53}
{'loss': 0.0234, 'grad_norm': 8.60927963256836, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.018910229206085205, 'loss_2': 0.004486083984375, 'loss_3': -16.15363311767578, 'loss_4': -0.33276504278182983, 'epoch': 7.53}
{'loss': 0.0276, 'grad_norm': 8.665254592895508, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.025564419105648994, 'loss_2': 0.00201416015625, 'loss_3': -16.189823150634766, 'loss_4': -0.3533894419670105, 'epoch': 7.54}
{'loss': 0.0385, 'grad_norm': 13.32370376586914, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.03436136245727539, 'loss_2': 0.004177093505859375, 'loss_3': -16.225311279296875, 'loss_4': 0.8225536942481995, 'epoch': 7.55}
{'loss': 0.0259, 'grad_norm': 8.609228134155273, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.025043020024895668, 'loss_2': 0.0008211135864257812, 'loss_3': -16.177919387817383, 'loss_4': -0.17551371455192566, 'epoch': 7.55}
{'loss': 0.0161, 'grad_norm': 6.287891864776611, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.014971652999520302, 'loss_2': 0.0011005401611328125, 'loss_3': -16.179073333740234, 'loss_4': -0.5887367725372314, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 12:52:40,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:40,087 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:34<1:06:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:47,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026781659573316574, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.023392021656036377, 'eval_loss_2': 0.0033896341919898987, 'eval_loss_3': -18.131668090820312, 'eval_loss_4': -0.2536487579345703, 'epoch': 7.56}
{'loss': 0.035, 'grad_norm': 15.065938949584961, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.029832767322659492, 'loss_2': 0.005153656005859375, 'loss_3': -16.296287536621094, 'loss_4': 0.2300778031349182, 'epoch': 7.56}
{'loss': 0.0259, 'grad_norm': 12.02377986907959, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.019814960658550262, 'loss_2': 0.00608062744140625, 'loss_3': -16.12728500366211, 'loss_4': 0.13716694712638855, 'epoch': 7.57}
{'loss': 0.0165, 'grad_norm': 5.346923351287842, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.014730468392372131, 'loss_2': 0.0017833709716796875, 'loss_3': -16.279117584228516, 'loss_4': 0.20082423090934753, 'epoch': 7.58}
{'loss': 0.0311, 'grad_norm': 8.252442359924316, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.018130727112293243, 'loss_2': 0.01300048828125, 'loss_3': -16.39898681640625, 'loss_4': 0.13466620445251465, 'epoch': 7.58}
{'loss': 0.0352, 'grad_norm': 7.235496997833252, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.02524898760020733, 'loss_2': 0.0099639892578125, 'loss_3': -16.306381225585938, 'loss_4': 0.041619472205638885, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 12:52:47,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:47,441 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:41<1:06:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:54,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02832230180501938, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.814, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.024784646928310394, 'eval_loss_2': 0.0035376548767089844, 'eval_loss_3': -18.144535064697266, 'eval_loss_4': -0.1590437889099121, 'epoch': 7.59}
{'loss': 0.0375, 'grad_norm': 8.636513710021973, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.03381946682929993, 'loss_2': 0.003635406494140625, 'loss_3': -16.14664649963379, 'loss_4': -0.14889946579933167, 'epoch': 7.59}
{'loss': 0.0474, 'grad_norm': 20.171710968017578, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.03673788160085678, 'loss_2': 0.01068878173828125, 'loss_3': -16.295766830444336, 'loss_4': -0.0031601786613464355, 'epoch': 7.6}
{'loss': 0.0713, 'grad_norm': 15.834359169006348, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.0648660734295845, 'loss_2': 0.006439208984375, 'loss_3': -16.136804580688477, 'loss_4': -0.2229767143726349, 'epoch': 7.6}
{'loss': 0.0294, 'grad_norm': 8.272926330566406, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.02614518441259861, 'loss_2': 0.003261566162109375, 'loss_3': -16.35401725769043, 'loss_4': -0.12411318719387054, 'epoch': 7.61}
{'loss': 0.0531, 'grad_norm': 17.082233428955078, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.052174195647239685, 'loss_2': 0.0008978843688964844, 'loss_3': -16.39092254638672, 'loss_4': 0.3921276032924652, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 12:52:54,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:54,798 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:49<1:06:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:02,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027302052825689316, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.684, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.02367399074137211, 'eval_loss_2': 0.003628067672252655, 'eval_loss_3': -18.20289421081543, 'eval_loss_4': -0.22846952080726624, 'epoch': 7.62}
{'loss': 0.0531, 'grad_norm': 10.521241188049316, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.04588908329606056, 'loss_2': 0.007205963134765625, 'loss_3': -16.386184692382812, 'loss_4': -0.6022741794586182, 'epoch': 7.62}
{'loss': 0.0396, 'grad_norm': 8.795561790466309, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.03365198150277138, 'loss_2': 0.00595855712890625, 'loss_3': -16.185335159301758, 'loss_4': 0.6146512031555176, 'epoch': 7.63}
{'loss': 0.0381, 'grad_norm': 9.695030212402344, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.037902556359767914, 'loss_2': 0.0002167224884033203, 'loss_3': -16.259227752685547, 'loss_4': -0.5240494608879089, 'epoch': 7.63}
{'loss': 0.0204, 'grad_norm': 6.447264671325684, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.015061034820973873, 'loss_2': 0.00537872314453125, 'loss_3': -16.435714721679688, 'loss_4': -0.031391441822052, 'epoch': 7.64}
{'loss': 0.0672, 'grad_norm': 27.72924041748047, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.06131187081336975, 'loss_2': 0.005859375, 'loss_3': -16.181840896606445, 'loss_4': 0.613422155380249, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 12:53:02,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:02,158 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:56<1:06:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:09,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025500964373350143, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.025, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02247028984129429, 'eval_loss_2': 0.0030306726694107056, 'eval_loss_3': -18.226959228515625, 'eval_loss_4': 0.040641024708747864, 'epoch': 7.65}
{'loss': 0.0455, 'grad_norm': 13.413495063781738, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.031769342720508575, 'loss_2': 0.013702392578125, 'loss_3': -16.337263107299805, 'loss_4': 0.5660619735717773, 'epoch': 7.65}
{'loss': 0.0175, 'grad_norm': 5.764252185821533, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.015653885900974274, 'loss_2': 0.001857757568359375, 'loss_3': -16.409744262695312, 'loss_4': 0.619350790977478, 'epoch': 7.66}
{'loss': 0.0499, 'grad_norm': 13.126323699951172, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.04328770563006401, 'loss_2': 0.006610870361328125, 'loss_3': -16.254608154296875, 'loss_4': 1.366358757019043, 'epoch': 7.66}
{'loss': 0.0397, 'grad_norm': 16.56196403503418, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.03694285824894905, 'loss_2': 0.00275421142578125, 'loss_3': -16.180862426757812, 'loss_4': 0.29686620831489563, 'epoch': 7.67}
{'loss': 0.0293, 'grad_norm': 10.651129722595215, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.0288612712174654, 'loss_2': 0.00043702125549316406, 'loss_3': -16.1424560546875, 'loss_4': 0.6635692715644836, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 12:53:09,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:09,520 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [33:04<1:07:22,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:53:17,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02017689310014248, 'eval_runtime': 4.0027, 'eval_samples_per_second': 255.827, 'eval_steps_per_second': 3.997, 'eval_loss_1': 0.016908464953303337, 'eval_loss_2': 0.003268428146839142, 'eval_loss_3': -18.262365341186523, 'eval_loss_4': 0.3973572254180908, 'epoch': 7.67}
{'loss': 0.0324, 'grad_norm': 11.698148727416992, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.030561257153749466, 'loss_2': 0.00180816650390625, 'loss_3': -16.246261596679688, 'loss_4': 0.3280313313007355, 'epoch': 7.68}
{'loss': 0.0957, 'grad_norm': 27.905574798583984, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.0812925174832344, 'loss_2': 0.01444244384765625, 'loss_3': -16.194107055664062, 'loss_4': 0.8288799524307251, 'epoch': 7.69}
{'loss': 0.0229, 'grad_norm': 9.380960464477539, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.02184445410966873, 'loss_2': 0.0010852813720703125, 'loss_3': -16.013484954833984, 'loss_4': 0.9491727352142334, 'epoch': 7.69}
{'loss': 0.0362, 'grad_norm': 15.903931617736816, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.029750045388936996, 'loss_2': 0.00640106201171875, 'loss_3': -16.243850708007812, 'loss_4': 0.6650917530059814, 'epoch': 7.7}
{'loss': 0.0255, 'grad_norm': 8.9738187789917, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.01887226663529873, 'loss_2': 0.006591796875, 'loss_3': -16.23078727722168, 'loss_4': 0.7497347593307495, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 12:53:17,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:17,076 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:11<1:06:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:24,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02403639629483223, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.019118621945381165, 'eval_loss_2': 0.004917774349451065, 'eval_loss_3': -18.32163429260254, 'eval_loss_4': 0.643118143081665, 'epoch': 7.7}
{'loss': 0.0793, 'grad_norm': 25.1356143951416, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.07819298654794693, 'loss_2': 0.0011501312255859375, 'loss_3': -16.203338623046875, 'loss_4': 1.2489533424377441, 'epoch': 7.71}
{'loss': 0.031, 'grad_norm': 9.309948921203613, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.02843160182237625, 'loss_2': 0.0025501251220703125, 'loss_3': -16.114654541015625, 'loss_4': 1.040043830871582, 'epoch': 7.72}
{'loss': 0.0333, 'grad_norm': 9.807561874389648, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.0280943363904953, 'loss_2': 0.005161285400390625, 'loss_3': -16.527463912963867, 'loss_4': 1.7492103576660156, 'epoch': 7.72}
{'loss': 0.0292, 'grad_norm': 8.601966857910156, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.027507608756422997, 'loss_2': 0.00165557861328125, 'loss_3': -16.312332153320312, 'loss_4': 1.2958028316497803, 'epoch': 7.73}
{'loss': 0.0192, 'grad_norm': 6.459077835083008, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.017682144418358803, 'loss_2': 0.0015039443969726562, 'loss_3': -16.260759353637695, 'loss_4': 0.8217657208442688, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 12:53:24,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:24,443 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:18<1:06:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:31,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020457692444324493, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014977090992033482, 'eval_loss_2': 0.005480602383613586, 'eval_loss_3': -18.32040786743164, 'eval_loss_4': 0.9424683451652527, 'epoch': 7.73}
{'loss': 0.0433, 'grad_norm': 12.674402236938477, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.03517160937190056, 'loss_2': 0.0081634521484375, 'loss_3': -15.876399040222168, 'loss_4': 0.5494942665100098, 'epoch': 7.74}
{'loss': 0.0447, 'grad_norm': 13.631718635559082, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.04123459383845329, 'loss_2': 0.003448486328125, 'loss_3': -16.12714958190918, 'loss_4': 1.1861774921417236, 'epoch': 7.74}
{'loss': 0.0483, 'grad_norm': 12.520769119262695, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.03597261756658554, 'loss_2': 0.0123443603515625, 'loss_3': -16.08514404296875, 'loss_4': 1.258455514907837, 'epoch': 7.75}
{'loss': 0.0208, 'grad_norm': 6.2955756187438965, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.01674742065370083, 'loss_2': 0.0040130615234375, 'loss_3': -16.2519474029541, 'loss_4': 1.1438400745391846, 'epoch': 7.76}
{'loss': 0.0218, 'grad_norm': 10.089458465576172, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.021803034469485283, 'loss_2': 3.4570693969726562e-06, 'loss_3': -16.099618911743164, 'loss_4': 1.2982722520828247, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 12:53:31,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:31,805 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:26<1:06:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:39,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020511530339717865, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.355, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.016544871032238007, 'eval_loss_2': 0.003966659307479858, 'eval_loss_3': -18.324634552001953, 'eval_loss_4': 1.0576324462890625, 'epoch': 7.76}
{'loss': 0.0665, 'grad_norm': 15.903693199157715, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.06642554700374603, 'loss_2': 2.8312206268310547e-05, 'loss_3': -16.497404098510742, 'loss_4': 1.5908355712890625, 'epoch': 7.77}
{'loss': 0.0427, 'grad_norm': 11.667961120605469, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.041742317378520966, 'loss_2': 0.0009450912475585938, 'loss_3': -16.288726806640625, 'loss_4': 1.1996632814407349, 'epoch': 7.77}
{'loss': 0.0298, 'grad_norm': 7.921713829040527, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.023760531097650528, 'loss_2': 0.006072998046875, 'loss_3': -16.02753448486328, 'loss_4': 0.9013575315475464, 'epoch': 7.78}
{'loss': 0.0642, 'grad_norm': 13.211546897888184, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.05959475040435791, 'loss_2': 0.004581451416015625, 'loss_3': -15.896934509277344, 'loss_4': 1.4531530141830444, 'epoch': 7.78}
{'loss': 0.0239, 'grad_norm': 8.73857593536377, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.023045768961310387, 'loss_2': 0.0008974075317382812, 'loss_3': -16.28603744506836, 'loss_4': 1.4403011798858643, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 12:53:39,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:39,175 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:33<1:06:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:46,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021380532532930374, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.657, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.016594761982560158, 'eval_loss_2': 0.004785768687725067, 'eval_loss_3': -18.3310489654541, 'eval_loss_4': 1.2488683462142944, 'epoch': 7.79}
{'loss': 0.039, 'grad_norm': 11.204310417175293, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.036698538810014725, 'loss_2': 0.002277374267578125, 'loss_3': -16.13905906677246, 'loss_4': 2.0949959754943848, 'epoch': 7.8}
{'loss': 0.0201, 'grad_norm': 5.652312755584717, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.017343604937195778, 'loss_2': 0.002750396728515625, 'loss_3': -16.245140075683594, 'loss_4': 1.4204308986663818, 'epoch': 7.8}
{'loss': 0.0341, 'grad_norm': 8.250842094421387, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.027147730812430382, 'loss_2': 0.006938934326171875, 'loss_3': -16.138105392456055, 'loss_4': 1.6310293674468994, 'epoch': 7.81}
{'loss': 0.0162, 'grad_norm': 6.294950485229492, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.014471860602498055, 'loss_2': 0.0017366409301757812, 'loss_3': -16.4008846282959, 'loss_4': 1.5911736488342285, 'epoch': 7.81}
{'loss': 0.0177, 'grad_norm': 5.751543045043945, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.016424674540758133, 'loss_2': 0.00122833251953125, 'loss_3': -16.138179779052734, 'loss_4': 1.3522334098815918, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 12:53:46,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:46,549 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:40<1:06:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:53,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021583855152130127, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01844361424446106, 'eval_loss_2': 0.0031402409076690674, 'eval_loss_3': -18.288007736206055, 'eval_loss_4': 1.329390048980713, 'epoch': 7.82}
{'loss': 0.0521, 'grad_norm': 15.421700477600098, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.05181385576725006, 'loss_2': 0.0002675056457519531, 'loss_3': -16.29353141784668, 'loss_4': 1.3727306127548218, 'epoch': 7.83}
{'loss': 0.04, 'grad_norm': 11.666181564331055, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.034936822950839996, 'loss_2': 0.005096435546875, 'loss_3': -16.070749282836914, 'loss_4': 0.9927144050598145, 'epoch': 7.83}
{'loss': 0.0281, 'grad_norm': 9.890597343444824, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.02387036755681038, 'loss_2': 0.00420379638671875, 'loss_3': -16.239612579345703, 'loss_4': 1.3572801351547241, 'epoch': 7.84}
{'loss': 0.0298, 'grad_norm': 7.876375675201416, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.019270891323685646, 'loss_2': 0.0104827880859375, 'loss_3': -16.102584838867188, 'loss_4': 1.5888930559158325, 'epoch': 7.84}
{'loss': 0.0315, 'grad_norm': 7.531494617462158, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.018496690317988396, 'loss_2': 0.01300048828125, 'loss_3': -16.11376190185547, 'loss_4': 1.7042560577392578, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 12:53:53,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:53,911 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:48<1:05:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:01,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027893390506505966, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020576266571879387, 'eval_loss_2': 0.0073171257972717285, 'eval_loss_3': -18.28156089782715, 'eval_loss_4': 1.2594876289367676, 'epoch': 7.85}
{'loss': 0.0635, 'grad_norm': 12.95176887512207, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.04929591342806816, 'loss_2': 0.014251708984375, 'loss_3': -16.207229614257812, 'loss_4': 1.431994915008545, 'epoch': 7.85}
{'loss': 0.0304, 'grad_norm': 7.729332447052002, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.024860208854079247, 'loss_2': 0.005512237548828125, 'loss_3': -16.127695083618164, 'loss_4': 1.2276203632354736, 'epoch': 7.86}
{'loss': 0.0087, 'grad_norm': 4.670260429382324, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.008620140142738819, 'loss_2': 6.598234176635742e-05, 'loss_3': -16.232759475708008, 'loss_4': 1.7286795377731323, 'epoch': 7.87}
{'loss': 0.0188, 'grad_norm': 6.7833733558654785, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.01836974360048771, 'loss_2': 0.00042748451232910156, 'loss_3': -16.34516143798828, 'loss_4': 0.8201866149902344, 'epoch': 7.87}
{'loss': 0.0507, 'grad_norm': 15.69401741027832, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.04006582871079445, 'loss_2': 0.01061248779296875, 'loss_3': -16.09010887145996, 'loss_4': 1.2776304483413696, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 12:54:01,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:01,269 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:55<1:05:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:08,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031042004004120827, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.025798223912715912, 'eval_loss_2': 0.005243778228759766, 'eval_loss_3': -18.204288482666016, 'eval_loss_4': 1.0057976245880127, 'epoch': 7.88}
{'loss': 0.0164, 'grad_norm': 4.891852378845215, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.012520321644842625, 'loss_2': 0.0039043426513671875, 'loss_3': -16.387405395507812, 'loss_4': 1.280754804611206, 'epoch': 7.88}
{'loss': 0.027, 'grad_norm': 5.722079753875732, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.015657855197787285, 'loss_2': 0.01139068603515625, 'loss_3': -16.1675968170166, 'loss_4': 1.2160792350769043, 'epoch': 7.89}
{'loss': 0.0251, 'grad_norm': 5.083062648773193, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.013255417346954346, 'loss_2': 0.0118865966796875, 'loss_3': -16.326251983642578, 'loss_4': 0.6379712820053101, 'epoch': 7.9}
{'loss': 0.0236, 'grad_norm': 6.754081726074219, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.015569832175970078, 'loss_2': 0.00801849365234375, 'loss_3': -16.27677345275879, 'loss_4': 0.7814290523529053, 'epoch': 7.9}
{'loss': 0.0145, 'grad_norm': 4.767637252807617, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.009545152075588703, 'loss_2': 0.00495147705078125, 'loss_3': -16.10540008544922, 'loss_4': 0.8991308808326721, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 12:54:08,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:08,634 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:03<1:05:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:15,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05092444270849228, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.044354505836963654, 'eval_loss_2': 0.0065699368715286255, 'eval_loss_3': -18.077239990234375, 'eval_loss_4': 0.9966012835502625, 'epoch': 7.91}
{'loss': 0.0261, 'grad_norm': 5.3198018074035645, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.014035320840775967, 'loss_2': 0.0120391845703125, 'loss_3': -16.054683685302734, 'loss_4': 0.9149391651153564, 'epoch': 7.91}
{'loss': 0.0466, 'grad_norm': 18.795944213867188, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.04331512749195099, 'loss_2': 0.003330230712890625, 'loss_3': -15.941893577575684, 'loss_4': 0.7470463514328003, 'epoch': 7.92}
{'loss': 0.0183, 'grad_norm': 9.497040748596191, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.017793836072087288, 'loss_2': 0.0004925727844238281, 'loss_3': -16.046239852905273, 'loss_4': 1.0973141193389893, 'epoch': 7.92}
{'loss': 0.014, 'grad_norm': 4.763291835784912, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.009500844404101372, 'loss_2': 0.0044708251953125, 'loss_3': -16.131580352783203, 'loss_4': 0.8884991407394409, 'epoch': 7.93}
{'loss': 0.0178, 'grad_norm': 7.136394500732422, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.016386831179261208, 'loss_2': 0.0013856887817382812, 'loss_3': -16.07689094543457, 'loss_4': 0.9882813096046448, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 12:54:15,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:15,998 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:10<1:05:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:23,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0690670758485794, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.573, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0630708858370781, 'eval_loss_2': 0.005996197462081909, 'eval_loss_3': -18.008642196655273, 'eval_loss_4': 1.20643949508667, 'epoch': 7.94}
{'loss': 0.0217, 'grad_norm': 5.896195411682129, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.01728672906756401, 'loss_2': 0.00445556640625, 'loss_3': -16.08600425720215, 'loss_4': 0.9179403781890869, 'epoch': 7.94}
{'loss': 0.0431, 'grad_norm': 18.68991470336914, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.035648588091135025, 'loss_2': 0.0074310302734375, 'loss_3': -15.843841552734375, 'loss_4': 1.3233575820922852, 'epoch': 7.95}
{'loss': 0.058, 'grad_norm': 13.474717140197754, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.04336901381611824, 'loss_2': 0.0146026611328125, 'loss_3': -16.129867553710938, 'loss_4': 1.3952298164367676, 'epoch': 7.95}
{'loss': 0.0198, 'grad_norm': 6.167926788330078, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.01656520366668701, 'loss_2': 0.0032501220703125, 'loss_3': -16.09160804748535, 'loss_4': 1.1673961877822876, 'epoch': 7.96}
{'loss': 0.0304, 'grad_norm': 7.64289665222168, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.02370494231581688, 'loss_2': 0.006744384765625, 'loss_3': -16.068653106689453, 'loss_4': 1.5844008922576904, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 12:54:23,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:23,369 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:17<1:05:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:30,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06195078790187836, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.05660053342580795, 'eval_loss_2': 0.005350250750780106, 'eval_loss_3': -18.044395446777344, 'eval_loss_4': 1.4931056499481201, 'epoch': 7.97}
{'loss': 0.032, 'grad_norm': 11.168943405151367, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.0290285125374794, 'loss_2': 0.003009796142578125, 'loss_3': -15.860761642456055, 'loss_4': 1.505568265914917, 'epoch': 7.97}
{'loss': 0.0212, 'grad_norm': 5.395791530609131, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.01292615756392479, 'loss_2': 0.00826263427734375, 'loss_3': -16.026466369628906, 'loss_4': 1.6330618858337402, 'epoch': 7.98}
{'loss': 0.0338, 'grad_norm': 14.4696044921875, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.032437216490507126, 'loss_2': 0.0013675689697265625, 'loss_3': -16.167984008789062, 'loss_4': 1.68141508102417, 'epoch': 7.98}
{'loss': 0.0415, 'grad_norm': 15.434896469116211, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.03932083398103714, 'loss_2': 0.002197265625, 'loss_3': -15.962736129760742, 'loss_4': 1.6545088291168213, 'epoch': 7.99}
{'loss': 0.0202, 'grad_norm': 6.374999523162842, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.01813877932727337, 'loss_2': 0.0020694732666015625, 'loss_3': -15.973703384399414, 'loss_4': 1.3231438398361206, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 12:54:30,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:30,712 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:24<1:04:15,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:54:37,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024526359513401985, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.788, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.021029934287071228, 'eval_loss_2': 0.0034964270889759064, 'eval_loss_3': -18.256866455078125, 'eval_loss_4': 1.4387485980987549, 'epoch': 7.99}
{'loss': 0.0429, 'grad_norm': 14.388875007629395, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.03814571723341942, 'loss_2': 0.0047454833984375, 'loss_3': -15.998783111572266, 'loss_4': 1.235094666481018, 'epoch': 8.0}
{'loss': 0.0196, 'grad_norm': 5.528120040893555, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.013760319910943508, 'loss_2': 0.005825042724609375, 'loss_3': -16.245647430419922, 'loss_4': 1.668628454208374, 'epoch': 8.01}
{'loss': 0.0256, 'grad_norm': 5.718514442443848, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.01301119290292263, 'loss_2': 0.0125579833984375, 'loss_3': -16.33039665222168, 'loss_4': 1.3577557802200317, 'epoch': 8.01}
{'loss': 0.0241, 'grad_norm': 8.948838233947754, 'learning_rate': 2.2e-05, 'loss_1': 0.021527603268623352, 'loss_2': 0.00255584716796875, 'loss_3': -16.338687896728516, 'loss_4': 1.706737995147705, 'epoch': 8.02}
{'loss': 0.0329, 'grad_norm': 13.138072967529297, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.026022128760814667, 'loss_2': 0.00682830810546875, 'loss_3': -15.97990608215332, 'loss_4': 1.6191649436950684, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 12:54:37,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:37,788 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:28<1:04:15,  1.02s/it][INFO|trainer.py:3910] 2025-01-21 12:54:41,593 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380
[INFO|configuration_utils.py:420] 2025-01-21 12:54:41,594 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380/config.json                                                                            
{'eval_loss': 0.01332151424139738, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.265, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00982635747641325, 'eval_loss_2': 0.003495156764984131, 'eval_loss_3': -18.32546615600586, 'eval_loss_4': 1.5099316835403442, 'epoch': 8.02}
[INFO|modeling_utils.py:2988] 2025-01-21 12:54:42,100 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:54:42,101 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:54:42,101 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:54:43,070 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1180] due to args.save_total_limit
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:33<1:12:16,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:54:46,708 >>
{'loss': 0.0173, 'grad_norm': 6.361714839935303, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.01650693640112877, 'loss_2': 0.000782012939453125, 'loss_3': -16.043235778808594, 'loss_4': 1.798060655593872, 'epoch': 8.03}
{'loss': 0.0204, 'grad_norm': 8.177713394165039, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.018363678827881813, 'loss_2': 0.0020122528076171875, 'loss_3': -15.95605754852295, 'loss_4': 2.219240665435791, 'epoch': 8.03}
{'loss': 0.0418, 'grad_norm': 18.811115264892578, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.03660273179411888, 'loss_2': 0.00524139404296875, 'loss_3': -16.079639434814453, 'loss_4': 2.4993419647216797, 'epoch': 8.04}
{'loss': 0.0312, 'grad_norm': 9.82639217376709, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.02660893276333809, 'loss_2': 0.004573822021484375, 'loss_3': -16.066226959228516, 'loss_4': 2.2902209758758545, 'epoch': 8.05}
{'loss': 0.0147, 'grad_norm': 5.151790142059326, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.011470922268927097, 'loss_2': 0.003246307373046875, 'loss_3': -16.04492950439453, 'loss_4': 1.7988660335540771, 'epoch': 8.05}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:54:46,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:46,708 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:41<1:06:21,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:54:54,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015961814671754837, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.805, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01126142404973507, 'eval_loss_2': 0.004700392484664917, 'eval_loss_3': -18.353761672973633, 'eval_loss_4': 1.3501746654510498, 'epoch': 8.05}
{'loss': 0.0238, 'grad_norm': 10.1168794631958, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.022930044680833817, 'loss_2': 0.0008463859558105469, 'loss_3': -16.286205291748047, 'loss_4': 1.1342456340789795, 'epoch': 8.06}
{'loss': 0.0198, 'grad_norm': 5.907268524169922, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.01671004295349121, 'loss_2': 0.003139495849609375, 'loss_3': -16.257816314697266, 'loss_4': 1.4750090837478638, 'epoch': 8.06}
{'loss': 0.0376, 'grad_norm': 14.263242721557617, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.03475039824843407, 'loss_2': 0.002803802490234375, 'loss_3': -16.17339515686035, 'loss_4': 1.7621395587921143, 'epoch': 8.07}
{'loss': 0.0146, 'grad_norm': 5.857819557189941, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.013093044981360435, 'loss_2': 0.001552581787109375, 'loss_3': -16.385467529296875, 'loss_4': 1.5934576988220215, 'epoch': 8.08}
{'loss': 0.0176, 'grad_norm': 5.762418270111084, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.013360733166337013, 'loss_2': 0.0042724609375, 'loss_3': -16.27124786376953, 'loss_4': 1.1158640384674072, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 12:54:54,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:54,050 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:48<1:05:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:01,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016039583832025528, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010680877603590488, 'eval_loss_2': 0.005358707159757614, 'eval_loss_3': -18.37460708618164, 'eval_loss_4': 1.1549590826034546, 'epoch': 8.08}
{'loss': 0.021, 'grad_norm': 6.296896457672119, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.017493346706032753, 'loss_2': 0.003551483154296875, 'loss_3': -16.18891143798828, 'loss_4': 1.3658747673034668, 'epoch': 8.09}
{'loss': 0.0466, 'grad_norm': 18.04201316833496, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.044343143701553345, 'loss_2': 0.002292633056640625, 'loss_3': -16.29507064819336, 'loss_4': 1.0853767395019531, 'epoch': 8.09}
{'loss': 0.0467, 'grad_norm': 10.761240005493164, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.03241545706987381, 'loss_2': 0.0142364501953125, 'loss_3': -16.33932876586914, 'loss_4': 1.300645112991333, 'epoch': 8.1}
{'loss': 0.0398, 'grad_norm': 13.753632545471191, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.0319814532995224, 'loss_2': 0.00777435302734375, 'loss_3': -16.07989501953125, 'loss_4': 1.472311019897461, 'epoch': 8.1}
{'loss': 0.0144, 'grad_norm': 5.9070587158203125, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.01315250713378191, 'loss_2': 0.0012798309326171875, 'loss_3': -16.346195220947266, 'loss_4': 1.6778192520141602, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 12:55:01,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:01,411 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:55<1:05:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:08,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015683285892009735, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011315129697322845, 'eval_loss_2': 0.00436815619468689, 'eval_loss_3': -18.380535125732422, 'eval_loss_4': 1.0506142377853394, 'epoch': 8.11}
{'loss': 0.0249, 'grad_norm': 7.0416646003723145, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.019357699900865555, 'loss_2': 0.005535125732421875, 'loss_3': -16.195648193359375, 'loss_4': 1.8920066356658936, 'epoch': 8.12}
{'loss': 0.0217, 'grad_norm': 6.6471848487854, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.02118854783475399, 'loss_2': 0.0005006790161132812, 'loss_3': -16.1748104095459, 'loss_4': 1.298546314239502, 'epoch': 8.12}
{'loss': 0.0329, 'grad_norm': 10.51919937133789, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.03183981403708458, 'loss_2': 0.0010118484497070312, 'loss_3': -16.27349281311035, 'loss_4': 1.300727128982544, 'epoch': 8.13}
{'loss': 0.0259, 'grad_norm': 7.125738620758057, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.019961444661021233, 'loss_2': 0.0059661865234375, 'loss_3': -16.08002281188965, 'loss_4': 1.229585886001587, 'epoch': 8.13}
{'loss': 0.0178, 'grad_norm': 5.5487060546875, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.013514594174921513, 'loss_2': 0.004322052001953125, 'loss_3': -16.370792388916016, 'loss_4': 1.3955544233322144, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 12:55:08,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:08,760 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [35:03<1:04:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:16,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01615547575056553, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012050206772983074, 'eval_loss_2': 0.004105269908905029, 'eval_loss_3': -18.39401626586914, 'eval_loss_4': 1.0104087591171265, 'epoch': 8.14}
{'loss': 0.053, 'grad_norm': 11.206836700439453, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.05055227503180504, 'loss_2': 0.002475738525390625, 'loss_3': -16.142581939697266, 'loss_4': 1.2044552564620972, 'epoch': 8.15}
{'loss': 0.0268, 'grad_norm': 8.547011375427246, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.024717943742871284, 'loss_2': 0.0020427703857421875, 'loss_3': -16.282258987426758, 'loss_4': 1.26570463180542, 'epoch': 8.15}
{'loss': 0.0434, 'grad_norm': 13.051498413085938, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.04301411658525467, 'loss_2': 0.0003914833068847656, 'loss_3': -16.215682983398438, 'loss_4': 0.3696807026863098, 'epoch': 8.16}
{'loss': 0.0108, 'grad_norm': 5.184431552886963, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.010599845089018345, 'loss_2': 0.00024127960205078125, 'loss_3': -16.241378784179688, 'loss_4': 0.9392428398132324, 'epoch': 8.16}
{'loss': 0.0144, 'grad_norm': 5.660976886749268, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.012666119262576103, 'loss_2': 0.001735687255859375, 'loss_3': -16.36243438720703, 'loss_4': 0.7625327706336975, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 12:55:16,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:16,103 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:10<1:04:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:23,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017800144851207733, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.496, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014243303798139095, 'eval_loss_2': 0.0035568401217460632, 'eval_loss_3': -18.336902618408203, 'eval_loss_4': 1.2851701974868774, 'epoch': 8.17}
{'loss': 0.0245, 'grad_norm': 6.301141262054443, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.02006063610315323, 'loss_2': 0.00440216064453125, 'loss_3': -16.283824920654297, 'loss_4': 1.2917590141296387, 'epoch': 8.17}
{'loss': 0.0252, 'grad_norm': 7.48154354095459, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.01682090200483799, 'loss_2': 0.0083465576171875, 'loss_3': -16.25769805908203, 'loss_4': 1.2466806173324585, 'epoch': 8.18}
{'loss': 0.02, 'grad_norm': 5.737572193145752, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.013838162645697594, 'loss_2': 0.006134033203125, 'loss_3': -16.187877655029297, 'loss_4': 1.2293829917907715, 'epoch': 8.19}
{'loss': 0.0161, 'grad_norm': 5.971601486206055, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.013734227046370506, 'loss_2': 0.002349853515625, 'loss_3': -16.386032104492188, 'loss_4': 1.4177783727645874, 'epoch': 8.19}
{'loss': 0.019, 'grad_norm': 7.868481159210205, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.018743233755230904, 'loss_2': 0.00022292137145996094, 'loss_3': -16.136962890625, 'loss_4': 1.7612849473953247, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 12:55:23,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:23,448 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:17<1:04:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:30,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020610155537724495, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.502, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017392026260495186, 'eval_loss_2': 0.003218129277229309, 'eval_loss_3': -18.27772331237793, 'eval_loss_4': 1.390096664428711, 'epoch': 8.2}
{'loss': 0.0179, 'grad_norm': 5.868839263916016, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.014617916196584702, 'loss_2': 0.003246307373046875, 'loss_3': -16.194244384765625, 'loss_4': 0.9102861881256104, 'epoch': 8.2}
{'loss': 0.0238, 'grad_norm': 6.184206485748291, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.01658277027308941, 'loss_2': 0.00719451904296875, 'loss_3': -15.999895095825195, 'loss_4': 0.7954912781715393, 'epoch': 8.21}
{'loss': 0.0188, 'grad_norm': 5.855535984039307, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.014888253062963486, 'loss_2': 0.00391387939453125, 'loss_3': -16.156494140625, 'loss_4': 0.8638757467269897, 'epoch': 8.22}
{'loss': 0.0217, 'grad_norm': 6.000118732452393, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.015881814062595367, 'loss_2': 0.005863189697265625, 'loss_3': -16.22356605529785, 'loss_4': 1.3360004425048828, 'epoch': 8.22}
{'loss': 0.0228, 'grad_norm': 6.329853057861328, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.018830442801117897, 'loss_2': 0.003932952880859375, 'loss_3': -16.245258331298828, 'loss_4': 1.1238245964050293, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 12:55:30,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:30,791 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:25<1:04:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:38,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02690325304865837, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.023504000157117844, 'eval_loss_2': 0.0033992528915405273, 'eval_loss_3': -18.218502044677734, 'eval_loss_4': 1.2683888673782349, 'epoch': 8.23}
{'loss': 0.0548, 'grad_norm': 13.073959350585938, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.053413622081279755, 'loss_2': 0.001422882080078125, 'loss_3': -16.069332122802734, 'loss_4': 1.112239122390747, 'epoch': 8.23}
{'loss': 0.0152, 'grad_norm': 8.600977897644043, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.014592640101909637, 'loss_2': 0.0006389617919921875, 'loss_3': -16.171232223510742, 'loss_4': 1.4994266033172607, 'epoch': 8.24}
{'loss': 0.021, 'grad_norm': 6.1318135261535645, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.013877585530281067, 'loss_2': 0.00708770751953125, 'loss_3': -16.22393226623535, 'loss_4': 0.9794433116912842, 'epoch': 8.24}
{'loss': 0.0241, 'grad_norm': 10.9810152053833, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.02259071357548237, 'loss_2': 0.0015544891357421875, 'loss_3': -16.15166473388672, 'loss_4': 1.3605413436889648, 'epoch': 8.25}
{'loss': 0.0246, 'grad_norm': 9.854342460632324, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.020165160298347473, 'loss_2': 0.00441741943359375, 'loss_3': -16.004302978515625, 'loss_4': 0.8897683024406433, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 12:55:38,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:38,144 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:32<1:04:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:45,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029429413378238678, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.207, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.023071061819791794, 'eval_loss_2': 0.006358355283737183, 'eval_loss_3': -18.200136184692383, 'eval_loss_4': 1.1826575994491577, 'epoch': 8.26}
{'loss': 0.0608, 'grad_norm': 27.8350887298584, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.05481427162885666, 'loss_2': 0.00600433349609375, 'loss_3': -15.99571418762207, 'loss_4': 0.6560044288635254, 'epoch': 8.26}
{'loss': 0.032, 'grad_norm': 7.811511993408203, 'learning_rate': 2.175e-05, 'loss_1': 0.028176866471767426, 'loss_2': 0.0038318634033203125, 'loss_3': -16.3756046295166, 'loss_4': 1.3453633785247803, 'epoch': 8.27}
{'loss': 0.0256, 'grad_norm': 8.593507766723633, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.022705407813191414, 'loss_2': 0.00293731689453125, 'loss_3': -16.199817657470703, 'loss_4': 1.395815372467041, 'epoch': 8.27}
{'loss': 0.0101, 'grad_norm': 5.538210868835449, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.00956928450614214, 'loss_2': 0.0005464553833007812, 'loss_3': -16.135282516479492, 'loss_4': 1.6069800853729248, 'epoch': 8.28}
{'loss': 0.0147, 'grad_norm': 5.166006565093994, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.009656871668994427, 'loss_2': 0.0050048828125, 'loss_3': -16.215911865234375, 'loss_4': 0.8130773901939392, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 12:55:45,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:45,522 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:39<1:04:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:52,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01742062158882618, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.288, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013209204189479351, 'eval_loss_2': 0.004211418330669403, 'eval_loss_3': -18.323034286499023, 'eval_loss_4': 1.1545830965042114, 'epoch': 8.28}
{'loss': 0.0212, 'grad_norm': 6.710252285003662, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.01774064265191555, 'loss_2': 0.0034427642822265625, 'loss_3': -16.196821212768555, 'loss_4': 1.1124364137649536, 'epoch': 8.29}
{'loss': 0.0371, 'grad_norm': 21.152090072631836, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.03208322450518608, 'loss_2': 0.0049896240234375, 'loss_3': -16.087787628173828, 'loss_4': 0.8017939329147339, 'epoch': 8.3}
{'loss': 0.0374, 'grad_norm': 10.45671272277832, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.022769693285226822, 'loss_2': 0.0146026611328125, 'loss_3': -16.479949951171875, 'loss_4': 1.50766921043396, 'epoch': 8.3}
{'loss': 0.0326, 'grad_norm': 6.925984859466553, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.020901484414935112, 'loss_2': 0.01171875, 'loss_3': -16.09923553466797, 'loss_4': 1.7816777229309082, 'epoch': 8.31}
{'loss': 0.0294, 'grad_norm': 8.297558784484863, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.02004939317703247, 'loss_2': 0.0093994140625, 'loss_3': -16.308746337890625, 'loss_4': 1.8381026983261108, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 12:55:52,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:52,874 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:47<1:04:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:00,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01873723417520523, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011363008059561253, 'eval_loss_2': 0.007374227046966553, 'eval_loss_3': -18.354345321655273, 'eval_loss_4': 1.2331182956695557, 'epoch': 8.31}
{'loss': 0.0321, 'grad_norm': 9.541707038879395, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.029574844986200333, 'loss_2': 0.002532958984375, 'loss_3': -16.235565185546875, 'loss_4': 1.6158742904663086, 'epoch': 8.32}
{'loss': 0.0225, 'grad_norm': 6.826081275939941, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.013634487986564636, 'loss_2': 0.0088958740234375, 'loss_3': -16.075416564941406, 'loss_4': 1.3297516107559204, 'epoch': 8.33}
{'loss': 0.0438, 'grad_norm': 24.399019241333008, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.03361519053578377, 'loss_2': 0.01019287109375, 'loss_3': -16.262012481689453, 'loss_4': 1.6232450008392334, 'epoch': 8.33}
{'loss': 0.0293, 'grad_norm': 7.225470066070557, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.02380736917257309, 'loss_2': 0.005489349365234375, 'loss_3': -16.11078453063965, 'loss_4': 0.9482462406158447, 'epoch': 8.34}
{'loss': 0.0274, 'grad_norm': 9.58434009552002, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.024049725383520126, 'loss_2': 0.0033702850341796875, 'loss_3': -16.257169723510742, 'loss_4': 1.3986018896102905, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 12:56:00,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:00,228 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:54<1:04:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:07,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026846550405025482, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.979, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.022883856669068336, 'eval_loss_2': 0.003962695598602295, 'eval_loss_3': -18.231201171875, 'eval_loss_4': 1.3227314949035645, 'epoch': 8.34}
{'loss': 0.0157, 'grad_norm': 5.1007819175720215, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.01117519848048687, 'loss_2': 0.00457000732421875, 'loss_3': -16.248924255371094, 'loss_4': 1.332843542098999, 'epoch': 8.35}
{'loss': 0.0303, 'grad_norm': 9.381399154663086, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.026957055553793907, 'loss_2': 0.0033054351806640625, 'loss_3': -16.102567672729492, 'loss_4': 1.3237159252166748, 'epoch': 8.35}
{'loss': 0.0196, 'grad_norm': 5.809065341949463, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.01644325442612171, 'loss_2': 0.003143310546875, 'loss_3': -15.990144729614258, 'loss_4': 1.4087533950805664, 'epoch': 8.36}
{'loss': 0.0327, 'grad_norm': 11.386764526367188, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.02494005113840103, 'loss_2': 0.007770538330078125, 'loss_3': -16.08022689819336, 'loss_4': 1.4950282573699951, 'epoch': 8.37}
{'loss': 0.033, 'grad_norm': 8.756819725036621, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.02049771323800087, 'loss_2': 0.01253509521484375, 'loss_3': -16.177715301513672, 'loss_4': 0.8496586084365845, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 12:56:07,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:07,588 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [36:02<1:04:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:14,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08882224559783936, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.115, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.07567846775054932, 'eval_loss_2': 0.013143777847290039, 'eval_loss_3': -17.981054306030273, 'eval_loss_4': 1.4504673480987549, 'epoch': 8.37}
{'loss': 0.0532, 'grad_norm': 16.172815322875977, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.0380638912320137, 'loss_2': 0.015106201171875, 'loss_3': -15.873552322387695, 'loss_4': 1.4123117923736572, 'epoch': 8.38}
{'loss': 0.0219, 'grad_norm': 6.350905895233154, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.013930493965744972, 'loss_2': 0.0080108642578125, 'loss_3': -16.08739471435547, 'loss_4': 0.7500902414321899, 'epoch': 8.38}
{'loss': 0.0238, 'grad_norm': 11.453527450561523, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.01612144149839878, 'loss_2': 0.00769805908203125, 'loss_3': -16.019683837890625, 'loss_4': 1.0718803405761719, 'epoch': 8.39}
{'loss': 0.024, 'grad_norm': 6.115731716156006, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.01604584977030754, 'loss_2': 0.007965087890625, 'loss_3': -16.156450271606445, 'loss_4': 0.8145734071731567, 'epoch': 8.4}
{'loss': 0.0355, 'grad_norm': 7.918197154998779, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.026068557053804398, 'loss_2': 0.00942230224609375, 'loss_3': -16.227140426635742, 'loss_4': 1.3834738731384277, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 12:56:14,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:14,941 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:09<1:04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:22,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06965310126543045, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.77, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0579109862446785, 'eval_loss_2': 0.011742115020751953, 'eval_loss_3': -18.005352020263672, 'eval_loss_4': 1.123434066772461, 'epoch': 8.4}
{'loss': 0.0279, 'grad_norm': 6.476934432983398, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.019428085535764694, 'loss_2': 0.0084991455078125, 'loss_3': -16.24262809753418, 'loss_4': 0.8806279897689819, 'epoch': 8.41}
{'loss': 0.0238, 'grad_norm': 5.623110294342041, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.017090316861867905, 'loss_2': 0.006740570068359375, 'loss_3': -15.953661918640137, 'loss_4': 0.7348677515983582, 'epoch': 8.41}
{'loss': 0.0186, 'grad_norm': 5.494750022888184, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.013693147338926792, 'loss_2': 0.004932403564453125, 'loss_3': -15.999544143676758, 'loss_4': 0.8545562028884888, 'epoch': 8.42}
{'loss': 0.0186, 'grad_norm': 5.946673393249512, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.015261176973581314, 'loss_2': 0.0033664703369140625, 'loss_3': -16.075843811035156, 'loss_4': 0.7914689779281616, 'epoch': 8.42}
{'loss': 0.0243, 'grad_norm': 7.253427028656006, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.02089584618806839, 'loss_2': 0.0033779144287109375, 'loss_3': -16.34898567199707, 'loss_4': 0.9269496202468872, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 12:56:22,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:22,303 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:16<1:04:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:29,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04198440909385681, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.037215277552604675, 'eval_loss_2': 0.004769131541252136, 'eval_loss_3': -18.045629501342773, 'eval_loss_4': 0.8894787430763245, 'epoch': 8.43}
{'loss': 0.0326, 'grad_norm': 14.01832103729248, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.02441287785768509, 'loss_2': 0.00821685791015625, 'loss_3': -16.278121948242188, 'loss_4': 0.7882721424102783, 'epoch': 8.44}
{'loss': 0.0413, 'grad_norm': 12.043444633483887, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.02584414929151535, 'loss_2': 0.01548004150390625, 'loss_3': -16.068405151367188, 'loss_4': 0.7439090609550476, 'epoch': 8.44}
{'loss': 0.0519, 'grad_norm': 11.27935791015625, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.03743189573287964, 'loss_2': 0.0144195556640625, 'loss_3': -15.949357986450195, 'loss_4': 0.6240072250366211, 'epoch': 8.45}
{'loss': 0.0268, 'grad_norm': 5.429675579071045, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.013641254976391792, 'loss_2': 0.013153076171875, 'loss_3': -16.222339630126953, 'loss_4': 0.6132237911224365, 'epoch': 8.45}
{'loss': 0.0226, 'grad_norm': 5.568599224090576, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.009776157326996326, 'loss_2': 0.0128326416015625, 'loss_3': -16.135507583618164, 'loss_4': 0.7171328067779541, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 12:56:29,652 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:29,652 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:24<1:04:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:37,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03893017768859863, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.028528694063425064, 'eval_loss_2': 0.010401487350463867, 'eval_loss_3': -18.083908081054688, 'eval_loss_4': 0.6517210006713867, 'epoch': 8.46}
{'loss': 0.027, 'grad_norm': 5.151644229888916, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.008081567473709583, 'loss_2': 0.018890380859375, 'loss_3': -15.865177154541016, 'loss_4': 0.362559974193573, 'epoch': 8.47}
{'loss': 0.0347, 'grad_norm': 11.666821479797363, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.02635883167386055, 'loss_2': 0.0083160400390625, 'loss_3': -15.855344772338867, 'loss_4': 0.9261497855186462, 'epoch': 8.47}
{'loss': 0.0339, 'grad_norm': 7.766605377197266, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.019630545750260353, 'loss_2': 0.01422882080078125, 'loss_3': -16.192909240722656, 'loss_4': 0.6321592330932617, 'epoch': 8.48}
{'loss': 0.0158, 'grad_norm': 6.903566837310791, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.013102583587169647, 'loss_2': 0.002716064453125, 'loss_3': -16.358654022216797, 'loss_4': 0.3987116515636444, 'epoch': 8.48}
{'loss': 0.0217, 'grad_norm': 5.8590593338012695, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.017841611057519913, 'loss_2': 0.0039005279541015625, 'loss_3': -16.06699562072754, 'loss_4': 0.7217420935630798, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 12:56:37,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:37,012 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:31<1:04:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:44,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025039512664079666, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.021515119820833206, 'eval_loss_2': 0.00352439284324646, 'eval_loss_3': -18.118846893310547, 'eval_loss_4': 0.6721341013908386, 'epoch': 8.49}
{'loss': 0.0115, 'grad_norm': 5.476980686187744, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.007671491242945194, 'loss_2': 0.0038299560546875, 'loss_3': -16.188217163085938, 'loss_4': 0.8653103709220886, 'epoch': 8.49}
{'loss': 0.0331, 'grad_norm': 9.077966690063477, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.027439353987574577, 'loss_2': 0.00565338134765625, 'loss_3': -16.105533599853516, 'loss_4': 0.5682392120361328, 'epoch': 8.5}
{'loss': 0.0226, 'grad_norm': 12.979108810424805, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.020346855744719505, 'loss_2': 0.0022735595703125, 'loss_3': -16.341106414794922, 'loss_4': 1.074950933456421, 'epoch': 8.51}
{'loss': 0.0248, 'grad_norm': 5.741239547729492, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.01348197553306818, 'loss_2': 0.011322021484375, 'loss_3': -16.079524993896484, 'loss_4': 0.8013945817947388, 'epoch': 8.51}
{'loss': 0.026, 'grad_norm': 8.616228103637695, 'learning_rate': 2.15e-05, 'loss_1': 0.018134616315364838, 'loss_2': 0.0078582763671875, 'loss_3': -16.16855239868164, 'loss_4': 0.7370491027832031, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 12:56:44,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:44,367 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:38<1:03:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:51,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02816125378012657, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017659392207860947, 'eval_loss_2': 0.010501861572265625, 'eval_loss_3': -18.174535751342773, 'eval_loss_4': 0.7712243795394897, 'epoch': 8.52}
{'loss': 0.0234, 'grad_norm': 7.306860446929932, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.013988177292048931, 'loss_2': 0.00939178466796875, 'loss_3': -16.228090286254883, 'loss_4': 0.8122107982635498, 'epoch': 8.52}
{'loss': 0.0221, 'grad_norm': 6.1579976081848145, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.013806273229420185, 'loss_2': 0.0082855224609375, 'loss_3': -16.307537078857422, 'loss_4': 1.262328028678894, 'epoch': 8.53}
{'loss': 0.0251, 'grad_norm': 4.499610424041748, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.00705870334059, 'loss_2': 0.0180816650390625, 'loss_3': -16.201183319091797, 'loss_4': 1.1053005456924438, 'epoch': 8.53}
{'loss': 0.0122, 'grad_norm': 5.445964336395264, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.010714227333664894, 'loss_2': 0.00150299072265625, 'loss_3': -16.287382125854492, 'loss_4': 0.5203187465667725, 'epoch': 8.54}
{'loss': 0.0369, 'grad_norm': 15.599810600280762, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.03669064864516258, 'loss_2': 0.00019741058349609375, 'loss_3': -16.23855972290039, 'loss_4': 0.5914832949638367, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 12:56:51,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:51,721 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:46<1:03:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:59,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017189811915159225, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.669, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013845618814229965, 'eval_loss_2': 0.0033441931009292603, 'eval_loss_3': -18.228225708007812, 'eval_loss_4': 0.9424018859863281, 'epoch': 8.55}
{'loss': 0.0172, 'grad_norm': 5.10486364364624, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.007660703267902136, 'loss_2': 0.00952911376953125, 'loss_3': -16.177711486816406, 'loss_4': 1.4187008142471313, 'epoch': 8.55}
{'loss': 0.0148, 'grad_norm': 4.610203742980957, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.008552683517336845, 'loss_2': 0.006256103515625, 'loss_3': -16.434858322143555, 'loss_4': 1.177429437637329, 'epoch': 8.56}
{'loss': 0.0298, 'grad_norm': 11.575895309448242, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.026952514424920082, 'loss_2': 0.002864837646484375, 'loss_3': -16.184541702270508, 'loss_4': 1.1412732601165771, 'epoch': 8.56}
{'loss': 0.0153, 'grad_norm': 5.066249370574951, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.008966327644884586, 'loss_2': 0.006359100341796875, 'loss_3': -16.37057876586914, 'loss_4': 0.7654562592506409, 'epoch': 8.57}
{'loss': 0.0335, 'grad_norm': 17.905609130859375, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.030295033007860184, 'loss_2': 0.003204345703125, 'loss_3': -16.165760040283203, 'loss_4': 1.8362482786178589, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 12:56:59,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:59,084 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:53<1:03:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:06,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01933252438902855, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013700484298169613, 'eval_loss_2': 0.00563204288482666, 'eval_loss_3': -18.26806640625, 'eval_loss_4': 0.8614053130149841, 'epoch': 8.58}
{'loss': 0.0332, 'grad_norm': 12.405527114868164, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.02551139146089554, 'loss_2': 0.0076904296875, 'loss_3': -16.16919708251953, 'loss_4': 1.3390671014785767, 'epoch': 8.58}
{'loss': 0.0273, 'grad_norm': 10.900321006774902, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.02204699069261551, 'loss_2': 0.0052032470703125, 'loss_3': -16.15802001953125, 'loss_4': 1.111614465713501, 'epoch': 8.59}
{'loss': 0.0159, 'grad_norm': 5.962702751159668, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.013501539826393127, 'loss_2': 0.0023784637451171875, 'loss_3': -16.160964965820312, 'loss_4': 0.6341122388839722, 'epoch': 8.59}
{'loss': 0.0198, 'grad_norm': 6.185031414031982, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.011823732405900955, 'loss_2': 0.0080108642578125, 'loss_3': -16.411752700805664, 'loss_4': 1.0775080919265747, 'epoch': 8.6}
{'loss': 0.0264, 'grad_norm': 6.67486047744751, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.019689492881298065, 'loss_2': 0.006687164306640625, 'loss_3': -16.267635345458984, 'loss_4': 0.6553882360458374, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 12:57:06,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:06,441 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [37:00<1:03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:13,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016221744939684868, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.551, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013528765179216862, 'eval_loss_2': 0.0026929788291454315, 'eval_loss_3': -18.262657165527344, 'eval_loss_4': 0.6702207326889038, 'epoch': 8.6}
{'loss': 0.0363, 'grad_norm': 11.077703475952148, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.032639484852552414, 'loss_2': 0.0036220550537109375, 'loss_3': -16.145729064941406, 'loss_4': 0.6912007927894592, 'epoch': 8.61}
{'loss': 0.0208, 'grad_norm': 8.255148887634277, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.012475240044295788, 'loss_2': 0.00832366943359375, 'loss_3': -16.109827041625977, 'loss_4': 0.626621425151825, 'epoch': 8.62}
{'loss': 0.0233, 'grad_norm': 5.689881801605225, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.014615941792726517, 'loss_2': 0.0087127685546875, 'loss_3': -16.141393661499023, 'loss_4': 1.1540539264678955, 'epoch': 8.62}
{'loss': 0.0208, 'grad_norm': 6.784400463104248, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.020664483308792114, 'loss_2': 0.00011146068572998047, 'loss_3': -16.27196502685547, 'loss_4': 0.3051060736179352, 'epoch': 8.63}
{'loss': 0.0279, 'grad_norm': 8.8471097946167, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.024518368765711784, 'loss_2': 0.003345489501953125, 'loss_3': -16.359268188476562, 'loss_4': 0.44398051500320435, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 12:57:13,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:13,790 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:08<1:03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:21,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016039447858929634, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.472, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013482237234711647, 'eval_loss_2': 0.002557210624217987, 'eval_loss_3': -18.272706985473633, 'eval_loss_4': 0.6630132794380188, 'epoch': 8.63}
{'loss': 0.0343, 'grad_norm': 13.200550079345703, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.028061632066965103, 'loss_2': 0.006259918212890625, 'loss_3': -16.226463317871094, 'loss_4': 1.0308362245559692, 'epoch': 8.64}
{'loss': 0.0233, 'grad_norm': 6.233673572540283, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.017627840861678123, 'loss_2': 0.005641937255859375, 'loss_3': -16.413938522338867, 'loss_4': 1.2556010484695435, 'epoch': 8.65}
{'loss': 0.0187, 'grad_norm': 7.716710567474365, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.018042031675577164, 'loss_2': 0.000659942626953125, 'loss_3': -16.185333251953125, 'loss_4': 1.1624956130981445, 'epoch': 8.65}
{'loss': 0.0499, 'grad_norm': 18.035396575927734, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.04902124032378197, 'loss_2': 0.0009031295776367188, 'loss_3': -16.4129581451416, 'loss_4': 0.7694022059440613, 'epoch': 8.66}
{'loss': 0.0828, 'grad_norm': 15.409383773803711, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.08097609877586365, 'loss_2': 0.0018625259399414062, 'loss_3': -16.322975158691406, 'loss_4': 1.0616848468780518, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 12:57:21,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:21,140 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:15<1:03:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:28,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01577691361308098, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0133921904489398, 'eval_loss_2': 0.0023847222328186035, 'eval_loss_3': -18.280916213989258, 'eval_loss_4': 0.5555088520050049, 'epoch': 8.66}
{'loss': 0.0181, 'grad_norm': 7.2645955085754395, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.01736651547253132, 'loss_2': 0.0007610321044921875, 'loss_3': -16.423660278320312, 'loss_4': 0.8888316750526428, 'epoch': 8.67}
{'loss': 0.0484, 'grad_norm': 10.95767593383789, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.04626801609992981, 'loss_2': 0.00209808349609375, 'loss_3': -16.38043975830078, 'loss_4': 0.782705545425415, 'epoch': 8.67}
{'loss': 0.0435, 'grad_norm': 15.499879837036133, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.03858306258916855, 'loss_2': 0.00496673583984375, 'loss_3': -16.243515014648438, 'loss_4': 0.8655939102172852, 'epoch': 8.68}
{'loss': 0.0329, 'grad_norm': 11.119513511657715, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.028663083910942078, 'loss_2': 0.004230499267578125, 'loss_3': -16.16329002380371, 'loss_4': 0.3926873803138733, 'epoch': 8.69}
{'loss': 0.0215, 'grad_norm': 7.185254096984863, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.01914878375828266, 'loss_2': 0.0023860931396484375, 'loss_3': -16.259292602539062, 'loss_4': 0.701373815536499, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 12:57:28,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:28,488 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:22<1:03:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:35,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015761636197566986, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013189826160669327, 'eval_loss_2': 0.0025718100368976593, 'eval_loss_3': -18.302814483642578, 'eval_loss_4': 0.5437049269676208, 'epoch': 8.69}
{'loss': 0.0332, 'grad_norm': 26.12592124938965, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.03237958624958992, 'loss_2': 0.0008554458618164062, 'loss_3': -16.2354736328125, 'loss_4': 0.6419081687927246, 'epoch': 8.7}
{'loss': 0.0314, 'grad_norm': 11.813642501831055, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.03128613904118538, 'loss_2': 8.952617645263672e-05, 'loss_3': -16.445819854736328, 'loss_4': 0.5733096599578857, 'epoch': 8.7}
{'loss': 0.0274, 'grad_norm': 9.799277305603027, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.027318961918354034, 'loss_2': 3.314018249511719e-05, 'loss_3': -16.32052993774414, 'loss_4': 1.2228933572769165, 'epoch': 8.71}
{'loss': 0.0289, 'grad_norm': 13.61632251739502, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.028037292882800102, 'loss_2': 0.0008192062377929688, 'loss_3': -16.212160110473633, 'loss_4': 1.1402676105499268, 'epoch': 8.72}
{'loss': 0.0496, 'grad_norm': 11.550209999084473, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.04553663730621338, 'loss_2': 0.0040740966796875, 'loss_3': -16.2069091796875, 'loss_4': 0.970307469367981, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 12:57:35,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:35,843 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:30<1:03:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:43,210 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016209401190280914, 'eval_runtime': 3.8219, 'eval_samples_per_second': 267.927, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.01184970885515213, 'eval_loss_2': 0.004359692335128784, 'eval_loss_3': -18.32465171813965, 'eval_loss_4': 0.6563996076583862, 'epoch': 8.72}
{'loss': 0.0319, 'grad_norm': 14.172880172729492, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.03106008656322956, 'loss_2': 0.000820159912109375, 'loss_3': -16.44916534423828, 'loss_4': 1.4503666162490845, 'epoch': 8.73}
{'loss': 0.0182, 'grad_norm': 6.619101524353027, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.015421212650835514, 'loss_2': 0.0028095245361328125, 'loss_3': -16.252086639404297, 'loss_4': 1.3336495161056519, 'epoch': 8.73}
{'loss': 0.0166, 'grad_norm': 6.7987895011901855, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.016166560351848602, 'loss_2': 0.00047898292541503906, 'loss_3': -16.334434509277344, 'loss_4': 0.48699110746383667, 'epoch': 8.74}
{'loss': 0.0097, 'grad_norm': 4.71890115737915, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.007864226587116718, 'loss_2': 0.0018587112426757812, 'loss_3': -16.422039031982422, 'loss_4': 0.7507533431053162, 'epoch': 8.74}
{'loss': 0.0097, 'grad_norm': 5.389403343200684, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.007224443834275007, 'loss_2': 0.0025043487548828125, 'loss_3': -16.444936752319336, 'loss_4': 1.1064499616622925, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 12:57:43,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:43,210 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:37<1:03:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:50,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014939244836568832, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010984365828335285, 'eval_loss_2': 0.003954879939556122, 'eval_loss_3': -18.34771728515625, 'eval_loss_4': 0.9214588403701782, 'epoch': 8.75}
{'loss': 0.0147, 'grad_norm': 8.099871635437012, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.013535122387111187, 'loss_2': 0.0011663436889648438, 'loss_3': -16.25847625732422, 'loss_4': 1.1605215072631836, 'epoch': 8.76}
{'loss': 0.0121, 'grad_norm': 5.294983386993408, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.011478181928396225, 'loss_2': 0.0006132125854492188, 'loss_3': -16.36466407775879, 'loss_4': 1.290582537651062, 'epoch': 8.76}
{'loss': 0.0179, 'grad_norm': 8.232560157775879, 'learning_rate': 2.125e-05, 'loss_1': 0.017313694581389427, 'loss_2': 0.0005521774291992188, 'loss_3': -16.328969955444336, 'loss_4': 2.0540122985839844, 'epoch': 8.77}
{'loss': 0.0323, 'grad_norm': 9.990033149719238, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.023546358570456505, 'loss_2': 0.0087738037109375, 'loss_3': -16.257137298583984, 'loss_4': 1.7803293466567993, 'epoch': 8.77}
{'loss': 0.0273, 'grad_norm': 10.63210678100586, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.018717085942626, 'loss_2': 0.00861358642578125, 'loss_3': -16.51618003845215, 'loss_4': 0.9774888753890991, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 12:57:50,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:50,566 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:44<1:03:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:57,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017360268160700798, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.427, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.014935312792658806, 'eval_loss_2': 0.002424955368041992, 'eval_loss_3': -18.310653686523438, 'eval_loss_4': 0.5885863304138184, 'epoch': 8.78}
{'loss': 0.0187, 'grad_norm': 7.539299964904785, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.013591657392680645, 'loss_2': 0.0051116943359375, 'loss_3': -16.26056671142578, 'loss_4': 0.8460809588432312, 'epoch': 8.78}
{'loss': 0.0169, 'grad_norm': 5.362682819366455, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.014505946077406406, 'loss_2': 0.002407073974609375, 'loss_3': -16.1256160736084, 'loss_4': 0.9847161173820496, 'epoch': 8.79}
{'loss': 0.0174, 'grad_norm': 5.350830554962158, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.011363559402525425, 'loss_2': 0.0060272216796875, 'loss_3': -16.25560760498047, 'loss_4': 1.2246732711791992, 'epoch': 8.8}
{'loss': 0.0289, 'grad_norm': 13.938541412353516, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.0280084777623415, 'loss_2': 0.00091552734375, 'loss_3': -16.306547164916992, 'loss_4': 0.6776801347732544, 'epoch': 8.8}
{'loss': 0.0384, 'grad_norm': 18.56608009338379, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.0353127121925354, 'loss_2': 0.003116607666015625, 'loss_3': -16.372142791748047, 'loss_4': 0.5369665622711182, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 12:57:57,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:57,925 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:52<1:02:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:05,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019244978204369545, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016358928754925728, 'eval_loss_2': 0.002886049449443817, 'eval_loss_3': -18.25714683532715, 'eval_loss_4': 0.30307379364967346, 'epoch': 8.81}
{'loss': 0.0705, 'grad_norm': 21.162904739379883, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.06417250633239746, 'loss_2': 0.006351470947265625, 'loss_3': -16.382373809814453, 'loss_4': 0.49806153774261475, 'epoch': 8.81}
{'loss': 0.0158, 'grad_norm': 6.535329341888428, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.011256727389991283, 'loss_2': 0.004535675048828125, 'loss_3': -16.29660415649414, 'loss_4': 0.4136027693748474, 'epoch': 8.82}
{'loss': 0.0455, 'grad_norm': 14.957141876220703, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.041405290365219116, 'loss_2': 0.004123687744140625, 'loss_3': -16.245929718017578, 'loss_4': 0.339260458946228, 'epoch': 8.83}
{'loss': 0.0089, 'grad_norm': 5.336755275726318, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.0074353888630867004, 'loss_2': 0.001438140869140625, 'loss_3': -16.282024383544922, 'loss_4': 0.3739796280860901, 'epoch': 8.83}
{'loss': 0.0142, 'grad_norm': 5.550228118896484, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.012833568267524242, 'loss_2': 0.001373291015625, 'loss_3': -16.050073623657227, 'loss_4': 0.27559030055999756, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 12:58:05,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:05,273 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [37:59<1:02:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:12,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021324731409549713, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.322, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018593816086649895, 'eval_loss_2': 0.0027309097349643707, 'eval_loss_3': -18.186330795288086, 'eval_loss_4': 0.18523955345153809, 'epoch': 8.84}
{'loss': 0.0099, 'grad_norm': 5.529267311096191, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.009262952022254467, 'loss_2': 0.0006127357482910156, 'loss_3': -16.355255126953125, 'loss_4': 0.4958048462867737, 'epoch': 8.84}
{'loss': 0.0243, 'grad_norm': 8.067498207092285, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.01635695993900299, 'loss_2': 0.0079345703125, 'loss_3': -16.171892166137695, 'loss_4': 0.29552850127220154, 'epoch': 8.85}
{'loss': 0.0281, 'grad_norm': 11.77347469329834, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.02631208673119545, 'loss_2': 0.0017757415771484375, 'loss_3': -16.201507568359375, 'loss_4': 0.1941538006067276, 'epoch': 8.85}
{'loss': 0.0182, 'grad_norm': 5.482726573944092, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.013172943145036697, 'loss_2': 0.0050048828125, 'loss_3': -16.431026458740234, 'loss_4': -0.0019753016531467438, 'epoch': 8.86}
{'loss': 0.0171, 'grad_norm': 10.91413688659668, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.015868324786424637, 'loss_2': 0.00119781494140625, 'loss_3': -16.38561248779297, 'loss_4': 0.42295676469802856, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 12:58:12,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:12,618 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:07<1:02:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:19,977 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02395765110850334, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.021296322345733643, 'eval_loss_2': 0.002661328762769699, 'eval_loss_3': -18.154369354248047, 'eval_loss_4': 0.2268182337284088, 'epoch': 8.87}
{'loss': 0.0146, 'grad_norm': 5.918494701385498, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.014127194881439209, 'loss_2': 0.0004515647888183594, 'loss_3': -16.34297752380371, 'loss_4': 0.2408437430858612, 'epoch': 8.87}
{'loss': 0.0153, 'grad_norm': 5.9001898765563965, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.012278825975954533, 'loss_2': 0.0030059814453125, 'loss_3': -16.150657653808594, 'loss_4': 0.761705756187439, 'epoch': 8.88}
{'loss': 0.0825, 'grad_norm': 18.03139305114746, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.07467685639858246, 'loss_2': 0.007793426513671875, 'loss_3': -16.425045013427734, 'loss_4': 0.6036975383758545, 'epoch': 8.88}
{'loss': 0.0274, 'grad_norm': 7.444676399230957, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.012355406768620014, 'loss_2': 0.01503753662109375, 'loss_3': -16.15984535217285, 'loss_4': 0.6475818753242493, 'epoch': 8.89}
{'loss': 0.0173, 'grad_norm': 7.1006388664245605, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.009862574748694897, 'loss_2': 0.00745391845703125, 'loss_3': -16.23365020751953, 'loss_4': 0.42557430267333984, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 12:58:19,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:19,977 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:14<1:02:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:27,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03282136097550392, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.68, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.023164933547377586, 'eval_loss_2': 0.009656429290771484, 'eval_loss_3': -18.115686416625977, 'eval_loss_4': 0.5750247836112976, 'epoch': 8.9}
{'loss': 0.0192, 'grad_norm': 5.781455993652344, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.010768565349280834, 'loss_2': 0.008392333984375, 'loss_3': -16.378244400024414, 'loss_4': 0.8768903613090515, 'epoch': 8.9}
{'loss': 0.0363, 'grad_norm': 14.270346641540527, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.02982613630592823, 'loss_2': 0.0064697265625, 'loss_3': -16.154876708984375, 'loss_4': 0.7596175670623779, 'epoch': 8.91}
{'loss': 0.0312, 'grad_norm': 7.07297420501709, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.014819290488958359, 'loss_2': 0.0163421630859375, 'loss_3': -16.29685401916504, 'loss_4': 0.7645519375801086, 'epoch': 8.91}
{'loss': 0.0428, 'grad_norm': 13.036200523376465, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.027685731649398804, 'loss_2': 0.015106201171875, 'loss_3': -16.23274803161621, 'loss_4': 0.7872795462608337, 'epoch': 8.92}
{'loss': 0.0326, 'grad_norm': 9.119474411010742, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.022543175145983696, 'loss_2': 0.01004791259765625, 'loss_3': -16.1591854095459, 'loss_4': 0.8713505864143372, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 12:58:27,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:27,334 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:21<1:02:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:34,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027288390323519707, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.023447168990969658, 'eval_loss_2': 0.003841221332550049, 'eval_loss_3': -18.09597396850586, 'eval_loss_4': 0.8598597049713135, 'epoch': 8.92}
{'loss': 0.0249, 'grad_norm': 7.457802772521973, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.01957400143146515, 'loss_2': 0.00531768798828125, 'loss_3': -16.27304458618164, 'loss_4': 1.1530323028564453, 'epoch': 8.93}
{'loss': 0.0487, 'grad_norm': 15.192097663879395, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.04363476485013962, 'loss_2': 0.005039215087890625, 'loss_3': -16.320228576660156, 'loss_4': 1.2478560209274292, 'epoch': 8.94}
{'loss': 0.0184, 'grad_norm': 6.873959064483643, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.016068367287516594, 'loss_2': 0.002285003662109375, 'loss_3': -16.31595802307129, 'loss_4': 1.250558853149414, 'epoch': 8.94}
{'loss': 0.0247, 'grad_norm': 6.301504611968994, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.01615508459508419, 'loss_2': 0.008514404296875, 'loss_3': -16.295047760009766, 'loss_4': 1.4537643194198608, 'epoch': 8.95}
{'loss': 0.0105, 'grad_norm': 5.197062969207764, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.006667721085250378, 'loss_2': 0.0038013458251953125, 'loss_3': -16.199195861816406, 'loss_4': 0.9596331715583801, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 12:58:34,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:34,686 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:29<1:02:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:42,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021452298387885094, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01818740740418434, 'eval_loss_2': 0.003264889121055603, 'eval_loss_3': -18.138671875, 'eval_loss_4': 0.8826872706413269, 'epoch': 8.95}
{'loss': 0.0095, 'grad_norm': 4.77852201461792, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.007569117471575737, 'loss_2': 0.001888275146484375, 'loss_3': -16.46961784362793, 'loss_4': 0.9793253540992737, 'epoch': 8.96}
{'loss': 0.0712, 'grad_norm': inf, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.06729499995708466, 'loss_2': 0.0039520263671875, 'loss_3': -16.039430618286133, 'loss_4': 0.719449520111084, 'epoch': 8.97}
{'loss': 0.0321, 'grad_norm': 25.016849517822266, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.025609387084841728, 'loss_2': 0.006519317626953125, 'loss_3': -16.298011779785156, 'loss_4': 0.5665842294692993, 'epoch': 8.97}
{'loss': 0.0179, 'grad_norm': 6.3729329109191895, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.016742929816246033, 'loss_2': 0.00112152099609375, 'loss_3': -16.5001220703125, 'loss_4': 0.5905863642692566, 'epoch': 8.98}
{'loss': 0.0142, 'grad_norm': 6.687743186950684, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.009387155063450336, 'loss_2': 0.00479888916015625, 'loss_3': -16.347537994384766, 'loss_4': 0.9774640798568726, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 12:58:42,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:42,021 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:36<59:50,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 12:58:49,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018591850996017456, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012909241020679474, 'eval_loss_2': 0.005682609975337982, 'eval_loss_3': -18.227079391479492, 'eval_loss_4': 0.8193453550338745, 'epoch': 8.98}
{'loss': 0.0238, 'grad_norm': 8.193120956420898, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.019606756046414375, 'loss_2': 0.004207611083984375, 'loss_3': -16.40819549560547, 'loss_4': 0.7591909766197205, 'epoch': 8.99}
{'loss': 0.027, 'grad_norm': 7.179406642913818, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.01781412772834301, 'loss_2': 0.0091552734375, 'loss_3': -16.210094451904297, 'loss_4': 1.4480156898498535, 'epoch': 8.99}
{'loss': 0.0067, 'grad_norm': 7.976511001586914, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.0045677851885557175, 'loss_2': 0.002140045166015625, 'loss_3': -16.265714645385742, 'loss_4': 1.5976262092590332, 'epoch': 9.0}
{'loss': 0.0247, 'grad_norm': 6.991983413696289, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.02242336980998516, 'loss_2': 0.00228118896484375, 'loss_3': -16.365285873413086, 'loss_4': 1.1622322797775269, 'epoch': 9.01}
{'loss': 0.0203, 'grad_norm': 7.4462714195251465, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.019512658938765526, 'loss_2': 0.0007619857788085938, 'loss_3': -16.362140655517578, 'loss_4': 1.9303010702133179, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 12:58:49,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:49,052 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:43<1:01:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:58:56,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016036801040172577, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01172585878521204, 'eval_loss_2': 0.004310943186283112, 'eval_loss_3': -18.31150245666504, 'eval_loss_4': 1.113530158996582, 'epoch': 9.01}
{'loss': 0.0295, 'grad_norm': 17.80525016784668, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.025487679988145828, 'loss_2': 0.004009246826171875, 'loss_3': -16.15183448791504, 'loss_4': 1.601975440979004, 'epoch': 9.02}
{'loss': 0.0147, 'grad_norm': 6.727721214294434, 'learning_rate': 2.1e-05, 'loss_1': 0.013870124705135822, 'loss_2': 0.000843048095703125, 'loss_3': -16.267040252685547, 'loss_4': 0.8791099786758423, 'epoch': 9.02}
{'loss': 0.0259, 'grad_norm': 6.123321533203125, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.01838887669146061, 'loss_2': 0.00746917724609375, 'loss_3': -16.2506103515625, 'loss_4': 1.1665160655975342, 'epoch': 9.03}
{'loss': 0.0271, 'grad_norm': 11.80836009979248, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.021597150713205338, 'loss_2': 0.0054931640625, 'loss_3': -16.135671615600586, 'loss_4': 1.474582314491272, 'epoch': 9.03}
{'loss': 0.0236, 'grad_norm': 8.014921188354492, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.01733795367181301, 'loss_2': 0.006298065185546875, 'loss_3': -16.319801330566406, 'loss_4': 1.9008797407150269, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 12:58:56,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:56,405 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:50<1:02:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:03,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016438648104667664, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.725, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.012886122800409794, 'eval_loss_2': 0.0035525262355804443, 'eval_loss_3': -18.28400993347168, 'eval_loss_4': 1.1407243013381958, 'epoch': 9.04}
{'loss': 0.018, 'grad_norm': 6.867581844329834, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.016769645735621452, 'loss_2': 0.0012264251708984375, 'loss_3': -16.09951400756836, 'loss_4': 1.63893723487854, 'epoch': 9.05}
{'loss': 0.0167, 'grad_norm': 5.400089740753174, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.015547622926533222, 'loss_2': 0.0011768341064453125, 'loss_3': -16.177051544189453, 'loss_4': 2.050330638885498, 'epoch': 9.05}
{'loss': 0.0172, 'grad_norm': 5.866321563720703, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.012875011190772057, 'loss_2': 0.00431060791015625, 'loss_3': -16.352924346923828, 'loss_4': 1.8625025749206543, 'epoch': 9.06}
{'loss': 0.0369, 'grad_norm': 11.906447410583496, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.031586166471242905, 'loss_2': 0.00531005859375, 'loss_3': -16.123992919921875, 'loss_4': 1.661454439163208, 'epoch': 9.06}
{'loss': 0.0763, 'grad_norm': 13.207557678222656, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.07167870551347733, 'loss_2': 0.004608154296875, 'loss_3': -16.02585220336914, 'loss_4': 1.629933476448059, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 12:59:03,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:03,772 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [38:58<1:02:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:11,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01956755481660366, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012624269351363182, 'eval_loss_2': 0.0069432854652404785, 'eval_loss_3': -18.263660430908203, 'eval_loss_4': 1.0328493118286133, 'epoch': 9.07}
{'loss': 0.0274, 'grad_norm': 8.004632949829102, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.02281828783452511, 'loss_2': 0.00457000732421875, 'loss_3': -16.336944580078125, 'loss_4': 1.4894864559173584, 'epoch': 9.08}
{'loss': 0.0145, 'grad_norm': 5.459885597229004, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.013145132921636105, 'loss_2': 0.0013179779052734375, 'loss_3': -16.290279388427734, 'loss_4': 1.7456235885620117, 'epoch': 9.08}
{'loss': 0.0457, 'grad_norm': 17.919601440429688, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.03101978823542595, 'loss_2': 0.01470184326171875, 'loss_3': -16.221670150756836, 'loss_4': 1.722973108291626, 'epoch': 9.09}
{'loss': 0.0177, 'grad_norm': 5.783454895019531, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.013756484724581242, 'loss_2': 0.0039825439453125, 'loss_3': -16.423568725585938, 'loss_4': 1.057464599609375, 'epoch': 9.09}
{'loss': 0.0211, 'grad_norm': 6.995019912719727, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.01458602212369442, 'loss_2': 0.00652313232421875, 'loss_3': -16.357553482055664, 'loss_4': 1.8485667705535889, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 12:59:11,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:11,125 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:05<1:02:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:18,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019545555114746094, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.568, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01210695505142212, 'eval_loss_2': 0.007438600063323975, 'eval_loss_3': -18.241737365722656, 'eval_loss_4': 1.1769053936004639, 'epoch': 9.1}
{'loss': 0.0496, 'grad_norm': 14.081055641174316, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.043209150433540344, 'loss_2': 0.0063934326171875, 'loss_3': -16.347021102905273, 'loss_4': 1.6305142641067505, 'epoch': 9.1}
{'loss': 0.0575, 'grad_norm': 18.984596252441406, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.0522693432867527, 'loss_2': 0.00521087646484375, 'loss_3': -16.249547958374023, 'loss_4': 1.2231767177581787, 'epoch': 9.11}
{'loss': 0.0354, 'grad_norm': 17.54290199279785, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.03261405602097511, 'loss_2': 0.0027751922607421875, 'loss_3': -16.338584899902344, 'loss_4': 1.7962924242019653, 'epoch': 9.12}
{'loss': 0.0255, 'grad_norm': 7.041866302490234, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.017741136252880096, 'loss_2': 0.0077362060546875, 'loss_3': -16.27889060974121, 'loss_4': 1.8490362167358398, 'epoch': 9.12}
{'loss': 0.0386, 'grad_norm': 12.535412788391113, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.03836142271757126, 'loss_2': 0.00022935867309570312, 'loss_3': -16.23001480102539, 'loss_4': 1.9880377054214478, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 12:59:18,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:18,472 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:12<1:02:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:25,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017912479117512703, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01457121316343546, 'eval_loss_2': 0.003341265022754669, 'eval_loss_3': -18.233915328979492, 'eval_loss_4': 1.2158294916152954, 'epoch': 9.13}
{'loss': 0.0202, 'grad_norm': 6.60345458984375, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.019754374399781227, 'loss_2': 0.00046253204345703125, 'loss_3': -16.34564971923828, 'loss_4': 1.0963151454925537, 'epoch': 9.13}
{'loss': 0.0258, 'grad_norm': 6.427777290344238, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.017564784735441208, 'loss_2': 0.0081939697265625, 'loss_3': -16.15178871154785, 'loss_4': 1.4142509698867798, 'epoch': 9.14}
{'loss': 0.0293, 'grad_norm': 9.391420364379883, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.024957289919257164, 'loss_2': 0.0043182373046875, 'loss_3': -16.338909149169922, 'loss_4': 1.425772786140442, 'epoch': 9.15}
{'loss': 0.0573, 'grad_norm': 10.976866722106934, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.04650586470961571, 'loss_2': 0.01080322265625, 'loss_3': -16.229015350341797, 'loss_4': 1.6439498662948608, 'epoch': 9.15}
{'loss': 0.0296, 'grad_norm': 7.532999515533447, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.022105097770690918, 'loss_2': 0.0074462890625, 'loss_3': -16.199195861816406, 'loss_4': 1.4924445152282715, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 12:59:25,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:25,814 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:20<1:01:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:33,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017563320696353912, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012943028472363949, 'eval_loss_2': 0.004620291292667389, 'eval_loss_3': -18.251075744628906, 'eval_loss_4': 1.1599364280700684, 'epoch': 9.16}
{'loss': 0.034, 'grad_norm': 9.506848335266113, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.024903554469347, 'loss_2': 0.00909423828125, 'loss_3': -16.343982696533203, 'loss_4': 1.2322343587875366, 'epoch': 9.16}
{'loss': 0.0938, 'grad_norm': 17.753231048583984, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.08967876434326172, 'loss_2': 0.00415802001953125, 'loss_3': -16.16632080078125, 'loss_4': 2.0860161781311035, 'epoch': 9.17}
{'loss': 0.0314, 'grad_norm': 7.7528228759765625, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.02609272487461567, 'loss_2': 0.005279541015625, 'loss_3': -16.352745056152344, 'loss_4': 1.8844622373580933, 'epoch': 9.17}
{'loss': 0.0257, 'grad_norm': 8.9218111038208, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.025262705981731415, 'loss_2': 0.00043392181396484375, 'loss_3': -16.33331871032715, 'loss_4': 1.4452677965164185, 'epoch': 9.18}
{'loss': 0.0833, 'grad_norm': 22.931427001953125, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.08324436843395233, 'loss_2': 4.947185516357422e-05, 'loss_3': -16.23052215576172, 'loss_4': 1.4133248329162598, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 12:59:33,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:33,159 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:27<1:01:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:40,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015547757968306541, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012745028361678123, 'eval_loss_2': 0.002802729606628418, 'eval_loss_3': -18.263181686401367, 'eval_loss_4': 0.8771312832832336, 'epoch': 9.19}
{'loss': 0.0759, 'grad_norm': 24.960771560668945, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.07541857659816742, 'loss_2': 0.0004401206970214844, 'loss_3': -16.359821319580078, 'loss_4': 1.1345362663269043, 'epoch': 9.19}
{'loss': 0.0343, 'grad_norm': 9.064838409423828, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.03368629142642021, 'loss_2': 0.0006055831909179688, 'loss_3': -16.189395904541016, 'loss_4': 1.2566877603530884, 'epoch': 9.2}
{'loss': 0.0192, 'grad_norm': 11.187762260437012, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.01727868616580963, 'loss_2': 0.001911163330078125, 'loss_3': -16.293210983276367, 'loss_4': 1.407104730606079, 'epoch': 9.2}
{'loss': 0.0199, 'grad_norm': 7.441656589508057, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.01616506464779377, 'loss_2': 0.0037384033203125, 'loss_3': -16.249393463134766, 'loss_4': 1.150442361831665, 'epoch': 9.21}
{'loss': 0.016, 'grad_norm': 5.2959675788879395, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.010585315525531769, 'loss_2': 0.00539398193359375, 'loss_3': -16.533573150634766, 'loss_4': 0.4729999303817749, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 12:59:40,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:40,501 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:34<1:01:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:47,854 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015691101551055908, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.944, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012645990587770939, 'eval_loss_2': 0.003045111894607544, 'eval_loss_3': -18.259288787841797, 'eval_loss_4': 0.4392451047897339, 'epoch': 9.22}
{'loss': 0.0103, 'grad_norm': 5.192193031311035, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.009334745816886425, 'loss_2': 0.0009984970092773438, 'loss_3': -16.43363380432129, 'loss_4': 0.745433509349823, 'epoch': 9.22}
{'loss': 0.0216, 'grad_norm': 11.345316886901855, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.020463738590478897, 'loss_2': 0.001125335693359375, 'loss_3': -16.2393798828125, 'loss_4': 0.26004353165626526, 'epoch': 9.23}
{'loss': 0.0241, 'grad_norm': 7.3864898681640625, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.018361896276474, 'loss_2': 0.0057525634765625, 'loss_3': -16.322452545166016, 'loss_4': 0.8426058292388916, 'epoch': 9.23}
{'loss': 0.0215, 'grad_norm': 6.631033897399902, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.016256676986813545, 'loss_2': 0.005279541015625, 'loss_3': -16.170875549316406, 'loss_4': 0.7952673435211182, 'epoch': 9.24}
{'loss': 0.0212, 'grad_norm': 5.993049621582031, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.01606048084795475, 'loss_2': 0.00513458251953125, 'loss_3': -16.22676658630371, 'loss_4': 0.42105817794799805, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 12:59:47,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:47,854 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:42<1:01:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:55,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014970974996685982, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.402, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012305055744946003, 'eval_loss_2': 0.002665918320417404, 'eval_loss_3': -18.27228546142578, 'eval_loss_4': 0.08071612566709518, 'epoch': 9.24}
{'loss': 0.0252, 'grad_norm': 6.5197434425354, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.019961636513471603, 'loss_2': 0.00525665283203125, 'loss_3': -16.344568252563477, 'loss_4': 0.41415852308273315, 'epoch': 9.25}
{'loss': 0.0153, 'grad_norm': 7.215085983276367, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.013498634099960327, 'loss_2': 0.0018463134765625, 'loss_3': -16.279150009155273, 'loss_4': 0.11783549189567566, 'epoch': 9.26}
{'loss': 0.0234, 'grad_norm': 6.235995769500732, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.013489949516952038, 'loss_2': 0.00994873046875, 'loss_3': -16.248363494873047, 'loss_4': -0.02496999502182007, 'epoch': 9.26}
{'loss': 0.0423, 'grad_norm': 12.765971183776855, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.031415652483701706, 'loss_2': 0.01091766357421875, 'loss_3': -16.415796279907227, 'loss_4': 0.4035074710845947, 'epoch': 9.27}
{'loss': 0.0237, 'grad_norm': 5.817358016967773, 'learning_rate': 2.075e-05, 'loss_1': 0.008994756266474724, 'loss_2': 0.01468658447265625, 'loss_3': -16.282506942749023, 'loss_4': 0.4597054421901703, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 12:59:55,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:55,200 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:49<1:01:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:02,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02005036734044552, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.472, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011976917274296284, 'eval_loss_2': 0.00807344913482666, 'eval_loss_3': -18.287677764892578, 'eval_loss_4': -0.0567464679479599, 'epoch': 9.27}
{'loss': 0.0399, 'grad_norm': 10.899097442626953, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.02829860895872116, 'loss_2': 0.0116119384765625, 'loss_3': -16.34961700439453, 'loss_4': -0.21001841127872467, 'epoch': 9.28}
{'loss': 0.0336, 'grad_norm': 12.408090591430664, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.02659379132091999, 'loss_2': 0.00698089599609375, 'loss_3': -16.31551742553711, 'loss_4': 0.15781864523887634, 'epoch': 9.28}
{'loss': 0.0422, 'grad_norm': 16.802038192749023, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.031517159193754196, 'loss_2': 0.010711669921875, 'loss_3': -16.170202255249023, 'loss_4': 0.2465391308069229, 'epoch': 9.29}
{'loss': 0.0116, 'grad_norm': 5.047962665557861, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.010542938485741615, 'loss_2': 0.0010738372802734375, 'loss_3': -16.14535140991211, 'loss_4': -0.03164795786142349, 'epoch': 9.3}
{'loss': 0.0181, 'grad_norm': 4.9738054275512695, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.00722905620932579, 'loss_2': 0.01088714599609375, 'loss_3': -16.29364776611328, 'loss_4': 0.0036460012197494507, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 13:00:02,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:02,542 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:56<1:01:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:09,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014335928484797478, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.877, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011600014753639698, 'eval_loss_2': 0.002735912799835205, 'eval_loss_3': -18.261316299438477, 'eval_loss_4': 0.02663596160709858, 'epoch': 9.3}
{'loss': 0.027, 'grad_norm': 6.8410491943359375, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.0192736703902483, 'loss_2': 0.00768280029296875, 'loss_3': -16.281917572021484, 'loss_4': 0.39890196919441223, 'epoch': 9.31}
{'loss': 0.0352, 'grad_norm': 10.865144729614258, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.033882737159729004, 'loss_2': 0.0013093948364257812, 'loss_3': -16.640676498413086, 'loss_4': 0.00987192988395691, 'epoch': 9.31}
{'loss': 0.0099, 'grad_norm': 5.02433443069458, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.008724450133740902, 'loss_2': 0.0011320114135742188, 'loss_3': -16.32159423828125, 'loss_4': 0.4098629951477051, 'epoch': 9.32}
{'loss': 0.0157, 'grad_norm': 6.753897666931152, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.011411705985665321, 'loss_2': 0.004322052001953125, 'loss_3': -16.515018463134766, 'loss_4': 0.6115185618400574, 'epoch': 9.33}
{'loss': 0.0223, 'grad_norm': 5.997392654418945, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.013748478144407272, 'loss_2': 0.008514404296875, 'loss_3': -16.112205505371094, 'loss_4': 0.19665151834487915, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 13:00:09,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:09,902 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:04<1:01:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:17,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022783514112234116, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011185167357325554, 'eval_loss_2': 0.011598348617553711, 'eval_loss_3': -18.273942947387695, 'eval_loss_4': 0.09336528182029724, 'epoch': 9.33}
{'loss': 0.0272, 'grad_norm': 5.005910396575928, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.011423771269619465, 'loss_2': 0.0157470703125, 'loss_3': -16.33220863342285, 'loss_4': 0.19434908032417297, 'epoch': 9.34}
{'loss': 0.0273, 'grad_norm': 6.825188636779785, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.016878997907042503, 'loss_2': 0.010467529296875, 'loss_3': -16.25949478149414, 'loss_4': 0.255229115486145, 'epoch': 9.34}
{'loss': 0.0212, 'grad_norm': 5.72959041595459, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.013442433439195156, 'loss_2': 0.00778961181640625, 'loss_3': -16.41377830505371, 'loss_4': 0.1103207916021347, 'epoch': 9.35}
{'loss': 0.0317, 'grad_norm': 8.428950309753418, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.020582381635904312, 'loss_2': 0.01114654541015625, 'loss_3': -16.302509307861328, 'loss_4': -0.010772999376058578, 'epoch': 9.35}
{'loss': 0.0084, 'grad_norm': 5.642093181610107, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.007673837244510651, 'loss_2': 0.0007009506225585938, 'loss_3': -16.355281829833984, 'loss_4': 0.4024301767349243, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 13:00:17,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:17,255 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:11<1:01:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:24,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018114496022462845, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.148, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010559847578406334, 'eval_loss_2': 0.00755465030670166, 'eval_loss_3': -18.21988296508789, 'eval_loss_4': 0.11859400570392609, 'epoch': 9.36}
{'loss': 0.0221, 'grad_norm': 7.6775407791137695, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.012463769875466824, 'loss_2': 0.00965118408203125, 'loss_3': -16.317279815673828, 'loss_4': -0.10169073194265366, 'epoch': 9.37}
{'loss': 0.0212, 'grad_norm': 10.047134399414062, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.01604154147207737, 'loss_2': 0.0052032470703125, 'loss_3': -16.32460594177246, 'loss_4': -0.0960734561085701, 'epoch': 9.37}
{'loss': 0.0253, 'grad_norm': 7.80532693862915, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.02241453155875206, 'loss_2': 0.002910614013671875, 'loss_3': -16.279891967773438, 'loss_4': -0.0548832044005394, 'epoch': 9.38}
{'loss': 0.016, 'grad_norm': 8.180785179138184, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.014975707978010178, 'loss_2': 0.0010089874267578125, 'loss_3': -16.280567169189453, 'loss_4': 0.442596971988678, 'epoch': 9.38}
{'loss': 0.0391, 'grad_norm': 16.566099166870117, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.028841136023402214, 'loss_2': 0.010284423828125, 'loss_3': -16.216312408447266, 'loss_4': 0.04736985266208649, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 13:00:24,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:24,606 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:19<1:01:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:31,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017918046563863754, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011334593407809734, 'eval_loss_2': 0.006583452224731445, 'eval_loss_3': -18.21114730834961, 'eval_loss_4': 0.0030356310307979584, 'epoch': 9.39}
{'loss': 0.0181, 'grad_norm': 6.095353126525879, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.01004123780876398, 'loss_2': 0.008056640625, 'loss_3': -16.363086700439453, 'loss_4': 0.6412877440452576, 'epoch': 9.4}
{'loss': 0.0349, 'grad_norm': 8.477431297302246, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.02679615095257759, 'loss_2': 0.00811767578125, 'loss_3': -16.249889373779297, 'loss_4': 0.14097850024700165, 'epoch': 9.4}
{'loss': 0.0303, 'grad_norm': 7.394955158233643, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.021457400172948837, 'loss_2': 0.0088653564453125, 'loss_3': -16.152965545654297, 'loss_4': 0.09003136307001114, 'epoch': 9.41}
{'loss': 0.0274, 'grad_norm': 8.165614128112793, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.018371878191828728, 'loss_2': 0.009063720703125, 'loss_3': -16.37754249572754, 'loss_4': -0.34302347898483276, 'epoch': 9.41}
{'loss': 0.0186, 'grad_norm': 6.620741367340088, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.011517957784235477, 'loss_2': 0.007076263427734375, 'loss_3': -16.21475601196289, 'loss_4': 0.11512789875268936, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 13:00:31,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:31,954 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:26<1:01:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:39,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020672351121902466, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011890381574630737, 'eval_loss_2': 0.008781969547271729, 'eval_loss_3': -18.197477340698242, 'eval_loss_4': -0.02747083082795143, 'epoch': 9.42}
{'loss': 0.0133, 'grad_norm': 5.893025875091553, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.011778555810451508, 'loss_2': 0.0014820098876953125, 'loss_3': -16.410593032836914, 'loss_4': -0.39375078678131104, 'epoch': 9.42}
{'loss': 0.0139, 'grad_norm': 5.315088748931885, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.006773156113922596, 'loss_2': 0.007129669189453125, 'loss_3': -16.23291015625, 'loss_4': 0.09282852709293365, 'epoch': 9.43}
{'loss': 0.0225, 'grad_norm': 11.133106231689453, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.016489746049046516, 'loss_2': 0.006008148193359375, 'loss_3': -16.354049682617188, 'loss_4': 0.09134295582771301, 'epoch': 9.44}
{'loss': 0.0196, 'grad_norm': 4.884191989898682, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.0064949579536914825, 'loss_2': 0.01308441162109375, 'loss_3': -16.40471839904785, 'loss_4': 0.6294780373573303, 'epoch': 9.44}
{'loss': 0.0238, 'grad_norm': 15.41043758392334, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.022845152765512466, 'loss_2': 0.00098419189453125, 'loss_3': -16.23174285888672, 'loss_4': 0.2135353982448578, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 13:00:39,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:39,305 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:33<1:01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:46,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01679321937263012, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013604097999632359, 'eval_loss_2': 0.003189120441675186, 'eval_loss_3': -18.1832275390625, 'eval_loss_4': 0.11856415122747421, 'epoch': 9.45}
{'loss': 0.0203, 'grad_norm': 9.5145902633667, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.017136381939053535, 'loss_2': 0.003143310546875, 'loss_3': -16.309906005859375, 'loss_4': 0.2723141312599182, 'epoch': 9.45}
{'loss': 0.0201, 'grad_norm': 8.428228378295898, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.0184676181524992, 'loss_2': 0.0016078948974609375, 'loss_3': -16.10265350341797, 'loss_4': 0.5893738269805908, 'epoch': 9.46}
{'loss': 0.0348, 'grad_norm': 27.948902130126953, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.03300626948475838, 'loss_2': 0.0018157958984375, 'loss_3': -16.250957489013672, 'loss_4': 0.03788939118385315, 'epoch': 9.47}
{'loss': 0.0127, 'grad_norm': 5.239450454711914, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.008223294280469418, 'loss_2': 0.00445556640625, 'loss_3': -16.28376007080078, 'loss_4': 0.37606364488601685, 'epoch': 9.47}
{'loss': 0.0187, 'grad_norm': 7.0890631675720215, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.018069934099912643, 'loss_2': 0.00058746337890625, 'loss_3': -16.402477264404297, 'loss_4': 0.2247770130634308, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 13:00:46,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:46,650 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:41<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:53,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018789811059832573, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015637677162885666, 'eval_loss_2': 0.003152132034301758, 'eval_loss_3': -18.136240005493164, 'eval_loss_4': 0.3598671555519104, 'epoch': 9.48}
{'loss': 0.02, 'grad_norm': 8.461198806762695, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.018539633601903915, 'loss_2': 0.00150299072265625, 'loss_3': -16.188159942626953, 'loss_4': 0.46654537320137024, 'epoch': 9.48}
{'loss': 0.0158, 'grad_norm': 5.873595237731934, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.01275189034640789, 'loss_2': 0.003078460693359375, 'loss_3': -16.218936920166016, 'loss_4': 0.06286990642547607, 'epoch': 9.49}
{'loss': 0.009, 'grad_norm': 4.534831523895264, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.006460780743509531, 'loss_2': 0.00250244140625, 'loss_3': -16.244586944580078, 'loss_4': 0.6416700482368469, 'epoch': 9.49}
{'loss': 0.0198, 'grad_norm': 7.100752353668213, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.01474759355187416, 'loss_2': 0.005016326904296875, 'loss_3': -16.025814056396484, 'loss_4': 0.6135935187339783, 'epoch': 9.5}
{'loss': 0.0091, 'grad_norm': 5.197704792022705, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.006157759111374617, 'loss_2': 0.0029048919677734375, 'loss_3': -16.178436279296875, 'loss_4': 0.392875611782074, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 13:00:53,999 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:54,000 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:48<1:00:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:01,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023480962961912155, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.775, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017245007678866386, 'eval_loss_2': 0.006235957145690918, 'eval_loss_3': -18.112545013427734, 'eval_loss_4': 0.5063063502311707, 'epoch': 9.51}
{'loss': 0.0243, 'grad_norm': 6.233308792114258, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.01604107767343521, 'loss_2': 0.0082244873046875, 'loss_3': -16.24331283569336, 'loss_4': 0.5933369994163513, 'epoch': 9.51}
{'loss': 0.0221, 'grad_norm': 8.215095520019531, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.011833512224256992, 'loss_2': 0.01026153564453125, 'loss_3': -16.388599395751953, 'loss_4': 1.0397045612335205, 'epoch': 9.52}
{'loss': 0.0181, 'grad_norm': 5.6774067878723145, 'learning_rate': 2.05e-05, 'loss_1': 0.009680960327386856, 'loss_2': 0.008453369140625, 'loss_3': -16.30947494506836, 'loss_4': 0.6617529392242432, 'epoch': 9.52}
{'loss': 0.0153, 'grad_norm': 6.603279113769531, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.010309831239283085, 'loss_2': 0.00494384765625, 'loss_3': -16.05524444580078, 'loss_4': 0.913192868232727, 'epoch': 9.53}
{'loss': 0.012, 'grad_norm': 5.571083068847656, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.007327152881771326, 'loss_2': 0.0047149658203125, 'loss_3': -16.139163970947266, 'loss_4': 0.22127559781074524, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 13:01:01,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:01,335 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [40:55<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:08,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02282116189599037, 'eval_runtime': 3.8416, 'eval_samples_per_second': 266.553, 'eval_steps_per_second': 4.165, 'eval_loss_1': 0.017318198457360268, 'eval_loss_2': 0.005502961575984955, 'eval_loss_3': -18.116275787353516, 'eval_loss_4': 0.38371145725250244, 'epoch': 9.53}
{'loss': 0.0085, 'grad_norm': 5.47760009765625, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.008178765885531902, 'loss_2': 0.0003414154052734375, 'loss_3': -16.197784423828125, 'loss_4': 0.6253355145454407, 'epoch': 9.54}
{'loss': 0.0926, 'grad_norm': 26.33519744873047, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.08916940540075302, 'loss_2': 0.0034027099609375, 'loss_3': -16.29043960571289, 'loss_4': 0.11394995450973511, 'epoch': 9.55}
{'loss': 0.0252, 'grad_norm': 11.13221549987793, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.023481745272874832, 'loss_2': 0.001750946044921875, 'loss_3': -16.033710479736328, 'loss_4': 0.5154869556427002, 'epoch': 9.55}
{'loss': 0.0193, 'grad_norm': 9.646333694458008, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.017911404371261597, 'loss_2': 0.0014066696166992188, 'loss_3': -16.31230926513672, 'loss_4': -0.05318457633256912, 'epoch': 9.56}
{'loss': 0.0137, 'grad_norm': 4.505316734313965, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.008075477555394173, 'loss_2': 0.0056304931640625, 'loss_3': -16.27404022216797, 'loss_4': 0.07253812253475189, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 13:01:08,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:08,723 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:03<1:00:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:16,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02151395007967949, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016418887302279472, 'eval_loss_2': 0.005095064640045166, 'eval_loss_3': -18.12104606628418, 'eval_loss_4': 0.32927706837654114, 'epoch': 9.56}
{'loss': 0.0171, 'grad_norm': 7.314415454864502, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.014783194288611412, 'loss_2': 0.0023517608642578125, 'loss_3': -16.32304573059082, 'loss_4': 0.048930004239082336, 'epoch': 9.57}
{'loss': 0.0138, 'grad_norm': 5.059386730194092, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.008192334324121475, 'loss_2': 0.00562286376953125, 'loss_3': -16.240440368652344, 'loss_4': 0.1516450196504593, 'epoch': 9.58}
{'loss': 0.0198, 'grad_norm': 6.686797142028809, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.019793257117271423, 'loss_2': 2.1576881408691406e-05, 'loss_3': -16.269256591796875, 'loss_4': 0.3470805287361145, 'epoch': 9.58}
{'loss': 0.0222, 'grad_norm': 12.129526138305664, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.018939465284347534, 'loss_2': 0.0032711029052734375, 'loss_3': -16.2390079498291, 'loss_4': 0.41084542870521545, 'epoch': 9.59}
{'loss': 0.0173, 'grad_norm': 10.476318359375, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.015404528006911278, 'loss_2': 0.001941680908203125, 'loss_3': -16.499582290649414, 'loss_4': 0.13117723166942596, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 13:01:16,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:16,065 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:10<1:00:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:23,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0177474282681942, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013736257329583168, 'eval_loss_2': 0.004011169075965881, 'eval_loss_3': -18.152416229248047, 'eval_loss_4': 0.27882689237594604, 'epoch': 9.59}
{'loss': 0.0126, 'grad_norm': 5.667305946350098, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.008462611585855484, 'loss_2': 0.004169464111328125, 'loss_3': -16.210115432739258, 'loss_4': 0.5243440866470337, 'epoch': 9.6}
{'loss': 0.0189, 'grad_norm': 6.908531188964844, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.01191488467156887, 'loss_2': 0.0070037841796875, 'loss_3': -16.2625675201416, 'loss_4': 0.5202227830886841, 'epoch': 9.6}
{'loss': 0.0193, 'grad_norm': 6.957294940948486, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.018778039142489433, 'loss_2': 0.000553131103515625, 'loss_3': -16.38770866394043, 'loss_4': 0.3725878596305847, 'epoch': 9.61}
{'loss': 0.0117, 'grad_norm': 6.737051010131836, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.009808308444917202, 'loss_2': 0.001850128173828125, 'loss_3': -16.295528411865234, 'loss_4': 0.42504048347473145, 'epoch': 9.62}
{'loss': 0.0145, 'grad_norm': 6.630447864532471, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.012340540997684002, 'loss_2': 0.0021190643310546875, 'loss_3': -16.40960121154785, 'loss_4': 0.6518162488937378, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 13:01:23,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:23,409 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:17<1:00:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:30,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016893204301595688, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011992299929261208, 'eval_loss_2': 0.004900902509689331, 'eval_loss_3': -18.20114517211914, 'eval_loss_4': 0.3856296241283417, 'epoch': 9.62}
{'loss': 0.0141, 'grad_norm': 5.6301493644714355, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.009544529020786285, 'loss_2': 0.00452423095703125, 'loss_3': -16.414627075195312, 'loss_4': 0.4794539213180542, 'epoch': 9.63}
{'loss': 0.0115, 'grad_norm': 5.907843589782715, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.008890623226761818, 'loss_2': 0.0026569366455078125, 'loss_3': -16.33100128173828, 'loss_4': 0.3495066165924072, 'epoch': 9.63}
{'loss': 0.0417, 'grad_norm': 10.6553316116333, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.041244421154260635, 'loss_2': 0.0004646778106689453, 'loss_3': -16.218753814697266, 'loss_4': 0.3878569006919861, 'epoch': 9.64}
{'loss': 0.0276, 'grad_norm': 13.217036247253418, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.021737949922680855, 'loss_2': 0.0058746337890625, 'loss_3': -16.25575065612793, 'loss_4': 0.35829970240592957, 'epoch': 9.65}
{'loss': 0.0206, 'grad_norm': 5.987910270690918, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.012000384740531445, 'loss_2': 0.0085601806640625, 'loss_3': -16.35881805419922, 'loss_4': 0.6701390743255615, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 13:01:30,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:30,749 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:25<1:00:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:38,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014685705304145813, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011529073119163513, 'eval_loss_2': 0.0031566321849823, 'eval_loss_3': -18.204580307006836, 'eval_loss_4': 0.36438414454460144, 'epoch': 9.65}
{'loss': 0.0134, 'grad_norm': 5.55917501449585, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.013254253193736076, 'loss_2': 0.0001653432846069336, 'loss_3': -16.15899085998535, 'loss_4': 0.15548951923847198, 'epoch': 9.66}
{'loss': 0.0126, 'grad_norm': 5.93057918548584, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.010918556712567806, 'loss_2': 0.00165557861328125, 'loss_3': -16.21388053894043, 'loss_4': 1.1232377290725708, 'epoch': 9.66}
{'loss': 0.0283, 'grad_norm': 9.636180877685547, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.025195907801389694, 'loss_2': 0.003139495849609375, 'loss_3': -16.09108543395996, 'loss_4': 0.6163001656532288, 'epoch': 9.67}
{'loss': 0.022, 'grad_norm': 9.369828224182129, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.018659086897969246, 'loss_2': 0.0032939910888671875, 'loss_3': -16.208494186401367, 'loss_4': 0.8545626401901245, 'epoch': 9.67}
{'loss': 0.0405, 'grad_norm': 10.563787460327148, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.0361751914024353, 'loss_2': 0.004302978515625, 'loss_3': -16.19293212890625, 'loss_4': 0.7100165486335754, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 13:01:38,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:38,101 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:32<1:00:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:45,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01637839525938034, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.169, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012096639722585678, 'eval_loss_2': 0.004281759262084961, 'eval_loss_3': -18.176982879638672, 'eval_loss_4': 0.48498401045799255, 'epoch': 9.68}
{'loss': 0.0168, 'grad_norm': 5.626877784729004, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.013025985099375248, 'loss_2': 0.003742218017578125, 'loss_3': -16.28569984436035, 'loss_4': 0.4241219162940979, 'epoch': 9.69}
{'loss': 0.0312, 'grad_norm': 25.695598602294922, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.0310312919318676, 'loss_2': 0.00013828277587890625, 'loss_3': -16.318641662597656, 'loss_4': 1.033337950706482, 'epoch': 9.69}
{'loss': 0.0102, 'grad_norm': 10.092994689941406, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.0066102962009608746, 'loss_2': 0.00359344482421875, 'loss_3': -16.28182601928711, 'loss_4': 0.8271913528442383, 'epoch': 9.7}
{'loss': 0.0246, 'grad_norm': 9.120365142822266, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.02357896976172924, 'loss_2': 0.000988006591796875, 'loss_3': -16.182819366455078, 'loss_4': 0.34164130687713623, 'epoch': 9.7}
{'loss': 0.0136, 'grad_norm': 8.429640769958496, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.01353280246257782, 'loss_2': 7.534027099609375e-05, 'loss_3': -16.255821228027344, 'loss_4': 0.675309419631958, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 13:01:45,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:45,449 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:40<1:01:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:01:52,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017330298200249672, 'eval_runtime': 3.9916, 'eval_samples_per_second': 256.537, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.011245411820709705, 'eval_loss_2': 0.00608488917350769, 'eval_loss_3': -18.157888412475586, 'eval_loss_4': 0.6611286997795105, 'epoch': 9.71}
{'loss': 0.0216, 'grad_norm': 6.439881801605225, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.012153374962508678, 'loss_2': 0.00946044921875, 'loss_3': -16.48299789428711, 'loss_4': 0.7634124755859375, 'epoch': 9.72}
{'loss': 0.0209, 'grad_norm': 7.599905967712402, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.019505560398101807, 'loss_2': 0.0014028549194335938, 'loss_3': -16.368927001953125, 'loss_4': 1.0134923458099365, 'epoch': 9.72}
{'loss': 0.0125, 'grad_norm': 5.6496052742004395, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.01088112872093916, 'loss_2': 0.0015926361083984375, 'loss_3': -15.976593017578125, 'loss_4': 0.7379729747772217, 'epoch': 9.73}
{'loss': 0.0062, 'grad_norm': 4.535633563995361, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.005432917736470699, 'loss_2': 0.0007352828979492188, 'loss_3': -16.304533004760742, 'loss_4': 1.2718995809555054, 'epoch': 9.73}
{'loss': 0.0101, 'grad_norm': 6.3039021492004395, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.009617031551897526, 'loss_2': 0.0005016326904296875, 'loss_3': -16.444507598876953, 'loss_4': 0.8088633418083191, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 13:01:52,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:52,981 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:47<1:00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:00,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018672052770853043, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.401, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014092089608311653, 'eval_loss_2': 0.00457996129989624, 'eval_loss_3': -18.136062622070312, 'eval_loss_4': 0.8271531462669373, 'epoch': 9.74}
{'loss': 0.0171, 'grad_norm': 6.625446796417236, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.012615606188774109, 'loss_2': 0.0045318603515625, 'loss_3': -16.24565315246582, 'loss_4': 1.1849920749664307, 'epoch': 9.74}
{'loss': 0.0129, 'grad_norm': 5.356293201446533, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.012183655053377151, 'loss_2': 0.0007228851318359375, 'loss_3': -16.123708724975586, 'loss_4': 0.7133580446243286, 'epoch': 9.75}
{'loss': 0.0327, 'grad_norm': 11.459723472595215, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.03003588877618313, 'loss_2': 0.0026531219482421875, 'loss_3': -16.233543395996094, 'loss_4': 0.9022008180618286, 'epoch': 9.76}
{'loss': 0.0178, 'grad_norm': 5.689080715179443, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.010439060628414154, 'loss_2': 0.00738525390625, 'loss_3': -16.154233932495117, 'loss_4': 1.6025495529174805, 'epoch': 9.76}
{'loss': 0.028, 'grad_norm': 17.05236053466797, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.026404542848467827, 'loss_2': 0.0015621185302734375, 'loss_3': -16.23500633239746, 'loss_4': 1.1473031044006348, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 13:02:00,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:00,327 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:54<1:00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:07,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020233653485774994, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015177002176642418, 'eval_loss_2': 0.005056649446487427, 'eval_loss_3': -18.135990142822266, 'eval_loss_4': 0.9883108139038086, 'epoch': 9.77}
{'loss': 0.0292, 'grad_norm': 9.365532875061035, 'learning_rate': 2.025e-05, 'loss_1': 0.023046940565109253, 'loss_2': 0.00615692138671875, 'loss_3': -16.30320167541504, 'loss_4': 0.8277087211608887, 'epoch': 9.77}
{'loss': 0.0392, 'grad_norm': 11.258414268493652, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.03319457173347473, 'loss_2': 0.00595855712890625, 'loss_3': -16.408567428588867, 'loss_4': 1.2822716236114502, 'epoch': 9.78}
{'loss': 0.0328, 'grad_norm': 7.919726848602295, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.020829858258366585, 'loss_2': 0.01197052001953125, 'loss_3': -16.1369686126709, 'loss_4': 1.2961139678955078, 'epoch': 9.78}
{'loss': 0.0348, 'grad_norm': 12.734272003173828, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.0311372559517622, 'loss_2': 0.0036411285400390625, 'loss_3': -16.081588745117188, 'loss_4': 1.0083842277526855, 'epoch': 9.79}
{'loss': 0.0114, 'grad_norm': 5.053121089935303, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.010098528116941452, 'loss_2': 0.0012950897216796875, 'loss_3': -16.27632713317871, 'loss_4': 1.2110360860824585, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 13:02:07,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:07,681 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [42:02<1:00:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:15,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018409840762615204, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.359, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014210155233740807, 'eval_loss_2': 0.004199683666229248, 'eval_loss_3': -18.160266876220703, 'eval_loss_4': 0.9876499772071838, 'epoch': 9.8}
{'loss': 0.0255, 'grad_norm': 9.381291389465332, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.015629896894097328, 'loss_2': 0.0099029541015625, 'loss_3': -16.292112350463867, 'loss_4': 0.7192488312721252, 'epoch': 9.8}
{'loss': 0.0337, 'grad_norm': 10.664872169494629, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.030132610350847244, 'loss_2': 0.0035648345947265625, 'loss_3': -16.290626525878906, 'loss_4': 1.175879716873169, 'epoch': 9.81}
{'loss': 0.0337, 'grad_norm': 10.863242149353027, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.026473455131053925, 'loss_2': 0.007213592529296875, 'loss_3': -16.49806785583496, 'loss_4': 1.2059624195098877, 'epoch': 9.81}
{'loss': 0.045, 'grad_norm': 11.368867874145508, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.04082389920949936, 'loss_2': 0.004150390625, 'loss_3': -16.34505271911621, 'loss_4': 1.177793264389038, 'epoch': 9.82}
{'loss': 0.0179, 'grad_norm': 6.269794940948486, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.015363238751888275, 'loss_2': 0.0025787353515625, 'loss_3': -16.33562469482422, 'loss_4': 1.2809364795684814, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 13:02:15,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:15,028 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1695/5160 [42:09<1:00:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:22,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01637543924152851, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.171, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.012758135795593262, 'eval_loss_2': 0.0036173015832901, 'eval_loss_3': -18.16261100769043, 'eval_loss_4': 0.876814067363739, 'epoch': 9.83}
{'loss': 0.0257, 'grad_norm': 6.581726551055908, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.018947087228298187, 'loss_2': 0.00672149658203125, 'loss_3': -16.021263122558594, 'loss_4': 0.8957886695861816, 'epoch': 9.83}
{'loss': 0.0357, 'grad_norm': 15.317583084106445, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.026127953082323074, 'loss_2': 0.0095672607421875, 'loss_3': -16.283626556396484, 'loss_4': 0.7196627259254456, 'epoch': 9.84}
{'loss': 0.0565, 'grad_norm': 17.19035530090332, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.05271444469690323, 'loss_2': 0.003803253173828125, 'loss_3': -15.971549987792969, 'loss_4': 1.0074710845947266, 'epoch': 9.84}
{'loss': 0.0231, 'grad_norm': 7.749807834625244, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.022216295823454857, 'loss_2': 0.0009174346923828125, 'loss_3': -16.215456008911133, 'loss_4': 0.8138343095779419, 'epoch': 9.85}
{'loss': 0.0244, 'grad_norm': 6.942221164703369, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.020882312208414078, 'loss_2': 0.0035400390625, 'loss_3': -16.506118774414062, 'loss_4': 0.7912859916687012, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 13:02:22,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:22,395 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:16<59:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:29,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016704067587852478, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013020084239542484, 'eval_loss_2': 0.0036839842796325684, 'eval_loss_3': -18.13218116760254, 'eval_loss_4': 0.7044732570648193, 'epoch': 9.85}
{'loss': 0.0096, 'grad_norm': 4.971720218658447, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.00955442525446415, 'loss_2': 6.616115570068359e-06, 'loss_3': -16.485458374023438, 'loss_4': 0.9592458009719849, 'epoch': 9.86}
{'loss': 0.0201, 'grad_norm': 7.467208385467529, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.01947590336203575, 'loss_2': 0.0006628036499023438, 'loss_3': -16.327266693115234, 'loss_4': 0.9085203409194946, 'epoch': 9.87}
{'loss': 0.0136, 'grad_norm': 5.859617233276367, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.010452794842422009, 'loss_2': 0.003116607666015625, 'loss_3': -16.578338623046875, 'loss_4': 1.0151318311691284, 'epoch': 9.87}
{'loss': 0.014, 'grad_norm': 6.4553656578063965, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.011430765502154827, 'loss_2': 0.002521514892578125, 'loss_3': -16.097736358642578, 'loss_4': 1.0759069919586182, 'epoch': 9.88}
{'loss': 0.0234, 'grad_norm': 7.653083801269531, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.017952725291252136, 'loss_2': 0.00548553466796875, 'loss_3': -16.14849853515625, 'loss_4': 0.9963493943214417, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 13:02:29,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:29,753 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:24<59:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:37,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015419745817780495, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.88, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011611154302954674, 'eval_loss_2': 0.003808591514825821, 'eval_loss_3': -18.094459533691406, 'eval_loss_4': 0.7268509268760681, 'epoch': 9.88}
{'loss': 0.0209, 'grad_norm': 8.20067024230957, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.012990417890250683, 'loss_2': 0.0079345703125, 'loss_3': -16.166820526123047, 'loss_4': 1.1348299980163574, 'epoch': 9.89}
{'loss': 0.0231, 'grad_norm': 6.155575275421143, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.016173318028450012, 'loss_2': 0.006900787353515625, 'loss_3': -16.258089065551758, 'loss_4': 1.2480436563491821, 'epoch': 9.9}
{'loss': 0.0235, 'grad_norm': 7.4758405685424805, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.016879133880138397, 'loss_2': 0.006622314453125, 'loss_3': -16.244548797607422, 'loss_4': 0.9471423625946045, 'epoch': 9.9}
{'loss': 0.0311, 'grad_norm': 9.560151100158691, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.025409674271941185, 'loss_2': 0.005645751953125, 'loss_3': -16.06676483154297, 'loss_4': 1.3215910196304321, 'epoch': 9.91}
{'loss': 0.0266, 'grad_norm': 14.364140510559082, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.025403153151273727, 'loss_2': 0.0011539459228515625, 'loss_3': -16.359386444091797, 'loss_4': 1.1261351108551025, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 13:02:37,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:37,102 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:31<59:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:44,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016231847926974297, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.215, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01272202841937542, 'eval_loss_2': 0.003509819507598877, 'eval_loss_3': -18.09805679321289, 'eval_loss_4': 0.9155433177947998, 'epoch': 9.91}
{'loss': 0.0264, 'grad_norm': 7.683060646057129, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.020919224247336388, 'loss_2': 0.00543212890625, 'loss_3': -16.430734634399414, 'loss_4': 1.3365001678466797, 'epoch': 9.92}
{'loss': 0.0222, 'grad_norm': 6.603976726531982, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.01838376559317112, 'loss_2': 0.003772735595703125, 'loss_3': -16.35245704650879, 'loss_4': 1.2362918853759766, 'epoch': 9.92}
{'loss': 0.0271, 'grad_norm': 6.666772365570068, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.024326836690306664, 'loss_2': 0.0027313232421875, 'loss_3': -16.323944091796875, 'loss_4': 1.2551136016845703, 'epoch': 9.93}
{'loss': 0.0998, 'grad_norm': 12.851242065429688, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.08639182895421982, 'loss_2': 0.01335906982421875, 'loss_3': -16.433053970336914, 'loss_4': 1.753272533416748, 'epoch': 9.94}
{'loss': 0.0267, 'grad_norm': 7.032620429992676, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.02452589012682438, 'loss_2': 0.0021991729736328125, 'loss_3': -16.19598388671875, 'loss_4': 1.295386791229248, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 13:02:44,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:44,448 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:38<59:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:51,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01431252621114254, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010256968438625336, 'eval_loss_2': 0.0040555596351623535, 'eval_loss_3': -18.157907485961914, 'eval_loss_4': 1.1590490341186523, 'epoch': 9.94}
{'loss': 0.0179, 'grad_norm': 5.908943176269531, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.013317734934389591, 'loss_2': 0.004608154296875, 'loss_3': -16.442832946777344, 'loss_4': 1.9156553745269775, 'epoch': 9.95}
{'loss': 0.0444, 'grad_norm': 14.770086288452148, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.03938785567879677, 'loss_2': 0.00498199462890625, 'loss_3': -16.211965560913086, 'loss_4': 1.7565538883209229, 'epoch': 9.95}
{'loss': 0.0198, 'grad_norm': 8.869391441345215, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.018795108422636986, 'loss_2': 0.0009737014770507812, 'loss_3': -16.15416717529297, 'loss_4': 1.3810720443725586, 'epoch': 9.96}
{'loss': 0.0238, 'grad_norm': 8.770079612731934, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.02260253205895424, 'loss_2': 0.001224517822265625, 'loss_3': -16.206621170043945, 'loss_4': 1.4429025650024414, 'epoch': 9.97}
{'loss': 0.0135, 'grad_norm': 5.424113750457764, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.010854431428015232, 'loss_2': 0.002655029296875, 'loss_3': -16.3215274810791, 'loss_4': 1.2979731559753418, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 13:02:51,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:51,801 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:45<53:32,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:02:58,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013638924807310104, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.237, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009710561484098434, 'eval_loss_2': 0.00392836332321167, 'eval_loss_3': -18.14840316772461, 'eval_loss_4': 1.2244371175765991, 'epoch': 9.97}
{'loss': 0.0289, 'grad_norm': 9.980854034423828, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.02235698699951172, 'loss_2': 0.006591796875, 'loss_3': -16.488069534301758, 'loss_4': 1.3084688186645508, 'epoch': 9.98}
{'loss': 0.0133, 'grad_norm': 5.454388618469238, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.009335123002529144, 'loss_2': 0.00392913818359375, 'loss_3': -16.35772132873535, 'loss_4': 1.2627885341644287, 'epoch': 9.98}
{'loss': 0.0186, 'grad_norm': 5.691796779632568, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.012095239944756031, 'loss_2': 0.006481170654296875, 'loss_3': -16.452354431152344, 'loss_4': 1.3083316087722778, 'epoch': 9.99}
{'loss': 0.0213, 'grad_norm': 6.991665840148926, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.013352274894714355, 'loss_2': 0.00798797607421875, 'loss_3': -16.277416229248047, 'loss_4': 1.457747459411621, 'epoch': 9.99}
{'loss': 0.0125, 'grad_norm': 6.251400947570801, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.004051251336932182, 'loss_2': 0.0084075927734375, 'loss_3': -16.478837966918945, 'loss_4': 0.5637110471725464, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 13:02:58,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:58,799 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:53<58:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:03:06,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015043197199702263, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.446, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009743674658238888, 'eval_loss_2': 0.00529952347278595, 'eval_loss_3': -18.15316390991211, 'eval_loss_4': 1.1292989253997803, 'epoch': 10.0}
{'loss': 0.0284, 'grad_norm': 8.247393608093262, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.020552365109324455, 'loss_2': 0.0078582763671875, 'loss_3': -16.200984954833984, 'loss_4': 1.5953311920166016, 'epoch': 10.01}
{'loss': 0.0114, 'grad_norm': 5.722628116607666, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.008212323300540447, 'loss_2': 0.003147125244140625, 'loss_3': -16.291730880737305, 'loss_4': 1.0909967422485352, 'epoch': 10.01}
{'loss': 0.0248, 'grad_norm': 7.708141803741455, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.019984783604741096, 'loss_2': 0.0048370361328125, 'loss_3': -16.403705596923828, 'loss_4': 1.8438130617141724, 'epoch': 10.02}
{'loss': 0.012, 'grad_norm': 5.254874229431152, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.011481394059956074, 'loss_2': 0.0004723072052001953, 'loss_3': -16.188919067382812, 'loss_4': 0.955474317073822, 'epoch': 10.02}
{'loss': 0.0235, 'grad_norm': 6.74258279800415, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.01575433649122715, 'loss_2': 0.00771331787109375, 'loss_3': -16.26709747314453, 'loss_4': 0.8095256686210632, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 13:03:06,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:06,206 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:57<58:42,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 13:03:10,013 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725
[INFO|configuration_utils.py:420] 2025-01-21 13:03:10,014 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725/config.json                                                                            
{'eval_loss': 0.012898428365588188, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009604943916201591, 'eval_loss_2': 0.0032934844493865967, 'eval_loss_3': -18.155221939086914, 'eval_loss_4': 0.9536924958229065, 'epoch': 10.03}
[INFO|modeling_utils.py:2988] 2025-01-21 13:03:10,493 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:03:10,495 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:03:10,495 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:03:11,438 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1380] due to args.save_total_limit
 34%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1730/5160 [43:02<1:05:22,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 13:03:15,063 >>
{'loss': 0.0286, 'grad_norm': 9.78767204284668, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.02374156564474106, 'loss_2': 0.004863739013671875, 'loss_3': -16.314289093017578, 'loss_4': 1.0064830780029297, 'epoch': 10.03}
{'loss': 0.0186, 'grad_norm': 6.688990116119385, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.017931994050741196, 'loss_2': 0.0006871223449707031, 'loss_3': -16.404705047607422, 'loss_4': 1.365125298500061, 'epoch': 10.04}
{'loss': 0.0115, 'grad_norm': 6.9290618896484375, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.010146625339984894, 'loss_2': 0.0013895034790039062, 'loss_3': -16.340938568115234, 'loss_4': 1.168637752532959, 'epoch': 10.05}
{'loss': 0.0155, 'grad_norm': 7.244060516357422, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.013519327156245708, 'loss_2': 0.0020084381103515625, 'loss_3': -16.28291893005371, 'loss_4': 1.2567698955535889, 'epoch': 10.05}
{'loss': 0.023, 'grad_norm': 6.586848258972168, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.016323857009410858, 'loss_2': 0.006649017333984375, 'loss_3': -16.384531021118164, 'loss_4': 1.4473141431808472, 'epoch': 10.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:03:15,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:15,063 >>   Batch size = 64
 34%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1730/5160 [43:05<1:05:22,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 13:03:18,855 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730
[INFO|configuration_utils.py:420] 2025-01-21 13:03:18,856 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730/config.json                                                                            
{'eval_loss': 0.011939795687794685, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.171, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008806840516626835, 'eval_loss_2': 0.003132954239845276, 'eval_loss_3': -18.103694915771484, 'eval_loss_4': 0.8211729526519775, 'epoch': 10.06}
[INFO|modeling_utils.py:2988] 2025-01-21 13:03:19,359 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:03:19,360 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:03:19,361 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:03:20,309 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1725] due to args.save_total_limit
 34%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                 | 1735/5160 [43:11<1:06:33,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 13:03:23,942 >>
{'loss': 0.0168, 'grad_norm': 5.966991424560547, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.011878535151481628, 'loss_2': 0.004970550537109375, 'loss_3': -16.24262237548828, 'loss_4': 0.6565371155738831, 'epoch': 10.06}
{'loss': 0.0194, 'grad_norm': 5.686712265014648, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.013255221769213676, 'loss_2': 0.006191253662109375, 'loss_3': -16.347627639770508, 'loss_4': 0.4857446849346161, 'epoch': 10.07}
{'loss': 0.015, 'grad_norm': 7.812412261962891, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.014563019387423992, 'loss_2': 0.0004630088806152344, 'loss_3': -16.179847717285156, 'loss_4': 1.0498669147491455, 'epoch': 10.08}
{'loss': 0.041, 'grad_norm': 19.03342628479004, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.03790557384490967, 'loss_2': 0.00307464599609375, 'loss_3': -16.201820373535156, 'loss_4': 1.3991057872772217, 'epoch': 10.08}
{'loss': 0.0088, 'grad_norm': 4.977810382843018, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.007975061424076557, 'loss_2': 0.0007867813110351562, 'loss_3': -16.310733795166016, 'loss_4': 0.610885739326477, 'epoch': 10.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:03:23,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:23,942 >>   Batch size = 64
 34%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                 | 1735/5160 [43:14<1:06:33,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 13:03:27,735 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735
[INFO|configuration_utils.py:420] 2025-01-21 13:03:27,736 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735/config.json                                                                            
{'eval_loss': 0.011552386917173862, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.115, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007498466409742832, 'eval_loss_2': 0.00405392050743103, 'eval_loss_3': -18.11209487915039, 'eval_loss_4': 0.7367432713508606, 'epoch': 10.09}
[INFO|modeling_utils.py:2988] 2025-01-21 13:03:28,216 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:03:28,217 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:03:28,217 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:03:29,188 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1730] due to args.save_total_limit
 34%|█████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1740/5160 [43:19<1:06:39,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 13:03:32,827 >>
{'loss': 0.0215, 'grad_norm': 8.81290340423584, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.01795281656086445, 'loss_2': 0.003505706787109375, 'loss_3': -16.211599349975586, 'loss_4': 1.091831922531128, 'epoch': 10.09}
{'loss': 0.025, 'grad_norm': 7.73664665222168, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.017329396679997444, 'loss_2': 0.00762176513671875, 'loss_3': -16.143823623657227, 'loss_4': 1.1608104705810547, 'epoch': 10.1}
{'loss': 0.0193, 'grad_norm': 8.577327728271484, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.015531875193119049, 'loss_2': 0.0038166046142578125, 'loss_3': -16.15890121459961, 'loss_4': 0.8597080707550049, 'epoch': 10.1}
{'loss': 0.0306, 'grad_norm': 7.129137992858887, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.021191393956542015, 'loss_2': 0.00936126708984375, 'loss_3': -16.377883911132812, 'loss_4': 0.7003880143165588, 'epoch': 10.11}
{'loss': 0.0445, 'grad_norm': 27.896717071533203, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.03853961080312729, 'loss_2': 0.00597381591796875, 'loss_3': -16.22641372680664, 'loss_4': 0.6819409132003784, 'epoch': 10.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:03:32,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:32,827 >>   Batch size = 64
 34%|█████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1740/5160 [43:23<1:06:39,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 13:03:36,630 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740
[INFO|configuration_utils.py:420] 2025-01-21 13:03:36,631 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740/config.json                                                                            
{'eval_loss': 0.011351455934345722, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008303411304950714, 'eval_loss_2': 0.0030480436980724335, 'eval_loss_3': -18.107500076293945, 'eval_loss_4': 0.4531157612800598, 'epoch': 10.12}
[INFO|modeling_utils.py:2988] 2025-01-21 13:03:37,135 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:03:37,136 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:03:37,137 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:03:38,103 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1735] due to args.save_total_limit
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1745/5160 [43:28<1:06:36,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 13:03:41,718 >>
{'loss': 0.0148, 'grad_norm': 6.540135860443115, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.010963290929794312, 'loss_2': 0.00386810302734375, 'loss_3': -16.372459411621094, 'loss_4': 1.0624327659606934, 'epoch': 10.12}
{'loss': 0.0258, 'grad_norm': 7.535656452178955, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.02549402229487896, 'loss_2': 0.0002741813659667969, 'loss_3': -16.204965591430664, 'loss_4': 0.7627670168876648, 'epoch': 10.13}
{'loss': 0.01, 'grad_norm': 4.855668544769287, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.007881703786551952, 'loss_2': 0.002140045166015625, 'loss_3': -16.327224731445312, 'loss_4': 0.8259565830230713, 'epoch': 10.13}
{'loss': 0.0143, 'grad_norm': 5.455284595489502, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.010716715827584267, 'loss_2': 0.00357818603515625, 'loss_3': -16.194631576538086, 'loss_4': 0.735429048538208, 'epoch': 10.14}
{'loss': 0.0176, 'grad_norm': 6.2639479637146, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.013535954989492893, 'loss_2': 0.00409698486328125, 'loss_3': -15.941513061523438, 'loss_4': -0.1782662570476532, 'epoch': 10.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:03:41,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:41,718 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                | 1750/5160 [43:36<1:00:08,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:03:49,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012208029627799988, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.969, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009832493960857391, 'eval_loss_2': 0.0023755356669425964, 'eval_loss_3': -18.12814712524414, 'eval_loss_4': 0.24523469805717468, 'epoch': 10.15}
{'loss': 0.021, 'grad_norm': 7.2656779289245605, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.018809575587511063, 'loss_2': 0.002216339111328125, 'loss_3': -16.36121940612793, 'loss_4': 0.2533811032772064, 'epoch': 10.15}
{'loss': 0.022, 'grad_norm': 8.958703994750977, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.019728513434529305, 'loss_2': 0.002227783203125, 'loss_3': -16.117359161376953, 'loss_4': 0.5833205580711365, 'epoch': 10.16}
{'loss': 0.0261, 'grad_norm': 10.054607391357422, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.022394081577658653, 'loss_2': 0.0036716461181640625, 'loss_3': -16.123634338378906, 'loss_4': 0.4436754882335663, 'epoch': 10.16}
{'loss': 0.0153, 'grad_norm': 4.978973388671875, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.011143113486468792, 'loss_2': 0.00417327880859375, 'loss_3': -16.177640914916992, 'loss_4': -0.09662330150604248, 'epoch': 10.17}
{'loss': 0.028, 'grad_norm': 9.931906700134277, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.027854282408952713, 'loss_2': 0.00015747547149658203, 'loss_3': -16.185710906982422, 'loss_4': 0.653772234916687, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 13:03:49,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:49,052 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:43<58:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:56,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014094549231231213, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01078829076141119, 'eval_loss_2': 0.0033062584698200226, 'eval_loss_3': -18.145200729370117, 'eval_loss_4': 0.48544248938560486, 'epoch': 10.17}
{'loss': 0.022, 'grad_norm': 9.114236831665039, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.020146753638982773, 'loss_2': 0.0018682479858398438, 'loss_3': -16.351686477661133, 'loss_4': 0.8911645412445068, 'epoch': 10.18}
{'loss': 0.0369, 'grad_norm': 13.755752563476562, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.028521422296762466, 'loss_2': 0.00838470458984375, 'loss_3': -16.003652572631836, 'loss_4': 1.2805581092834473, 'epoch': 10.19}
{'loss': 0.0259, 'grad_norm': 11.044516563415527, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.022342389449477196, 'loss_2': 0.00356292724609375, 'loss_3': -16.088321685791016, 'loss_4': 0.5805304050445557, 'epoch': 10.19}
{'loss': 0.0238, 'grad_norm': 6.885435581207275, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.016888149082660675, 'loss_2': 0.00687408447265625, 'loss_3': -16.28365707397461, 'loss_4': 0.9720247387886047, 'epoch': 10.2}
{'loss': 0.0159, 'grad_norm': 6.241171836853027, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.012420891784131527, 'loss_2': 0.00345611572265625, 'loss_3': -16.403156280517578, 'loss_4': 1.2719166278839111, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 13:03:56,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:56,376 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:50<58:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:04:03,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014361065812408924, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010810595005750656, 'eval_loss_2': 0.0035504698753356934, 'eval_loss_3': -18.12928581237793, 'eval_loss_4': 1.1072146892547607, 'epoch': 10.2}
{'loss': 0.0215, 'grad_norm': 8.234057426452637, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.020564140751957893, 'loss_2': 0.000888824462890625, 'loss_3': -16.036264419555664, 'loss_4': 1.6094911098480225, 'epoch': 10.21}
{'loss': 0.0128, 'grad_norm': 5.796475410461426, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.009408911690115929, 'loss_2': 0.0034027099609375, 'loss_3': -16.14034652709961, 'loss_4': 1.0541733503341675, 'epoch': 10.22}
{'loss': 0.0177, 'grad_norm': 6.179422378540039, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.013591000810265541, 'loss_2': 0.004119873046875, 'loss_3': -16.198009490966797, 'loss_4': 1.6964976787567139, 'epoch': 10.22}
{'loss': 0.0081, 'grad_norm': 4.31733512878418, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.006453651934862137, 'loss_2': 0.0016422271728515625, 'loss_3': -16.29085350036621, 'loss_4': 1.2662338018417358, 'epoch': 10.23}
{'loss': 0.0141, 'grad_norm': 6.164918422698975, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.011728255078196526, 'loss_2': 0.0023250579833984375, 'loss_3': -16.243576049804688, 'loss_4': 1.4151942729949951, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 13:04:03,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:03,695 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:58<58:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:11,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016029756516218185, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.012279045768082142, 'eval_loss_2': 0.003750711679458618, 'eval_loss_3': -18.121814727783203, 'eval_loss_4': 1.5636488199234009, 'epoch': 10.23}
{'loss': 0.013, 'grad_norm': 7.798162937164307, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.012090547941625118, 'loss_2': 0.0008668899536132812, 'loss_3': -16.296016693115234, 'loss_4': 1.7672436237335205, 'epoch': 10.24}
{'loss': 0.0218, 'grad_norm': 9.379762649536133, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.021571777760982513, 'loss_2': 0.000263214111328125, 'loss_3': -16.258474349975586, 'loss_4': 1.5807809829711914, 'epoch': 10.24}
{'loss': 0.0314, 'grad_norm': 13.763516426086426, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.029116705060005188, 'loss_2': 0.0023136138916015625, 'loss_3': -15.960988998413086, 'loss_4': 1.8808531761169434, 'epoch': 10.25}
{'loss': 0.0135, 'grad_norm': 5.364459991455078, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.00911843404173851, 'loss_2': 0.00441741943359375, 'loss_3': -16.262968063354492, 'loss_4': 1.9778099060058594, 'epoch': 10.26}
{'loss': 0.0233, 'grad_norm': 9.582509994506836, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.022023195400834084, 'loss_2': 0.0012874603271484375, 'loss_3': -16.39345359802246, 'loss_4': 1.806230068206787, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 13:04:11,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:11,031 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [44:05<58:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:18,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01621398515999317, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.024, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013469317927956581, 'eval_loss_2': 0.0027446672320365906, 'eval_loss_3': -18.129690170288086, 'eval_loss_4': 1.8590035438537598, 'epoch': 10.26}
{'loss': 0.0273, 'grad_norm': 8.746353149414062, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.024717984721064568, 'loss_2': 0.002613067626953125, 'loss_3': -16.454986572265625, 'loss_4': 2.06215763092041, 'epoch': 10.27}
{'loss': 0.0314, 'grad_norm': 19.666452407836914, 'learning_rate': 1.975e-05, 'loss_1': 0.027246177196502686, 'loss_2': 0.00420379638671875, 'loss_3': -16.25198745727539, 'loss_4': 2.185398817062378, 'epoch': 10.27}
{'loss': 0.0119, 'grad_norm': 5.37803316116333, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.010833079926669598, 'loss_2': 0.0010929107666015625, 'loss_3': -16.415966033935547, 'loss_4': 1.8630900382995605, 'epoch': 10.28}
{'loss': 0.0249, 'grad_norm': 10.219595909118652, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.02275300957262516, 'loss_2': 0.00211334228515625, 'loss_3': -16.246849060058594, 'loss_4': 1.9957951307296753, 'epoch': 10.28}
{'loss': 0.0235, 'grad_norm': 8.55015754699707, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.02319219894707203, 'loss_2': 0.0003523826599121094, 'loss_3': -16.37217903137207, 'loss_4': 2.063145637512207, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 13:04:18,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:18,367 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:12<58:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:25,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017082376405596733, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.114, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014584014192223549, 'eval_loss_2': 0.002498362213373184, 'eval_loss_3': -18.163982391357422, 'eval_loss_4': 1.9669291973114014, 'epoch': 10.29}
{'loss': 0.033, 'grad_norm': 16.100379943847656, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.02969595231115818, 'loss_2': 0.00333404541015625, 'loss_3': -16.32052993774414, 'loss_4': 1.9837745428085327, 'epoch': 10.3}
{'loss': 0.027, 'grad_norm': 6.918199062347412, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.0153820114210248, 'loss_2': 0.0115966796875, 'loss_3': -16.312236785888672, 'loss_4': 2.247899293899536, 'epoch': 10.3}
{'loss': 0.0381, 'grad_norm': 10.795425415039062, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.03349686786532402, 'loss_2': 0.004589080810546875, 'loss_3': -16.228294372558594, 'loss_4': 1.6596193313598633, 'epoch': 10.31}
{'loss': 0.0277, 'grad_norm': 10.702130317687988, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.02654801681637764, 'loss_2': 0.0011196136474609375, 'loss_3': -16.278120040893555, 'loss_4': 1.9845361709594727, 'epoch': 10.31}
{'loss': 0.0513, 'grad_norm': 20.243579864501953, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.041851021349430084, 'loss_2': 0.00942230224609375, 'loss_3': -16.234783172607422, 'loss_4': 1.7667181491851807, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 13:04:25,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:25,697 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:20<58:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:33,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02026629075407982, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016373692080378532, 'eval_loss_2': 0.0038926005363464355, 'eval_loss_3': -18.175867080688477, 'eval_loss_4': 1.8911901712417603, 'epoch': 10.32}
{'loss': 0.0595, 'grad_norm': 18.24584197998047, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.048624325543642044, 'loss_2': 0.01092529296875, 'loss_3': -16.340526580810547, 'loss_4': 1.9008302688598633, 'epoch': 10.33}
{'loss': 0.0242, 'grad_norm': 7.652824401855469, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.018237359821796417, 'loss_2': 0.0059356689453125, 'loss_3': -16.1988468170166, 'loss_4': 1.78138267993927, 'epoch': 10.33}
{'loss': 0.038, 'grad_norm': 10.360323905944824, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.033164992928504944, 'loss_2': 0.004863739013671875, 'loss_3': -16.296804428100586, 'loss_4': 2.254239082336426, 'epoch': 10.34}
{'loss': 0.0265, 'grad_norm': 6.99832820892334, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.02364446595311165, 'loss_2': 0.002834320068359375, 'loss_3': -16.351524353027344, 'loss_4': 1.8418177366256714, 'epoch': 10.34}
{'loss': 0.0314, 'grad_norm': 9.223158836364746, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.02347196452319622, 'loss_2': 0.0078887939453125, 'loss_3': -16.21662139892578, 'loss_4': 1.504528522491455, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 13:04:33,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:33,039 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:27<58:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:40,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0180804543197155, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01468588225543499, 'eval_loss_2': 0.003394573926925659, 'eval_loss_3': -18.190752029418945, 'eval_loss_4': 1.5736602544784546, 'epoch': 10.35}
{'loss': 0.025, 'grad_norm': 7.79481840133667, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.01914811320602894, 'loss_2': 0.005802154541015625, 'loss_3': -16.352794647216797, 'loss_4': 1.6991875171661377, 'epoch': 10.35}
{'loss': 0.0198, 'grad_norm': 7.372095108032227, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.018071671947836876, 'loss_2': 0.0017213821411132812, 'loss_3': -16.36933135986328, 'loss_4': 2.0586142539978027, 'epoch': 10.36}
{'loss': 0.0198, 'grad_norm': 9.043315887451172, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.014628141187131405, 'loss_2': 0.00518798828125, 'loss_3': -16.43246841430664, 'loss_4': 1.7464265823364258, 'epoch': 10.37}
{'loss': 0.027, 'grad_norm': 8.199738502502441, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.024692058563232422, 'loss_2': 0.002315521240234375, 'loss_3': -16.301603317260742, 'loss_4': 1.558504343032837, 'epoch': 10.37}
{'loss': 0.0343, 'grad_norm': 9.656393051147461, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.026726853102445602, 'loss_2': 0.0076141357421875, 'loss_3': -16.446388244628906, 'loss_4': 1.5544404983520508, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 13:04:40,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:40,373 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:34<58:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:47,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017182838171720505, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.858, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013627883046865463, 'eval_loss_2': 0.0035549551248550415, 'eval_loss_3': -18.17911148071289, 'eval_loss_4': 1.2604873180389404, 'epoch': 10.38}
{'loss': 0.0233, 'grad_norm': 8.878769874572754, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.01937677524983883, 'loss_2': 0.00394439697265625, 'loss_3': -16.25773048400879, 'loss_4': 1.2376537322998047, 'epoch': 10.38}
{'loss': 0.0168, 'grad_norm': 6.206420421600342, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.013886009342968464, 'loss_2': 0.002902984619140625, 'loss_3': -16.401077270507812, 'loss_4': 1.5927221775054932, 'epoch': 10.39}
{'loss': 0.0183, 'grad_norm': 5.3805952072143555, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.012682520784437656, 'loss_2': 0.00560760498046875, 'loss_3': -16.449129104614258, 'loss_4': 1.1330363750457764, 'epoch': 10.4}
{'loss': 0.0185, 'grad_norm': 7.173058032989502, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.017739851027727127, 'loss_2': 0.0007219314575195312, 'loss_3': -16.423511505126953, 'loss_4': 0.9848792552947998, 'epoch': 10.4}
{'loss': 0.0187, 'grad_norm': 5.5747270584106445, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.012361985631287098, 'loss_2': 0.006366729736328125, 'loss_3': -16.449283599853516, 'loss_4': 1.1896553039550781, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 13:04:47,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:47,719 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:42<58:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:55,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01721821539103985, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.747, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012420755811035633, 'eval_loss_2': 0.004797458648681641, 'eval_loss_3': -18.19684410095215, 'eval_loss_4': 0.9076347351074219, 'epoch': 10.41}
{'loss': 0.0136, 'grad_norm': 5.858370304107666, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.012996945530176163, 'loss_2': 0.0005998611450195312, 'loss_3': -16.372241973876953, 'loss_4': 0.8630332946777344, 'epoch': 10.41}
{'loss': 0.0412, 'grad_norm': 16.517118453979492, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.04028775915503502, 'loss_2': 0.000934600830078125, 'loss_3': -16.203859329223633, 'loss_4': 1.2759952545166016, 'epoch': 10.42}
{'loss': 0.0222, 'grad_norm': 6.403088092803955, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.016581837087869644, 'loss_2': 0.0055694580078125, 'loss_3': -16.29039192199707, 'loss_4': 1.059524655342102, 'epoch': 10.42}
{'loss': 0.0123, 'grad_norm': 5.822145938873291, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.011053238995373249, 'loss_2': 0.001247406005859375, 'loss_3': -16.27762222290039, 'loss_4': 0.9361590147018433, 'epoch': 10.43}
{'loss': 0.0256, 'grad_norm': 7.257562637329102, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.023307278752326965, 'loss_2': 0.00226593017578125, 'loss_3': -16.327293395996094, 'loss_4': 0.6855819225311279, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 13:04:55,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:55,057 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:49<57:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:02,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017631538212299347, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013622974045574665, 'eval_loss_2': 0.004008561372756958, 'eval_loss_3': -18.213014602661133, 'eval_loss_4': 0.7482224702835083, 'epoch': 10.44}
{'loss': 0.0261, 'grad_norm': 7.687442779541016, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.019412823021411896, 'loss_2': 0.006649017333984375, 'loss_3': -16.321670532226562, 'loss_4': 0.8274481892585754, 'epoch': 10.44}
{'loss': 0.04, 'grad_norm': 15.130075454711914, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.03715312108397484, 'loss_2': 0.002849578857421875, 'loss_3': -16.210433959960938, 'loss_4': 1.1171143054962158, 'epoch': 10.45}
{'loss': 0.0187, 'grad_norm': 8.182489395141602, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.017820721492171288, 'loss_2': 0.0008869171142578125, 'loss_3': -16.2576904296875, 'loss_4': 0.5331809520721436, 'epoch': 10.45}
{'loss': 0.0213, 'grad_norm': 6.369356632232666, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.013241887092590332, 'loss_2': 0.0080718994140625, 'loss_3': -16.389116287231445, 'loss_4': 0.9568590521812439, 'epoch': 10.46}
{'loss': 0.0211, 'grad_norm': 9.122191429138184, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.020473549142479897, 'loss_2': 0.0006265640258789062, 'loss_3': -16.498830795288086, 'loss_4': 1.2015550136566162, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 13:05:02,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:02,384 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:56<58:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:09,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020302951335906982, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.315, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01658373326063156, 'eval_loss_2': 0.003719218075275421, 'eval_loss_3': -18.21076011657715, 'eval_loss_4': 0.6587469577789307, 'epoch': 10.47}
{'loss': 0.0253, 'grad_norm': 6.507913112640381, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.01974521018564701, 'loss_2': 0.00553131103515625, 'loss_3': -16.335926055908203, 'loss_4': 0.6944637298583984, 'epoch': 10.47}
{'loss': 0.013, 'grad_norm': 5.4317474365234375, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.011610278859734535, 'loss_2': 0.001346588134765625, 'loss_3': -16.410675048828125, 'loss_4': 0.782931923866272, 'epoch': 10.48}
{'loss': 0.0217, 'grad_norm': 9.804299354553223, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.02044571563601494, 'loss_2': 0.001255035400390625, 'loss_3': -16.331972122192383, 'loss_4': 0.45430535078048706, 'epoch': 10.48}
{'loss': 0.0408, 'grad_norm': 10.574677467346191, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.030911238864064217, 'loss_2': 0.00989532470703125, 'loss_3': -16.36878204345703, 'loss_4': 0.8284493684768677, 'epoch': 10.49}
{'loss': 0.0219, 'grad_norm': 4.808783531188965, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.008970956318080425, 'loss_2': 0.0128936767578125, 'loss_3': -16.38657569885254, 'loss_4': 0.8454608917236328, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 13:05:09,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:09,730 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [45:04<57:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:17,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02786530926823616, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.492, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01745029166340828, 'eval_loss_2': 0.01041501760482788, 'eval_loss_3': -18.192577362060547, 'eval_loss_4': 0.49478334188461304, 'epoch': 10.49}
{'loss': 0.1051, 'grad_norm': 19.397018432617188, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.09649790078401566, 'loss_2': 0.00856781005859375, 'loss_3': -15.860847473144531, 'loss_4': 0.5263623595237732, 'epoch': 10.5}
{'loss': 0.0338, 'grad_norm': 8.987580299377441, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.02410801686346531, 'loss_2': 0.00969696044921875, 'loss_3': -16.222434997558594, 'loss_4': 0.2906792461872101, 'epoch': 10.51}
{'loss': 0.026, 'grad_norm': 9.11547565460205, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.020106196403503418, 'loss_2': 0.00586700439453125, 'loss_3': -16.350971221923828, 'loss_4': 0.3660922944545746, 'epoch': 10.51}
{'loss': 0.0207, 'grad_norm': 6.1588053703308105, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.013092013075947762, 'loss_2': 0.00757598876953125, 'loss_3': -16.320770263671875, 'loss_4': 0.38916081190109253, 'epoch': 10.52}
{'loss': 0.0183, 'grad_norm': 5.787929534912109, 'learning_rate': 1.95e-05, 'loss_1': 0.010815988294780254, 'loss_2': 0.007476806640625, 'loss_3': -16.206382751464844, 'loss_4': 0.6583855748176575, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 13:05:17,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:17,068 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:11<57:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:24,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02314215525984764, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016341563314199448, 'eval_loss_2': 0.006800591945648193, 'eval_loss_3': -18.183490753173828, 'eval_loss_4': 0.37442946434020996, 'epoch': 10.52}
{'loss': 0.0167, 'grad_norm': 5.684695720672607, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.014007451944053173, 'loss_2': 0.002712249755859375, 'loss_3': -16.072824478149414, 'loss_4': 0.39746636152267456, 'epoch': 10.53}
{'loss': 0.0288, 'grad_norm': 8.44775390625, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.02637551911175251, 'loss_2': 0.0023975372314453125, 'loss_3': -16.251102447509766, 'loss_4': 0.5603369474411011, 'epoch': 10.53}
{'loss': 0.0378, 'grad_norm': 8.685189247131348, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.03630645200610161, 'loss_2': 0.0015048980712890625, 'loss_3': -16.070690155029297, 'loss_4': 0.8485501408576965, 'epoch': 10.54}
{'loss': 0.0258, 'grad_norm': 6.540298938751221, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.014927850104868412, 'loss_2': 0.01082611083984375, 'loss_3': -16.158203125, 'loss_4': 0.9512304067611694, 'epoch': 10.55}
{'loss': 0.0184, 'grad_norm': 7.375351428985596, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.01736082136631012, 'loss_2': 0.000995635986328125, 'loss_3': -16.2289981842041, 'loss_4': 0.3377217948436737, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 13:05:24,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:24,403 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:18<57:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:31,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02236856520175934, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.717, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01624159887433052, 'eval_loss_2': 0.006126970052719116, 'eval_loss_3': -18.195188522338867, 'eval_loss_4': 0.4083634316921234, 'epoch': 10.55}
{'loss': 0.0232, 'grad_norm': 5.643093109130859, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.014432000927627087, 'loss_2': 0.008758544921875, 'loss_3': -16.262956619262695, 'loss_4': 0.44545096158981323, 'epoch': 10.56}
{'loss': 0.034, 'grad_norm': 8.84337329864502, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.0246959887444973, 'loss_2': 0.0093231201171875, 'loss_3': -16.295948028564453, 'loss_4': 1.0490883588790894, 'epoch': 10.56}
{'loss': 0.0172, 'grad_norm': 5.440711975097656, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.009483007714152336, 'loss_2': 0.007740020751953125, 'loss_3': -16.410465240478516, 'loss_4': 0.5330411195755005, 'epoch': 10.57}
{'loss': 0.0366, 'grad_norm': 11.925288200378418, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.03579140827059746, 'loss_2': 0.0008368492126464844, 'loss_3': -16.10061264038086, 'loss_4': 0.3551720678806305, 'epoch': 10.58}
{'loss': 0.0188, 'grad_norm': 7.036207675933838, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.016403716057538986, 'loss_2': 0.00244140625, 'loss_3': -16.1717586517334, 'loss_4': 0.5518128871917725, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 13:05:31,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:31,743 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:26<57:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:39,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01967385783791542, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.639, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01534709706902504, 'eval_loss_2': 0.004326760768890381, 'eval_loss_3': -18.216238021850586, 'eval_loss_4': 0.5734206438064575, 'epoch': 10.58}
{'loss': 0.0281, 'grad_norm': 7.00980806350708, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.013120478950440884, 'loss_2': 0.01495361328125, 'loss_3': -16.32855987548828, 'loss_4': 0.05017903074622154, 'epoch': 10.59}
{'loss': 0.0293, 'grad_norm': 9.338665962219238, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.020664509385824203, 'loss_2': 0.00860595703125, 'loss_3': -16.279232025146484, 'loss_4': 0.6263673305511475, 'epoch': 10.59}
{'loss': 0.024, 'grad_norm': 7.230190277099609, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.02385437861084938, 'loss_2': 0.00013709068298339844, 'loss_3': -16.104490280151367, 'loss_4': 0.6039749979972839, 'epoch': 10.6}
{'loss': 0.0305, 'grad_norm': 10.520120620727539, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.027311839163303375, 'loss_2': 0.0032196044921875, 'loss_3': -16.418922424316406, 'loss_4': 0.39291074872016907, 'epoch': 10.6}
{'loss': 0.029, 'grad_norm': 10.786714553833008, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.02851603738963604, 'loss_2': 0.0004668235778808594, 'loss_3': -16.346492767333984, 'loss_4': 0.4832999110221863, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 13:05:39,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:39,081 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:33<57:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:46,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020331092178821564, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014744704589247704, 'eval_loss_2': 0.005586385726928711, 'eval_loss_3': -18.226089477539062, 'eval_loss_4': 0.5871713757514954, 'epoch': 10.61}
{'loss': 0.0605, 'grad_norm': 12.796697616577148, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.04943809658288956, 'loss_2': 0.011077880859375, 'loss_3': -16.25119400024414, 'loss_4': 1.2463327646255493, 'epoch': 10.62}
{'loss': 0.0166, 'grad_norm': 6.296449661254883, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.015946093946695328, 'loss_2': 0.0006246566772460938, 'loss_3': -16.217754364013672, 'loss_4': 0.781989574432373, 'epoch': 10.62}
{'loss': 0.032, 'grad_norm': 8.894577980041504, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.02373790554702282, 'loss_2': 0.00830078125, 'loss_3': -16.304393768310547, 'loss_4': 0.4763561189174652, 'epoch': 10.63}
{'loss': 0.0179, 'grad_norm': 5.525308132171631, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.01561742089688778, 'loss_2': 0.002288818359375, 'loss_3': -16.425369262695312, 'loss_4': 0.37195533514022827, 'epoch': 10.63}
{'loss': 0.0321, 'grad_norm': 10.057358741760254, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.027608681470155716, 'loss_2': 0.0044708251953125, 'loss_3': -16.203693389892578, 'loss_4': 0.491607666015625, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 13:05:46,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:46,420 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:40<57:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:53,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018118251115083694, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01387332659214735, 'eval_loss_2': 0.0042449235916137695, 'eval_loss_3': -18.267253875732422, 'eval_loss_4': 0.44576793909072876, 'epoch': 10.64}
{'loss': 0.0247, 'grad_norm': 7.79397439956665, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.020423894748091698, 'loss_2': 0.00429534912109375, 'loss_3': -16.268413543701172, 'loss_4': 0.38656067848205566, 'epoch': 10.65}
{'loss': 0.0293, 'grad_norm': 8.969615936279297, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.02580878511071205, 'loss_2': 0.0034999847412109375, 'loss_3': -16.322757720947266, 'loss_4': 0.3647860288619995, 'epoch': 10.65}
{'loss': 0.0845, 'grad_norm': 18.04794692993164, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.07518887519836426, 'loss_2': 0.009307861328125, 'loss_3': -16.247447967529297, 'loss_4': 0.9345070123672485, 'epoch': 10.66}
{'loss': 0.0191, 'grad_norm': 5.870581150054932, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.015759415924549103, 'loss_2': 0.00334930419921875, 'loss_3': -16.303598403930664, 'loss_4': 0.3163624405860901, 'epoch': 10.66}
{'loss': 0.0301, 'grad_norm': 6.737040042877197, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.02085077576339245, 'loss_2': 0.00921630859375, 'loss_3': -16.35158348083496, 'loss_4': 0.8353533744812012, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 13:05:53,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:53,759 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:48<57:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:06:01,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01930038444697857, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013749238103628159, 'eval_loss_2': 0.00555114820599556, 'eval_loss_3': -18.25335121154785, 'eval_loss_4': 0.5551276803016663, 'epoch': 10.67}
{'loss': 0.0177, 'grad_norm': 5.804253578186035, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.015159228816628456, 'loss_2': 0.00252532958984375, 'loss_3': -16.065942764282227, 'loss_4': 0.6109834909439087, 'epoch': 10.67}
{'loss': 0.0322, 'grad_norm': 11.254980087280273, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.028293529525399208, 'loss_2': 0.003910064697265625, 'loss_3': -15.93375015258789, 'loss_4': 0.7039844393730164, 'epoch': 10.68}
{'loss': 0.0195, 'grad_norm': 8.070009231567383, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.016852280125021935, 'loss_2': 0.0026149749755859375, 'loss_3': -16.436981201171875, 'loss_4': 0.43082815408706665, 'epoch': 10.69}
{'loss': 0.0228, 'grad_norm': 8.704415321350098, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.015689672902226448, 'loss_2': 0.00714111328125, 'loss_3': -16.26595115661621, 'loss_4': 0.7460417747497559, 'epoch': 10.69}
{'loss': 0.0215, 'grad_norm': 6.134896755218506, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.016174472868442535, 'loss_2': 0.005279541015625, 'loss_3': -16.123178482055664, 'loss_4': 0.8344041109085083, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 13:06:01,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:01,086 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:55<57:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:08,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018910285085439682, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.732, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014342157170176506, 'eval_loss_2': 0.004568129777908325, 'eval_loss_3': -18.2547607421875, 'eval_loss_4': 0.7069133520126343, 'epoch': 10.7}
{'loss': 0.022, 'grad_norm': 7.740350723266602, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.01591065526008606, 'loss_2': 0.00605010986328125, 'loss_3': -16.246082305908203, 'loss_4': 0.3494681119918823, 'epoch': 10.7}
{'loss': 0.0314, 'grad_norm': 10.491242408752441, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.031200869008898735, 'loss_2': 0.000194549560546875, 'loss_3': -16.04646873474121, 'loss_4': 0.7198500633239746, 'epoch': 10.71}
{'loss': 0.0207, 'grad_norm': 8.142073631286621, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.019952433183789253, 'loss_2': 0.0007238388061523438, 'loss_3': -16.263521194458008, 'loss_4': 0.4254964590072632, 'epoch': 10.72}
{'loss': 0.0237, 'grad_norm': 6.7105536460876465, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.015465568751096725, 'loss_2': 0.00823211669921875, 'loss_3': -16.214101791381836, 'loss_4': 0.5107519626617432, 'epoch': 10.72}
{'loss': 0.0179, 'grad_norm': 5.59426212310791, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.013118927367031574, 'loss_2': 0.00473785400390625, 'loss_3': -16.269855499267578, 'loss_4': 0.7484757900238037, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 13:06:08,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:08,426 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [46:02<57:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:15,762 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018403951078653336, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014024290256202221, 'eval_loss_2': 0.00437965989112854, 'eval_loss_3': -18.21662712097168, 'eval_loss_4': 0.5937210917472839, 'epoch': 10.73}
{'loss': 0.0162, 'grad_norm': 6.006228923797607, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.015179715119302273, 'loss_2': 0.001056671142578125, 'loss_3': -16.14927864074707, 'loss_4': 0.9279816150665283, 'epoch': 10.73}
{'loss': 0.022, 'grad_norm': 6.988459587097168, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.013539296574890614, 'loss_2': 0.0084228515625, 'loss_3': -16.408222198486328, 'loss_4': 0.5059411525726318, 'epoch': 10.74}
{'loss': 0.0167, 'grad_norm': 9.757122039794922, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.013642371632158756, 'loss_2': 0.0030918121337890625, 'loss_3': -16.181169509887695, 'loss_4': 0.4192802309989929, 'epoch': 10.74}
{'loss': 0.014, 'grad_norm': 4.8755645751953125, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.006459102500230074, 'loss_2': 0.0075836181640625, 'loss_3': -16.36376190185547, 'loss_4': 0.8272165060043335, 'epoch': 10.75}
{'loss': 0.0152, 'grad_norm': 5.454391956329346, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.009798366576433182, 'loss_2': 0.00536346435546875, 'loss_3': -16.197444915771484, 'loss_4': 0.9669901728630066, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 13:06:15,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:15,762 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:10<57:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:23,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01386239379644394, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01013799849897623, 'eval_loss_2': 0.003724396228790283, 'eval_loss_3': -18.229097366333008, 'eval_loss_4': 0.37977349758148193, 'epoch': 10.76}
{'loss': 0.0153, 'grad_norm': 5.659502029418945, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.008993923664093018, 'loss_2': 0.006290435791015625, 'loss_3': -16.249391555786133, 'loss_4': 0.40062081813812256, 'epoch': 10.76}
{'loss': 0.0187, 'grad_norm': 7.901462554931641, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.01795249804854393, 'loss_2': 0.0007572174072265625, 'loss_3': -16.19263458251953, 'loss_4': 0.2980417311191559, 'epoch': 10.77}
{'loss': 0.0221, 'grad_norm': 6.296452045440674, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.017497582361102104, 'loss_2': 0.00464630126953125, 'loss_3': -16.165082931518555, 'loss_4': 0.3056440055370331, 'epoch': 10.77}
{'loss': 0.0102, 'grad_norm': 5.485292911529541, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.00956872757524252, 'loss_2': 0.000583648681640625, 'loss_3': -16.13003921508789, 'loss_4': 0.4725869297981262, 'epoch': 10.78}
{'loss': 0.0154, 'grad_norm': 6.7154154777526855, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.010794325731694698, 'loss_2': 0.00464630126953125, 'loss_3': -16.660717010498047, 'loss_4': 0.16783010959625244, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 13:06:23,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:23,093 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:17<57:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:30,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01626245491206646, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.563, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010749350301921368, 'eval_loss_2': 0.005513105541467667, 'eval_loss_3': -18.204940795898438, 'eval_loss_4': 0.4404567778110504, 'epoch': 10.78}
{'loss': 0.0148, 'grad_norm': 5.5197038650512695, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.009127737022936344, 'loss_2': 0.005687713623046875, 'loss_3': -16.232816696166992, 'loss_4': 0.5633223056793213, 'epoch': 10.79}
{'loss': 0.0166, 'grad_norm': 5.619539260864258, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.008417397737503052, 'loss_2': 0.0081634521484375, 'loss_3': -16.35100555419922, 'loss_4': 0.3284083902835846, 'epoch': 10.8}
{'loss': 0.0086, 'grad_norm': 5.30665922164917, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.004537397529929876, 'loss_2': 0.004093170166015625, 'loss_3': -16.345172882080078, 'loss_4': 0.5347516536712646, 'epoch': 10.8}
{'loss': 0.0244, 'grad_norm': 10.774277687072754, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.016608310863375664, 'loss_2': 0.00778961181640625, 'loss_3': -16.225677490234375, 'loss_4': 0.2975243926048279, 'epoch': 10.81}
{'loss': 0.0205, 'grad_norm': 10.949432373046875, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.016544600948691368, 'loss_2': 0.003963470458984375, 'loss_3': -16.399869918823242, 'loss_4': 0.42030370235443115, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 13:06:30,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:30,437 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:24<57:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:37,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015838179737329483, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012045953422784805, 'eval_loss_2': 0.0037922263145446777, 'eval_loss_3': -18.189233779907227, 'eval_loss_4': 0.6923143267631531, 'epoch': 10.81}
{'loss': 0.0173, 'grad_norm': 6.59201192855835, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.0151136489585042, 'loss_2': 0.002170562744140625, 'loss_3': -16.375293731689453, 'loss_4': 1.3424915075302124, 'epoch': 10.82}
{'loss': 0.0185, 'grad_norm': 6.023167610168457, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.010570752434432507, 'loss_2': 0.0078887939453125, 'loss_3': -16.420513153076172, 'loss_4': 0.7688341736793518, 'epoch': 10.83}
{'loss': 0.0151, 'grad_norm': 5.276222229003906, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.009284915402531624, 'loss_2': 0.00580596923828125, 'loss_3': -16.34311866760254, 'loss_4': 0.5096144676208496, 'epoch': 10.83}
{'loss': 0.0221, 'grad_norm': 5.8436665534973145, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.010980761609971523, 'loss_2': 0.011138916015625, 'loss_3': -16.203020095825195, 'loss_4': 1.0495890378952026, 'epoch': 10.84}
{'loss': 0.0086, 'grad_norm': 5.8476152420043945, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.008122943341732025, 'loss_2': 0.000507354736328125, 'loss_3': -16.510709762573242, 'loss_4': 0.5401768684387207, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 13:06:37,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:37,789 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:32<56:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:45,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016471946612000465, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.827, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012657271698117256, 'eval_loss_2': 0.0038146749138832092, 'eval_loss_3': -18.203889846801758, 'eval_loss_4': 0.668969452381134, 'epoch': 10.84}
{'loss': 0.0063, 'grad_norm': 4.742023468017578, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.0053589423187077045, 'loss_2': 0.0009822845458984375, 'loss_3': -16.459224700927734, 'loss_4': 0.7277858257293701, 'epoch': 10.85}
{'loss': 0.0172, 'grad_norm': 5.839803218841553, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.012379636988043785, 'loss_2': 0.00481414794921875, 'loss_3': -16.333097457885742, 'loss_4': 0.3020460605621338, 'epoch': 10.85}
{'loss': 0.0114, 'grad_norm': 6.1457624435424805, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.009362965822219849, 'loss_2': 0.002071380615234375, 'loss_3': -16.26287078857422, 'loss_4': 0.6644333600997925, 'epoch': 10.86}
{'loss': 0.0123, 'grad_norm': 5.546821117401123, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.009916024282574654, 'loss_2': 0.002410888671875, 'loss_3': -16.456642150878906, 'loss_4': 0.6227931380271912, 'epoch': 10.87}
{'loss': 0.0218, 'grad_norm': 6.989917755126953, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.011029181070625782, 'loss_2': 0.0107879638671875, 'loss_3': -16.493877410888672, 'loss_4': 0.21291550993919373, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 13:06:45,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:45,123 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:39<56:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:52,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018292026594281197, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.841, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013379708863794804, 'eval_loss_2': 0.004912316799163818, 'eval_loss_3': -18.2293758392334, 'eval_loss_4': 0.48451095819473267, 'epoch': 10.87}
{'loss': 0.0137, 'grad_norm': 7.684543132781982, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.013465231284499168, 'loss_2': 0.0002391338348388672, 'loss_3': -16.420808792114258, 'loss_4': 0.2250172644853592, 'epoch': 10.88}
{'loss': 0.0231, 'grad_norm': 7.630019664764404, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.016706420108675957, 'loss_2': 0.00638580322265625, 'loss_3': -16.435457229614258, 'loss_4': 0.5156183242797852, 'epoch': 10.88}
{'loss': 0.0162, 'grad_norm': 7.858882427215576, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.016203133389353752, 'loss_2': 3.8743019104003906e-05, 'loss_3': -16.548992156982422, 'loss_4': 1.089576244354248, 'epoch': 10.89}
{'loss': 0.0264, 'grad_norm': 15.242254257202148, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.024254174903035164, 'loss_2': 0.00212860107421875, 'loss_3': -16.463665008544922, 'loss_4': 0.5253041982650757, 'epoch': 10.9}
{'loss': 0.0134, 'grad_norm': 5.026185035705566, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.008822278119623661, 'loss_2': 0.00457000732421875, 'loss_3': -16.455005645751953, 'loss_4': 1.2046979665756226, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 13:06:52,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:52,458 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:46<56:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:59,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018906278535723686, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.914, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014576655812561512, 'eval_loss_2': 0.0043296217918396, 'eval_loss_3': -18.269643783569336, 'eval_loss_4': 0.4204418957233429, 'epoch': 10.9}
{'loss': 0.0187, 'grad_norm': 10.112748146057129, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.01730341650545597, 'loss_2': 0.0014133453369140625, 'loss_3': -16.220836639404297, 'loss_4': 0.2930087447166443, 'epoch': 10.91}
{'loss': 0.0101, 'grad_norm': 5.507420063018799, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.009452702477574348, 'loss_2': 0.0006437301635742188, 'loss_3': -16.354650497436523, 'loss_4': 0.8910666108131409, 'epoch': 10.91}
{'loss': 0.0147, 'grad_norm': 5.48733377456665, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.01012432761490345, 'loss_2': 0.00453948974609375, 'loss_3': -16.33582878112793, 'loss_4': 0.5423769354820251, 'epoch': 10.92}
{'loss': 0.0192, 'grad_norm': 7.923086643218994, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.017802400514483452, 'loss_2': 0.0014324188232421875, 'loss_3': -16.475994110107422, 'loss_4': 0.38548755645751953, 'epoch': 10.92}
{'loss': 0.0104, 'grad_norm': 5.265929698944092, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.0075309304520487785, 'loss_2': 0.0028285980224609375, 'loss_3': -16.445274353027344, 'loss_4': 0.22456897795200348, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 13:06:59,787 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:59,787 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:54<56:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:07,113 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020259737968444824, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.263, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0141603359952569, 'eval_loss_2': 0.006099402904510498, 'eval_loss_3': -18.279224395751953, 'eval_loss_4': 0.35165998339653015, 'epoch': 10.93}
{'loss': 0.0151, 'grad_norm': 7.987551212310791, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.01358823012560606, 'loss_2': 0.0015125274658203125, 'loss_3': -16.59014129638672, 'loss_4': 0.38777732849121094, 'epoch': 10.94}
{'loss': 0.0916, 'grad_norm': 19.204669952392578, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.08665014058351517, 'loss_2': 0.004901885986328125, 'loss_3': -16.61420249938965, 'loss_4': 0.3177891969680786, 'epoch': 10.94}
{'loss': 0.0233, 'grad_norm': 6.826053619384766, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.018367812037467957, 'loss_2': 0.004913330078125, 'loss_3': -16.558752059936523, 'loss_4': 0.34859317541122437, 'epoch': 10.95}
{'loss': 0.0156, 'grad_norm': 8.0175199508667, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.014188304543495178, 'loss_2': 0.0014362335205078125, 'loss_3': -16.479328155517578, 'loss_4': 0.4681953191757202, 'epoch': 10.95}
{'loss': 0.0147, 'grad_norm': 5.272480010986328, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.009939845651388168, 'loss_2': 0.00478363037109375, 'loss_3': -16.67815399169922, 'loss_4': 0.41793709993362427, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 13:07:07,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:07,113 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [47:01<56:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:14,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018302369862794876, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.254, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014883612282574177, 'eval_loss_2': 0.003418758511543274, 'eval_loss_3': -18.279705047607422, 'eval_loss_4': 0.38090935349464417, 'epoch': 10.96}
{'loss': 0.0293, 'grad_norm': 9.943567276000977, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.0290079303085804, 'loss_2': 0.0003330707550048828, 'loss_3': -16.22791290283203, 'loss_4': 0.08185174316167831, 'epoch': 10.97}
{'loss': 0.0135, 'grad_norm': 7.223089694976807, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.01261721272021532, 'loss_2': 0.0008540153503417969, 'loss_3': -16.403366088867188, 'loss_4': 0.4978076219558716, 'epoch': 10.97}
{'loss': 0.0715, 'grad_norm': 8.334315299987793, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.06826242804527283, 'loss_2': 0.003192901611328125, 'loss_3': -16.34370994567871, 'loss_4': 0.5204358696937561, 'epoch': 10.98}
{'loss': 0.0237, 'grad_norm': 10.93226432800293, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.022067446261644363, 'loss_2': 0.00164031982421875, 'loss_3': -16.312938690185547, 'loss_4': 0.18064314126968384, 'epoch': 10.98}
{'loss': 0.0296, 'grad_norm': 14.3175630569458, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.025558479130268097, 'loss_2': 0.004001617431640625, 'loss_3': -16.365493774414062, 'loss_4': 1.1819262504577637, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 13:07:14,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:14,457 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:08<54:44,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:07:21,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017435457557439804, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012088057585060596, 'eval_loss_2': 0.005347400903701782, 'eval_loss_3': -18.26716423034668, 'eval_loss_4': 0.6972402334213257, 'epoch': 10.99}
{'loss': 0.0173, 'grad_norm': 8.124552726745605, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.01347294170409441, 'loss_2': 0.00379180908203125, 'loss_3': -16.461362838745117, 'loss_4': 0.7253645658493042, 'epoch': 10.99}
{'loss': 0.0067, 'grad_norm': 6.775822639465332, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.0017397893825545907, 'loss_2': 0.00493621826171875, 'loss_3': -16.650283813476562, 'loss_4': 1.1190340518951416, 'epoch': 11.0}
{'loss': 0.0259, 'grad_norm': 12.060930252075195, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.023164529353380203, 'loss_2': 0.002704620361328125, 'loss_3': -16.49970817565918, 'loss_4': 0.7361586093902588, 'epoch': 11.01}
{'loss': 0.0231, 'grad_norm': 10.055046081542969, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.021941088140010834, 'loss_2': 0.0011138916015625, 'loss_3': -16.37269401550293, 'loss_4': 1.1805994510650635, 'epoch': 11.01}
{'loss': 0.0126, 'grad_norm': 5.274125099182129, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.007703943178057671, 'loss_2': 0.004871368408203125, 'loss_3': -16.458168029785156, 'loss_4': 1.5141401290893555, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 13:07:21,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:21,480 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:15<55:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:07:28,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016485150903463364, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01142709981650114, 'eval_loss_2': 0.0050580501556396484, 'eval_loss_3': -18.25905990600586, 'eval_loss_4': 1.082539439201355, 'epoch': 11.02}
{'loss': 0.008, 'grad_norm': 4.354012489318848, 'learning_rate': 1.9e-05, 'loss_1': 0.005015797447413206, 'loss_2': 0.0029659271240234375, 'loss_3': -16.39104461669922, 'loss_4': 1.0229358673095703, 'epoch': 11.02}
{'loss': 0.0098, 'grad_norm': 5.078536033630371, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.009702567011117935, 'loss_2': 8.130073547363281e-05, 'loss_3': -16.41861343383789, 'loss_4': 1.0060210227966309, 'epoch': 11.03}
{'loss': 0.0127, 'grad_norm': 4.81063985824585, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.006627637892961502, 'loss_2': 0.00606536865234375, 'loss_3': -16.24042320251465, 'loss_4': 1.3019112348556519, 'epoch': 11.03}
{'loss': 0.0048, 'grad_norm': 4.6600661277771, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.0047251442447304726, 'loss_2': 0.00011408329010009766, 'loss_3': -16.38823127746582, 'loss_4': 0.9751632809638977, 'epoch': 11.04}
{'loss': 0.0096, 'grad_norm': 5.651387691497803, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.00677177868783474, 'loss_2': 0.002857208251953125, 'loss_3': -16.500099182128906, 'loss_4': 1.1695892810821533, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 13:07:28,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:28,810 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:23<56:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:36,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017610054463148117, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.964, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011097532697021961, 'eval_loss_2': 0.0065125226974487305, 'eval_loss_3': -18.275970458984375, 'eval_loss_4': 1.0894927978515625, 'epoch': 11.05}
{'loss': 0.0497, 'grad_norm': 14.954446792602539, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.047103025019168854, 'loss_2': 0.002635955810546875, 'loss_3': -16.3528995513916, 'loss_4': 1.2525492906570435, 'epoch': 11.05}
{'loss': 0.0241, 'grad_norm': 8.775202751159668, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.018560172989964485, 'loss_2': 0.0054931640625, 'loss_3': -16.435129165649414, 'loss_4': 1.2874038219451904, 'epoch': 11.06}
{'loss': 0.0186, 'grad_norm': 5.569945812225342, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.008360423147678375, 'loss_2': 0.01021575927734375, 'loss_3': -16.373870849609375, 'loss_4': 1.2386994361877441, 'epoch': 11.06}
{'loss': 0.0144, 'grad_norm': 7.242710590362549, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.014169345609843731, 'loss_2': 0.00018072128295898438, 'loss_3': -16.236068725585938, 'loss_4': 1.3863000869750977, 'epoch': 11.07}
{'loss': 0.0223, 'grad_norm': 8.183829307556152, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.017774933949112892, 'loss_2': 0.00453948974609375, 'loss_3': -16.577163696289062, 'loss_4': 1.0568487644195557, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 13:07:36,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:36,141 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:30<56:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:43,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0182426068931818, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012071545235812664, 'eval_loss_2': 0.006171062588691711, 'eval_loss_3': -18.253868103027344, 'eval_loss_4': 1.1329901218414307, 'epoch': 11.08}
{'loss': 0.0109, 'grad_norm': 6.257780075073242, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.009882871992886066, 'loss_2': 0.00101470947265625, 'loss_3': -16.135984420776367, 'loss_4': 1.0549976825714111, 'epoch': 11.08}
{'loss': 0.0159, 'grad_norm': 4.947117805480957, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.007079419679939747, 'loss_2': 0.0087738037109375, 'loss_3': -16.385019302368164, 'loss_4': 1.2856310606002808, 'epoch': 11.09}
{'loss': 0.0159, 'grad_norm': 5.838516712188721, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.01045036781579256, 'loss_2': 0.005435943603515625, 'loss_3': -16.282854080200195, 'loss_4': 1.4437150955200195, 'epoch': 11.09}
{'loss': 0.0282, 'grad_norm': 19.272005081176758, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.023157253861427307, 'loss_2': 0.00504302978515625, 'loss_3': -16.228818893432617, 'loss_4': 1.068061113357544, 'epoch': 11.1}
{'loss': 0.0352, 'grad_norm': 13.571292877197266, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.032042328268289566, 'loss_2': 0.003170013427734375, 'loss_3': -16.155025482177734, 'loss_4': 1.865469217300415, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 13:07:43,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:43,482 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:37<56:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:50,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018817581236362457, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.415, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013527284376323223, 'eval_loss_2': 0.005290299654006958, 'eval_loss_3': -18.25203514099121, 'eval_loss_4': 1.3377046585083008, 'epoch': 11.1}
{'loss': 0.0097, 'grad_norm': 4.903088092803955, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.00894217286258936, 'loss_2': 0.0007987022399902344, 'loss_3': -16.26852798461914, 'loss_4': 1.8931394815444946, 'epoch': 11.11}
{'loss': 0.0183, 'grad_norm': 5.542641639709473, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.012238644063472748, 'loss_2': 0.006046295166015625, 'loss_3': -16.302631378173828, 'loss_4': 1.5961519479751587, 'epoch': 11.12}
{'loss': 0.0158, 'grad_norm': 6.084706783294678, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.0125984326004982, 'loss_2': 0.00324249267578125, 'loss_3': -16.370084762573242, 'loss_4': 2.3245248794555664, 'epoch': 11.12}
{'loss': 0.015, 'grad_norm': 5.932571887969971, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.012213131412863731, 'loss_2': 0.002758026123046875, 'loss_3': -16.4376163482666, 'loss_4': 1.8592932224273682, 'epoch': 11.13}
{'loss': 0.0234, 'grad_norm': 6.970952033996582, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.015171482227742672, 'loss_2': 0.008270263671875, 'loss_3': -16.184860229492188, 'loss_4': 1.368417501449585, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 13:07:50,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:50,825 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:45<55:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:58,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022004026919603348, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015175363048911095, 'eval_loss_2': 0.006828665733337402, 'eval_loss_3': -18.256650924682617, 'eval_loss_4': 1.5232216119766235, 'epoch': 11.13}
{'loss': 0.0198, 'grad_norm': 5.0084638595581055, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.007847040891647339, 'loss_2': 0.011962890625, 'loss_3': -16.345598220825195, 'loss_4': 1.6337800025939941, 'epoch': 11.14}
{'loss': 0.016, 'grad_norm': 6.63515567779541, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.012461909092962742, 'loss_2': 0.00356292724609375, 'loss_3': -16.29547691345215, 'loss_4': 1.393101453781128, 'epoch': 11.15}
{'loss': 0.0129, 'grad_norm': 5.172581195831299, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.009453409351408482, 'loss_2': 0.00341796875, 'loss_3': -16.353424072265625, 'loss_4': 1.1718271970748901, 'epoch': 11.15}
{'loss': 0.0204, 'grad_norm': 8.129800796508789, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.017464352771639824, 'loss_2': 0.002948760986328125, 'loss_3': -16.35068130493164, 'loss_4': 1.870161771774292, 'epoch': 11.16}
{'loss': 0.0187, 'grad_norm': 6.690199851989746, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.014995072036981583, 'loss_2': 0.003662109375, 'loss_3': -16.113323211669922, 'loss_4': 1.4074417352676392, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 13:07:58,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:58,161 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:52<55:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:05,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02029576525092125, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.941, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016102664172649384, 'eval_loss_2': 0.004193101078271866, 'eval_loss_3': -18.222064971923828, 'eval_loss_4': 1.6257429122924805, 'epoch': 11.16}
{'loss': 0.0155, 'grad_norm': 5.507671356201172, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.007249199785292149, 'loss_2': 0.00830078125, 'loss_3': -16.258411407470703, 'loss_4': 1.534346342086792, 'epoch': 11.17}
{'loss': 0.0148, 'grad_norm': 7.229881286621094, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.01061418280005455, 'loss_2': 0.004169464111328125, 'loss_3': -16.292163848876953, 'loss_4': 1.3939998149871826, 'epoch': 11.17}
{'loss': 0.0197, 'grad_norm': 8.421921730041504, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.0143017852678895, 'loss_2': 0.0054168701171875, 'loss_3': -16.25925636291504, 'loss_4': 1.3325138092041016, 'epoch': 11.18}
{'loss': 0.0185, 'grad_norm': 6.940835475921631, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.01339440792798996, 'loss_2': 0.005084991455078125, 'loss_3': -16.17335319519043, 'loss_4': 1.3544189929962158, 'epoch': 11.19}
{'loss': 0.0394, 'grad_norm': 12.490798950195312, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.03819984570145607, 'loss_2': 0.001163482666015625, 'loss_3': -16.221702575683594, 'loss_4': 2.0332322120666504, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 13:08:05,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:05,495 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:59<55:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:12,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02649965137243271, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.017498575150966644, 'eval_loss_2': 0.009001076221466064, 'eval_loss_3': -18.177873611450195, 'eval_loss_4': 1.7853031158447266, 'epoch': 11.19}
{'loss': 0.0141, 'grad_norm': 5.5905046463012695, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.008320939727127552, 'loss_2': 0.0057373046875, 'loss_3': -16.413660049438477, 'loss_4': 1.3247711658477783, 'epoch': 11.2}
{'loss': 0.0189, 'grad_norm': 5.324345111846924, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.009550017304718494, 'loss_2': 0.0093994140625, 'loss_3': -16.172624588012695, 'loss_4': 1.7024731636047363, 'epoch': 11.2}
{'loss': 0.0317, 'grad_norm': 9.270373344421387, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.02560097724199295, 'loss_2': 0.00612640380859375, 'loss_3': -16.150808334350586, 'loss_4': 1.762303113937378, 'epoch': 11.21}
{'loss': 0.0171, 'grad_norm': 5.165099143981934, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.005344926379621029, 'loss_2': 0.01180267333984375, 'loss_3': -16.52893829345703, 'loss_4': 1.4860873222351074, 'epoch': 11.22}
{'loss': 0.0353, 'grad_norm': 16.7706241607666, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.025909077376127243, 'loss_2': 0.009429931640625, 'loss_3': -16.39743423461914, 'loss_4': 2.4382102489471436, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 13:08:12,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:12,826 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [48:07<55:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:20,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02963661029934883, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.843, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02253817394375801, 'eval_loss_2': 0.00709843635559082, 'eval_loss_3': -18.14476776123047, 'eval_loss_4': 1.8095662593841553, 'epoch': 11.22}
{'loss': 0.0207, 'grad_norm': 5.860968112945557, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.009834242053329945, 'loss_2': 0.010833740234375, 'loss_3': -16.497108459472656, 'loss_4': 1.9623732566833496, 'epoch': 11.23}
{'loss': 0.0128, 'grad_norm': 5.654027462005615, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.009539211168885231, 'loss_2': 0.003246307373046875, 'loss_3': -16.56829071044922, 'loss_4': 1.7203794717788696, 'epoch': 11.23}
{'loss': 0.0233, 'grad_norm': 11.579080581665039, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.017600547522306442, 'loss_2': 0.00572967529296875, 'loss_3': -16.453176498413086, 'loss_4': 1.700685739517212, 'epoch': 11.24}
{'loss': 0.0127, 'grad_norm': 5.619078159332275, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.009778818115592003, 'loss_2': 0.00293731689453125, 'loss_3': -16.26158905029297, 'loss_4': 1.7303746938705444, 'epoch': 11.24}
{'loss': 0.017, 'grad_norm': 6.7074151039123535, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.01407625898718834, 'loss_2': 0.002941131591796875, 'loss_3': -16.25945472717285, 'loss_4': 1.8080265522003174, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 13:08:20,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:20,160 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:14<55:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:27,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03046819195151329, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.001, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.025859562680125237, 'eval_loss_2': 0.004608631134033203, 'eval_loss_3': -18.162410736083984, 'eval_loss_4': 1.7613532543182373, 'epoch': 11.25}
{'loss': 0.0147, 'grad_norm': 5.233051776885986, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.006665906868875027, 'loss_2': 0.0080108642578125, 'loss_3': -16.319591522216797, 'loss_4': 1.836072564125061, 'epoch': 11.26}
{'loss': 0.0099, 'grad_norm': 5.115543842315674, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.008549928665161133, 'loss_2': 0.0013837814331054688, 'loss_3': -16.139719009399414, 'loss_4': 1.6080572605133057, 'epoch': 11.26}
{'loss': 0.0165, 'grad_norm': 5.904819965362549, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.010852045379579067, 'loss_2': 0.00566864013671875, 'loss_3': -16.23281478881836, 'loss_4': 1.5330064296722412, 'epoch': 11.27}
{'loss': 0.0114, 'grad_norm': 5.295258045196533, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.00709407078102231, 'loss_2': 0.00434112548828125, 'loss_3': -16.210651397705078, 'loss_4': 1.5354154109954834, 'epoch': 11.27}
{'loss': 0.0104, 'grad_norm': 5.1255202293396, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.009137468412518501, 'loss_2': 0.0012674331665039062, 'loss_3': -16.343128204345703, 'loss_4': 1.664903163909912, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 13:08:27,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:27,490 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:21<55:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:34,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027475904673337936, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020795658230781555, 'eval_loss_2': 0.00668025016784668, 'eval_loss_3': -18.150699615478516, 'eval_loss_4': 1.7241637706756592, 'epoch': 11.28}
{'loss': 0.0149, 'grad_norm': 9.506817817687988, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.011224289424717426, 'loss_2': 0.00366973876953125, 'loss_3': -16.432140350341797, 'loss_4': 1.542036533355713, 'epoch': 11.28}
{'loss': 0.0329, 'grad_norm': 10.625444412231445, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.026363814249634743, 'loss_2': 0.006580352783203125, 'loss_3': -16.30396270751953, 'loss_4': 1.7499769926071167, 'epoch': 11.29}
{'loss': 0.0175, 'grad_norm': 5.114726543426514, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.008193240500986576, 'loss_2': 0.0093536376953125, 'loss_3': -16.166645050048828, 'loss_4': 2.2269933223724365, 'epoch': 11.3}
{'loss': 0.0302, 'grad_norm': 7.698191165924072, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.0156675036996603, 'loss_2': 0.0145111083984375, 'loss_3': -16.464719772338867, 'loss_4': 2.0371322631835938, 'epoch': 11.3}
{'loss': 0.0225, 'grad_norm': 4.90691614151001, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.0057669212110340595, 'loss_2': 0.016693115234375, 'loss_3': -16.13561248779297, 'loss_4': 2.0377354621887207, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 13:08:34,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:34,838 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:29<55:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:42,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024167044088244438, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.833, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01617206260561943, 'eval_loss_2': 0.007994979619979858, 'eval_loss_3': -18.24054527282715, 'eval_loss_4': 1.9463300704956055, 'epoch': 11.31}
{'loss': 0.0562, 'grad_norm': 9.05286693572998, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.04647982120513916, 'loss_2': 0.009674072265625, 'loss_3': -16.292034149169922, 'loss_4': 2.354562759399414, 'epoch': 11.31}
{'loss': 0.0244, 'grad_norm': 8.000819206237793, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.017876222729682922, 'loss_2': 0.00655364990234375, 'loss_3': -16.19786834716797, 'loss_4': 2.1275734901428223, 'epoch': 11.32}
{'loss': 0.0166, 'grad_norm': 6.031671047210693, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.012347174808382988, 'loss_2': 0.00429534912109375, 'loss_3': -16.275188446044922, 'loss_4': 2.3379507064819336, 'epoch': 11.33}
{'loss': 0.0273, 'grad_norm': 11.27334213256836, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.020296409726142883, 'loss_2': 0.00701141357421875, 'loss_3': -16.133769989013672, 'loss_4': 2.6997909545898438, 'epoch': 11.33}
{'loss': 0.0176, 'grad_norm': 5.5433030128479, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.013773437589406967, 'loss_2': 0.00386810302734375, 'loss_3': -16.33959197998047, 'loss_4': 1.7531437873840332, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 13:08:42,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:42,172 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:36<55:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:49,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019650980830192566, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.699, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01577022671699524, 'eval_loss_2': 0.0038807541131973267, 'eval_loss_3': -18.284969329833984, 'eval_loss_4': 2.2932615280151367, 'epoch': 11.34}
{'loss': 0.0776, 'grad_norm': 27.9886474609375, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.07179825752973557, 'loss_2': 0.0058441162109375, 'loss_3': -16.307903289794922, 'loss_4': 2.883183479309082, 'epoch': 11.34}
{'loss': 0.0503, 'grad_norm': 15.896625518798828, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.045955151319503784, 'loss_2': 0.004314422607421875, 'loss_3': -16.328784942626953, 'loss_4': 2.2152931690216064, 'epoch': 11.35}
{'loss': 0.0247, 'grad_norm': 6.949743747711182, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.02066647633910179, 'loss_2': 0.0040130615234375, 'loss_3': -16.116744995117188, 'loss_4': 2.412445068359375, 'epoch': 11.35}
{'loss': 0.0175, 'grad_norm': 4.7763590812683105, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.009072436951100826, 'loss_2': 0.00841522216796875, 'loss_3': -16.1662654876709, 'loss_4': 2.123626708984375, 'epoch': 11.36}
{'loss': 0.0201, 'grad_norm': 7.939814567565918, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.014382603578269482, 'loss_2': 0.00571441650390625, 'loss_3': -16.463085174560547, 'loss_4': 2.7328977584838867, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 13:08:49,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:49,509 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:43<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:56,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020007185637950897, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.015086646191775799, 'eval_loss_2': 0.004920542240142822, 'eval_loss_3': -18.308818817138672, 'eval_loss_4': 2.7488362789154053, 'epoch': 11.37}
{'loss': 0.0283, 'grad_norm': 8.682558059692383, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.022127091884613037, 'loss_2': 0.00612640380859375, 'loss_3': -16.158447265625, 'loss_4': 2.860898017883301, 'epoch': 11.37}
{'loss': 0.0237, 'grad_norm': 5.879297733306885, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.013159740716218948, 'loss_2': 0.0105133056640625, 'loss_3': -16.083253860473633, 'loss_4': 2.390303134918213, 'epoch': 11.38}
{'loss': 0.0277, 'grad_norm': 11.348143577575684, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.02430807054042816, 'loss_2': 0.0033969879150390625, 'loss_3': -16.1636905670166, 'loss_4': 3.1356701850891113, 'epoch': 11.38}
{'loss': 0.0197, 'grad_norm': 5.693404674530029, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.013766824267804623, 'loss_2': 0.00589752197265625, 'loss_3': -16.272441864013672, 'loss_4': 2.7771477699279785, 'epoch': 11.39}
{'loss': 0.0264, 'grad_norm': 9.860004425048828, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.02326921932399273, 'loss_2': 0.003086090087890625, 'loss_3': -16.474170684814453, 'loss_4': 3.310777187347412, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 13:08:56,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:56,846 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:51<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:04,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019298410043120384, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.83, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015269150957465172, 'eval_loss_2': 0.004029259085655212, 'eval_loss_3': -18.283639907836914, 'eval_loss_4': 2.930182695388794, 'epoch': 11.4}
{'loss': 0.0208, 'grad_norm': 7.575176239013672, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.020451918244361877, 'loss_2': 0.00034308433532714844, 'loss_3': -16.209619522094727, 'loss_4': 3.51255464553833, 'epoch': 11.4}
{'loss': 0.0354, 'grad_norm': 12.052250862121582, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.028085459023714066, 'loss_2': 0.00736236572265625, 'loss_3': -16.15859603881836, 'loss_4': 3.5635151863098145, 'epoch': 11.41}
{'loss': 0.032, 'grad_norm': 8.429274559020996, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.025984618812799454, 'loss_2': 0.00600433349609375, 'loss_3': -16.361068725585938, 'loss_4': 2.7193760871887207, 'epoch': 11.41}
{'loss': 0.0154, 'grad_norm': 5.63278865814209, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.011442448943853378, 'loss_2': 0.003917694091796875, 'loss_3': -16.289424896240234, 'loss_4': 2.5381555557250977, 'epoch': 11.42}
{'loss': 0.0145, 'grad_norm': 5.004360198974609, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.009223815985023975, 'loss_2': 0.00524139404296875, 'loss_3': -16.276348114013672, 'loss_4': 2.837754249572754, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 13:09:04,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:04,193 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:58<55:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:11,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020269017666578293, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.561, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.016657093539834023, 'eval_loss_2': 0.003611922264099121, 'eval_loss_3': -18.207427978515625, 'eval_loss_4': 2.6661431789398193, 'epoch': 11.42}
{'loss': 0.0213, 'grad_norm': 7.745720863342285, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.017853444442152977, 'loss_2': 0.0034637451171875, 'loss_3': -16.136390686035156, 'loss_4': 2.621917724609375, 'epoch': 11.43}
{'loss': 0.0127, 'grad_norm': 5.704141616821289, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.010600518435239792, 'loss_2': 0.0020694732666015625, 'loss_3': -16.303890228271484, 'loss_4': 2.2421200275421143, 'epoch': 11.44}
{'loss': 0.0156, 'grad_norm': 4.551352024078369, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.0063998461700975895, 'loss_2': 0.009185791015625, 'loss_3': -16.485933303833008, 'loss_4': 2.3780360221862793, 'epoch': 11.44}
{'loss': 0.019, 'grad_norm': 8.682421684265137, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.016895713284611702, 'loss_2': 0.002132415771484375, 'loss_3': -16.18140983581543, 'loss_4': 2.00620436668396, 'epoch': 11.45}
{'loss': 0.0336, 'grad_norm': 14.067984580993652, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.03070809133350849, 'loss_2': 0.0028839111328125, 'loss_3': -16.208927154541016, 'loss_4': 2.3223822116851807, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 13:09:11,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:11,541 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [49:05<55:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:18,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02707177773118019, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.023796992376446724, 'eval_loss_2': 0.003274783492088318, 'eval_loss_3': -18.121007919311523, 'eval_loss_4': 2.507990837097168, 'epoch': 11.45}
{'loss': 0.0211, 'grad_norm': 7.812587261199951, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.01728479191660881, 'loss_2': 0.00382232666015625, 'loss_3': -16.299217224121094, 'loss_4': 2.438511848449707, 'epoch': 11.46}
{'loss': 0.0053, 'grad_norm': 4.928737640380859, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.005213532596826553, 'loss_2': 3.647804260253906e-05, 'loss_3': -16.300315856933594, 'loss_4': 2.1042490005493164, 'epoch': 11.47}
{'loss': 0.0217, 'grad_norm': 11.324053764343262, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.019877906888723373, 'loss_2': 0.0017786026000976562, 'loss_3': -16.158447265625, 'loss_4': 2.062814235687256, 'epoch': 11.47}
{'loss': 0.0656, 'grad_norm': 14.682219505310059, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.06379355490207672, 'loss_2': 0.001781463623046875, 'loss_3': -16.233795166015625, 'loss_4': 2.4468507766723633, 'epoch': 11.48}
{'loss': 0.0103, 'grad_norm': 4.82431173324585, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.010244462639093399, 'loss_2': 4.8220157623291016e-05, 'loss_3': -16.420970916748047, 'loss_4': 2.6676177978515625, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 13:09:18,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:18,894 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:13<54:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:26,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06102558970451355, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.989, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.05759039521217346, 'eval_loss_2': 0.003435194492340088, 'eval_loss_3': -17.990732192993164, 'eval_loss_4': 2.515836238861084, 'epoch': 11.48}
{'loss': 0.0184, 'grad_norm': 6.730494022369385, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.013814530335366726, 'loss_2': 0.004608154296875, 'loss_3': -16.381874084472656, 'loss_4': 2.0869462490081787, 'epoch': 11.49}
{'loss': 0.0198, 'grad_norm': 7.006669998168945, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.015018611215054989, 'loss_2': 0.00479888916015625, 'loss_3': -16.33246612548828, 'loss_4': 2.814434051513672, 'epoch': 11.49}
{'loss': 0.0445, 'grad_norm': 26.075359344482422, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.03955863043665886, 'loss_2': 0.004962921142578125, 'loss_3': -16.114316940307617, 'loss_4': 2.191054344177246, 'epoch': 11.5}
{'loss': 0.0315, 'grad_norm': 7.202065944671631, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.02777910605072975, 'loss_2': 0.0037517547607421875, 'loss_3': -16.201129913330078, 'loss_4': 2.475888252258301, 'epoch': 11.51}
{'loss': 0.0361, 'grad_norm': 10.573725700378418, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.02765709161758423, 'loss_2': 0.0084228515625, 'loss_3': -16.239282608032227, 'loss_4': 2.133143901824951, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 13:09:26,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:26,228 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:20<54:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:33,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0752665251493454, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.928, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.06642310321331024, 'eval_loss_2': 0.008843421936035156, 'eval_loss_3': -17.986299514770508, 'eval_loss_4': 2.285327434539795, 'epoch': 11.51}
{'loss': 0.0458, 'grad_norm': 13.7761812210083, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.034005723893642426, 'loss_2': 0.0117950439453125, 'loss_3': -16.367992401123047, 'loss_4': 2.945183277130127, 'epoch': 11.52}
{'loss': 0.0209, 'grad_norm': 7.042417526245117, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.014701833948493004, 'loss_2': 0.006198883056640625, 'loss_3': -16.007972717285156, 'loss_4': 1.7687640190124512, 'epoch': 11.52}
{'loss': 0.037, 'grad_norm': 12.32220458984375, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.029949024319648743, 'loss_2': 0.0070953369140625, 'loss_3': -16.529102325439453, 'loss_4': 2.040015697479248, 'epoch': 11.53}
{'loss': 0.0337, 'grad_norm': 19.543004989624023, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.028310786932706833, 'loss_2': 0.005340576171875, 'loss_3': -16.177621841430664, 'loss_4': 2.099262237548828, 'epoch': 11.53}
{'loss': 0.0202, 'grad_norm': 6.080516815185547, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.017791828140616417, 'loss_2': 0.0023956298828125, 'loss_3': -16.348175048828125, 'loss_4': 2.197998523712158, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 13:09:33,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:33,558 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:27<54:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:40,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04660235345363617, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.040190692991018295, 'eval_loss_2': 0.006411656737327576, 'eval_loss_3': -18.04604148864746, 'eval_loss_4': 1.828255295753479, 'epoch': 11.54}
{'loss': 0.0384, 'grad_norm': 11.326993942260742, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.029477637261152267, 'loss_2': 0.008941650390625, 'loss_3': -16.0731201171875, 'loss_4': 1.2429299354553223, 'epoch': 11.55}
{'loss': 0.0275, 'grad_norm': 10.441079139709473, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.019640540704131126, 'loss_2': 0.00785064697265625, 'loss_3': -16.44033432006836, 'loss_4': 1.6399593353271484, 'epoch': 11.55}
{'loss': 0.0177, 'grad_norm': 6.077692985534668, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.010228266939520836, 'loss_2': 0.007472991943359375, 'loss_3': -16.2960147857666, 'loss_4': 1.8001954555511475, 'epoch': 11.56}
{'loss': 0.02, 'grad_norm': 8.722238540649414, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.017560528591275215, 'loss_2': 0.002468109130859375, 'loss_3': -16.3404483795166, 'loss_4': 1.1737099885940552, 'epoch': 11.56}
{'loss': 0.0111, 'grad_norm': 5.977585792541504, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.009785762056708336, 'loss_2': 0.0013628005981445312, 'loss_3': -16.196151733398438, 'loss_4': 1.3868300914764404, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 13:09:40,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:40,896 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:35<54:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:48,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019905060529708862, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016490546986460686, 'eval_loss_2': 0.0034145116806030273, 'eval_loss_3': -18.160171508789062, 'eval_loss_4': 1.2346774339675903, 'epoch': 11.57}
{'loss': 0.0155, 'grad_norm': 5.777124881744385, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.010347372852265835, 'loss_2': 0.00511932373046875, 'loss_3': -16.40424919128418, 'loss_4': 1.2057315111160278, 'epoch': 11.58}
{'loss': 0.0163, 'grad_norm': 6.496985912322998, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.014301557093858719, 'loss_2': 0.002002716064453125, 'loss_3': -16.545141220092773, 'loss_4': 0.7438894510269165, 'epoch': 11.58}
{'loss': 0.0248, 'grad_norm': 9.415349006652832, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.02102341316640377, 'loss_2': 0.0037689208984375, 'loss_3': -16.33922576904297, 'loss_4': 0.8582155704498291, 'epoch': 11.59}
{'loss': 0.0218, 'grad_norm': 9.690077781677246, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.021253490820527077, 'loss_2': 0.0005412101745605469, 'loss_3': -16.23544692993164, 'loss_4': 0.6436198949813843, 'epoch': 11.59}
{'loss': 0.014, 'grad_norm': 5.814977169036865, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.0087175527587533, 'loss_2': 0.005279541015625, 'loss_3': -16.075977325439453, 'loss_4': 0.8059780597686768, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 13:09:48,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:48,230 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:42<54:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:55,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017959807068109512, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013133984059095383, 'eval_loss_2': 0.00482582300901413, 'eval_loss_3': -18.21598243713379, 'eval_loss_4': 0.7981461882591248, 'epoch': 11.6}
{'loss': 0.0183, 'grad_norm': 10.744742393493652, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.016373731195926666, 'loss_2': 0.001903533935546875, 'loss_3': -16.16396713256836, 'loss_4': 0.816469669342041, 'epoch': 11.6}
{'loss': 0.0199, 'grad_norm': 5.443715572357178, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.012737274169921875, 'loss_2': 0.00711822509765625, 'loss_3': -16.391324996948242, 'loss_4': 1.0467816591262817, 'epoch': 11.61}
{'loss': 0.0361, 'grad_norm': 8.277542114257812, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.03265399858355522, 'loss_2': 0.003406524658203125, 'loss_3': -16.068782806396484, 'loss_4': 0.8490391969680786, 'epoch': 11.62}
{'loss': 0.0201, 'grad_norm': 5.708049774169922, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.011906653642654419, 'loss_2': 0.0081939697265625, 'loss_3': -16.36988067626953, 'loss_4': 1.1016547679901123, 'epoch': 11.62}
{'loss': 0.0092, 'grad_norm': 4.966889381408691, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.006164552178233862, 'loss_2': 0.002986907958984375, 'loss_3': -16.17266845703125, 'loss_4': 0.8879354596138, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 13:09:55,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:55,567 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:49<54:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:02,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015814587473869324, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.88, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.012496025301516056, 'eval_loss_2': 0.0033185631036758423, 'eval_loss_3': -18.220014572143555, 'eval_loss_4': 0.5844031572341919, 'epoch': 11.63}
{'loss': 0.0126, 'grad_norm': 5.4806809425354, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.009809697978198528, 'loss_2': 0.00275421142578125, 'loss_3': -16.30437469482422, 'loss_4': 0.9092817902565002, 'epoch': 11.63}
{'loss': 0.0391, 'grad_norm': 14.922258377075195, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.03760275989770889, 'loss_2': 0.00153350830078125, 'loss_3': -16.12575340270996, 'loss_4': 0.9108130931854248, 'epoch': 11.64}
{'loss': 0.0089, 'grad_norm': 4.742241382598877, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.006625120993703604, 'loss_2': 0.0023040771484375, 'loss_3': -16.258440017700195, 'loss_4': 0.5636047720909119, 'epoch': 11.65}
{'loss': 0.0207, 'grad_norm': 5.192551612854004, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.010713049210608006, 'loss_2': 0.0100250244140625, 'loss_3': -16.094345092773438, 'loss_4': 0.9102076888084412, 'epoch': 11.65}
{'loss': 0.0177, 'grad_norm': 6.366507530212402, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.011236140504479408, 'loss_2': 0.006496429443359375, 'loss_3': -16.38528060913086, 'loss_4': 0.9062312841415405, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 13:10:02,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:02,904 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:57<54:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:10,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020726317539811134, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012584563344717026, 'eval_loss_2': 0.008141756057739258, 'eval_loss_3': -18.237878799438477, 'eval_loss_4': 0.7610776424407959, 'epoch': 11.66}
{'loss': 0.0206, 'grad_norm': 7.71614408493042, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.01682421565055847, 'loss_2': 0.003772735595703125, 'loss_3': -16.25432014465332, 'loss_4': 1.2677369117736816, 'epoch': 11.66}
{'loss': 0.0164, 'grad_norm': 8.168315887451172, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.013835238292813301, 'loss_2': 0.002574920654296875, 'loss_3': -16.05329132080078, 'loss_4': 1.5545220375061035, 'epoch': 11.67}
{'loss': 0.0113, 'grad_norm': 6.238144397735596, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.008768584579229355, 'loss_2': 0.00249481201171875, 'loss_3': -16.43084716796875, 'loss_4': 1.9490193128585815, 'epoch': 11.67}
{'loss': 0.0195, 'grad_norm': 9.631953239440918, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.014519195072352886, 'loss_2': 0.00496673583984375, 'loss_3': -16.0946044921875, 'loss_4': 0.917341411113739, 'epoch': 11.68}
{'loss': 0.0159, 'grad_norm': 5.860506534576416, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.007568397093564272, 'loss_2': 0.00830841064453125, 'loss_3': -16.121110916137695, 'loss_4': 0.9140743017196655, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 13:10:10,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:10,240 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [50:04<57:23,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 13:10:17,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020690158009529114, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.546, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012226056307554245, 'eval_loss_2': 0.00846409797668457, 'eval_loss_3': -18.234708786010742, 'eval_loss_4': 0.9976589679718018, 'epoch': 11.69}
{'loss': 0.0344, 'grad_norm': 9.779641151428223, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.025522278621792793, 'loss_2': 0.0089111328125, 'loss_3': -16.091381072998047, 'loss_4': 1.5114033222198486, 'epoch': 11.69}
{'loss': 0.0202, 'grad_norm': 5.370038986206055, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.011663820594549179, 'loss_2': 0.00850677490234375, 'loss_3': -16.09771728515625, 'loss_4': 1.3860751390457153, 'epoch': 11.7}
{'loss': 0.0189, 'grad_norm': 8.616060256958008, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.012699448503553867, 'loss_2': 0.006195068359375, 'loss_3': -16.029088973999023, 'loss_4': 1.4341344833374023, 'epoch': 11.7}
{'loss': 0.0095, 'grad_norm': 6.431549072265625, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.005532022565603256, 'loss_2': 0.003955841064453125, 'loss_3': -16.173023223876953, 'loss_4': 1.1052238941192627, 'epoch': 11.71}
{'loss': 0.0136, 'grad_norm': 4.597128868103027, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.006862591952085495, 'loss_2': 0.00669097900390625, 'loss_3': -16.115982055664062, 'loss_4': 1.631495475769043, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 13:10:17,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:17,775 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:12<54:47,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:10:25,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016936806961894035, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013228965923190117, 'eval_loss_2': 0.0037078410387039185, 'eval_loss_3': -18.214149475097656, 'eval_loss_4': 1.2930182218551636, 'epoch': 11.72}
{'loss': 0.0187, 'grad_norm': 7.3703742027282715, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.012953586876392365, 'loss_2': 0.0057220458984375, 'loss_3': -15.911154747009277, 'loss_4': 1.7929819822311401, 'epoch': 11.72}
{'loss': 0.0453, 'grad_norm': 18.687591552734375, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.04375452175736427, 'loss_2': 0.00159454345703125, 'loss_3': -16.21942710876465, 'loss_4': 1.5602779388427734, 'epoch': 11.73}
{'loss': 0.0132, 'grad_norm': 6.413288116455078, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.013050087727606297, 'loss_2': 0.00015997886657714844, 'loss_3': -16.185693740844727, 'loss_4': 1.4039099216461182, 'epoch': 11.73}
{'loss': 0.0067, 'grad_norm': 4.481940269470215, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.005357691086828709, 'loss_2': 0.0013761520385742188, 'loss_3': -16.423948287963867, 'loss_4': 1.506277322769165, 'epoch': 11.74}
{'loss': 0.0156, 'grad_norm': 5.060690879821777, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.00834736693650484, 'loss_2': 0.00727081298828125, 'loss_3': -16.227386474609375, 'loss_4': 1.8221774101257324, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 13:10:25,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:25,114 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:19<54:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:32,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02069733291864395, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014996472746133804, 'eval_loss_2': 0.005700860172510147, 'eval_loss_3': -18.21477508544922, 'eval_loss_4': 1.2986587285995483, 'epoch': 11.74}
{'loss': 0.0195, 'grad_norm': 5.284521102905273, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.005875895265489817, 'loss_2': 0.0136566162109375, 'loss_3': -16.453731536865234, 'loss_4': 1.1164014339447021, 'epoch': 11.75}
{'loss': 0.013, 'grad_norm': 5.331785202026367, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.007665786426514387, 'loss_2': 0.0053558349609375, 'loss_3': -16.252870559692383, 'loss_4': 1.2956358194351196, 'epoch': 11.76}
{'loss': 0.0109, 'grad_norm': 5.463850975036621, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.008600722067058086, 'loss_2': 0.002346038818359375, 'loss_3': -16.209243774414062, 'loss_4': 1.3013601303100586, 'epoch': 11.76}
{'loss': 0.0145, 'grad_norm': 6.3402180671691895, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.010182665660977364, 'loss_2': 0.00433349609375, 'loss_3': -16.38928985595703, 'loss_4': 1.2219157218933105, 'epoch': 11.77}
{'loss': 0.0102, 'grad_norm': 5.435985088348389, 'learning_rate': 1.825e-05, 'loss_1': 0.00982679147273302, 'loss_2': 0.00041747093200683594, 'loss_3': -16.123332977294922, 'loss_4': 1.743445634841919, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 13:10:32,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:32,461 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:26<54:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:39,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01931534707546234, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.415, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01598276011645794, 'eval_loss_2': 0.003332585096359253, 'eval_loss_3': -18.21404457092285, 'eval_loss_4': 1.3190137147903442, 'epoch': 11.77}
{'loss': 0.0121, 'grad_norm': 5.287424564361572, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.00549338897690177, 'loss_2': 0.00656890869140625, 'loss_3': -16.150249481201172, 'loss_4': 1.4002478122711182, 'epoch': 11.78}
{'loss': 0.0332, 'grad_norm': 16.60249900817871, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.029858414083719254, 'loss_2': 0.003391265869140625, 'loss_3': -16.164339065551758, 'loss_4': 1.7671153545379639, 'epoch': 11.78}
{'loss': 0.0109, 'grad_norm': 4.789211273193359, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.006436697207391262, 'loss_2': 0.0045013427734375, 'loss_3': -16.493560791015625, 'loss_4': 1.6045657396316528, 'epoch': 11.79}
{'loss': 0.0126, 'grad_norm': 5.633622646331787, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.01046051550656557, 'loss_2': 0.0021762847900390625, 'loss_3': -16.236026763916016, 'loss_4': 0.910144031047821, 'epoch': 11.8}
{'loss': 0.017, 'grad_norm': 8.941773414611816, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.015226087532937527, 'loss_2': 0.0017833709716796875, 'loss_3': -16.40538787841797, 'loss_4': 1.3953874111175537, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 13:10:39,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:39,814 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:34<54:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:47,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021092215552926064, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.525, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01617147959768772, 'eval_loss_2': 0.004920735955238342, 'eval_loss_3': -18.183420181274414, 'eval_loss_4': 1.3462880849838257, 'epoch': 11.8}
{'loss': 0.0175, 'grad_norm': 6.186105251312256, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.008667470887303352, 'loss_2': 0.0088043212890625, 'loss_3': -16.021831512451172, 'loss_4': 1.7456867694854736, 'epoch': 11.81}
{'loss': 0.0224, 'grad_norm': 7.991840839385986, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.013898910023272038, 'loss_2': 0.0084991455078125, 'loss_3': -16.120363235473633, 'loss_4': 1.1728146076202393, 'epoch': 11.81}
{'loss': 0.0689, 'grad_norm': 16.937986373901367, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.0675613284111023, 'loss_2': 0.0013561248779296875, 'loss_3': -16.270862579345703, 'loss_4': 1.5865812301635742, 'epoch': 11.82}
{'loss': 0.008, 'grad_norm': 5.607466220855713, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.007982701063156128, 'loss_2': 1.9848346710205078e-05, 'loss_3': -16.189844131469727, 'loss_4': 1.4965925216674805, 'epoch': 11.83}
{'loss': 0.0143, 'grad_norm': 5.514488220214844, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.007756853010505438, 'loss_2': 0.006542205810546875, 'loss_3': -16.22937774658203, 'loss_4': 1.8091431856155396, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 13:10:47,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:47,162 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:41<53:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:54,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018735336139798164, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.44, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013220343738794327, 'eval_loss_2': 0.005514994263648987, 'eval_loss_3': -18.18379783630371, 'eval_loss_4': 1.3288376331329346, 'epoch': 11.83}
{'loss': 0.0231, 'grad_norm': 5.59162712097168, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.011267104186117649, 'loss_2': 0.01186370849609375, 'loss_3': -16.14679718017578, 'loss_4': 1.897184133529663, 'epoch': 11.84}
{'loss': 0.0155, 'grad_norm': 5.982449531555176, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.011352420784533024, 'loss_2': 0.004138946533203125, 'loss_3': -16.24735450744629, 'loss_4': 1.6056160926818848, 'epoch': 11.84}
{'loss': 0.0114, 'grad_norm': 5.710510730743408, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.009537482634186745, 'loss_2': 0.001865386962890625, 'loss_3': -16.235090255737305, 'loss_4': 1.0587440729141235, 'epoch': 11.85}
{'loss': 0.0365, 'grad_norm': 21.940265655517578, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.03624213486909866, 'loss_2': 0.000247955322265625, 'loss_3': -16.086545944213867, 'loss_4': 1.2566241025924683, 'epoch': 11.85}
{'loss': 0.0171, 'grad_norm': 7.734626770019531, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.011639725416898727, 'loss_2': 0.00548553466796875, 'loss_3': -16.353191375732422, 'loss_4': 1.19338858127594, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 13:10:54,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:54,500 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:48<53:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:01,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017504990100860596, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.789, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01356952078640461, 'eval_loss_2': 0.003935471177101135, 'eval_loss_3': -18.159244537353516, 'eval_loss_4': 1.2990206480026245, 'epoch': 11.86}
{'loss': 0.0156, 'grad_norm': 5.245215892791748, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.009524287655949593, 'loss_2': 0.0061187744140625, 'loss_3': -16.25600814819336, 'loss_4': 1.5384855270385742, 'epoch': 11.87}
{'loss': 0.008, 'grad_norm': 4.709720611572266, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.0053924014791846275, 'loss_2': 0.00263214111328125, 'loss_3': -16.306827545166016, 'loss_4': 1.6177469491958618, 'epoch': 11.87}
{'loss': 0.0099, 'grad_norm': 6.186533451080322, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.009033344686031342, 'loss_2': 0.0008707046508789062, 'loss_3': -16.131122589111328, 'loss_4': 1.928575038909912, 'epoch': 11.88}
{'loss': 0.0112, 'grad_norm': 5.6679534912109375, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.010490207932889462, 'loss_2': 0.0007586479187011719, 'loss_3': -16.215045928955078, 'loss_4': 1.125120997428894, 'epoch': 11.88}
{'loss': 0.0128, 'grad_norm': 5.117420196533203, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.00785196851938963, 'loss_2': 0.004974365234375, 'loss_3': -16.154979705810547, 'loss_4': 1.6744557619094849, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 13:11:01,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:01,836 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:56<53:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:09,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018219400197267532, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.57, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014454176649451256, 'eval_loss_2': 0.0037652254104614258, 'eval_loss_3': -18.17924690246582, 'eval_loss_4': 1.3380895853042603, 'epoch': 11.89}
{'loss': 0.0115, 'grad_norm': 5.358028888702393, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.007099415175616741, 'loss_2': 0.004425048828125, 'loss_3': -16.00401496887207, 'loss_4': 1.3274447917938232, 'epoch': 11.9}
{'loss': 0.0182, 'grad_norm': 6.387080669403076, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.014712526462972164, 'loss_2': 0.003505706787109375, 'loss_3': -16.06859016418457, 'loss_4': 1.564636468887329, 'epoch': 11.9}
{'loss': 0.0138, 'grad_norm': 4.824775218963623, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.007509575691074133, 'loss_2': 0.00634002685546875, 'loss_3': -16.44792938232422, 'loss_4': 1.2179219722747803, 'epoch': 11.91}
{'loss': 0.0126, 'grad_norm': 5.611776828765869, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.008869661018252373, 'loss_2': 0.00370025634765625, 'loss_3': -16.19318199157715, 'loss_4': 1.5576610565185547, 'epoch': 11.91}
{'loss': 0.0184, 'grad_norm': 6.969038009643555, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.01687776856124401, 'loss_2': 0.0014972686767578125, 'loss_3': -16.169570922851562, 'loss_4': 1.6375770568847656, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 13:11:09,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:09,177 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [51:03<53:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:16,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01603950560092926, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.815, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012457714416086674, 'eval_loss_2': 0.003581792116165161, 'eval_loss_3': -18.197572708129883, 'eval_loss_4': 1.3434851169586182, 'epoch': 11.92}
{'loss': 0.0144, 'grad_norm': 7.56369686126709, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.008940370753407478, 'loss_2': 0.005462646484375, 'loss_3': -16.025083541870117, 'loss_4': 1.991576910018921, 'epoch': 11.92}
{'loss': 0.0152, 'grad_norm': 6.406457901000977, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.011264439672231674, 'loss_2': 0.00392913818359375, 'loss_3': -16.174911499023438, 'loss_4': 1.3648624420166016, 'epoch': 11.93}
{'loss': 0.0105, 'grad_norm': 4.847754001617432, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.006442418787628412, 'loss_2': 0.0040435791015625, 'loss_3': -16.126686096191406, 'loss_4': 1.1627874374389648, 'epoch': 11.94}
{'loss': 0.0258, 'grad_norm': 13.309436798095703, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.024595441296696663, 'loss_2': 0.001209259033203125, 'loss_3': -16.283733367919922, 'loss_4': 1.4191293716430664, 'epoch': 11.94}
{'loss': 0.0151, 'grad_norm': 6.0302228927612305, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.012181621044874191, 'loss_2': 0.00286865234375, 'loss_3': -16.37212562561035, 'loss_4': 1.2980989217758179, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 13:11:16,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:16,534 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:10<53:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:23,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01648208126425743, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013268251903355122, 'eval_loss_2': 0.003213830292224884, 'eval_loss_3': -18.18619728088379, 'eval_loss_4': 1.166282296180725, 'epoch': 11.95}
{'loss': 0.0181, 'grad_norm': 5.96707010269165, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.012050587683916092, 'loss_2': 0.006038665771484375, 'loss_3': -16.3127498626709, 'loss_4': 1.2897895574569702, 'epoch': 11.95}
{'loss': 0.0173, 'grad_norm': 6.403122901916504, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.01040730345994234, 'loss_2': 0.0068511962890625, 'loss_3': -16.41757583618164, 'loss_4': 1.1069738864898682, 'epoch': 11.96}
{'loss': 0.0169, 'grad_norm': 7.5178961753845215, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.013388335704803467, 'loss_2': 0.003551483154296875, 'loss_3': -16.370346069335938, 'loss_4': 1.0650336742401123, 'epoch': 11.97}
{'loss': 0.0265, 'grad_norm': 18.29780387878418, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.023818960413336754, 'loss_2': 0.002719879150390625, 'loss_3': -16.199098587036133, 'loss_4': 0.8837471008300781, 'epoch': 11.97}
{'loss': 0.0181, 'grad_norm': 11.288061141967773, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.017813272774219513, 'loss_2': 0.0002758502960205078, 'loss_3': -16.137771606445312, 'loss_4': 0.9648988246917725, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 13:11:23,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:23,875 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:17<50:18,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 13:11:30,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016517482697963715, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.776, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012814218178391457, 'eval_loss_2': 0.0037032663822174072, 'eval_loss_3': -18.19842529296875, 'eval_loss_4': 0.9261672496795654, 'epoch': 11.98}
{'loss': 0.1003, 'grad_norm': 17.81037712097168, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.09935919940471649, 'loss_2': 0.0008955001831054688, 'loss_3': -16.04094696044922, 'loss_4': 1.0595979690551758, 'epoch': 11.98}
{'loss': 0.0199, 'grad_norm': 6.6515212059021, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.014475959353148937, 'loss_2': 0.00542449951171875, 'loss_3': -16.203758239746094, 'loss_4': 0.36692535877227783, 'epoch': 11.99}
{'loss': 0.0141, 'grad_norm': 5.256754398345947, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.009089690633118153, 'loss_2': 0.00496673583984375, 'loss_3': -16.172683715820312, 'loss_4': 1.0320351123809814, 'epoch': 11.99}
{'loss': 0.0355, 'grad_norm': 21.220090866088867, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.0222039632499218, 'loss_2': 0.0133209228515625, 'loss_3': -16.162555694580078, 'loss_4': 1.1251137256622314, 'epoch': 12.0}
{'loss': 0.0849, 'grad_norm': 17.10428810119629, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.07450298964977264, 'loss_2': 0.01035308837890625, 'loss_3': -16.40148162841797, 'loss_4': 1.1556072235107422, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 13:11:30,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:30,895 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:25<52:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:11:38,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01837156154215336, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013883450999855995, 'eval_loss_2': 0.004488110542297363, 'eval_loss_3': -18.198909759521484, 'eval_loss_4': 0.7249624133110046, 'epoch': 12.01}
{'loss': 0.0276, 'grad_norm': 7.519506931304932, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.017271900549530983, 'loss_2': 0.0103759765625, 'loss_3': -16.133174896240234, 'loss_4': 0.8008769750595093, 'epoch': 12.01}
{'loss': 0.0109, 'grad_norm': 5.096395015716553, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.009510280564427376, 'loss_2': 0.0013494491577148438, 'loss_3': -16.33566665649414, 'loss_4': 1.0305392742156982, 'epoch': 12.02}
{'loss': 0.0069, 'grad_norm': 5.165927886962891, 'learning_rate': 1.8e-05, 'loss_1': 0.006718182470649481, 'loss_2': 0.00020956993103027344, 'loss_3': -16.38655662536621, 'loss_4': 0.8505801558494568, 'epoch': 12.02}
{'loss': 0.0106, 'grad_norm': 7.559115409851074, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.010162965394556522, 'loss_2': 0.00045418739318847656, 'loss_3': -16.394407272338867, 'loss_4': 0.7210386991500854, 'epoch': 12.03}
{'loss': 0.0173, 'grad_norm': 6.4174604415893555, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.012974902987480164, 'loss_2': 0.004283905029296875, 'loss_3': -16.272111892700195, 'loss_4': 1.0362472534179688, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 13:11:38,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:38,235 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:32<53:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:45,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0164229366928339, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.608, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013101215474307537, 'eval_loss_2': 0.003321722149848938, 'eval_loss_3': -18.19919204711914, 'eval_loss_4': 0.8548760414123535, 'epoch': 12.03}
{'loss': 0.0233, 'grad_norm': 8.178791046142578, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.018370890989899635, 'loss_2': 0.00495147705078125, 'loss_3': -16.34093475341797, 'loss_4': 0.7426310181617737, 'epoch': 12.04}
{'loss': 0.0129, 'grad_norm': 6.507443904876709, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.01181658636778593, 'loss_2': 0.0010700225830078125, 'loss_3': -16.357877731323242, 'loss_4': 0.7735944390296936, 'epoch': 12.05}
{'loss': 0.0368, 'grad_norm': 30.019601821899414, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.03068573959171772, 'loss_2': 0.00609588623046875, 'loss_3': -16.394535064697266, 'loss_4': 1.29954195022583, 'epoch': 12.05}
{'loss': 0.0178, 'grad_norm': 7.251278877258301, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.014561725780367851, 'loss_2': 0.003246307373046875, 'loss_3': -16.094017028808594, 'loss_4': 1.1371344327926636, 'epoch': 12.06}
{'loss': 0.0181, 'grad_norm': 4.785109043121338, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.012143691070377827, 'loss_2': 0.00598907470703125, 'loss_3': -16.17420196533203, 'loss_4': 1.0229829549789429, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 13:11:45,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:45,576 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:39<53:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:52,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01805199682712555, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013079613447189331, 'eval_loss_2': 0.004972383379936218, 'eval_loss_3': -18.200550079345703, 'eval_loss_4': 0.9932994246482849, 'epoch': 12.06}
{'loss': 0.0236, 'grad_norm': 6.770527362823486, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.01524926908314228, 'loss_2': 0.00836181640625, 'loss_3': -16.262874603271484, 'loss_4': 0.8759672045707703, 'epoch': 12.07}
{'loss': 0.014, 'grad_norm': 6.061225891113281, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.012915844097733498, 'loss_2': 0.0010547637939453125, 'loss_3': -16.22028923034668, 'loss_4': 1.3343628644943237, 'epoch': 12.08}
{'loss': 0.0159, 'grad_norm': 7.178112506866455, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.012254484929144382, 'loss_2': 0.003681182861328125, 'loss_3': -16.166837692260742, 'loss_4': 1.066180944442749, 'epoch': 12.08}
{'loss': 0.0442, 'grad_norm': 18.038829803466797, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.03970295935869217, 'loss_2': 0.004520416259765625, 'loss_3': -16.28651237487793, 'loss_4': 1.4239529371261597, 'epoch': 12.09}
{'loss': 0.0187, 'grad_norm': 7.033146381378174, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.016268029808998108, 'loss_2': 0.002407073974609375, 'loss_3': -16.383808135986328, 'loss_4': 1.2457542419433594, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 13:11:52,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:52,920 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:47<53:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:00,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015553581528365612, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011924694292247295, 'eval_loss_2': 0.0036288872361183167, 'eval_loss_3': -18.19670867919922, 'eval_loss_4': 0.9570727944374084, 'epoch': 12.09}
{'loss': 0.013, 'grad_norm': 5.973992347717285, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.01097559928894043, 'loss_2': 0.00205230712890625, 'loss_3': -16.20726776123047, 'loss_4': 0.577232837677002, 'epoch': 12.1}
{'loss': 0.0196, 'grad_norm': 6.1924872398376465, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.011731534264981747, 'loss_2': 0.007904052734375, 'loss_3': -16.36733627319336, 'loss_4': 1.2226555347442627, 'epoch': 12.1}
{'loss': 0.0059, 'grad_norm': 4.911057472229004, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.0052072228863835335, 'loss_2': 0.0006866455078125, 'loss_3': -16.1318416595459, 'loss_4': 1.2280800342559814, 'epoch': 12.11}
{'loss': 0.0126, 'grad_norm': 5.283542156219482, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.00960505660623312, 'loss_2': 0.00302886962890625, 'loss_3': -16.16404914855957, 'loss_4': 1.2488744258880615, 'epoch': 12.12}
{'loss': 0.0138, 'grad_norm': 7.17618989944458, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.012881534174084663, 'loss_2': 0.0008702278137207031, 'loss_3': -16.30382537841797, 'loss_4': 1.104333519935608, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 13:12:00,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:00,253 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:54<53:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:07,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01839635707437992, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015034864656627178, 'eval_loss_2': 0.0033614933490753174, 'eval_loss_3': -18.173690795898438, 'eval_loss_4': 1.0210994482040405, 'epoch': 12.12}
{'loss': 0.0168, 'grad_norm': 5.826538562774658, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.012985613197088242, 'loss_2': 0.00377655029296875, 'loss_3': -16.306873321533203, 'loss_4': 0.8360471725463867, 'epoch': 12.13}
{'loss': 0.0179, 'grad_norm': 4.951783180236816, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.008337445557117462, 'loss_2': 0.00958251953125, 'loss_3': -16.283348083496094, 'loss_4': 1.2283437252044678, 'epoch': 12.13}
{'loss': 0.0136, 'grad_norm': 9.618607521057129, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.012451820075511932, 'loss_2': 0.0011692047119140625, 'loss_3': -16.328529357910156, 'loss_4': 1.0306217670440674, 'epoch': 12.14}
{'loss': 0.0152, 'grad_norm': 4.877092361450195, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.007599763572216034, 'loss_2': 0.00756072998046875, 'loss_3': -16.372005462646484, 'loss_4': 1.4344899654388428, 'epoch': 12.15}
{'loss': 0.0141, 'grad_norm': 5.504598617553711, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.009540137834846973, 'loss_2': 0.00457763671875, 'loss_3': -16.401283264160156, 'loss_4': 0.9326921105384827, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 13:12:07,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:07,592 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:01<53:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:14,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021686816588044167, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.018163688480854034, 'eval_loss_2': 0.003523126244544983, 'eval_loss_3': -18.158885955810547, 'eval_loss_4': 0.9979846477508545, 'epoch': 12.15}
{'loss': 0.0321, 'grad_norm': 7.669548511505127, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.02378254570066929, 'loss_2': 0.00833892822265625, 'loss_3': -16.28614616394043, 'loss_4': 1.6984021663665771, 'epoch': 12.16}
{'loss': 0.0285, 'grad_norm': 11.736438751220703, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.025723885744810104, 'loss_2': 0.002773284912109375, 'loss_3': -16.144227981567383, 'loss_4': 1.4076323509216309, 'epoch': 12.16}
{'loss': 0.0222, 'grad_norm': 8.074703216552734, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.01758739911019802, 'loss_2': 0.00457763671875, 'loss_3': -16.346641540527344, 'loss_4': 0.8030600547790527, 'epoch': 12.17}
{'loss': 0.0338, 'grad_norm': 13.33894157409668, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.02770555205643177, 'loss_2': 0.0061187744140625, 'loss_3': -16.197425842285156, 'loss_4': 0.7819281816482544, 'epoch': 12.17}
{'loss': 0.0114, 'grad_norm': 5.701416969299316, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.009868316352367401, 'loss_2': 0.00156402587890625, 'loss_3': -16.220802307128906, 'loss_4': 1.3329710960388184, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 13:12:14,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:14,934 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:09<52:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:22,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02322695404291153, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018098512664437294, 'eval_loss_2': 0.005128443241119385, 'eval_loss_3': -18.171396255493164, 'eval_loss_4': 0.6923306584358215, 'epoch': 12.18}
{'loss': 0.014, 'grad_norm': 5.654970169067383, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.009960198774933815, 'loss_2': 0.004009246826171875, 'loss_3': -16.31243324279785, 'loss_4': 0.6371468305587769, 'epoch': 12.19}
{'loss': 0.0162, 'grad_norm': 9.405061721801758, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.01103238109499216, 'loss_2': 0.0052032470703125, 'loss_3': -16.262672424316406, 'loss_4': 0.9673304557800293, 'epoch': 12.19}
{'loss': 0.0204, 'grad_norm': 5.399539470672607, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.010801197960972786, 'loss_2': 0.0095977783203125, 'loss_3': -16.321449279785156, 'loss_4': 1.1871854066848755, 'epoch': 12.2}
{'loss': 0.0361, 'grad_norm': 11.717909812927246, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.026532139629125595, 'loss_2': 0.009552001953125, 'loss_3': -16.305652618408203, 'loss_4': 0.3775497078895569, 'epoch': 12.2}
{'loss': 0.012, 'grad_norm': 4.988576889038086, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.007297044154256582, 'loss_2': 0.004669189453125, 'loss_3': -16.13259506225586, 'loss_4': 0.6581973433494568, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 13:12:22,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:22,271 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:16<52:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:29,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022241123020648956, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01889299601316452, 'eval_loss_2': 0.003348127007484436, 'eval_loss_3': -18.17365264892578, 'eval_loss_4': 0.6837191581726074, 'epoch': 12.21}
{'loss': 0.0093, 'grad_norm': 4.878032207489014, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.008370467461645603, 'loss_2': 0.0009374618530273438, 'loss_3': -16.179569244384766, 'loss_4': 0.6335266828536987, 'epoch': 12.22}
{'loss': 0.0114, 'grad_norm': 5.299746990203857, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.010475593619048595, 'loss_2': 0.0009469985961914062, 'loss_3': -16.35269546508789, 'loss_4': 0.8461028337478638, 'epoch': 12.22}
{'loss': 0.0084, 'grad_norm': 5.181600093841553, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.007008809596300125, 'loss_2': 0.0013580322265625, 'loss_3': -16.33243179321289, 'loss_4': 0.9184335470199585, 'epoch': 12.23}
{'loss': 0.0214, 'grad_norm': 6.9204792976379395, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.015051068738102913, 'loss_2': 0.00638580322265625, 'loss_3': -16.09896469116211, 'loss_4': 1.4112913608551025, 'epoch': 12.23}
{'loss': 0.0178, 'grad_norm': 9.400469779968262, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.014346913434565067, 'loss_2': 0.003498077392578125, 'loss_3': -16.242204666137695, 'loss_4': 0.8298757076263428, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 13:12:29,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:29,612 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:24<52:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:36,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024748239666223526, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.814, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02065676636993885, 'eval_loss_2': 0.004091475158929825, 'eval_loss_3': -18.19770622253418, 'eval_loss_4': 0.8329294919967651, 'epoch': 12.24}
{'loss': 0.0108, 'grad_norm': 4.971996784210205, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.008725208230316639, 'loss_2': 0.002105712890625, 'loss_3': -16.28630828857422, 'loss_4': 0.6971864104270935, 'epoch': 12.24}
{'loss': 0.0134, 'grad_norm': 4.38436222076416, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.006569533608853817, 'loss_2': 0.00678253173828125, 'loss_3': -16.144392013549805, 'loss_4': 0.8854858875274658, 'epoch': 12.25}
{'loss': 0.0219, 'grad_norm': 7.596070289611816, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.018730130046606064, 'loss_2': 0.0031280517578125, 'loss_3': -16.248151779174805, 'loss_4': 1.2361347675323486, 'epoch': 12.26}
{'loss': 0.0158, 'grad_norm': 5.416058540344238, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.013979976996779442, 'loss_2': 0.00177764892578125, 'loss_3': -16.415191650390625, 'loss_4': 1.4651284217834473, 'epoch': 12.26}
{'loss': 0.0119, 'grad_norm': 5.082391262054443, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.010539839044213295, 'loss_2': 0.00133514404296875, 'loss_3': -16.119441986083984, 'loss_4': 1.4631567001342773, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 13:12:36,967 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:36,967 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:31<52:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:44,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02407623454928398, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.02121610939502716, 'eval_loss_2': 0.002860128879547119, 'eval_loss_3': -18.21840476989746, 'eval_loss_4': 0.9650998711585999, 'epoch': 12.27}
{'loss': 0.008, 'grad_norm': 4.821108818054199, 'learning_rate': 1.775e-05, 'loss_1': 0.006216836627572775, 'loss_2': 0.001743316650390625, 'loss_3': -16.35866355895996, 'loss_4': 1.0468425750732422, 'epoch': 12.27}
{'loss': 0.0152, 'grad_norm': 6.902920722961426, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.010891136713325977, 'loss_2': 0.004302978515625, 'loss_3': -16.311355590820312, 'loss_4': 0.7103949785232544, 'epoch': 12.28}
{'loss': 0.0197, 'grad_norm': 5.9760589599609375, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.013940319418907166, 'loss_2': 0.00576019287109375, 'loss_3': -16.24990463256836, 'loss_4': 1.2256803512573242, 'epoch': 12.28}
{'loss': 0.0305, 'grad_norm': 12.686838150024414, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.029341695830225945, 'loss_2': 0.0011892318725585938, 'loss_3': -16.12643051147461, 'loss_4': 1.1907018423080444, 'epoch': 12.29}
{'loss': 0.0087, 'grad_norm': 5.403937816619873, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.005623313598334789, 'loss_2': 0.003101348876953125, 'loss_3': -16.069887161254883, 'loss_4': 1.0747630596160889, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 13:12:44,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:44,306 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:38<52:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:51,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02227170020341873, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.019398977980017662, 'eval_loss_2': 0.0028727203607559204, 'eval_loss_3': -18.194528579711914, 'eval_loss_4': 0.9680969715118408, 'epoch': 12.3}
{'loss': 0.0162, 'grad_norm': 5.597105503082275, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.011212381534278393, 'loss_2': 0.00498199462890625, 'loss_3': -16.331819534301758, 'loss_4': 0.8160364627838135, 'epoch': 12.3}
{'loss': 0.0109, 'grad_norm': 5.080909252166748, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.009244844317436218, 'loss_2': 0.001659393310546875, 'loss_3': -16.449989318847656, 'loss_4': 0.9232827425003052, 'epoch': 12.31}
{'loss': 0.1107, 'grad_norm': 27.294458389282227, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.10518237203359604, 'loss_2': 0.0054779052734375, 'loss_3': -16.182870864868164, 'loss_4': 0.8930879831314087, 'epoch': 12.31}
{'loss': 0.0231, 'grad_norm': 5.840351104736328, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.014848431572318077, 'loss_2': 0.00830078125, 'loss_3': -16.388185501098633, 'loss_4': 0.8014840483665466, 'epoch': 12.32}
{'loss': 0.0208, 'grad_norm': 7.560340404510498, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.01858360320329666, 'loss_2': 0.0021762847900390625, 'loss_3': -16.23497200012207, 'loss_4': 1.0941205024719238, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 13:12:51,644 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:51,644 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:46<52:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:58,983 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021387068554759026, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01821097731590271, 'eval_loss_2': 0.003176093101501465, 'eval_loss_3': -18.185110092163086, 'eval_loss_4': 0.5677838325500488, 'epoch': 12.33}
{'loss': 0.0174, 'grad_norm': 5.517430782318115, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.011184543371200562, 'loss_2': 0.0062408447265625, 'loss_3': -16.148115158081055, 'loss_4': 0.7252376079559326, 'epoch': 12.33}
{'loss': 0.0122, 'grad_norm': 5.8166823387146, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.011075576767325401, 'loss_2': 0.0010833740234375, 'loss_3': -16.09762954711914, 'loss_4': 0.2097049206495285, 'epoch': 12.34}
{'loss': 0.0262, 'grad_norm': 8.844964981079102, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.019343487918376923, 'loss_2': 0.006900787353515625, 'loss_3': -16.259056091308594, 'loss_4': 0.45480769872665405, 'epoch': 12.34}
{'loss': 0.0147, 'grad_norm': 6.018888473510742, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.013360445387661457, 'loss_2': 0.0013256072998046875, 'loss_3': -16.340845108032227, 'loss_4': 0.5392613410949707, 'epoch': 12.35}
{'loss': 0.0125, 'grad_norm': 4.880208969116211, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.008030072785913944, 'loss_2': 0.004505157470703125, 'loss_3': -16.19900131225586, 'loss_4': 0.6127228140830994, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 13:12:58,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:58,983 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:53<52:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:06,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024262607097625732, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.561, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019976690411567688, 'eval_loss_2': 0.004285916686058044, 'eval_loss_3': -18.20882797241211, 'eval_loss_4': 0.4842865467071533, 'epoch': 12.35}
{'loss': 0.0411, 'grad_norm': 15.489799499511719, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.035722095519304276, 'loss_2': 0.0054168701171875, 'loss_3': -16.165740966796875, 'loss_4': 0.5005124807357788, 'epoch': 12.36}
{'loss': 0.0136, 'grad_norm': 5.19679594039917, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.012261398136615753, 'loss_2': 0.001361846923828125, 'loss_3': -16.176185607910156, 'loss_4': 0.24570095539093018, 'epoch': 12.37}
{'loss': 0.0123, 'grad_norm': 4.848745822906494, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.007025489583611488, 'loss_2': 0.005245208740234375, 'loss_3': -16.458097457885742, 'loss_4': 0.49573907256126404, 'epoch': 12.37}
{'loss': 0.0119, 'grad_norm': 5.610293865203857, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.0083408048376441, 'loss_2': 0.0035858154296875, 'loss_3': -16.27383041381836, 'loss_4': 0.7254406213760376, 'epoch': 12.38}
{'loss': 0.0187, 'grad_norm': 5.627541542053223, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.014847541227936745, 'loss_2': 0.003871917724609375, 'loss_3': -16.3974552154541, 'loss_4': 0.8660165071487427, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 13:13:06,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:06,332 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [53:00<52:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:13,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023700252175331116, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.774, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.021077800542116165, 'eval_loss_2': 0.002622455358505249, 'eval_loss_3': -18.202377319335938, 'eval_loss_4': 0.5288112759590149, 'epoch': 12.38}
{'loss': 0.0169, 'grad_norm': 5.097485542297363, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.009794888086616993, 'loss_2': 0.007080078125, 'loss_3': -16.305410385131836, 'loss_4': 0.8410800695419312, 'epoch': 12.39}
{'loss': 0.0161, 'grad_norm': 6.3641533851623535, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.01326075755059719, 'loss_2': 0.0028839111328125, 'loss_3': -16.208263397216797, 'loss_4': -0.0033267363905906677, 'epoch': 12.4}
{'loss': 0.0119, 'grad_norm': 5.1569647789001465, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.009709923528134823, 'loss_2': 0.00215911865234375, 'loss_3': -16.24599838256836, 'loss_4': 0.41162362694740295, 'epoch': 12.4}
{'loss': 0.0179, 'grad_norm': 6.5852813720703125, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.014927221462130547, 'loss_2': 0.0029926300048828125, 'loss_3': -16.32135009765625, 'loss_4': 0.8093374967575073, 'epoch': 12.41}
{'loss': 0.0098, 'grad_norm': 5.042135715484619, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.007935553789138794, 'loss_2': 0.0018634796142578125, 'loss_3': -16.47146224975586, 'loss_4': 0.08778481185436249, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 13:13:13,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:13,684 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:08<52:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:21,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024159515276551247, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.020665526390075684, 'eval_loss_2': 0.003493987023830414, 'eval_loss_3': -18.191654205322266, 'eval_loss_4': 0.547189474105835, 'epoch': 12.41}
{'loss': 0.0183, 'grad_norm': 6.966160774230957, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.015461355447769165, 'loss_2': 0.00279998779296875, 'loss_3': -16.043018341064453, 'loss_4': 0.5403046607971191, 'epoch': 12.42}
{'loss': 0.0162, 'grad_norm': 6.754448890686035, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.014459683559834957, 'loss_2': 0.0017747879028320312, 'loss_3': -16.163578033447266, 'loss_4': 0.869382917881012, 'epoch': 12.42}
{'loss': 0.0221, 'grad_norm': 6.149852275848389, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.012644156813621521, 'loss_2': 0.00946807861328125, 'loss_3': -16.126617431640625, 'loss_4': 0.8570764660835266, 'epoch': 12.43}
{'loss': 0.0226, 'grad_norm': 6.403989315032959, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.010141395032405853, 'loss_2': 0.012481689453125, 'loss_3': -15.952801704406738, 'loss_4': 0.623967170715332, 'epoch': 12.44}
{'loss': 0.0102, 'grad_norm': 5.116788387298584, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.008164403960108757, 'loss_2': 0.0020236968994140625, 'loss_3': -16.152812957763672, 'loss_4': 0.9327327013015747, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 13:13:21,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:21,026 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:15<52:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:28,365 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027289774268865585, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.020769773051142693, 'eval_loss_2': 0.006520003080368042, 'eval_loss_3': -18.189069747924805, 'eval_loss_4': 0.683620274066925, 'epoch': 12.44}
{'loss': 0.0187, 'grad_norm': 9.608445167541504, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.018520142883062363, 'loss_2': 0.0002002716064453125, 'loss_3': -16.130416870117188, 'loss_4': 0.6845611333847046, 'epoch': 12.45}
{'loss': 0.0158, 'grad_norm': 5.833542346954346, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.011836636811494827, 'loss_2': 0.00396728515625, 'loss_3': -16.2703914642334, 'loss_4': 0.6761941909790039, 'epoch': 12.45}
{'loss': 0.061, 'grad_norm': 16.10578727722168, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.05650639533996582, 'loss_2': 0.0044708251953125, 'loss_3': -16.032447814941406, 'loss_4': 0.7488733530044556, 'epoch': 12.46}
{'loss': 0.0132, 'grad_norm': 5.241063594818115, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.012850881554186344, 'loss_2': 0.0003447532653808594, 'loss_3': -16.297086715698242, 'loss_4': 1.004658818244934, 'epoch': 12.47}
{'loss': 0.0255, 'grad_norm': 7.737960338592529, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.02039233036339283, 'loss_2': 0.0051422119140625, 'loss_3': -16.2182674407959, 'loss_4': 1.189746379852295, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 13:13:28,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:28,365 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:22<52:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:35,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023650353774428368, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.020730363205075264, 'eval_loss_2': 0.002919994294643402, 'eval_loss_3': -18.19481086730957, 'eval_loss_4': 0.712392270565033, 'epoch': 12.47}
{'loss': 0.0135, 'grad_norm': 5.603600978851318, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.012752341106534004, 'loss_2': 0.0007219314575195312, 'loss_3': -16.30924415588379, 'loss_4': 0.9455429911613464, 'epoch': 12.48}
{'loss': 0.0083, 'grad_norm': 4.675114154815674, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.008218764327466488, 'loss_2': 4.1484832763671875e-05, 'loss_3': -16.135705947875977, 'loss_4': 0.9633017182350159, 'epoch': 12.48}
{'loss': 0.0199, 'grad_norm': 5.8667426109313965, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.012133890762925148, 'loss_2': 0.00775909423828125, 'loss_3': -16.24897003173828, 'loss_4': 0.7358639240264893, 'epoch': 12.49}
{'loss': 0.0228, 'grad_norm': 11.55777359008789, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.019888559356331825, 'loss_2': 0.00287628173828125, 'loss_3': -15.945206642150879, 'loss_4': 1.08873450756073, 'epoch': 12.49}
{'loss': 0.0082, 'grad_norm': 4.4115777015686035, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.006263342685997486, 'loss_2': 0.0019741058349609375, 'loss_3': -16.320568084716797, 'loss_4': 0.6222202777862549, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 13:13:35,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:35,711 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:30<51:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:43,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02335165999829769, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.791, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0197813231498003, 'eval_loss_2': 0.0035703331232070923, 'eval_loss_3': -18.238666534423828, 'eval_loss_4': 0.6867808103561401, 'epoch': 12.5}
{'loss': 0.0166, 'grad_norm': 4.857875347137451, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.009272624738514423, 'loss_2': 0.007335662841796875, 'loss_3': -16.235301971435547, 'loss_4': 1.1679730415344238, 'epoch': 12.51}
{'loss': 0.0285, 'grad_norm': 10.232781410217285, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.02676805481314659, 'loss_2': 0.0017690658569335938, 'loss_3': -16.332931518554688, 'loss_4': 0.46759092807769775, 'epoch': 12.51}
{'loss': 0.015, 'grad_norm': 6.327478885650635, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.012873472645878792, 'loss_2': 0.002086639404296875, 'loss_3': -16.30236053466797, 'loss_4': 0.7618675231933594, 'epoch': 12.52}
{'loss': 0.016, 'grad_norm': 5.026538372039795, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.011483464390039444, 'loss_2': 0.0045318603515625, 'loss_3': -16.167436599731445, 'loss_4': 0.24930340051651, 'epoch': 12.52}
{'loss': 0.014, 'grad_norm': 5.282865047454834, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.011042440310120583, 'loss_2': 0.002964019775390625, 'loss_3': -16.30445098876953, 'loss_4': 0.7354440689086914, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 13:13:43,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:43,044 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:37<51:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:50,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025077009573578835, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020566722378134727, 'eval_loss_2': 0.004510283470153809, 'eval_loss_3': -18.205345153808594, 'eval_loss_4': 0.6745657324790955, 'epoch': 12.53}
{'loss': 0.0184, 'grad_norm': 9.229066848754883, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.015544596128165722, 'loss_2': 0.002880096435546875, 'loss_3': -16.1329288482666, 'loss_4': 0.874401330947876, 'epoch': 12.53}
{'loss': 0.0194, 'grad_norm': 5.508021354675293, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.017145667225122452, 'loss_2': 0.002269744873046875, 'loss_3': -16.51258087158203, 'loss_4': 0.44234350323677063, 'epoch': 12.54}
{'loss': 0.0111, 'grad_norm': 5.322575092315674, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.008921563625335693, 'loss_2': 0.0021820068359375, 'loss_3': -16.392940521240234, 'loss_4': 0.861580491065979, 'epoch': 12.55}
{'loss': 0.0117, 'grad_norm': 4.880466461181641, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.007597104646265507, 'loss_2': 0.004085540771484375, 'loss_3': -16.183025360107422, 'loss_4': 0.6319352388381958, 'epoch': 12.55}
{'loss': 0.0322, 'grad_norm': 7.121974945068359, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.019188400357961655, 'loss_2': 0.013031005859375, 'loss_3': -16.21677017211914, 'loss_4': 0.6502233743667603, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 13:13:50,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:50,383 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:44<51:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:57,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02804551273584366, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.571, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.023045159876346588, 'eval_loss_2': 0.00500035285949707, 'eval_loss_3': -18.18277359008789, 'eval_loss_4': 0.5923604965209961, 'epoch': 12.56}
{'loss': 0.0162, 'grad_norm': 5.8055877685546875, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.012652859091758728, 'loss_2': 0.0035858154296875, 'loss_3': -16.18320083618164, 'loss_4': 0.37603095173835754, 'epoch': 12.56}
{'loss': 0.0271, 'grad_norm': 9.924810409545898, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.022938521578907967, 'loss_2': 0.00421142578125, 'loss_3': -16.31085968017578, 'loss_4': 0.6144136786460876, 'epoch': 12.57}
{'loss': 0.0096, 'grad_norm': 4.607715129852295, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.007786532863974571, 'loss_2': 0.0018520355224609375, 'loss_3': -16.557449340820312, 'loss_4': -0.027350492775440216, 'epoch': 12.58}
{'loss': 0.0285, 'grad_norm': 9.153738975524902, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.021253552287817, 'loss_2': 0.00724029541015625, 'loss_3': -16.22590446472168, 'loss_4': 0.8364211916923523, 'epoch': 12.58}
{'loss': 0.0204, 'grad_norm': 5.799314022064209, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.01183091476559639, 'loss_2': 0.00856781005859375, 'loss_3': -16.46084976196289, 'loss_4': 1.3824472427368164, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 13:13:57,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:57,721 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:52<51:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:05,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032087408006191254, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.599, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0251901987940073, 'eval_loss_2': 0.0068972110748291016, 'eval_loss_3': -18.18090057373047, 'eval_loss_4': 0.6697995066642761, 'epoch': 12.59}
{'loss': 0.0291, 'grad_norm': 11.834997177124023, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.027139700949192047, 'loss_2': 0.001979827880859375, 'loss_3': -16.26272201538086, 'loss_4': 0.8460946083068848, 'epoch': 12.59}
{'loss': 0.0269, 'grad_norm': 6.532667636871338, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.019921183586120605, 'loss_2': 0.006988525390625, 'loss_3': -16.5906925201416, 'loss_4': 1.1482150554656982, 'epoch': 12.6}
{'loss': 0.0191, 'grad_norm': 5.30566930770874, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.010207660496234894, 'loss_2': 0.0089111328125, 'loss_3': -16.475730895996094, 'loss_4': 0.6126450300216675, 'epoch': 12.6}
{'loss': 0.0152, 'grad_norm': 5.768093109130859, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.010205020196735859, 'loss_2': 0.004974365234375, 'loss_3': -16.30264663696289, 'loss_4': 0.7046172618865967, 'epoch': 12.61}
{'loss': 0.0167, 'grad_norm': 5.243932247161865, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.016067370772361755, 'loss_2': 0.000598907470703125, 'loss_3': -16.33195686340332, 'loss_4': 1.2958998680114746, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 13:14:05,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:05,059 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:59<51:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:12,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03035583160817623, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02601846307516098, 'eval_loss_2': 0.0043373703956604, 'eval_loss_3': -18.16194725036621, 'eval_loss_4': 0.5766609907150269, 'epoch': 12.62}
{'loss': 0.0161, 'grad_norm': 7.0141987800598145, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.01338203065097332, 'loss_2': 0.0027294158935546875, 'loss_3': -16.22290802001953, 'loss_4': 1.1427135467529297, 'epoch': 12.62}
{'loss': 0.0369, 'grad_norm': 12.876754760742188, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.028833314776420593, 'loss_2': 0.0081024169921875, 'loss_3': -16.293445587158203, 'loss_4': 0.6581231951713562, 'epoch': 12.63}
{'loss': 0.0107, 'grad_norm': 4.59199333190918, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.00763299223035574, 'loss_2': 0.0030975341796875, 'loss_3': -16.237953186035156, 'loss_4': 0.5009586811065674, 'epoch': 12.63}
{'loss': 0.0217, 'grad_norm': 6.4882893562316895, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.018375085666775703, 'loss_2': 0.0032749176025390625, 'loss_3': -16.381227493286133, 'loss_4': 0.719082236289978, 'epoch': 12.64}
{'loss': 0.0148, 'grad_norm': 6.530365943908691, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.010692745447158813, 'loss_2': 0.00412750244140625, 'loss_3': -16.348745346069336, 'loss_4': 0.1320144087076187, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 13:14:12,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:12,392 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [54:06<51:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:14:19,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03196072578430176, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.745, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02758195996284485, 'eval_loss_2': 0.004378758370876312, 'eval_loss_3': -18.13038444519043, 'eval_loss_4': 0.37497854232788086, 'epoch': 12.65}
{'loss': 0.0283, 'grad_norm': 10.501709938049316, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.02570662833750248, 'loss_2': 0.002597808837890625, 'loss_3': -16.41620635986328, 'loss_4': 0.45037296414375305, 'epoch': 12.65}
{'loss': 0.0165, 'grad_norm': 5.436482906341553, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.010533071123063564, 'loss_2': 0.0059661865234375, 'loss_3': -16.089550018310547, 'loss_4': 0.5093422532081604, 'epoch': 12.66}
{'loss': 0.022, 'grad_norm': 13.679097175598145, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.02173229306936264, 'loss_2': 0.0002779960632324219, 'loss_3': -16.124004364013672, 'loss_4': 0.12241725623607635, 'epoch': 12.66}
{'loss': 0.0218, 'grad_norm': 6.713490962982178, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.01578509248793125, 'loss_2': 0.0059661865234375, 'loss_3': -16.274131774902344, 'loss_4': -0.2642732560634613, 'epoch': 12.67}
{'loss': 0.0159, 'grad_norm': 4.900996208190918, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.010271693579852581, 'loss_2': 0.005619049072265625, 'loss_3': -16.408889770507812, 'loss_4': -0.24112266302108765, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 13:14:19,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:19,719 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:14<51:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:27,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03386199474334717, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.83, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.029353080317378044, 'eval_loss_2': 0.0045089200139045715, 'eval_loss_3': -18.120054244995117, 'eval_loss_4': 0.1671529859304428, 'epoch': 12.67}
{'loss': 0.0135, 'grad_norm': 4.851339340209961, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.009766423143446445, 'loss_2': 0.0037689208984375, 'loss_3': -16.404163360595703, 'loss_4': -0.34153950214385986, 'epoch': 12.68}
{'loss': 0.0145, 'grad_norm': 7.098259925842285, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.01316134724766016, 'loss_2': 0.00128936767578125, 'loss_3': -16.26473045349121, 'loss_4': 0.007347557693719864, 'epoch': 12.69}
{'loss': 0.0166, 'grad_norm': 7.1732306480407715, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.015594074502587318, 'loss_2': 0.000995635986328125, 'loss_3': -16.177589416503906, 'loss_4': 0.376544713973999, 'epoch': 12.69}
{'loss': 0.0168, 'grad_norm': 4.829958915710449, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.00941226165741682, 'loss_2': 0.007415771484375, 'loss_3': -16.26378631591797, 'loss_4': 0.3545222878456116, 'epoch': 12.7}
{'loss': 0.0211, 'grad_norm': 9.14085578918457, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.017790982499718666, 'loss_2': 0.0032958984375, 'loss_3': -16.375356674194336, 'loss_4': 0.10243650525808334, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 13:14:27,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:27,049 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:21<51:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:34,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037851158529520035, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03481525927782059, 'eval_loss_2': 0.0030358992516994476, 'eval_loss_3': -18.10221290588379, 'eval_loss_4': 0.309671550989151, 'epoch': 12.7}
{'loss': 0.0203, 'grad_norm': 10.973114013671875, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.018076932057738304, 'loss_2': 0.0022258758544921875, 'loss_3': -16.48283576965332, 'loss_4': 0.5099459886550903, 'epoch': 12.71}
{'loss': 0.0145, 'grad_norm': 5.5216875076293945, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.01260374579578638, 'loss_2': 0.0018939971923828125, 'loss_3': -16.084659576416016, 'loss_4': 0.6547620892524719, 'epoch': 12.72}
{'loss': 0.0111, 'grad_norm': 5.100644111633301, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.007716617546975613, 'loss_2': 0.003398895263671875, 'loss_3': -16.37814712524414, 'loss_4': 0.48837822675704956, 'epoch': 12.72}
{'loss': 0.0203, 'grad_norm': 6.4100189208984375, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.016915980726480484, 'loss_2': 0.00334930419921875, 'loss_3': -16.295364379882812, 'loss_4': 0.3156091272830963, 'epoch': 12.73}
{'loss': 0.013, 'grad_norm': 10.850875854492188, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.011689087375998497, 'loss_2': 0.0013303756713867188, 'loss_3': -16.266036987304688, 'loss_4': -0.3721282482147217, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 13:14:34,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:34,389 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:28<51:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:14:41,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0344143807888031, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.031950872391462326, 'eval_loss_2': 0.002463504672050476, 'eval_loss_3': -18.116483688354492, 'eval_loss_4': 0.4547797739505768, 'epoch': 12.73}
{'loss': 0.0641, 'grad_norm': 17.15945816040039, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.062489304691553116, 'loss_2': 0.00164794921875, 'loss_3': -16.264001846313477, 'loss_4': 0.6280367374420166, 'epoch': 12.74}
{'loss': 0.0542, 'grad_norm': 18.502479553222656, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.0528196282684803, 'loss_2': 0.001354217529296875, 'loss_3': -16.2630615234375, 'loss_4': 0.961679220199585, 'epoch': 12.74}
{'loss': 0.0123, 'grad_norm': 5.672380447387695, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.009906264953315258, 'loss_2': 0.002410888671875, 'loss_3': -16.30543327331543, 'loss_4': 0.6593917608261108, 'epoch': 12.75}
{'loss': 0.0235, 'grad_norm': 7.476639270782471, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.018834758549928665, 'loss_2': 0.0046234130859375, 'loss_3': -16.35269546508789, 'loss_4': 0.7841570973396301, 'epoch': 12.76}
{'loss': 0.0208, 'grad_norm': 6.258162021636963, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.014104894362390041, 'loss_2': 0.00670623779296875, 'loss_3': -16.287479400634766, 'loss_4': 0.66733318567276, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 13:14:41,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:41,713 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:36<51:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:49,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02835064008831978, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.543, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.024284319952130318, 'eval_loss_2': 0.0040663182735443115, 'eval_loss_3': -18.15198516845703, 'eval_loss_4': 0.5889092683792114, 'epoch': 12.76}
{'loss': 0.0099, 'grad_norm': 5.0462517738342285, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.007499472703784704, 'loss_2': 0.002361297607421875, 'loss_3': -16.23645782470703, 'loss_4': 0.3396624028682709, 'epoch': 12.77}
{'loss': 0.0129, 'grad_norm': 5.298399925231934, 'learning_rate': 1.725e-05, 'loss_1': 0.009553277865052223, 'loss_2': 0.003387451171875, 'loss_3': -16.308656692504883, 'loss_4': 0.5577437281608582, 'epoch': 12.77}
{'loss': 0.0138, 'grad_norm': 5.070329189300537, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.010256338864564896, 'loss_2': 0.003559112548828125, 'loss_3': -16.579540252685547, 'loss_4': 0.8308029174804688, 'epoch': 12.78}
{'loss': 0.0821, 'grad_norm': 13.46865177154541, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.0795767605304718, 'loss_2': 0.0025463104248046875, 'loss_3': -16.312114715576172, 'loss_4': 0.5602542161941528, 'epoch': 12.78}
{'loss': 0.0205, 'grad_norm': 6.987057685852051, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.01800459995865822, 'loss_2': 0.0024871826171875, 'loss_3': -16.173908233642578, 'loss_4': 0.8333041071891785, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 13:14:49,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:49,052 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:43<51:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:56,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026305660605430603, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.704, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.022391662001609802, 'eval_loss_2': 0.003913998603820801, 'eval_loss_3': -18.157114028930664, 'eval_loss_4': 0.6167481541633606, 'epoch': 12.79}
{'loss': 0.0156, 'grad_norm': 6.059109210968018, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.01505805179476738, 'loss_2': 0.000579833984375, 'loss_3': -16.21951675415039, 'loss_4': 1.0617581605911255, 'epoch': 12.8}
{'loss': 0.0131, 'grad_norm': 5.980291843414307, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.011934897862374783, 'loss_2': 0.0011835098266601562, 'loss_3': -16.343032836914062, 'loss_4': 1.176788568496704, 'epoch': 12.8}
{'loss': 0.0142, 'grad_norm': 5.523879051208496, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.008687968365848064, 'loss_2': 0.005496978759765625, 'loss_3': -16.39640998840332, 'loss_4': 0.9024531841278076, 'epoch': 12.81}
{'loss': 0.0278, 'grad_norm': 8.443243026733398, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.02015143632888794, 'loss_2': 0.007659912109375, 'loss_3': -16.314685821533203, 'loss_4': 0.49325358867645264, 'epoch': 12.81}
{'loss': 0.0124, 'grad_norm': 6.962422847747803, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.008850517682731152, 'loss_2': 0.003589630126953125, 'loss_3': -16.15273666381836, 'loss_4': 0.7675033211708069, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 13:14:56,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:56,389 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:50<50:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:03,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0248424019664526, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.020555665716528893, 'eval_loss_2': 0.004286736249923706, 'eval_loss_3': -18.173574447631836, 'eval_loss_4': 0.46039217710494995, 'epoch': 12.82}
{'loss': 0.0258, 'grad_norm': 15.06686019897461, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.02140757627785206, 'loss_2': 0.0044403076171875, 'loss_3': -16.10148811340332, 'loss_4': 0.5540684461593628, 'epoch': 12.83}
{'loss': 0.0198, 'grad_norm': 6.949364185333252, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.014136528596282005, 'loss_2': 0.00566864013671875, 'loss_3': -16.427444458007812, 'loss_4': 0.5160173773765564, 'epoch': 12.83}
{'loss': 0.0121, 'grad_norm': 5.436887741088867, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.008066785521805286, 'loss_2': 0.00403594970703125, 'loss_3': -16.34095001220703, 'loss_4': 0.01162700355052948, 'epoch': 12.84}
{'loss': 0.0109, 'grad_norm': 4.708588123321533, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.006200657691806555, 'loss_2': 0.004650115966796875, 'loss_3': -16.480613708496094, 'loss_4': 0.8233727812767029, 'epoch': 12.84}
{'loss': 0.0115, 'grad_norm': 8.655965805053711, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.010441365651786327, 'loss_2': 0.0010356903076171875, 'loss_3': -16.44508171081543, 'loss_4': 0.7996940612792969, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 13:15:03,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:03,728 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:58<50:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:11,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023687900975346565, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.608, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019301505759358406, 'eval_loss_2': 0.004386395215988159, 'eval_loss_3': -18.216588973999023, 'eval_loss_4': 0.4017566442489624, 'epoch': 12.85}
{'loss': 0.0187, 'grad_norm': 5.066462993621826, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.009155773557722569, 'loss_2': 0.00951385498046875, 'loss_3': -16.316341400146484, 'loss_4': 0.17670300602912903, 'epoch': 12.85}
{'loss': 0.0086, 'grad_norm': 5.049332141876221, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.006431553512811661, 'loss_2': 0.00215911865234375, 'loss_3': -16.14056396484375, 'loss_4': 0.3930370807647705, 'epoch': 12.86}
{'loss': 0.0073, 'grad_norm': 4.786474704742432, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.006025739014148712, 'loss_2': 0.0012760162353515625, 'loss_3': -16.24359893798828, 'loss_4': 1.0050885677337646, 'epoch': 12.87}
{'loss': 0.0127, 'grad_norm': 5.145053863525391, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.00913301296532154, 'loss_2': 0.003570556640625, 'loss_3': -16.451976776123047, 'loss_4': 0.4723295569419861, 'epoch': 12.87}
{'loss': 0.0193, 'grad_norm': 6.591746807098389, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.011341285891830921, 'loss_2': 0.00791168212890625, 'loss_3': -16.35348129272461, 'loss_4': 0.954039454460144, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 13:15:11,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:11,072 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [55:05<50:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:18,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021770669147372246, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0184017401188612, 'eval_loss_2': 0.003368925303220749, 'eval_loss_3': -18.262632369995117, 'eval_loss_4': 0.5080530643463135, 'epoch': 12.88}
{'loss': 0.0137, 'grad_norm': 5.852806091308594, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.01045334991067648, 'loss_2': 0.00323486328125, 'loss_3': -16.399343490600586, 'loss_4': 0.5570288896560669, 'epoch': 12.88}
{'loss': 0.0207, 'grad_norm': 9.442286491394043, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.020383771508932114, 'loss_2': 0.00034999847412109375, 'loss_3': -16.236038208007812, 'loss_4': 0.9367771148681641, 'epoch': 12.89}
{'loss': 0.0118, 'grad_norm': 5.77734375, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.009309536777436733, 'loss_2': 0.00249481201171875, 'loss_3': -16.31169319152832, 'loss_4': 1.1970829963684082, 'epoch': 12.9}
{'loss': 0.0102, 'grad_norm': 5.040492057800293, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.0066677238792181015, 'loss_2': 0.00356292724609375, 'loss_3': -16.346675872802734, 'loss_4': 0.8408598899841309, 'epoch': 12.9}
{'loss': 0.0242, 'grad_norm': 7.84627103805542, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.015397857874631882, 'loss_2': 0.00876617431640625, 'loss_3': -16.32406997680664, 'loss_4': 0.7863025665283203, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 13:15:18,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:18,423 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:12<50:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:25,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021436529234051704, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.835, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018149033188819885, 'eval_loss_2': 0.00328749418258667, 'eval_loss_3': -18.262252807617188, 'eval_loss_4': 0.5227163434028625, 'epoch': 12.91}
{'loss': 0.0195, 'grad_norm': 6.818643093109131, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.013246375136077404, 'loss_2': 0.006214141845703125, 'loss_3': -16.270526885986328, 'loss_4': 0.6796633005142212, 'epoch': 12.91}
{'loss': 0.0145, 'grad_norm': 9.36755084991455, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.014028720557689667, 'loss_2': 0.000514984130859375, 'loss_3': -16.576099395751953, 'loss_4': 0.5538191795349121, 'epoch': 12.92}
{'loss': 0.0142, 'grad_norm': 4.9345808029174805, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.0070920679718256, 'loss_2': 0.00714874267578125, 'loss_3': -16.276540756225586, 'loss_4': 0.5914453268051147, 'epoch': 12.92}
{'loss': 0.0246, 'grad_norm': 13.080543518066406, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.01984289102256298, 'loss_2': 0.0047607421875, 'loss_3': -16.357107162475586, 'loss_4': 0.5393147468566895, 'epoch': 12.93}
{'loss': 0.0091, 'grad_norm': 6.613296985626221, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.008192820474505424, 'loss_2': 0.0009431838989257812, 'loss_3': -16.4564151763916, 'loss_4': 0.6743156909942627, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 13:15:25,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:25,754 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:20<50:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:33,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025653701275587082, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.977, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02113511599600315, 'eval_loss_2': 0.004518583416938782, 'eval_loss_3': -18.215866088867188, 'eval_loss_4': 0.5156387090682983, 'epoch': 12.94}
{'loss': 0.0541, 'grad_norm': 12.686172485351562, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.051078930497169495, 'loss_2': 0.0029773712158203125, 'loss_3': -16.482248306274414, 'loss_4': 0.4728931784629822, 'epoch': 12.94}
{'loss': 0.0354, 'grad_norm': 9.993574142456055, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.02543049305677414, 'loss_2': 0.0099334716796875, 'loss_3': -16.194162368774414, 'loss_4': 0.4722249507904053, 'epoch': 12.95}
{'loss': 0.0143, 'grad_norm': 4.863224029541016, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.009181858040392399, 'loss_2': 0.0050811767578125, 'loss_3': -16.38481903076172, 'loss_4': 0.8071715831756592, 'epoch': 12.95}
{'loss': 0.0174, 'grad_norm': 7.535749912261963, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.01373328547924757, 'loss_2': 0.0036220550537109375, 'loss_3': -16.19971466064453, 'loss_4': 0.34736186265945435, 'epoch': 12.96}
{'loss': 0.0129, 'grad_norm': 7.329593658447266, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.010819295421242714, 'loss_2': 0.0020751953125, 'loss_3': -16.393848419189453, 'loss_4': 0.17138344049453735, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 13:15:33,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:33,084 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:27<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:15:40,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02496163547039032, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.664, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021218791604042053, 'eval_loss_2': 0.0037428438663482666, 'eval_loss_3': -18.184972763061523, 'eval_loss_4': 0.4716169536113739, 'epoch': 12.97}
{'loss': 0.033, 'grad_norm': 17.032350540161133, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.03215843439102173, 'loss_2': 0.0008840560913085938, 'loss_3': -16.434280395507812, 'loss_4': 0.4188086986541748, 'epoch': 12.97}
{'loss': 0.0224, 'grad_norm': 10.324874877929688, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.01641729660332203, 'loss_2': 0.005950927734375, 'loss_3': -16.569440841674805, 'loss_4': 0.7609546780586243, 'epoch': 12.98}
{'loss': 0.0199, 'grad_norm': 10.456229209899902, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.01676180213689804, 'loss_2': 0.003139495849609375, 'loss_3': -16.26116371154785, 'loss_4': 0.44722995162010193, 'epoch': 12.98}
{'loss': 0.0192, 'grad_norm': 8.186563491821289, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.015207174234092236, 'loss_2': 0.0039825439453125, 'loss_3': -16.228477478027344, 'loss_4': 0.22983302175998688, 'epoch': 12.99}
{'loss': 0.0213, 'grad_norm': 7.0886712074279785, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.01904800347983837, 'loss_2': 0.00228118896484375, 'loss_3': -16.004262924194336, 'loss_4': 0.5322843790054321, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 13:15:40,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:40,392 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:34<49:26,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:15:47,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02611815556883812, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.169, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.02216454967856407, 'eval_loss_2': 0.003953605890274048, 'eval_loss_3': -18.198131561279297, 'eval_loss_4': 0.5367405414581299, 'epoch': 12.99}
{'loss': 0.0058, 'grad_norm': 5.882416248321533, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.004655901808291674, 'loss_2': 0.001129150390625, 'loss_3': -16.55786895751953, 'loss_4': 0.8199141025543213, 'epoch': 13.0}
{'loss': 0.0263, 'grad_norm': 12.488494873046875, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.02574748918414116, 'loss_2': 0.0005502700805664062, 'loss_3': -16.642162322998047, 'loss_4': 0.6491386890411377, 'epoch': 13.01}
{'loss': 0.0228, 'grad_norm': 8.954435348510742, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.01721370220184326, 'loss_2': 0.00560760498046875, 'loss_3': -16.36333465576172, 'loss_4': 0.7136498689651489, 'epoch': 13.01}
{'loss': 0.0184, 'grad_norm': 7.297372817993164, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.015997860580682755, 'loss_2': 0.00238800048828125, 'loss_3': -16.449981689453125, 'loss_4': 0.4840136766433716, 'epoch': 13.02}
{'loss': 0.0144, 'grad_norm': 5.072898864746094, 'learning_rate': 1.7e-05, 'loss_1': 0.010578235611319542, 'loss_2': 0.00385284423828125, 'loss_3': -16.53005599975586, 'loss_4': 0.15658816695213318, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 13:15:47,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:47,441 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:41<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:15:54,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026048041880130768, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.022278500720858574, 'eval_loss_2': 0.0037695467472076416, 'eval_loss_3': -18.22012710571289, 'eval_loss_4': 0.5447359681129456, 'epoch': 13.02}
{'loss': 0.0146, 'grad_norm': 5.517667293548584, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.01432209461927414, 'loss_2': 0.0003008842468261719, 'loss_3': -16.542118072509766, 'loss_4': 0.32239872217178345, 'epoch': 13.03}
{'loss': 0.0232, 'grad_norm': 9.12448787689209, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.021092455834150314, 'loss_2': 0.0021228790283203125, 'loss_3': -16.413076400756836, 'loss_4': 0.3089118003845215, 'epoch': 13.03}
{'loss': 0.0137, 'grad_norm': 5.357497692108154, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.010945563204586506, 'loss_2': 0.002712249755859375, 'loss_3': -16.382461547851562, 'loss_4': 0.767880916595459, 'epoch': 13.04}
{'loss': 0.0168, 'grad_norm': 9.27611255645752, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.014761216007173061, 'loss_2': 0.002048492431640625, 'loss_3': -16.477497100830078, 'loss_4': 0.7019345760345459, 'epoch': 13.05}
{'loss': 0.0107, 'grad_norm': 5.172477722167969, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.00875559076666832, 'loss_2': 0.001911163330078125, 'loss_3': -16.35920524597168, 'loss_4': 0.7308651804924011, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 13:15:54,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:54,784 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:49<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:16:02,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02844686433672905, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.712, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.023429986089468002, 'eval_loss_2': 0.005016878247261047, 'eval_loss_3': -18.21224594116211, 'eval_loss_4': 0.47010451555252075, 'epoch': 13.05}
{'loss': 0.0204, 'grad_norm': 7.209744930267334, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.01393210981041193, 'loss_2': 0.006504058837890625, 'loss_3': -16.3388729095459, 'loss_4': 1.010364055633545, 'epoch': 13.06}
{'loss': 0.0225, 'grad_norm': 5.59026575088501, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.012181982398033142, 'loss_2': 0.0103607177734375, 'loss_3': -16.378368377685547, 'loss_4': 0.37294042110443115, 'epoch': 13.06}
{'loss': 0.0176, 'grad_norm': 4.888701915740967, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.007365243509411812, 'loss_2': 0.01018524169921875, 'loss_3': -16.396652221679688, 'loss_4': 0.7503201961517334, 'epoch': 13.07}
{'loss': 0.0197, 'grad_norm': 4.413230895996094, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.005525919143110514, 'loss_2': 0.01416015625, 'loss_3': -16.62314796447754, 'loss_4': 1.2415190935134888, 'epoch': 13.08}
{'loss': 0.0336, 'grad_norm': 11.699363708496094, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.02395273931324482, 'loss_2': 0.0096282958984375, 'loss_3': -16.494272232055664, 'loss_4': 0.829994261264801, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 13:16:02,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:02,114 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:56<50:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:09,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02965468540787697, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.392, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02455422468483448, 'eval_loss_2': 0.005100458860397339, 'eval_loss_3': -18.204647064208984, 'eval_loss_4': 0.44893598556518555, 'epoch': 13.08}
{'loss': 0.009, 'grad_norm': 4.878698825836182, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.006164529360830784, 'loss_2': 0.002803802490234375, 'loss_3': -16.29323387145996, 'loss_4': 0.29664450883865356, 'epoch': 13.09}
{'loss': 0.0364, 'grad_norm': 8.838666915893555, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.027777506038546562, 'loss_2': 0.0086517333984375, 'loss_3': -16.39410400390625, 'loss_4': 0.6302227973937988, 'epoch': 13.09}
{'loss': 0.0113, 'grad_norm': 5.519317626953125, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.006990063935518265, 'loss_2': 0.0043487548828125, 'loss_3': -16.452373504638672, 'loss_4': 0.11045682430267334, 'epoch': 13.1}
{'loss': 0.0123, 'grad_norm': 5.223685264587402, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.010969038121402264, 'loss_2': 0.001285552978515625, 'loss_3': -16.62769317626953, 'loss_4': 0.1511012464761734, 'epoch': 13.1}
{'loss': 0.0166, 'grad_norm': 5.924910068511963, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.009859018959105015, 'loss_2': 0.006755828857421875, 'loss_3': -16.40353012084961, 'loss_4': -0.08388859778642654, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 13:16:09,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:09,449 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [56:03<50:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:16,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027079468593001366, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.022098684683442116, 'eval_loss_2': 0.00498078390955925, 'eval_loss_3': -18.237600326538086, 'eval_loss_4': 0.2856255769729614, 'epoch': 13.11}
{'loss': 0.0232, 'grad_norm': 6.556100368499756, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.015111473388969898, 'loss_2': 0.00807952880859375, 'loss_3': -16.610309600830078, 'loss_4': 0.5620824098587036, 'epoch': 13.12}
{'loss': 0.0252, 'grad_norm': 10.014148712158203, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.022276202216744423, 'loss_2': 0.0028820037841796875, 'loss_3': -16.714019775390625, 'loss_4': 0.12560641765594482, 'epoch': 13.12}
{'loss': 0.0341, 'grad_norm': 8.39528751373291, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.02012747712433338, 'loss_2': 0.01392364501953125, 'loss_3': -16.580398559570312, 'loss_4': 0.1981181502342224, 'epoch': 13.13}
{'loss': 0.0243, 'grad_norm': 6.359351634979248, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.018956447020173073, 'loss_2': 0.00537872314453125, 'loss_3': -16.408273696899414, 'loss_4': -0.07604328542947769, 'epoch': 13.13}
{'loss': 0.0313, 'grad_norm': 8.60703182220459, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.0272295493632555, 'loss_2': 0.00408935546875, 'loss_3': -16.640310287475586, 'loss_4': 0.1275942325592041, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 13:16:16,787 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:16,788 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:11<50:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:24,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023663591593503952, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01857748255133629, 'eval_loss_2': 0.005086109042167664, 'eval_loss_3': -18.303028106689453, 'eval_loss_4': 0.06500249356031418, 'epoch': 13.14}
{'loss': 0.0154, 'grad_norm': 5.694843769073486, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.011755874380469322, 'loss_2': 0.0036869049072265625, 'loss_3': -16.40572166442871, 'loss_4': 0.3509162366390228, 'epoch': 13.15}
{'loss': 0.016, 'grad_norm': 6.114707946777344, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.013826078735291958, 'loss_2': 0.00222015380859375, 'loss_3': -16.515975952148438, 'loss_4': 0.2770610451698303, 'epoch': 13.15}
{'loss': 0.0099, 'grad_norm': 5.062003135681152, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.008390179835259914, 'loss_2': 0.0015592575073242188, 'loss_3': -16.586957931518555, 'loss_4': 0.45254963636398315, 'epoch': 13.16}
{'loss': 0.0185, 'grad_norm': 7.395912170410156, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.01273095142096281, 'loss_2': 0.005767822265625, 'loss_3': -16.556697845458984, 'loss_4': 0.23061750829219818, 'epoch': 13.16}
{'loss': 0.0182, 'grad_norm': 5.618332386016846, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.016088953241705894, 'loss_2': 0.0020771026611328125, 'loss_3': -16.492103576660156, 'loss_4': -0.07400361448526382, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 13:16:24,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:24,124 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:18<49:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:31,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018187103793025017, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.286, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01432651188224554, 'eval_loss_2': 0.0038605928421020508, 'eval_loss_3': -18.315265655517578, 'eval_loss_4': -0.024080868810415268, 'epoch': 13.17}
{'loss': 0.0403, 'grad_norm': 11.325243949890137, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.03358479589223862, 'loss_2': 0.0067291259765625, 'loss_3': -16.695232391357422, 'loss_4': -0.32109734416007996, 'epoch': 13.17}
{'loss': 0.0117, 'grad_norm': 5.150935173034668, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.010371305048465729, 'loss_2': 0.00131988525390625, 'loss_3': -16.36701202392578, 'loss_4': 0.4079260230064392, 'epoch': 13.18}
{'loss': 0.0375, 'grad_norm': 11.659567832946777, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.035485006868839264, 'loss_2': 0.001979827880859375, 'loss_3': -16.505821228027344, 'loss_4': 0.07162092626094818, 'epoch': 13.19}
{'loss': 0.0113, 'grad_norm': 4.973017692565918, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.00750618614256382, 'loss_2': 0.0037822723388671875, 'loss_3': -16.588220596313477, 'loss_4': -0.021248020231723785, 'epoch': 13.19}
{'loss': 0.0457, 'grad_norm': 15.739977836608887, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.0430094413459301, 'loss_2': 0.00264739990234375, 'loss_3': -16.369678497314453, 'loss_4': 0.5251685976982117, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 13:16:31,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:31,466 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:25<49:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:38,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018544990569353104, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014251027256250381, 'eval_loss_2': 0.004293963313102722, 'eval_loss_3': -18.31681251525879, 'eval_loss_4': -0.1498958021402359, 'epoch': 13.2}
{'loss': 0.0174, 'grad_norm': 6.17932653427124, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.013674604706466198, 'loss_2': 0.00370025634765625, 'loss_3': -16.391569137573242, 'loss_4': -0.030490558594465256, 'epoch': 13.2}
{'loss': 0.0225, 'grad_norm': 5.237558364868164, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.014239045791327953, 'loss_2': 0.00827789306640625, 'loss_3': -16.45296287536621, 'loss_4': 0.087016761302948, 'epoch': 13.21}
{'loss': 0.0159, 'grad_norm': 7.577589511871338, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.013714296743273735, 'loss_2': 0.0021572113037109375, 'loss_3': -16.455636978149414, 'loss_4': 0.02819650247693062, 'epoch': 13.22}
{'loss': 0.0181, 'grad_norm': 5.882429599761963, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.015801606699824333, 'loss_2': 0.002254486083984375, 'loss_3': -16.494792938232422, 'loss_4': -0.6917912364006042, 'epoch': 13.22}
{'loss': 0.0134, 'grad_norm': 4.964217185974121, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.007190719712525606, 'loss_2': 0.0062103271484375, 'loss_3': -16.506942749023438, 'loss_4': -0.25188878178596497, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 13:16:38,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:38,805 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:33<49:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:46,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01937159337103367, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.846, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01585065759718418, 'eval_loss_2': 0.0035209357738494873, 'eval_loss_3': -18.320392608642578, 'eval_loss_4': -0.23307545483112335, 'epoch': 13.23}
{'loss': 0.02, 'grad_norm': 6.767888069152832, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.017953570932149887, 'loss_2': 0.0019969940185546875, 'loss_3': -16.60297203063965, 'loss_4': -0.3548254370689392, 'epoch': 13.23}
{'loss': 0.0195, 'grad_norm': 6.841909885406494, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.01679103448987007, 'loss_2': 0.002727508544921875, 'loss_3': -16.406219482421875, 'loss_4': -0.09752966463565826, 'epoch': 13.24}
{'loss': 0.0208, 'grad_norm': 5.448877334594727, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.015022750943899155, 'loss_2': 0.0057373046875, 'loss_3': -16.38018035888672, 'loss_4': -0.23990099132061005, 'epoch': 13.24}
{'loss': 0.0233, 'grad_norm': 5.936413288116455, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.014662538655102253, 'loss_2': 0.008636474609375, 'loss_3': -16.561412811279297, 'loss_4': 0.03844105824828148, 'epoch': 13.25}
{'loss': 0.0154, 'grad_norm': 5.209845542907715, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.009848929941654205, 'loss_2': 0.0055389404296875, 'loss_3': -16.37185287475586, 'loss_4': 0.043516457080841064, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 13:16:46,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:46,145 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:40<49:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:53,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01992437243461609, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016894251108169556, 'eval_loss_2': 0.003030121326446533, 'eval_loss_3': -18.289901733398438, 'eval_loss_4': -0.1742783635854721, 'epoch': 13.26}
{'loss': 0.0281, 'grad_norm': 10.111462593078613, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.01966700702905655, 'loss_2': 0.00841522216796875, 'loss_3': -16.493408203125, 'loss_4': 0.25698959827423096, 'epoch': 13.26}
{'loss': 0.01, 'grad_norm': 5.916074275970459, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.009827458299696445, 'loss_2': 0.00012493133544921875, 'loss_3': -16.558364868164062, 'loss_4': 0.032464057207107544, 'epoch': 13.27}
{'loss': 0.0365, 'grad_norm': 11.72358512878418, 'learning_rate': 1.675e-05, 'loss_1': 0.03184639289975166, 'loss_2': 0.00469970703125, 'loss_3': -16.268430709838867, 'loss_4': 0.031070224940776825, 'epoch': 13.27}
{'loss': 0.0145, 'grad_norm': 6.7505693435668945, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.01189313642680645, 'loss_2': 0.0026264190673828125, 'loss_3': -16.397483825683594, 'loss_4': -0.021479584276676178, 'epoch': 13.28}
{'loss': 0.0635, 'grad_norm': 11.279542922973633, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.061333730816841125, 'loss_2': 0.0021915435791015625, 'loss_3': -16.287071228027344, 'loss_4': 0.08433794975280762, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 13:16:53,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:53,474 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:47<49:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:00,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023969223722815514, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.8, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018302101641893387, 'eval_loss_2': 0.0056671202182769775, 'eval_loss_3': -18.24875831604004, 'eval_loss_4': -0.23817962408065796, 'epoch': 13.28}
{'loss': 0.0129, 'grad_norm': 5.080156326293945, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.01018992904573679, 'loss_2': 0.00266265869140625, 'loss_3': -16.475969314575195, 'loss_4': -0.35986974835395813, 'epoch': 13.29}
{'loss': 0.0169, 'grad_norm': 5.149564743041992, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.009458118118345737, 'loss_2': 0.007442474365234375, 'loss_3': -16.540584564208984, 'loss_4': 0.046040698885917664, 'epoch': 13.3}
{'loss': 0.0675, 'grad_norm': 26.394149780273438, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.057124700397253036, 'loss_2': 0.0103759765625, 'loss_3': -16.157005310058594, 'loss_4': -0.11819832026958466, 'epoch': 13.3}
{'loss': 0.0165, 'grad_norm': 6.602484226226807, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.01048062089830637, 'loss_2': 0.0059814453125, 'loss_3': -16.377159118652344, 'loss_4': 0.1082555428147316, 'epoch': 13.31}
{'loss': 0.0159, 'grad_norm': 5.32701301574707, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.011665617115795612, 'loss_2': 0.00418853759765625, 'loss_3': -16.384754180908203, 'loss_4': 0.4836445152759552, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 13:17:00,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:00,808 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:55<49:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:08,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01945316419005394, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01698470674455166, 'eval_loss_2': 0.0024684593081474304, 'eval_loss_3': -18.254741668701172, 'eval_loss_4': -0.18148162961006165, 'epoch': 13.31}
{'loss': 0.0108, 'grad_norm': 6.525660037994385, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.010345210321247578, 'loss_2': 0.0004353523254394531, 'loss_3': -16.307964324951172, 'loss_4': 0.0943794697523117, 'epoch': 13.32}
{'loss': 0.0259, 'grad_norm': 10.514456748962402, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.015860185027122498, 'loss_2': 0.0100250244140625, 'loss_3': -16.59146499633789, 'loss_4': 0.16282285749912262, 'epoch': 13.33}
{'loss': 0.0162, 'grad_norm': 7.632043838500977, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.013272635638713837, 'loss_2': 0.0029449462890625, 'loss_3': -16.354230880737305, 'loss_4': -0.01157340407371521, 'epoch': 13.33}
{'loss': 0.0067, 'grad_norm': 5.020549297332764, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.005128099583089352, 'loss_2': 0.0015735626220703125, 'loss_3': -16.477602005004883, 'loss_4': -0.07888342440128326, 'epoch': 13.34}
{'loss': 0.0174, 'grad_norm': 6.183763027191162, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.008919889107346535, 'loss_2': 0.00847625732421875, 'loss_3': -16.621095657348633, 'loss_4': -0.20542645454406738, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 13:17:08,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:08,141 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [57:02<49:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:15,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021027134731411934, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.235, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016917278990149498, 'eval_loss_2': 0.004109855741262436, 'eval_loss_3': -18.232589721679688, 'eval_loss_4': -0.11154718697071075, 'epoch': 13.34}
{'loss': 0.0192, 'grad_norm': 6.499776363372803, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.011121915653347969, 'loss_2': 0.00811767578125, 'loss_3': -16.47237777709961, 'loss_4': -0.016228191554546356, 'epoch': 13.35}
{'loss': 0.0205, 'grad_norm': 13.43991756439209, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.01606595702469349, 'loss_2': 0.00447845458984375, 'loss_3': -16.24266815185547, 'loss_4': -0.023115944117307663, 'epoch': 13.35}
{'loss': 0.0102, 'grad_norm': 5.822707653045654, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.007644594646990299, 'loss_2': 0.002544403076171875, 'loss_3': -16.339704513549805, 'loss_4': 0.019337989389896393, 'epoch': 13.36}
{'loss': 0.0077, 'grad_norm': 5.085449695587158, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.006733535323292017, 'loss_2': 0.001010894775390625, 'loss_3': -16.373291015625, 'loss_4': 0.4798864722251892, 'epoch': 13.37}
{'loss': 0.0241, 'grad_norm': 10.366937637329102, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.02394249103963375, 'loss_2': 0.00017333030700683594, 'loss_3': -16.514785766601562, 'loss_4': 0.13302427530288696, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 13:17:15,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:15,482 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:09<49:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:22,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020829129964113235, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016479332000017166, 'eval_loss_2': 0.004349797964096069, 'eval_loss_3': -18.239042282104492, 'eval_loss_4': -0.22524957358837128, 'epoch': 13.37}
{'loss': 0.0127, 'grad_norm': 5.084149360656738, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.006780557334423065, 'loss_2': 0.005939483642578125, 'loss_3': -16.43529510498047, 'loss_4': 0.3569522202014923, 'epoch': 13.38}
{'loss': 0.0398, 'grad_norm': 12.546957969665527, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.02731977216899395, 'loss_2': 0.012481689453125, 'loss_3': -16.57693862915039, 'loss_4': -0.5342026352882385, 'epoch': 13.38}
{'loss': 0.0105, 'grad_norm': 4.575043201446533, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.005580142606049776, 'loss_2': 0.0049591064453125, 'loss_3': -16.232736587524414, 'loss_4': -0.0897459089756012, 'epoch': 13.39}
{'loss': 0.018, 'grad_norm': 11.02185344696045, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.014131215400993824, 'loss_2': 0.00390625, 'loss_3': -16.341934204101562, 'loss_4': 0.011462729424238205, 'epoch': 13.4}
{'loss': 0.0067, 'grad_norm': 5.180994033813477, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.006712704431265593, 'loss_2': 5.4836273193359375e-06, 'loss_3': -16.116504669189453, 'loss_4': -0.31436172127723694, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 13:17:22,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:22,814 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:17<49:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:30,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022966429591178894, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01741659827530384, 'eval_loss_2': 0.005549833178520203, 'eval_loss_3': -18.2388858795166, 'eval_loss_4': -0.32737332582473755, 'epoch': 13.4}
{'loss': 0.0095, 'grad_norm': 4.843830108642578, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.008231747895479202, 'loss_2': 0.0012540817260742188, 'loss_3': -16.539609909057617, 'loss_4': -0.44364264607429504, 'epoch': 13.41}
{'loss': 0.0136, 'grad_norm': 6.412516117095947, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.011581216007471085, 'loss_2': 0.001995086669921875, 'loss_3': -16.462562561035156, 'loss_4': -0.44531938433647156, 'epoch': 13.41}
{'loss': 0.0186, 'grad_norm': 6.883821487426758, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.012923309579491615, 'loss_2': 0.00571441650390625, 'loss_3': -16.2955379486084, 'loss_4': 0.1375150978565216, 'epoch': 13.42}
{'loss': 0.0644, 'grad_norm': 29.155397415161133, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.06208816543221474, 'loss_2': 0.0023193359375, 'loss_3': -16.12681007385254, 'loss_4': -0.07673226296901703, 'epoch': 13.42}
{'loss': 0.0165, 'grad_norm': 7.454187393188477, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.01492906454950571, 'loss_2': 0.0015878677368164062, 'loss_3': -16.471290588378906, 'loss_4': -0.42883414030075073, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 13:17:30,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:30,152 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:24<49:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:37,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02010689489543438, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016851214691996574, 'eval_loss_2': 0.003255680203437805, 'eval_loss_3': -18.25396728515625, 'eval_loss_4': -0.34174564480781555, 'epoch': 13.43}
{'loss': 0.0154, 'grad_norm': 5.100673198699951, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.009396277368068695, 'loss_2': 0.00600433349609375, 'loss_3': -16.363082885742188, 'loss_4': -0.580195426940918, 'epoch': 13.44}
{'loss': 0.0154, 'grad_norm': 13.31507396697998, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.014121211133897305, 'loss_2': 0.001262664794921875, 'loss_3': -16.446762084960938, 'loss_4': -0.00451694056391716, 'epoch': 13.44}
{'loss': 0.0103, 'grad_norm': 6.862581729888916, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.009993954561650753, 'loss_2': 0.0003116130828857422, 'loss_3': -16.444936752319336, 'loss_4': -0.25014063715934753, 'epoch': 13.45}
{'loss': 0.0575, 'grad_norm': 17.449567794799805, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.05566699802875519, 'loss_2': 0.0017976760864257812, 'loss_3': -16.3087158203125, 'loss_4': 0.14932751655578613, 'epoch': 13.45}
{'loss': 0.0108, 'grad_norm': 5.026194095611572, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.0058935354463756084, 'loss_2': 0.0048828125, 'loss_3': -16.362661361694336, 'loss_4': -0.06116195023059845, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 13:17:37,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:37,488 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:31<49:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:44,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020960083231329918, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017252935096621513, 'eval_loss_2': 0.0037071481347084045, 'eval_loss_3': -18.246347427368164, 'eval_loss_4': -0.3589222729206085, 'epoch': 13.46}
{'loss': 0.0151, 'grad_norm': 6.678093910217285, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.010945135727524757, 'loss_2': 0.004150390625, 'loss_3': -16.49028778076172, 'loss_4': -0.16551661491394043, 'epoch': 13.47}
{'loss': 0.0162, 'grad_norm': 5.775238513946533, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.011951570399105549, 'loss_2': 0.0042572021484375, 'loss_3': -16.350738525390625, 'loss_4': -0.17453402280807495, 'epoch': 13.47}
{'loss': 0.0102, 'grad_norm': 5.3297553062438965, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.009143717586994171, 'loss_2': 0.001071929931640625, 'loss_3': -16.295942306518555, 'loss_4': -0.01776936650276184, 'epoch': 13.48}
{'loss': 0.0083, 'grad_norm': 5.014191627502441, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.006942287553101778, 'loss_2': 0.0013246536254882812, 'loss_3': -16.421802520751953, 'loss_4': -0.35254624485969543, 'epoch': 13.48}
{'loss': 0.0118, 'grad_norm': 6.4852986335754395, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.009163979440927505, 'loss_2': 0.002620697021484375, 'loss_3': -16.350004196166992, 'loss_4': -0.4576236605644226, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 13:17:44,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:44,821 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:39<48:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:52,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022326437756419182, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017479058355093002, 'eval_loss_2': 0.00484737753868103, 'eval_loss_3': -18.22269630432129, 'eval_loss_4': -0.41815510392189026, 'epoch': 13.49}
{'loss': 0.0161, 'grad_norm': 10.131500244140625, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.011325757019221783, 'loss_2': 0.004730224609375, 'loss_3': -16.361913681030273, 'loss_4': -0.6639711856842041, 'epoch': 13.49}
{'loss': 0.0068, 'grad_norm': 4.964554309844971, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.006094115320593119, 'loss_2': 0.000728607177734375, 'loss_3': -16.248764038085938, 'loss_4': -0.9762408137321472, 'epoch': 13.5}
{'loss': 0.0102, 'grad_norm': 4.213155746459961, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.005458274390548468, 'loss_2': 0.0047760009765625, 'loss_3': -16.463565826416016, 'loss_4': -0.6168788075447083, 'epoch': 13.51}
{'loss': 0.0125, 'grad_norm': 5.058818817138672, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.009255940094590187, 'loss_2': 0.003215789794921875, 'loss_3': -16.180110931396484, 'loss_4': -0.6655337810516357, 'epoch': 13.51}
{'loss': 0.0068, 'grad_norm': 6.596924304962158, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.005325675942003727, 'loss_2': 0.0014667510986328125, 'loss_3': -16.107004165649414, 'loss_4': -0.09047596156597137, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 13:17:52,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:52,162 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:46<48:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:59,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01859799399971962, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014255248010158539, 'eval_loss_2': 0.0043427422642707825, 'eval_loss_3': -18.262466430664062, 'eval_loss_4': -0.5243781208992004, 'epoch': 13.52}
{'loss': 0.0128, 'grad_norm': 6.032894611358643, 'learning_rate': 1.65e-05, 'loss_1': 0.00590638630092144, 'loss_2': 0.006927490234375, 'loss_3': -16.30049705505371, 'loss_4': -0.3693837523460388, 'epoch': 13.52}
{'loss': 0.0413, 'grad_norm': 16.362791061401367, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.03791506215929985, 'loss_2': 0.0034275054931640625, 'loss_3': -16.020437240600586, 'loss_4': -0.568766713142395, 'epoch': 13.53}
{'loss': 0.0133, 'grad_norm': 6.388770580291748, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.007785102818161249, 'loss_2': 0.005504608154296875, 'loss_3': -16.320737838745117, 'loss_4': -0.5676561594009399, 'epoch': 13.53}
{'loss': 0.0316, 'grad_norm': 8.739982604980469, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.02822558954358101, 'loss_2': 0.0033721923828125, 'loss_3': -16.271900177001953, 'loss_4': -0.22274747490882874, 'epoch': 13.54}
{'loss': 0.0089, 'grad_norm': 5.300405979156494, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.005152826197445393, 'loss_2': 0.00379180908203125, 'loss_3': -16.506328582763672, 'loss_4': -0.6094310283660889, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 13:17:59,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:59,506 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:53<48:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:06,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017333373427391052, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013194664381444454, 'eval_loss_2': 0.0041387081146240234, 'eval_loss_3': -18.239757537841797, 'eval_loss_4': -0.5485682487487793, 'epoch': 13.55}
{'loss': 0.0033, 'grad_norm': 4.553379535675049, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.0033064899034798145, 'loss_2': 2.092123031616211e-05, 'loss_3': -16.281021118164062, 'loss_4': -0.4512104392051697, 'epoch': 13.55}
{'loss': 0.0197, 'grad_norm': 6.727462291717529, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.01206720806658268, 'loss_2': 0.00759124755859375, 'loss_3': -16.26451301574707, 'loss_4': -0.07276192307472229, 'epoch': 13.56}
{'loss': 0.0083, 'grad_norm': 5.05858850479126, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.0069754961878061295, 'loss_2': 0.0012760162353515625, 'loss_3': -16.409719467163086, 'loss_4': -0.6181772351264954, 'epoch': 13.56}
{'loss': 0.0195, 'grad_norm': 7.85659646987915, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.01605933904647827, 'loss_2': 0.0034694671630859375, 'loss_3': -16.1192626953125, 'loss_4': 0.10095033049583435, 'epoch': 13.57}
{'loss': 0.0068, 'grad_norm': 5.003236293792725, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.005285969935357571, 'loss_2': 0.0015277862548828125, 'loss_3': -16.416759490966797, 'loss_4': -0.4127575159072876, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 13:18:06,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:06,837 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [58:01<48:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:14,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01795516535639763, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.542, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013750050216913223, 'eval_loss_2': 0.0042051151394844055, 'eval_loss_3': -18.272506713867188, 'eval_loss_4': -0.5099913477897644, 'epoch': 13.58}
{'loss': 0.0081, 'grad_norm': 5.225397109985352, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.00677865743637085, 'loss_2': 0.00136566162109375, 'loss_3': -16.384010314941406, 'loss_4': -0.4813804626464844, 'epoch': 13.58}
{'loss': 0.0115, 'grad_norm': 5.069032192230225, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.008050788193941116, 'loss_2': 0.003482818603515625, 'loss_3': -16.326519012451172, 'loss_4': 0.103823721408844, 'epoch': 13.59}
{'loss': 0.0186, 'grad_norm': 5.227664947509766, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.010043212212622166, 'loss_2': 0.0085601806640625, 'loss_3': -16.010875701904297, 'loss_4': -0.489221453666687, 'epoch': 13.59}
{'loss': 0.0186, 'grad_norm': 8.916277885437012, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.013311974704265594, 'loss_2': 0.00533294677734375, 'loss_3': -16.406230926513672, 'loss_4': -0.32162222266197205, 'epoch': 13.6}
{'loss': 0.0431, 'grad_norm': 20.036964416503906, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.04246315360069275, 'loss_2': 0.0006160736083984375, 'loss_3': -16.489315032958984, 'loss_4': -0.14919380843639374, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 13:18:14,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:14,175 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:08<48:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:18:21,502 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01777980476617813, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014081396162509918, 'eval_loss_2': 0.003698408603668213, 'eval_loss_3': -18.268741607666016, 'eval_loss_4': -0.5094826817512512, 'epoch': 13.6}
{'loss': 0.012, 'grad_norm': 5.230796813964844, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.007390303071588278, 'loss_2': 0.0045623779296875, 'loss_3': -16.17367172241211, 'loss_4': -0.11028037965297699, 'epoch': 13.61}
{'loss': 0.0215, 'grad_norm': 6.367257118225098, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.011144322343170643, 'loss_2': 0.01033782958984375, 'loss_3': -16.34724235534668, 'loss_4': -0.3580133020877838, 'epoch': 13.62}
{'loss': 0.0161, 'grad_norm': 5.8695573806762695, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.013617649674415588, 'loss_2': 0.00252532958984375, 'loss_3': -16.16032600402832, 'loss_4': -0.10987960547208786, 'epoch': 13.62}
{'loss': 0.0324, 'grad_norm': 10.940902709960938, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.026480095461010933, 'loss_2': 0.00592041015625, 'loss_3': -16.189128875732422, 'loss_4': -0.42525333166122437, 'epoch': 13.63}
{'loss': 0.0131, 'grad_norm': 7.668591022491455, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.011383714154362679, 'loss_2': 0.0017328262329101562, 'loss_3': -16.367202758789062, 'loss_4': -0.47808361053466797, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 13:18:21,502 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:21,502 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:15<48:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:28,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01748548448085785, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014275536872446537, 'eval_loss_2': 0.0032099485397338867, 'eval_loss_3': -18.295352935791016, 'eval_loss_4': -0.6554369330406189, 'epoch': 13.63}
{'loss': 0.0113, 'grad_norm': 5.018956661224365, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.007944073528051376, 'loss_2': 0.003376007080078125, 'loss_3': -16.258543014526367, 'loss_4': -0.3353825509548187, 'epoch': 13.64}
{'loss': 0.0161, 'grad_norm': 6.218374729156494, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.013569139875471592, 'loss_2': 0.0025787353515625, 'loss_3': -16.4256591796875, 'loss_4': -0.5094342231750488, 'epoch': 13.65}
{'loss': 0.0099, 'grad_norm': 5.223842144012451, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.009205189533531666, 'loss_2': 0.000705718994140625, 'loss_3': -16.339086532592773, 'loss_4': -0.5024868249893188, 'epoch': 13.65}
{'loss': 0.0091, 'grad_norm': 6.490971088409424, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.008152170106768608, 'loss_2': 0.0009241104125976562, 'loss_3': -16.337646484375, 'loss_4': -0.5152941942214966, 'epoch': 13.66}
{'loss': 0.0296, 'grad_norm': 11.901908874511719, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.028959009796380997, 'loss_2': 0.000659942626953125, 'loss_3': -16.39056396484375, 'loss_4': -0.25555920600891113, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 13:18:28,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:28,837 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:23<48:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:36,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017412595450878143, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014585448428988457, 'eval_loss_2': 0.0028271451592445374, 'eval_loss_3': -18.305389404296875, 'eval_loss_4': -0.6473619341850281, 'epoch': 13.66}
{'loss': 0.0134, 'grad_norm': 5.115644454956055, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.006447178777307272, 'loss_2': 0.00696563720703125, 'loss_3': -16.29502296447754, 'loss_4': -0.575151264667511, 'epoch': 13.67}
{'loss': 0.0145, 'grad_norm': 6.223833084106445, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.010442436672747135, 'loss_2': 0.00409698486328125, 'loss_3': -16.433473587036133, 'loss_4': -0.7165197730064392, 'epoch': 13.67}
{'loss': 0.0512, 'grad_norm': 22.940038681030273, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.04638407751917839, 'loss_2': 0.00484466552734375, 'loss_3': -16.349735260009766, 'loss_4': -0.22253401577472687, 'epoch': 13.68}
{'loss': 0.0184, 'grad_norm': 8.255064010620117, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.015443187206983566, 'loss_2': 0.00298309326171875, 'loss_3': -16.413127899169922, 'loss_4': -0.3665919899940491, 'epoch': 13.69}
{'loss': 0.0305, 'grad_norm': 11.906672477722168, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.02611445263028145, 'loss_2': 0.00441741943359375, 'loss_3': -16.330482482910156, 'loss_4': -0.16757670044898987, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 13:18:36,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:36,184 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:30<48:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:43,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019867464900016785, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.915, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01607413776218891, 'eval_loss_2': 0.0037933290004730225, 'eval_loss_3': -18.263137817382812, 'eval_loss_4': -0.47544431686401367, 'epoch': 13.69}
{'loss': 0.0133, 'grad_norm': 4.515787601470947, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.011479418724775314, 'loss_2': 0.0018405914306640625, 'loss_3': -16.479835510253906, 'loss_4': -0.00029309093952178955, 'epoch': 13.7}
{'loss': 0.0122, 'grad_norm': 4.831002235412598, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.008037401363253593, 'loss_2': 0.004131317138671875, 'loss_3': -16.193984985351562, 'loss_4': -0.24148297309875488, 'epoch': 13.7}
{'loss': 0.0197, 'grad_norm': 7.205265998840332, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.015889625996351242, 'loss_2': 0.003810882568359375, 'loss_3': -16.24797821044922, 'loss_4': -0.34109604358673096, 'epoch': 13.71}
{'loss': 0.0329, 'grad_norm': 8.661345481872559, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.02747870422899723, 'loss_2': 0.00540924072265625, 'loss_3': -16.38022232055664, 'loss_4': -0.5400828719139099, 'epoch': 13.72}
{'loss': 0.0102, 'grad_norm': 5.281754016876221, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.00722159631550312, 'loss_2': 0.0029392242431640625, 'loss_3': -16.44274139404297, 'loss_4': -0.5302009582519531, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 13:18:43,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:43,510 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:37<48:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:50,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02351870760321617, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.071, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0195851419121027, 'eval_loss_2': 0.003933567553758621, 'eval_loss_3': -18.200477600097656, 'eval_loss_4': -0.36688876152038574, 'epoch': 13.72}
{'loss': 0.0194, 'grad_norm': 5.974946975708008, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.010099505074322224, 'loss_2': 0.009307861328125, 'loss_3': -16.235885620117188, 'loss_4': -0.6070212125778198, 'epoch': 13.73}
{'loss': 0.0149, 'grad_norm': 5.749144554138184, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.005933075211942196, 'loss_2': 0.008941650390625, 'loss_3': -16.493391036987305, 'loss_4': -0.3192005753517151, 'epoch': 13.73}
{'loss': 0.0113, 'grad_norm': 6.324270725250244, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.008730673231184483, 'loss_2': 0.002532958984375, 'loss_3': -16.39923095703125, 'loss_4': -0.5756458640098572, 'epoch': 13.74}
{'loss': 0.0129, 'grad_norm': 5.100429534912109, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.007561958394944668, 'loss_2': 0.005336761474609375, 'loss_3': -16.55402183532715, 'loss_4': -0.294977068901062, 'epoch': 13.74}
{'loss': 0.0059, 'grad_norm': 4.960439205169678, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.0054297358728945255, 'loss_2': 0.0004696846008300781, 'loss_3': -16.409494400024414, 'loss_4': -0.699291467666626, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 13:18:50,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:50,844 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:45<50:56,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 13:18:58,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025671927258372307, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.022379068657755852, 'eval_loss_2': 0.003292858600616455, 'eval_loss_3': -18.168540954589844, 'eval_loss_4': -0.2641143798828125, 'epoch': 13.75}
{'loss': 0.0059, 'grad_norm': 4.749853134155273, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.005726441740989685, 'loss_2': 0.0001666545867919922, 'loss_3': -16.134716033935547, 'loss_4': -0.17078234255313873, 'epoch': 13.76}
{'loss': 0.0206, 'grad_norm': 14.999283790588379, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.016708282753825188, 'loss_2': 0.003936767578125, 'loss_3': -16.271516799926758, 'loss_4': 0.1230635792016983, 'epoch': 13.76}
{'loss': 0.0314, 'grad_norm': 16.65741539001465, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.025123022496700287, 'loss_2': 0.006252288818359375, 'loss_3': -16.108867645263672, 'loss_4': 0.1914312243461609, 'epoch': 13.77}
{'loss': 0.0866, 'grad_norm': 15.783032417297363, 'learning_rate': 1.625e-05, 'loss_1': 0.0724695548415184, 'loss_2': 0.01415252685546875, 'loss_3': -16.259777069091797, 'loss_4': 0.3644619286060333, 'epoch': 13.77}
{'loss': 0.0278, 'grad_norm': 7.618190765380859, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.02456459030508995, 'loss_2': 0.0032501220703125, 'loss_3': -16.32164192199707, 'loss_4': -0.17065897583961487, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 13:18:58,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:58,378 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:52<48:36,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:19:05,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03301582857966423, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.025416001677513123, 'eval_loss_2': 0.007599830627441406, 'eval_loss_3': -18.114322662353516, 'eval_loss_4': -0.09872360527515411, 'epoch': 13.78}
{'loss': 0.0234, 'grad_norm': 6.322983741760254, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.009977987967431545, 'loss_2': 0.0134429931640625, 'loss_3': -16.275413513183594, 'loss_4': -0.2583140432834625, 'epoch': 13.78}
{'loss': 0.0245, 'grad_norm': 5.058448314666748, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.008602193556725979, 'loss_2': 0.0158538818359375, 'loss_3': -16.357877731323242, 'loss_4': 0.10242737829685211, 'epoch': 13.79}
{'loss': 0.0135, 'grad_norm': 4.405747413635254, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.006528613157570362, 'loss_2': 0.0069427490234375, 'loss_3': -16.30061149597168, 'loss_4': 0.19127832353115082, 'epoch': 13.8}
{'loss': 0.017, 'grad_norm': 4.549053192138672, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.005074246786534786, 'loss_2': 0.0119171142578125, 'loss_3': -16.373868942260742, 'loss_4': -0.23290614783763885, 'epoch': 13.8}
{'loss': 0.0139, 'grad_norm': 4.618242263793945, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.008619324304163456, 'loss_2': 0.005306243896484375, 'loss_3': -16.371532440185547, 'loss_4': -0.053888969123363495, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 13:19:05,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:05,721 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [59:00<48:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:13,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03386708348989487, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02981283701956272, 'eval_loss_2': 0.004054248332977295, 'eval_loss_3': -18.121784210205078, 'eval_loss_4': -0.0856284499168396, 'epoch': 13.81}
{'loss': 0.0154, 'grad_norm': 4.629620552062988, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.007092737592756748, 'loss_2': 0.008331298828125, 'loss_3': -16.328350067138672, 'loss_4': -0.13973046839237213, 'epoch': 13.81}
{'loss': 0.014, 'grad_norm': 6.0047173500061035, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.01165779773145914, 'loss_2': 0.002330780029296875, 'loss_3': -16.386646270751953, 'loss_4': -0.05985182523727417, 'epoch': 13.82}
{'loss': 0.0259, 'grad_norm': 10.168097496032715, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.024569574743509293, 'loss_2': 0.0013751983642578125, 'loss_3': -16.34092140197754, 'loss_4': -0.4010195732116699, 'epoch': 13.83}
{'loss': 0.0201, 'grad_norm': 6.616724014282227, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.014650985598564148, 'loss_2': 0.005462646484375, 'loss_3': -16.122913360595703, 'loss_4': -0.39125141501426697, 'epoch': 13.83}
{'loss': 0.0187, 'grad_norm': 6.900068283081055, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.015159443952143192, 'loss_2': 0.003559112548828125, 'loss_3': -16.261219024658203, 'loss_4': -0.14893442392349243, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 13:19:13,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:13,072 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:07<48:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:20,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03490857779979706, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.072, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.02717319130897522, 'eval_loss_2': 0.007735386490821838, 'eval_loss_3': -18.174055099487305, 'eval_loss_4': -0.14046983420848846, 'epoch': 13.84}
{'loss': 0.031, 'grad_norm': 9.065118789672852, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.024259008467197418, 'loss_2': 0.0067138671875, 'loss_3': -16.33837890625, 'loss_4': -0.1231994703412056, 'epoch': 13.84}
{'loss': 0.0373, 'grad_norm': 6.789538860321045, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.017657114192843437, 'loss_2': 0.0196533203125, 'loss_3': -16.268844604492188, 'loss_4': -0.6580091714859009, 'epoch': 13.85}
{'loss': 0.0406, 'grad_norm': 16.16779136657715, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.033467259258031845, 'loss_2': 0.007110595703125, 'loss_3': -16.45582389831543, 'loss_4': -0.1585252583026886, 'epoch': 13.85}
{'loss': 0.0347, 'grad_norm': 13.742457389831543, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.022568555548787117, 'loss_2': 0.0121612548828125, 'loss_3': -16.409622192382812, 'loss_4': 0.27219411730766296, 'epoch': 13.86}
{'loss': 0.0165, 'grad_norm': 5.455084800720215, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.007337280083447695, 'loss_2': 0.0091705322265625, 'loss_3': -16.243467330932617, 'loss_4': -0.07652077823877335, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 13:19:20,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:20,436 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:14<47:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:27,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02921038493514061, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.9, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.021201666444540024, 'eval_loss_2': 0.008008718490600586, 'eval_loss_3': -18.211105346679688, 'eval_loss_4': -0.18624238669872284, 'epoch': 13.87}
{'loss': 0.0197, 'grad_norm': 5.16591215133667, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.008681167848408222, 'loss_2': 0.01104736328125, 'loss_3': -16.314952850341797, 'loss_4': -0.3592994511127472, 'epoch': 13.87}
{'loss': 0.0388, 'grad_norm': 8.285783767700195, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.02603469043970108, 'loss_2': 0.0127410888671875, 'loss_3': -16.329212188720703, 'loss_4': -0.16346193850040436, 'epoch': 13.88}
{'loss': 0.027, 'grad_norm': 8.05347728729248, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.016924407333135605, 'loss_2': 0.01007080078125, 'loss_3': -16.560749053955078, 'loss_4': -0.26032647490501404, 'epoch': 13.88}
{'loss': 0.0087, 'grad_norm': 4.312493324279785, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.00506554776802659, 'loss_2': 0.003643035888671875, 'loss_3': -16.556135177612305, 'loss_4': -0.35889703035354614, 'epoch': 13.89}
{'loss': 0.0097, 'grad_norm': 6.69724702835083, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.007805649656802416, 'loss_2': 0.001941680908203125, 'loss_3': -16.43869400024414, 'loss_4': -0.5183680653572083, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 13:19:27,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:27,786 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:22<47:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:35,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020969802513718605, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0179324671626091, 'eval_loss_2': 0.0030373334884643555, 'eval_loss_3': -18.259777069091797, 'eval_loss_4': -0.22604092955589294, 'epoch': 13.9}
{'loss': 0.0118, 'grad_norm': 5.236236095428467, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.00745335454121232, 'loss_2': 0.00439453125, 'loss_3': -16.50046157836914, 'loss_4': -0.10939104110002518, 'epoch': 13.9}
{'loss': 0.0172, 'grad_norm': 7.649935245513916, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.012797510251402855, 'loss_2': 0.00437164306640625, 'loss_3': -16.556360244750977, 'loss_4': -0.07452481985092163, 'epoch': 13.91}
{'loss': 0.0095, 'grad_norm': 4.530327320098877, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.006157773546874523, 'loss_2': 0.0033416748046875, 'loss_3': -16.67238426208496, 'loss_4': -0.5431954264640808, 'epoch': 13.91}
{'loss': 0.0262, 'grad_norm': 10.874131202697754, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.023782804608345032, 'loss_2': 0.002422332763671875, 'loss_3': -16.3895263671875, 'loss_4': -0.02821667492389679, 'epoch': 13.92}
{'loss': 0.0128, 'grad_norm': 6.296252727508545, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.00955323874950409, 'loss_2': 0.0032367706298828125, 'loss_3': -16.388328552246094, 'loss_4': -0.1916292905807495, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 13:19:35,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:35,140 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:29<47:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:42,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021844251081347466, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01875348389148712, 'eval_loss_2': 0.003090769052505493, 'eval_loss_3': -18.262989044189453, 'eval_loss_4': -0.3917170763015747, 'epoch': 13.92}
{'loss': 0.0161, 'grad_norm': 6.212475299835205, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.01107756793498993, 'loss_2': 0.00505828857421875, 'loss_3': -16.45755386352539, 'loss_4': -0.42873072624206543, 'epoch': 13.93}
{'loss': 0.0173, 'grad_norm': 9.600818634033203, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.011441631242632866, 'loss_2': 0.00589752197265625, 'loss_3': -16.342283248901367, 'loss_4': -0.18953122198581696, 'epoch': 13.94}
{'loss': 0.0217, 'grad_norm': 6.021755218505859, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.011446548625826836, 'loss_2': 0.01025390625, 'loss_3': -16.23690414428711, 'loss_4': -0.5503240823745728, 'epoch': 13.94}
{'loss': 0.0214, 'grad_norm': 13.551102638244629, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.018028875812888145, 'loss_2': 0.00335693359375, 'loss_3': -16.42226791381836, 'loss_4': -0.25993072986602783, 'epoch': 13.95}
{'loss': 0.0169, 'grad_norm': 5.071393013000488, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.008674445562064648, 'loss_2': 0.00823211669921875, 'loss_3': -16.335613250732422, 'loss_4': -0.41106075048446655, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 13:19:42,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:42,497 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:36<47:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:49,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023283876478672028, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01940341293811798, 'eval_loss_2': 0.0038804635405540466, 'eval_loss_3': -18.25619125366211, 'eval_loss_4': -0.4174783229827881, 'epoch': 13.95}
{'loss': 0.0225, 'grad_norm': 11.016745567321777, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.014519456773996353, 'loss_2': 0.0079803466796875, 'loss_3': -16.346633911132812, 'loss_4': -0.5594720840454102, 'epoch': 13.96}
{'loss': 0.0073, 'grad_norm': 4.8718061447143555, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.005367256700992584, 'loss_2': 0.0019207000732421875, 'loss_3': -16.317533493041992, 'loss_4': -0.36018672585487366, 'epoch': 13.97}
{'loss': 0.0135, 'grad_norm': 5.9012322425842285, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.010793031193315983, 'loss_2': 0.002742767333984375, 'loss_3': -16.330482482910156, 'loss_4': -0.5575937628746033, 'epoch': 13.97}
{'loss': 0.0174, 'grad_norm': 5.279311656951904, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.008357145823538303, 'loss_2': 0.009033203125, 'loss_3': -16.247867584228516, 'loss_4': -0.41841650009155273, 'epoch': 13.98}
{'loss': 0.0114, 'grad_norm': 5.764472961425781, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.010104168206453323, 'loss_2': 0.0012493133544921875, 'loss_3': -16.446590423583984, 'loss_4': -0.3397766947746277, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 13:19:49,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:49,855 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:43<45:43,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 13:19:56,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022162675857543945, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.508, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01871331036090851, 'eval_loss_2': 0.003449365496635437, 'eval_loss_3': -18.25586700439453, 'eval_loss_4': -0.16422036290168762, 'epoch': 13.98}
{'loss': 0.0204, 'grad_norm': 8.803667068481445, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.014660556800663471, 'loss_2': 0.005771636962890625, 'loss_3': -16.387760162353516, 'loss_4': -0.20809519290924072, 'epoch': 13.99}
{'loss': 0.0239, 'grad_norm': 10.595941543579102, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.016938652843236923, 'loss_2': 0.00691986083984375, 'loss_3': -16.43777847290039, 'loss_4': 0.29274219274520874, 'epoch': 13.99}
{'loss': 0.0045, 'grad_norm': 6.059431076049805, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.0030421586707234383, 'loss_2': 0.0014705657958984375, 'loss_3': -16.45631980895996, 'loss_4': -0.14941371977329254, 'epoch': 14.0}
{'loss': 0.0153, 'grad_norm': 5.501592636108398, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.00966095831245184, 'loss_2': 0.00566864013671875, 'loss_3': -16.473926544189453, 'loss_4': 0.28551360964775085, 'epoch': 14.01}
{'loss': 0.0272, 'grad_norm': 10.21281909942627, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.024707214906811714, 'loss_2': 0.0024776458740234375, 'loss_3': -16.57033920288086, 'loss_4': 0.5939136743545532, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 13:19:56,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:56,908 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:51<47:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:20:04,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022976014763116837, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.839, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02005927823483944, 'eval_loss_2': 0.002916734665632248, 'eval_loss_3': -18.237411499023438, 'eval_loss_4': 0.1955636739730835, 'epoch': 14.01}
{'loss': 0.014, 'grad_norm': 5.718498706817627, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.011403066106140614, 'loss_2': 0.0026035308837890625, 'loss_3': -16.35306167602539, 'loss_4': 0.594480574131012, 'epoch': 14.02}
{'loss': 0.0177, 'grad_norm': 7.710118293762207, 'learning_rate': 1.6e-05, 'loss_1': 0.012374104000627995, 'loss_2': 0.00530242919921875, 'loss_3': -16.247661590576172, 'loss_4': 0.5678119659423828, 'epoch': 14.02}
{'loss': 0.0144, 'grad_norm': 5.461153507232666, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.0076731545850634575, 'loss_2': 0.0067138671875, 'loss_3': -16.602792739868164, 'loss_4': 0.398819237947464, 'epoch': 14.03}
{'loss': 0.0445, 'grad_norm': 11.776723861694336, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.039090290665626526, 'loss_2': 0.00545501708984375, 'loss_3': -16.167417526245117, 'loss_4': 0.41044867038726807, 'epoch': 14.03}
{'loss': 0.0141, 'grad_norm': 5.835703372955322, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.007823383435606956, 'loss_2': 0.006290435791015625, 'loss_3': -16.516082763671875, 'loss_4': 0.10899842530488968, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 13:20:04,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:04,258 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:58<47:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:11,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02394566312432289, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.019609753042459488, 'eval_loss_2': 0.004335910081863403, 'eval_loss_3': -18.221084594726562, 'eval_loss_4': 0.32395243644714355, 'epoch': 14.04}
{'loss': 0.0322, 'grad_norm': 18.07868003845215, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.030880099162459373, 'loss_2': 0.0013294219970703125, 'loss_3': -16.276676177978516, 'loss_4': 0.24642176926136017, 'epoch': 14.05}
{'loss': 0.0144, 'grad_norm': 5.008810520172119, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.008274477906525135, 'loss_2': 0.00612640380859375, 'loss_3': -16.413402557373047, 'loss_4': 0.4613918662071228, 'epoch': 14.05}
{'loss': 0.0189, 'grad_norm': 4.938169479370117, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.010020398534834385, 'loss_2': 0.0088958740234375, 'loss_3': -16.56438636779785, 'loss_4': 0.6140801906585693, 'epoch': 14.06}
{'loss': 0.0201, 'grad_norm': 7.95904541015625, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.017911842092871666, 'loss_2': 0.00217437744140625, 'loss_3': -16.547029495239258, 'loss_4': 0.6367669105529785, 'epoch': 14.06}
{'loss': 0.0115, 'grad_norm': 5.392289638519287, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.010603673756122589, 'loss_2': 0.0009140968322753906, 'loss_3': -16.097373962402344, 'loss_4': 0.4699166417121887, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 13:20:11,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:11,610 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 2425/5160 [1:00:06<47:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:18,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02221137285232544, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.413, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01888776384294033, 'eval_loss_2': 0.0033236071467399597, 'eval_loss_3': -18.212617874145508, 'eval_loss_4': 0.49897879362106323, 'epoch': 14.07}
{'loss': 0.0184, 'grad_norm': 6.236898899078369, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.017833618447184563, 'loss_2': 0.000560760498046875, 'loss_3': -16.28936004638672, 'loss_4': 0.8047376871109009, 'epoch': 14.08}
{'loss': 0.019, 'grad_norm': 8.652669906616211, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.017117269337177277, 'loss_2': 0.001850128173828125, 'loss_3': -16.411235809326172, 'loss_4': 0.7545168399810791, 'epoch': 14.08}
{'loss': 0.0145, 'grad_norm': 7.611629962921143, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.012920028530061245, 'loss_2': 0.0015735626220703125, 'loss_3': -16.30370330810547, 'loss_4': 0.9580661654472351, 'epoch': 14.09}
{'loss': 0.0239, 'grad_norm': 7.286825180053711, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.012764615006744862, 'loss_2': 0.01116943359375, 'loss_3': -16.371135711669922, 'loss_4': 0.32426321506500244, 'epoch': 14.09}
{'loss': 0.017, 'grad_norm': 4.67147159576416, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.007990626618266106, 'loss_2': 0.00897216796875, 'loss_3': -16.414703369140625, 'loss_4': 0.6755728721618652, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 13:20:18,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:18,979 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:13<47:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:26,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022085655480623245, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01765042170882225, 'eval_loss_2': 0.004435233771800995, 'eval_loss_3': -18.184513092041016, 'eval_loss_4': 0.5621825456619263, 'epoch': 14.1}
{'loss': 0.0545, 'grad_norm': 11.8721342086792, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.05058247596025467, 'loss_2': 0.003875732421875, 'loss_3': -16.31471061706543, 'loss_4': 0.8340238332748413, 'epoch': 14.1}
{'loss': 0.0118, 'grad_norm': 6.6299967765808105, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.010084609501063824, 'loss_2': 0.0017070770263671875, 'loss_3': -16.21489143371582, 'loss_4': 0.8707008957862854, 'epoch': 14.11}
{'loss': 0.017, 'grad_norm': 5.520103454589844, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.010614275932312012, 'loss_2': 0.00635528564453125, 'loss_3': -16.46869659423828, 'loss_4': 0.8805906772613525, 'epoch': 14.12}
{'loss': 0.0117, 'grad_norm': 5.83244514465332, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.010692690499126911, 'loss_2': 0.0010042190551757812, 'loss_3': -16.487842559814453, 'loss_4': 0.9018298387527466, 'epoch': 14.12}
{'loss': 0.0154, 'grad_norm': 7.238779067993164, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.012455062009394169, 'loss_2': 0.002895355224609375, 'loss_3': -16.352901458740234, 'loss_4': 0.6987162828445435, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 13:20:26,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:26,334 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:20<47:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:33,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019950080662965775, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01632782444357872, 'eval_loss_2': 0.0036222562193870544, 'eval_loss_3': -18.17313575744629, 'eval_loss_4': 0.7311559915542603, 'epoch': 14.13}
{'loss': 0.0235, 'grad_norm': 12.734907150268555, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.01829514093697071, 'loss_2': 0.0052490234375, 'loss_3': -16.426143646240234, 'loss_4': 1.0101053714752197, 'epoch': 14.13}
{'loss': 0.0145, 'grad_norm': 7.32008695602417, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.011404217220842838, 'loss_2': 0.00311279296875, 'loss_3': -16.314285278320312, 'loss_4': 0.7445134520530701, 'epoch': 14.14}
{'loss': 0.0345, 'grad_norm': 15.944343566894531, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.029234806075692177, 'loss_2': 0.0052947998046875, 'loss_3': -16.232864379882812, 'loss_4': 0.8126451969146729, 'epoch': 14.15}
{'loss': 0.0177, 'grad_norm': 5.72452974319458, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.0128294313326478, 'loss_2': 0.004871368408203125, 'loss_3': -16.468673706054688, 'loss_4': 0.5889897346496582, 'epoch': 14.15}
{'loss': 0.011, 'grad_norm': 7.746175289154053, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.009570479393005371, 'loss_2': 0.00138092041015625, 'loss_3': -16.335290908813477, 'loss_4': 0.8470538854598999, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 13:20:33,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:33,680 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:28<47:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:41,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017847636714577675, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.664, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014433640986680984, 'eval_loss_2': 0.0034139975905418396, 'eval_loss_3': -18.168277740478516, 'eval_loss_4': 0.7823783159255981, 'epoch': 14.16}
{'loss': 0.0137, 'grad_norm': 6.972324848175049, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.013276663608849049, 'loss_2': 0.000396728515625, 'loss_3': -16.430274963378906, 'loss_4': 0.4587559103965759, 'epoch': 14.16}
{'loss': 0.0249, 'grad_norm': 9.805872917175293, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.021338939666748047, 'loss_2': 0.0035457611083984375, 'loss_3': -16.40438461303711, 'loss_4': 0.37240034341812134, 'epoch': 14.17}
{'loss': 0.0169, 'grad_norm': 5.887979030609131, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.01357295736670494, 'loss_2': 0.00334930419921875, 'loss_3': -16.446929931640625, 'loss_4': 0.8011508584022522, 'epoch': 14.17}
{'loss': 0.0121, 'grad_norm': 5.093766212463379, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.009899059310555458, 'loss_2': 0.00215911865234375, 'loss_3': -16.20037269592285, 'loss_4': 0.7952032685279846, 'epoch': 14.18}
{'loss': 0.0083, 'grad_norm': 5.795022010803223, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.007845478132367134, 'loss_2': 0.00043487548828125, 'loss_3': -16.241514205932617, 'loss_4': 0.5770798325538635, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 13:20:41,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:41,044 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:35<46:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:48,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01676863431930542, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012830891646444798, 'eval_loss_2': 0.003937743604183197, 'eval_loss_3': -18.168371200561523, 'eval_loss_4': 0.7671079039573669, 'epoch': 14.19}
{'loss': 0.0358, 'grad_norm': 9.774624824523926, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.0249955877661705, 'loss_2': 0.01081085205078125, 'loss_3': -16.285240173339844, 'loss_4': 0.8137534856796265, 'epoch': 14.19}
{'loss': 0.0201, 'grad_norm': 5.56165885925293, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.010296624153852463, 'loss_2': 0.009765625, 'loss_3': -16.302507400512695, 'loss_4': 1.1309431791305542, 'epoch': 14.2}
{'loss': 0.0083, 'grad_norm': 6.712268829345703, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.00807134434580803, 'loss_2': 0.00025463104248046875, 'loss_3': -16.29397201538086, 'loss_4': 0.5602126717567444, 'epoch': 14.2}
{'loss': 0.0133, 'grad_norm': 6.482863903045654, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.009065475314855576, 'loss_2': 0.004241943359375, 'loss_3': -16.22447967529297, 'loss_4': 0.5975464582443237, 'epoch': 14.21}
{'loss': 0.0099, 'grad_norm': 5.1345906257629395, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.007660052739083767, 'loss_2': 0.002254486083984375, 'loss_3': -16.38763999938965, 'loss_4': 0.6753898859024048, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 13:20:48,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:48,396 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:42<47:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:55,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018100610002875328, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.014336278662085533, 'eval_loss_2': 0.003764331340789795, 'eval_loss_3': -18.141237258911133, 'eval_loss_4': 0.7107922434806824, 'epoch': 14.22}
{'loss': 0.0114, 'grad_norm': 5.230349540710449, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.0040390691719949245, 'loss_2': 0.007328033447265625, 'loss_3': -16.228696823120117, 'loss_4': 0.3025180995464325, 'epoch': 14.22}
{'loss': 0.012, 'grad_norm': 4.202387809753418, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.0051359557546675205, 'loss_2': 0.006839752197265625, 'loss_3': -16.302139282226562, 'loss_4': 0.6665428876876831, 'epoch': 14.23}
{'loss': 0.0085, 'grad_norm': 5.00827169418335, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.005680805072188377, 'loss_2': 0.00281524658203125, 'loss_3': -16.30191421508789, 'loss_4': 0.5293731689453125, 'epoch': 14.23}
{'loss': 0.0141, 'grad_norm': 6.822594165802002, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.014053327031433582, 'loss_2': 4.082918167114258e-05, 'loss_3': -16.20439910888672, 'loss_4': 0.8547050952911377, 'epoch': 14.24}
{'loss': 0.0705, 'grad_norm': 14.12872314453125, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.059836965054273605, 'loss_2': 0.01068115234375, 'loss_3': -16.478015899658203, 'loss_4': 0.8555399775505066, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 13:20:55,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:55,776 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:50<46:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:03,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017672933638095856, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.261, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014529597945511341, 'eval_loss_2': 0.0031433366239070892, 'eval_loss_3': -18.149288177490234, 'eval_loss_4': 0.5859041810035706, 'epoch': 14.24}
{'loss': 0.0157, 'grad_norm': 5.553539276123047, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.009489397518336773, 'loss_2': 0.00624847412109375, 'loss_3': -16.234251022338867, 'loss_4': 0.2624526917934418, 'epoch': 14.25}
{'loss': 0.0207, 'grad_norm': 9.690082550048828, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.013188143260776997, 'loss_2': 0.007556915283203125, 'loss_3': -16.126619338989258, 'loss_4': 0.17125047743320465, 'epoch': 14.26}
{'loss': 0.0412, 'grad_norm': 10.146174430847168, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.03597874194383621, 'loss_2': 0.0051727294921875, 'loss_3': -16.38534927368164, 'loss_4': 0.27103498578071594, 'epoch': 14.26}
{'loss': 0.0174, 'grad_norm': 7.10530948638916, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.01384472195059061, 'loss_2': 0.00357818603515625, 'loss_3': -16.315059661865234, 'loss_4': 0.4830070734024048, 'epoch': 14.27}
{'loss': 0.0044, 'grad_norm': 4.790092468261719, 'learning_rate': 1.575e-05, 'loss_1': 0.0037660677917301655, 'loss_2': 0.0006356239318847656, 'loss_3': -16.4383487701416, 'loss_4': 0.8642477989196777, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 13:21:03,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:03,121 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:57<46:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:10,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016438910737633705, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.831, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01323850080370903, 'eval_loss_2': 0.0032004117965698242, 'eval_loss_3': -18.194242477416992, 'eval_loss_4': 0.4642324447631836, 'epoch': 14.27}
{'loss': 0.0077, 'grad_norm': 6.1073079109191895, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.005361185874789953, 'loss_2': 0.002323150634765625, 'loss_3': -16.446949005126953, 'loss_4': 1.0949589014053345, 'epoch': 14.28}
{'loss': 0.0277, 'grad_norm': 20.144027709960938, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.024541154503822327, 'loss_2': 0.003143310546875, 'loss_3': -16.45309829711914, 'loss_4': 0.6395121812820435, 'epoch': 14.28}
{'loss': 0.0045, 'grad_norm': 4.957160949707031, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.00366998091340065, 'loss_2': 0.0008449554443359375, 'loss_3': -16.157573699951172, 'loss_4': 0.7904592752456665, 'epoch': 14.29}
{'loss': 0.0105, 'grad_norm': 5.547679424285889, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.00721492525190115, 'loss_2': 0.00330352783203125, 'loss_3': -16.287269592285156, 'loss_4': 0.3293572664260864, 'epoch': 14.3}
{'loss': 0.0146, 'grad_norm': 9.758540153503418, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.012615909799933434, 'loss_2': 0.0019397735595703125, 'loss_3': -16.474056243896484, 'loss_4': 0.1567942500114441, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 13:21:10,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:10,479 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:01:04<46:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:17,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015897788107395172, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.969, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012020925059914589, 'eval_loss_2': 0.0038768649101257324, 'eval_loss_3': -18.193483352661133, 'eval_loss_4': 0.4070628583431244, 'epoch': 14.3}
{'loss': 0.015, 'grad_norm': 5.696966648101807, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.013122409582138062, 'loss_2': 0.0018901824951171875, 'loss_3': -16.103986740112305, 'loss_4': 0.5186938047409058, 'epoch': 14.31}
{'loss': 0.0106, 'grad_norm': 6.3226518630981445, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.008758383803069592, 'loss_2': 0.0018644332885742188, 'loss_3': -16.395092010498047, 'loss_4': 0.6130030155181885, 'epoch': 14.31}
{'loss': 0.0135, 'grad_norm': 6.140707492828369, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.011184672825038433, 'loss_2': 0.0023403167724609375, 'loss_3': -16.162734985351562, 'loss_4': 0.5237549543380737, 'epoch': 14.32}
{'loss': 0.0143, 'grad_norm': 5.032927989959717, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.010237669572234154, 'loss_2': 0.00411224365234375, 'loss_3': -16.44390296936035, 'loss_4': 0.33630508184432983, 'epoch': 14.33}
{'loss': 0.0417, 'grad_norm': 10.254182815551758, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.039305493235588074, 'loss_2': 0.0024318695068359375, 'loss_3': -16.254459381103516, 'loss_4': 0.15476998686790466, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 13:21:17,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:17,833 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:12<46:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:25,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017802711576223373, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014457043260335922, 'eval_loss_2': 0.003345668315887451, 'eval_loss_3': -18.216794967651367, 'eval_loss_4': 0.2896021008491516, 'epoch': 14.33}
{'loss': 0.014, 'grad_norm': 6.385037899017334, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.010379789397120476, 'loss_2': 0.0036029815673828125, 'loss_3': -16.246671676635742, 'loss_4': -0.12725606560707092, 'epoch': 14.34}
{'loss': 0.0105, 'grad_norm': 5.029566287994385, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.008647747337818146, 'loss_2': 0.0018062591552734375, 'loss_3': -16.21697998046875, 'loss_4': 0.7093888521194458, 'epoch': 14.34}
{'loss': 0.0171, 'grad_norm': 6.897818565368652, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.014723540283739567, 'loss_2': 0.0024127960205078125, 'loss_3': -16.385772705078125, 'loss_4': 0.4138562083244324, 'epoch': 14.35}
{'loss': 0.0104, 'grad_norm': 5.483513355255127, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.008025120943784714, 'loss_2': 0.002422332763671875, 'loss_3': -16.49036979675293, 'loss_4': 0.38418078422546387, 'epoch': 14.35}
{'loss': 0.0076, 'grad_norm': 4.732307434082031, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.005065924488008022, 'loss_2': 0.00251007080078125, 'loss_3': -16.464672088623047, 'loss_4': 0.3899298906326294, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 13:21:25,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:25,189 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:19<46:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:32,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017162032425403595, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.874, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013918064534664154, 'eval_loss_2': 0.003243967890739441, 'eval_loss_3': -18.249874114990234, 'eval_loss_4': 0.3622446656227112, 'epoch': 14.36}
{'loss': 0.0157, 'grad_norm': 7.407547950744629, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.014750099740922451, 'loss_2': 0.0009050369262695312, 'loss_3': -16.28139305114746, 'loss_4': 0.20478200912475586, 'epoch': 14.37}
{'loss': 0.0088, 'grad_norm': 4.009637355804443, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.0035278231371194124, 'loss_2': 0.00527191162109375, 'loss_3': -16.527755737304688, 'loss_4': 0.44229304790496826, 'epoch': 14.37}
{'loss': 0.0212, 'grad_norm': 7.529033184051514, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.012526441365480423, 'loss_2': 0.0086669921875, 'loss_3': -16.47418785095215, 'loss_4': 0.5676324963569641, 'epoch': 14.38}
{'loss': 0.0077, 'grad_norm': 4.9758124351501465, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.005354185122996569, 'loss_2': 0.00229644775390625, 'loss_3': -16.277681350708008, 'loss_4': 0.4901272654533386, 'epoch': 14.38}
{'loss': 0.0177, 'grad_norm': 11.460662841796875, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.015310627408325672, 'loss_2': 0.002346038818359375, 'loss_3': -16.54849624633789, 'loss_4': 0.5183008909225464, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 13:21:32,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:32,545 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:26<46:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:39,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015835396945476532, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012085073627531528, 'eval_loss_2': 0.003750324249267578, 'eval_loss_3': -18.27182388305664, 'eval_loss_4': 0.4448268413543701, 'epoch': 14.39}
{'loss': 0.0156, 'grad_norm': 7.072929382324219, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.013840879313647747, 'loss_2': 0.0017108917236328125, 'loss_3': -16.254470825195312, 'loss_4': 0.45410019159317017, 'epoch': 14.4}
{'loss': 0.0139, 'grad_norm': 4.864137172698975, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.0075562503188848495, 'loss_2': 0.006351470947265625, 'loss_3': -16.23141860961914, 'loss_4': 0.2919219434261322, 'epoch': 14.4}
{'loss': 0.0089, 'grad_norm': 4.618229389190674, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.006830521393567324, 'loss_2': 0.00209808349609375, 'loss_3': -16.239742279052734, 'loss_4': 0.5729304552078247, 'epoch': 14.41}
{'loss': 0.0181, 'grad_norm': 5.607675075531006, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.013549629598855972, 'loss_2': 0.004505157470703125, 'loss_3': -16.22040557861328, 'loss_4': 0.4232935607433319, 'epoch': 14.41}
{'loss': 0.0108, 'grad_norm': 5.979450702667236, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.01032424345612526, 'loss_2': 0.00047016143798828125, 'loss_3': -16.137104034423828, 'loss_4': 0.5443974733352661, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 13:21:39,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:39,895 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:34<46:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:47,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01518280990421772, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.924, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011816547252237797, 'eval_loss_2': 0.0033662617206573486, 'eval_loss_3': -18.28933334350586, 'eval_loss_4': 0.4976886510848999, 'epoch': 14.42}
{'loss': 0.02, 'grad_norm': 8.433507919311523, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.019391020759940147, 'loss_2': 0.0005993843078613281, 'loss_3': -16.335119247436523, 'loss_4': -0.046903640031814575, 'epoch': 14.42}
{'loss': 0.0197, 'grad_norm': 7.165177345275879, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.015431207604706287, 'loss_2': 0.0043182373046875, 'loss_3': -16.411598205566406, 'loss_4': 0.9298394322395325, 'epoch': 14.43}
{'loss': 0.0293, 'grad_norm': 12.874249458312988, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.024356268346309662, 'loss_2': 0.0049285888671875, 'loss_3': -16.18742561340332, 'loss_4': 0.7801849246025085, 'epoch': 14.44}
{'loss': 0.0475, 'grad_norm': 18.735191345214844, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.04714793711900711, 'loss_2': 0.0003330707550048828, 'loss_3': -16.33595085144043, 'loss_4': 0.31049370765686035, 'epoch': 14.44}
{'loss': 0.019, 'grad_norm': 7.074246406555176, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.014685036614537239, 'loss_2': 0.0042724609375, 'loss_3': -16.43636131286621, 'loss_4': 1.0837624073028564, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 13:21:47,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:47,254 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:41<46:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:54,615 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014827721752226353, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011824839748442173, 'eval_loss_2': 0.0030028820037841797, 'eval_loss_3': -18.290075302124023, 'eval_loss_4': 0.5032699108123779, 'epoch': 14.45}
{'loss': 0.0142, 'grad_norm': 6.736699104309082, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.013180768117308617, 'loss_2': 0.001018524169921875, 'loss_3': -16.344141006469727, 'loss_4': 0.6697288751602173, 'epoch': 14.45}
{'loss': 0.0204, 'grad_norm': 5.337369918823242, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.01762295514345169, 'loss_2': 0.0027313232421875, 'loss_3': -16.433643341064453, 'loss_4': 1.1001160144805908, 'epoch': 14.46}
{'loss': 0.0143, 'grad_norm': 5.097372055053711, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.009297235868871212, 'loss_2': 0.004970550537109375, 'loss_3': -16.133880615234375, 'loss_4': 0.5468130111694336, 'epoch': 14.47}
{'loss': 0.036, 'grad_norm': 15.952062606811523, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.033192798495292664, 'loss_2': 0.0028476715087890625, 'loss_3': -16.39051055908203, 'loss_4': 0.34513193368911743, 'epoch': 14.47}
{'loss': 0.0147, 'grad_norm': 6.406977653503418, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.011728624813258648, 'loss_2': 0.0030040740966796875, 'loss_3': -16.384511947631836, 'loss_4': 0.4594578742980957, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 13:21:54,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:54,615 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:49<46:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:01,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015503041446208954, 'eval_runtime': 3.8256, 'eval_samples_per_second': 267.667, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.012824108824133873, 'eval_loss_2': 0.0026789307594299316, 'eval_loss_3': -18.26038932800293, 'eval_loss_4': 0.3207649886608124, 'epoch': 14.48}
{'loss': 0.0155, 'grad_norm': 4.405496120452881, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.008763380348682404, 'loss_2': 0.00672149658203125, 'loss_3': -16.2427921295166, 'loss_4': 0.4645797610282898, 'epoch': 14.48}
{'loss': 0.0198, 'grad_norm': 6.705350399017334, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.015503495931625366, 'loss_2': 0.00432586669921875, 'loss_3': -16.28765106201172, 'loss_4': -0.1334936022758484, 'epoch': 14.49}
{'loss': 0.0115, 'grad_norm': 5.516822338104248, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.011335109360516071, 'loss_2': 0.00019431114196777344, 'loss_3': -16.41234588623047, 'loss_4': 0.4658510088920593, 'epoch': 14.49}
{'loss': 0.0121, 'grad_norm': 5.670158863067627, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.008827054873108864, 'loss_2': 0.003276824951171875, 'loss_3': -16.3184814453125, 'loss_4': 0.22639471292495728, 'epoch': 14.5}
{'loss': 0.0315, 'grad_norm': 19.57391929626465, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.020881470292806625, 'loss_2': 0.010589599609375, 'loss_3': -16.306259155273438, 'loss_4': 0.3425591289997101, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 13:22:01,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:01,985 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:56<46:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:09,333 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015423519536852837, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.22, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012759215198457241, 'eval_loss_2': 0.00266430526971817, 'eval_loss_3': -18.230972290039062, 'eval_loss_4': 0.16476008296012878, 'epoch': 14.51}
{'loss': 0.0131, 'grad_norm': 5.948212623596191, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.011166692711412907, 'loss_2': 0.0019817352294921875, 'loss_3': -16.365398406982422, 'loss_4': -0.12967853248119354, 'epoch': 14.51}
{'loss': 0.0199, 'grad_norm': 5.64732027053833, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.01765223778784275, 'loss_2': 0.002277374267578125, 'loss_3': -16.280742645263672, 'loss_4': 0.1443122774362564, 'epoch': 14.52}
{'loss': 0.0162, 'grad_norm': 6.169882774353027, 'learning_rate': 1.55e-05, 'loss_1': 0.014626463875174522, 'loss_2': 0.001560211181640625, 'loss_3': -16.231828689575195, 'loss_4': -0.11709392070770264, 'epoch': 14.52}
{'loss': 0.0154, 'grad_norm': 6.5363593101501465, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.012148499488830566, 'loss_2': 0.003253936767578125, 'loss_3': -16.375261306762695, 'loss_4': 0.06021862104535103, 'epoch': 14.53}
{'loss': 0.0182, 'grad_norm': 9.846735000610352, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.014881758019328117, 'loss_2': 0.003314971923828125, 'loss_3': -16.498689651489258, 'loss_4': 0.38442274928092957, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 13:22:09,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:09,334 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:02:03<45:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:16,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018783338367938995, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015172772109508514, 'eval_loss_2': 0.003610566258430481, 'eval_loss_3': -18.20372772216797, 'eval_loss_4': 0.09692058712244034, 'epoch': 14.53}
{'loss': 0.0112, 'grad_norm': 4.877798080444336, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.004725804552435875, 'loss_2': 0.00652313232421875, 'loss_3': -16.47795867919922, 'loss_4': -0.07445137202739716, 'epoch': 14.54}
{'loss': 0.0154, 'grad_norm': 4.602025985717773, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.008325549773871899, 'loss_2': 0.00707244873046875, 'loss_3': -16.211538314819336, 'loss_4': 0.29888004064559937, 'epoch': 14.55}
{'loss': 0.0099, 'grad_norm': 5.193513870239258, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.007575477939099073, 'loss_2': 0.002285003662109375, 'loss_3': -16.395816802978516, 'loss_4': 0.16484665870666504, 'epoch': 14.55}
{'loss': 0.0131, 'grad_norm': 5.154619216918945, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.006614135578274727, 'loss_2': 0.00649261474609375, 'loss_3': -16.376266479492188, 'loss_4': 0.35692286491394043, 'epoch': 14.56}
{'loss': 0.012, 'grad_norm': 4.707997798919678, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.005697612650692463, 'loss_2': 0.00632476806640625, 'loss_3': -16.170822143554688, 'loss_4': -0.012001857161521912, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 13:22:16,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:16,679 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:11<45:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:24,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016616111621260643, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.665, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014517215080559254, 'eval_loss_2': 0.0020988956093788147, 'eval_loss_3': -18.203388214111328, 'eval_loss_4': 0.026414092630147934, 'epoch': 14.56}
{'loss': 0.0093, 'grad_norm': 5.962811470031738, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.008069325238466263, 'loss_2': 0.0012683868408203125, 'loss_3': -16.454792022705078, 'loss_4': 0.010324053466320038, 'epoch': 14.57}
{'loss': 0.0048, 'grad_norm': 4.28012752532959, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.0043169669806957245, 'loss_2': 0.00046634674072265625, 'loss_3': -16.549774169921875, 'loss_4': -0.38956233859062195, 'epoch': 14.58}
{'loss': 0.0215, 'grad_norm': 9.996811866760254, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.0176386758685112, 'loss_2': 0.003879547119140625, 'loss_3': -16.183210372924805, 'loss_4': -0.03578401729464531, 'epoch': 14.58}
{'loss': 0.0066, 'grad_norm': 4.58721399307251, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.0064422558061778545, 'loss_2': 0.00015592575073242188, 'loss_3': -16.265178680419922, 'loss_4': 0.09156425297260284, 'epoch': 14.59}
{'loss': 0.0178, 'grad_norm': 6.917459011077881, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.012888532131910324, 'loss_2': 0.00487518310546875, 'loss_3': -16.350791931152344, 'loss_4': -0.1905009001493454, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 13:22:24,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:24,034 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:18<45:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:31,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01677316427230835, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.398, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01229444146156311, 'eval_loss_2': 0.004478722810745239, 'eval_loss_3': -18.22140121459961, 'eval_loss_4': -0.015135242603719234, 'epoch': 14.59}
{'loss': 0.0106, 'grad_norm': 5.430593967437744, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.008821862749755383, 'loss_2': 0.0017538070678710938, 'loss_3': -16.25714874267578, 'loss_4': -0.04376967251300812, 'epoch': 14.6}
{'loss': 0.0124, 'grad_norm': 4.750916481018066, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.004589817486703396, 'loss_2': 0.007843017578125, 'loss_3': -16.439098358154297, 'loss_4': -0.0726887583732605, 'epoch': 14.6}
{'loss': 0.0263, 'grad_norm': 6.211289882659912, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.011705072596669197, 'loss_2': 0.01458740234375, 'loss_3': -16.367950439453125, 'loss_4': 0.2114602029323578, 'epoch': 14.61}
{'loss': 0.0093, 'grad_norm': 4.3479790687561035, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.004266364499926567, 'loss_2': 0.004985809326171875, 'loss_3': -16.364866256713867, 'loss_4': -0.15458200871944427, 'epoch': 14.62}
{'loss': 0.0107, 'grad_norm': 5.027292728424072, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.006679363548755646, 'loss_2': 0.004058837890625, 'loss_3': -16.421096801757812, 'loss_4': 0.05334655940532684, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 13:22:31,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:31,399 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:25<45:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:38,762 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01515466533601284, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.41, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0120528694242239, 'eval_loss_2': 0.0031017959117889404, 'eval_loss_3': -18.21375274658203, 'eval_loss_4': -0.0960484966635704, 'epoch': 14.62}
{'loss': 0.0167, 'grad_norm': 5.850074768066406, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.011338474228978157, 'loss_2': 0.00537109375, 'loss_3': -16.334068298339844, 'loss_4': 0.38271135091781616, 'epoch': 14.63}
{'loss': 0.0145, 'grad_norm': 5.597410678863525, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.0072095030918717384, 'loss_2': 0.00730133056640625, 'loss_3': -16.19230079650879, 'loss_4': -0.4870297908782959, 'epoch': 14.63}
{'loss': 0.0097, 'grad_norm': 7.664427280426025, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.008798887021839619, 'loss_2': 0.000911712646484375, 'loss_3': -16.42308807373047, 'loss_4': -0.09391636401414871, 'epoch': 14.64}
{'loss': 0.0072, 'grad_norm': 5.197754859924316, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.005992886144667864, 'loss_2': 0.0012378692626953125, 'loss_3': -16.282161712646484, 'loss_4': -0.40824007987976074, 'epoch': 14.65}
{'loss': 0.0164, 'grad_norm': 5.278634071350098, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.01309951487928629, 'loss_2': 0.0032787322998046875, 'loss_3': -16.431196212768555, 'loss_4': 0.06494972854852676, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 13:22:38,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:38,762 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:33<45:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:46,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01690470054745674, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012735234573483467, 'eval_loss_2': 0.004169464111328125, 'eval_loss_3': -18.223922729492188, 'eval_loss_4': -0.2440539449453354, 'epoch': 14.65}
{'loss': 0.0072, 'grad_norm': 4.633625507354736, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.0034665341954678297, 'loss_2': 0.003753662109375, 'loss_3': -16.518991470336914, 'loss_4': -0.2518673539161682, 'epoch': 14.66}
{'loss': 0.0118, 'grad_norm': 4.8160200119018555, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.007797751575708389, 'loss_2': 0.003963470458984375, 'loss_3': -16.584003448486328, 'loss_4': -0.011718593537807465, 'epoch': 14.66}
{'loss': 0.0135, 'grad_norm': 7.864202976226807, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.012917759828269482, 'loss_2': 0.0005474090576171875, 'loss_3': -16.43718719482422, 'loss_4': -0.28726500272750854, 'epoch': 14.67}
{'loss': 0.011, 'grad_norm': 4.436436176300049, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.00620904890820384, 'loss_2': 0.00482940673828125, 'loss_3': -16.522159576416016, 'loss_4': -0.36052238941192627, 'epoch': 14.67}
{'loss': 0.0095, 'grad_norm': 5.072385787963867, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.00441818917170167, 'loss_2': 0.0050811767578125, 'loss_3': -16.550527572631836, 'loss_4': -0.7751349210739136, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 13:22:46,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:46,118 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:40<45:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:53,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0162496455013752, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01247432641685009, 'eval_loss_2': 0.003775317221879959, 'eval_loss_3': -18.266569137573242, 'eval_loss_4': -0.3026806712150574, 'epoch': 14.68}
{'loss': 0.0295, 'grad_norm': 19.329906463623047, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.029323507100343704, 'loss_2': 0.0001385211944580078, 'loss_3': -16.55349349975586, 'loss_4': -0.1415858268737793, 'epoch': 14.69}
{'loss': 0.011, 'grad_norm': 7.0525383949279785, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.0073760817758738995, 'loss_2': 0.00359344482421875, 'loss_3': -16.479290008544922, 'loss_4': -0.32803040742874146, 'epoch': 14.69}
{'loss': 0.0147, 'grad_norm': 4.415346145629883, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.004957336466759443, 'loss_2': 0.009735107421875, 'loss_3': -16.470726013183594, 'loss_4': -0.5160350799560547, 'epoch': 14.7}
{'loss': 0.0294, 'grad_norm': 11.76264762878418, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.026386216282844543, 'loss_2': 0.0030517578125, 'loss_3': -16.531044006347656, 'loss_4': 0.05042846500873566, 'epoch': 14.7}
{'loss': 0.0179, 'grad_norm': 5.763547897338867, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.010174897499382496, 'loss_2': 0.00775146484375, 'loss_3': -16.382667541503906, 'loss_4': 0.32423657178878784, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 13:22:53,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:53,472 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:47<45:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:00,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01820756308734417, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.111, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014156593941152096, 'eval_loss_2': 0.0040509700775146484, 'eval_loss_3': -18.2878360748291, 'eval_loss_4': -0.15187354385852814, 'epoch': 14.71}
{'loss': 0.0158, 'grad_norm': 7.656741142272949, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.011557101272046566, 'loss_2': 0.00426483154296875, 'loss_3': -16.448705673217773, 'loss_4': -0.4714674949645996, 'epoch': 14.72}
{'loss': 0.0086, 'grad_norm': 5.584943771362305, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.006400165148079395, 'loss_2': 0.002193450927734375, 'loss_3': -16.28989028930664, 'loss_4': -0.2360960841178894, 'epoch': 14.72}
{'loss': 0.02, 'grad_norm': 7.191242694854736, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.01463492400944233, 'loss_2': 0.005401611328125, 'loss_3': -16.38361930847168, 'loss_4': -0.08121021836996078, 'epoch': 14.73}
{'loss': 0.0124, 'grad_norm': 5.19868803024292, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.006113676354289055, 'loss_2': 0.006313323974609375, 'loss_3': -16.535388946533203, 'loss_4': -0.22804127633571625, 'epoch': 14.73}
{'loss': 0.0177, 'grad_norm': 6.265585422515869, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.010173662565648556, 'loss_2': 0.007518768310546875, 'loss_3': -16.400548934936523, 'loss_4': -0.060555845499038696, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 13:23:00,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:00,818 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:55<45:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:08,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019858481362462044, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.775, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0157413799315691, 'eval_loss_2': 0.004117101430892944, 'eval_loss_3': -18.273292541503906, 'eval_loss_4': -0.1608843207359314, 'epoch': 14.74}
{'loss': 0.0199, 'grad_norm': 8.205035209655762, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.015390927903354168, 'loss_2': 0.00449371337890625, 'loss_3': -16.16240119934082, 'loss_4': -0.3108345568180084, 'epoch': 14.74}
{'loss': 0.013, 'grad_norm': 5.5262298583984375, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.00993511825799942, 'loss_2': 0.003047943115234375, 'loss_3': -16.583017349243164, 'loss_4': 0.1284826695919037, 'epoch': 14.75}
{'loss': 0.0081, 'grad_norm': 4.762557029724121, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.006411691661924124, 'loss_2': 0.0016717910766601562, 'loss_3': -16.24283218383789, 'loss_4': -0.3096236288547516, 'epoch': 14.76}
{'loss': 0.0167, 'grad_norm': 5.203567981719971, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.01083183754235506, 'loss_2': 0.005855560302734375, 'loss_3': -16.394065856933594, 'loss_4': 0.2576271593570709, 'epoch': 14.76}
{'loss': 0.0109, 'grad_norm': 4.967002868652344, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.007321270648390055, 'loss_2': 0.00356292724609375, 'loss_3': -16.530160903930664, 'loss_4': -0.2455320954322815, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 13:23:08,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:08,173 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:03:02<45:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:15,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01854221150279045, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.9, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01562950387597084, 'eval_loss_2': 0.0029127076268196106, 'eval_loss_3': -18.258953094482422, 'eval_loss_4': -0.14357995986938477, 'epoch': 14.77}
{'loss': 0.0684, 'grad_norm': 17.27364158630371, 'learning_rate': 1.525e-05, 'loss_1': 0.06452158093452454, 'loss_2': 0.003887176513671875, 'loss_3': -16.369348526000977, 'loss_4': 0.054686516523361206, 'epoch': 14.77}
{'loss': 0.0123, 'grad_norm': 7.0314812660217285, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.00920918956398964, 'loss_2': 0.0031375885009765625, 'loss_3': -16.189422607421875, 'loss_4': 0.014963116496801376, 'epoch': 14.78}
{'loss': 0.0275, 'grad_norm': 11.21572208404541, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.022991875186562538, 'loss_2': 0.004497528076171875, 'loss_3': -16.388629913330078, 'loss_4': -0.33822375535964966, 'epoch': 14.78}
{'loss': 0.0267, 'grad_norm': 11.56192398071289, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.025091033428907394, 'loss_2': 0.001621246337890625, 'loss_3': -16.346454620361328, 'loss_4': -0.31409162282943726, 'epoch': 14.79}
{'loss': 0.0122, 'grad_norm': 4.44904088973999, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.003932996653020382, 'loss_2': 0.008270263671875, 'loss_3': -16.402734756469727, 'loss_4': -0.1519252061843872, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 13:23:15,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:15,530 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:09<45:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:22,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018162645399570465, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.466, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.014860532246530056, 'eval_loss_2': 0.0033021122217178345, 'eval_loss_3': -18.272985458374023, 'eval_loss_4': -0.21233907341957092, 'epoch': 14.8}
{'loss': 0.0131, 'grad_norm': 5.644105911254883, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.011746779084205627, 'loss_2': 0.00131988525390625, 'loss_3': -16.438983917236328, 'loss_4': -0.1522352695465088, 'epoch': 14.8}
{'loss': 0.0106, 'grad_norm': 4.795840263366699, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.008141396567225456, 'loss_2': 0.002475738525390625, 'loss_3': -16.504316329956055, 'loss_4': -0.30224382877349854, 'epoch': 14.81}
{'loss': 0.0093, 'grad_norm': 5.734534740447998, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.007688550278544426, 'loss_2': 0.0016088485717773438, 'loss_3': -16.47333526611328, 'loss_4': -0.679074227809906, 'epoch': 14.81}
{'loss': 0.0124, 'grad_norm': 4.712966442108154, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.007297375705093145, 'loss_2': 0.005062103271484375, 'loss_3': -16.444578170776367, 'loss_4': -0.01874392479658127, 'epoch': 14.82}
{'loss': 0.0063, 'grad_norm': 4.506330490112305, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.0050355419516563416, 'loss_2': 0.001232147216796875, 'loss_3': -16.480361938476562, 'loss_4': -0.18471597135066986, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 13:23:22,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:22,890 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:17<45:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:30,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015314418822526932, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011670907959342003, 'eval_loss_2': 0.003643512725830078, 'eval_loss_3': -18.278980255126953, 'eval_loss_4': -0.43278682231903076, 'epoch': 14.83}
{'loss': 0.0166, 'grad_norm': 5.804982662200928, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.009791632182896137, 'loss_2': 0.006778717041015625, 'loss_3': -16.510990142822266, 'loss_4': 0.01739242672920227, 'epoch': 14.83}
{'loss': 0.0221, 'grad_norm': 6.389833927154541, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.013990834355354309, 'loss_2': 0.008148193359375, 'loss_3': -16.693849563598633, 'loss_4': -0.05068528652191162, 'epoch': 14.84}
{'loss': 0.0074, 'grad_norm': 4.828338146209717, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.005389262922108173, 'loss_2': 0.001987457275390625, 'loss_3': -16.156410217285156, 'loss_4': -0.17412765324115753, 'epoch': 14.84}
{'loss': 0.0167, 'grad_norm': 5.3457865715026855, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.007890285924077034, 'loss_2': 0.00884246826171875, 'loss_3': -16.435203552246094, 'loss_4': -0.20813055336475372, 'epoch': 14.85}
{'loss': 0.0133, 'grad_norm': 4.835752010345459, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.007582204416394234, 'loss_2': 0.00574493408203125, 'loss_3': -16.357059478759766, 'loss_4': -0.4382140636444092, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 13:23:30,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:30,242 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:24<44:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:37,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015636228024959564, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.994, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012302315793931484, 'eval_loss_2': 0.0033339112997055054, 'eval_loss_3': -18.29175567626953, 'eval_loss_4': -0.4793163537979126, 'epoch': 14.85}
{'loss': 0.0189, 'grad_norm': 8.156309127807617, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.01384394709020853, 'loss_2': 0.005035400390625, 'loss_3': -16.470863342285156, 'loss_4': -0.3312031924724579, 'epoch': 14.86}
{'loss': 0.0113, 'grad_norm': 6.08160924911499, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.00722934165969491, 'loss_2': 0.004024505615234375, 'loss_3': -16.37525749206543, 'loss_4': 0.3159336447715759, 'epoch': 14.87}
{'loss': 0.0445, 'grad_norm': 16.021486282348633, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.03751257434487343, 'loss_2': 0.0069427490234375, 'loss_3': -16.2259521484375, 'loss_4': -0.64827561378479, 'epoch': 14.87}
{'loss': 0.0158, 'grad_norm': 5.394392013549805, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.01190428901463747, 'loss_2': 0.00390625, 'loss_3': -16.169471740722656, 'loss_4': -0.6110286712646484, 'epoch': 14.88}
{'loss': 0.0217, 'grad_norm': 6.831948280334473, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.015238489024341106, 'loss_2': 0.00643157958984375, 'loss_3': -16.429244995117188, 'loss_4': -0.5118297338485718, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 13:23:37,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:37,591 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:31<44:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:44,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015892311930656433, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.327, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01310171838849783, 'eval_loss_2': 0.002790592610836029, 'eval_loss_3': -18.261146545410156, 'eval_loss_4': -0.6005666851997375, 'epoch': 14.88}
{'loss': 0.01, 'grad_norm': 5.7741312980651855, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.007892885245382786, 'loss_2': 0.00211334228515625, 'loss_3': -16.3160400390625, 'loss_4': -0.32739198207855225, 'epoch': 14.89}
{'loss': 0.0145, 'grad_norm': 5.835386276245117, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.007115150801837444, 'loss_2': 0.007358551025390625, 'loss_3': -16.285614013671875, 'loss_4': -0.5634300708770752, 'epoch': 14.9}
{'loss': 0.0166, 'grad_norm': 6.277081489562988, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.015465164557099342, 'loss_2': 0.0011119842529296875, 'loss_3': -16.2520751953125, 'loss_4': -1.0929458141326904, 'epoch': 14.9}
{'loss': 0.0134, 'grad_norm': 6.074307441711426, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.012757810764014721, 'loss_2': 0.0006685256958007812, 'loss_3': -16.125667572021484, 'loss_4': -0.9069859385490417, 'epoch': 14.91}
{'loss': 0.0171, 'grad_norm': 7.940439224243164, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.016602274030447006, 'loss_2': 0.0004949569702148438, 'loss_3': -16.138622283935547, 'loss_4': -0.2658613324165344, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 13:23:44,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:44,934 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:39<44:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:52,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01605840027332306, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.773, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01393305417150259, 'eval_loss_2': 0.0021253451704978943, 'eval_loss_3': -18.25642967224121, 'eval_loss_4': -0.6567941308021545, 'epoch': 14.91}
{'loss': 0.0147, 'grad_norm': 5.110776424407959, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.005726057104766369, 'loss_2': 0.00896453857421875, 'loss_3': -16.174152374267578, 'loss_4': -0.9753611087799072, 'epoch': 14.92}
{'loss': 0.0155, 'grad_norm': 7.966747283935547, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.012785802595317364, 'loss_2': 0.0027618408203125, 'loss_3': -16.346729278564453, 'loss_4': -0.26878270506858826, 'epoch': 14.92}
{'loss': 0.0173, 'grad_norm': 6.749218463897705, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.013082227669656277, 'loss_2': 0.0042266845703125, 'loss_3': -16.246967315673828, 'loss_4': -0.5790585279464722, 'epoch': 14.93}
{'loss': 0.0132, 'grad_norm': 8.138607025146484, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.00894917082041502, 'loss_2': 0.0042572021484375, 'loss_3': -16.44797134399414, 'loss_4': -0.43628501892089844, 'epoch': 14.94}
{'loss': 0.0041, 'grad_norm': 4.326786041259766, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.003626252058893442, 'loss_2': 0.0004334449768066406, 'loss_3': -16.333885192871094, 'loss_4': -0.36250928044319153, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 13:23:52,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:52,283 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:46<44:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:59,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018232276663184166, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015950864180922508, 'eval_loss_2': 0.0022814124822616577, 'eval_loss_3': -18.222177505493164, 'eval_loss_4': -0.6018906235694885, 'epoch': 14.94}
{'loss': 0.0092, 'grad_norm': 6.338284969329834, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.006766317877918482, 'loss_2': 0.00241851806640625, 'loss_3': -16.2905330657959, 'loss_4': -0.6132110953330994, 'epoch': 14.95}
{'loss': 0.0157, 'grad_norm': 5.9491047859191895, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.01385806780308485, 'loss_2': 0.00183868408203125, 'loss_3': -16.388948440551758, 'loss_4': -0.22109048068523407, 'epoch': 14.95}
{'loss': 0.0113, 'grad_norm': 6.153764247894287, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.009903740137815475, 'loss_2': 0.0013837814331054688, 'loss_3': -16.211034774780273, 'loss_4': -0.5420881509780884, 'epoch': 14.96}
{'loss': 0.0155, 'grad_norm': 7.152077674865723, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.00939506758004427, 'loss_2': 0.00614166259765625, 'loss_3': -16.34420394897461, 'loss_4': -0.38617947697639465, 'epoch': 14.97}
{'loss': 0.0409, 'grad_norm': 15.133874893188477, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.03723261132836342, 'loss_2': 0.0036525726318359375, 'loss_3': -16.386640548706055, 'loss_4': -0.22205403447151184, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 13:23:59,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:59,628 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:53<40:09,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:24:06,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0190273430198431, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.685, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.016484459862113, 'eval_loss_2': 0.0025428831577301025, 'eval_loss_3': -18.186843872070312, 'eval_loss_4': -0.40421465039253235, 'epoch': 14.97}
{'loss': 0.0095, 'grad_norm': 4.433486461639404, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.007220762316137552, 'loss_2': 0.0022983551025390625, 'loss_3': -16.276880264282227, 'loss_4': -0.9031379818916321, 'epoch': 14.98}
{'loss': 0.0336, 'grad_norm': 13.010849952697754, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.032467130571603775, 'loss_2': 0.0010833740234375, 'loss_3': -16.49677276611328, 'loss_4': -0.023047953844070435, 'epoch': 14.98}
{'loss': 0.0123, 'grad_norm': 5.161344051361084, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.008422749117016792, 'loss_2': 0.00388336181640625, 'loss_3': -16.310815811157227, 'loss_4': -0.21636050939559937, 'epoch': 14.99}
{'loss': 0.018, 'grad_norm': 5.9238152503967285, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.012735973112285137, 'loss_2': 0.005306243896484375, 'loss_3': -16.161163330078125, 'loss_4': -0.3920579254627228, 'epoch': 14.99}
{'loss': 0.0023, 'grad_norm': 6.497338771820068, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.0019330424256622791, 'loss_2': 0.0003809928894042969, 'loss_3': -16.13296127319336, 'loss_4': -0.3512375056743622, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 13:24:06,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:06,632 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:04:01<43:53,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:24:14,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02007090114057064, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016401758417487144, 'eval_loss_2': 0.003669142723083496, 'eval_loss_3': -18.164180755615234, 'eval_loss_4': -0.32815977931022644, 'epoch': 15.0}
{'loss': 0.0091, 'grad_norm': 4.911135196685791, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.006442732643336058, 'loss_2': 0.002620697021484375, 'loss_3': -16.242351531982422, 'loss_4': -0.4798617362976074, 'epoch': 15.01}
{'loss': 0.0099, 'grad_norm': 5.188164710998535, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.005845003295689821, 'loss_2': 0.004058837890625, 'loss_3': -16.348697662353516, 'loss_4': -0.2872699499130249, 'epoch': 15.01}
{'loss': 0.0117, 'grad_norm': 6.587147235870361, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.010449564084410667, 'loss_2': 0.001247406005859375, 'loss_3': -16.456607818603516, 'loss_4': -0.08593401312828064, 'epoch': 15.02}
{'loss': 0.0104, 'grad_norm': 6.680360794067383, 'learning_rate': 1.5e-05, 'loss_1': 0.009860733523964882, 'loss_2': 0.0005803108215332031, 'loss_3': -16.14801788330078, 'loss_4': 0.2171923965215683, 'epoch': 15.02}
{'loss': 0.0076, 'grad_norm': 4.511675834655762, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.0057806093245744705, 'loss_2': 0.0018224716186523438, 'loss_3': -16.300498962402344, 'loss_4': 0.08560995012521744, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 13:24:14,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:14,018 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:08<44:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:24:21,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02010052464902401, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01689058728516102, 'eval_loss_2': 0.0032099373638629913, 'eval_loss_3': -18.134628295898438, 'eval_loss_4': -0.2665746510028839, 'epoch': 15.03}
{'loss': 0.0141, 'grad_norm': 5.230183124542236, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.00572108943015337, 'loss_2': 0.00835418701171875, 'loss_3': -16.288530349731445, 'loss_4': -0.23579788208007812, 'epoch': 15.03}
{'loss': 0.0198, 'grad_norm': 9.490007400512695, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.016549604013562202, 'loss_2': 0.0032138824462890625, 'loss_3': -16.200178146362305, 'loss_4': -0.12180086970329285, 'epoch': 15.04}
{'loss': 0.019, 'grad_norm': 6.219266891479492, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.011956089176237583, 'loss_2': 0.007080078125, 'loss_3': -16.226329803466797, 'loss_4': -0.1381208300590515, 'epoch': 15.05}
{'loss': 0.0164, 'grad_norm': 6.6522369384765625, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.01284308172762394, 'loss_2': 0.00354766845703125, 'loss_3': -16.065946578979492, 'loss_4': -0.31120118498802185, 'epoch': 15.05}
{'loss': 0.0232, 'grad_norm': 7.167355060577393, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.016460102051496506, 'loss_2': 0.00669097900390625, 'loss_3': -16.099952697753906, 'loss_4': -0.3169049024581909, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 13:24:21,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:21,363 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:15<44:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:28,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019289329648017883, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016061319038271904, 'eval_loss_2': 0.00322800874710083, 'eval_loss_3': -18.16118049621582, 'eval_loss_4': -0.29587996006011963, 'epoch': 15.06}
{'loss': 0.0193, 'grad_norm': 8.358149528503418, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.016970327123999596, 'loss_2': 0.00235748291015625, 'loss_3': -16.048078536987305, 'loss_4': -0.5893582105636597, 'epoch': 15.06}
{'loss': 0.0327, 'grad_norm': 12.10770320892334, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.023092910647392273, 'loss_2': 0.0095977783203125, 'loss_3': -16.03146743774414, 'loss_4': -0.3360150456428528, 'epoch': 15.07}
{'loss': 0.013, 'grad_norm': 5.747845649719238, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.010799729265272617, 'loss_2': 0.0022068023681640625, 'loss_3': -16.484540939331055, 'loss_4': 0.16771137714385986, 'epoch': 15.08}
{'loss': 0.0159, 'grad_norm': 6.3544230461120605, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.0107418866828084, 'loss_2': 0.00513458251953125, 'loss_3': -16.348968505859375, 'loss_4': 0.050065286457538605, 'epoch': 15.08}
{'loss': 0.0136, 'grad_norm': 4.977889060974121, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.010335071012377739, 'loss_2': 0.003246307373046875, 'loss_3': -16.315052032470703, 'loss_4': -0.4738773703575134, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 13:24:28,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:28,712 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:23<44:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:36,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018917830660939217, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01570889540016651, 'eval_loss_2': 0.003208935260772705, 'eval_loss_3': -18.199527740478516, 'eval_loss_4': -0.42900872230529785, 'epoch': 15.09}
{'loss': 0.017, 'grad_norm': 6.975599765777588, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.014115199446678162, 'loss_2': 0.002864837646484375, 'loss_3': -16.48270606994629, 'loss_4': -0.3601909577846527, 'epoch': 15.09}
{'loss': 0.0175, 'grad_norm': 7.274456977844238, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.01661129854619503, 'loss_2': 0.0008535385131835938, 'loss_3': -16.457233428955078, 'loss_4': -0.33537039160728455, 'epoch': 15.1}
{'loss': 0.0098, 'grad_norm': 6.827365875244141, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.008681715466082096, 'loss_2': 0.001140594482421875, 'loss_3': -16.32660675048828, 'loss_4': -0.23560386896133423, 'epoch': 15.1}
{'loss': 0.0192, 'grad_norm': 5.995967864990234, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.010931963101029396, 'loss_2': 0.00830078125, 'loss_3': -16.53120231628418, 'loss_4': -0.07089684903621674, 'epoch': 15.11}
{'loss': 0.0093, 'grad_norm': 5.089636325836182, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.005796816200017929, 'loss_2': 0.003551483154296875, 'loss_3': -16.271854400634766, 'loss_4': -0.3676275610923767, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 13:24:36,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:36,066 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:30<44:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:43,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018100999295711517, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.946, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013894454576075077, 'eval_loss_2': 0.004206545650959015, 'eval_loss_3': -18.24481964111328, 'eval_loss_4': -0.3289982080459595, 'epoch': 15.12}
{'loss': 0.0106, 'grad_norm': 5.6136088371276855, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.010220466181635857, 'loss_2': 0.00037288665771484375, 'loss_3': -16.27931785583496, 'loss_4': -0.06684625148773193, 'epoch': 15.12}
{'loss': 0.0208, 'grad_norm': 7.5103044509887695, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.011815829202532768, 'loss_2': 0.009002685546875, 'loss_3': -16.29731559753418, 'loss_4': -0.27493372559547424, 'epoch': 15.13}
{'loss': 0.0125, 'grad_norm': 5.4016804695129395, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.008792968466877937, 'loss_2': 0.00373077392578125, 'loss_3': -16.622207641601562, 'loss_4': -0.03025476634502411, 'epoch': 15.13}
{'loss': 0.0149, 'grad_norm': 5.571044445037842, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.011059033684432507, 'loss_2': 0.003879547119140625, 'loss_3': -16.1453857421875, 'loss_4': -0.17865782976150513, 'epoch': 15.14}
{'loss': 0.0151, 'grad_norm': 4.905123233795166, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.006246341858059168, 'loss_2': 0.0088958740234375, 'loss_3': -16.240459442138672, 'loss_4': 0.4503161907196045, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 13:24:43,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:43,418 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:37<44:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:50,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018873577937483788, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015294483862817287, 'eval_loss_2': 0.0035790950059890747, 'eval_loss_3': -18.248559951782227, 'eval_loss_4': -0.2135266661643982, 'epoch': 15.15}
{'loss': 0.0117, 'grad_norm': 5.8149094581604, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.010110949166119099, 'loss_2': 0.0016317367553710938, 'loss_3': -16.327926635742188, 'loss_4': -0.16107837855815887, 'epoch': 15.15}
{'loss': 0.0187, 'grad_norm': 5.4564714431762695, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.009273405186831951, 'loss_2': 0.0094757080078125, 'loss_3': -16.32912826538086, 'loss_4': 0.0651530921459198, 'epoch': 15.16}
{'loss': 0.0174, 'grad_norm': 6.417704105377197, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.012213461101055145, 'loss_2': 0.005176544189453125, 'loss_3': -16.27699851989746, 'loss_4': -0.3707175850868225, 'epoch': 15.16}
{'loss': 0.0964, 'grad_norm': 14.24708366394043, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.08768708258867264, 'loss_2': 0.008697509765625, 'loss_3': -16.229923248291016, 'loss_4': 0.1734485626220703, 'epoch': 15.17}
{'loss': 0.0207, 'grad_norm': 6.309148788452148, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.010063309222459793, 'loss_2': 0.010650634765625, 'loss_3': -16.39474105834961, 'loss_4': -0.11818546056747437, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 13:24:50,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:50,770 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:45<44:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:58,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019429266452789307, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01511821337044239, 'eval_loss_2': 0.004311054944992065, 'eval_loss_3': -18.248065948486328, 'eval_loss_4': -0.1923617273569107, 'epoch': 15.17}
{'loss': 0.0157, 'grad_norm': 5.603176593780518, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.01036433968693018, 'loss_2': 0.00531768798828125, 'loss_3': -16.40515899658203, 'loss_4': 0.019929945468902588, 'epoch': 15.18}
{'loss': 0.012, 'grad_norm': 5.846827030181885, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.011007341556251049, 'loss_2': 0.0010166168212890625, 'loss_3': -16.30942153930664, 'loss_4': -0.2513875663280487, 'epoch': 15.19}
{'loss': 0.0125, 'grad_norm': 5.142966270446777, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.009415149688720703, 'loss_2': 0.0031108856201171875, 'loss_3': -16.446104049682617, 'loss_4': -0.37100571393966675, 'epoch': 15.19}
{'loss': 0.0274, 'grad_norm': 18.99669647216797, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.023491043597459793, 'loss_2': 0.00388336181640625, 'loss_3': -16.521190643310547, 'loss_4': -0.23786121606826782, 'epoch': 15.2}
{'loss': 0.0389, 'grad_norm': 14.80450439453125, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.033158741891384125, 'loss_2': 0.005756378173828125, 'loss_3': -16.333866119384766, 'loss_4': -0.15651339292526245, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 13:24:58,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:58,122 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:52<43:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:05,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017434407025575638, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.182, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013571280054748058, 'eval_loss_2': 0.003863126039505005, 'eval_loss_3': -18.265789031982422, 'eval_loss_4': -0.35770854353904724, 'epoch': 15.2}
{'loss': 0.0209, 'grad_norm': 5.903407573699951, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.009932460263371468, 'loss_2': 0.01094818115234375, 'loss_3': -16.34882354736328, 'loss_4': -0.16608060896396637, 'epoch': 15.21}
{'loss': 0.0099, 'grad_norm': 5.030577659606934, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.007785348687320948, 'loss_2': 0.00214385986328125, 'loss_3': -16.302833557128906, 'loss_4': -1.2858237028121948, 'epoch': 15.22}
{'loss': 0.0335, 'grad_norm': 19.495031356811523, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.03323786333203316, 'loss_2': 0.00025534629821777344, 'loss_3': -16.208160400390625, 'loss_4': -0.4333495497703552, 'epoch': 15.22}
{'loss': 0.0153, 'grad_norm': 5.397822856903076, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.009571160189807415, 'loss_2': 0.00574493408203125, 'loss_3': -16.385326385498047, 'loss_4': -0.29323095083236694, 'epoch': 15.23}
{'loss': 0.0199, 'grad_norm': 13.744436264038086, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.016044247895479202, 'loss_2': 0.0038356781005859375, 'loss_3': -16.340620040893555, 'loss_4': 0.14714254438877106, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 13:25:05,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:05,471 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:59<43:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:12,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01675065979361534, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013135419227182865, 'eval_loss_2': 0.0036152414977550507, 'eval_loss_3': -18.284015655517578, 'eval_loss_4': -0.5592691898345947, 'epoch': 15.23}
{'loss': 0.0775, 'grad_norm': 20.860361099243164, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.06992318481206894, 'loss_2': 0.007541656494140625, 'loss_3': -16.336048126220703, 'loss_4': 0.18561938405036926, 'epoch': 15.24}
{'loss': 0.0254, 'grad_norm': 8.853342056274414, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.022190898656845093, 'loss_2': 0.0032367706298828125, 'loss_3': -16.350528717041016, 'loss_4': -0.19590115547180176, 'epoch': 15.24}
{'loss': 0.0069, 'grad_norm': 4.853448867797852, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.003749403404071927, 'loss_2': 0.003143310546875, 'loss_3': -16.580760955810547, 'loss_4': -0.5523547530174255, 'epoch': 15.25}
{'loss': 0.0149, 'grad_norm': 8.427248001098633, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.012154518626630306, 'loss_2': 0.0027618408203125, 'loss_3': -16.59746551513672, 'loss_4': -0.17628943920135498, 'epoch': 15.26}
{'loss': 0.0429, 'grad_norm': 14.535528182983398, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.041552454233169556, 'loss_2': 0.0013036727905273438, 'loss_3': -16.429645538330078, 'loss_4': -0.6936870813369751, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 13:25:12,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:12,822 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:05:07<43:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:20,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01842944324016571, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013544759713113308, 'eval_loss_2': 0.004884682595729828, 'eval_loss_3': -18.283432006835938, 'eval_loss_4': -0.5975009202957153, 'epoch': 15.26}
{'loss': 0.0167, 'grad_norm': 6.488208770751953, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.010213660076260567, 'loss_2': 0.006500244140625, 'loss_3': -16.311542510986328, 'loss_4': -0.4986041784286499, 'epoch': 15.27}
{'loss': 0.0076, 'grad_norm': 5.978283405303955, 'learning_rate': 1.475e-05, 'loss_1': 0.007035593967884779, 'loss_2': 0.0005350112915039062, 'loss_3': -16.39922523498535, 'loss_4': -0.4080202579498291, 'epoch': 15.27}
{'loss': 0.0113, 'grad_norm': 5.328516483306885, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.005545623134821653, 'loss_2': 0.0057830810546875, 'loss_3': -16.50778579711914, 'loss_4': -0.17727094888687134, 'epoch': 15.28}
{'loss': 0.01, 'grad_norm': 5.455913066864014, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.00946319755166769, 'loss_2': 0.0004944801330566406, 'loss_3': -16.34377670288086, 'loss_4': -0.28949174284935, 'epoch': 15.28}
{'loss': 0.0198, 'grad_norm': 8.365463256835938, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.01974078267812729, 'loss_2': 9.137392044067383e-05, 'loss_3': -16.523414611816406, 'loss_4': -0.09472524374723434, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 13:25:20,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:20,176 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:14<43:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:27,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017719238996505737, 'eval_runtime': 3.8188, 'eval_samples_per_second': 268.144, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.01276424527168274, 'eval_loss_2': 0.004954993724822998, 'eval_loss_3': -18.274282455444336, 'eval_loss_4': -0.6242504119873047, 'epoch': 15.29}
{'loss': 0.0126, 'grad_norm': 5.203004837036133, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.006808241363614798, 'loss_2': 0.005832672119140625, 'loss_3': -16.497051239013672, 'loss_4': -0.8294328451156616, 'epoch': 15.3}
{'loss': 0.032, 'grad_norm': 7.472973346710205, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.029042981564998627, 'loss_2': 0.00299835205078125, 'loss_3': -16.36542510986328, 'loss_4': -0.1680021584033966, 'epoch': 15.3}
{'loss': 0.0104, 'grad_norm': 5.147990703582764, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.008816130459308624, 'loss_2': 0.0015954971313476562, 'loss_3': -16.314002990722656, 'loss_4': -0.2958909571170807, 'epoch': 15.31}
{'loss': 0.0235, 'grad_norm': 11.509795188903809, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.016715601086616516, 'loss_2': 0.00678253173828125, 'loss_3': -16.281803131103516, 'loss_4': -0.9572610855102539, 'epoch': 15.31}
{'loss': 0.0143, 'grad_norm': 5.475248336791992, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.012682482600212097, 'loss_2': 0.0015954971313476562, 'loss_3': -16.502880096435547, 'loss_4': -1.0122721195220947, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 13:25:27,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:27,538 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:21<43:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:34,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01612493023276329, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01194228045642376, 'eval_loss_2': 0.00418265163898468, 'eval_loss_3': -18.293928146362305, 'eval_loss_4': -0.5758178234100342, 'epoch': 15.32}
{'loss': 0.0278, 'grad_norm': 9.881521224975586, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.027478845790028572, 'loss_2': 0.00033020973205566406, 'loss_3': -16.283178329467773, 'loss_4': -0.6177597045898438, 'epoch': 15.33}
{'loss': 0.044, 'grad_norm': 12.673579216003418, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.04257002845406532, 'loss_2': 0.0014352798461914062, 'loss_3': -16.414440155029297, 'loss_4': -0.39517879486083984, 'epoch': 15.33}
{'loss': 0.0145, 'grad_norm': 6.61603307723999, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.010163684375584126, 'loss_2': 0.0042877197265625, 'loss_3': -16.33680534362793, 'loss_4': -0.7291489839553833, 'epoch': 15.34}
{'loss': 0.0089, 'grad_norm': 5.662200450897217, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.008112415671348572, 'loss_2': 0.00081634521484375, 'loss_3': -16.403827667236328, 'loss_4': -0.47216349840164185, 'epoch': 15.34}
{'loss': 0.0125, 'grad_norm': 7.06532096862793, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.011598793789744377, 'loss_2': 0.000904083251953125, 'loss_3': -16.397796630859375, 'loss_4': -0.5305343270301819, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 13:25:34,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:34,893 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:29<43:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:42,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01420515775680542, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010135362856090069, 'eval_loss_2': 0.004069797694683075, 'eval_loss_3': -18.296518325805664, 'eval_loss_4': -0.410226434469223, 'epoch': 15.35}
{'loss': 0.0093, 'grad_norm': 5.248370170593262, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.008452563546597958, 'loss_2': 0.0008425712585449219, 'loss_3': -16.305004119873047, 'loss_4': 0.017827201634645462, 'epoch': 15.35}
{'loss': 0.031, 'grad_norm': 19.848176956176758, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.028392424806952477, 'loss_2': 0.00258636474609375, 'loss_3': -16.384672164916992, 'loss_4': -0.019670531153678894, 'epoch': 15.36}
{'loss': 0.0098, 'grad_norm': 5.00279426574707, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.009611200541257858, 'loss_2': 0.00017964839935302734, 'loss_3': -16.29292106628418, 'loss_4': 0.2013225555419922, 'epoch': 15.37}
{'loss': 0.0144, 'grad_norm': 7.297287464141846, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.014115664176642895, 'loss_2': 0.00032806396484375, 'loss_3': -16.197643280029297, 'loss_4': -0.4244512915611267, 'epoch': 15.37}
{'loss': 0.0087, 'grad_norm': 5.251744747161865, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.007532379124313593, 'loss_2': 0.0011272430419921875, 'loss_3': -16.298492431640625, 'loss_4': -0.5424996018409729, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 13:25:42,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:42,236 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:36<43:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:49,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013884492218494415, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.333, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009181343950331211, 'eval_loss_2': 0.004703149199485779, 'eval_loss_3': -18.266691207885742, 'eval_loss_4': -0.2672315835952759, 'epoch': 15.38}
{'loss': 0.0316, 'grad_norm': 8.748969078063965, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.02799643762409687, 'loss_2': 0.0036163330078125, 'loss_3': -16.418834686279297, 'loss_4': 0.08196195960044861, 'epoch': 15.38}
{'loss': 0.039, 'grad_norm': 11.78288459777832, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.03486812114715576, 'loss_2': 0.00415802001953125, 'loss_3': -16.320785522460938, 'loss_4': -0.3398239016532898, 'epoch': 15.39}
{'loss': 0.036, 'grad_norm': 8.498693466186523, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.033644869923591614, 'loss_2': 0.00238800048828125, 'loss_3': -16.358137130737305, 'loss_4': 0.08872200548648834, 'epoch': 15.4}
{'loss': 0.0176, 'grad_norm': 6.777818202972412, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.014129123650491238, 'loss_2': 0.00348663330078125, 'loss_3': -16.329509735107422, 'loss_4': -0.43694615364074707, 'epoch': 15.4}
{'loss': 0.0429, 'grad_norm': 47.58222579956055, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.039777182042598724, 'loss_2': 0.0031185150146484375, 'loss_3': -16.245819091796875, 'loss_4': -0.07884541898965836, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 13:25:49,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:49,585 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:43<43:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:56,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014238460920751095, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009724062867462635, 'eval_loss_2': 0.0045143961906433105, 'eval_loss_3': -18.268722534179688, 'eval_loss_4': -0.20358841121196747, 'epoch': 15.41}
{'loss': 0.0109, 'grad_norm': 5.772133827209473, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.009926259517669678, 'loss_2': 0.0009241104125976562, 'loss_3': -16.504627227783203, 'loss_4': -0.07319923490285873, 'epoch': 15.41}
{'loss': 0.0081, 'grad_norm': 5.35752534866333, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.00721652340143919, 'loss_2': 0.0009298324584960938, 'loss_3': -16.369657516479492, 'loss_4': -0.18264512717723846, 'epoch': 15.42}
{'loss': 0.0175, 'grad_norm': 11.13850212097168, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.015353560447692871, 'loss_2': 0.0021152496337890625, 'loss_3': -16.373952865600586, 'loss_4': 0.34678059816360474, 'epoch': 15.42}
{'loss': 0.0179, 'grad_norm': 5.599165916442871, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.011185036972165108, 'loss_2': 0.00675201416015625, 'loss_3': -16.273298263549805, 'loss_4': -0.5654367208480835, 'epoch': 15.43}
{'loss': 0.0129, 'grad_norm': 4.99468469619751, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.009923053905367851, 'loss_2': 0.0030059814453125, 'loss_3': -16.448152542114258, 'loss_4': -0.007717937231063843, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 13:25:56,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:56,935 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:51<43:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:04,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015373502857983112, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.728, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011093205772340298, 'eval_loss_2': 0.004280298948287964, 'eval_loss_3': -18.273427963256836, 'eval_loss_4': -0.25579795241355896, 'epoch': 15.44}
{'loss': 0.0095, 'grad_norm': 4.521712779998779, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.004974110051989555, 'loss_2': 0.004486083984375, 'loss_3': -16.26444435119629, 'loss_4': -0.21883133053779602, 'epoch': 15.44}
{'loss': 0.0297, 'grad_norm': 12.161043167114258, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.02838025987148285, 'loss_2': 0.0012807846069335938, 'loss_3': -16.127553939819336, 'loss_4': -0.2560619115829468, 'epoch': 15.45}
{'loss': 0.0138, 'grad_norm': 6.109464168548584, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.008404545485973358, 'loss_2': 0.0054168701171875, 'loss_3': -16.30703353881836, 'loss_4': -0.3123088479042053, 'epoch': 15.45}
{'loss': 0.0238, 'grad_norm': 11.159149169921875, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.020099176093935966, 'loss_2': 0.0037288665771484375, 'loss_3': -16.374393463134766, 'loss_4': -0.26472553610801697, 'epoch': 15.46}
{'loss': 0.0151, 'grad_norm': 6.026646614074707, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.013699078932404518, 'loss_2': 0.001430511474609375, 'loss_3': -16.549602508544922, 'loss_4': 0.49013054370880127, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 13:26:04,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:04,291 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:58<43:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:11,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01562640629708767, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01235111616551876, 'eval_loss_2': 0.0032752901315689087, 'eval_loss_3': -18.269453048706055, 'eval_loss_4': -0.36108845472335815, 'epoch': 15.47}
{'loss': 0.0131, 'grad_norm': 5.478264331817627, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.008079085499048233, 'loss_2': 0.005035400390625, 'loss_3': -16.459869384765625, 'loss_4': -0.10845714062452316, 'epoch': 15.47}
{'loss': 0.026, 'grad_norm': 11.23917007446289, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.02315058745443821, 'loss_2': 0.002864837646484375, 'loss_3': -16.282073974609375, 'loss_4': -0.053884439170360565, 'epoch': 15.48}
{'loss': 0.0175, 'grad_norm': 5.511279582977295, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.008641290478408337, 'loss_2': 0.00882720947265625, 'loss_3': -16.461517333984375, 'loss_4': -0.5522063374519348, 'epoch': 15.48}
{'loss': 0.0082, 'grad_norm': 4.655501365661621, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.008024289272725582, 'loss_2': 0.00021064281463623047, 'loss_3': -16.445955276489258, 'loss_4': -0.7407571077346802, 'epoch': 15.49}
{'loss': 0.013, 'grad_norm': 5.516175270080566, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.011070480570197105, 'loss_2': 0.00196075439453125, 'loss_3': -16.457809448242188, 'loss_4': -0.16820672154426575, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 13:26:11,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:11,636 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:06:06<43:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:18,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015855085104703903, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.288, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011747312732040882, 'eval_loss_2': 0.004107773303985596, 'eval_loss_3': -18.27627944946289, 'eval_loss_4': -0.4731365442276001, 'epoch': 15.49}
{'loss': 0.0103, 'grad_norm': 5.444030284881592, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.007635343354195356, 'loss_2': 0.0026149749755859375, 'loss_3': -16.463743209838867, 'loss_4': -0.19114452600479126, 'epoch': 15.5}
{'loss': 0.0175, 'grad_norm': 6.151759147644043, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.013566921465098858, 'loss_2': 0.003910064697265625, 'loss_3': -16.4210147857666, 'loss_4': -0.09433340281248093, 'epoch': 15.51}
{'loss': 0.0163, 'grad_norm': 6.098771095275879, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.013644770719110966, 'loss_2': 0.002685546875, 'loss_3': -16.27691650390625, 'loss_4': -0.5877001285552979, 'epoch': 15.51}
{'loss': 0.0135, 'grad_norm': 7.800577163696289, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.012466617859899998, 'loss_2': 0.0009975433349609375, 'loss_3': -16.254528045654297, 'loss_4': -0.11718849837779999, 'epoch': 15.52}
{'loss': 0.0107, 'grad_norm': 5.410435199737549, 'learning_rate': 1.45e-05, 'loss_1': 0.00884732324630022, 'loss_2': 0.0018787384033203125, 'loss_3': -16.40570068359375, 'loss_4': -0.13584472239017487, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 13:26:18,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:18,986 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:13<43:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:26,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01636938564479351, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01129863876849413, 'eval_loss_2': 0.005070745944976807, 'eval_loss_3': -18.30322265625, 'eval_loss_4': -0.6764972805976868, 'epoch': 15.52}
{'loss': 0.0102, 'grad_norm': 4.989536762237549, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.006852075923234224, 'loss_2': 0.00331878662109375, 'loss_3': -16.610702514648438, 'loss_4': -0.5491756200790405, 'epoch': 15.53}
{'loss': 0.0145, 'grad_norm': 4.951617240905762, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.00589058268815279, 'loss_2': 0.0085906982421875, 'loss_3': -16.690073013305664, 'loss_4': -0.3544074296951294, 'epoch': 15.53}
{'loss': 0.0129, 'grad_norm': 4.300800323486328, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.008913389407098293, 'loss_2': 0.0040283203125, 'loss_3': -16.495838165283203, 'loss_4': -0.34644150733947754, 'epoch': 15.54}
{'loss': 0.0465, 'grad_norm': 18.511913299560547, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.04590418189764023, 'loss_2': 0.000591278076171875, 'loss_3': -16.385478973388672, 'loss_4': -0.49867168068885803, 'epoch': 15.55}
{'loss': 0.0383, 'grad_norm': 9.746956825256348, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.025563476607203484, 'loss_2': 0.0127716064453125, 'loss_3': -16.30467414855957, 'loss_4': -1.0650608539581299, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 13:26:26,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:26,340 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:20<42:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:33,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016178494319319725, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011759079061448574, 'eval_loss_2': 0.004419416189193726, 'eval_loss_3': -18.314289093017578, 'eval_loss_4': -0.7562055587768555, 'epoch': 15.55}
{'loss': 0.0078, 'grad_norm': 5.092492580413818, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.00670661823824048, 'loss_2': 0.001071929931640625, 'loss_3': -16.461074829101562, 'loss_4': -0.8191299438476562, 'epoch': 15.56}
{'loss': 0.0416, 'grad_norm': 17.836162567138672, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.039678461849689484, 'loss_2': 0.0019092559814453125, 'loss_3': -16.281478881835938, 'loss_4': -0.5103068351745605, 'epoch': 15.56}
{'loss': 0.0173, 'grad_norm': 6.122592449188232, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.012256158515810966, 'loss_2': 0.005062103271484375, 'loss_3': -16.344083786010742, 'loss_4': -0.9095625281333923, 'epoch': 15.57}
{'loss': 0.0104, 'grad_norm': 4.708792209625244, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.0051336102187633514, 'loss_2': 0.0052337646484375, 'loss_3': -16.458633422851562, 'loss_4': -0.6391345262527466, 'epoch': 15.58}
{'loss': 0.0124, 'grad_norm': 7.985633850097656, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.012307271361351013, 'loss_2': 6.937980651855469e-05, 'loss_3': -16.587738037109375, 'loss_4': -1.1374645233154297, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 13:26:33,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:33,682 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:28<42:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:41,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017510036006569862, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.264, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013925265520811081, 'eval_loss_2': 0.003584768623113632, 'eval_loss_3': -18.306861877441406, 'eval_loss_4': -0.7774145007133484, 'epoch': 15.58}
{'loss': 0.0068, 'grad_norm': 4.708197116851807, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.006125749554485083, 'loss_2': 0.0006608963012695312, 'loss_3': -16.324867248535156, 'loss_4': -1.0009032487869263, 'epoch': 15.59}
{'loss': 0.0082, 'grad_norm': 4.763998031616211, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.005060394294559956, 'loss_2': 0.0031719207763671875, 'loss_3': -16.37928009033203, 'loss_4': -0.8208809494972229, 'epoch': 15.59}
{'loss': 0.0128, 'grad_norm': 4.570501327514648, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.006415527779608965, 'loss_2': 0.00640869140625, 'loss_3': -16.363262176513672, 'loss_4': -0.44523996114730835, 'epoch': 15.6}
{'loss': 0.0212, 'grad_norm': 6.343753337860107, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.013969163410365582, 'loss_2': 0.007221221923828125, 'loss_3': -16.412033081054688, 'loss_4': -0.9661927223205566, 'epoch': 15.6}
{'loss': 0.0366, 'grad_norm': 9.01589584350586, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.02686869539320469, 'loss_2': 0.009765625, 'loss_3': -16.3885498046875, 'loss_4': -0.49757254123687744, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 13:26:41,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:41,031 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:35<42:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:48,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021770315244793892, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015288428403437138, 'eval_loss_2': 0.00648188591003418, 'eval_loss_3': -18.313440322875977, 'eval_loss_4': -0.6404868960380554, 'epoch': 15.61}
{'loss': 0.0192, 'grad_norm': 6.853448390960693, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.009715736843645573, 'loss_2': 0.00945281982421875, 'loss_3': -16.41393280029297, 'loss_4': -0.6153429746627808, 'epoch': 15.62}
{'loss': 0.0192, 'grad_norm': 8.612784385681152, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.011187597177922726, 'loss_2': 0.00804901123046875, 'loss_3': -16.431777954101562, 'loss_4': 0.0978371798992157, 'epoch': 15.62}
{'loss': 0.0228, 'grad_norm': 5.881528854370117, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.016089649870991707, 'loss_2': 0.00669097900390625, 'loss_3': -16.478069305419922, 'loss_4': -0.641251802444458, 'epoch': 15.63}
{'loss': 0.0324, 'grad_norm': 13.436899185180664, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.02753998339176178, 'loss_2': 0.004852294921875, 'loss_3': -16.44747543334961, 'loss_4': -0.3979763686656952, 'epoch': 15.63}
{'loss': 0.0159, 'grad_norm': 5.242959022521973, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.008905813097953796, 'loss_2': 0.0070037841796875, 'loss_3': -16.439260482788086, 'loss_4': -0.175204336643219, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 13:26:48,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:48,378 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:42<42:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:55,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01836245134472847, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014256284572184086, 'eval_loss_2': 0.00410616397857666, 'eval_loss_3': -18.304386138916016, 'eval_loss_4': -0.4622259736061096, 'epoch': 15.64}
{'loss': 0.0175, 'grad_norm': 5.814850807189941, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.010255623608827591, 'loss_2': 0.00726318359375, 'loss_3': -16.389068603515625, 'loss_4': -0.5709287524223328, 'epoch': 15.65}
{'loss': 0.0145, 'grad_norm': 5.1513800621032715, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.010127536021173, 'loss_2': 0.00438690185546875, 'loss_3': -16.308399200439453, 'loss_4': -0.27428513765335083, 'epoch': 15.65}
{'loss': 0.0124, 'grad_norm': 4.26645040512085, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.004810601472854614, 'loss_2': 0.007556915283203125, 'loss_3': -16.364696502685547, 'loss_4': -0.4012131690979004, 'epoch': 15.66}
{'loss': 0.005, 'grad_norm': 4.353155612945557, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.0038563627749681473, 'loss_2': 0.0011577606201171875, 'loss_3': -16.505695343017578, 'loss_4': -0.8836410641670227, 'epoch': 15.66}
{'loss': 0.0134, 'grad_norm': 6.167419910430908, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.012501247227191925, 'loss_2': 0.0009398460388183594, 'loss_3': -16.295141220092773, 'loss_4': -0.6191664338111877, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 13:26:55,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:55,715 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:50<42:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:03,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017297174781560898, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.428, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013659175485372543, 'eval_loss_2': 0.0036379992961883545, 'eval_loss_3': -18.266075134277344, 'eval_loss_4': -0.4592406749725342, 'epoch': 15.67}
{'loss': 0.0143, 'grad_norm': 5.478011608123779, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.009025723673403263, 'loss_2': 0.005313873291015625, 'loss_3': -16.543643951416016, 'loss_4': -0.22416433691978455, 'epoch': 15.67}
{'loss': 0.0186, 'grad_norm': 9.417435646057129, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.017034845426678658, 'loss_2': 0.0015516281127929688, 'loss_3': -16.308080673217773, 'loss_4': -0.46219363808631897, 'epoch': 15.68}
{'loss': 0.0062, 'grad_norm': 4.483152866363525, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.006059898994863033, 'loss_2': 0.0001569986343383789, 'loss_3': -16.286176681518555, 'loss_4': -0.5104393362998962, 'epoch': 15.69}
{'loss': 0.0188, 'grad_norm': 9.03200912475586, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.0179439689964056, 'loss_2': 0.0008907318115234375, 'loss_3': -16.474956512451172, 'loss_4': -0.4842696189880371, 'epoch': 15.69}
{'loss': 0.0098, 'grad_norm': 4.540319919586182, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.008418693207204342, 'loss_2': 0.0013751983642578125, 'loss_3': -16.721324920654297, 'loss_4': -0.44878971576690674, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 13:27:03,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:03,055 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:57<42:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:10,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018926110118627548, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014209892600774765, 'eval_loss_2': 0.004716217517852783, 'eval_loss_3': -18.276330947875977, 'eval_loss_4': -0.4246373772621155, 'epoch': 15.7}
{'loss': 0.0056, 'grad_norm': 4.958523750305176, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.003936741501092911, 'loss_2': 0.0016307830810546875, 'loss_3': -16.570240020751953, 'loss_4': -0.29871928691864014, 'epoch': 15.7}
{'loss': 0.0147, 'grad_norm': 7.19293737411499, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.009902958758175373, 'loss_2': 0.004833221435546875, 'loss_3': -16.419052124023438, 'loss_4': -0.45257195830345154, 'epoch': 15.71}
{'loss': 0.0093, 'grad_norm': 5.299417495727539, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.007808168884366751, 'loss_2': 0.0014553070068359375, 'loss_3': -16.37811851501465, 'loss_4': -0.5705310702323914, 'epoch': 15.72}
{'loss': 0.0123, 'grad_norm': 5.034282207489014, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.007699601352214813, 'loss_2': 0.004608154296875, 'loss_3': -16.441303253173828, 'loss_4': -0.28808510303497314, 'epoch': 15.72}
{'loss': 0.0114, 'grad_norm': 6.364286422729492, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.010359586216509342, 'loss_2': 0.0010242462158203125, 'loss_3': -16.612224578857422, 'loss_4': -0.7349852323532104, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 13:27:10,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:10,398 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:07:04<42:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:17,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017959289252758026, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.527, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015070992521941662, 'eval_loss_2': 0.0028882957994937897, 'eval_loss_3': -18.24311065673828, 'eval_loss_4': -0.2507478892803192, 'epoch': 15.73}
{'loss': 0.0158, 'grad_norm': 5.778714179992676, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.01294669322669506, 'loss_2': 0.002826690673828125, 'loss_3': -16.176639556884766, 'loss_4': -0.420212984085083, 'epoch': 15.73}
{'loss': 0.0123, 'grad_norm': 5.072393894195557, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.007390500977635384, 'loss_2': 0.00487518310546875, 'loss_3': -16.34079933166504, 'loss_4': -0.11163721233606339, 'epoch': 15.74}
{'loss': 0.0161, 'grad_norm': 5.605404853820801, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.01281798630952835, 'loss_2': 0.003326416015625, 'loss_3': -16.436710357666016, 'loss_4': -0.40060099959373474, 'epoch': 15.74}
{'loss': 0.0161, 'grad_norm': 4.97061824798584, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.011526522226631641, 'loss_2': 0.0045623779296875, 'loss_3': -16.312273025512695, 'loss_4': -0.2090357542037964, 'epoch': 15.75}
{'loss': 0.0164, 'grad_norm': 5.344483852386475, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.010144748724997044, 'loss_2': 0.006229400634765625, 'loss_3': -16.520986557006836, 'loss_4': -0.3090149462223053, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 13:27:17,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:17,739 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:12<42:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:25,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019833466038107872, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014922731555998325, 'eval_loss_2': 0.0049107372760772705, 'eval_loss_3': -18.241676330566406, 'eval_loss_4': -0.029080627486109734, 'epoch': 15.76}
{'loss': 0.0149, 'grad_norm': 5.140022277832031, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.009048999287188053, 'loss_2': 0.00588226318359375, 'loss_3': -16.32024574279785, 'loss_4': -0.005393259227275848, 'epoch': 15.76}
{'loss': 0.0379, 'grad_norm': 17.968521118164062, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.02681971713900566, 'loss_2': 0.0110321044921875, 'loss_3': -16.275169372558594, 'loss_4': 0.16869817674160004, 'epoch': 15.77}
{'loss': 0.022, 'grad_norm': 5.7086286544799805, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.01070568710565567, 'loss_2': 0.01128387451171875, 'loss_3': -16.437789916992188, 'loss_4': -0.2025192826986313, 'epoch': 15.77}
{'loss': 0.0142, 'grad_norm': 5.598165035247803, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.010773921385407448, 'loss_2': 0.003459930419921875, 'loss_3': -16.2617244720459, 'loss_4': -0.17665918171405792, 'epoch': 15.78}
{'loss': 0.0091, 'grad_norm': 5.056375503540039, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.005910420790314674, 'loss_2': 0.00316619873046875, 'loss_3': -16.398815155029297, 'loss_4': 0.09954030811786652, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 13:27:25,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:25,086 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:19<42:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:32,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018250420689582825, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.015546323731541634, 'eval_loss_2': 0.0027040988206863403, 'eval_loss_3': -18.23928451538086, 'eval_loss_4': 0.06236942857503891, 'epoch': 15.78}
{'loss': 0.0055, 'grad_norm': 4.689620018005371, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.005410307552665472, 'loss_2': 0.00013363361358642578, 'loss_3': -16.554462432861328, 'loss_4': 0.1895923614501953, 'epoch': 15.79}
{'loss': 0.0279, 'grad_norm': 7.892175674438477, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.020261075347661972, 'loss_2': 0.0076141357421875, 'loss_3': -16.32295799255371, 'loss_4': -0.012151218950748444, 'epoch': 15.8}
{'loss': 0.0085, 'grad_norm': 6.381192684173584, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.008438716642558575, 'loss_2': 0.00010573863983154297, 'loss_3': -16.273574829101562, 'loss_4': -0.10467047989368439, 'epoch': 15.8}
{'loss': 0.0121, 'grad_norm': 7.761651515960693, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.009929477237164974, 'loss_2': 0.0022182464599609375, 'loss_3': -16.40723419189453, 'loss_4': 0.03014087677001953, 'epoch': 15.81}
{'loss': 0.0107, 'grad_norm': 4.57214879989624, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.005722064059227705, 'loss_2': 0.005016326904296875, 'loss_3': -16.517322540283203, 'loss_4': 0.13431566953659058, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 13:27:32,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:32,420 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:26<42:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:39,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019740311428904533, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.363, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016550030559301376, 'eval_loss_2': 0.003190279006958008, 'eval_loss_3': -18.233509063720703, 'eval_loss_4': 0.218831405043602, 'epoch': 15.81}
{'loss': 0.0133, 'grad_norm': 5.773037910461426, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.00707231042906642, 'loss_2': 0.006221771240234375, 'loss_3': -16.366907119750977, 'loss_4': -0.39604654908180237, 'epoch': 15.82}
{'loss': 0.0301, 'grad_norm': 14.067837715148926, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.02685205265879631, 'loss_2': 0.00323486328125, 'loss_3': -16.431560516357422, 'loss_4': 0.10922199487686157, 'epoch': 15.83}
{'loss': 0.0083, 'grad_norm': 5.0001349449157715, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.006522865034639835, 'loss_2': 0.0018224716186523438, 'loss_3': -16.23035430908203, 'loss_4': 0.5456584692001343, 'epoch': 15.83}
{'loss': 0.0171, 'grad_norm': 8.001738548278809, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.01674879901111126, 'loss_2': 0.00034427642822265625, 'loss_3': -16.633264541625977, 'loss_4': 0.4030360281467438, 'epoch': 15.84}
{'loss': 0.0215, 'grad_norm': 9.919238090515137, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.020309114828705788, 'loss_2': 0.0012044906616210938, 'loss_3': -16.253984451293945, 'loss_4': 0.04080291837453842, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 13:27:39,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:39,761 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:34<42:29,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:27:47,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017916876822710037, 'eval_runtime': 3.9894, 'eval_samples_per_second': 256.678, 'eval_steps_per_second': 4.011, 'eval_loss_1': 0.014590639621019363, 'eval_loss_2': 0.003326237201690674, 'eval_loss_3': -18.242145538330078, 'eval_loss_4': 0.14482413232326508, 'epoch': 15.84}
{'loss': 0.0104, 'grad_norm': 5.213663578033447, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.008693424053490162, 'loss_2': 0.0017108917236328125, 'loss_3': -16.41497802734375, 'loss_4': 0.21832257509231567, 'epoch': 15.85}
{'loss': 0.0077, 'grad_norm': 4.945875644683838, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.007338767871260643, 'loss_2': 0.0003743171691894531, 'loss_3': -16.463077545166016, 'loss_4': 0.032826006412506104, 'epoch': 15.85}
{'loss': 0.0199, 'grad_norm': 9.18805980682373, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.01480365265160799, 'loss_2': 0.005126953125, 'loss_3': -16.294334411621094, 'loss_4': -0.20020268857479095, 'epoch': 15.86}
{'loss': 0.0081, 'grad_norm': 5.905694007873535, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.007598412688821554, 'loss_2': 0.0005311965942382812, 'loss_3': -16.439472198486328, 'loss_4': -0.011588379740715027, 'epoch': 15.87}
{'loss': 0.0112, 'grad_norm': 6.871046543121338, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.008931662887334824, 'loss_2': 0.00228118896484375, 'loss_3': -16.455604553222656, 'loss_4': 0.1338476836681366, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 13:27:47,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:47,284 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:41<41:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:54,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01767965778708458, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.369, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014431784860789776, 'eval_loss_2': 0.003247871994972229, 'eval_loss_3': -18.24384117126465, 'eval_loss_4': -0.0008033514022827148, 'epoch': 15.87}
{'loss': 0.0147, 'grad_norm': 5.962123394012451, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.00801103562116623, 'loss_2': 0.00666046142578125, 'loss_3': -16.231962203979492, 'loss_4': 0.1207735687494278, 'epoch': 15.88}
{'loss': 0.0207, 'grad_norm': 8.238746643066406, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.01760086789727211, 'loss_2': 0.00310516357421875, 'loss_3': -16.460844039916992, 'loss_4': -0.20998713374137878, 'epoch': 15.88}
{'loss': 0.0942, 'grad_norm': 22.65026092529297, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.09354748576879501, 'loss_2': 0.0006265640258789062, 'loss_3': -16.280847549438477, 'loss_4': 0.4469596743583679, 'epoch': 15.89}
{'loss': 0.0327, 'grad_norm': 13.449542999267578, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.03138856589794159, 'loss_2': 0.001331329345703125, 'loss_3': -16.320327758789062, 'loss_4': 0.007641840726137161, 'epoch': 15.9}
{'loss': 0.0179, 'grad_norm': 6.045166492462158, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.011699250899255276, 'loss_2': 0.0061798095703125, 'loss_3': -16.343711853027344, 'loss_4': 0.028268426656723022, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 13:27:54,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:54,623 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:49<41:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:01,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018229015171527863, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.429, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014870504848659039, 'eval_loss_2': 0.003358513116836548, 'eval_loss_3': -18.242713928222656, 'eval_loss_4': 0.11298075318336487, 'epoch': 15.9}
{'loss': 0.0093, 'grad_norm': 4.978260040283203, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.005489112809300423, 'loss_2': 0.003810882568359375, 'loss_3': -16.335054397583008, 'loss_4': 0.25774019956588745, 'epoch': 15.91}
{'loss': 0.0136, 'grad_norm': 6.1017231941223145, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.009274132549762726, 'loss_2': 0.004375457763671875, 'loss_3': -16.343242645263672, 'loss_4': 0.29069364070892334, 'epoch': 15.91}
{'loss': 0.0187, 'grad_norm': 5.969148635864258, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.00947504211217165, 'loss_2': 0.00925445556640625, 'loss_3': -16.084903717041016, 'loss_4': 0.21176868677139282, 'epoch': 15.92}
{'loss': 0.01, 'grad_norm': 4.969210624694824, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.006314575206488371, 'loss_2': 0.0036373138427734375, 'loss_3': -16.22576904296875, 'loss_4': 0.4156884551048279, 'epoch': 15.92}
{'loss': 0.0303, 'grad_norm': 11.289855003356934, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.020754743367433548, 'loss_2': 0.0095367431640625, 'loss_3': -16.440454483032227, 'loss_4': 0.3299773335456848, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 13:28:01,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:01,961 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:56<41:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:09,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018035858869552612, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014489379711449146, 'eval_loss_2': 0.003546476364135742, 'eval_loss_3': -18.25844955444336, 'eval_loss_4': 0.3155730366706848, 'epoch': 15.93}
{'loss': 0.0081, 'grad_norm': 5.029483318328857, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.005607581697404385, 'loss_2': 0.002536773681640625, 'loss_3': -16.421222686767578, 'loss_4': 0.6126101016998291, 'epoch': 15.94}
{'loss': 0.0112, 'grad_norm': 4.6735405921936035, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.008452078327536583, 'loss_2': 0.002777099609375, 'loss_3': -16.220964431762695, 'loss_4': 0.6397362351417542, 'epoch': 15.94}
{'loss': 0.0118, 'grad_norm': 5.321441173553467, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.00754899624735117, 'loss_2': 0.004283905029296875, 'loss_3': -16.531579971313477, 'loss_4': 0.6480789184570312, 'epoch': 15.95}
{'loss': 0.0132, 'grad_norm': 6.463278293609619, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.010942161083221436, 'loss_2': 0.0023040771484375, 'loss_3': -16.402456283569336, 'loss_4': 0.8771926164627075, 'epoch': 15.95}
{'loss': 0.0081, 'grad_norm': 4.904165267944336, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.006573530845344067, 'loss_2': 0.001544952392578125, 'loss_3': -16.487144470214844, 'loss_4': 0.9300815463066101, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 13:28:09,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:09,311 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:08:03<41:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:16,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019007232040166855, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.524, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015370008535683155, 'eval_loss_2': 0.0036372244358062744, 'eval_loss_3': -18.26544952392578, 'eval_loss_4': 0.47933924198150635, 'epoch': 15.96}
{'loss': 0.0115, 'grad_norm': 4.704060077667236, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.009236535057425499, 'loss_2': 0.0022983551025390625, 'loss_3': -16.275110244750977, 'loss_4': 0.808845043182373, 'epoch': 15.97}
{'loss': 0.0141, 'grad_norm': 6.814441204071045, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.013957316055893898, 'loss_2': 0.0001817941665649414, 'loss_3': -16.300018310546875, 'loss_4': 1.3065102100372314, 'epoch': 15.97}
{'loss': 0.008, 'grad_norm': 5.895572662353516, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.007572181057184935, 'loss_2': 0.0004029273986816406, 'loss_3': -16.461257934570312, 'loss_4': 0.3786667287349701, 'epoch': 15.98}
{'loss': 0.009, 'grad_norm': 4.587359428405762, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.007166774477809668, 'loss_2': 0.0018367767333984375, 'loss_3': -16.433916091918945, 'loss_4': 0.9607763886451721, 'epoch': 15.98}
{'loss': 0.0095, 'grad_norm': 5.097410678863525, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.008367659524083138, 'loss_2': 0.0011444091796875, 'loss_3': -16.217788696289062, 'loss_4': 0.9422242045402527, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 13:28:16,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:16,654 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:10<40:22,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:28:23,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019737647846341133, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.515, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01636013574898243, 'eval_loss_2': 0.0033775120973587036, 'eval_loss_3': -18.28131675720215, 'eval_loss_4': 0.7151651978492737, 'epoch': 15.99}
{'loss': 0.0192, 'grad_norm': 8.153985977172852, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.016312889754772186, 'loss_2': 0.0029296875, 'loss_3': -16.42620849609375, 'loss_4': 1.2467241287231445, 'epoch': 15.99}
{'loss': 0.012, 'grad_norm': 5.720828056335449, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.0033278241753578186, 'loss_2': 0.0086822509765625, 'loss_3': -16.219635009765625, 'loss_4': 0.3433089554309845, 'epoch': 16.0}
{'loss': 0.0109, 'grad_norm': 4.567662715911865, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.008300269953906536, 'loss_2': 0.0025959014892578125, 'loss_3': -16.3815860748291, 'loss_4': 0.7345855236053467, 'epoch': 16.01}
{'loss': 0.0071, 'grad_norm': 5.248179912567139, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.00654296949505806, 'loss_2': 0.00058746337890625, 'loss_3': -16.173633575439453, 'loss_4': 0.5356502532958984, 'epoch': 16.01}
{'loss': 0.0152, 'grad_norm': 7.389072418212891, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.010696595534682274, 'loss_2': 0.004505157470703125, 'loss_3': -16.565908432006836, 'loss_4': 0.19497255980968475, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 13:28:23,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:23,681 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:18<41:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:28:31,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018751241266727448, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015448039397597313, 'eval_loss_2': 0.0033032000064849854, 'eval_loss_3': -18.274574279785156, 'eval_loss_4': 0.8522704839706421, 'epoch': 16.02}
{'loss': 0.0357, 'grad_norm': 6.357755661010742, 'learning_rate': 1.4e-05, 'loss_1': 0.028512902557849884, 'loss_2': 0.007232666015625, 'loss_3': -16.41223907470703, 'loss_4': 1.1144049167633057, 'epoch': 16.02}
{'loss': 0.0128, 'grad_norm': 6.572639465332031, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.010731274262070656, 'loss_2': 0.002044677734375, 'loss_3': -16.262781143188477, 'loss_4': 1.5506694316864014, 'epoch': 16.03}
{'loss': 0.0078, 'grad_norm': 4.6805315017700195, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.006486962083727121, 'loss_2': 0.0012845993041992188, 'loss_3': -16.42679786682129, 'loss_4': 1.0886592864990234, 'epoch': 16.03}
{'loss': 0.0154, 'grad_norm': 6.833425998687744, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.013604037463665009, 'loss_2': 0.0017604827880859375, 'loss_3': -16.24544906616211, 'loss_4': 1.0684640407562256, 'epoch': 16.04}
{'loss': 0.0577, 'grad_norm': 19.639074325561523, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.0538875088095665, 'loss_2': 0.003833770751953125, 'loss_3': -16.493648529052734, 'loss_4': 1.0265278816223145, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 13:28:31,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:31,023 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:25<41:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:38,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019317377358675003, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.37, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016503944993019104, 'eval_loss_2': 0.0028134286403656006, 'eval_loss_3': -18.28028678894043, 'eval_loss_4': 0.9728692173957825, 'epoch': 16.05}
{'loss': 0.0125, 'grad_norm': 4.650029182434082, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.007014312781393528, 'loss_2': 0.005519866943359375, 'loss_3': -16.4697208404541, 'loss_4': 0.8531674146652222, 'epoch': 16.05}
{'loss': 0.0156, 'grad_norm': 5.268185138702393, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.013389509171247482, 'loss_2': 0.002193450927734375, 'loss_3': -16.120201110839844, 'loss_4': 1.3764081001281738, 'epoch': 16.06}
{'loss': 0.0119, 'grad_norm': 5.011621475219727, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.010856186971068382, 'loss_2': 0.0010528564453125, 'loss_3': -16.47585105895996, 'loss_4': 1.4696004390716553, 'epoch': 16.06}
{'loss': 0.0176, 'grad_norm': 6.5749592781066895, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.014630310237407684, 'loss_2': 0.00292205810546875, 'loss_3': -16.35442352294922, 'loss_4': 1.3866522312164307, 'epoch': 16.07}
{'loss': 0.0281, 'grad_norm': 15.147117614746094, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.02592046745121479, 'loss_2': 0.00217437744140625, 'loss_3': -16.298620223999023, 'loss_4': 1.3302510976791382, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 13:28:38,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:38,368 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:32<41:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:45,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019361479207873344, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.719, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.016240190714597702, 'eval_loss_2': 0.003121286630630493, 'eval_loss_3': -18.285329818725586, 'eval_loss_4': 1.026972770690918, 'epoch': 16.08}
{'loss': 0.0062, 'grad_norm': 4.14332914352417, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.005633920431137085, 'loss_2': 0.0005626678466796875, 'loss_3': -16.394302368164062, 'loss_4': 1.183039665222168, 'epoch': 16.08}
{'loss': 0.0141, 'grad_norm': 5.702245235443115, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.012555246241390705, 'loss_2': 0.001567840576171875, 'loss_3': -16.518333435058594, 'loss_4': 1.0732696056365967, 'epoch': 16.09}
{'loss': 0.0159, 'grad_norm': 7.006719589233398, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.014920785091817379, 'loss_2': 0.0009679794311523438, 'loss_3': -16.29330062866211, 'loss_4': 1.2146399021148682, 'epoch': 16.09}
{'loss': 0.033, 'grad_norm': 12.266008377075195, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.025545675307512283, 'loss_2': 0.0074310302734375, 'loss_3': -16.50811004638672, 'loss_4': 0.9063949584960938, 'epoch': 16.1}
{'loss': 0.0262, 'grad_norm': 9.601020812988281, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.02145618572831154, 'loss_2': 0.004734039306640625, 'loss_3': -16.604171752929688, 'loss_4': 0.9141375422477722, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 13:28:45,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:45,711 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:40<41:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:53,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01893812045454979, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015423934906721115, 'eval_loss_2': 0.0035141855478286743, 'eval_loss_3': -18.30202865600586, 'eval_loss_4': 0.9261623024940491, 'epoch': 16.1}
{'loss': 0.02, 'grad_norm': 7.562930583953857, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.015109584666788578, 'loss_2': 0.00490570068359375, 'loss_3': -16.29733657836914, 'loss_4': 1.4554247856140137, 'epoch': 16.11}
{'loss': 0.0161, 'grad_norm': 5.646848201751709, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.011743433773517609, 'loss_2': 0.0043182373046875, 'loss_3': -16.443248748779297, 'loss_4': 1.049498438835144, 'epoch': 16.12}
{'loss': 0.0109, 'grad_norm': 4.888767242431641, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.007555063348263502, 'loss_2': 0.00333404541015625, 'loss_3': -16.403047561645508, 'loss_4': 1.2128013372421265, 'epoch': 16.12}
{'loss': 0.0079, 'grad_norm': 5.013890266418457, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.005785751156508923, 'loss_2': 0.0020923614501953125, 'loss_3': -16.429611206054688, 'loss_4': 0.7900165319442749, 'epoch': 16.13}
{'loss': 0.0299, 'grad_norm': 12.812442779541016, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.0227099247276783, 'loss_2': 0.00720977783203125, 'loss_3': -16.433692932128906, 'loss_4': 1.163456678390503, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 13:28:53,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:53,051 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:47<41:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:00,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017523404210805893, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.518, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014253135770559311, 'eval_loss_2': 0.003270268440246582, 'eval_loss_3': -18.298757553100586, 'eval_loss_4': 0.7212806940078735, 'epoch': 16.13}
{'loss': 0.0176, 'grad_norm': 6.621575832366943, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.015390690416097641, 'loss_2': 0.002166748046875, 'loss_3': -16.380565643310547, 'loss_4': 0.8972708582878113, 'epoch': 16.14}
{'loss': 0.0182, 'grad_norm': 11.626291275024414, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.017375780269503593, 'loss_2': 0.0008449554443359375, 'loss_3': -16.255489349365234, 'loss_4': 0.7362751364707947, 'epoch': 16.15}
{'loss': 0.0196, 'grad_norm': 4.382109642028809, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.008207997307181358, 'loss_2': 0.01137542724609375, 'loss_3': -16.400638580322266, 'loss_4': 0.9821270704269409, 'epoch': 16.15}
{'loss': 0.0236, 'grad_norm': 7.564975261688232, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.02045920491218567, 'loss_2': 0.003162384033203125, 'loss_3': -16.374868392944336, 'loss_4': 1.2937040328979492, 'epoch': 16.16}
{'loss': 0.0161, 'grad_norm': 5.007659435272217, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.010518628172576427, 'loss_2': 0.005580902099609375, 'loss_3': -16.73159408569336, 'loss_4': 0.9075843691825867, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 13:29:00,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:00,395 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:54<41:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:07,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018818754702806473, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.54, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014402242377400398, 'eval_loss_2': 0.004416510462760925, 'eval_loss_3': -18.304609298706055, 'eval_loss_4': 0.6397687196731567, 'epoch': 16.16}
{'loss': 0.0259, 'grad_norm': 5.92395544052124, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.013389521278440952, 'loss_2': 0.0125274658203125, 'loss_3': -16.39423179626465, 'loss_4': 0.649242639541626, 'epoch': 16.17}
{'loss': 0.0381, 'grad_norm': 10.625463485717773, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.03418974205851555, 'loss_2': 0.003875732421875, 'loss_3': -16.307453155517578, 'loss_4': 0.9023351669311523, 'epoch': 16.17}
{'loss': 0.0446, 'grad_norm': 13.57935619354248, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.044282466173172, 'loss_2': 0.0003383159637451172, 'loss_3': -16.320823669433594, 'loss_4': 0.6691499948501587, 'epoch': 16.18}
{'loss': 0.0116, 'grad_norm': 5.080200672149658, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.010151050984859467, 'loss_2': 0.00147247314453125, 'loss_3': -16.36176300048828, 'loss_4': 0.6168837547302246, 'epoch': 16.19}
{'loss': 0.0165, 'grad_norm': 6.540931701660156, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.016099797561764717, 'loss_2': 0.0003998279571533203, 'loss_3': -16.27642822265625, 'loss_4': 1.243309736251831, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 13:29:07,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:07,737 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:09:02<40:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:15,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019417524337768555, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.684, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01488539483398199, 'eval_loss_2': 0.004532128572463989, 'eval_loss_3': -18.313234329223633, 'eval_loss_4': 0.4969446361064911, 'epoch': 16.19}
{'loss': 0.019, 'grad_norm': 5.685393333435059, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.01077515073120594, 'loss_2': 0.00824737548828125, 'loss_3': -16.4791259765625, 'loss_4': 0.7456232309341431, 'epoch': 16.2}
{'loss': 0.0238, 'grad_norm': 6.352626323699951, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.01851503923535347, 'loss_2': 0.00527191162109375, 'loss_3': -16.408105850219727, 'loss_4': 0.7281439304351807, 'epoch': 16.2}
{'loss': 0.0146, 'grad_norm': 6.99497652053833, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.010758569464087486, 'loss_2': 0.0038585662841796875, 'loss_3': -16.544588088989258, 'loss_4': 0.32034581899642944, 'epoch': 16.21}
{'loss': 0.016, 'grad_norm': 6.362854480743408, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.013366772793233395, 'loss_2': 0.0026378631591796875, 'loss_3': -16.443035125732422, 'loss_4': 0.5781700611114502, 'epoch': 16.22}
{'loss': 0.0352, 'grad_norm': 10.725872039794922, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.034922532737255096, 'loss_2': 0.00028896331787109375, 'loss_3': -16.397979736328125, 'loss_4': 0.6642525792121887, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 13:29:15,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:15,077 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:09<40:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:22,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018465889617800713, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014163447543978691, 'eval_loss_2': 0.0043024420738220215, 'eval_loss_3': -18.303909301757812, 'eval_loss_4': 0.23464909195899963, 'epoch': 16.22}
{'loss': 0.0169, 'grad_norm': 6.793576240539551, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.01350848563015461, 'loss_2': 0.003360748291015625, 'loss_3': -16.272756576538086, 'loss_4': 0.5552425980567932, 'epoch': 16.23}
{'loss': 0.0185, 'grad_norm': 9.03641128540039, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.017408858984708786, 'loss_2': 0.0010623931884765625, 'loss_3': -16.56435775756836, 'loss_4': 0.6049898862838745, 'epoch': 16.23}
{'loss': 0.0204, 'grad_norm': 7.082795143127441, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.016662973910570145, 'loss_2': 0.0037517547607421875, 'loss_3': -16.26955795288086, 'loss_4': 0.26803356409072876, 'epoch': 16.24}
{'loss': 0.0174, 'grad_norm': 6.096502780914307, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.011639663949608803, 'loss_2': 0.005748748779296875, 'loss_3': -16.46363639831543, 'loss_4': 0.4906053841114044, 'epoch': 16.24}
{'loss': 0.0173, 'grad_norm': 6.127995491027832, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.016187384724617004, 'loss_2': 0.00107574462890625, 'loss_3': -16.30142593383789, 'loss_4': 0.6633728742599487, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 13:29:22,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:22,414 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:16<40:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:29,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015373189002275467, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01250116154551506, 'eval_loss_2': 0.0028720274567604065, 'eval_loss_3': -18.326684951782227, 'eval_loss_4': 0.14047999680042267, 'epoch': 16.25}
{'loss': 0.0177, 'grad_norm': 6.824208736419678, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.014504398219287395, 'loss_2': 0.0031871795654296875, 'loss_3': -16.466815948486328, 'loss_4': 0.27035441994667053, 'epoch': 16.26}
{'loss': 0.0138, 'grad_norm': 5.3555426597595215, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.011569122783839703, 'loss_2': 0.0022735595703125, 'loss_3': -16.438758850097656, 'loss_4': 0.5209486484527588, 'epoch': 16.26}
{'loss': 0.0063, 'grad_norm': 4.620640754699707, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.006204203702509403, 'loss_2': 8.171796798706055e-05, 'loss_3': -16.52690315246582, 'loss_4': 0.13606542348861694, 'epoch': 16.27}
{'loss': 0.0137, 'grad_norm': 5.636906147003174, 'learning_rate': 1.375e-05, 'loss_1': 0.012039108201861382, 'loss_2': 0.0016965866088867188, 'loss_3': -16.473514556884766, 'loss_4': 0.23646192252635956, 'epoch': 16.27}
{'loss': 0.0224, 'grad_norm': 7.062544345855713, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.019952651113271713, 'loss_2': 0.002429962158203125, 'loss_3': -16.3082332611084, 'loss_4': 0.25884348154067993, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 13:29:29,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:29,764 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:24<40:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:37,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022083517163991928, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.644, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014242167584598064, 'eval_loss_2': 0.007841348648071289, 'eval_loss_3': -18.319679260253906, 'eval_loss_4': 0.24248692393302917, 'epoch': 16.28}
{'loss': 0.037, 'grad_norm': 11.872831344604492, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.024238836020231247, 'loss_2': 0.01275634765625, 'loss_3': -16.522174835205078, 'loss_4': 0.507542073726654, 'epoch': 16.28}
{'loss': 0.0178, 'grad_norm': 5.40213680267334, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.009536214172840118, 'loss_2': 0.0082550048828125, 'loss_3': -16.501670837402344, 'loss_4': 0.7361396551132202, 'epoch': 16.29}
{'loss': 0.0272, 'grad_norm': 7.351913928985596, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.022196773439645767, 'loss_2': 0.005035400390625, 'loss_3': -16.337472915649414, 'loss_4': 0.5695382356643677, 'epoch': 16.3}
{'loss': 0.0258, 'grad_norm': 4.835909843444824, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.010408088564872742, 'loss_2': 0.01543426513671875, 'loss_3': -16.39762306213379, 'loss_4': 0.732245147228241, 'epoch': 16.3}
{'loss': 0.0306, 'grad_norm': 10.734939575195312, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.019472310319542885, 'loss_2': 0.0111541748046875, 'loss_3': -16.47321319580078, 'loss_4': 0.4052913188934326, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 13:29:37,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:37,105 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:31<40:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:44,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02093176171183586, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.704, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014380854554474354, 'eval_loss_2': 0.006550908088684082, 'eval_loss_3': -18.32961654663086, 'eval_loss_4': 0.25220006704330444, 'epoch': 16.31}
{'loss': 0.0385, 'grad_norm': 13.414355278015137, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.031532108783721924, 'loss_2': 0.00693511962890625, 'loss_3': -16.163475036621094, 'loss_4': 0.30919522047042847, 'epoch': 16.31}
{'loss': 0.0334, 'grad_norm': 7.547642230987549, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.02688642218708992, 'loss_2': 0.0065460205078125, 'loss_3': -16.5144100189209, 'loss_4': 0.17402383685112, 'epoch': 16.32}
{'loss': 0.0155, 'grad_norm': 5.840744972229004, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.014961812645196915, 'loss_2': 0.0005664825439453125, 'loss_3': -16.423925399780273, 'loss_4': 0.43379291892051697, 'epoch': 16.33}
{'loss': 0.018, 'grad_norm': 6.687082290649414, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.017826182767748833, 'loss_2': 0.00021016597747802734, 'loss_3': -16.315210342407227, 'loss_4': 0.3734312355518341, 'epoch': 16.33}
{'loss': 0.0115, 'grad_norm': 4.996079921722412, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.010442744940519333, 'loss_2': 0.00104522705078125, 'loss_3': -16.43426513671875, 'loss_4': 0.406963974237442, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 13:29:44,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:44,442 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:38<40:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:51,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016216661781072617, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.656, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013934406451880932, 'eval_loss_2': 0.00228225439786911, 'eval_loss_3': -18.30689811706543, 'eval_loss_4': 0.13702179491519928, 'epoch': 16.34}
{'loss': 0.0194, 'grad_norm': 5.570371150970459, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.016594428569078445, 'loss_2': 0.00278472900390625, 'loss_3': -16.47515869140625, 'loss_4': 0.12250794470310211, 'epoch': 16.34}
{'loss': 0.0165, 'grad_norm': 6.864286422729492, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.013896049931645393, 'loss_2': 0.002635955810546875, 'loss_3': -16.37665557861328, 'loss_4': 0.12013904005289078, 'epoch': 16.35}
{'loss': 0.0103, 'grad_norm': 4.8870649337768555, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.0075950962491333485, 'loss_2': 0.00275421142578125, 'loss_3': -16.52062225341797, 'loss_4': 0.5448415279388428, 'epoch': 16.35}
{'loss': 0.016, 'grad_norm': 6.993483066558838, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.01525825820863247, 'loss_2': 0.0007910728454589844, 'loss_3': -16.407148361206055, 'loss_4': 0.6701638102531433, 'epoch': 16.36}
{'loss': 0.0245, 'grad_norm': 6.207053184509277, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.016881922259926796, 'loss_2': 0.00760650634765625, 'loss_3': -16.4849853515625, 'loss_4': 0.6227465867996216, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 13:29:51,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:51,782 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:46<40:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:59,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016624290496110916, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.466, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012670285068452358, 'eval_loss_2': 0.003954008221626282, 'eval_loss_3': -18.317716598510742, 'eval_loss_4': 0.09571647644042969, 'epoch': 16.37}
{'loss': 0.0208, 'grad_norm': 5.820639133453369, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.014995135366916656, 'loss_2': 0.005767822265625, 'loss_3': -16.56527328491211, 'loss_4': 0.4810059070587158, 'epoch': 16.37}
{'loss': 0.0183, 'grad_norm': 6.679879665374756, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.012634038925170898, 'loss_2': 0.005641937255859375, 'loss_3': -16.367164611816406, 'loss_4': 0.5210371017456055, 'epoch': 16.38}
{'loss': 0.0296, 'grad_norm': 11.205517768859863, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.025053950026631355, 'loss_2': 0.004535675048828125, 'loss_3': -16.427547454833984, 'loss_4': 0.06888814270496368, 'epoch': 16.38}
{'loss': 0.0081, 'grad_norm': 5.132993698120117, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.006716253235936165, 'loss_2': 0.00133514404296875, 'loss_3': -16.311634063720703, 'loss_4': 0.006619401276111603, 'epoch': 16.39}
{'loss': 0.0268, 'grad_norm': 9.755188941955566, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.025643160566687584, 'loss_2': 0.0011081695556640625, 'loss_3': -16.374317169189453, 'loss_4': 0.8613471984863281, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 13:29:59,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:59,123 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:53<40:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:06,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016255775466561317, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01323903352022171, 'eval_loss_2': 0.003016740083694458, 'eval_loss_3': -18.272972106933594, 'eval_loss_4': 0.16870059072971344, 'epoch': 16.4}
{'loss': 0.0132, 'grad_norm': 8.0877103805542, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.012138145044445992, 'loss_2': 0.0010499954223632812, 'loss_3': -16.373598098754883, 'loss_4': 0.7179131507873535, 'epoch': 16.4}
{'loss': 0.0143, 'grad_norm': 7.925068378448486, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.01285180076956749, 'loss_2': 0.0014095306396484375, 'loss_3': -16.34990119934082, 'loss_4': 0.14804206788539886, 'epoch': 16.41}
{'loss': 0.0186, 'grad_norm': 5.662659168243408, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.012129131704568863, 'loss_2': 0.0064697265625, 'loss_3': -16.262451171875, 'loss_4': 0.731590747833252, 'epoch': 16.41}
{'loss': 0.0234, 'grad_norm': 8.121187210083008, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.020338620990514755, 'loss_2': 0.003063201904296875, 'loss_3': -16.384265899658203, 'loss_4': 0.6291455030441284, 'epoch': 16.42}
{'loss': 0.0219, 'grad_norm': 8.051499366760254, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.01651753857731819, 'loss_2': 0.005401611328125, 'loss_3': -16.44554328918457, 'loss_4': 0.1675817370414734, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 13:30:06,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:06,461 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:10:00<40:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:13,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017684809863567352, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.926, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013054728507995605, 'eval_loss_2': 0.004630081355571747, 'eval_loss_3': -18.238584518432617, 'eval_loss_4': 0.2759871482849121, 'epoch': 16.42}
{'loss': 0.0115, 'grad_norm': 4.75386905670166, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.006813074927777052, 'loss_2': 0.00472259521484375, 'loss_3': -16.432666778564453, 'loss_4': 0.2287389487028122, 'epoch': 16.43}
{'loss': 0.0049, 'grad_norm': 4.491090774536133, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.004163311794400215, 'loss_2': 0.0007410049438476562, 'loss_3': -16.359294891357422, 'loss_4': 0.34551694989204407, 'epoch': 16.44}
{'loss': 0.0098, 'grad_norm': 5.881598949432373, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.008326450362801552, 'loss_2': 0.0015201568603515625, 'loss_3': -16.26380157470703, 'loss_4': -0.02381230890750885, 'epoch': 16.44}
{'loss': 0.0109, 'grad_norm': 5.381948947906494, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.007253263145685196, 'loss_2': 0.003665924072265625, 'loss_3': -16.27720832824707, 'loss_4': 0.6107061505317688, 'epoch': 16.45}
{'loss': 0.0129, 'grad_norm': 4.639405727386475, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.005339736118912697, 'loss_2': 0.007564544677734375, 'loss_3': -16.419269561767578, 'loss_4': 0.6621483564376831, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 13:30:13,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:13,803 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:08<40:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:21,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017153287306427956, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.348, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011796083301305771, 'eval_loss_2': 0.005357205867767334, 'eval_loss_3': -18.224912643432617, 'eval_loss_4': 0.3143930733203888, 'epoch': 16.45}
{'loss': 0.0087, 'grad_norm': 4.9873247146606445, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.007896319031715393, 'loss_2': 0.0007686614990234375, 'loss_3': -16.230497360229492, 'loss_4': 0.38954317569732666, 'epoch': 16.46}
{'loss': 0.0589, 'grad_norm': 10.278630256652832, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.048047713935375214, 'loss_2': 0.010833740234375, 'loss_3': -16.219451904296875, 'loss_4': 0.41016995906829834, 'epoch': 16.47}
{'loss': 0.0128, 'grad_norm': 5.392219543457031, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.006343178451061249, 'loss_2': 0.0064849853515625, 'loss_3': -16.275049209594727, 'loss_4': 0.13969331979751587, 'epoch': 16.47}
{'loss': 0.0093, 'grad_norm': 5.255720615386963, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.009190752170979977, 'loss_2': 0.00010156631469726562, 'loss_3': -16.35581398010254, 'loss_4': 0.25794631242752075, 'epoch': 16.48}
{'loss': 0.0183, 'grad_norm': 5.506580352783203, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.01018267311155796, 'loss_2': 0.0081634521484375, 'loss_3': -16.38949203491211, 'loss_4': 0.31299257278442383, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 13:30:21,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:21,143 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:15<40:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:28,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015291940420866013, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.675, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011746910400688648, 'eval_loss_2': 0.003545030951499939, 'eval_loss_3': -18.236242294311523, 'eval_loss_4': 0.38441699743270874, 'epoch': 16.48}
{'loss': 0.0093, 'grad_norm': 6.888247489929199, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.008418194018304348, 'loss_2': 0.0008478164672851562, 'loss_3': -16.200855255126953, 'loss_4': 0.6256883144378662, 'epoch': 16.49}
{'loss': 0.0179, 'grad_norm': 10.074790954589844, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.014963917434215546, 'loss_2': 0.00293731689453125, 'loss_3': -16.449064254760742, 'loss_4': 0.6030496954917908, 'epoch': 16.49}
{'loss': 0.0131, 'grad_norm': 4.571601390838623, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.006670646835118532, 'loss_2': 0.00643157958984375, 'loss_3': -16.394683837890625, 'loss_4': 0.766129732131958, 'epoch': 16.5}
{'loss': 0.0097, 'grad_norm': 4.98245096206665, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.008510822430253029, 'loss_2': 0.0012302398681640625, 'loss_3': -16.408727645874023, 'loss_4': 0.5560890436172485, 'epoch': 16.51}
{'loss': 0.0139, 'grad_norm': 6.733521461486816, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.011366700753569603, 'loss_2': 0.002506256103515625, 'loss_3': -16.38578224182129, 'loss_4': 0.8936284780502319, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 13:30:28,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:28,478 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:22<39:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:35,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013826102018356323, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.067, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011112750507891178, 'eval_loss_2': 0.0027133524417877197, 'eval_loss_3': -18.23696517944336, 'eval_loss_4': 0.44019654393196106, 'epoch': 16.51}
{'loss': 0.02, 'grad_norm': 7.74704122543335, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.016352873295545578, 'loss_2': 0.003643035888671875, 'loss_3': -16.336429595947266, 'loss_4': 0.2164924591779709, 'epoch': 16.52}
{'loss': 0.0129, 'grad_norm': 6.528122901916504, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.01158980280160904, 'loss_2': 0.0013256072998046875, 'loss_3': -16.124099731445312, 'loss_4': 0.7870848178863525, 'epoch': 16.52}
{'loss': 0.0119, 'grad_norm': 5.423890590667725, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.009857035242021084, 'loss_2': 0.0020465850830078125, 'loss_3': -16.333398818969727, 'loss_4': 0.8584970831871033, 'epoch': 16.53}
{'loss': 0.0238, 'grad_norm': 6.441925525665283, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.019476281479001045, 'loss_2': 0.004329681396484375, 'loss_3': -16.560283660888672, 'loss_4': 0.408223420381546, 'epoch': 16.53}
{'loss': 0.0767, 'grad_norm': 22.201248168945312, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.0695004090666771, 'loss_2': 0.00719451904296875, 'loss_3': -16.280349731445312, 'loss_4': 0.8291557431221008, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 13:30:35,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:35,806 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:30<39:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:43,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015185220167040825, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.528, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011447565630078316, 'eval_loss_2': 0.003737654536962509, 'eval_loss_3': -18.25345230102539, 'eval_loss_4': 0.4679501950740814, 'epoch': 16.54}
{'loss': 0.0119, 'grad_norm': 5.749237060546875, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.009565661661326885, 'loss_2': 0.0023288726806640625, 'loss_3': -16.365215301513672, 'loss_4': 0.5818349123001099, 'epoch': 16.55}
{'loss': 0.0177, 'grad_norm': 9.747200012207031, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.016638174653053284, 'loss_2': 0.0010633468627929688, 'loss_3': -16.43602752685547, 'loss_4': 0.7729791402816772, 'epoch': 16.55}
{'loss': 0.0179, 'grad_norm': 4.30830717086792, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.005068062338978052, 'loss_2': 0.01285552978515625, 'loss_3': -16.416095733642578, 'loss_4': 0.7411606311798096, 'epoch': 16.56}
{'loss': 0.0184, 'grad_norm': 4.913384914398193, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.010632905177772045, 'loss_2': 0.00780487060546875, 'loss_3': -16.358882904052734, 'loss_4': 0.7560701966285706, 'epoch': 16.56}
{'loss': 0.0105, 'grad_norm': 4.840044975280762, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.00806004274636507, 'loss_2': 0.0023956298828125, 'loss_3': -16.258525848388672, 'loss_4': 0.39919453859329224, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 13:30:43,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:43,144 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:37<39:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:50,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019655779004096985, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013240844942629337, 'eval_loss_2': 0.006414934992790222, 'eval_loss_3': -18.262922286987305, 'eval_loss_4': 0.5796213150024414, 'epoch': 16.57}
{'loss': 0.0184, 'grad_norm': 4.944194793701172, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.004952963907271624, 'loss_2': 0.01348876953125, 'loss_3': -16.550127029418945, 'loss_4': 0.37970542907714844, 'epoch': 16.58}
{'loss': 0.015, 'grad_norm': 4.642940044403076, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.007278419099748135, 'loss_2': 0.007724761962890625, 'loss_3': -16.55842399597168, 'loss_4': 0.8828696012496948, 'epoch': 16.58}
{'loss': 0.0123, 'grad_norm': 4.8972859382629395, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.008790550753474236, 'loss_2': 0.00347900390625, 'loss_3': -16.454498291015625, 'loss_4': 0.5348184108734131, 'epoch': 16.59}
{'loss': 0.0215, 'grad_norm': 7.89361047744751, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.018433481454849243, 'loss_2': 0.003025054931640625, 'loss_3': -16.151662826538086, 'loss_4': 0.6397519707679749, 'epoch': 16.59}
{'loss': 0.011, 'grad_norm': 4.679343223571777, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.006888909265398979, 'loss_2': 0.00414276123046875, 'loss_3': -16.612018585205078, 'loss_4': 1.0226407051086426, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 13:30:50,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:50,488 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:44<39:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:57,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018753521144390106, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.738, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01485537551343441, 'eval_loss_2': 0.003898143768310547, 'eval_loss_3': -18.27707862854004, 'eval_loss_4': 0.7571166753768921, 'epoch': 16.6}
{'loss': 0.0149, 'grad_norm': 7.687482833862305, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.013859964907169342, 'loss_2': 0.0010051727294921875, 'loss_3': -16.471355438232422, 'loss_4': 0.44427600502967834, 'epoch': 16.6}
{'loss': 0.013, 'grad_norm': 5.082973003387451, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.009997118264436722, 'loss_2': 0.0029621124267578125, 'loss_3': -16.233083724975586, 'loss_4': 0.852904200553894, 'epoch': 16.61}
{'loss': 0.0127, 'grad_norm': 4.97730016708374, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.005735192447900772, 'loss_2': 0.006931304931640625, 'loss_3': -16.414371490478516, 'loss_4': 1.0156280994415283, 'epoch': 16.62}
{'loss': 0.0408, 'grad_norm': 11.955565452575684, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.03173380345106125, 'loss_2': 0.009063720703125, 'loss_3': -16.365718841552734, 'loss_4': 0.6449120044708252, 'epoch': 16.62}
{'loss': 0.02, 'grad_norm': 6.184377193450928, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.009785034693777561, 'loss_2': 0.01024627685546875, 'loss_3': -16.39010238647461, 'loss_4': 1.0762825012207031, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 13:30:57,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:57,828 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:52<39:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:05,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02661610022187233, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.843, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01607566885650158, 'eval_loss_2': 0.0105404332280159, 'eval_loss_3': -18.286949157714844, 'eval_loss_4': 0.8446549773216248, 'epoch': 16.63}
{'loss': 0.0247, 'grad_norm': 4.970526695251465, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.009457695297896862, 'loss_2': 0.01528167724609375, 'loss_3': -16.279048919677734, 'loss_4': 0.7305008172988892, 'epoch': 16.63}
{'loss': 0.0283, 'grad_norm': 7.945869445800781, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.023068653419613838, 'loss_2': 0.005184173583984375, 'loss_3': -16.316802978515625, 'loss_4': 1.0706027746200562, 'epoch': 16.64}
{'loss': 0.0159, 'grad_norm': 5.304243564605713, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.010529751889407635, 'loss_2': 0.005352020263671875, 'loss_3': -16.46010971069336, 'loss_4': 0.9675143361091614, 'epoch': 16.65}
{'loss': 0.0246, 'grad_norm': 6.135425567626953, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.013927160762250423, 'loss_2': 0.01068878173828125, 'loss_3': -16.38719367980957, 'loss_4': 0.7886325120925903, 'epoch': 16.65}
{'loss': 0.0255, 'grad_norm': 5.3440446853637695, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.012808448635041714, 'loss_2': 0.01267242431640625, 'loss_3': -16.286453247070312, 'loss_4': 1.229851484298706, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 13:31:05,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:05,163 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:59<39:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:12,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02415739931166172, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017301257699728012, 'eval_loss_2': 0.006856143474578857, 'eval_loss_3': -18.258424758911133, 'eval_loss_4': 0.8566511869430542, 'epoch': 16.66}
{'loss': 0.0189, 'grad_norm': 6.6275458335876465, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.014215236529707909, 'loss_2': 0.00470733642578125, 'loss_3': -16.363685607910156, 'loss_4': 0.8420501947402954, 'epoch': 16.66}
{'loss': 0.0249, 'grad_norm': 9.402907371520996, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.017740903422236443, 'loss_2': 0.00717926025390625, 'loss_3': -16.32073211669922, 'loss_4': 1.1357321739196777, 'epoch': 16.67}
{'loss': 0.0155, 'grad_norm': 6.819334030151367, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.012273727916181087, 'loss_2': 0.0032291412353515625, 'loss_3': -16.30255126953125, 'loss_4': 0.8858282566070557, 'epoch': 16.67}
{'loss': 0.0159, 'grad_norm': 5.712610721588135, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.011086590588092804, 'loss_2': 0.0048065185546875, 'loss_3': -16.240493774414062, 'loss_4': 1.1636611223220825, 'epoch': 16.68}
{'loss': 0.0263, 'grad_norm': 8.987044334411621, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.022350158542394638, 'loss_2': 0.003963470458984375, 'loss_3': -16.273841857910156, 'loss_4': 0.644730806350708, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 13:31:12,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:12,508 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:11:06<39:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:19,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02363118901848793, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019547535106539726, 'eval_loss_2': 0.004083655774593353, 'eval_loss_3': -18.25032615661621, 'eval_loss_4': 0.9336018562316895, 'epoch': 16.69}
{'loss': 0.0175, 'grad_norm': 6.274781703948975, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.01568787172436714, 'loss_2': 0.0018529891967773438, 'loss_3': -16.334768295288086, 'loss_4': 0.5504717826843262, 'epoch': 16.69}
{'loss': 0.0629, 'grad_norm': 26.817689895629883, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.05701000615954399, 'loss_2': 0.00585174560546875, 'loss_3': -16.23467445373535, 'loss_4': 0.8487265110015869, 'epoch': 16.7}
{'loss': 0.013, 'grad_norm': 6.748852252960205, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.01286549586802721, 'loss_2': 0.00015735626220703125, 'loss_3': -16.307239532470703, 'loss_4': 0.9373342394828796, 'epoch': 16.7}
{'loss': 0.0132, 'grad_norm': 5.381721019744873, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.008730543777346611, 'loss_2': 0.004497528076171875, 'loss_3': -16.329769134521484, 'loss_4': 1.0680732727050781, 'epoch': 16.71}
{'loss': 0.0266, 'grad_norm': 12.11988353729248, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.025110820308327675, 'loss_2': 0.0014400482177734375, 'loss_3': -16.34322738647461, 'loss_4': 0.6539497375488281, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 13:31:19,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:19,852 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:14<39:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:27,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026203103363513947, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.554, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01959015615284443, 'eval_loss_2': 0.006612945348024368, 'eval_loss_3': -18.23154067993164, 'eval_loss_4': 0.8838167786598206, 'epoch': 16.72}
{'loss': 0.0183, 'grad_norm': 4.363719463348389, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.006206847261637449, 'loss_2': 0.01206207275390625, 'loss_3': -16.4110050201416, 'loss_4': 1.6336145401000977, 'epoch': 16.72}
{'loss': 0.0121, 'grad_norm': 4.789510726928711, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.008523833006620407, 'loss_2': 0.003543853759765625, 'loss_3': -16.449663162231445, 'loss_4': 0.9066882133483887, 'epoch': 16.73}
{'loss': 0.0089, 'grad_norm': 4.627535343170166, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.006709465757012367, 'loss_2': 0.0022144317626953125, 'loss_3': -16.420169830322266, 'loss_4': 1.0658535957336426, 'epoch': 16.73}
{'loss': 0.0203, 'grad_norm': 10.566339492797852, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.01808694750070572, 'loss_2': 0.002254486083984375, 'loss_3': -16.288982391357422, 'loss_4': 1.0238587856292725, 'epoch': 16.74}
{'loss': 0.0178, 'grad_norm': 5.413102149963379, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.01348390243947506, 'loss_2': 0.004329681396484375, 'loss_3': -16.26824378967285, 'loss_4': 0.790912926197052, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 13:31:27,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:27,195 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:21<39:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:34,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020854860544204712, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.017042847350239754, 'eval_loss_2': 0.0038120150566101074, 'eval_loss_3': -18.23834800720215, 'eval_loss_4': 0.7430227994918823, 'epoch': 16.74}
{'loss': 0.01, 'grad_norm': 5.355798721313477, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.009450286626815796, 'loss_2': 0.000579833984375, 'loss_3': -16.390291213989258, 'loss_4': 0.9243857264518738, 'epoch': 16.75}
{'loss': 0.035, 'grad_norm': 14.958712577819824, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.03486170619726181, 'loss_2': 0.00018477439880371094, 'loss_3': -16.3582763671875, 'loss_4': 1.042038917541504, 'epoch': 16.76}
{'loss': 0.0146, 'grad_norm': 6.121105194091797, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.012359867803752422, 'loss_2': 0.0022792816162109375, 'loss_3': -16.243465423583984, 'loss_4': 1.225644826889038, 'epoch': 16.76}
{'loss': 0.0099, 'grad_norm': 4.593262195587158, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.003572101006284356, 'loss_2': 0.006336212158203125, 'loss_3': -16.120769500732422, 'loss_4': 0.9006726741790771, 'epoch': 16.77}
{'loss': 0.0125, 'grad_norm': 4.527479648590088, 'learning_rate': 1.325e-05, 'loss_1': 0.006240034010261297, 'loss_2': 0.0062713623046875, 'loss_3': -16.414955139160156, 'loss_4': 0.5444697737693787, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 13:31:34,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:34,535 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:28<39:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:41,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018901467323303223, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015441196970641613, 'eval_loss_2': 0.0034602731466293335, 'eval_loss_3': -18.22027015686035, 'eval_loss_4': 0.7443879246711731, 'epoch': 16.77}
{'loss': 0.016, 'grad_norm': 6.739311695098877, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.011671654880046844, 'loss_2': 0.00435638427734375, 'loss_3': -16.402524948120117, 'loss_4': 1.1052237749099731, 'epoch': 16.78}
{'loss': 0.0217, 'grad_norm': 6.5262932777404785, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.016278067603707314, 'loss_2': 0.00542449951171875, 'loss_3': -16.4241886138916, 'loss_4': 0.7973597049713135, 'epoch': 16.78}
{'loss': 0.0124, 'grad_norm': 4.760583877563477, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.008314348757266998, 'loss_2': 0.00406646728515625, 'loss_3': -16.38894271850586, 'loss_4': 1.1372042894363403, 'epoch': 16.79}
{'loss': 0.0322, 'grad_norm': 13.858531951904297, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.028844168409705162, 'loss_2': 0.003353118896484375, 'loss_3': -16.179168701171875, 'loss_4': 0.6909675598144531, 'epoch': 16.8}
{'loss': 0.0134, 'grad_norm': 5.454867362976074, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.008293109014630318, 'loss_2': 0.00508880615234375, 'loss_3': -16.324792861938477, 'loss_4': 1.050843596458435, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 13:31:41,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:41,881 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:36<39:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:49,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017752133309841156, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014562701806426048, 'eval_loss_2': 0.003189433366060257, 'eval_loss_3': -18.201133728027344, 'eval_loss_4': 0.8649356365203857, 'epoch': 16.8}
{'loss': 0.0117, 'grad_norm': 7.654111385345459, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.010959690436720848, 'loss_2': 0.000705718994140625, 'loss_3': -16.433107376098633, 'loss_4': 0.8857227563858032, 'epoch': 16.81}
{'loss': 0.0292, 'grad_norm': 8.255462646484375, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.01730813831090927, 'loss_2': 0.011871337890625, 'loss_3': -16.299034118652344, 'loss_4': 1.0519440174102783, 'epoch': 16.81}
{'loss': 0.0153, 'grad_norm': 5.610514163970947, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.008197816088795662, 'loss_2': 0.007099151611328125, 'loss_3': -16.600439071655273, 'loss_4': 1.421995997428894, 'epoch': 16.82}
{'loss': 0.0045, 'grad_norm': 4.5913310050964355, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.0034178912173956633, 'loss_2': 0.0011272430419921875, 'loss_3': -16.534278869628906, 'loss_4': 1.2883479595184326, 'epoch': 16.83}
{'loss': 0.0219, 'grad_norm': 6.198818683624268, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.01611771248281002, 'loss_2': 0.00582122802734375, 'loss_3': -16.381656646728516, 'loss_4': 0.7812962532043457, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 13:31:49,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:49,224 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:43<39:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:56,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018243063241243362, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.727, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014406250789761543, 'eval_loss_2': 0.00383681058883667, 'eval_loss_3': -18.2307071685791, 'eval_loss_4': 0.9392194151878357, 'epoch': 16.83}
{'loss': 0.0058, 'grad_norm': 4.354323387145996, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.004503763280808926, 'loss_2': 0.001277923583984375, 'loss_3': -16.418363571166992, 'loss_4': 1.0572478771209717, 'epoch': 16.84}
{'loss': 0.0178, 'grad_norm': 9.237442970275879, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.012251750566065311, 'loss_2': 0.005580902099609375, 'loss_3': -16.543956756591797, 'loss_4': 1.00626540184021, 'epoch': 16.84}
{'loss': 0.0067, 'grad_norm': 5.434464454650879, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.006200145464390516, 'loss_2': 0.0004601478576660156, 'loss_3': -16.263940811157227, 'loss_4': 0.8194568157196045, 'epoch': 16.85}
{'loss': 0.0132, 'grad_norm': 4.998115062713623, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.008441480807960033, 'loss_2': 0.00478363037109375, 'loss_3': -16.222482681274414, 'loss_4': 0.8465155363082886, 'epoch': 16.85}
{'loss': 0.0809, 'grad_norm': 17.263731002807617, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.07294956594705582, 'loss_2': 0.0079803466796875, 'loss_3': -16.338497161865234, 'loss_4': 1.757286787033081, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 13:31:56,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:56,561 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:50<38:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:03,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015376914292573929, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.496, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011715042404830456, 'eval_loss_2': 0.0036618709564208984, 'eval_loss_3': -18.24343490600586, 'eval_loss_4': 1.019584059715271, 'epoch': 16.86}
{'loss': 0.006, 'grad_norm': 5.241793632507324, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.005339724011719227, 'loss_2': 0.0006427764892578125, 'loss_3': -16.24502944946289, 'loss_4': 1.0185248851776123, 'epoch': 16.87}
{'loss': 0.0168, 'grad_norm': 5.994110584259033, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.015517610125243664, 'loss_2': 0.0012760162353515625, 'loss_3': -16.186111450195312, 'loss_4': 1.3309521675109863, 'epoch': 16.87}
{'loss': 0.0301, 'grad_norm': 10.099104881286621, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.026185927912592888, 'loss_2': 0.0039043426513671875, 'loss_3': -16.577728271484375, 'loss_4': 1.1938211917877197, 'epoch': 16.88}
{'loss': 0.0075, 'grad_norm': 4.523540019989014, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.0061998190358281136, 'loss_2': 0.001262664794921875, 'loss_3': -16.369413375854492, 'loss_4': 1.3360458612442017, 'epoch': 16.88}
{'loss': 0.0158, 'grad_norm': 6.681692123413086, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.015688270330429077, 'loss_2': 0.00010287761688232422, 'loss_3': -16.211885452270508, 'loss_4': 1.1803072690963745, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 13:32:03,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:03,905 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:58<38:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:11,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014863754622638226, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.339, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010450298897922039, 'eval_loss_2': 0.0044134557247161865, 'eval_loss_3': -18.263254165649414, 'eval_loss_4': 1.0946829319000244, 'epoch': 16.89}
{'loss': 0.0189, 'grad_norm': 5.19138765335083, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.008712882176041603, 'loss_2': 0.01019287109375, 'loss_3': -16.439430236816406, 'loss_4': 1.5599939823150635, 'epoch': 16.9}
{'loss': 0.0197, 'grad_norm': 5.03745174407959, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.007778992410749197, 'loss_2': 0.01197052001953125, 'loss_3': -16.176258087158203, 'loss_4': 1.3039042949676514, 'epoch': 16.9}
{'loss': 0.0091, 'grad_norm': 4.5952887535095215, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.005765264853835106, 'loss_2': 0.0033245086669921875, 'loss_3': -16.361513137817383, 'loss_4': 1.4310674667358398, 'epoch': 16.91}
{'loss': 0.0143, 'grad_norm': 4.835307598114014, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.007737745996564627, 'loss_2': 0.006542205810546875, 'loss_3': -16.309772491455078, 'loss_4': 1.0793668031692505, 'epoch': 16.91}
{'loss': 0.0081, 'grad_norm': 4.960878372192383, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.0071294354274868965, 'loss_2': 0.0009622573852539062, 'loss_3': -16.668743133544922, 'loss_4': 1.359092354774475, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 13:32:11,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:11,246 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:12:05<38:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:18,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013290389440953732, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01009233109652996, 'eval_loss_2': 0.0031980574131011963, 'eval_loss_3': -18.26799201965332, 'eval_loss_4': 1.1444538831710815, 'epoch': 16.92}
{'loss': 0.018, 'grad_norm': 11.559014320373535, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.015144621953368187, 'loss_2': 0.0028553009033203125, 'loss_3': -16.450904846191406, 'loss_4': 1.6853934526443481, 'epoch': 16.92}
{'loss': 0.0122, 'grad_norm': 4.921418190002441, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.005575769115239382, 'loss_2': 0.00661468505859375, 'loss_3': -16.351181030273438, 'loss_4': 1.167975664138794, 'epoch': 16.93}
{'loss': 0.0134, 'grad_norm': 4.555360794067383, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.008066777139902115, 'loss_2': 0.005340576171875, 'loss_3': -16.28182029724121, 'loss_4': 1.4132349491119385, 'epoch': 16.94}
{'loss': 0.0104, 'grad_norm': 4.702913761138916, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.0061211856082081795, 'loss_2': 0.0042572021484375, 'loss_3': -16.325275421142578, 'loss_4': 0.9470527768135071, 'epoch': 16.94}
{'loss': 0.0106, 'grad_norm': 5.402256011962891, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.0101193031296134, 'loss_2': 0.0004611015319824219, 'loss_3': -16.515796661376953, 'loss_4': 1.7861413955688477, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 13:32:18,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:18,593 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:12<38:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:25,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013932866044342518, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010361683554947376, 'eval_loss_2': 0.0035711824893951416, 'eval_loss_3': -18.253890991210938, 'eval_loss_4': 1.2028014659881592, 'epoch': 16.95}
{'loss': 0.0114, 'grad_norm': 4.631539344787598, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.00563343008980155, 'loss_2': 0.0058135986328125, 'loss_3': -16.340309143066406, 'loss_4': 0.794543981552124, 'epoch': 16.95}
{'loss': 0.0102, 'grad_norm': 4.531136512756348, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.006052819546312094, 'loss_2': 0.0041656494140625, 'loss_3': -16.370742797851562, 'loss_4': 1.611031174659729, 'epoch': 16.96}
{'loss': 0.0175, 'grad_norm': 7.00516414642334, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.016727665439248085, 'loss_2': 0.0007886886596679688, 'loss_3': -16.414649963378906, 'loss_4': 1.4450387954711914, 'epoch': 16.97}
{'loss': 0.0242, 'grad_norm': 8.183303833007812, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.02277064137160778, 'loss_2': 0.0013980865478515625, 'loss_3': -16.132476806640625, 'loss_4': 0.6641369462013245, 'epoch': 16.97}
{'loss': 0.0163, 'grad_norm': 6.195247650146484, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.01019657589495182, 'loss_2': 0.006122589111328125, 'loss_3': -16.324769973754883, 'loss_4': 1.045372486114502, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 13:32:25,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:25,931 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:20<36:20,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 13:32:32,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015293427743017673, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.824, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01164359599351883, 'eval_loss_2': 0.0036498308181762695, 'eval_loss_3': -18.261066436767578, 'eval_loss_4': 1.3189250230789185, 'epoch': 16.98}
{'loss': 0.0425, 'grad_norm': 23.549423217773438, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.04220610111951828, 'loss_2': 0.0003306865692138672, 'loss_3': -16.424497604370117, 'loss_4': 1.9252673387527466, 'epoch': 16.98}
{'loss': 0.0112, 'grad_norm': 5.092575550079346, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.006345254834741354, 'loss_2': 0.004848480224609375, 'loss_3': -16.45452117919922, 'loss_4': 1.533684253692627, 'epoch': 16.99}
{'loss': 0.0164, 'grad_norm': 8.05900764465332, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.008487306535243988, 'loss_2': 0.00786590576171875, 'loss_3': -16.371990203857422, 'loss_4': 1.4874361753463745, 'epoch': 16.99}
{'loss': 0.0104, 'grad_norm': 6.184568405151367, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.004887799732387066, 'loss_2': 0.005504608154296875, 'loss_3': -16.297199249267578, 'loss_4': 2.174833059310913, 'epoch': 17.0}
{'loss': 0.0084, 'grad_norm': 4.6159749031066895, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.005396883934736252, 'loss_2': 0.00298309326171875, 'loss_3': -16.379352569580078, 'loss_4': 1.711851954460144, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 13:32:32,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:32,953 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:27<38:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:40,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015483152121305466, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012709390372037888, 'eval_loss_2': 0.002773761749267578, 'eval_loss_3': -18.24662971496582, 'eval_loss_4': 1.3363734483718872, 'epoch': 17.01}
{'loss': 0.0301, 'grad_norm': 11.278275489807129, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.027686893939971924, 'loss_2': 0.00244140625, 'loss_3': -16.438156127929688, 'loss_4': 1.9226521253585815, 'epoch': 17.01}
{'loss': 0.0126, 'grad_norm': 4.49522590637207, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.007338682655245066, 'loss_2': 0.00525665283203125, 'loss_3': -16.280988693237305, 'loss_4': 1.5609521865844727, 'epoch': 17.02}
{'loss': 0.0201, 'grad_norm': 7.44261360168457, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.01329704187810421, 'loss_2': 0.00682830810546875, 'loss_3': -16.492525100708008, 'loss_4': 1.3041937351226807, 'epoch': 17.02}
{'loss': 0.014, 'grad_norm': 5.313833236694336, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.00706543680280447, 'loss_2': 0.00693511962890625, 'loss_3': -16.438505172729492, 'loss_4': 1.4636074304580688, 'epoch': 17.03}
{'loss': 0.0125, 'grad_norm': 5.2627129554748535, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.008211703039705753, 'loss_2': 0.00424957275390625, 'loss_3': -16.37127685546875, 'loss_4': 1.1737785339355469, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 13:32:40,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:40,287 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:34<38:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:47,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01573353074491024, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.771, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012816783972084522, 'eval_loss_2': 0.0029167458415031433, 'eval_loss_3': -18.24088478088379, 'eval_loss_4': 1.2866592407226562, 'epoch': 17.03}
{'loss': 0.0123, 'grad_norm': 5.087369918823242, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.007828128524124622, 'loss_2': 0.004425048828125, 'loss_3': -16.36505699157715, 'loss_4': 1.5716049671173096, 'epoch': 17.04}
{'loss': 0.0163, 'grad_norm': 5.522368431091309, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.009627391584217548, 'loss_2': 0.006649017333984375, 'loss_3': -16.499874114990234, 'loss_4': 1.286604642868042, 'epoch': 17.05}
{'loss': 0.0151, 'grad_norm': 5.857326984405518, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.012546510435640812, 'loss_2': 0.002559661865234375, 'loss_3': -16.218046188354492, 'loss_4': 1.6775792837142944, 'epoch': 17.05}
{'loss': 0.011, 'grad_norm': 4.819311141967773, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.008293518796563148, 'loss_2': 0.002735137939453125, 'loss_3': -16.495925903320312, 'loss_4': 1.7608106136322021, 'epoch': 17.06}
{'loss': 0.0387, 'grad_norm': 12.254484176635742, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.03677164763212204, 'loss_2': 0.001911163330078125, 'loss_3': -16.157451629638672, 'loss_4': 1.188389778137207, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 13:32:47,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:47,621 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:42<38:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:54,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016602888703346252, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.676, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013362722471356392, 'eval_loss_2': 0.0032401680946350098, 'eval_loss_3': -18.23776626586914, 'eval_loss_4': 1.2005128860473633, 'epoch': 17.06}
{'loss': 0.0294, 'grad_norm': 8.05498218536377, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.02803737111389637, 'loss_2': 0.0013885498046875, 'loss_3': -16.408613204956055, 'loss_4': 1.6872262954711914, 'epoch': 17.07}
{'loss': 0.0105, 'grad_norm': 5.136568069458008, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.007320919539779425, 'loss_2': 0.00319671630859375, 'loss_3': -16.308427810668945, 'loss_4': 1.382447361946106, 'epoch': 17.08}
{'loss': 0.0087, 'grad_norm': 4.680872440338135, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.007742138113826513, 'loss_2': 0.0009241104125976562, 'loss_3': -16.344186782836914, 'loss_4': 1.5139522552490234, 'epoch': 17.08}
{'loss': 0.0102, 'grad_norm': 4.68821382522583, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.006710960064083338, 'loss_2': 0.00347137451171875, 'loss_3': -16.473304748535156, 'loss_4': 1.4384479522705078, 'epoch': 17.09}
{'loss': 0.017, 'grad_norm': 5.18966007232666, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.0086997514590621, 'loss_2': 0.00832366943359375, 'loss_3': -16.275236129760742, 'loss_4': 1.314802885055542, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 13:32:54,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:54,968 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:49<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:02,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017956912517547607, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.401, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013558120466768742, 'eval_loss_2': 0.00439879298210144, 'eval_loss_3': -18.232135772705078, 'eval_loss_4': 0.9730287790298462, 'epoch': 17.09}
{'loss': 0.0092, 'grad_norm': 5.587081432342529, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.007453686557710171, 'loss_2': 0.0017375946044921875, 'loss_3': -16.256622314453125, 'loss_4': 0.6038373708724976, 'epoch': 17.1}
{'loss': 0.0133, 'grad_norm': 5.391075611114502, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.009045288898050785, 'loss_2': 0.00426483154296875, 'loss_3': -16.138336181640625, 'loss_4': 0.7128384113311768, 'epoch': 17.1}
{'loss': 0.015, 'grad_norm': 5.398229598999023, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.00947497133165598, 'loss_2': 0.00553131103515625, 'loss_3': -16.362342834472656, 'loss_4': 1.2393208742141724, 'epoch': 17.11}
{'loss': 0.0164, 'grad_norm': 8.634531021118164, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.015198763459920883, 'loss_2': 0.001251220703125, 'loss_3': -16.347824096679688, 'loss_4': 0.8370329737663269, 'epoch': 17.12}
{'loss': 0.0153, 'grad_norm': 5.810021877288818, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.008285705000162125, 'loss_2': 0.00696563720703125, 'loss_3': -16.433780670166016, 'loss_4': 0.9581557512283325, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 13:33:02,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:02,313 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:56<38:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:09,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015620671212673187, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011702663265168667, 'eval_loss_2': 0.003918007016181946, 'eval_loss_3': -18.208810806274414, 'eval_loss_4': 0.8328192234039307, 'epoch': 17.12}
{'loss': 0.0135, 'grad_norm': 5.062568664550781, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.009846688248217106, 'loss_2': 0.0036258697509765625, 'loss_3': -16.34469985961914, 'loss_4': 0.7185724377632141, 'epoch': 17.13}
{'loss': 0.0282, 'grad_norm': 7.1173224449157715, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.017960794270038605, 'loss_2': 0.01027679443359375, 'loss_3': -16.290719985961914, 'loss_4': 1.271935224533081, 'epoch': 17.13}
{'loss': 0.0124, 'grad_norm': 5.125146865844727, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.007312819827347994, 'loss_2': 0.0051116943359375, 'loss_3': -16.489107131958008, 'loss_4': 0.7680214047431946, 'epoch': 17.14}
{'loss': 0.0046, 'grad_norm': 4.796580791473389, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.0034338352270424366, 'loss_2': 0.0011615753173828125, 'loss_3': -16.410648345947266, 'loss_4': 0.6642324924468994, 'epoch': 17.15}
{'loss': 0.0123, 'grad_norm': 5.157166004180908, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.00979732908308506, 'loss_2': 0.0025310516357421875, 'loss_3': -16.276554107666016, 'loss_4': 0.35891735553741455, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 13:33:09,652 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:09,652 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:13:04<38:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:16,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01520331110805273, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.468, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012679454870522022, 'eval_loss_2': 0.002523854374885559, 'eval_loss_3': -18.196392059326172, 'eval_loss_4': 0.5615510940551758, 'epoch': 17.15}
{'loss': 0.0045, 'grad_norm': 4.9834465980529785, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.0038832928985357285, 'loss_2': 0.0005755424499511719, 'loss_3': -16.51776885986328, 'loss_4': 0.7555660009384155, 'epoch': 17.16}
{'loss': 0.006, 'grad_norm': 5.156041622161865, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.004872285295277834, 'loss_2': 0.0011653900146484375, 'loss_3': -16.3270263671875, 'loss_4': 0.7121835947036743, 'epoch': 17.16}
{'loss': 0.0112, 'grad_norm': 5.2881059646606445, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.007345277350395918, 'loss_2': 0.003856658935546875, 'loss_3': -16.537532806396484, 'loss_4': 0.571495771408081, 'epoch': 17.17}
{'loss': 0.0107, 'grad_norm': 5.770941257476807, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.009702836163341999, 'loss_2': 0.0009546279907226562, 'loss_3': -16.34221649169922, 'loss_4': 0.2581738829612732, 'epoch': 17.17}
{'loss': 0.0149, 'grad_norm': 7.761541366577148, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.014827242121100426, 'loss_2': 9.292364120483398e-05, 'loss_3': -16.451698303222656, 'loss_4': 0.7305821180343628, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 13:33:16,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:16,997 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:11<37:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:24,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013795876875519753, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011137123219668865, 'eval_loss_2': 0.002658754587173462, 'eval_loss_3': -18.201038360595703, 'eval_loss_4': 0.22963298857212067, 'epoch': 17.18}
{'loss': 0.0178, 'grad_norm': 6.1779279708862305, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.007832189090549946, 'loss_2': 0.00995635986328125, 'loss_3': -16.36626625061035, 'loss_4': 0.09484061598777771, 'epoch': 17.19}
{'loss': 0.0162, 'grad_norm': 8.03791618347168, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.013072982430458069, 'loss_2': 0.003108978271484375, 'loss_3': -16.319265365600586, 'loss_4': 0.6348992586135864, 'epoch': 17.19}
{'loss': 0.0172, 'grad_norm': 10.713316917419434, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.014226914383471012, 'loss_2': 0.0029964447021484375, 'loss_3': -16.22202491760254, 'loss_4': 0.7379651069641113, 'epoch': 17.2}
{'loss': 0.0191, 'grad_norm': 6.966747760772705, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.011443308554589748, 'loss_2': 0.007648468017578125, 'loss_3': -16.153444290161133, 'loss_4': 0.5019030570983887, 'epoch': 17.2}
{'loss': 0.0088, 'grad_norm': 5.081708908081055, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.005418982356786728, 'loss_2': 0.003360748291015625, 'loss_3': -16.25725746154785, 'loss_4': 0.3506089746952057, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 13:33:24,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:24,329 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:18<37:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:31,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013262656517326832, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010565873235464096, 'eval_loss_2': 0.002696782350540161, 'eval_loss_3': -18.206809997558594, 'eval_loss_4': 0.01270008273422718, 'epoch': 17.21}
{'loss': 0.0083, 'grad_norm': 4.910690784454346, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.006120292469859123, 'loss_2': 0.00217437744140625, 'loss_3': -16.277496337890625, 'loss_4': 0.3892093896865845, 'epoch': 17.22}
{'loss': 0.0534, 'grad_norm': 13.200421333312988, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.0518835186958313, 'loss_2': 0.0015573501586914062, 'loss_3': -16.22642707824707, 'loss_4': 0.7770374417304993, 'epoch': 17.22}
{'loss': 0.0045, 'grad_norm': 4.328946590423584, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.004253731109201908, 'loss_2': 0.0002334117889404297, 'loss_3': -16.26317024230957, 'loss_4': 0.25654691457748413, 'epoch': 17.23}
{'loss': 0.0172, 'grad_norm': 10.605384826660156, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.014910918660461903, 'loss_2': 0.002277374267578125, 'loss_3': -16.387237548828125, 'loss_4': 0.33125489950180054, 'epoch': 17.23}
{'loss': 0.0241, 'grad_norm': 6.5503058433532715, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.017424430698156357, 'loss_2': 0.00666046142578125, 'loss_3': -16.44303321838379, 'loss_4': 0.26552122831344604, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 13:33:31,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:31,677 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:26<37:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:39,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01395916473120451, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.488, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010569611564278603, 'eval_loss_2': 0.0033895522356033325, 'eval_loss_3': -18.22760009765625, 'eval_loss_4': -0.08629375696182251, 'epoch': 17.24}
{'loss': 0.0063, 'grad_norm': 4.926165580749512, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.003947393968701363, 'loss_2': 0.002399444580078125, 'loss_3': -16.327369689941406, 'loss_4': 0.294416606426239, 'epoch': 17.24}
{'loss': 0.0115, 'grad_norm': 5.468972682952881, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.00760249188169837, 'loss_2': 0.003879547119140625, 'loss_3': -16.127790451049805, 'loss_4': 0.795778214931488, 'epoch': 17.25}
{'loss': 0.0123, 'grad_norm': 5.377506256103516, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.00815824419260025, 'loss_2': 0.0041046142578125, 'loss_3': -16.52899932861328, 'loss_4': 0.16262386739253998, 'epoch': 17.26}
{'loss': 0.0106, 'grad_norm': 5.0623064041137695, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.0044103264808654785, 'loss_2': 0.00618743896484375, 'loss_3': -16.219690322875977, 'loss_4': 0.07836364209651947, 'epoch': 17.26}
{'loss': 0.0168, 'grad_norm': 5.135494709014893, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.003637938527390361, 'loss_2': 0.01311492919921875, 'loss_3': -16.48758316040039, 'loss_4': -0.07154306769371033, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 13:33:39,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:39,019 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:33<37:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:46,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01795782521367073, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009847003035247326, 'eval_loss_2': 0.00811082124710083, 'eval_loss_3': -18.2351131439209, 'eval_loss_4': 0.018412847071886063, 'epoch': 17.27}
{'loss': 0.007, 'grad_norm': 4.478321075439453, 'learning_rate': 1.275e-05, 'loss_1': 0.004306173417717218, 'loss_2': 0.002681732177734375, 'loss_3': -16.369003295898438, 'loss_4': 0.4909176230430603, 'epoch': 17.27}
{'loss': 0.0172, 'grad_norm': 4.389188289642334, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.007440838031470776, 'loss_2': 0.00971221923828125, 'loss_3': -16.415470123291016, 'loss_4': 0.3922940790653229, 'epoch': 17.28}
{'loss': 0.0168, 'grad_norm': 6.5286149978637695, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.012074090540409088, 'loss_2': 0.00469970703125, 'loss_3': -16.446300506591797, 'loss_4': 0.3984103798866272, 'epoch': 17.28}
{'loss': 0.0223, 'grad_norm': 10.36413860321045, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.014304855838418007, 'loss_2': 0.0080108642578125, 'loss_3': -16.39015007019043, 'loss_4': 0.2941482365131378, 'epoch': 17.29}
{'loss': 0.0122, 'grad_norm': 5.005579948425293, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.004480752628296614, 'loss_2': 0.00774383544921875, 'loss_3': -16.222476959228516, 'loss_4': 0.4096851348876953, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 13:33:46,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:46,361 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:40<37:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:53,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015111244283616543, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.784, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008784756995737553, 'eval_loss_2': 0.006326489150524139, 'eval_loss_3': -18.24761962890625, 'eval_loss_4': 0.10199932754039764, 'epoch': 17.3}
{'loss': 0.012, 'grad_norm': 5.322394847869873, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.005492134485393763, 'loss_2': 0.0064849853515625, 'loss_3': -16.31386947631836, 'loss_4': -0.28963902592658997, 'epoch': 17.3}
{'loss': 0.013, 'grad_norm': 4.121845722198486, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.004509200807660818, 'loss_2': 0.00847625732421875, 'loss_3': -16.099151611328125, 'loss_4': 0.3601143956184387, 'epoch': 17.31}
{'loss': 0.0035, 'grad_norm': 4.864971160888672, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.003153994446620345, 'loss_2': 0.0003924369812011719, 'loss_3': -16.46027183532715, 'loss_4': 0.5537408590316772, 'epoch': 17.31}
{'loss': 0.0298, 'grad_norm': 10.906824111938477, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.025133473798632622, 'loss_2': 0.00466156005859375, 'loss_3': -16.317285537719727, 'loss_4': 0.27915647625923157, 'epoch': 17.32}
{'loss': 0.0077, 'grad_norm': 4.331936836242676, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.004273208789527416, 'loss_2': 0.003448486328125, 'loss_3': -16.31279754638672, 'loss_4': 0.502880871295929, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 13:33:53,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:53,694 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:48<37:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:01,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011976398527622223, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.704, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008773854933679104, 'eval_loss_2': 0.0032025426626205444, 'eval_loss_3': -18.235103607177734, 'eval_loss_4': 0.22922876477241516, 'epoch': 17.33}
{'loss': 0.041, 'grad_norm': 12.494816780090332, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.02720215730369091, 'loss_2': 0.01384735107421875, 'loss_3': -16.153762817382812, 'loss_4': 0.9216006994247437, 'epoch': 17.33}
{'loss': 0.014, 'grad_norm': 4.795711994171143, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.00577028701081872, 'loss_2': 0.008270263671875, 'loss_3': -16.371681213378906, 'loss_4': 0.5194211006164551, 'epoch': 17.34}
{'loss': 0.0136, 'grad_norm': 5.293008804321289, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.006036450155079365, 'loss_2': 0.00753021240234375, 'loss_3': -16.310245513916016, 'loss_4': 0.5039702653884888, 'epoch': 17.34}
{'loss': 0.0273, 'grad_norm': 11.39420223236084, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.02305140718817711, 'loss_2': 0.00421142578125, 'loss_3': -16.312618255615234, 'loss_4': 0.35272055864334106, 'epoch': 17.35}
{'loss': 0.0157, 'grad_norm': 5.706655502319336, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.009859815239906311, 'loss_2': 0.00580596923828125, 'loss_3': -16.34699249267578, 'loss_4': 0.6270517110824585, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 13:34:01,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:01,032 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:55<37:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:08,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013746332377195358, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010306017473340034, 'eval_loss_2': 0.0034403130412101746, 'eval_loss_3': -18.21204376220703, 'eval_loss_4': 0.2233675718307495, 'epoch': 17.35}
{'loss': 0.0138, 'grad_norm': 4.642550945281982, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.0061194151639938354, 'loss_2': 0.00763702392578125, 'loss_3': -16.494937896728516, 'loss_4': 0.5595353245735168, 'epoch': 17.36}
{'loss': 0.0152, 'grad_norm': 6.414644718170166, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.014591308310627937, 'loss_2': 0.0005664825439453125, 'loss_3': -16.35801887512207, 'loss_4': 0.9701076149940491, 'epoch': 17.37}
{'loss': 0.0124, 'grad_norm': 6.741500377655029, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.004040766041725874, 'loss_2': 0.008392333984375, 'loss_3': -16.329757690429688, 'loss_4': 0.3571658432483673, 'epoch': 17.37}
{'loss': 0.0121, 'grad_norm': 5.616602897644043, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.00824109185487032, 'loss_2': 0.003810882568359375, 'loss_3': -16.427919387817383, 'loss_4': 0.05957355350255966, 'epoch': 17.38}
{'loss': 0.016, 'grad_norm': 5.460272312164307, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.012620728462934494, 'loss_2': 0.00336456298828125, 'loss_3': -16.435298919677734, 'loss_4': 0.9737896919250488, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 13:34:08,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:08,375 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:14:02<37:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:15,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015967071056365967, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01129183080047369, 'eval_loss_2': 0.004675239324569702, 'eval_loss_3': -18.244152069091797, 'eval_loss_4': 0.17703792452812195, 'epoch': 17.38}
{'loss': 0.0175, 'grad_norm': 5.756689071655273, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.0077990819700062275, 'loss_2': 0.009674072265625, 'loss_3': -16.498523712158203, 'loss_4': 0.6835103034973145, 'epoch': 17.39}
{'loss': 0.0172, 'grad_norm': 7.778714179992676, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.014242324978113174, 'loss_2': 0.0029506683349609375, 'loss_3': -16.53597068786621, 'loss_4': 0.32639431953430176, 'epoch': 17.4}
{'loss': 0.0129, 'grad_norm': 6.42990779876709, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.011650103144347668, 'loss_2': 0.0012254714965820312, 'loss_3': -16.304122924804688, 'loss_4': 0.3378358781337738, 'epoch': 17.4}
{'loss': 0.0214, 'grad_norm': 16.580713272094727, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.020626729354262352, 'loss_2': 0.000797271728515625, 'loss_3': -16.497817993164062, 'loss_4': 0.4626973867416382, 'epoch': 17.41}
{'loss': 0.0114, 'grad_norm': 5.925591468811035, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.010477720759809017, 'loss_2': 0.0008869171142578125, 'loss_3': -16.580432891845703, 'loss_4': 0.2926298975944519, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 13:34:15,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:15,719 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:10<37:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:23,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015734069049358368, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.718, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011580339632928371, 'eval_loss_2': 0.004153728485107422, 'eval_loss_3': -18.233489990234375, 'eval_loss_4': 0.10436472296714783, 'epoch': 17.41}
{'loss': 0.0154, 'grad_norm': 6.470452308654785, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.013390559703111649, 'loss_2': 0.001979827880859375, 'loss_3': -16.417184829711914, 'loss_4': 0.6708319187164307, 'epoch': 17.42}
{'loss': 0.0132, 'grad_norm': 6.728237152099609, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.012007015757262707, 'loss_2': 0.001201629638671875, 'loss_3': -16.396142959594727, 'loss_4': 0.4431028962135315, 'epoch': 17.42}
{'loss': 0.0108, 'grad_norm': 4.974334716796875, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.004373448435217142, 'loss_2': 0.0064697265625, 'loss_3': -16.43391227722168, 'loss_4': 0.1357177197933197, 'epoch': 17.43}
{'loss': 0.0183, 'grad_norm': 5.256424903869629, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.008379633538424969, 'loss_2': 0.0098724365234375, 'loss_3': -16.485023498535156, 'loss_4': 0.47609978914260864, 'epoch': 17.44}
{'loss': 0.0157, 'grad_norm': 4.303075313568115, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.005581933073699474, 'loss_2': 0.0101318359375, 'loss_3': -16.354644775390625, 'loss_4': 0.1593123972415924, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 13:34:23,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:23,050 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:17<37:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:30,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01572578027844429, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012035633437335491, 'eval_loss_2': 0.0036901459097862244, 'eval_loss_3': -18.2401065826416, 'eval_loss_4': 0.05967383086681366, 'epoch': 17.44}
{'loss': 0.0184, 'grad_norm': 6.374577522277832, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.013425067998468876, 'loss_2': 0.00501251220703125, 'loss_3': -16.4953670501709, 'loss_4': 0.04511461406946182, 'epoch': 17.45}
{'loss': 0.0138, 'grad_norm': 6.649765491485596, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.01320801954716444, 'loss_2': 0.0005712509155273438, 'loss_3': -16.400100708007812, 'loss_4': 0.08268245309591293, 'epoch': 17.45}
{'loss': 0.0391, 'grad_norm': 14.834410667419434, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.03803074359893799, 'loss_2': 0.0010852813720703125, 'loss_3': -16.37071990966797, 'loss_4': 0.2545256018638611, 'epoch': 17.46}
{'loss': 0.0091, 'grad_norm': 4.928137302398682, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.007963343523442745, 'loss_2': 0.001125335693359375, 'loss_3': -16.588512420654297, 'loss_4': 0.7929134368896484, 'epoch': 17.47}
{'loss': 0.0138, 'grad_norm': 6.1124267578125, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.011212779209017754, 'loss_2': 0.0026302337646484375, 'loss_3': -16.535839080810547, 'loss_4': 0.4842935800552368, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 13:34:30,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:30,386 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:24<37:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:37,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0154753178358078, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012691876851022243, 'eval_loss_2': 0.002783440053462982, 'eval_loss_3': -18.241371154785156, 'eval_loss_4': 0.06019821763038635, 'epoch': 17.47}
{'loss': 0.0129, 'grad_norm': 4.902786731719971, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.007836692966520786, 'loss_2': 0.00502777099609375, 'loss_3': -16.52012825012207, 'loss_4': 0.34975188970565796, 'epoch': 17.48}
{'loss': 0.0124, 'grad_norm': 4.93013858795166, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.004073227755725384, 'loss_2': 0.00836181640625, 'loss_3': -16.516172409057617, 'loss_4': 0.2883468270301819, 'epoch': 17.48}
{'loss': 0.0159, 'grad_norm': 7.333590507507324, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.015212032943964005, 'loss_2': 0.0006742477416992188, 'loss_3': -16.22709846496582, 'loss_4': 0.07475389540195465, 'epoch': 17.49}
{'loss': 0.0144, 'grad_norm': 5.448291778564453, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.008664790540933609, 'loss_2': 0.005779266357421875, 'loss_3': -16.264156341552734, 'loss_4': 0.19415131211280823, 'epoch': 17.49}
{'loss': 0.02, 'grad_norm': 8.516773223876953, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.013439098373055458, 'loss_2': 0.00656890869140625, 'loss_3': -16.46946907043457, 'loss_4': 0.33723872900009155, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 13:34:37,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:37,724 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:32<37:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:45,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01589275524020195, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012111344374716282, 'eval_loss_2': 0.0037814080715179443, 'eval_loss_3': -18.21245574951172, 'eval_loss_4': -0.042390234768390656, 'epoch': 17.5}
{'loss': 0.0119, 'grad_norm': 5.212762832641602, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.008083745837211609, 'loss_2': 0.00383758544921875, 'loss_3': -16.257232666015625, 'loss_4': 0.1429438292980194, 'epoch': 17.51}
{'loss': 0.0106, 'grad_norm': 4.992029666900635, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.008925742469727993, 'loss_2': 0.0017032623291015625, 'loss_3': -16.402835845947266, 'loss_4': 0.22968637943267822, 'epoch': 17.51}
{'loss': 0.079, 'grad_norm': 20.16510581970215, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.07719859480857849, 'loss_2': 0.00176239013671875, 'loss_3': -16.52682876586914, 'loss_4': 0.7504833936691284, 'epoch': 17.52}
{'loss': 0.0165, 'grad_norm': 6.456467628479004, 'learning_rate': 1.25e-05, 'loss_1': 0.008687513880431652, 'loss_2': 0.00783538818359375, 'loss_3': -16.087244033813477, 'loss_4': 0.24410925805568695, 'epoch': 17.52}
{'loss': 0.0094, 'grad_norm': 4.955165386199951, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.0056433044373989105, 'loss_2': 0.003734588623046875, 'loss_3': -16.50668716430664, 'loss_4': 0.3792763352394104, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 13:34:45,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:45,057 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:39<36:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:52,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01438959501683712, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.276, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012095851823687553, 'eval_loss_2': 0.0022937431931495667, 'eval_loss_3': -18.203781127929688, 'eval_loss_4': -0.25189828872680664, 'epoch': 17.53}
{'loss': 0.0222, 'grad_norm': 10.604290008544922, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.015456648543477058, 'loss_2': 0.00678253173828125, 'loss_3': -16.3635311126709, 'loss_4': -0.22339728474617004, 'epoch': 17.53}
{'loss': 0.0136, 'grad_norm': 7.334975242614746, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.012925373390316963, 'loss_2': 0.0006456375122070312, 'loss_3': -16.253482818603516, 'loss_4': -0.16526561975479126, 'epoch': 17.54}
{'loss': 0.0178, 'grad_norm': 5.523989200592041, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.01019268948584795, 'loss_2': 0.007568359375, 'loss_3': -16.506206512451172, 'loss_4': -0.010452672839164734, 'epoch': 17.55}
{'loss': 0.0141, 'grad_norm': 6.12682580947876, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.01010722666978836, 'loss_2': 0.00397491455078125, 'loss_3': -16.356752395629883, 'loss_4': -0.10573502629995346, 'epoch': 17.55}
{'loss': 0.0286, 'grad_norm': 8.219157218933105, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.021590473130345345, 'loss_2': 0.00701904296875, 'loss_3': -16.084503173828125, 'loss_4': -0.2890828847885132, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 13:34:52,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:52,398 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:46<37:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:59,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018058661371469498, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012791218236088753, 'eval_loss_2': 0.005267441272735596, 'eval_loss_3': -18.214298248291016, 'eval_loss_4': -0.36987629532814026, 'epoch': 17.56}
{'loss': 0.0156, 'grad_norm': 4.690022945404053, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.00767518999055028, 'loss_2': 0.0079193115234375, 'loss_3': -16.330963134765625, 'loss_4': -0.08342766761779785, 'epoch': 17.56}
{'loss': 0.016, 'grad_norm': 6.619769096374512, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.00929115992039442, 'loss_2': 0.0067138671875, 'loss_3': -16.498960494995117, 'loss_4': 0.3329971432685852, 'epoch': 17.57}
{'loss': 0.0319, 'grad_norm': 10.423956871032715, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.027198296040296555, 'loss_2': 0.004665374755859375, 'loss_3': -16.34320068359375, 'loss_4': -0.012224987149238586, 'epoch': 17.58}
{'loss': 0.0101, 'grad_norm': 5.09063720703125, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.006767980754375458, 'loss_2': 0.00331878662109375, 'loss_3': -16.378889083862305, 'loss_4': -0.5472251176834106, 'epoch': 17.58}
{'loss': 0.0107, 'grad_norm': 5.348410129547119, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.00918990932404995, 'loss_2': 0.0015020370483398438, 'loss_3': -16.42255210876465, 'loss_4': -0.42699766159057617, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 13:34:59,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:59,756 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:54<36:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:07,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016191206872463226, 'eval_runtime': 3.8297, 'eval_samples_per_second': 267.384, 'eval_steps_per_second': 4.178, 'eval_loss_1': 0.013107366859912872, 'eval_loss_2': 0.003083840012550354, 'eval_loss_3': -18.216197967529297, 'eval_loss_4': -0.5225234627723694, 'epoch': 17.59}
{'loss': 0.0218, 'grad_norm': 11.640445709228516, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.020591527223587036, 'loss_2': 0.001251220703125, 'loss_3': -16.449600219726562, 'loss_4': -0.0883030891418457, 'epoch': 17.59}
{'loss': 0.0198, 'grad_norm': 5.086222171783447, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.011369886808097363, 'loss_2': 0.0084075927734375, 'loss_3': -16.448673248291016, 'loss_4': -0.6715905666351318, 'epoch': 17.6}
{'loss': 0.0115, 'grad_norm': 5.601187229156494, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.009012173861265182, 'loss_2': 0.002529144287109375, 'loss_3': -16.58478355407715, 'loss_4': -0.6061789989471436, 'epoch': 17.6}
{'loss': 0.0142, 'grad_norm': 8.338301658630371, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.010334989987313747, 'loss_2': 0.0038509368896484375, 'loss_3': -16.56777572631836, 'loss_4': -0.6969329714775085, 'epoch': 17.61}
{'loss': 0.0249, 'grad_norm': 7.763123989105225, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.02450835518538952, 'loss_2': 0.0004200935363769531, 'loss_3': -16.45248031616211, 'loss_4': -0.2838013768196106, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 13:35:07,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:07,134 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:15:01<36:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:14,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017591772601008415, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.014160198159515858, 'eval_loss_2': 0.003431573510169983, 'eval_loss_3': -18.19904899597168, 'eval_loss_4': -0.612926185131073, 'epoch': 17.62}
{'loss': 0.0083, 'grad_norm': 4.382955074310303, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.004693015478551388, 'loss_2': 0.003570556640625, 'loss_3': -16.53631591796875, 'loss_4': -0.5802948474884033, 'epoch': 17.62}
{'loss': 0.0114, 'grad_norm': 5.393702507019043, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.006655616220086813, 'loss_2': 0.0047760009765625, 'loss_3': -16.37571144104004, 'loss_4': -0.48189592361450195, 'epoch': 17.63}
{'loss': 0.0093, 'grad_norm': 4.553762912750244, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.007142296060919762, 'loss_2': 0.00211334228515625, 'loss_3': -16.480270385742188, 'loss_4': -0.5176988244056702, 'epoch': 17.63}
{'loss': 0.01, 'grad_norm': 5.676027774810791, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.007182864937931299, 'loss_2': 0.002819061279296875, 'loss_3': -16.514419555664062, 'loss_4': -0.88251793384552, 'epoch': 17.64}
{'loss': 0.0145, 'grad_norm': 8.16163444519043, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.010747229680418968, 'loss_2': 0.0037384033203125, 'loss_3': -16.440250396728516, 'loss_4': -0.6891307234764099, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 13:35:14,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:14,508 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:08<36:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:21,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017891721799969673, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013802782632410526, 'eval_loss_2': 0.004088938236236572, 'eval_loss_3': -18.2052059173584, 'eval_loss_4': -0.5969858765602112, 'epoch': 17.65}
{'loss': 0.0104, 'grad_norm': 5.114181041717529, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.008954706601798534, 'loss_2': 0.0014476776123046875, 'loss_3': -16.384681701660156, 'loss_4': -0.14442026615142822, 'epoch': 17.65}
{'loss': 0.0151, 'grad_norm': 5.873316287994385, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.008829900063574314, 'loss_2': 0.00626373291015625, 'loss_3': -16.48934555053711, 'loss_4': -0.27757734060287476, 'epoch': 17.66}
{'loss': 0.0089, 'grad_norm': 4.43806791305542, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.0038216793909668922, 'loss_2': 0.005069732666015625, 'loss_3': -16.655452728271484, 'loss_4': -0.38442161679267883, 'epoch': 17.66}
{'loss': 0.011, 'grad_norm': 5.789608955383301, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.00818261131644249, 'loss_2': 0.002796173095703125, 'loss_3': -16.5596923828125, 'loss_4': -0.10831224918365479, 'epoch': 17.67}
{'loss': 0.0086, 'grad_norm': 4.780948162078857, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.0063814641907811165, 'loss_2': 0.00220489501953125, 'loss_3': -16.495752334594727, 'loss_4': -0.8624857664108276, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 13:35:21,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:21,856 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:16<36:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:29,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017236819490790367, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.765, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.014860173687338829, 'eval_loss_2': 0.002376645803451538, 'eval_loss_3': -18.204065322875977, 'eval_loss_4': -0.5789134502410889, 'epoch': 17.67}
{'loss': 0.0129, 'grad_norm': 6.108298301696777, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.0118070924654603, 'loss_2': 0.0010509490966796875, 'loss_3': -16.41747283935547, 'loss_4': -0.7674075365066528, 'epoch': 17.68}
{'loss': 0.0266, 'grad_norm': 19.557321548461914, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.024358296766877174, 'loss_2': 0.002227783203125, 'loss_3': -16.4630184173584, 'loss_4': -0.5385310053825378, 'epoch': 17.69}
{'loss': 0.0054, 'grad_norm': 5.658970355987549, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.005194452125579119, 'loss_2': 0.00019288063049316406, 'loss_3': -16.466842651367188, 'loss_4': -0.3291480541229248, 'epoch': 17.69}
{'loss': 0.0145, 'grad_norm': 8.457900047302246, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.01444604154676199, 'loss_2': 3.8743019104003906e-05, 'loss_3': -16.38811683654785, 'loss_4': -0.054459892213344574, 'epoch': 17.7}
{'loss': 0.009, 'grad_norm': 5.345281600952148, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.008193213492631912, 'loss_2': 0.0008025169372558594, 'loss_3': -16.511215209960938, 'loss_4': -0.6161233186721802, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 13:35:29,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:29,214 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:23<36:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:36,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01789151132106781, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013991768471896648, 'eval_loss_2': 0.003899741917848587, 'eval_loss_3': -18.219669342041016, 'eval_loss_4': -0.5490264892578125, 'epoch': 17.7}
{'loss': 0.01, 'grad_norm': 5.517191410064697, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.006329982075840235, 'loss_2': 0.003643035888671875, 'loss_3': -16.353370666503906, 'loss_4': -0.8422531485557556, 'epoch': 17.71}
{'loss': 0.0158, 'grad_norm': 5.708014965057373, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.013023029081523418, 'loss_2': 0.002819061279296875, 'loss_3': -16.374425888061523, 'loss_4': -0.3449329733848572, 'epoch': 17.72}
{'loss': 0.0143, 'grad_norm': 5.384571075439453, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.013506918214261532, 'loss_2': 0.0008087158203125, 'loss_3': -16.379222869873047, 'loss_4': -0.7023487091064453, 'epoch': 17.72}
{'loss': 0.0331, 'grad_norm': 10.74587345123291, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.022391151636838913, 'loss_2': 0.010711669921875, 'loss_3': -16.300872802734375, 'loss_4': -0.09778988361358643, 'epoch': 17.73}
{'loss': 0.016, 'grad_norm': 6.489321708679199, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.014423346146941185, 'loss_2': 0.0015277862548828125, 'loss_3': -16.28536605834961, 'loss_4': -0.42309534549713135, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 13:35:36,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:36,558 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:30<36:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:43,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015913646668195724, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013259809464216232, 'eval_loss_2': 0.002653837203979492, 'eval_loss_3': -18.247676849365234, 'eval_loss_4': -0.5021401047706604, 'epoch': 17.73}
{'loss': 0.0163, 'grad_norm': 11.007396697998047, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.013552429154515266, 'loss_2': 0.00270843505859375, 'loss_3': -16.50644874572754, 'loss_4': -0.07499389350414276, 'epoch': 17.74}
{'loss': 0.0139, 'grad_norm': 6.888992786407471, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.010182269848883152, 'loss_2': 0.0036773681640625, 'loss_3': -16.38791275024414, 'loss_4': -0.2379763424396515, 'epoch': 17.74}
{'loss': 0.0059, 'grad_norm': 5.7992072105407715, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.005640492774546146, 'loss_2': 0.00030517578125, 'loss_3': -16.531970977783203, 'loss_4': -0.2605811059474945, 'epoch': 17.75}
{'loss': 0.0233, 'grad_norm': 10.352551460266113, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.019153671339154243, 'loss_2': 0.0041046142578125, 'loss_3': -16.389436721801758, 'loss_4': -0.007420085370540619, 'epoch': 17.76}
{'loss': 0.0205, 'grad_norm': 13.080896377563477, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.01985100284218788, 'loss_2': 0.0006361007690429688, 'loss_3': -16.22632598876953, 'loss_4': -0.28484272956848145, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 13:35:43,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:43,894 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:38<36:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:51,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015500739216804504, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.775, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01269511878490448, 'eval_loss_2': 0.0028056204319000244, 'eval_loss_3': -18.23569107055664, 'eval_loss_4': -0.3947718143463135, 'epoch': 17.76}
{'loss': 0.0086, 'grad_norm': 4.751302242279053, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.007666368968784809, 'loss_2': 0.0009298324584960938, 'loss_3': -16.201330184936523, 'loss_4': 0.0932336300611496, 'epoch': 17.77}
{'loss': 0.0178, 'grad_norm': 6.8102192878723145, 'learning_rate': 1.225e-05, 'loss_1': 0.017479917034506798, 'loss_2': 0.0003437995910644531, 'loss_3': -16.46278953552246, 'loss_4': -0.21035468578338623, 'epoch': 17.77}
{'loss': 0.0104, 'grad_norm': 6.198310852050781, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.010286363773047924, 'loss_2': 7.712841033935547e-05, 'loss_3': -16.37245750427246, 'loss_4': -0.01198171079158783, 'epoch': 17.78}
{'loss': 0.0164, 'grad_norm': 7.105823516845703, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.009769250638782978, 'loss_2': 0.00659942626953125, 'loss_3': -16.40500259399414, 'loss_4': -0.5044569373130798, 'epoch': 17.78}
{'loss': 0.0307, 'grad_norm': 9.609902381896973, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.02172239124774933, 'loss_2': 0.009002685546875, 'loss_3': -16.457441329956055, 'loss_4': -0.21812818944454193, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 13:35:51,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:51,229 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:45<36:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:58,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01481628231704235, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.56, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012121346779167652, 'eval_loss_2': 0.002694934606552124, 'eval_loss_3': -18.209545135498047, 'eval_loss_4': -0.25021687150001526, 'epoch': 17.79}
{'loss': 0.0212, 'grad_norm': 12.939569473266602, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.021106867119669914, 'loss_2': 0.00010561943054199219, 'loss_3': -16.29529571533203, 'loss_4': -0.024984583258628845, 'epoch': 17.8}
{'loss': 0.0254, 'grad_norm': 12.027554512023926, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.022941142320632935, 'loss_2': 0.002414703369140625, 'loss_3': -16.57356071472168, 'loss_4': -0.3419490456581116, 'epoch': 17.8}
{'loss': 0.019, 'grad_norm': 6.8243842124938965, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.01651756465435028, 'loss_2': 0.00249481201171875, 'loss_3': -16.464128494262695, 'loss_4': 0.09494709968566895, 'epoch': 17.81}
{'loss': 0.0166, 'grad_norm': 5.806206703186035, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.011913290247321129, 'loss_2': 0.00472259521484375, 'loss_3': -16.423002243041992, 'loss_4': -0.19673621654510498, 'epoch': 17.81}
{'loss': 0.0134, 'grad_norm': 6.6302666664123535, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.008659093640744686, 'loss_2': 0.0047607421875, 'loss_3': -16.56329345703125, 'loss_4': -0.08157259225845337, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 13:35:58,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:58,569 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:52<36:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:05,912 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015248198062181473, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011891739442944527, 'eval_loss_2': 0.003356456756591797, 'eval_loss_3': -18.204849243164062, 'eval_loss_4': -0.19688984751701355, 'epoch': 17.82}
{'loss': 0.0076, 'grad_norm': 5.312303066253662, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.005908391438424587, 'loss_2': 0.001659393310546875, 'loss_3': -16.302797317504883, 'loss_4': 0.030680686235427856, 'epoch': 17.83}
{'loss': 0.009, 'grad_norm': 5.905810832977295, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.008155220188200474, 'loss_2': 0.0008172988891601562, 'loss_3': -16.413450241088867, 'loss_4': -0.5019614100456238, 'epoch': 17.83}
{'loss': 0.0122, 'grad_norm': 5.496972560882568, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.009055908769369125, 'loss_2': 0.003185272216796875, 'loss_3': -16.23008918762207, 'loss_4': 0.24703478813171387, 'epoch': 17.84}
{'loss': 0.0079, 'grad_norm': 4.767650604248047, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.006580271292477846, 'loss_2': 0.00136566162109375, 'loss_3': -16.38131332397461, 'loss_4': 0.039371661841869354, 'epoch': 17.84}
{'loss': 0.0173, 'grad_norm': 5.388812065124512, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.010471855290234089, 'loss_2': 0.006847381591796875, 'loss_3': -16.301189422607422, 'loss_4': -0.22817301750183105, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 13:36:05,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:05,912 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:16:00<36:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:13,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016655191779136658, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012992098927497864, 'eval_loss_2': 0.003663092851638794, 'eval_loss_3': -18.20760154724121, 'eval_loss_4': -0.09817271679639816, 'epoch': 17.85}
{'loss': 0.0141, 'grad_norm': 5.148960590362549, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.007840114645659924, 'loss_2': 0.006256103515625, 'loss_3': -16.295085906982422, 'loss_4': -0.10841776430606842, 'epoch': 17.85}
{'loss': 0.0081, 'grad_norm': 4.734848976135254, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.004146881401538849, 'loss_2': 0.00399017333984375, 'loss_3': -16.232580184936523, 'loss_4': 0.2634539008140564, 'epoch': 17.86}
{'loss': 0.0283, 'grad_norm': 7.645287036895752, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.021881256252527237, 'loss_2': 0.00637054443359375, 'loss_3': -16.32050323486328, 'loss_4': 0.1716414988040924, 'epoch': 17.87}
{'loss': 0.0113, 'grad_norm': 6.029173851013184, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.010197668336331844, 'loss_2': 0.00115203857421875, 'loss_3': -16.26968002319336, 'loss_4': 0.08029139041900635, 'epoch': 17.87}
{'loss': 0.0083, 'grad_norm': 4.213817119598389, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.00551987998187542, 'loss_2': 0.0028076171875, 'loss_3': -16.412582397460938, 'loss_4': 0.3006432056427002, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 13:36:13,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:13,249 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:07<35:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:20,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017793092876672745, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.895, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014545969665050507, 'eval_loss_2': 0.003247123211622238, 'eval_loss_3': -18.19140625, 'eval_loss_4': 0.14097096025943756, 'epoch': 17.88}
{'loss': 0.0235, 'grad_norm': 10.783496856689453, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.018631279468536377, 'loss_2': 0.0048370361328125, 'loss_3': -16.296695709228516, 'loss_4': 0.30160778760910034, 'epoch': 17.88}
{'loss': 0.0094, 'grad_norm': 4.855389595031738, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.005599826108664274, 'loss_2': 0.0038204193115234375, 'loss_3': -16.523408889770508, 'loss_4': 0.38691526651382446, 'epoch': 17.89}
{'loss': 0.0088, 'grad_norm': 4.584534645080566, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.006636337377130985, 'loss_2': 0.002193450927734375, 'loss_3': -16.49678611755371, 'loss_4': 0.34368419647216797, 'epoch': 17.9}
{'loss': 0.0117, 'grad_norm': 6.716102600097656, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.009999308735132217, 'loss_2': 0.0017299652099609375, 'loss_3': -16.35538101196289, 'loss_4': 0.7339301109313965, 'epoch': 17.9}
{'loss': 0.0237, 'grad_norm': 16.979990005493164, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.022697273641824722, 'loss_2': 0.00103759765625, 'loss_3': -16.3101749420166, 'loss_4': 0.25211969017982483, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 13:36:20,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:20,597 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:14<35:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:27,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018450040370225906, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.976, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.015054646879434586, 'eval_loss_2': 0.003395393490791321, 'eval_loss_3': -18.200206756591797, 'eval_loss_4': 0.21299542486667633, 'epoch': 17.91}
{'loss': 0.0191, 'grad_norm': 14.498130798339844, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.01503717340528965, 'loss_2': 0.00403594970703125, 'loss_3': -16.40764617919922, 'loss_4': -0.2697972059249878, 'epoch': 17.91}
{'loss': 0.0586, 'grad_norm': 12.616670608520508, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.05626078322529793, 'loss_2': 0.00238037109375, 'loss_3': -16.639142990112305, 'loss_4': 0.8986234664916992, 'epoch': 17.92}
{'loss': 0.0084, 'grad_norm': 5.478050231933594, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.007830235175788403, 'loss_2': 0.000553131103515625, 'loss_3': -16.361366271972656, 'loss_4': -0.12289756536483765, 'epoch': 17.92}
{'loss': 0.0077, 'grad_norm': 4.519279479980469, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.005990262143313885, 'loss_2': 0.0017414093017578125, 'loss_3': -16.620450973510742, 'loss_4': 0.5159445405006409, 'epoch': 17.93}
{'loss': 0.0087, 'grad_norm': 5.665414333343506, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.007981687784194946, 'loss_2': 0.0006771087646484375, 'loss_3': -16.227394104003906, 'loss_4': 0.26953279972076416, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 13:36:27,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:27,933 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:22<36:16,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:36:35,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019608810544013977, 'eval_runtime': 3.9979, 'eval_samples_per_second': 256.137, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.01604558527469635, 'eval_loss_2': 0.003563225269317627, 'eval_loss_3': -18.21880340576172, 'eval_loss_4': 0.19471730291843414, 'epoch': 17.94}
{'loss': 0.0367, 'grad_norm': 24.42499351501465, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.033769894391298294, 'loss_2': 0.00295257568359375, 'loss_3': -16.41375160217285, 'loss_4': 0.5234038233757019, 'epoch': 17.94}
{'loss': 0.0083, 'grad_norm': 5.154269218444824, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.004830020014196634, 'loss_2': 0.003498077392578125, 'loss_3': -16.36749839782715, 'loss_4': 0.516024112701416, 'epoch': 17.95}
{'loss': 0.01, 'grad_norm': 4.69334602355957, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.0070266094990074635, 'loss_2': 0.002979278564453125, 'loss_3': -16.192584991455078, 'loss_4': 0.4332605004310608, 'epoch': 17.95}
{'loss': 0.0108, 'grad_norm': 5.3007893562316895, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.006258242763578892, 'loss_2': 0.0045623779296875, 'loss_3': -16.465394973754883, 'loss_4': 0.43627023696899414, 'epoch': 17.96}
{'loss': 0.0185, 'grad_norm': 5.6461992263793945, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.011195143684744835, 'loss_2': 0.007354736328125, 'loss_3': -16.393753051757812, 'loss_4': 0.445867657661438, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 13:36:35,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:35,476 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:29<35:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:42,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020377185195684433, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.462, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015126611106097698, 'eval_loss_2': 0.00525057315826416, 'eval_loss_3': -18.2243709564209, 'eval_loss_4': 0.2703065574169159, 'epoch': 17.97}
{'loss': 0.0107, 'grad_norm': 6.262854099273682, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.008096050471067429, 'loss_2': 0.002597808837890625, 'loss_3': -16.45473861694336, 'loss_4': 0.48222848773002625, 'epoch': 17.97}
{'loss': 0.0366, 'grad_norm': 27.3824405670166, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.025979528203606606, 'loss_2': 0.0106048583984375, 'loss_3': -16.409711837768555, 'loss_4': 0.362617552280426, 'epoch': 17.98}
{'loss': 0.0105, 'grad_norm': 4.9893999099731445, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.00686904089525342, 'loss_2': 0.0036220550537109375, 'loss_3': -16.46424674987793, 'loss_4': 0.20442387461662292, 'epoch': 17.98}
{'loss': 0.021, 'grad_norm': 9.158618927001953, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.015055249445140362, 'loss_2': 0.005992889404296875, 'loss_3': -16.451000213623047, 'loss_4': 0.09466136246919632, 'epoch': 17.99}
{'loss': 0.0096, 'grad_norm': 5.943833351135254, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.008517170324921608, 'loss_2': 0.0011005401611328125, 'loss_3': -16.494672775268555, 'loss_4': 0.31529343128204346, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 13:36:42,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:42,807 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:36<34:56,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:36:49,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018825404345989227, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.689, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015246622264385223, 'eval_loss_2': 0.003578782081604004, 'eval_loss_3': -18.20025062561035, 'eval_loss_4': 0.18013958632946014, 'epoch': 17.99}
{'loss': 0.005, 'grad_norm': 6.232585906982422, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.003371437778696418, 'loss_2': 0.0016326904296875, 'loss_3': -16.383033752441406, 'loss_4': 0.5386819839477539, 'epoch': 18.0}
{'loss': 0.02, 'grad_norm': 8.12044620513916, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.018397098407149315, 'loss_2': 0.0015926361083984375, 'loss_3': -16.446224212646484, 'loss_4': 0.7962680459022522, 'epoch': 18.01}
{'loss': 0.0178, 'grad_norm': 5.901093482971191, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.012117746286094189, 'loss_2': 0.0056915283203125, 'loss_3': -16.282236099243164, 'loss_4': 0.3325442969799042, 'epoch': 18.01}
{'loss': 0.0098, 'grad_norm': 4.9564337730407715, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.0061527094803750515, 'loss_2': 0.003650665283203125, 'loss_3': -16.428762435913086, 'loss_4': 0.1902703195810318, 'epoch': 18.02}
{'loss': 0.0136, 'grad_norm': 5.498462677001953, 'learning_rate': 1.2e-05, 'loss_1': 0.007975734770298004, 'loss_2': 0.00566864013671875, 'loss_3': -16.369552612304688, 'loss_4': 0.3933185935020447, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 13:36:49,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:49,868 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:44<35:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:57,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018937598913908005, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014690589159727097, 'eval_loss_2': 0.004247009754180908, 'eval_loss_3': -18.208898544311523, 'eval_loss_4': -0.02409524843096733, 'epoch': 18.02}
{'loss': 0.0177, 'grad_norm': 10.152613639831543, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.01699749007821083, 'loss_2': 0.000682830810546875, 'loss_3': -16.35824966430664, 'loss_4': -0.3585778772830963, 'epoch': 18.03}
{'loss': 0.0159, 'grad_norm': 6.480840682983398, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.01092458888888359, 'loss_2': 0.00495147705078125, 'loss_3': -16.37670135498047, 'loss_4': 0.3631226420402527, 'epoch': 18.03}
{'loss': 0.0192, 'grad_norm': 5.621119976043701, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.00888853333890438, 'loss_2': 0.010345458984375, 'loss_3': -16.3306884765625, 'loss_4': 0.32691487669944763, 'epoch': 18.04}
{'loss': 0.0161, 'grad_norm': 6.0146894454956055, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.009458500891923904, 'loss_2': 0.006622314453125, 'loss_3': -16.435020446777344, 'loss_4': 0.3902171552181244, 'epoch': 18.05}
{'loss': 0.0096, 'grad_norm': 5.262147426605225, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.009010608308017254, 'loss_2': 0.0005412101745605469, 'loss_3': -16.357444763183594, 'loss_4': 0.05688934028148651, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 13:36:57,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:57,226 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:51<35:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:04,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01682332530617714, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.921, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01341965887695551, 'eval_loss_2': 0.0034036673605442047, 'eval_loss_3': -18.206871032714844, 'eval_loss_4': -0.042166948318481445, 'epoch': 18.05}
{'loss': 0.0075, 'grad_norm': 5.13556432723999, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.004440659657120705, 'loss_2': 0.003055572509765625, 'loss_3': -16.177278518676758, 'loss_4': 0.2863149046897888, 'epoch': 18.06}
{'loss': 0.0174, 'grad_norm': 5.520603656768799, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.009049949236214161, 'loss_2': 0.0083160400390625, 'loss_3': -16.27988052368164, 'loss_4': 0.11457328498363495, 'epoch': 18.06}
{'loss': 0.0088, 'grad_norm': 5.3631391525268555, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.008737312629818916, 'loss_2': 9.655952453613281e-05, 'loss_3': -16.492389678955078, 'loss_4': -0.09909874200820923, 'epoch': 18.07}
{'loss': 0.0211, 'grad_norm': 6.951330184936523, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.01719886250793934, 'loss_2': 0.00389862060546875, 'loss_3': -16.351823806762695, 'loss_4': -0.12166865170001984, 'epoch': 18.08}
{'loss': 0.0138, 'grad_norm': 8.863678932189941, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.01200136635452509, 'loss_2': 0.0017604827880859375, 'loss_3': -16.517433166503906, 'loss_4': 0.2408071756362915, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 13:37:04,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:04,583 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:58<35:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:11,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01646098867058754, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.509, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013148206286132336, 'eval_loss_2': 0.0033127814531326294, 'eval_loss_3': -18.221012115478516, 'eval_loss_4': -0.1739683747291565, 'epoch': 18.08}
{'loss': 0.0082, 'grad_norm': 5.324671745300293, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.007186161354184151, 'loss_2': 0.0010318756103515625, 'loss_3': -16.418315887451172, 'loss_4': -0.044881436973810196, 'epoch': 18.09}
{'loss': 0.012, 'grad_norm': 4.608698844909668, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.004976243246346712, 'loss_2': 0.0070343017578125, 'loss_3': -16.47336196899414, 'loss_4': -0.21656477451324463, 'epoch': 18.09}
{'loss': 0.0071, 'grad_norm': 5.422485828399658, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.005897602532058954, 'loss_2': 0.001224517822265625, 'loss_3': -16.34276580810547, 'loss_4': -0.3854330778121948, 'epoch': 18.1}
{'loss': 0.0057, 'grad_norm': 4.684351444244385, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.0041922759264707565, 'loss_2': 0.0014638900756835938, 'loss_3': -16.337902069091797, 'loss_4': 0.2772497236728668, 'epoch': 18.1}
{'loss': 0.0704, 'grad_norm': 12.751888275146484, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.06615713238716125, 'loss_2': 0.00421142578125, 'loss_3': -16.483184814453125, 'loss_4': 0.13666364550590515, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 13:37:11,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:11,932 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:17:06<35:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:19,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01763814128935337, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.175, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014530430547893047, 'eval_loss_2': 0.003107711672782898, 'eval_loss_3': -18.202123641967773, 'eval_loss_4': -0.4556092619895935, 'epoch': 18.11}
{'loss': 0.0173, 'grad_norm': 6.430996894836426, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.014813879504799843, 'loss_2': 0.0025081634521484375, 'loss_3': -16.404273986816406, 'loss_4': -0.014581874012947083, 'epoch': 18.12}
{'loss': 0.0184, 'grad_norm': 6.322744369506836, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.014329694211483002, 'loss_2': 0.0040435791015625, 'loss_3': -16.316791534423828, 'loss_4': -0.4355538785457611, 'epoch': 18.12}
{'loss': 0.0133, 'grad_norm': 5.994579315185547, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.010546990670263767, 'loss_2': 0.0027923583984375, 'loss_3': -16.40917205810547, 'loss_4': -0.6476731300354004, 'epoch': 18.13}
{'loss': 0.0077, 'grad_norm': 5.5351080894470215, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.007312615867704153, 'loss_2': 0.0003540515899658203, 'loss_3': -16.310373306274414, 'loss_4': -0.37246960401535034, 'epoch': 18.13}
{'loss': 0.0155, 'grad_norm': 5.513829708099365, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.0072874645702540874, 'loss_2': 0.00824737548828125, 'loss_3': -16.354572296142578, 'loss_4': -0.625381588935852, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 13:37:19,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:19,272 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:13<35:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:26,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018411148339509964, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015510861761868, 'eval_loss_2': 0.0029002875089645386, 'eval_loss_3': -18.203094482421875, 'eval_loss_4': -0.7422810792922974, 'epoch': 18.14}
{'loss': 0.0093, 'grad_norm': 4.416292667388916, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.004601350519806147, 'loss_2': 0.00469970703125, 'loss_3': -16.35329818725586, 'loss_4': -0.6271754503250122, 'epoch': 18.15}
{'loss': 0.0411, 'grad_norm': 30.22545051574707, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.036430589854717255, 'loss_2': 0.004627227783203125, 'loss_3': -16.333555221557617, 'loss_4': -0.6829870939254761, 'epoch': 18.15}
{'loss': 0.0183, 'grad_norm': 7.062150478363037, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.012895849533379078, 'loss_2': 0.0054168701171875, 'loss_3': -16.47586441040039, 'loss_4': -0.5910307765007019, 'epoch': 18.16}
{'loss': 0.0123, 'grad_norm': 4.425859451293945, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.00880042277276516, 'loss_2': 0.003467559814453125, 'loss_3': -16.399301528930664, 'loss_4': -0.4935011863708496, 'epoch': 18.16}
{'loss': 0.0228, 'grad_norm': 7.912994861602783, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.01770634762942791, 'loss_2': 0.005107879638671875, 'loss_3': -16.510835647583008, 'loss_4': -0.6533768177032471, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 13:37:26,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:26,621 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:21<35:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:33,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018895961344242096, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015772946178913116, 'eval_loss_2': 0.0031230151653289795, 'eval_loss_3': -18.208873748779297, 'eval_loss_4': -0.8544126749038696, 'epoch': 18.17}
{'loss': 0.0191, 'grad_norm': 8.515706062316895, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.01848747208714485, 'loss_2': 0.0005922317504882812, 'loss_3': -16.196014404296875, 'loss_4': -0.7306383848190308, 'epoch': 18.17}
{'loss': 0.0165, 'grad_norm': 8.877216339111328, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.011796722188591957, 'loss_2': 0.0046539306640625, 'loss_3': -16.423934936523438, 'loss_4': -0.4505552351474762, 'epoch': 18.18}
{'loss': 0.0101, 'grad_norm': 4.52480411529541, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.005779013503342867, 'loss_2': 0.0043182373046875, 'loss_3': -16.50123405456543, 'loss_4': -0.30453959107398987, 'epoch': 18.19}
{'loss': 0.0173, 'grad_norm': 7.6781463623046875, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.013375463895499706, 'loss_2': 0.003932952880859375, 'loss_3': -16.469680786132812, 'loss_4': -0.7679716944694519, 'epoch': 18.19}
{'loss': 0.012, 'grad_norm': 6.244858264923096, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.009591395035386086, 'loss_2': 0.0023975372314453125, 'loss_3': -16.674713134765625, 'loss_4': -0.6675028204917908, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 13:37:33,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:33,956 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:28<35:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:41,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018445055931806564, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015615281648933887, 'eval_loss_2': 0.0028297752141952515, 'eval_loss_3': -18.215070724487305, 'eval_loss_4': -0.8723247051239014, 'epoch': 18.2}
{'loss': 0.0131, 'grad_norm': 4.700688362121582, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.004322594963014126, 'loss_2': 0.008758544921875, 'loss_3': -16.29633331298828, 'loss_4': -0.10480256378650665, 'epoch': 18.2}
{'loss': 0.0079, 'grad_norm': 4.598489284515381, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.007323595229536295, 'loss_2': 0.00061798095703125, 'loss_3': -16.39137840270996, 'loss_4': -0.43004828691482544, 'epoch': 18.21}
{'loss': 0.013, 'grad_norm': 5.719980239868164, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.007732355035841465, 'loss_2': 0.0052490234375, 'loss_3': -16.42578887939453, 'loss_4': -1.141849160194397, 'epoch': 18.22}
{'loss': 0.0089, 'grad_norm': 4.464195251464844, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.006954235024750233, 'loss_2': 0.001979827880859375, 'loss_3': -16.532394409179688, 'loss_4': -0.4450663924217224, 'epoch': 18.22}
{'loss': 0.0209, 'grad_norm': 7.523426532745361, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.011491311714053154, 'loss_2': 0.00940704345703125, 'loss_3': -16.306102752685547, 'loss_4': -0.3988279104232788, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 13:37:41,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:41,309 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:35<34:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:48,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019376017153263092, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01630132831633091, 'eval_loss_2': 0.0030746906995773315, 'eval_loss_3': -18.21270751953125, 'eval_loss_4': -0.969270646572113, 'epoch': 18.23}
{'loss': 0.0131, 'grad_norm': 5.939177989959717, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.011826500296592712, 'loss_2': 0.0012559890747070312, 'loss_3': -16.478668212890625, 'loss_4': -0.727789044380188, 'epoch': 18.23}
{'loss': 0.0184, 'grad_norm': 8.808761596679688, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.015247809700667858, 'loss_2': 0.00318145751953125, 'loss_3': -16.349367141723633, 'loss_4': -0.4959743618965149, 'epoch': 18.24}
{'loss': 0.0151, 'grad_norm': 7.939292907714844, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.012177416123449802, 'loss_2': 0.002960205078125, 'loss_3': -16.467723846435547, 'loss_4': -0.8103309273719788, 'epoch': 18.24}
{'loss': 0.0192, 'grad_norm': 6.0286784172058105, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.012055695988237858, 'loss_2': 0.007110595703125, 'loss_3': -16.39539337158203, 'loss_4': -0.7001144289970398, 'epoch': 18.25}
{'loss': 0.0227, 'grad_norm': 9.114171981811523, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.01774885132908821, 'loss_2': 0.00498199462890625, 'loss_3': -16.540895462036133, 'loss_4': -0.3816891312599182, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 13:37:48,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:48,646 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:43<34:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:55,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0187595896422863, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015829404816031456, 'eval_loss_2': 0.002930186688899994, 'eval_loss_3': -18.234577178955078, 'eval_loss_4': -1.0799641609191895, 'epoch': 18.26}
{'loss': 0.0122, 'grad_norm': 5.040080547332764, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.004779634531587362, 'loss_2': 0.007396697998046875, 'loss_3': -16.46375846862793, 'loss_4': -0.6418401598930359, 'epoch': 18.26}
{'loss': 0.0159, 'grad_norm': 6.591405391693115, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.012733242474496365, 'loss_2': 0.0031414031982421875, 'loss_3': -16.369314193725586, 'loss_4': -1.386252522468567, 'epoch': 18.27}
{'loss': 0.0709, 'grad_norm': 7.418989181518555, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.06366068124771118, 'loss_2': 0.00720977783203125, 'loss_3': -16.50441551208496, 'loss_4': -0.6118581295013428, 'epoch': 18.27}
{'loss': 0.0137, 'grad_norm': 5.406447410583496, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.008095095865428448, 'loss_2': 0.005584716796875, 'loss_3': -16.527006149291992, 'loss_4': -0.5729615688323975, 'epoch': 18.28}
{'loss': 0.013, 'grad_norm': 5.000030040740967, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.006730395369231701, 'loss_2': 0.006267547607421875, 'loss_3': -16.50627899169922, 'loss_4': -0.8379861116409302, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 13:37:55,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:55,986 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:50<34:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:03,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018877435475587845, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.786, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015695203095674515, 'eval_loss_2': 0.00318223237991333, 'eval_loss_3': -18.238018035888672, 'eval_loss_4': -1.020580530166626, 'epoch': 18.28}
{'loss': 0.006, 'grad_norm': 4.892515659332275, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.004784026648849249, 'loss_2': 0.0011806488037109375, 'loss_3': -16.572643280029297, 'loss_4': -1.159159541130066, 'epoch': 18.29}
{'loss': 0.0103, 'grad_norm': 4.969731330871582, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.006350300740450621, 'loss_2': 0.003997802734375, 'loss_3': -16.4560546875, 'loss_4': -0.9002692699432373, 'epoch': 18.3}
{'loss': 0.0335, 'grad_norm': 14.955068588256836, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.025535989552736282, 'loss_2': 0.00797271728515625, 'loss_3': -16.409387588500977, 'loss_4': -0.9222052097320557, 'epoch': 18.3}
{'loss': 0.0137, 'grad_norm': 4.77437162399292, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.00604943698272109, 'loss_2': 0.0076141357421875, 'loss_3': -16.354951858520508, 'loss_4': -0.41233599185943604, 'epoch': 18.31}
{'loss': 0.01, 'grad_norm': 5.453189849853516, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.00826446432620287, 'loss_2': 0.0016918182373046875, 'loss_3': -16.381267547607422, 'loss_4': -0.7175897359848022, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 13:38:03,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:03,325 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:57<34:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:10,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019663948565721512, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.679, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015633149072527885, 'eval_loss_2': 0.004030801355838776, 'eval_loss_3': -18.248489379882812, 'eval_loss_4': -0.8520113229751587, 'epoch': 18.31}
{'loss': 0.0098, 'grad_norm': 4.671366214752197, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.007527078036218882, 'loss_2': 0.0022869110107421875, 'loss_3': -16.511764526367188, 'loss_4': -0.6738073825836182, 'epoch': 18.32}
{'loss': 0.0081, 'grad_norm': 5.329413414001465, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.007216349709779024, 'loss_2': 0.0009279251098632812, 'loss_3': -16.517671585083008, 'loss_4': -0.4062017798423767, 'epoch': 18.33}
{'loss': 0.0107, 'grad_norm': 5.455475330352783, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.01001961063593626, 'loss_2': 0.0006322860717773438, 'loss_3': -16.380598068237305, 'loss_4': -0.9340327382087708, 'epoch': 18.33}
{'loss': 0.0391, 'grad_norm': 20.56018829345703, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.038173943758010864, 'loss_2': 0.0008945465087890625, 'loss_3': -16.534404754638672, 'loss_4': -0.889854907989502, 'epoch': 18.34}
{'loss': 0.0094, 'grad_norm': 4.608259201049805, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.006248893216252327, 'loss_2': 0.003143310546875, 'loss_3': -16.542579650878906, 'loss_4': -0.6041176915168762, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 13:38:10,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:10,658 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:18:05<34:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:18,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019790824502706528, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.017129307612776756, 'eval_loss_2': 0.002661515027284622, 'eval_loss_3': -18.256439208984375, 'eval_loss_4': -0.6897802948951721, 'epoch': 18.34}
{'loss': 0.0123, 'grad_norm': 4.563976764678955, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.005348864942789078, 'loss_2': 0.006927490234375, 'loss_3': -16.45328712463379, 'loss_4': -0.7753220796585083, 'epoch': 18.35}
{'loss': 0.0116, 'grad_norm': 5.148963928222656, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.009236454963684082, 'loss_2': 0.0023345947265625, 'loss_3': -16.656145095825195, 'loss_4': -0.7780537605285645, 'epoch': 18.35}
{'loss': 0.0104, 'grad_norm': 4.536495208740234, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.003929197788238525, 'loss_2': 0.0064544677734375, 'loss_3': -16.313589096069336, 'loss_4': -0.6849719285964966, 'epoch': 18.36}
{'loss': 0.0205, 'grad_norm': 6.9670281410217285, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.016652775928378105, 'loss_2': 0.0038299560546875, 'loss_3': -16.389413833618164, 'loss_4': -0.7095507383346558, 'epoch': 18.37}
{'loss': 0.0165, 'grad_norm': 6.337186813354492, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.0144564900547266, 'loss_2': 0.0020904541015625, 'loss_3': -16.22486114501953, 'loss_4': -0.37521427869796753, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 13:38:18,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:18,004 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:12<34:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:25,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020746929571032524, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016986964270472527, 'eval_loss_2': 0.0037599653005599976, 'eval_loss_3': -18.260513305664062, 'eval_loss_4': -0.5489640235900879, 'epoch': 18.37}
{'loss': 0.0064, 'grad_norm': 5.327408790588379, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.0057656546123325825, 'loss_2': 0.0005879402160644531, 'loss_3': -16.447561264038086, 'loss_4': -0.5782070159912109, 'epoch': 18.38}
{'loss': 0.0089, 'grad_norm': 4.855342864990234, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.005754985846579075, 'loss_2': 0.003139495849609375, 'loss_3': -16.495948791503906, 'loss_4': -0.1666949838399887, 'epoch': 18.38}
{'loss': 0.0097, 'grad_norm': 5.032947063446045, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.005342571996152401, 'loss_2': 0.004383087158203125, 'loss_3': -16.459697723388672, 'loss_4': -0.4188712239265442, 'epoch': 18.39}
{'loss': 0.0121, 'grad_norm': 4.4701457023620605, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.007426214404404163, 'loss_2': 0.00470733642578125, 'loss_3': -16.448043823242188, 'loss_4': -0.2991817593574524, 'epoch': 18.4}
{'loss': 0.0144, 'grad_norm': 9.841960906982422, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.013245107606053352, 'loss_2': 0.0011310577392578125, 'loss_3': -16.285690307617188, 'loss_4': -0.23978865146636963, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 13:38:25,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:25,351 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:19<34:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:32,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0226142555475235, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01817546971142292, 'eval_loss_2': 0.0044387876987457275, 'eval_loss_3': -18.23813819885254, 'eval_loss_4': -0.2858525812625885, 'epoch': 18.4}
{'loss': 0.0068, 'grad_norm': 5.3232421875, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.005838449578732252, 'loss_2': 0.0009665489196777344, 'loss_3': -16.538991928100586, 'loss_4': -0.43675747513771057, 'epoch': 18.41}
{'loss': 0.0127, 'grad_norm': 5.866207122802734, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.012635249644517899, 'loss_2': 3.355741500854492e-05, 'loss_3': -16.427183151245117, 'loss_4': -0.3787555694580078, 'epoch': 18.41}
{'loss': 0.0233, 'grad_norm': 6.840354919433594, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.013901589438319206, 'loss_2': 0.009429931640625, 'loss_3': -16.33102035522461, 'loss_4': -0.34559082984924316, 'epoch': 18.42}
{'loss': 0.0073, 'grad_norm': 4.941771984100342, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.005852685309946537, 'loss_2': 0.0014286041259765625, 'loss_3': -16.571603775024414, 'loss_4': 0.16469523310661316, 'epoch': 18.42}
{'loss': 0.017, 'grad_norm': 13.026691436767578, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.015596929006278515, 'loss_2': 0.0014276504516601562, 'loss_3': -16.5146541595459, 'loss_4': 0.018390491604804993, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 13:38:32,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:32,688 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:27<34:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:40,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020962664857506752, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.368, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016842596232891083, 'eval_loss_2': 0.00412006676197052, 'eval_loss_3': -18.226396560668945, 'eval_loss_4': 0.02137903682887554, 'epoch': 18.43}
{'loss': 0.0148, 'grad_norm': 7.505865573883057, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.013265857473015785, 'loss_2': 0.0015840530395507812, 'loss_3': -16.371341705322266, 'loss_4': 0.20432616770267487, 'epoch': 18.44}
{'loss': 0.0336, 'grad_norm': 9.820212364196777, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.025586703792214394, 'loss_2': 0.00799560546875, 'loss_3': -16.327068328857422, 'loss_4': 0.13625726103782654, 'epoch': 18.44}
{'loss': 0.0132, 'grad_norm': 6.870121002197266, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.010043545626103878, 'loss_2': 0.00313568115234375, 'loss_3': -16.324161529541016, 'loss_4': -0.20464953780174255, 'epoch': 18.45}
{'loss': 0.0105, 'grad_norm': 5.382534503936768, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.009794902056455612, 'loss_2': 0.0007152557373046875, 'loss_3': -16.465253829956055, 'loss_4': 0.21258379518985748, 'epoch': 18.45}
{'loss': 0.0102, 'grad_norm': 4.978643417358398, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.007105961907655001, 'loss_2': 0.003108978271484375, 'loss_3': -16.42157554626465, 'loss_4': -0.030589289963245392, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 13:38:40,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:40,033 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:34<34:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:47,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021818064153194427, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.502, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.018643319606781006, 'eval_loss_2': 0.0031747445464134216, 'eval_loss_3': -18.207792282104492, 'eval_loss_4': 0.23876646161079407, 'epoch': 18.46}
{'loss': 0.0123, 'grad_norm': 5.189824104309082, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.009493852965533733, 'loss_2': 0.0028228759765625, 'loss_3': -16.35842514038086, 'loss_4': 0.16136963665485382, 'epoch': 18.47}
{'loss': 0.0082, 'grad_norm': 5.388697147369385, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.006769127212464809, 'loss_2': 0.001407623291015625, 'loss_3': -16.280118942260742, 'loss_4': 0.4674169421195984, 'epoch': 18.47}
{'loss': 0.0086, 'grad_norm': 5.258179664611816, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.007841303944587708, 'loss_2': 0.000728607177734375, 'loss_3': -16.518878936767578, 'loss_4': 0.4842227101325989, 'epoch': 18.48}
{'loss': 0.0148, 'grad_norm': 6.268813133239746, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.011081981472671032, 'loss_2': 0.00366973876953125, 'loss_3': -16.467979431152344, 'loss_4': 0.7609817981719971, 'epoch': 18.48}
{'loss': 0.0123, 'grad_norm': 4.53285026550293, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.008484558202326298, 'loss_2': 0.003864288330078125, 'loss_3': -16.26093864440918, 'loss_4': 0.3715754449367523, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 13:38:47,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:47,370 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:41<34:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:54,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021819625049829483, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017764689400792122, 'eval_loss_2': 0.004054933786392212, 'eval_loss_3': -18.219934463500977, 'eval_loss_4': 0.3993310034275055, 'epoch': 18.49}
{'loss': 0.0152, 'grad_norm': 6.617236137390137, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.013437860645353794, 'loss_2': 0.0017948150634765625, 'loss_3': -16.33205795288086, 'loss_4': 0.6091022491455078, 'epoch': 18.49}
{'loss': 0.0108, 'grad_norm': 5.376220226287842, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.010450328700244427, 'loss_2': 0.00038242340087890625, 'loss_3': -16.280364990234375, 'loss_4': 0.1307477056980133, 'epoch': 18.5}
{'loss': 0.0161, 'grad_norm': 7.559467315673828, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.016019077971577644, 'loss_2': 7.033348083496094e-05, 'loss_3': -16.366456985473633, 'loss_4': 0.2762879729270935, 'epoch': 18.51}
{'loss': 0.0163, 'grad_norm': 5.568704128265381, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.014622457325458527, 'loss_2': 0.0016880035400390625, 'loss_3': -16.23834800720215, 'loss_4': 0.564249575138092, 'epoch': 18.51}
{'loss': 0.0131, 'grad_norm': 5.039670944213867, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.0067831361666321754, 'loss_2': 0.00628662109375, 'loss_3': -16.36664581298828, 'loss_4': 0.7599954009056091, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 13:38:54,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:54,710 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:49<34:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:02,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02429451420903206, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016973277553915977, 'eval_loss_2': 0.0073212385177612305, 'eval_loss_3': -18.207332611083984, 'eval_loss_4': 0.42139843106269836, 'epoch': 18.52}
{'loss': 0.0166, 'grad_norm': 5.521740436553955, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.008173887617886066, 'loss_2': 0.0084381103515625, 'loss_3': -16.36594581604004, 'loss_4': 0.3248651623725891, 'epoch': 18.52}
{'loss': 0.0153, 'grad_norm': 5.1922993659973145, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.009614716283977032, 'loss_2': 0.005657196044921875, 'loss_3': -16.534814834594727, 'loss_4': -0.029787972569465637, 'epoch': 18.53}
{'loss': 0.0186, 'grad_norm': 5.38138484954834, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.008333512581884861, 'loss_2': 0.01023101806640625, 'loss_3': -16.495647430419922, 'loss_4': 0.5001814961433411, 'epoch': 18.53}
{'loss': 0.0309, 'grad_norm': 11.384801864624023, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.019491732120513916, 'loss_2': 0.0113983154296875, 'loss_3': -16.518978118896484, 'loss_4': 0.06512373685836792, 'epoch': 18.54}
{'loss': 0.0317, 'grad_norm': 18.870452880859375, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.025972241535782814, 'loss_2': 0.00572967529296875, 'loss_3': -16.273548126220703, 'loss_4': 0.1225544661283493, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 13:39:02,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:02,057 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:56<33:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:09,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021667229011654854, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016742248088121414, 'eval_loss_2': 0.004924982786178589, 'eval_loss_3': -18.16852569580078, 'eval_loss_4': 0.3713456392288208, 'epoch': 18.55}
{'loss': 0.017, 'grad_norm': 6.268544673919678, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.011118622496724129, 'loss_2': 0.00592041015625, 'loss_3': -16.339872360229492, 'loss_4': 0.4835250973701477, 'epoch': 18.55}
{'loss': 0.0186, 'grad_norm': 5.758853435516357, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.010024121962487698, 'loss_2': 0.008575439453125, 'loss_3': -16.409849166870117, 'loss_4': 0.476484477519989, 'epoch': 18.56}
{'loss': 0.019, 'grad_norm': 5.729471683502197, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.008541000075638294, 'loss_2': 0.0104522705078125, 'loss_3': -16.16881561279297, 'loss_4': 0.19572141766548157, 'epoch': 18.56}
{'loss': 0.006, 'grad_norm': 4.609348297119141, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.004850707948207855, 'loss_2': 0.001148223876953125, 'loss_3': -16.472394943237305, 'loss_4': 0.2781111001968384, 'epoch': 18.57}
{'loss': 0.0038, 'grad_norm': 4.513701915740967, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.0031298594549298286, 'loss_2': 0.0006237030029296875, 'loss_3': -16.588459014892578, 'loss_4': 0.6395691633224487, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 13:39:09,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:09,398 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:19:03<33:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:16,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019340479746460915, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.631, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01742100715637207, 'eval_loss_2': 0.0019194744527339935, 'eval_loss_3': -18.139575958251953, 'eval_loss_4': 0.327322781085968, 'epoch': 18.58}
{'loss': 0.0177, 'grad_norm': 8.801405906677246, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.01761385053396225, 'loss_2': 0.00010502338409423828, 'loss_3': -16.463729858398438, 'loss_4': 0.3804034888744354, 'epoch': 18.58}
{'loss': 0.021, 'grad_norm': 10.595903396606445, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.02067853882908821, 'loss_2': 0.00036334991455078125, 'loss_3': -16.039947509765625, 'loss_4': 0.17155656218528748, 'epoch': 18.59}
{'loss': 0.0145, 'grad_norm': 6.330750465393066, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.011101064272224903, 'loss_2': 0.003391265869140625, 'loss_3': -16.5737247467041, 'loss_4': 0.2106453776359558, 'epoch': 18.59}
{'loss': 0.0116, 'grad_norm': 5.691800117492676, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.007261771708726883, 'loss_2': 0.004291534423828125, 'loss_3': -16.357933044433594, 'loss_4': 0.2039760947227478, 'epoch': 18.6}
{'loss': 0.0158, 'grad_norm': 6.325394153594971, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.009009583853185177, 'loss_2': 0.00681304931640625, 'loss_3': -16.444595336914062, 'loss_4': 0.4875922203063965, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 13:39:16,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:16,733 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:11<33:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:24,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020979106426239014, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.659, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018524933606386185, 'eval_loss_2': 0.0024541765451431274, 'eval_loss_3': -18.14179229736328, 'eval_loss_4': 0.30436083674430847, 'epoch': 18.6}
{'loss': 0.0723, 'grad_norm': 17.910411834716797, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.07062496244907379, 'loss_2': 0.00164031982421875, 'loss_3': -16.4097957611084, 'loss_4': 0.44213688373565674, 'epoch': 18.61}
{'loss': 0.0088, 'grad_norm': 4.894791603088379, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.007677080109715462, 'loss_2': 0.0011501312255859375, 'loss_3': -16.274091720581055, 'loss_4': 0.19289681315422058, 'epoch': 18.62}
{'loss': 0.0264, 'grad_norm': 11.659213066101074, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.023780515417456627, 'loss_2': 0.002605438232421875, 'loss_3': -16.339536666870117, 'loss_4': 0.8427979946136475, 'epoch': 18.62}
{'loss': 0.0107, 'grad_norm': 4.976234436035156, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.006052883341908455, 'loss_2': 0.0046539306640625, 'loss_3': -16.350679397583008, 'loss_4': 0.18008214235305786, 'epoch': 18.63}
{'loss': 0.0232, 'grad_norm': 9.650206565856934, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.016609953716397285, 'loss_2': 0.00655364990234375, 'loss_3': -16.300682067871094, 'loss_4': -0.1750962734222412, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 13:39:24,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:24,071 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:18<33:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:31,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023517802357673645, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.019818512722849846, 'eval_loss_2': 0.00369928777217865, 'eval_loss_3': -18.143877029418945, 'eval_loss_4': 0.2899859547615051, 'epoch': 18.63}
{'loss': 0.0128, 'grad_norm': 5.689741611480713, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.010380236431956291, 'loss_2': 0.002452850341796875, 'loss_3': -16.142925262451172, 'loss_4': 0.2172272503376007, 'epoch': 18.64}
{'loss': 0.0071, 'grad_norm': 4.490645885467529, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.006025341805070639, 'loss_2': 0.001026153564453125, 'loss_3': -16.525236129760742, 'loss_4': 0.03971484303474426, 'epoch': 18.65}
{'loss': 0.0107, 'grad_norm': 5.213459014892578, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.010471020825207233, 'loss_2': 0.00027823448181152344, 'loss_3': -16.40436363220215, 'loss_4': -0.04100595414638519, 'epoch': 18.65}
{'loss': 0.0051, 'grad_norm': 4.780318260192871, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.004643858876079321, 'loss_2': 0.00049591064453125, 'loss_3': -16.549251556396484, 'loss_4': 0.1956070363521576, 'epoch': 18.66}
{'loss': 0.0099, 'grad_norm': 5.102553367614746, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.008687442168593407, 'loss_2': 0.00121307373046875, 'loss_3': -16.380157470703125, 'loss_4': -0.2766653597354889, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 13:39:31,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:31,408 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:25<33:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:38,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021462170407176018, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.078, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.018655050545930862, 'eval_loss_2': 0.002807117998600006, 'eval_loss_3': -18.150497436523438, 'eval_loss_4': 0.291930615901947, 'epoch': 18.66}
{'loss': 0.0103, 'grad_norm': 4.378709316253662, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.00636071152985096, 'loss_2': 0.0038909912109375, 'loss_3': -16.437782287597656, 'loss_4': 0.5250439047813416, 'epoch': 18.67}
{'loss': 0.0235, 'grad_norm': 8.833606719970703, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.018888123333454132, 'loss_2': 0.00460052490234375, 'loss_3': -16.526865005493164, 'loss_4': 0.2924395501613617, 'epoch': 18.67}
{'loss': 0.013, 'grad_norm': 4.645862102508545, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.004499298054724932, 'loss_2': 0.00847625732421875, 'loss_3': -16.47567367553711, 'loss_4': 0.03322590887546539, 'epoch': 18.68}
{'loss': 0.0181, 'grad_norm': 5.664963722229004, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.012093381024897099, 'loss_2': 0.0059661865234375, 'loss_3': -16.598365783691406, 'loss_4': 0.13237492740154266, 'epoch': 18.69}
{'loss': 0.0078, 'grad_norm': 4.60585880279541, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.006393262185156345, 'loss_2': 0.001399993896484375, 'loss_3': -16.29313850402832, 'loss_4': 0.6376844048500061, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 13:39:38,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:38,756 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:33<33:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:46,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01960352435708046, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.508, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016876796260476112, 'eval_loss_2': 0.0027267299592494965, 'eval_loss_3': -18.149208068847656, 'eval_loss_4': 0.2319459617137909, 'epoch': 18.69}
{'loss': 0.005, 'grad_norm': 4.862119674682617, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.004851676989346743, 'loss_2': 0.00015103816986083984, 'loss_3': -16.424591064453125, 'loss_4': 0.3736014664173126, 'epoch': 18.7}
{'loss': 0.0094, 'grad_norm': 4.732361316680908, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.008464907296001911, 'loss_2': 0.000972747802734375, 'loss_3': -16.42558479309082, 'loss_4': 0.3666226863861084, 'epoch': 18.7}
{'loss': 0.0081, 'grad_norm': 4.5499982833862305, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.004406861029565334, 'loss_2': 0.00370025634765625, 'loss_3': -16.132970809936523, 'loss_4': 0.1835031658411026, 'epoch': 18.71}
{'loss': 0.0191, 'grad_norm': 9.693666458129883, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.01689949631690979, 'loss_2': 0.00223541259765625, 'loss_3': -16.29290771484375, 'loss_4': 0.22823621332645416, 'epoch': 18.72}
{'loss': 0.0146, 'grad_norm': 5.624085426330566, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.00710730766877532, 'loss_2': 0.00753021240234375, 'loss_3': -16.369518280029297, 'loss_4': 0.2757408618927002, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 13:39:46,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:46,095 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:40<33:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:53,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018146352842450142, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.278, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015880607068538666, 'eval_loss_2': 0.002265743911266327, 'eval_loss_3': -18.164878845214844, 'eval_loss_4': 0.17833760380744934, 'epoch': 18.72}
{'loss': 0.0183, 'grad_norm': 5.079846382141113, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.005797518417239189, 'loss_2': 0.01251220703125, 'loss_3': -16.592180252075195, 'loss_4': 0.0975523591041565, 'epoch': 18.73}
{'loss': 0.0189, 'grad_norm': 13.354660987854004, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.01881244033575058, 'loss_2': 8.183717727661133e-05, 'loss_3': -16.341636657714844, 'loss_4': -0.09015491604804993, 'epoch': 18.73}
{'loss': 0.0101, 'grad_norm': 4.937567234039307, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.006714077666401863, 'loss_2': 0.0034160614013671875, 'loss_3': -16.278499603271484, 'loss_4': -0.07011053711175919, 'epoch': 18.74}
{'loss': 0.0196, 'grad_norm': 8.980985641479492, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.01583985425531864, 'loss_2': 0.0037689208984375, 'loss_3': -16.235767364501953, 'loss_4': 0.19291983544826508, 'epoch': 18.74}
{'loss': 0.0102, 'grad_norm': 4.688738822937012, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.003987932112067938, 'loss_2': 0.00621795654296875, 'loss_3': -16.541255950927734, 'loss_4': -0.0243338942527771, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 13:39:53,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:53,437 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:47<33:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:00,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018007775768637657, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016117585822939873, 'eval_loss_2': 0.0018901899456977844, 'eval_loss_3': -18.175212860107422, 'eval_loss_4': 0.1772979497909546, 'epoch': 18.75}
{'loss': 0.0052, 'grad_norm': 4.582330226898193, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.0036043182481080294, 'loss_2': 0.0016298294067382812, 'loss_3': -16.480712890625, 'loss_4': 0.09354065358638763, 'epoch': 18.76}
{'loss': 0.011, 'grad_norm': 5.220014572143555, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.010079652070999146, 'loss_2': 0.0009365081787109375, 'loss_3': -16.354860305786133, 'loss_4': 0.006250053644180298, 'epoch': 18.76}
{'loss': 0.0041, 'grad_norm': 4.335439682006836, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.0036359201185405254, 'loss_2': 0.000507354736328125, 'loss_3': -16.44297981262207, 'loss_4': -0.05518176034092903, 'epoch': 18.77}
{'loss': 0.0273, 'grad_norm': 14.094971656799316, 'learning_rate': 1.125e-05, 'loss_1': 0.02636975422501564, 'loss_2': 0.0009069442749023438, 'loss_3': -16.2465877532959, 'loss_4': 0.14524586498737335, 'epoch': 18.77}
{'loss': 0.0122, 'grad_norm': 5.91339635848999, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.008812859654426575, 'loss_2': 0.00334930419921875, 'loss_3': -16.292680740356445, 'loss_4': 0.24164849519729614, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 13:40:00,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:00,772 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:55<33:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:08,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019999375566840172, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.508, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017261793836951256, 'eval_loss_2': 0.002737581729888916, 'eval_loss_3': -18.181079864501953, 'eval_loss_4': 0.2245863378047943, 'epoch': 18.78}
{'loss': 0.0137, 'grad_norm': 6.649343490600586, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.012014375068247318, 'loss_2': 0.001659393310546875, 'loss_3': -16.295934677124023, 'loss_4': 0.07929692417383194, 'epoch': 18.78}
{'loss': 0.0117, 'grad_norm': 5.642519950866699, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.009171594865620136, 'loss_2': 0.0025157928466796875, 'loss_3': -16.43683624267578, 'loss_4': -0.004855446517467499, 'epoch': 18.79}
{'loss': 0.0081, 'grad_norm': 4.583726406097412, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.006087370216846466, 'loss_2': 0.00200653076171875, 'loss_3': -16.101268768310547, 'loss_4': 0.6036391258239746, 'epoch': 18.8}
{'loss': 0.0077, 'grad_norm': 4.998972415924072, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.00740142073482275, 'loss_2': 0.0003139972686767578, 'loss_3': -16.488853454589844, 'loss_4': 0.3653572201728821, 'epoch': 18.8}
{'loss': 0.0116, 'grad_norm': 4.530445098876953, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.010600196197628975, 'loss_2': 0.0009641647338867188, 'loss_3': -16.152250289916992, 'loss_4': 0.09989970922470093, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 13:40:08,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:08,109 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:20:02<33:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:15,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01898847334086895, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.929, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01625622808933258, 'eval_loss_2': 0.00273224338889122, 'eval_loss_3': -18.210420608520508, 'eval_loss_4': 0.321231484413147, 'epoch': 18.81}
{'loss': 0.0071, 'grad_norm': 4.553478717803955, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.006104337051510811, 'loss_2': 0.0009613037109375, 'loss_3': -16.50727081298828, 'loss_4': 0.9001253843307495, 'epoch': 18.81}
{'loss': 0.0087, 'grad_norm': 5.522290229797363, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.008071650750935078, 'loss_2': 0.0006780624389648438, 'loss_3': -16.396841049194336, 'loss_4': 0.4920375645160675, 'epoch': 18.82}
{'loss': 0.0195, 'grad_norm': 9.626150131225586, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.01697077602148056, 'loss_2': 0.00254058837890625, 'loss_3': -16.424175262451172, 'loss_4': 0.5161866545677185, 'epoch': 18.83}
{'loss': 0.0088, 'grad_norm': 5.324160575866699, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.007125538308173418, 'loss_2': 0.0016965866088867188, 'loss_3': -16.263782501220703, 'loss_4': 0.7795494794845581, 'epoch': 18.83}
{'loss': 0.0094, 'grad_norm': 4.15511417388916, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.004759239964187145, 'loss_2': 0.004669189453125, 'loss_3': -16.303997039794922, 'loss_4': 0.4132976531982422, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 13:40:15,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:15,442 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:09<33:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:22,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017490539699792862, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.897, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015100125223398209, 'eval_loss_2': 0.0023904144763946533, 'eval_loss_3': -18.218660354614258, 'eval_loss_4': 0.25504064559936523, 'epoch': 18.84}
{'loss': 0.0079, 'grad_norm': 5.205036163330078, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.007546952925622463, 'loss_2': 0.00035858154296875, 'loss_3': -16.24416160583496, 'loss_4': 0.20106223225593567, 'epoch': 18.84}
{'loss': 0.0098, 'grad_norm': 5.0652337074279785, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.008240731433033943, 'loss_2': 0.001522064208984375, 'loss_3': -16.45892333984375, 'loss_4': 0.35025912523269653, 'epoch': 18.85}
{'loss': 0.0107, 'grad_norm': 4.370281219482422, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.00886986218392849, 'loss_2': 0.0018157958984375, 'loss_3': -16.447921752929688, 'loss_4': 0.15221835672855377, 'epoch': 18.85}
{'loss': 0.0174, 'grad_norm': 8.766798973083496, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.016657410189509392, 'loss_2': 0.0007429122924804688, 'loss_3': -16.434646606445312, 'loss_4': 0.2740371823310852, 'epoch': 18.86}
{'loss': 0.0125, 'grad_norm': 4.968565940856934, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.0067688580602407455, 'loss_2': 0.005748748779296875, 'loss_3': -16.41168785095215, 'loss_4': 0.48096996545791626, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 13:40:22,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:22,789 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:17<32:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:30,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016961243003606796, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.593, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01443534530699253, 'eval_loss_2': 0.0025258995592594147, 'eval_loss_3': -18.252782821655273, 'eval_loss_4': 0.29018479585647583, 'epoch': 18.87}
{'loss': 0.0121, 'grad_norm': 5.214293003082275, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.00854614470154047, 'loss_2': 0.00359344482421875, 'loss_3': -16.540233612060547, 'loss_4': 0.3596404790878296, 'epoch': 18.87}
{'loss': 0.0193, 'grad_norm': 8.9124174118042, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.013058197684586048, 'loss_2': 0.006206512451171875, 'loss_3': -16.376619338989258, 'loss_4': 0.3606909513473511, 'epoch': 18.88}
{'loss': 0.0105, 'grad_norm': 5.768924713134766, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.008213439024984837, 'loss_2': 0.002277374267578125, 'loss_3': -16.486614227294922, 'loss_4': 0.38334140181541443, 'epoch': 18.88}
{'loss': 0.0062, 'grad_norm': 4.508280277252197, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.004471440799534321, 'loss_2': 0.00174713134765625, 'loss_3': -16.47319221496582, 'loss_4': 0.3697252869606018, 'epoch': 18.89}
{'loss': 0.0142, 'grad_norm': 8.444206237792969, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.012609538622200489, 'loss_2': 0.001598358154296875, 'loss_3': -16.402116775512695, 'loss_4': 0.4148862063884735, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 13:40:30,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:30,122 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:24<32:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:37,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0163002610206604, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013762354850769043, 'eval_loss_2': 0.0025379061698913574, 'eval_loss_3': -18.27935028076172, 'eval_loss_4': 0.31495681405067444, 'epoch': 18.9}
{'loss': 0.0148, 'grad_norm': 6.0876641273498535, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.012186165899038315, 'loss_2': 0.002628326416015625, 'loss_3': -16.49261474609375, 'loss_4': 0.7011845111846924, 'epoch': 18.9}
{'loss': 0.0105, 'grad_norm': 6.362809658050537, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.009014044888317585, 'loss_2': 0.0014562606811523438, 'loss_3': -16.57057762145996, 'loss_4': 0.24702847003936768, 'epoch': 18.91}
{'loss': 0.0099, 'grad_norm': 4.648989677429199, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.0058565628714859486, 'loss_2': 0.00408935546875, 'loss_3': -16.364463806152344, 'loss_4': 0.5295119881629944, 'epoch': 18.91}
{'loss': 0.0239, 'grad_norm': 9.009966850280762, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.017943037673830986, 'loss_2': 0.0059814453125, 'loss_3': -16.536956787109375, 'loss_4': 0.40626633167266846, 'epoch': 18.92}
{'loss': 0.0134, 'grad_norm': 5.444992542266846, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.006956413853913546, 'loss_2': 0.006465911865234375, 'loss_3': -16.39847183227539, 'loss_4': 0.6456774473190308, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 13:40:37,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:37,461 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:31<32:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:44,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014141984283924103, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011888927780091763, 'eval_loss_2': 0.0022530555725097656, 'eval_loss_3': -18.282756805419922, 'eval_loss_4': 0.3527512848377228, 'epoch': 18.92}
{'loss': 0.0064, 'grad_norm': 4.921584606170654, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.0062306844629347324, 'loss_2': 0.0001919269561767578, 'loss_3': -16.3975772857666, 'loss_4': 0.361062228679657, 'epoch': 18.93}
{'loss': 0.0334, 'grad_norm': 14.602520942687988, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.024781597778201103, 'loss_2': 0.008636474609375, 'loss_3': -16.553531646728516, 'loss_4': 0.6731089353561401, 'epoch': 18.94}
{'loss': 0.0147, 'grad_norm': 9.902305603027344, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.014381015673279762, 'loss_2': 0.0003066062927246094, 'loss_3': -16.368728637695312, 'loss_4': 0.6538730263710022, 'epoch': 18.94}
{'loss': 0.011, 'grad_norm': 5.4614434242248535, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.009983525611460209, 'loss_2': 0.0009946823120117188, 'loss_3': -16.371482849121094, 'loss_4': -0.027646496891975403, 'epoch': 18.95}
{'loss': 0.0086, 'grad_norm': 4.738099098205566, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.00754457525908947, 'loss_2': 0.0010976791381835938, 'loss_3': -16.53950309753418, 'loss_4': 0.5258727669715881, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 13:40:44,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:44,805 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:39<32:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:52,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015797676518559456, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012786746956408024, 'eval_loss_2': 0.0030109286308288574, 'eval_loss_3': -18.296646118164062, 'eval_loss_4': 0.17202575504779816, 'epoch': 18.95}
{'loss': 0.0089, 'grad_norm': 5.3909478187561035, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.008617435581982136, 'loss_2': 0.00032901763916015625, 'loss_3': -16.554981231689453, 'loss_4': 0.3536217212677002, 'epoch': 18.96}
{'loss': 0.0265, 'grad_norm': 11.023247718811035, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.021772097796201706, 'loss_2': 0.00476837158203125, 'loss_3': -16.384735107421875, 'loss_4': 0.19434672594070435, 'epoch': 18.97}
{'loss': 0.0127, 'grad_norm': 4.697873115539551, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.005411519203335047, 'loss_2': 0.00724029541015625, 'loss_3': -16.530611038208008, 'loss_4': 0.6188566088676453, 'epoch': 18.97}
{'loss': 0.0116, 'grad_norm': 5.205488681793213, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.009969672188162804, 'loss_2': 0.0016431808471679688, 'loss_3': -16.542142868041992, 'loss_4': 0.3211504817008972, 'epoch': 18.98}
{'loss': 0.018, 'grad_norm': 7.300034046173096, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.014389670453965664, 'loss_2': 0.0036220550537109375, 'loss_3': -16.508731842041016, 'loss_4': 0.14803019165992737, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 13:40:52,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:52,156 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:46<31:21,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 13:40:59,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017259564250707626, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014047859236598015, 'eval_loss_2': 0.0032117068767547607, 'eval_loss_3': -18.30192756652832, 'eval_loss_4': 0.016739871352910995, 'epoch': 18.98}
{'loss': 0.0095, 'grad_norm': 4.987674236297607, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.009308249689638615, 'loss_2': 0.00022912025451660156, 'loss_3': -16.669818878173828, 'loss_4': 0.35205867886543274, 'epoch': 18.99}
{'loss': 0.0221, 'grad_norm': 6.778895854949951, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.013904457911849022, 'loss_2': 0.008209228515625, 'loss_3': -16.560985565185547, 'loss_4': 0.3371204435825348, 'epoch': 18.99}
{'loss': 0.0243, 'grad_norm': 10.290336608886719, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.020073046907782555, 'loss_2': 0.00423431396484375, 'loss_3': -16.349885940551758, 'loss_4': -0.004177486058324575, 'epoch': 19.0}
{'loss': 0.0089, 'grad_norm': 5.862775802612305, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.007291407324373722, 'loss_2': 0.001644134521484375, 'loss_3': -16.656105041503906, 'loss_4': 0.17203256487846375, 'epoch': 19.01}
{'loss': 0.0629, 'grad_norm': 11.85102653503418, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.05856458470225334, 'loss_2': 0.00429534912109375, 'loss_3': -16.604238510131836, 'loss_4': 0.4475107192993164, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 13:40:59,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:59,192 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:53<32:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:06,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01649678871035576, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013133954256772995, 'eval_loss_2': 0.0033628344535827637, 'eval_loss_3': -18.307126998901367, 'eval_loss_4': -0.027935106307268143, 'epoch': 19.01}
{'loss': 0.0116, 'grad_norm': 4.8137898445129395, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.008795810863375664, 'loss_2': 0.002834320068359375, 'loss_3': -16.47736358642578, 'loss_4': 0.22670702636241913, 'epoch': 19.02}
{'loss': 0.0126, 'grad_norm': 6.645295143127441, 'learning_rate': 1.1e-05, 'loss_1': 0.008310377597808838, 'loss_2': 0.00426483154296875, 'loss_3': -16.539817810058594, 'loss_4': 0.4652698338031769, 'epoch': 19.02}
{'loss': 0.0059, 'grad_norm': 5.309342861175537, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.005630099680274725, 'loss_2': 0.0002315044403076172, 'loss_3': -16.56463623046875, 'loss_4': 0.5713918209075928, 'epoch': 19.03}
{'loss': 0.0115, 'grad_norm': 4.993188381195068, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.006460104137659073, 'loss_2': 0.005046844482421875, 'loss_3': -16.498313903808594, 'loss_4': 0.30825039744377136, 'epoch': 19.03}
{'loss': 0.0085, 'grad_norm': 4.613120079040527, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.005815694108605385, 'loss_2': 0.0027008056640625, 'loss_3': -16.642192840576172, 'loss_4': 0.1866186559200287, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 13:41:06,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:06,536 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:21:00<32:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:13,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015647340565919876, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013280424289405346, 'eval_loss_2': 0.0023669153451919556, 'eval_loss_3': -18.290922164916992, 'eval_loss_4': 0.01585281640291214, 'epoch': 19.04}
{'loss': 0.0078, 'grad_norm': 4.999480247497559, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.004708780441433191, 'loss_2': 0.0030841827392578125, 'loss_3': -16.60440444946289, 'loss_4': 0.3350602984428406, 'epoch': 19.05}
{'loss': 0.0105, 'grad_norm': 4.915224075317383, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.005924906115978956, 'loss_2': 0.004611968994140625, 'loss_3': -16.46662712097168, 'loss_4': 0.41269242763519287, 'epoch': 19.05}
{'loss': 0.0607, 'grad_norm': 12.147469520568848, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.055909112095832825, 'loss_2': 0.004756927490234375, 'loss_3': -16.37429428100586, 'loss_4': 0.19285748898983002, 'epoch': 19.06}
{'loss': 0.0111, 'grad_norm': 5.050924301147461, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.008466717787086964, 'loss_2': 0.002655029296875, 'loss_3': -16.472204208374023, 'loss_4': 0.5007985830307007, 'epoch': 19.06}
{'loss': 0.0092, 'grad_norm': 4.915105819702148, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.006399695295840502, 'loss_2': 0.0028400421142578125, 'loss_3': -16.40629768371582, 'loss_4': -0.038861215114593506, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 13:41:13,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:13,869 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:08<32:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:21,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015401069074869156, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013425436802208424, 'eval_loss_2': 0.001975633203983307, 'eval_loss_3': -18.289302825927734, 'eval_loss_4': -0.06068064644932747, 'epoch': 19.07}
{'loss': 0.0252, 'grad_norm': 5.715363502502441, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.015234766528010368, 'loss_2': 0.009918212890625, 'loss_3': -16.75172233581543, 'loss_4': 0.541205883026123, 'epoch': 19.08}
{'loss': 0.0077, 'grad_norm': 4.5296854972839355, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.004728750325739384, 'loss_2': 0.0029392242431640625, 'loss_3': -16.45609474182129, 'loss_4': 0.28941404819488525, 'epoch': 19.08}
{'loss': 0.0171, 'grad_norm': 5.932213306427002, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.012552754022181034, 'loss_2': 0.00457763671875, 'loss_3': -16.401092529296875, 'loss_4': 0.040449440479278564, 'epoch': 19.09}
{'loss': 0.0101, 'grad_norm': 5.396742820739746, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.007884250022470951, 'loss_2': 0.002223968505859375, 'loss_3': -16.47183609008789, 'loss_4': -0.09858682751655579, 'epoch': 19.09}
{'loss': 0.0132, 'grad_norm': 4.733094215393066, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.009554645977914333, 'loss_2': 0.003604888916015625, 'loss_3': -16.28730010986328, 'loss_4': -0.02486063539981842, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 13:41:21,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:21,215 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:15<32:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:28,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016405265778303146, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01381122600287199, 'eval_loss_2': 0.0025940388441085815, 'eval_loss_3': -18.279495239257812, 'eval_loss_4': 0.0054494459182024, 'epoch': 19.1}
{'loss': 0.0086, 'grad_norm': 4.980265140533447, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.005509379785507917, 'loss_2': 0.003082275390625, 'loss_3': -16.442359924316406, 'loss_4': -0.0013861693441867828, 'epoch': 19.1}
{'loss': 0.0143, 'grad_norm': 6.350331783294678, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.010240299627184868, 'loss_2': 0.0041046142578125, 'loss_3': -16.547264099121094, 'loss_4': 0.4906371533870697, 'epoch': 19.11}
{'loss': 0.0181, 'grad_norm': 8.479825019836426, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.01730962283909321, 'loss_2': 0.000820159912109375, 'loss_3': -16.471242904663086, 'loss_4': 0.05567239224910736, 'epoch': 19.12}
{'loss': 0.0105, 'grad_norm': 6.179271697998047, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.009129278361797333, 'loss_2': 0.00139617919921875, 'loss_3': -16.442405700683594, 'loss_4': 0.15091711282730103, 'epoch': 19.12}
{'loss': 0.0153, 'grad_norm': 7.974836826324463, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.012686435133218765, 'loss_2': 0.002582550048828125, 'loss_3': -16.48403549194336, 'loss_4': 0.49686694145202637, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 13:41:28,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:28,555 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:22<32:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:35,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01506628654897213, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.635, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012413566932082176, 'eval_loss_2': 0.0026527196168899536, 'eval_loss_3': -18.286861419677734, 'eval_loss_4': 0.11768916994333267, 'epoch': 19.13}
{'loss': 0.0128, 'grad_norm': 6.924222946166992, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.009793370962142944, 'loss_2': 0.003017425537109375, 'loss_3': -16.390995025634766, 'loss_4': 0.2593538165092468, 'epoch': 19.13}
{'loss': 0.0098, 'grad_norm': 5.176548957824707, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.009767206385731697, 'loss_2': 1.0728836059570312e-05, 'loss_3': -16.55143165588379, 'loss_4': 0.5020967721939087, 'epoch': 19.14}
{'loss': 0.0124, 'grad_norm': 8.838154792785645, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.011774390004575253, 'loss_2': 0.0006308555603027344, 'loss_3': -16.523006439208984, 'loss_4': 0.3434990644454956, 'epoch': 19.15}
{'loss': 0.0135, 'grad_norm': 6.273433208465576, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.009007186628878117, 'loss_2': 0.004497528076171875, 'loss_3': -16.635475158691406, 'loss_4': 0.30404090881347656, 'epoch': 19.15}
{'loss': 0.0114, 'grad_norm': 5.474621772766113, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.011389510706067085, 'loss_2': 1.2755393981933594e-05, 'loss_3': -16.553043365478516, 'loss_4': -0.03617553412914276, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 13:41:35,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:35,895 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:30<32:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:43,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014631006866693497, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012391826137900352, 'eval_loss_2': 0.0022391825914382935, 'eval_loss_3': -18.292280197143555, 'eval_loss_4': 0.13956280052661896, 'epoch': 19.16}
{'loss': 0.0144, 'grad_norm': 5.951074600219727, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.011504576541483402, 'loss_2': 0.0029087066650390625, 'loss_3': -16.402023315429688, 'loss_4': 0.5610067248344421, 'epoch': 19.16}
{'loss': 0.0362, 'grad_norm': 9.581711769104004, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.024386873468756676, 'loss_2': 0.0117950439453125, 'loss_3': -16.488128662109375, 'loss_4': 0.6067522168159485, 'epoch': 19.17}
{'loss': 0.0314, 'grad_norm': 13.52800464630127, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.023115292191505432, 'loss_2': 0.0082550048828125, 'loss_3': -16.461803436279297, 'loss_4': 0.3526524007320404, 'epoch': 19.17}
{'loss': 0.0139, 'grad_norm': 5.7343244552612305, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.012301514856517315, 'loss_2': 0.0015773773193359375, 'loss_3': -16.66253662109375, 'loss_4': 0.41288405656814575, 'epoch': 19.18}
{'loss': 0.0129, 'grad_norm': 5.121303081512451, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.009914525784552097, 'loss_2': 0.003032684326171875, 'loss_3': -16.450212478637695, 'loss_4': 0.04745732620358467, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 13:41:43,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:43,235 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:37<32:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:50,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014439646154642105, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01184302568435669, 'eval_loss_2': 0.0025966204702854156, 'eval_loss_3': -18.288740158081055, 'eval_loss_4': 0.12056073546409607, 'epoch': 19.19}
{'loss': 0.0116, 'grad_norm': 4.911221981048584, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.006689976900815964, 'loss_2': 0.004955291748046875, 'loss_3': -16.46173667907715, 'loss_4': 0.37865570187568665, 'epoch': 19.19}
{'loss': 0.0112, 'grad_norm': 4.942283630371094, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.00672916229814291, 'loss_2': 0.0045166015625, 'loss_3': -16.667232513427734, 'loss_4': 0.7197964787483215, 'epoch': 19.2}
{'loss': 0.0086, 'grad_norm': 5.1738386154174805, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.007523466367274523, 'loss_2': 0.0010814666748046875, 'loss_3': -16.349449157714844, 'loss_4': 0.5802017450332642, 'epoch': 19.2}
{'loss': 0.0279, 'grad_norm': 11.040750503540039, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.021593591198325157, 'loss_2': 0.00634765625, 'loss_3': -16.358383178710938, 'loss_4': 0.30821382999420166, 'epoch': 19.21}
{'loss': 0.0266, 'grad_norm': 7.745663642883301, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.022724885493516922, 'loss_2': 0.003917694091796875, 'loss_3': -16.529104232788086, 'loss_4': 0.14058175683021545, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 13:41:50,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:50,566 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:44<31:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:57,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013691163621842861, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.645, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010439760982990265, 'eval_loss_2': 0.003251403570175171, 'eval_loss_3': -18.28217124938965, 'eval_loss_4': 0.18838690221309662, 'epoch': 19.22}
{'loss': 0.0086, 'grad_norm': 4.836043834686279, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.005585421808063984, 'loss_2': 0.0030498504638671875, 'loss_3': -16.38515853881836, 'loss_4': 0.5061097145080566, 'epoch': 19.22}
{'loss': 0.006, 'grad_norm': 4.3928399085998535, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.005105024669319391, 'loss_2': 0.0008859634399414062, 'loss_3': -16.422489166259766, 'loss_4': 0.45346370339393616, 'epoch': 19.23}
{'loss': 0.0126, 'grad_norm': 5.145737171173096, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.007146104238927364, 'loss_2': 0.00550079345703125, 'loss_3': -16.34081268310547, 'loss_4': 0.04516477882862091, 'epoch': 19.23}
{'loss': 0.015, 'grad_norm': 4.70343542098999, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.0046270922757685184, 'loss_2': 0.0103912353515625, 'loss_3': -16.44634246826172, 'loss_4': 0.1873643547296524, 'epoch': 19.24}
{'loss': 0.0111, 'grad_norm': 5.6174516677856445, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.00882369838654995, 'loss_2': 0.002315521240234375, 'loss_3': -16.50433921813965, 'loss_4': 0.268110990524292, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 13:41:57,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:57,898 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:52<31:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:05,234 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01530696265399456, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01111660711467266, 'eval_loss_2': 0.004190355539321899, 'eval_loss_3': -18.264156341552734, 'eval_loss_4': 0.23202106356620789, 'epoch': 19.24}
{'loss': 0.0097, 'grad_norm': 4.240161895751953, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.005359199363738298, 'loss_2': 0.004299163818359375, 'loss_3': -16.42464256286621, 'loss_4': 0.21608978509902954, 'epoch': 19.25}
{'loss': 0.0208, 'grad_norm': 10.090303421020508, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.016020726412534714, 'loss_2': 0.004791259765625, 'loss_3': -16.567222595214844, 'loss_4': 0.3652549386024475, 'epoch': 19.26}
{'loss': 0.0127, 'grad_norm': 6.370644569396973, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.010838822461664677, 'loss_2': 0.0018901824951171875, 'loss_3': -16.48261070251465, 'loss_4': 0.7312166690826416, 'epoch': 19.26}
{'loss': 0.0054, 'grad_norm': 5.523947715759277, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.005308290012180805, 'loss_2': 9.965896606445312e-05, 'loss_3': -16.406068801879883, 'loss_4': 0.3853287398815155, 'epoch': 19.27}
{'loss': 0.0051, 'grad_norm': 4.4059600830078125, 'learning_rate': 1.075e-05, 'loss_1': 0.002930291462689638, 'loss_2': 0.00213623046875, 'loss_3': -16.439668655395508, 'loss_4': 0.2674251198768616, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 13:42:05,234 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:05,234 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:59<31:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:12,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015093806199729443, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010657758451998234, 'eval_loss_2': 0.00443604588508606, 'eval_loss_3': -18.279598236083984, 'eval_loss_4': 0.36838680505752563, 'epoch': 19.27}
{'loss': 0.0098, 'grad_norm': 4.8806047439575195, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.004983072634786367, 'loss_2': 0.004840850830078125, 'loss_3': -16.523374557495117, 'loss_4': 0.47107094526290894, 'epoch': 19.28}
{'loss': 0.0127, 'grad_norm': 4.785173416137695, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.008823808282613754, 'loss_2': 0.003917694091796875, 'loss_3': -16.347240447998047, 'loss_4': 0.43322473764419556, 'epoch': 19.28}
{'loss': 0.0275, 'grad_norm': 10.403696060180664, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.024903107434511185, 'loss_2': 0.002582550048828125, 'loss_3': -16.570322036743164, 'loss_4': 0.4079689681529999, 'epoch': 19.29}
{'loss': 0.0115, 'grad_norm': 5.634355545043945, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.009268676862120628, 'loss_2': 0.00218963623046875, 'loss_3': -16.408885955810547, 'loss_4': 0.5425928831100464, 'epoch': 19.3}
{'loss': 0.0621, 'grad_norm': 10.386438369750977, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.059883829206228256, 'loss_2': 0.00223541259765625, 'loss_3': -16.245590209960938, 'loss_4': 0.48398664593696594, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 13:42:12,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:12,572 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:22:06<31:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:19,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015766695141792297, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0109371617436409, 'eval_loss_2': 0.004829533398151398, 'eval_loss_3': -18.29288101196289, 'eval_loss_4': 0.4787600338459015, 'epoch': 19.3}
{'loss': 0.0164, 'grad_norm': 5.438030242919922, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.010651174001395702, 'loss_2': 0.005733489990234375, 'loss_3': -16.518203735351562, 'loss_4': 0.5726954936981201, 'epoch': 19.31}
{'loss': 0.0216, 'grad_norm': 8.940885543823242, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.01844101771712303, 'loss_2': 0.00319671630859375, 'loss_3': -16.483657836914062, 'loss_4': 0.32200556993484497, 'epoch': 19.31}
{'loss': 0.0073, 'grad_norm': 5.437258720397949, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.006133837625384331, 'loss_2': 0.0011768341064453125, 'loss_3': -16.58489227294922, 'loss_4': 0.7911642789840698, 'epoch': 19.32}
{'loss': 0.0232, 'grad_norm': 4.622908115386963, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.008343922905623913, 'loss_2': 0.01483154296875, 'loss_3': -16.549774169921875, 'loss_4': 0.9665030837059021, 'epoch': 19.33}
{'loss': 0.0124, 'grad_norm': 4.552576065063477, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.005687879864126444, 'loss_2': 0.00670623779296875, 'loss_3': -16.32787322998047, 'loss_4': 0.6519147157669067, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 13:42:19,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:19,918 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:14<31:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:27,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015115880407392979, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.478, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011809132993221283, 'eval_loss_2': 0.003306746482849121, 'eval_loss_3': -18.279857635498047, 'eval_loss_4': 0.5754448771476746, 'epoch': 19.33}
{'loss': 0.031, 'grad_norm': 12.477222442626953, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.030484631657600403, 'loss_2': 0.0005483627319335938, 'loss_3': -16.385108947753906, 'loss_4': 0.6333622932434082, 'epoch': 19.34}
{'loss': 0.0143, 'grad_norm': 9.70876693725586, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.01229536347091198, 'loss_2': 0.00201416015625, 'loss_3': -16.47311782836914, 'loss_4': 0.9038012027740479, 'epoch': 19.34}
{'loss': 0.0292, 'grad_norm': 15.593671798706055, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.027490848675370216, 'loss_2': 0.0017194747924804688, 'loss_3': -16.434289932250977, 'loss_4': 0.7294614315032959, 'epoch': 19.35}
{'loss': 0.0112, 'grad_norm': 6.343633651733398, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.008930159732699394, 'loss_2': 0.00226593017578125, 'loss_3': -16.563386917114258, 'loss_4': 0.870482861995697, 'epoch': 19.35}
{'loss': 0.0133, 'grad_norm': 4.18382453918457, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.005240828264504671, 'loss_2': 0.0080108642578125, 'loss_3': -16.511751174926758, 'loss_4': 0.7686752676963806, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 13:42:27,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:27,259 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:21<31:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:34,599 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016154155135154724, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011681422591209412, 'eval_loss_2': 0.0044727325439453125, 'eval_loss_3': -18.288284301757812, 'eval_loss_4': 0.6377081871032715, 'epoch': 19.36}
{'loss': 0.0443, 'grad_norm': 22.74582290649414, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.038878947496414185, 'loss_2': 0.00537109375, 'loss_3': -16.698150634765625, 'loss_4': 0.619698703289032, 'epoch': 19.37}
{'loss': 0.0094, 'grad_norm': 4.9630351066589355, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.006472171284258366, 'loss_2': 0.0029621124267578125, 'loss_3': -16.45317268371582, 'loss_4': 0.7484583258628845, 'epoch': 19.37}
{'loss': 0.0146, 'grad_norm': 6.786769390106201, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.014247063547372818, 'loss_2': 0.0003604888916015625, 'loss_3': -16.46792984008789, 'loss_4': 0.25725746154785156, 'epoch': 19.38}
{'loss': 0.0107, 'grad_norm': 7.828037738800049, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.010430329479277134, 'loss_2': 0.0002503395080566406, 'loss_3': -16.661239624023438, 'loss_4': 0.9185552597045898, 'epoch': 19.38}
{'loss': 0.032, 'grad_norm': 12.852218627929688, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.022565217688679695, 'loss_2': 0.009429931640625, 'loss_3': -16.45698356628418, 'loss_4': 1.2277828454971313, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 13:42:34,599 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:34,599 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:29<31:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:41,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0165861789137125, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013118811883032322, 'eval_loss_2': 0.003467366099357605, 'eval_loss_3': -18.283327102661133, 'eval_loss_4': 0.6568403840065002, 'epoch': 19.39}
{'loss': 0.0149, 'grad_norm': 6.016790866851807, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.014277972280979156, 'loss_2': 0.0006151199340820312, 'loss_3': -16.579816818237305, 'loss_4': 0.735859751701355, 'epoch': 19.4}
{'loss': 0.0236, 'grad_norm': 10.19448184967041, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.02046879380941391, 'loss_2': 0.003170013427734375, 'loss_3': -16.225767135620117, 'loss_4': 0.716524600982666, 'epoch': 19.4}
{'loss': 0.0141, 'grad_norm': 5.174798011779785, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.011688057333230972, 'loss_2': 0.0023956298828125, 'loss_3': -16.3408203125, 'loss_4': 0.8130713105201721, 'epoch': 19.41}
{'loss': 0.0162, 'grad_norm': 7.181923866271973, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.015606244094669819, 'loss_2': 0.0006246566772460938, 'loss_3': -16.43708038330078, 'loss_4': 0.4313354194164276, 'epoch': 19.41}
{'loss': 0.015, 'grad_norm': 5.518249988555908, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.00806207861751318, 'loss_2': 0.006916046142578125, 'loss_3': -16.591768264770508, 'loss_4': 0.9997736811637878, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 13:42:41,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:41,937 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:36<31:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:49,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01625864952802658, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013260385021567345, 'eval_loss_2': 0.002998262643814087, 'eval_loss_3': -18.297290802001953, 'eval_loss_4': 0.5975639224052429, 'epoch': 19.42}
{'loss': 0.0272, 'grad_norm': 9.411170959472656, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.025463169440627098, 'loss_2': 0.0017137527465820312, 'loss_3': -16.54552459716797, 'loss_4': 0.5713279247283936, 'epoch': 19.42}
{'loss': 0.009, 'grad_norm': 5.531256198883057, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.007717075292021036, 'loss_2': 0.0012979507446289062, 'loss_3': -16.301891326904297, 'loss_4': 0.5342511534690857, 'epoch': 19.43}
{'loss': 0.0174, 'grad_norm': 6.817917823791504, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.017020022496581078, 'loss_2': 0.0003848075866699219, 'loss_3': -16.358854293823242, 'loss_4': 0.6652693748474121, 'epoch': 19.44}
{'loss': 0.0128, 'grad_norm': 5.204320907592773, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.007503400556743145, 'loss_2': 0.0052642822265625, 'loss_3': -16.585535049438477, 'loss_4': 1.082014560699463, 'epoch': 19.44}
{'loss': 0.0152, 'grad_norm': 5.564291954040527, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.013959409669041634, 'loss_2': 0.0012645721435546875, 'loss_3': -16.56204605102539, 'loss_4': 0.6832983493804932, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 13:42:49,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:49,268 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:43<31:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:56,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01524883508682251, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01319431234151125, 'eval_loss_2': 0.002054523676633835, 'eval_loss_3': -18.300273895263672, 'eval_loss_4': 0.5866281390190125, 'epoch': 19.45}
{'loss': 0.0167, 'grad_norm': 6.391793251037598, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.011265696957707405, 'loss_2': 0.00545501708984375, 'loss_3': -16.563661575317383, 'loss_4': 0.7445106506347656, 'epoch': 19.45}
{'loss': 0.0076, 'grad_norm': 4.8810505867004395, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.004770337138324976, 'loss_2': 0.0028667449951171875, 'loss_3': -16.453134536743164, 'loss_4': 1.0198384523391724, 'epoch': 19.46}
{'loss': 0.0109, 'grad_norm': 5.896084785461426, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.010588319040834904, 'loss_2': 0.0003542900085449219, 'loss_3': -16.31661605834961, 'loss_4': 0.8238985538482666, 'epoch': 19.47}
{'loss': 0.0135, 'grad_norm': 5.282043933868408, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.010585334151983261, 'loss_2': 0.0029430389404296875, 'loss_3': -16.531055450439453, 'loss_4': 0.5848895907402039, 'epoch': 19.47}
{'loss': 0.009, 'grad_norm': 5.005928993225098, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.006535712629556656, 'loss_2': 0.0024852752685546875, 'loss_3': -16.498565673828125, 'loss_4': 0.890117883682251, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 13:42:56,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:56,609 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:51<31:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:03,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015927638858556747, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.207, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012029453180730343, 'eval_loss_2': 0.0038981884717941284, 'eval_loss_3': -18.32063865661621, 'eval_loss_4': 0.5979896187782288, 'epoch': 19.48}
{'loss': 0.0238, 'grad_norm': 9.234307289123535, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.021299170330166817, 'loss_2': 0.0025157928466796875, 'loss_3': -16.3973445892334, 'loss_4': 0.48993611335754395, 'epoch': 19.48}
{'loss': 0.0157, 'grad_norm': 5.340169906616211, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.010128400288522243, 'loss_2': 0.0055694580078125, 'loss_3': -16.544475555419922, 'loss_4': 0.8265160322189331, 'epoch': 19.49}
{'loss': 0.0123, 'grad_norm': 4.792809009552002, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.005069484002888203, 'loss_2': 0.007266998291015625, 'loss_3': -16.38780403137207, 'loss_4': 0.7193667888641357, 'epoch': 19.49}
{'loss': 0.0085, 'grad_norm': 4.967578411102295, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.005869721062481403, 'loss_2': 0.002613067626953125, 'loss_3': -16.61187744140625, 'loss_4': 0.7202152013778687, 'epoch': 19.5}
{'loss': 0.0074, 'grad_norm': 4.9479498863220215, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.006419239100068808, 'loss_2': 0.0010080337524414062, 'loss_3': -16.540307998657227, 'loss_4': 0.9624441862106323, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 13:43:03,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:03,950 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:58<31:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:11,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014173280447721481, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011212129145860672, 'eval_loss_2': 0.0029611513018608093, 'eval_loss_3': -18.303207397460938, 'eval_loss_4': 0.5903286337852478, 'epoch': 19.51}
{'loss': 0.0222, 'grad_norm': 7.832793235778809, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.022172633558511734, 'loss_2': 6.73532485961914e-05, 'loss_3': -16.53811264038086, 'loss_4': 0.7042573094367981, 'epoch': 19.51}
{'loss': 0.0172, 'grad_norm': 8.453584671020508, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.01602771133184433, 'loss_2': 0.0011968612670898438, 'loss_3': -16.4465389251709, 'loss_4': 0.6348671317100525, 'epoch': 19.52}
{'loss': 0.0139, 'grad_norm': 7.373414039611816, 'learning_rate': 1.05e-05, 'loss_1': 0.013449307531118393, 'loss_2': 0.0004506111145019531, 'loss_3': -16.401805877685547, 'loss_4': 0.23057299852371216, 'epoch': 19.52}
{'loss': 0.0096, 'grad_norm': 5.535147190093994, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.00884309783577919, 'loss_2': 0.0007824897766113281, 'loss_3': -16.46333122253418, 'loss_4': 0.9507546424865723, 'epoch': 19.53}
{'loss': 0.0136, 'grad_norm': 5.731764793395996, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.007358366623520851, 'loss_2': 0.006275177001953125, 'loss_3': -16.57851791381836, 'loss_4': 1.0978466272354126, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 13:43:11,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:11,288 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:23:05<31:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:18,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013574402779340744, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010692580603063107, 'eval_loss_2': 0.002881821244955063, 'eval_loss_3': -18.285388946533203, 'eval_loss_4': 0.6389058232307434, 'epoch': 19.53}
{'loss': 0.0074, 'grad_norm': 4.390279293060303, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.005585952661931515, 'loss_2': 0.001773834228515625, 'loss_3': -16.505603790283203, 'loss_4': 0.5914299488067627, 'epoch': 19.54}
{'loss': 0.006, 'grad_norm': 4.597237586975098, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.0025754140224307775, 'loss_2': 0.003448486328125, 'loss_3': -16.60814666748047, 'loss_4': 0.7342952489852905, 'epoch': 19.55}
{'loss': 0.0086, 'grad_norm': 4.6169633865356445, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.007024042308330536, 'loss_2': 0.001621246337890625, 'loss_3': -16.549148559570312, 'loss_4': 0.40602806210517883, 'epoch': 19.55}
{'loss': 0.0091, 'grad_norm': 4.6849188804626465, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.00387360155582428, 'loss_2': 0.005245208740234375, 'loss_3': -16.312801361083984, 'loss_4': 0.8705573678016663, 'epoch': 19.56}
{'loss': 0.0058, 'grad_norm': 4.813140392303467, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.004064726177603006, 'loss_2': 0.0017261505126953125, 'loss_3': -16.351280212402344, 'loss_4': 0.5919437408447266, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 13:43:18,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:18,628 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:13<30:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:25,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012279104441404343, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009187025018036366, 'eval_loss_2': 0.0030920803546905518, 'eval_loss_3': -18.276897430419922, 'eval_loss_4': 0.7615338563919067, 'epoch': 19.56}
{'loss': 0.0101, 'grad_norm': 5.748954772949219, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.008410819806158543, 'loss_2': 0.00170135498046875, 'loss_3': -16.219141006469727, 'loss_4': 1.0087181329727173, 'epoch': 19.57}
{'loss': 0.0061, 'grad_norm': 4.537586212158203, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.005756710190325975, 'loss_2': 0.0003101825714111328, 'loss_3': -16.512107849121094, 'loss_4': 1.1381160020828247, 'epoch': 19.58}
{'loss': 0.0141, 'grad_norm': 6.146771430969238, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.008696486242115498, 'loss_2': 0.00537872314453125, 'loss_3': -16.507070541381836, 'loss_4': 0.863700807094574, 'epoch': 19.58}
{'loss': 0.0109, 'grad_norm': 5.567054271697998, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.007635790389031172, 'loss_2': 0.003253936767578125, 'loss_3': -16.624889373779297, 'loss_4': 1.2321851253509521, 'epoch': 19.59}
{'loss': 0.0084, 'grad_norm': 4.589026927947998, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.004682199098169804, 'loss_2': 0.0036945343017578125, 'loss_3': -16.554256439208984, 'loss_4': 0.9533467292785645, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 13:43:25,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:25,960 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:20<30:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:33,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012750218622386456, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010172094218432903, 'eval_loss_2': 0.0025781244039535522, 'eval_loss_3': -18.245037078857422, 'eval_loss_4': 0.9090362191200256, 'epoch': 19.59}
{'loss': 0.0081, 'grad_norm': 4.944249153137207, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.007212037220597267, 'loss_2': 0.0009212493896484375, 'loss_3': -16.2666015625, 'loss_4': 0.894515335559845, 'epoch': 19.6}
{'loss': 0.0102, 'grad_norm': 4.956585884094238, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.005206845235079527, 'loss_2': 0.00501251220703125, 'loss_3': -16.65350914001465, 'loss_4': 0.7324258685112, 'epoch': 19.6}
{'loss': 0.0166, 'grad_norm': 5.5702948570251465, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.013440779410302639, 'loss_2': 0.0031261444091796875, 'loss_3': -16.46002960205078, 'loss_4': 1.4380344152450562, 'epoch': 19.61}
{'loss': 0.0283, 'grad_norm': 8.850607872009277, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.025244122371077538, 'loss_2': 0.0030364990234375, 'loss_3': -16.388999938964844, 'loss_4': 0.9832690954208374, 'epoch': 19.62}
{'loss': 0.0088, 'grad_norm': 7.686371326446533, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.008003540337085724, 'loss_2': 0.0008358955383300781, 'loss_3': -16.49143409729004, 'loss_4': 1.0690580606460571, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 13:43:33,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:33,297 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:27<30:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:40,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01283437293022871, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01041150651872158, 'eval_loss_2': 0.002422865480184555, 'eval_loss_3': -18.253089904785156, 'eval_loss_4': 0.975530743598938, 'epoch': 19.62}
{'loss': 0.009, 'grad_norm': 6.8086442947387695, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.008666780777275562, 'loss_2': 0.00035691261291503906, 'loss_3': -16.388824462890625, 'loss_4': 1.1558126211166382, 'epoch': 19.63}
{'loss': 0.009, 'grad_norm': 4.24447774887085, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.004082458559423685, 'loss_2': 0.00490570068359375, 'loss_3': -16.53879165649414, 'loss_4': 1.244881272315979, 'epoch': 19.63}
{'loss': 0.01, 'grad_norm': 5.6991801261901855, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.009290081448853016, 'loss_2': 0.0007491111755371094, 'loss_3': -16.399524688720703, 'loss_4': 1.300668478012085, 'epoch': 19.64}
{'loss': 0.0316, 'grad_norm': 8.432642936706543, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.027486557140946388, 'loss_2': 0.004161834716796875, 'loss_3': -16.3217716217041, 'loss_4': 1.2459392547607422, 'epoch': 19.65}
{'loss': 0.0342, 'grad_norm': 10.839716911315918, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.028780559077858925, 'loss_2': 0.00545501708984375, 'loss_3': -16.511592864990234, 'loss_4': 1.189845323562622, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 13:43:40,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:40,632 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:35<30:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:47,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012993274256587029, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.778, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010542092844843864, 'eval_loss_2': 0.002451181411743164, 'eval_loss_3': -18.2615909576416, 'eval_loss_4': 0.836596667766571, 'epoch': 19.65}
{'loss': 0.0122, 'grad_norm': 5.6260666847229, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.009366398677229881, 'loss_2': 0.0028228759765625, 'loss_3': -16.57237434387207, 'loss_4': 1.1873468160629272, 'epoch': 19.66}
{'loss': 0.008, 'grad_norm': 4.69892692565918, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.0073158773593604565, 'loss_2': 0.00067138671875, 'loss_3': -16.585948944091797, 'loss_4': 0.8822071552276611, 'epoch': 19.66}
{'loss': 0.0103, 'grad_norm': 5.14624547958374, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.008588944561779499, 'loss_2': 0.0016651153564453125, 'loss_3': -16.5946044921875, 'loss_4': 0.6868314146995544, 'epoch': 19.67}
{'loss': 0.0177, 'grad_norm': 8.544877052307129, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.012299271300435066, 'loss_2': 0.0053558349609375, 'loss_3': -16.70738410949707, 'loss_4': 1.0796070098876953, 'epoch': 19.67}
{'loss': 0.0208, 'grad_norm': 7.318384170532227, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.013442069292068481, 'loss_2': 0.007381439208984375, 'loss_3': -16.452442169189453, 'loss_4': 1.1273906230926514, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 13:43:47,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:47,982 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:42<30:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:55,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013165628537535667, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010620420798659325, 'eval_loss_2': 0.0025452077388763428, 'eval_loss_3': -18.282432556152344, 'eval_loss_4': 0.7454861998558044, 'epoch': 19.68}
{'loss': 0.0096, 'grad_norm': 5.002383232116699, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.005788430105894804, 'loss_2': 0.003765106201171875, 'loss_3': -16.408491134643555, 'loss_4': 0.9463075399398804, 'epoch': 19.69}
{'loss': 0.0196, 'grad_norm': 6.378424644470215, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.015439043752849102, 'loss_2': 0.00418853759765625, 'loss_3': -16.40532684326172, 'loss_4': 1.1742219924926758, 'epoch': 19.69}
{'loss': 0.0075, 'grad_norm': 5.201427936553955, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.004558279644697905, 'loss_2': 0.002902984619140625, 'loss_3': -16.600778579711914, 'loss_4': 0.835699200630188, 'epoch': 19.7}
{'loss': 0.0066, 'grad_norm': 4.6448445320129395, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.004935888107866049, 'loss_2': 0.0016918182373046875, 'loss_3': -16.490684509277344, 'loss_4': 0.8515110015869141, 'epoch': 19.7}
{'loss': 0.0138, 'grad_norm': 6.235854148864746, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.00791270099580288, 'loss_2': 0.0059051513671875, 'loss_3': -16.476842880249023, 'loss_4': 0.5588563084602356, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 13:43:55,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:55,326 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:49<30:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:02,669 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01418246515095234, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011419521644711494, 'eval_loss_2': 0.0027629435062408447, 'eval_loss_3': -18.287841796875, 'eval_loss_4': 0.729663610458374, 'epoch': 19.71}
{'loss': 0.0095, 'grad_norm': 5.541733264923096, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.006652400828897953, 'loss_2': 0.00289154052734375, 'loss_3': -16.482311248779297, 'loss_4': 0.8145033121109009, 'epoch': 19.72}
{'loss': 0.0118, 'grad_norm': 5.66870641708374, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.009872615337371826, 'loss_2': 0.00196075439453125, 'loss_3': -16.642324447631836, 'loss_4': 0.6399127244949341, 'epoch': 19.72}
{'loss': 0.018, 'grad_norm': 9.814676284790039, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.013558650389313698, 'loss_2': 0.004444122314453125, 'loss_3': -16.586383819580078, 'loss_4': 1.0475175380706787, 'epoch': 19.73}
{'loss': 0.016, 'grad_norm': 5.427626609802246, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.007967274636030197, 'loss_2': 0.00803375244140625, 'loss_3': -16.56107521057129, 'loss_4': 0.9869953393936157, 'epoch': 19.73}
{'loss': 0.0074, 'grad_norm': 4.79024600982666, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.006160215474665165, 'loss_2': 0.0012617111206054688, 'loss_3': -16.452606201171875, 'loss_4': 1.0548986196517944, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 13:44:02,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:02,669 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:57<30:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:10,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01296798512339592, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.996, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010383869521319866, 'eval_loss_2': 0.002584114670753479, 'eval_loss_3': -18.275978088378906, 'eval_loss_4': 0.7327155470848083, 'epoch': 19.74}
{'loss': 0.0224, 'grad_norm': 8.860245704650879, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.021701384335756302, 'loss_2': 0.0006647109985351562, 'loss_3': -16.561113357543945, 'loss_4': 1.2713686227798462, 'epoch': 19.74}
{'loss': 0.0149, 'grad_norm': 8.319453239440918, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.01308054942637682, 'loss_2': 0.0018157958984375, 'loss_3': -16.482755661010742, 'loss_4': 0.35524994134902954, 'epoch': 19.75}
{'loss': 0.0088, 'grad_norm': 5.392934322357178, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.00758755300194025, 'loss_2': 0.0012063980102539062, 'loss_3': -16.432811737060547, 'loss_4': 0.9307935833930969, 'epoch': 19.76}
{'loss': 0.0169, 'grad_norm': 7.634398937225342, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.011724328622221947, 'loss_2': 0.00521087646484375, 'loss_3': -16.572431564331055, 'loss_4': 0.6667723059654236, 'epoch': 19.76}
{'loss': 0.0087, 'grad_norm': 6.284903049468994, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.005238336976617575, 'loss_2': 0.0034313201904296875, 'loss_3': -16.39668083190918, 'loss_4': 0.7560153007507324, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 13:44:10,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:10,023 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:24:04<30:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:17,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014426738023757935, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01094359252601862, 'eval_loss_2': 0.0034831464290618896, 'eval_loss_3': -18.250396728515625, 'eval_loss_4': 0.713291585445404, 'epoch': 19.77}
{'loss': 0.0101, 'grad_norm': 4.771084785461426, 'learning_rate': 1.025e-05, 'loss_1': 0.006521094124764204, 'loss_2': 0.003627777099609375, 'loss_3': -16.449970245361328, 'loss_4': 0.8307115435600281, 'epoch': 19.77}
{'loss': 0.0209, 'grad_norm': 4.6660990715026855, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.006183177698403597, 'loss_2': 0.0147552490234375, 'loss_3': -16.408145904541016, 'loss_4': 0.7956252098083496, 'epoch': 19.78}
{'loss': 0.0127, 'grad_norm': 6.339395046234131, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.012331057339906693, 'loss_2': 0.0004010200500488281, 'loss_3': -16.45277214050293, 'loss_4': 0.9907546043395996, 'epoch': 19.78}
{'loss': 0.0332, 'grad_norm': 19.814802169799805, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.031698696315288544, 'loss_2': 0.001468658447265625, 'loss_3': -16.464496612548828, 'loss_4': 0.6592766642570496, 'epoch': 19.79}
{'loss': 0.0054, 'grad_norm': 5.197352409362793, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.003786381334066391, 'loss_2': 0.001651763916015625, 'loss_3': -16.525442123413086, 'loss_4': 1.0834617614746094, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 13:44:17,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:17,364 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:11<30:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:24,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015766385942697525, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.184, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01103950198739767, 'eval_loss_2': 0.004726886749267578, 'eval_loss_3': -18.233505249023438, 'eval_loss_4': 0.7373216152191162, 'epoch': 19.8}
{'loss': 0.0213, 'grad_norm': 9.393208503723145, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.0193687342107296, 'loss_2': 0.0019474029541015625, 'loss_3': -16.65872573852539, 'loss_4': 0.8775851726531982, 'epoch': 19.8}
{'loss': 0.0123, 'grad_norm': 4.542469501495361, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.007227158639580011, 'loss_2': 0.005115509033203125, 'loss_3': -16.53406524658203, 'loss_4': 0.7957048416137695, 'epoch': 19.81}
{'loss': 0.0111, 'grad_norm': 4.208749771118164, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.004136219155043364, 'loss_2': 0.006969451904296875, 'loss_3': -16.67689323425293, 'loss_4': 0.9719727039337158, 'epoch': 19.81}
{'loss': 0.0259, 'grad_norm': 4.449379920959473, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.007089477963745594, 'loss_2': 0.018798828125, 'loss_3': -16.487455368041992, 'loss_4': 0.7463942766189575, 'epoch': 19.82}
{'loss': 0.0429, 'grad_norm': 17.14482879638672, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.04134248569607735, 'loss_2': 0.0016021728515625, 'loss_3': -16.477882385253906, 'loss_4': 0.9500619769096375, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 13:44:24,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:24,712 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:19<30:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:32,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015014877542853355, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010777367278933525, 'eval_loss_2': 0.00423751026391983, 'eval_loss_3': -18.223630905151367, 'eval_loss_4': 0.8283863067626953, 'epoch': 19.83}
{'loss': 0.0067, 'grad_norm': 5.2739577293396, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.005865917541086674, 'loss_2': 0.0008740425109863281, 'loss_3': -16.37733268737793, 'loss_4': 0.8980742692947388, 'epoch': 19.83}
{'loss': 0.0143, 'grad_norm': 4.475699424743652, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.0051689473912119865, 'loss_2': 0.00908660888671875, 'loss_3': -16.488933563232422, 'loss_4': 0.5522003173828125, 'epoch': 19.84}
{'loss': 0.0189, 'grad_norm': 6.785963535308838, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.014424781315028667, 'loss_2': 0.00446319580078125, 'loss_3': -16.491989135742188, 'loss_4': 1.3498541116714478, 'epoch': 19.84}
{'loss': 0.0041, 'grad_norm': 4.27374267578125, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.004041004925966263, 'loss_2': 9.512901306152344e-05, 'loss_3': -16.55122947692871, 'loss_4': 1.2181117534637451, 'epoch': 19.85}
{'loss': 0.0142, 'grad_norm': 6.0123820304870605, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.006863077636808157, 'loss_2': 0.007343292236328125, 'loss_3': -16.497432708740234, 'loss_4': 1.0920460224151611, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 13:44:32,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:32,050 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:26<30:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:39,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01427521463483572, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.527, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010976342484354973, 'eval_loss_2': 0.0032988712191581726, 'eval_loss_3': -18.214801788330078, 'eval_loss_4': 0.8314682245254517, 'epoch': 19.85}
{'loss': 0.0143, 'grad_norm': 7.0405354499816895, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.014096591621637344, 'loss_2': 0.0001571178436279297, 'loss_3': -16.480552673339844, 'loss_4': 1.3754935264587402, 'epoch': 19.86}
{'loss': 0.0063, 'grad_norm': 4.737117767333984, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.005301652941852808, 'loss_2': 0.0009598731994628906, 'loss_3': -16.441394805908203, 'loss_4': 1.2886415719985962, 'epoch': 19.87}
{'loss': 0.0075, 'grad_norm': 4.565485954284668, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.005002729594707489, 'loss_2': 0.0025272369384765625, 'loss_3': -16.49222183227539, 'loss_4': 0.7526378631591797, 'epoch': 19.87}
{'loss': 0.0042, 'grad_norm': 4.996196269989014, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.0026101956609636545, 'loss_2': 0.0015554428100585938, 'loss_3': -16.478084564208984, 'loss_4': 0.9400230050086975, 'epoch': 19.88}
{'loss': 0.0215, 'grad_norm': 8.274218559265137, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.018686383962631226, 'loss_2': 0.0028076171875, 'loss_3': -16.494291305541992, 'loss_4': 1.0086352825164795, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 13:44:39,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:39,388 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:33<29:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:46,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01602405309677124, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.701, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01178663782775402, 'eval_loss_2': 0.00423741340637207, 'eval_loss_3': -18.196678161621094, 'eval_loss_4': 0.9472973346710205, 'epoch': 19.88}
{'loss': 0.0062, 'grad_norm': 4.9760613441467285, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.004762932658195496, 'loss_2': 0.0014057159423828125, 'loss_3': -16.645172119140625, 'loss_4': 1.1856632232666016, 'epoch': 19.89}
{'loss': 0.0104, 'grad_norm': 4.848630905151367, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.0036289130803197622, 'loss_2': 0.00676727294921875, 'loss_3': -16.38921546936035, 'loss_4': 1.0999479293823242, 'epoch': 19.9}
{'loss': 0.0196, 'grad_norm': 16.023006439208984, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.01928681507706642, 'loss_2': 0.00027441978454589844, 'loss_3': -16.523048400878906, 'loss_4': 1.1405044794082642, 'epoch': 19.9}
{'loss': 0.0069, 'grad_norm': 4.5627264976501465, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.005918094422668219, 'loss_2': 0.00096893310546875, 'loss_3': -16.5537052154541, 'loss_4': 1.0845191478729248, 'epoch': 19.91}
{'loss': 0.0123, 'grad_norm': 6.857874393463135, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.009056811220943928, 'loss_2': 0.003231048583984375, 'loss_3': -16.5904541015625, 'loss_4': 0.8703151941299438, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 13:44:46,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:46,724 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:41<29:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:54,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01759003847837448, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013235562480986118, 'eval_loss_2': 0.0043544769287109375, 'eval_loss_3': -18.204486846923828, 'eval_loss_4': 1.0524359941482544, 'epoch': 19.91}
{'loss': 0.0108, 'grad_norm': 5.2638773918151855, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.0045693363063037395, 'loss_2': 0.006256103515625, 'loss_3': -16.364185333251953, 'loss_4': 0.8568999767303467, 'epoch': 19.92}
{'loss': 0.011, 'grad_norm': 5.296905994415283, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.007034598849713802, 'loss_2': 0.00394439697265625, 'loss_3': -16.276275634765625, 'loss_4': 1.5220460891723633, 'epoch': 19.92}
{'loss': 0.0157, 'grad_norm': 4.370180130004883, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.005725066643208265, 'loss_2': 0.00998687744140625, 'loss_3': -16.654861450195312, 'loss_4': 1.0994949340820312, 'epoch': 19.93}
{'loss': 0.0125, 'grad_norm': 5.4275126457214355, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.010811381042003632, 'loss_2': 0.0016422271728515625, 'loss_3': -16.329906463623047, 'loss_4': 0.9930456280708313, 'epoch': 19.94}
{'loss': 0.0157, 'grad_norm': 8.020608901977539, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.013028486631810665, 'loss_2': 0.0026874542236328125, 'loss_3': -16.432010650634766, 'loss_4': 0.7787660360336304, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 13:44:54,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:54,062 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:48<29:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:01,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018411383032798767, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.626, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014347419142723083, 'eval_loss_2': 0.004063963890075684, 'eval_loss_3': -18.2022705078125, 'eval_loss_4': 0.9535619020462036, 'epoch': 19.94}
{'loss': 0.0064, 'grad_norm': 5.531106948852539, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.005823340732604265, 'loss_2': 0.0005655288696289062, 'loss_3': -16.539514541625977, 'loss_4': 1.2039175033569336, 'epoch': 19.95}
{'loss': 0.0264, 'grad_norm': 9.89627456665039, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.020644361153244972, 'loss_2': 0.00571441650390625, 'loss_3': -16.37957763671875, 'loss_4': 1.1684800386428833, 'epoch': 19.95}
{'loss': 0.0058, 'grad_norm': 4.509482383728027, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.004266361705958843, 'loss_2': 0.0014925003051757812, 'loss_3': -16.432371139526367, 'loss_4': 1.1188362836837769, 'epoch': 19.96}
{'loss': 0.0318, 'grad_norm': 14.238755226135254, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.03040727972984314, 'loss_2': 0.0014314651489257812, 'loss_3': -16.381458282470703, 'loss_4': 0.9324675798416138, 'epoch': 19.97}
{'loss': 0.0734, 'grad_norm': 26.795822143554688, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.06936770677566528, 'loss_2': 0.00402069091796875, 'loss_3': -16.641334533691406, 'loss_4': 1.447319746017456, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 13:45:01,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:01,400 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:55<26:44,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:45:08,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020737934857606888, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.787, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.014473484829068184, 'eval_loss_2': 0.006264448165893555, 'eval_loss_3': -18.217178344726562, 'eval_loss_4': 0.8692809343338013, 'epoch': 19.97}
{'loss': 0.0222, 'grad_norm': 6.702683448791504, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.009941104799509048, 'loss_2': 0.01221466064453125, 'loss_3': -16.443729400634766, 'loss_4': 1.0731637477874756, 'epoch': 19.98}
{'loss': 0.0196, 'grad_norm': 4.793129920959473, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.007134489715099335, 'loss_2': 0.01251220703125, 'loss_3': -16.651416778564453, 'loss_4': 0.550553560256958, 'epoch': 19.98}
{'loss': 0.0094, 'grad_norm': 4.570696830749512, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.0053976126946508884, 'loss_2': 0.00400543212890625, 'loss_3': -16.21392059326172, 'loss_4': 0.9943985939025879, 'epoch': 19.99}
{'loss': 0.0419, 'grad_norm': 12.679986953735352, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.03032759577035904, 'loss_2': 0.01153564453125, 'loss_3': -16.397628784179688, 'loss_4': 1.10100257396698, 'epoch': 19.99}
{'loss': 0.0099, 'grad_norm': 7.1686811447143555, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.004373158793896437, 'loss_2': 0.0055084228515625, 'loss_3': -16.355512619018555, 'loss_4': 1.3754966259002686, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 13:45:08,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:08,395 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:25:02<29:11,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:45:15,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02058054506778717, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015779277309775352, 'eval_loss_2': 0.004801269620656967, 'eval_loss_3': -18.215669631958008, 'eval_loss_4': 0.8471671342849731, 'epoch': 20.0}
{'loss': 0.0068, 'grad_norm': 4.961472034454346, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.006161446683108807, 'loss_2': 0.0006361007690429688, 'loss_3': -16.39051055908203, 'loss_4': 1.4928414821624756, 'epoch': 20.01}
{'loss': 0.0123, 'grad_norm': 5.11536169052124, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.007152169477194548, 'loss_2': 0.00514984130859375, 'loss_3': -16.551395416259766, 'loss_4': 0.792941689491272, 'epoch': 20.01}
{'loss': 0.0176, 'grad_norm': 6.004913330078125, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.008563787676393986, 'loss_2': 0.00907135009765625, 'loss_3': -16.482295989990234, 'loss_4': 1.1647528409957886, 'epoch': 20.02}
{'loss': 0.0136, 'grad_norm': 5.489778518676758, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.008287496864795685, 'loss_2': 0.0053253173828125, 'loss_3': -16.384796142578125, 'loss_4': 1.3293647766113281, 'epoch': 20.02}
{'loss': 0.0091, 'grad_norm': 6.84574031829834, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.008444597013294697, 'loss_2': 0.00067138671875, 'loss_3': -16.512948989868164, 'loss_4': 0.777518630027771, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 13:45:15,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:15,769 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:10<29:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:45:23,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020079689100384712, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01625414378941059, 'eval_loss_2': 0.003825545310974121, 'eval_loss_3': -18.191295623779297, 'eval_loss_4': 0.8064174652099609, 'epoch': 20.03}
{'loss': 0.027, 'grad_norm': 10.599124908447266, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.02069292776286602, 'loss_2': 0.0062713623046875, 'loss_3': -16.441484451293945, 'loss_4': 0.4551824629306793, 'epoch': 20.03}
{'loss': 0.0202, 'grad_norm': 6.19373893737793, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.013730104081332684, 'loss_2': 0.006511688232421875, 'loss_3': -16.5000057220459, 'loss_4': 1.0175223350524902, 'epoch': 20.04}
{'loss': 0.007, 'grad_norm': 4.854638576507568, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.0035852878354489803, 'loss_2': 0.0033721923828125, 'loss_3': -16.540918350219727, 'loss_4': 0.44535163044929504, 'epoch': 20.05}
{'loss': 0.0094, 'grad_norm': 5.592076778411865, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.006065886467695236, 'loss_2': 0.0033416748046875, 'loss_3': -16.377098083496094, 'loss_4': 0.6269235610961914, 'epoch': 20.05}
{'loss': 0.014, 'grad_norm': 6.7098774909973145, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.011279759928584099, 'loss_2': 0.002742767333984375, 'loss_3': -16.54486846923828, 'loss_4': 0.7559604048728943, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 13:45:23,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:23,102 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:17<29:51,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:45:30,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020429827272892, 'eval_runtime': 3.9998, 'eval_samples_per_second': 256.012, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.01604096032679081, 'eval_loss_2': 0.004388868808746338, 'eval_loss_3': -18.191932678222656, 'eval_loss_4': 0.6990523934364319, 'epoch': 20.06}
{'loss': 0.0157, 'grad_norm': 6.412319660186768, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.013319247402250767, 'loss_2': 0.002349853515625, 'loss_3': -16.319904327392578, 'loss_4': 0.7740194797515869, 'epoch': 20.06}
{'loss': 0.0203, 'grad_norm': 9.02827262878418, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.013015350326895714, 'loss_2': 0.007289886474609375, 'loss_3': -16.31844711303711, 'loss_4': 0.8844377398490906, 'epoch': 20.07}
{'loss': 0.009, 'grad_norm': 4.948322296142578, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.004787882789969444, 'loss_2': 0.004215240478515625, 'loss_3': -16.46129035949707, 'loss_4': 1.1449661254882812, 'epoch': 20.08}
{'loss': 0.0152, 'grad_norm': 5.163702964782715, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.005854351911693811, 'loss_2': 0.00931549072265625, 'loss_3': -16.54620361328125, 'loss_4': 0.47908857464790344, 'epoch': 20.08}
{'loss': 0.0125, 'grad_norm': 5.704836845397949, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.008785939775407314, 'loss_2': 0.00372314453125, 'loss_3': -16.493988037109375, 'loss_4': 0.9372650384902954, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 13:45:30,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:30,643 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:25<29:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:37,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021851681172847748, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.018336854875087738, 'eval_loss_2': 0.0035148262977600098, 'eval_loss_3': -18.181489944458008, 'eval_loss_4': 0.566590428352356, 'epoch': 20.09}
{'loss': 0.0076, 'grad_norm': 4.788338661193848, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.006751920096576214, 'loss_2': 0.0008244514465332031, 'loss_3': -16.50100326538086, 'loss_4': 0.8006928563117981, 'epoch': 20.09}
{'loss': 0.0727, 'grad_norm': 19.716205596923828, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.06965190917253494, 'loss_2': 0.00299835205078125, 'loss_3': -16.243000030517578, 'loss_4': 1.0169639587402344, 'epoch': 20.1}
{'loss': 0.0035, 'grad_norm': 4.630802631378174, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.003295713569968939, 'loss_2': 0.00016105175018310547, 'loss_3': -16.417295455932617, 'loss_4': 0.7716763019561768, 'epoch': 20.1}
{'loss': 0.0127, 'grad_norm': 5.338546276092529, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.008877911604940891, 'loss_2': 0.003810882568359375, 'loss_3': -16.343387603759766, 'loss_4': 0.44912031292915344, 'epoch': 20.11}
{'loss': 0.0176, 'grad_norm': 7.248441696166992, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.011732817627489567, 'loss_2': 0.00586700439453125, 'loss_3': -16.48676300048828, 'loss_4': 0.5395348072052002, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 13:45:37,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:37,984 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:32<29:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:45,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020690981298685074, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.998, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.017267050221562386, 'eval_loss_2': 0.003423929214477539, 'eval_loss_3': -18.181180953979492, 'eval_loss_4': 0.49465838074684143, 'epoch': 20.12}
{'loss': 0.0038, 'grad_norm': 4.944010257720947, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.0027766407001763582, 'loss_2': 0.001049041748046875, 'loss_3': -16.465389251708984, 'loss_4': 0.7400049567222595, 'epoch': 20.12}
{'loss': 0.0067, 'grad_norm': 4.290797233581543, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.004387755412608385, 'loss_2': 0.0022754669189453125, 'loss_3': -16.294063568115234, 'loss_4': 0.687593936920166, 'epoch': 20.13}
{'loss': 0.011, 'grad_norm': 6.9009246826171875, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.010247531346976757, 'loss_2': 0.0007448196411132812, 'loss_3': -16.291900634765625, 'loss_4': 1.0747520923614502, 'epoch': 20.13}
{'loss': 0.01, 'grad_norm': 5.087681770324707, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.006226475350558758, 'loss_2': 0.00380706787109375, 'loss_3': -16.57872200012207, 'loss_4': 0.5928712487220764, 'epoch': 20.14}
{'loss': 0.0187, 'grad_norm': 9.537755966186523, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.014421921223402023, 'loss_2': 0.00429534912109375, 'loss_3': -16.590248107910156, 'loss_4': 0.17765216529369354, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 13:45:45,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:45,329 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:39<29:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:52,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021150654181838036, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.446, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.017325647175312042, 'eval_loss_2': 0.0038250088691711426, 'eval_loss_3': -18.18581771850586, 'eval_loss_4': 0.533303439617157, 'epoch': 20.15}
{'loss': 0.0087, 'grad_norm': 4.869264602661133, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.006579906679689884, 'loss_2': 0.0021572113037109375, 'loss_3': -16.611454010009766, 'loss_4': 0.7590088844299316, 'epoch': 20.15}
{'loss': 0.0121, 'grad_norm': 8.036462783813477, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.010041766799986362, 'loss_2': 0.00209808349609375, 'loss_3': -16.458608627319336, 'loss_4': 0.549767017364502, 'epoch': 20.16}
{'loss': 0.0107, 'grad_norm': 5.001749515533447, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.003747320733964443, 'loss_2': 0.0069580078125, 'loss_3': -16.394672393798828, 'loss_4': 0.9851224422454834, 'epoch': 20.16}
{'loss': 0.0175, 'grad_norm': 6.731256008148193, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.010594809427857399, 'loss_2': 0.006927490234375, 'loss_3': -16.31267547607422, 'loss_4': 0.7367818355560303, 'epoch': 20.17}
{'loss': 0.0124, 'grad_norm': 5.828867435455322, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.010889804922044277, 'loss_2': 0.00151824951171875, 'loss_3': -16.399465560913086, 'loss_4': 0.18376299738883972, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 13:45:52,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:52,667 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:47<29:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:00,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024266572669148445, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.109, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.019194334745407104, 'eval_loss_2': 0.005072236061096191, 'eval_loss_3': -18.184741973876953, 'eval_loss_4': 0.5615453720092773, 'epoch': 20.17}
{'loss': 0.0209, 'grad_norm': 5.80348014831543, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.01086090225726366, 'loss_2': 0.01006317138671875, 'loss_3': -16.625246047973633, 'loss_4': 0.47237512469291687, 'epoch': 20.18}
{'loss': 0.0162, 'grad_norm': 5.048547744750977, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.007680260110646486, 'loss_2': 0.0084991455078125, 'loss_3': -16.381914138793945, 'loss_4': 1.0189332962036133, 'epoch': 20.19}
{'loss': 0.0226, 'grad_norm': 11.804243087768555, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.015343885868787766, 'loss_2': 0.00726318359375, 'loss_3': -16.42961883544922, 'loss_4': 0.6132343411445618, 'epoch': 20.19}
{'loss': 0.0181, 'grad_norm': 6.217413425445557, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.013598601333796978, 'loss_2': 0.00450897216796875, 'loss_3': -16.274869918823242, 'loss_4': 0.30844882130622864, 'epoch': 20.2}
{'loss': 0.0074, 'grad_norm': 4.348492622375488, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.004082756582647562, 'loss_2': 0.003299713134765625, 'loss_3': -16.589963912963867, 'loss_4': 0.9364367723464966, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 13:46:00,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:00,021 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:54<29:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:07,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022435259073972702, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.018378030508756638, 'eval_loss_2': 0.0040572285652160645, 'eval_loss_3': -18.194808959960938, 'eval_loss_4': 0.5560309886932373, 'epoch': 20.2}
{'loss': 0.0093, 'grad_norm': 4.722395420074463, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.006166957318782806, 'loss_2': 0.0031719207763671875, 'loss_3': -16.51604652404785, 'loss_4': 1.2185832262039185, 'epoch': 20.21}
{'loss': 0.0073, 'grad_norm': 4.809773921966553, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.006005133036524057, 'loss_2': 0.0012950897216796875, 'loss_3': -16.451560974121094, 'loss_4': 0.6133651733398438, 'epoch': 20.22}
{'loss': 0.0054, 'grad_norm': 4.585841655731201, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.005153410602360964, 'loss_2': 0.0002493858337402344, 'loss_3': -16.38681411743164, 'loss_4': 0.7023665904998779, 'epoch': 20.22}
{'loss': 0.0067, 'grad_norm': 4.877440929412842, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.003197617130354047, 'loss_2': 0.003528594970703125, 'loss_3': -16.421680450439453, 'loss_4': 0.5509994029998779, 'epoch': 20.23}
{'loss': 0.0099, 'grad_norm': 4.291030406951904, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.0064688632264733315, 'loss_2': 0.003437042236328125, 'loss_3': -16.538164138793945, 'loss_4': 0.8841990828514099, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 13:46:07,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:07,362 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:26:01<28:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:14,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02062498964369297, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.528, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01761428453028202, 'eval_loss_2': 0.0030107051134109497, 'eval_loss_3': -18.200603485107422, 'eval_loss_4': 0.6387004256248474, 'epoch': 20.23}
{'loss': 0.0187, 'grad_norm': 6.685957908630371, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.014881965704262257, 'loss_2': 0.00384521484375, 'loss_3': -16.29250144958496, 'loss_4': 0.38318711519241333, 'epoch': 20.24}
{'loss': 0.0083, 'grad_norm': 4.9614105224609375, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.006669824477285147, 'loss_2': 0.0016727447509765625, 'loss_3': -16.49005889892578, 'loss_4': 0.4492550492286682, 'epoch': 20.24}
{'loss': 0.0163, 'grad_norm': 6.875966548919678, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.012142210267484188, 'loss_2': 0.00412750244140625, 'loss_3': -16.324249267578125, 'loss_4': 0.9684176445007324, 'epoch': 20.25}
{'loss': 0.0119, 'grad_norm': 5.701169967651367, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.010003099218010902, 'loss_2': 0.0018472671508789062, 'loss_3': -16.255821228027344, 'loss_4': 0.5165888071060181, 'epoch': 20.26}
{'loss': 0.0136, 'grad_norm': 7.866685390472412, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.01091364212334156, 'loss_2': 0.0026988983154296875, 'loss_3': -16.49033546447754, 'loss_4': 1.194554090499878, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 13:46:14,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:14,703 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:09<28:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:22,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020082509145140648, 'eval_runtime': 3.8241, 'eval_samples_per_second': 267.774, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.016951914876699448, 'eval_loss_2': 0.003130592405796051, 'eval_loss_3': -18.187217712402344, 'eval_loss_4': 0.6868165731430054, 'epoch': 20.26}
{'loss': 0.0148, 'grad_norm': 5.181973457336426, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.008887792937457561, 'loss_2': 0.00594329833984375, 'loss_3': -16.53948974609375, 'loss_4': 0.7578332424163818, 'epoch': 20.27}
{'loss': 0.0084, 'grad_norm': 4.80665397644043, 'learning_rate': 9.75e-06, 'loss_1': 0.006466879043728113, 'loss_2': 0.0019464492797851562, 'loss_3': -16.514965057373047, 'loss_4': 0.6538407206535339, 'epoch': 20.27}
{'loss': 0.0097, 'grad_norm': 5.135209083557129, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.003956818487495184, 'loss_2': 0.0057373046875, 'loss_3': -16.46854019165039, 'loss_4': 0.7104101181030273, 'epoch': 20.28}
{'loss': 0.009, 'grad_norm': 5.4057135581970215, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.007224861532449722, 'loss_2': 0.00174713134765625, 'loss_3': -16.529430389404297, 'loss_4': 0.554072380065918, 'epoch': 20.28}
{'loss': 0.0117, 'grad_norm': 5.684646129608154, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.009557491168379784, 'loss_2': 0.0021381378173828125, 'loss_3': -16.454641342163086, 'loss_4': 1.4521229267120361, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 13:46:22,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:22,069 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:16<28:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:29,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018519235774874687, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014299405738711357, 'eval_loss_2': 0.00421983003616333, 'eval_loss_3': -18.212753295898438, 'eval_loss_4': 0.6871264576911926, 'epoch': 20.29}
{'loss': 0.0128, 'grad_norm': 6.649003028869629, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.01191891822963953, 'loss_2': 0.0008411407470703125, 'loss_3': -16.42563247680664, 'loss_4': 0.804008960723877, 'epoch': 20.3}
{'loss': 0.0314, 'grad_norm': 10.224688529968262, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.022003673017024994, 'loss_2': 0.0093994140625, 'loss_3': -16.41440773010254, 'loss_4': 1.1624835729599, 'epoch': 20.3}
{'loss': 0.0106, 'grad_norm': 5.168323516845703, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.006780693773180246, 'loss_2': 0.003856658935546875, 'loss_3': -16.53555679321289, 'loss_4': 1.142559289932251, 'epoch': 20.31}
{'loss': 0.0168, 'grad_norm': 6.108598709106445, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.01083400472998619, 'loss_2': 0.0059814453125, 'loss_3': -16.446693420410156, 'loss_4': 0.3480072319507599, 'epoch': 20.31}
{'loss': 0.0064, 'grad_norm': 4.684946537017822, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.0035899574868381023, 'loss_2': 0.0028076171875, 'loss_3': -16.495290756225586, 'loss_4': 1.3540318012237549, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 13:46:29,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:29,416 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:23<28:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:36,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01478305459022522, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.375, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011006216518580914, 'eval_loss_2': 0.0037768371403217316, 'eval_loss_3': -18.252729415893555, 'eval_loss_4': 0.641819953918457, 'epoch': 20.32}
{'loss': 0.0122, 'grad_norm': 5.464876174926758, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.008008266799151897, 'loss_2': 0.004146575927734375, 'loss_3': -16.474021911621094, 'loss_4': 0.689803421497345, 'epoch': 20.33}
{'loss': 0.0174, 'grad_norm': 6.4401535987854, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.014018363319337368, 'loss_2': 0.00341033935546875, 'loss_3': -16.557594299316406, 'loss_4': 0.636069655418396, 'epoch': 20.33}
{'loss': 0.0076, 'grad_norm': 4.633526802062988, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.0064791422337293625, 'loss_2': 0.0011043548583984375, 'loss_3': -16.580181121826172, 'loss_4': 0.8325129747390747, 'epoch': 20.34}
{'loss': 0.0116, 'grad_norm': 5.535261154174805, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.00923212617635727, 'loss_2': 0.0023860931396484375, 'loss_3': -16.537700653076172, 'loss_4': 0.6010798811912537, 'epoch': 20.34}
{'loss': 0.0105, 'grad_norm': 5.012053489685059, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.009626262821257114, 'loss_2': 0.0008983612060546875, 'loss_3': -16.40866470336914, 'loss_4': 0.8401905298233032, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 13:46:36,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:36,760 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:31<28:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:44,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01494674850255251, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011295457370579243, 'eval_loss_2': 0.0036512911319732666, 'eval_loss_3': -18.28133773803711, 'eval_loss_4': 0.5698559880256653, 'epoch': 20.35}
{'loss': 0.0173, 'grad_norm': 7.272216320037842, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.015174055472016335, 'loss_2': 0.0020809173583984375, 'loss_3': -16.567445755004883, 'loss_4': 1.3000569343566895, 'epoch': 20.35}
{'loss': 0.0193, 'grad_norm': 7.137513160705566, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.017644979059696198, 'loss_2': 0.0016632080078125, 'loss_3': -16.706024169921875, 'loss_4': 0.6560305953025818, 'epoch': 20.36}
{'loss': 0.0112, 'grad_norm': 7.7130231857299805, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.010937262326478958, 'loss_2': 0.0002467632293701172, 'loss_3': -16.465341567993164, 'loss_4': 0.9400122761726379, 'epoch': 20.37}
{'loss': 0.0073, 'grad_norm': 5.210216045379639, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.006889339070767164, 'loss_2': 0.00036215782165527344, 'loss_3': -16.34850311279297, 'loss_4': 0.6409159898757935, 'epoch': 20.37}
{'loss': 0.0103, 'grad_norm': 4.919882297515869, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.00824650377035141, 'loss_2': 0.002017974853515625, 'loss_3': -16.327476501464844, 'loss_4': 0.35732603073120117, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 13:46:44,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:44,108 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:38<28:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:51,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013611271977424622, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010104135610163212, 'eval_loss_2': 0.0035071372985839844, 'eval_loss_3': -18.316999435424805, 'eval_loss_4': 0.5265048146247864, 'epoch': 20.38}
{'loss': 0.0246, 'grad_norm': 7.055635929107666, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.014385510236024857, 'loss_2': 0.0102386474609375, 'loss_3': -16.2874755859375, 'loss_4': 0.6943092346191406, 'epoch': 20.38}
{'loss': 0.0118, 'grad_norm': 5.53926420211792, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.011672018095850945, 'loss_2': 0.00012540817260742188, 'loss_3': -16.510038375854492, 'loss_4': 0.18865540623664856, 'epoch': 20.39}
{'loss': 0.0133, 'grad_norm': 5.9961700439453125, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.011464969255030155, 'loss_2': 0.0018138885498046875, 'loss_3': -16.59081268310547, 'loss_4': 0.873723030090332, 'epoch': 20.4}
{'loss': 0.0074, 'grad_norm': 4.711392402648926, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.003870275104418397, 'loss_2': 0.003566741943359375, 'loss_3': -16.42230987548828, 'loss_4': 0.6922388672828674, 'epoch': 20.4}
{'loss': 0.0097, 'grad_norm': 4.629308223724365, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.00441938079893589, 'loss_2': 0.005306243896484375, 'loss_3': -16.517318725585938, 'loss_4': 0.6964520812034607, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 13:46:51,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:51,450 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:45<28:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:58,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012698553502559662, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009783744812011719, 'eval_loss_2': 0.002914808690547943, 'eval_loss_3': -18.31841278076172, 'eval_loss_4': 0.5104482173919678, 'epoch': 20.41}
{'loss': 0.0048, 'grad_norm': 4.7498040199279785, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.0030101840384304523, 'loss_2': 0.0017414093017578125, 'loss_3': -16.60500144958496, 'loss_4': 0.6151252388954163, 'epoch': 20.41}
{'loss': 0.0107, 'grad_norm': 6.174480438232422, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.009561341255903244, 'loss_2': 0.001186370849609375, 'loss_3': -16.507551193237305, 'loss_4': 0.5891551375389099, 'epoch': 20.42}
{'loss': 0.0125, 'grad_norm': 5.807814598083496, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.010690907947719097, 'loss_2': 0.0018129348754882812, 'loss_3': -16.682920455932617, 'loss_4': 0.7143943309783936, 'epoch': 20.42}
{'loss': 0.0057, 'grad_norm': 4.7533345222473145, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.005124039016664028, 'loss_2': 0.000598907470703125, 'loss_3': -16.47180938720703, 'loss_4': 0.7280892729759216, 'epoch': 20.43}
{'loss': 0.0116, 'grad_norm': 6.150786399841309, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.0082894591614604, 'loss_2': 0.0033416748046875, 'loss_3': -16.436004638671875, 'loss_4': 0.42328935861587524, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 13:46:58,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:58,791 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:53<28:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:06,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012520822696387768, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009959379211068153, 'eval_loss_2': 0.00256144255399704, 'eval_loss_3': -18.286418914794922, 'eval_loss_4': 0.40444618463516235, 'epoch': 20.44}
{'loss': 0.0108, 'grad_norm': 5.08485221862793, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.005865084007382393, 'loss_2': 0.004886627197265625, 'loss_3': -16.50101661682129, 'loss_4': 0.7940438985824585, 'epoch': 20.44}
{'loss': 0.0154, 'grad_norm': 9.590195655822754, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.015260052867233753, 'loss_2': 0.00017392635345458984, 'loss_3': -16.432613372802734, 'loss_4': 0.4731406569480896, 'epoch': 20.45}
{'loss': 0.0135, 'grad_norm': 6.122676372528076, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.007505103945732117, 'loss_2': 0.006011962890625, 'loss_3': -16.478282928466797, 'loss_4': 0.7684116959571838, 'epoch': 20.45}
{'loss': 0.0066, 'grad_norm': 4.35291051864624, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.004690105095505714, 'loss_2': 0.001873016357421875, 'loss_3': -16.633190155029297, 'loss_4': 0.18180981278419495, 'epoch': 20.46}
{'loss': 0.006, 'grad_norm': 4.625743865966797, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.005398532375693321, 'loss_2': 0.0005540847778320312, 'loss_3': -16.35004425048828, 'loss_4': 0.28863710165023804, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 13:47:06,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:06,143 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:27:00<28:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:13,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013458849862217903, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010428731329739094, 'eval_loss_2': 0.0030301176011562347, 'eval_loss_3': -18.276897430419922, 'eval_loss_4': 0.22053484618663788, 'epoch': 20.47}
{'loss': 0.0083, 'grad_norm': 4.805816650390625, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.005670467391610146, 'loss_2': 0.002628326416015625, 'loss_3': -16.347248077392578, 'loss_4': 0.7435667514801025, 'epoch': 20.47}
{'loss': 0.0058, 'grad_norm': 5.2917070388793945, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.005223289597779512, 'loss_2': 0.0006098747253417969, 'loss_3': -16.524776458740234, 'loss_4': 0.38554954528808594, 'epoch': 20.48}
{'loss': 0.0682, 'grad_norm': 6.288449287414551, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.06462971866130829, 'loss_2': 0.003582000732421875, 'loss_3': -16.394813537597656, 'loss_4': 0.5594494342803955, 'epoch': 20.48}
{'loss': 0.0163, 'grad_norm': 8.374104499816895, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.013046665117144585, 'loss_2': 0.003253936767578125, 'loss_3': -16.304109573364258, 'loss_4': 0.6765944361686707, 'epoch': 20.49}
{'loss': 0.0153, 'grad_norm': 5.396465301513672, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.00853427778929472, 'loss_2': 0.00677490234375, 'loss_3': -16.577556610107422, 'loss_4': 0.4076337218284607, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 13:47:13,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:13,484 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:07<28:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:20,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014260344207286835, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01050782110542059, 'eval_loss_2': 0.0037525221705436707, 'eval_loss_3': -18.26773452758789, 'eval_loss_4': 0.19710545241832733, 'epoch': 20.49}
{'loss': 0.0124, 'grad_norm': 5.081936836242676, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.004556711763143539, 'loss_2': 0.0078887939453125, 'loss_3': -16.513904571533203, 'loss_4': 0.069396011531353, 'epoch': 20.5}
{'loss': 0.0141, 'grad_norm': 4.976835250854492, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.004618543200194836, 'loss_2': 0.00948333740234375, 'loss_3': -16.601154327392578, 'loss_4': 0.1694488227367401, 'epoch': 20.51}
{'loss': 0.01, 'grad_norm': 4.442864418029785, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.00673259561881423, 'loss_2': 0.0032196044921875, 'loss_3': -16.218456268310547, 'loss_4': 0.24568623304367065, 'epoch': 20.51}
{'loss': 0.0103, 'grad_norm': 7.687888145446777, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.008868368342518806, 'loss_2': 0.0014171600341796875, 'loss_3': -16.4422550201416, 'loss_4': 0.18207354843616486, 'epoch': 20.52}
{'loss': 0.0193, 'grad_norm': 10.060530662536621, 'learning_rate': 9.5e-06, 'loss_1': 0.016770217567682266, 'loss_2': 0.002574920654296875, 'loss_3': -16.374786376953125, 'loss_4': 0.3601236939430237, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 13:47:20,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:20,823 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:15<28:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:28,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014457028359174728, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011224498972296715, 'eval_loss_2': 0.003232531249523163, 'eval_loss_3': -18.262367248535156, 'eval_loss_4': 0.2079886794090271, 'epoch': 20.52}
{'loss': 0.0107, 'grad_norm': 8.14216423034668, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.008235716260969639, 'loss_2': 0.0024662017822265625, 'loss_3': -16.452346801757812, 'loss_4': 0.02871839329600334, 'epoch': 20.53}
{'loss': 0.0076, 'grad_norm': 4.410616397857666, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.004330569878220558, 'loss_2': 0.003246307373046875, 'loss_3': -16.439294815063477, 'loss_4': 0.3920377790927887, 'epoch': 20.53}
{'loss': 0.0037, 'grad_norm': 4.414386749267578, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.002943117404356599, 'loss_2': 0.0007109642028808594, 'loss_3': -16.233930587768555, 'loss_4': 0.3229407072067261, 'epoch': 20.54}
{'loss': 0.0365, 'grad_norm': 10.540376663208008, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.029603153467178345, 'loss_2': 0.0069427490234375, 'loss_3': -16.371246337890625, 'loss_4': 0.17154951393604279, 'epoch': 20.55}
{'loss': 0.0095, 'grad_norm': 4.324602127075195, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.004247518256306648, 'loss_2': 0.00522613525390625, 'loss_3': -16.420555114746094, 'loss_4': 0.3644883930683136, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 13:47:28,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:28,158 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:22<28:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:35,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013347563333809376, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.804, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010702673345804214, 'eval_loss_2': 0.0026448890566825867, 'eval_loss_3': -18.260305404663086, 'eval_loss_4': 0.20377832651138306, 'epoch': 20.55}
{'loss': 0.019, 'grad_norm': 7.024532318115234, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.016322314739227295, 'loss_2': 0.0027065277099609375, 'loss_3': -16.246212005615234, 'loss_4': 0.5543111562728882, 'epoch': 20.56}
{'loss': 0.0063, 'grad_norm': 5.233856678009033, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.006072518415749073, 'loss_2': 0.0002684593200683594, 'loss_3': -16.633543014526367, 'loss_4': 0.3671925663948059, 'epoch': 20.56}
{'loss': 0.012, 'grad_norm': 4.859465599060059, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.0067257359623909, 'loss_2': 0.00525665283203125, 'loss_3': -16.42942237854004, 'loss_4': 0.1509874016046524, 'epoch': 20.57}
{'loss': 0.0104, 'grad_norm': 7.374869346618652, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.010098949074745178, 'loss_2': 0.0003325939178466797, 'loss_3': -16.696990966796875, 'loss_4': 0.13630595803260803, 'epoch': 20.58}
{'loss': 0.0261, 'grad_norm': 9.179972648620605, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.023485803976655006, 'loss_2': 0.002643585205078125, 'loss_3': -16.488628387451172, 'loss_4': 0.3958578109741211, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 13:47:35,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:35,500 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:29<27:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:42,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014846380800008774, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.651, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010560746304690838, 'eval_loss_2': 0.004285633563995361, 'eval_loss_3': -18.25672149658203, 'eval_loss_4': 0.14305606484413147, 'epoch': 20.58}
{'loss': 0.0181, 'grad_norm': 6.684906959533691, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.01526825875043869, 'loss_2': 0.00283050537109375, 'loss_3': -16.378005981445312, 'loss_4': 0.3757215142250061, 'epoch': 20.59}
{'loss': 0.0122, 'grad_norm': 6.547430038452148, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.009292167611420155, 'loss_2': 0.0029201507568359375, 'loss_3': -16.435462951660156, 'loss_4': 0.3397713899612427, 'epoch': 20.59}
{'loss': 0.0187, 'grad_norm': 12.64157485961914, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.014968168921768665, 'loss_2': 0.0037384033203125, 'loss_3': -16.528446197509766, 'loss_4': 0.46961265802383423, 'epoch': 20.6}
{'loss': 0.0124, 'grad_norm': 6.03287410736084, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.008445537649095058, 'loss_2': 0.003997802734375, 'loss_3': -16.383209228515625, 'loss_4': 0.6290555000305176, 'epoch': 20.6}
{'loss': 0.0744, 'grad_norm': 20.009557723999023, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.07333316653966904, 'loss_2': 0.00106048583984375, 'loss_3': -16.506126403808594, 'loss_4': 0.4982621967792511, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 13:47:42,842 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:42,842 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:37<27:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:50,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014598500914871693, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010288609191775322, 'eval_loss_2': 0.004309892654418945, 'eval_loss_3': -18.255130767822266, 'eval_loss_4': 0.12726929783821106, 'epoch': 20.61}
{'loss': 0.0126, 'grad_norm': 7.376143932342529, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.011972669512033463, 'loss_2': 0.0006093978881835938, 'loss_3': -16.563323974609375, 'loss_4': 0.12451693415641785, 'epoch': 20.62}
{'loss': 0.0172, 'grad_norm': 6.527212142944336, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.00844835489988327, 'loss_2': 0.0087890625, 'loss_3': -16.400630950927734, 'loss_4': 0.0502638965845108, 'epoch': 20.62}
{'loss': 0.0079, 'grad_norm': 7.512765884399414, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.006299818400293589, 'loss_2': 0.001605987548828125, 'loss_3': -16.531757354736328, 'loss_4': -0.40664640069007874, 'epoch': 20.63}
{'loss': 0.0115, 'grad_norm': 5.7408552169799805, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.008515427820384502, 'loss_2': 0.003002166748046875, 'loss_3': -16.444847106933594, 'loss_4': 0.17319932579994202, 'epoch': 20.63}
{'loss': 0.0318, 'grad_norm': 12.176706314086914, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.022293565794825554, 'loss_2': 0.0095367431640625, 'loss_3': -16.379043579101562, 'loss_4': 0.4921830892562866, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 13:47:50,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:50,186 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:44<27:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:57,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013671169988811016, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.631, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009745092131197453, 'eval_loss_2': 0.003926075994968414, 'eval_loss_3': -18.24352264404297, 'eval_loss_4': 0.06673379242420197, 'epoch': 20.64}
{'loss': 0.01, 'grad_norm': 5.276257514953613, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.0064248088747262955, 'loss_2': 0.00357818603515625, 'loss_3': -16.27554702758789, 'loss_4': 0.1967119723558426, 'epoch': 20.65}
{'loss': 0.0097, 'grad_norm': 5.0760416984558105, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.005136696621775627, 'loss_2': 0.004547119140625, 'loss_3': -16.475128173828125, 'loss_4': 0.6608809232711792, 'epoch': 20.65}
{'loss': 0.0182, 'grad_norm': 6.665441513061523, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.012294216081500053, 'loss_2': 0.005859375, 'loss_3': -16.508638381958008, 'loss_4': 0.21848469972610474, 'epoch': 20.66}
{'loss': 0.0087, 'grad_norm': 8.519318580627441, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.007831382565200329, 'loss_2': 0.0009074211120605469, 'loss_3': -16.346181869506836, 'loss_4': -0.0044242143630981445, 'epoch': 20.66}
{'loss': 0.0034, 'grad_norm': 5.05410623550415, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.002748252125456929, 'loss_2': 0.000690460205078125, 'loss_3': -16.634973526000977, 'loss_4': 0.35333794355392456, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 13:47:57,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:57,526 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:51<27:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:04,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014440958388149738, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010943356901407242, 'eval_loss_2': 0.003497600555419922, 'eval_loss_3': -18.238296508789062, 'eval_loss_4': 0.10720844566822052, 'epoch': 20.67}
{'loss': 0.0115, 'grad_norm': 4.909793376922607, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.0052782525308430195, 'loss_2': 0.006259918212890625, 'loss_3': -16.473552703857422, 'loss_4': 0.0239675622433424, 'epoch': 20.67}
{'loss': 0.0119, 'grad_norm': 6.366992950439453, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.008403817191720009, 'loss_2': 0.0035343170166015625, 'loss_3': -16.50055694580078, 'loss_4': 0.14214113354682922, 'epoch': 20.68}
{'loss': 0.0071, 'grad_norm': 4.739097595214844, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.004636464640498161, 'loss_2': 0.002437591552734375, 'loss_3': -16.432844161987305, 'loss_4': 0.35262006521224976, 'epoch': 20.69}
{'loss': 0.0072, 'grad_norm': 5.1271443367004395, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.006483342964202166, 'loss_2': 0.0007171630859375, 'loss_3': -16.241485595703125, 'loss_4': -0.07646305859088898, 'epoch': 20.69}
{'loss': 0.0062, 'grad_norm': 4.531264781951904, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.004668354522436857, 'loss_2': 0.0015535354614257812, 'loss_3': -16.35733413696289, 'loss_4': 0.38908177614212036, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 13:48:04,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:04,871 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:59<27:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:12,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015320507809519768, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011442151851952076, 'eval_loss_2': 0.003878355026245117, 'eval_loss_3': -18.249195098876953, 'eval_loss_4': 0.13902361690998077, 'epoch': 20.7}
{'loss': 0.0091, 'grad_norm': 8.44930648803711, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.008440679870545864, 'loss_2': 0.0006227493286132812, 'loss_3': -16.33063507080078, 'loss_4': 0.044323161244392395, 'epoch': 20.7}
{'loss': 0.007, 'grad_norm': 5.284862518310547, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.005691721104085445, 'loss_2': 0.00125885009765625, 'loss_3': -16.431032180786133, 'loss_4': 0.4790240526199341, 'epoch': 20.71}
{'loss': 0.0194, 'grad_norm': 8.789917945861816, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.013358285650610924, 'loss_2': 0.006031036376953125, 'loss_3': -16.39371109008789, 'loss_4': 0.4169958829879761, 'epoch': 20.72}
{'loss': 0.0071, 'grad_norm': 4.717319965362549, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.002540106885135174, 'loss_2': 0.00457763671875, 'loss_3': -16.334922790527344, 'loss_4': -0.08645416051149368, 'epoch': 20.72}
{'loss': 0.0167, 'grad_norm': 11.715906143188477, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.01260011363774538, 'loss_2': 0.004116058349609375, 'loss_3': -16.42249298095703, 'loss_4': 0.38946232199668884, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 13:48:12,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:12,214 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:28:06<27:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:19,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01625584438443184, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011813093908131123, 'eval_loss_2': 0.004442751407623291, 'eval_loss_3': -18.232728958129883, 'eval_loss_4': 0.13691584765911102, 'epoch': 20.73}
{'loss': 0.0094, 'grad_norm': 5.856266498565674, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.005437952931970358, 'loss_2': 0.003936767578125, 'loss_3': -16.336023330688477, 'loss_4': 0.10008066892623901, 'epoch': 20.73}
{'loss': 0.0075, 'grad_norm': 5.0629048347473145, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.0036885368172079325, 'loss_2': 0.0037841796875, 'loss_3': -16.24933624267578, 'loss_4': 0.11205843091011047, 'epoch': 20.74}
{'loss': 0.0148, 'grad_norm': 6.755037784576416, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.00929965265095234, 'loss_2': 0.00550079345703125, 'loss_3': -16.321224212646484, 'loss_4': 0.3346010744571686, 'epoch': 20.74}
{'loss': 0.0212, 'grad_norm': 4.341640949249268, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.004983054008334875, 'loss_2': 0.01617431640625, 'loss_3': -16.409975051879883, 'loss_4': 0.17415353655815125, 'epoch': 20.75}
{'loss': 0.004, 'grad_norm': 4.252549648284912, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.0029547421727329493, 'loss_2': 0.0010242462158203125, 'loss_3': -16.411724090576172, 'loss_4': 0.28581875562667847, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 13:48:19,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:19,567 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:13<27:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:26,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017279131338000298, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.807, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012318683788180351, 'eval_loss_2': 0.004960447549819946, 'eval_loss_3': -18.207921981811523, 'eval_loss_4': 0.10379272699356079, 'epoch': 20.76}
{'loss': 0.0113, 'grad_norm': 5.225092887878418, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.0048222714103758335, 'loss_2': 0.006439208984375, 'loss_3': -16.359392166137695, 'loss_4': -0.29288268089294434, 'epoch': 20.76}
{'loss': 0.0113, 'grad_norm': 5.353736400604248, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.005726311355829239, 'loss_2': 0.00559234619140625, 'loss_3': -16.441814422607422, 'loss_4': 0.050056591629981995, 'epoch': 20.77}
{'loss': 0.0058, 'grad_norm': 4.8691534996032715, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.005804105196148157, 'loss_2': 2.372264862060547e-05, 'loss_3': -16.328664779663086, 'loss_4': -0.1712900847196579, 'epoch': 20.77}
{'loss': 0.0134, 'grad_norm': 8.220510482788086, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.007706278003752232, 'loss_2': 0.0056915283203125, 'loss_3': -16.30321502685547, 'loss_4': 0.5449276566505432, 'epoch': 20.78}
{'loss': 0.0124, 'grad_norm': 5.054562091827393, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.007553631905466318, 'loss_2': 0.0048675537109375, 'loss_3': -16.56077003479004, 'loss_4': 0.23631706833839417, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 13:48:26,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:26,919 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:21<27:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:34,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01803268864750862, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013092835433781147, 'eval_loss_2': 0.004939854145050049, 'eval_loss_3': -18.206554412841797, 'eval_loss_4': 0.20070727169513702, 'epoch': 20.78}
{'loss': 0.0039, 'grad_norm': 4.440335750579834, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.0031943100038915873, 'loss_2': 0.0007004737854003906, 'loss_3': -16.282047271728516, 'loss_4': 0.32972991466522217, 'epoch': 20.79}
{'loss': 0.0073, 'grad_norm': 4.417891502380371, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.005124228075146675, 'loss_2': 0.0021343231201171875, 'loss_3': -16.326087951660156, 'loss_4': 0.16802260279655457, 'epoch': 20.8}
{'loss': 0.0085, 'grad_norm': 4.83363151550293, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.004405122250318527, 'loss_2': 0.00409698486328125, 'loss_3': -16.29911231994629, 'loss_4': 0.4579457640647888, 'epoch': 20.8}
{'loss': 0.0173, 'grad_norm': 35.627838134765625, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.015846168622374535, 'loss_2': 0.0014495849609375, 'loss_3': -16.189605712890625, 'loss_4': 0.24100537598133087, 'epoch': 20.81}
{'loss': 0.0101, 'grad_norm': 6.466338157653809, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.007623099721968174, 'loss_2': 0.00250244140625, 'loss_3': -16.497894287109375, 'loss_4': 0.0615890808403492, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 13:48:34,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:34,256 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:28<27:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:41,594 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01754743605852127, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.315, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013476437889039516, 'eval_loss_2': 0.00407099723815918, 'eval_loss_3': -18.22161865234375, 'eval_loss_4': 0.26682066917419434, 'epoch': 20.81}
{'loss': 0.0065, 'grad_norm': 4.081493854522705, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.0034275997895747423, 'loss_2': 0.0030651092529296875, 'loss_3': -16.498395919799805, 'loss_4': 0.5805597305297852, 'epoch': 20.82}
{'loss': 0.0034, 'grad_norm': 5.040423393249512, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.0032594306394457817, 'loss_2': 0.00011074542999267578, 'loss_3': -16.259267807006836, 'loss_4': 0.2764682173728943, 'epoch': 20.83}
{'loss': 0.0067, 'grad_norm': 4.593686580657959, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.005881143268197775, 'loss_2': 0.0007715225219726562, 'loss_3': -16.43141746520996, 'loss_4': 0.17439430952072144, 'epoch': 20.83}
{'loss': 0.0151, 'grad_norm': 5.214359283447266, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.0066528720781207085, 'loss_2': 0.008453369140625, 'loss_3': -16.479156494140625, 'loss_4': 0.11210362613201141, 'epoch': 20.84}
{'loss': 0.0142, 'grad_norm': 4.578118324279785, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.0029432205483317375, 'loss_2': 0.0113067626953125, 'loss_3': -16.157615661621094, 'loss_4': 0.44158297777175903, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 13:48:41,594 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:41,594 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:36<27:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:48,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017325609922409058, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013715445064008236, 'eval_loss_2': 0.003610163927078247, 'eval_loss_3': -18.218290328979492, 'eval_loss_4': 0.30519768595695496, 'epoch': 20.84}
{'loss': 0.0052, 'grad_norm': 4.234402179718018, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.001525983097963035, 'loss_2': 0.0036907196044921875, 'loss_3': -16.556514739990234, 'loss_4': 0.3539597988128662, 'epoch': 20.85}
{'loss': 0.0172, 'grad_norm': 5.804140090942383, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.009358816780149937, 'loss_2': 0.007801055908203125, 'loss_3': -16.151525497436523, 'loss_4': 0.4663597643375397, 'epoch': 20.85}
{'loss': 0.0168, 'grad_norm': 5.947174072265625, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.01119238417595625, 'loss_2': 0.0056304931640625, 'loss_3': -16.346912384033203, 'loss_4': 0.3174455761909485, 'epoch': 20.86}
{'loss': 0.0069, 'grad_norm': 4.7693963050842285, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.005585306324064732, 'loss_2': 0.0013408660888671875, 'loss_3': -16.462421417236328, 'loss_4': 0.10964906215667725, 'epoch': 20.87}
{'loss': 0.0116, 'grad_norm': 5.170162200927734, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.006500186398625374, 'loss_2': 0.00506591796875, 'loss_3': -16.441829681396484, 'loss_4': 0.1466211974620819, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 13:48:48,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:48,937 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:43<27:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:56,274 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017507918179035187, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.626, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013642411679029465, 'eval_loss_2': 0.0038655102252960205, 'eval_loss_3': -18.214374542236328, 'eval_loss_4': 0.3757418096065521, 'epoch': 20.87}
{'loss': 0.0115, 'grad_norm': 4.853358745574951, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.0045112185180187225, 'loss_2': 0.00701141357421875, 'loss_3': -16.353179931640625, 'loss_4': 0.6947129964828491, 'epoch': 20.88}
{'loss': 0.0029, 'grad_norm': 4.358346462249756, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.002690574387088418, 'loss_2': 0.000247955322265625, 'loss_3': -16.408039093017578, 'loss_4': 0.44022315740585327, 'epoch': 20.88}
{'loss': 0.0184, 'grad_norm': 8.481498718261719, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.01568744145333767, 'loss_2': 0.0027065277099609375, 'loss_3': -16.305957794189453, 'loss_4': 0.6577221155166626, 'epoch': 20.89}
{'loss': 0.0098, 'grad_norm': 4.885128021240234, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.008164819329977036, 'loss_2': 0.0016765594482421875, 'loss_3': -16.204776763916016, 'loss_4': 0.8056105375289917, 'epoch': 20.9}
{'loss': 0.0086, 'grad_norm': 4.691318035125732, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.0031218717340379953, 'loss_2': 0.00547027587890625, 'loss_3': -16.064531326293945, 'loss_4': 0.5898507237434387, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 13:48:56,274 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:56,274 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:50<26:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:03,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019339246675372124, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01554036047309637, 'eval_loss_2': 0.0037988871335983276, 'eval_loss_3': -18.204240798950195, 'eval_loss_4': 0.49943122267723083, 'epoch': 20.9}
{'loss': 0.0079, 'grad_norm': 4.808279037475586, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.00501996697857976, 'loss_2': 0.002895355224609375, 'loss_3': -16.2448673248291, 'loss_4': 0.6412373185157776, 'epoch': 20.91}
{'loss': 0.0086, 'grad_norm': 6.064260959625244, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.008590586483478546, 'loss_2': 9.655952453613281e-06, 'loss_3': -16.205821990966797, 'loss_4': 0.7224646806716919, 'epoch': 20.91}
{'loss': 0.0111, 'grad_norm': 4.728224277496338, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.004999664146453142, 'loss_2': 0.0061187744140625, 'loss_3': -16.397293090820312, 'loss_4': 0.16359129548072815, 'epoch': 20.92}
{'loss': 0.0112, 'grad_norm': 4.2175445556640625, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.003733332036063075, 'loss_2': 0.00745391845703125, 'loss_3': -16.29726791381836, 'loss_4': 0.6409927010536194, 'epoch': 20.92}
{'loss': 0.0117, 'grad_norm': 10.290120124816895, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.010944221168756485, 'loss_2': 0.00077056884765625, 'loss_3': -16.306358337402344, 'loss_4': 0.3174598515033722, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 13:49:03,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:03,623 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:58<26:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:10,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018699416890740395, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015596759505569935, 'eval_loss_2': 0.0031026601791381836, 'eval_loss_3': -18.208995819091797, 'eval_loss_4': 0.6171040534973145, 'epoch': 20.93}
{'loss': 0.0072, 'grad_norm': 5.7713823318481445, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.0038454572204500437, 'loss_2': 0.0033321380615234375, 'loss_3': -16.25006866455078, 'loss_4': 0.5031726360321045, 'epoch': 20.94}
{'loss': 0.0063, 'grad_norm': 4.5024027824401855, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.004301339387893677, 'loss_2': 0.001956939697265625, 'loss_3': -16.5277099609375, 'loss_4': 0.9535911083221436, 'epoch': 20.94}
{'loss': 0.0101, 'grad_norm': 4.897241115570068, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.00782407633960247, 'loss_2': 0.002262115478515625, 'loss_3': -16.284502029418945, 'loss_4': 0.5134093761444092, 'epoch': 20.95}
{'loss': 0.016, 'grad_norm': 4.748109817504883, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.005565170664340258, 'loss_2': 0.0104217529296875, 'loss_3': -16.65355682373047, 'loss_4': 0.7942413091659546, 'epoch': 20.95}
{'loss': 0.0176, 'grad_norm': 5.82848596572876, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.010152102448046207, 'loss_2': 0.007476806640625, 'loss_3': -16.257369995117188, 'loss_4': 0.5331954956054688, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 13:49:10,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:10,976 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:29:05<26:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:18,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019012287259101868, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.192, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01503690518438816, 'eval_loss_2': 0.003975383937358856, 'eval_loss_3': -18.220840454101562, 'eval_loss_4': 0.6140198707580566, 'epoch': 20.96}
{'loss': 0.0153, 'grad_norm': 5.081258773803711, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.004623224958777428, 'loss_2': 0.01068878173828125, 'loss_3': -16.324533462524414, 'loss_4': 0.5969693660736084, 'epoch': 20.97}
{'loss': 0.008, 'grad_norm': 5.254576206207275, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.005253081675618887, 'loss_2': 0.0027313232421875, 'loss_3': -16.320293426513672, 'loss_4': 0.3158986568450928, 'epoch': 20.97}
{'loss': 0.0213, 'grad_norm': 7.7334885597229, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.010971544310450554, 'loss_2': 0.0103607177734375, 'loss_3': -15.974932670593262, 'loss_4': 0.8800042271614075, 'epoch': 20.98}
{'loss': 0.009, 'grad_norm': 4.938663959503174, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.004921848885715008, 'loss_2': 0.00403594970703125, 'loss_3': -16.308244705200195, 'loss_4': 0.6831099987030029, 'epoch': 20.98}
{'loss': 0.0148, 'grad_norm': 6.25976037979126, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.011147672310471535, 'loss_2': 0.00363922119140625, 'loss_3': -16.195392608642578, 'loss_4': 0.4290783405303955, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 13:49:18,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:18,319 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:12<25:56,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:49:25,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017871180549263954, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014938297681510448, 'eval_loss_2': 0.0029328837990760803, 'eval_loss_3': -18.208555221557617, 'eval_loss_4': 0.5493069887161255, 'epoch': 20.99}
{'loss': 0.0133, 'grad_norm': 6.51478385925293, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.006267314776778221, 'loss_2': 0.0070037841796875, 'loss_3': -16.308374404907227, 'loss_4': 0.5758794546127319, 'epoch': 20.99}
{'loss': 0.002, 'grad_norm': 6.207300662994385, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.00191179767716676, 'loss_2': 0.00011527538299560547, 'loss_3': -16.341556549072266, 'loss_4': 0.5324063301086426, 'epoch': 21.0}
{'loss': 0.0062, 'grad_norm': 4.608254909515381, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.004685143940150738, 'loss_2': 0.0015001296997070312, 'loss_3': -16.239395141601562, 'loss_4': 0.20590241253376007, 'epoch': 21.01}
{'loss': 0.0178, 'grad_norm': 8.530084609985352, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.010594809427857399, 'loss_2': 0.00719451904296875, 'loss_3': -16.304668426513672, 'loss_4': 0.42361295223236084, 'epoch': 21.01}
{'loss': 0.0082, 'grad_norm': 4.168678283691406, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.0048387316055595875, 'loss_2': 0.00341033935546875, 'loss_3': -16.44011116027832, 'loss_4': 0.7986003160476685, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 13:49:25,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:25,348 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:19<26:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:32,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019116098061203957, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015420462004840374, 'eval_loss_2': 0.0036956369876861572, 'eval_loss_3': -18.20891761779785, 'eval_loss_4': 0.5187655687332153, 'epoch': 21.02}
{'loss': 0.0063, 'grad_norm': 4.516268253326416, 'learning_rate': 9e-06, 'loss_1': 0.004508200567215681, 'loss_2': 0.001773834228515625, 'loss_3': -16.284496307373047, 'loss_4': 0.3620851933956146, 'epoch': 21.02}
{'loss': 0.0115, 'grad_norm': 4.329784393310547, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.005021987482905388, 'loss_2': 0.0064849853515625, 'loss_3': -16.470077514648438, 'loss_4': 0.39564114809036255, 'epoch': 21.03}
{'loss': 0.0067, 'grad_norm': 4.365726470947266, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.003358161775395274, 'loss_2': 0.003376007080078125, 'loss_3': -16.319168090820312, 'loss_4': 0.39288750290870667, 'epoch': 21.03}
{'loss': 0.0127, 'grad_norm': 4.847790718078613, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.00886336900293827, 'loss_2': 0.003879547119140625, 'loss_3': -16.176576614379883, 'loss_4': 0.4699738025665283, 'epoch': 21.04}
{'loss': 0.0088, 'grad_norm': 5.006247520446777, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.005745100788772106, 'loss_2': 0.003070831298828125, 'loss_3': -16.38613510131836, 'loss_4': 0.44938477873802185, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 13:49:32,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:32,712 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:27<26:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:40,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01893230527639389, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014949825592339039, 'eval_loss_2': 0.003982476890087128, 'eval_loss_3': -18.221939086914062, 'eval_loss_4': 0.48637866973876953, 'epoch': 21.05}
{'loss': 0.011, 'grad_norm': 4.985854625701904, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.008782084099948406, 'loss_2': 0.0022220611572265625, 'loss_3': -16.301427841186523, 'loss_4': 0.6197755336761475, 'epoch': 21.05}
{'loss': 0.0125, 'grad_norm': 6.859391212463379, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.011764864437282085, 'loss_2': 0.0007238388061523438, 'loss_3': -16.63250732421875, 'loss_4': 0.31013041734695435, 'epoch': 21.06}
{'loss': 0.0131, 'grad_norm': 5.518378257751465, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.007066406775265932, 'loss_2': 0.0060577392578125, 'loss_3': -16.324064254760742, 'loss_4': 0.6533055305480957, 'epoch': 21.06}
{'loss': 0.0085, 'grad_norm': 5.029837131500244, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.003381121437996626, 'loss_2': 0.005157470703125, 'loss_3': -16.309452056884766, 'loss_4': 0.3934348225593567, 'epoch': 21.07}
{'loss': 0.0203, 'grad_norm': 5.938774108886719, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.018906155601143837, 'loss_2': 0.0013885498046875, 'loss_3': -16.24051284790039, 'loss_4': 0.49042537808418274, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 13:49:40,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:40,072 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:34<26:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:47,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018576620146632195, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.205, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.015245645307004452, 'eval_loss_2': 0.0033309757709503174, 'eval_loss_3': -18.204286575317383, 'eval_loss_4': 0.3828689455986023, 'epoch': 21.08}
{'loss': 0.0072, 'grad_norm': 4.42901611328125, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.004693522583693266, 'loss_2': 0.002536773681640625, 'loss_3': -16.345149993896484, 'loss_4': 0.17020875215530396, 'epoch': 21.08}
{'loss': 0.0111, 'grad_norm': 4.826776027679443, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.009417985565960407, 'loss_2': 0.0016908645629882812, 'loss_3': -16.22380828857422, 'loss_4': 0.5701207518577576, 'epoch': 21.09}
{'loss': 0.006, 'grad_norm': 4.403811454772949, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.004314288031309843, 'loss_2': 0.001735687255859375, 'loss_3': -16.400121688842773, 'loss_4': 0.32019123435020447, 'epoch': 21.09}
{'loss': 0.0146, 'grad_norm': 6.585065841674805, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.011938432231545448, 'loss_2': 0.00261688232421875, 'loss_3': -16.459129333496094, 'loss_4': 0.4910598397254944, 'epoch': 21.1}
{'loss': 0.0123, 'grad_norm': 5.318821907043457, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.007133837323635817, 'loss_2': 0.00516510009765625, 'loss_3': -16.150859832763672, 'loss_4': 0.6125511527061462, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 13:49:47,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:47,430 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:41<26:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:54,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02072026953101158, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017632659524679184, 'eval_loss_2': 0.0030876100063323975, 'eval_loss_3': -18.171852111816406, 'eval_loss_4': 0.36793822050094604, 'epoch': 21.1}
{'loss': 0.0574, 'grad_norm': 10.433876037597656, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.05634398013353348, 'loss_2': 0.001041412353515625, 'loss_3': -16.385482788085938, 'loss_4': 0.9324616193771362, 'epoch': 21.11}
{'loss': 0.0149, 'grad_norm': 5.764952659606934, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.008736737072467804, 'loss_2': 0.00615692138671875, 'loss_3': -16.328174591064453, 'loss_4': 0.4142646789550781, 'epoch': 21.12}
{'loss': 0.0101, 'grad_norm': 4.595885276794434, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.004842494614422321, 'loss_2': 0.00521087646484375, 'loss_3': -16.366107940673828, 'loss_4': 0.5161296725273132, 'epoch': 21.12}
{'loss': 0.0115, 'grad_norm': 3.999666452407837, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.002935051452368498, 'loss_2': 0.00856781005859375, 'loss_3': -16.457714080810547, 'loss_4': 0.1556786596775055, 'epoch': 21.13}
{'loss': 0.0046, 'grad_norm': 4.720272541046143, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.004278581123799086, 'loss_2': 0.0002765655517578125, 'loss_3': -16.440441131591797, 'loss_4': 0.2592398524284363, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 13:49:54,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:54,784 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:49<26:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:02,126 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022679196670651436, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01932642236351967, 'eval_loss_2': 0.0033527761697769165, 'eval_loss_3': -18.154380798339844, 'eval_loss_4': 0.33147376775741577, 'epoch': 21.13}
{'loss': 0.0092, 'grad_norm': 5.076473712921143, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.007537374272942543, 'loss_2': 0.0016880035400390625, 'loss_3': -16.455751419067383, 'loss_4': 0.4210278391838074, 'epoch': 21.14}
{'loss': 0.0056, 'grad_norm': 5.061563968658447, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.004423512611538172, 'loss_2': 0.0011320114135742188, 'loss_3': -16.252300262451172, 'loss_4': 0.6289994120597839, 'epoch': 21.15}
{'loss': 0.0134, 'grad_norm': 4.873148441314697, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.009161600843071938, 'loss_2': 0.00421142578125, 'loss_3': -16.09542465209961, 'loss_4': 0.25703635811805725, 'epoch': 21.15}
{'loss': 0.016, 'grad_norm': 5.886016368865967, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.011685766279697418, 'loss_2': 0.00433349609375, 'loss_3': -16.38369369506836, 'loss_4': 0.5220041871070862, 'epoch': 21.16}
{'loss': 0.0066, 'grad_norm': 4.91022253036499, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.0058274781331419945, 'loss_2': 0.00079345703125, 'loss_3': -16.254507064819336, 'loss_4': 0.29448366165161133, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 13:50:02,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:02,127 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:56<26:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:09,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023956310003995895, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.529, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.019934633746743202, 'eval_loss_2': 0.004021674394607544, 'eval_loss_3': -18.15012550354004, 'eval_loss_4': 0.3344121277332306, 'epoch': 21.16}
{'loss': 0.011, 'grad_norm': 4.912421703338623, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.003276295494288206, 'loss_2': 0.00775146484375, 'loss_3': -16.446308135986328, 'loss_4': 0.32235580682754517, 'epoch': 21.17}
{'loss': 0.0149, 'grad_norm': 4.874875068664551, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.008603429421782494, 'loss_2': 0.0063018798828125, 'loss_3': -16.46689224243164, 'loss_4': 0.16800861060619354, 'epoch': 21.17}
{'loss': 0.0064, 'grad_norm': 4.645590782165527, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.0023669779766350985, 'loss_2': 0.004058837890625, 'loss_3': -16.542917251586914, 'loss_4': 0.2039148062467575, 'epoch': 21.18}
{'loss': 0.0037, 'grad_norm': 4.9636759757995605, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.002786385826766491, 'loss_2': 0.0009222030639648438, 'loss_3': -16.476932525634766, 'loss_4': 0.3248595595359802, 'epoch': 21.19}
{'loss': 0.0066, 'grad_norm': 4.9192938804626465, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.005588489584624767, 'loss_2': 0.0010204315185546875, 'loss_3': -16.400409698486328, 'loss_4': 0.2983808219432831, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 13:50:09,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:09,473 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:03<26:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:16,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024207253009080887, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.020522328093647957, 'eval_loss_2': 0.0036849230527877808, 'eval_loss_3': -18.153076171875, 'eval_loss_4': 0.2514396905899048, 'epoch': 21.19}
{'loss': 0.0078, 'grad_norm': 4.790522575378418, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.004179089795798063, 'loss_2': 0.003631591796875, 'loss_3': -16.437158584594727, 'loss_4': 0.5959303975105286, 'epoch': 21.2}
{'loss': 0.0131, 'grad_norm': 5.436864852905273, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.012734539806842804, 'loss_2': 0.0004086494445800781, 'loss_3': -16.22243881225586, 'loss_4': 0.04547525942325592, 'epoch': 21.2}
{'loss': 0.0372, 'grad_norm': 14.041473388671875, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.028144311159849167, 'loss_2': 0.00909423828125, 'loss_3': -16.222150802612305, 'loss_4': 0.42655912041664124, 'epoch': 21.21}
{'loss': 0.0051, 'grad_norm': 4.5184407234191895, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.003953579347580671, 'loss_2': 0.0011501312255859375, 'loss_3': -16.24311065673828, 'loss_4': 0.3655756413936615, 'epoch': 21.22}
{'loss': 0.0172, 'grad_norm': 6.154174327850342, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.006892112083733082, 'loss_2': 0.01032257080078125, 'loss_3': -16.397409439086914, 'loss_4': -0.018930114805698395, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 13:50:16,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:16,815 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:11<26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:24,167 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025705449283123016, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.022246718406677246, 'eval_loss_2': 0.0034587308764457703, 'eval_loss_3': -18.145408630371094, 'eval_loss_4': 0.16207782924175262, 'epoch': 21.22}
{'loss': 0.0099, 'grad_norm': 4.888132095336914, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.005406781565397978, 'loss_2': 0.00449371337890625, 'loss_3': -16.155052185058594, 'loss_4': -0.2948610186576843, 'epoch': 21.23}
{'loss': 0.0063, 'grad_norm': 4.184247970581055, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.0024955582339316607, 'loss_2': 0.003810882568359375, 'loss_3': -16.52275848388672, 'loss_4': -0.22669202089309692, 'epoch': 21.23}
{'loss': 0.015, 'grad_norm': 9.866250038146973, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.010560965165495872, 'loss_2': 0.004398345947265625, 'loss_3': -16.157350540161133, 'loss_4': -0.112297423183918, 'epoch': 21.24}
{'loss': 0.013, 'grad_norm': 6.657978057861328, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.012330443598330021, 'loss_2': 0.000675201416015625, 'loss_3': -16.444652557373047, 'loss_4': -0.09966481477022171, 'epoch': 21.24}
{'loss': 0.0152, 'grad_norm': 9.243388175964355, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.014022973366081715, 'loss_2': 0.0011348724365234375, 'loss_3': -16.393470764160156, 'loss_4': 0.022493988275527954, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 13:50:24,167 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:24,167 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:18<25:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:31,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026985662057995796, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02334021031856537, 'eval_loss_2': 0.0036454498767852783, 'eval_loss_3': -18.115785598754883, 'eval_loss_4': 0.10590653121471405, 'epoch': 21.25}
{'loss': 0.0057, 'grad_norm': 4.546236515045166, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.004294119775295258, 'loss_2': 0.001377105712890625, 'loss_3': -16.55656623840332, 'loss_4': 0.08212174475193024, 'epoch': 21.26}
{'loss': 0.0095, 'grad_norm': 5.732269287109375, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.006858387961983681, 'loss_2': 0.002685546875, 'loss_3': -16.1768798828125, 'loss_4': 0.146234929561615, 'epoch': 21.26}
{'loss': 0.0042, 'grad_norm': 4.548663139343262, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.003089026315137744, 'loss_2': 0.0011501312255859375, 'loss_3': -16.32845115661621, 'loss_4': -0.28476086258888245, 'epoch': 21.27}
{'loss': 0.0186, 'grad_norm': 5.391014575958252, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.011273471638560295, 'loss_2': 0.007335662841796875, 'loss_3': -16.415084838867188, 'loss_4': 0.2622525990009308, 'epoch': 21.27}
{'loss': 0.0186, 'grad_norm': 5.443995475769043, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.011094789952039719, 'loss_2': 0.007534027099609375, 'loss_3': -16.45163345336914, 'loss_4': -0.13019397854804993, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 13:50:31,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:31,509 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:25<25:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:38,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028277887031435966, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.024137748405337334, 'eval_loss_2': 0.004140138626098633, 'eval_loss_3': -18.10097885131836, 'eval_loss_4': 0.020386844873428345, 'epoch': 21.28}
{'loss': 0.0143, 'grad_norm': 7.6691060066223145, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.012104060500860214, 'loss_2': 0.002166748046875, 'loss_3': -16.39600372314453, 'loss_4': -0.2590920925140381, 'epoch': 21.28}
{'loss': 0.0195, 'grad_norm': 9.157755851745605, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.01772022247314453, 'loss_2': 0.0017633438110351562, 'loss_3': -16.293100357055664, 'loss_4': 0.23795659840106964, 'epoch': 21.29}
{'loss': 0.0078, 'grad_norm': 4.547891616821289, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.0036079396959394217, 'loss_2': 0.004184722900390625, 'loss_3': -16.302650451660156, 'loss_4': 0.1983211487531662, 'epoch': 21.3}
{'loss': 0.0099, 'grad_norm': 5.496746063232422, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.009677140042185783, 'loss_2': 0.00019657611846923828, 'loss_3': -16.24779510498047, 'loss_4': -0.21557670831680298, 'epoch': 21.3}
{'loss': 0.0045, 'grad_norm': 4.410457611083984, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0033833603374660015, 'loss_2': 0.0011568069458007812, 'loss_3': -16.27985382080078, 'loss_4': 0.14879225194454193, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 13:50:38,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:38,851 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:33<25:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:46,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033925510942935944, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.331, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02989872358739376, 'eval_loss_2': 0.004026792943477631, 'eval_loss_3': -18.075637817382812, 'eval_loss_4': 0.022737767547369003, 'epoch': 21.31}
{'loss': 0.014, 'grad_norm': 4.6584062576293945, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.009301797486841679, 'loss_2': 0.00466156005859375, 'loss_3': -16.194866180419922, 'loss_4': -0.09899070858955383, 'epoch': 21.31}
{'loss': 0.006, 'grad_norm': 4.792766571044922, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.004999568220227957, 'loss_2': 0.0009832382202148438, 'loss_3': -16.417224884033203, 'loss_4': 0.32250621914863586, 'epoch': 21.32}
{'loss': 0.0072, 'grad_norm': 5.673931121826172, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.006415823474526405, 'loss_2': 0.0007944107055664062, 'loss_3': -16.300823211669922, 'loss_4': 0.1992877721786499, 'epoch': 21.33}
{'loss': 0.0118, 'grad_norm': 6.0959930419921875, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.008686250075697899, 'loss_2': 0.003131866455078125, 'loss_3': -16.405323028564453, 'loss_4': -0.005196195095777512, 'epoch': 21.33}
{'loss': 0.0056, 'grad_norm': 4.641420364379883, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.004810899496078491, 'loss_2': 0.00075531005859375, 'loss_3': -16.345752716064453, 'loss_4': 0.18250218033790588, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 13:50:46,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:46,198 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:40<25:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:53,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03218241035938263, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.667, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02855352871119976, 'eval_loss_2': 0.0036288797855377197, 'eval_loss_3': -18.054840087890625, 'eval_loss_4': -0.03873646631836891, 'epoch': 21.34}
{'loss': 0.0182, 'grad_norm': 9.671687126159668, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.016637194901704788, 'loss_2': 0.0015239715576171875, 'loss_3': -16.392536163330078, 'loss_4': -0.24228012561798096, 'epoch': 21.34}
{'loss': 0.0128, 'grad_norm': 6.151559829711914, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.009675955399870872, 'loss_2': 0.0031280517578125, 'loss_3': -16.374149322509766, 'loss_4': 0.10362853109836578, 'epoch': 21.35}
{'loss': 0.0082, 'grad_norm': 4.39102029800415, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.005657981149852276, 'loss_2': 0.0025005340576171875, 'loss_3': -16.114526748657227, 'loss_4': -0.1236429437994957, 'epoch': 21.35}
{'loss': 0.01, 'grad_norm': 4.520452976226807, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.0033095981925725937, 'loss_2': 0.00670623779296875, 'loss_3': -16.371917724609375, 'loss_4': -0.2723793387413025, 'epoch': 21.36}
{'loss': 0.0074, 'grad_norm': 5.165562152862549, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.004344400484114885, 'loss_2': 0.00310516357421875, 'loss_3': -16.606704711914062, 'loss_4': 0.29444512724876404, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 13:50:53,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:53,537 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:47<25:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:00,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0334923192858696, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.030031373724341393, 'eval_loss_2': 0.0034609436988830566, 'eval_loss_3': -18.0394229888916, 'eval_loss_4': -0.046771880239248276, 'epoch': 21.37}
{'loss': 0.0062, 'grad_norm': 4.690268039703369, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.004831794183701277, 'loss_2': 0.00135040283203125, 'loss_3': -16.482540130615234, 'loss_4': -0.7895734310150146, 'epoch': 21.37}
{'loss': 0.0103, 'grad_norm': 4.49795389175415, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.004422071855515242, 'loss_2': 0.005832672119140625, 'loss_3': -16.22518539428711, 'loss_4': -0.2592637836933136, 'epoch': 21.38}
{'loss': 0.011, 'grad_norm': 5.99681282043457, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.0072210365906357765, 'loss_2': 0.0037689208984375, 'loss_3': -16.487075805664062, 'loss_4': -0.49467504024505615, 'epoch': 21.38}
{'loss': 0.0047, 'grad_norm': 5.049264430999756, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.003815610194578767, 'loss_2': 0.0009307861328125, 'loss_3': -16.401416778564453, 'loss_4': 0.007467061281204224, 'epoch': 21.39}
{'loss': 0.0181, 'grad_norm': 6.920175075531006, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.013145862147212029, 'loss_2': 0.004913330078125, 'loss_3': -16.433170318603516, 'loss_4': 0.3307707905769348, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 13:51:00,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:00,885 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:55<25:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:08,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.044735707342624664, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.678, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.04165913537144661, 'eval_loss_2': 0.0030765682458877563, 'eval_loss_3': -18.01864242553711, 'eval_loss_4': -0.01408778503537178, 'epoch': 21.4}
{'loss': 0.0037, 'grad_norm': 4.639853000640869, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.003737593535333872, 'loss_2': 5.841255187988281e-06, 'loss_3': -16.278751373291016, 'loss_4': -0.07625551521778107, 'epoch': 21.4}
{'loss': 0.0083, 'grad_norm': 4.39622163772583, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.004706841427832842, 'loss_2': 0.003551483154296875, 'loss_3': -16.300094604492188, 'loss_4': -0.32760411500930786, 'epoch': 21.41}
{'loss': 0.0351, 'grad_norm': 18.85921859741211, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.029605478048324585, 'loss_2': 0.00548553466796875, 'loss_3': -16.27398681640625, 'loss_4': -0.25160402059555054, 'epoch': 21.41}
{'loss': 0.0103, 'grad_norm': 5.949837684631348, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.010290904901921749, 'loss_2': 4.118680953979492e-05, 'loss_3': -16.530902862548828, 'loss_4': -0.21176069974899292, 'epoch': 21.42}
{'loss': 0.0817, 'grad_norm': 27.365812301635742, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.07770971953868866, 'loss_2': 0.003993988037109375, 'loss_3': -16.203086853027344, 'loss_4': 0.09849078953266144, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 13:51:08,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:08,247 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:31:02<25:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:15,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04739147052168846, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.04435598850250244, 'eval_loss_2': 0.0030354857444763184, 'eval_loss_3': -18.011075973510742, 'eval_loss_4': -0.00016414280980825424, 'epoch': 21.42}
{'loss': 0.0088, 'grad_norm': 11.498047828674316, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.007771245203912258, 'loss_2': 0.0009975433349609375, 'loss_3': -16.305625915527344, 'loss_4': -0.29676952958106995, 'epoch': 21.43}
{'loss': 0.0124, 'grad_norm': 6.175421237945557, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.008195173926651478, 'loss_2': 0.004241943359375, 'loss_3': -16.04892921447754, 'loss_4': 0.13681679964065552, 'epoch': 21.44}
{'loss': 0.0059, 'grad_norm': 4.828885078430176, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.0027648627292364836, 'loss_2': 0.00310516357421875, 'loss_3': -16.339637756347656, 'loss_4': -0.03911291062831879, 'epoch': 21.44}
{'loss': 0.018, 'grad_norm': 6.214317798614502, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.012458361685276031, 'loss_2': 0.005523681640625, 'loss_3': -16.195140838623047, 'loss_4': 0.47432029247283936, 'epoch': 21.45}
{'loss': 0.019, 'grad_norm': 9.512622833251953, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.015696685761213303, 'loss_2': 0.0033054351806640625, 'loss_3': -16.427001953125, 'loss_4': 0.02256658673286438, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 13:51:15,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:15,588 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:09<25:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:22,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08013006299734116, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.07659135013818741, 'eval_loss_2': 0.0035387128591537476, 'eval_loss_3': -17.942142486572266, 'eval_loss_4': 0.06748013198375702, 'epoch': 21.45}
{'loss': 0.0079, 'grad_norm': 9.9685640335083, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.005956646054983139, 'loss_2': 0.001918792724609375, 'loss_3': -16.17431640625, 'loss_4': -0.27351829409599304, 'epoch': 21.46}
{'loss': 0.0119, 'grad_norm': 5.25815486907959, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.011050899513065815, 'loss_2': 0.0008215904235839844, 'loss_3': -16.505306243896484, 'loss_4': 0.12396196275949478, 'epoch': 21.47}
{'loss': 0.0178, 'grad_norm': 6.5593743324279785, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.012815877795219421, 'loss_2': 0.00495147705078125, 'loss_3': -16.498817443847656, 'loss_4': -0.24412837624549866, 'epoch': 21.47}
{'loss': 0.0123, 'grad_norm': 7.724734783172607, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.011393656954169273, 'loss_2': 0.0008716583251953125, 'loss_3': -16.282255172729492, 'loss_4': -0.19866831600666046, 'epoch': 21.48}
{'loss': 0.0467, 'grad_norm': 20.701711654663086, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.04079871252179146, 'loss_2': 0.00592041015625, 'loss_3': -16.41407012939453, 'loss_4': 0.07282346487045288, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 13:51:22,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:22,933 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:17<25:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:30,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.047814253717660904, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.04526520147919655, 'eval_loss_2': 0.0025490522384643555, 'eval_loss_3': -18.015913009643555, 'eval_loss_4': -0.0323866605758667, 'epoch': 21.48}
{'loss': 0.0138, 'grad_norm': 5.07290506362915, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.005478788632899523, 'loss_2': 0.00836181640625, 'loss_3': -16.407421112060547, 'loss_4': 0.10195724666118622, 'epoch': 21.49}
{'loss': 0.016, 'grad_norm': 5.64820671081543, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.014670384116470814, 'loss_2': 0.0013751983642578125, 'loss_3': -16.4559268951416, 'loss_4': 0.2139052152633667, 'epoch': 21.49}
{'loss': 0.0149, 'grad_norm': 10.238636016845703, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.009575881063938141, 'loss_2': 0.005313873291015625, 'loss_3': -16.277347564697266, 'loss_4': -0.3898918032646179, 'epoch': 21.5}
{'loss': 0.0104, 'grad_norm': 4.619185447692871, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.0039117177948355675, 'loss_2': 0.0065155029296875, 'loss_3': -16.29125213623047, 'loss_4': 0.0015622079372406006, 'epoch': 21.51}
{'loss': 0.0119, 'grad_norm': 5.81339693069458, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.008342789486050606, 'loss_2': 0.003520965576171875, 'loss_3': -16.383041381835938, 'loss_4': -0.2732332646846771, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 13:51:30,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:30,267 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:24<25:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:37,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02706388384103775, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.516, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02390357479453087, 'eval_loss_2': 0.0031603053212165833, 'eval_loss_3': -18.10812759399414, 'eval_loss_4': -0.18313582241535187, 'epoch': 21.51}
{'loss': 0.0064, 'grad_norm': 5.077025890350342, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.005314379930496216, 'loss_2': 0.0010919570922851562, 'loss_3': -16.18720245361328, 'loss_4': 0.28984102606773376, 'epoch': 21.52}
{'loss': 0.0085, 'grad_norm': 4.813779354095459, 'learning_rate': 8.5e-06, 'loss_1': 0.006905109155923128, 'loss_2': 0.001598358154296875, 'loss_3': -16.36688995361328, 'loss_4': -0.2647043764591217, 'epoch': 21.52}
{'loss': 0.0071, 'grad_norm': 4.541436672210693, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.006546035874634981, 'loss_2': 0.0005359649658203125, 'loss_3': -16.569398880004883, 'loss_4': -0.44012919068336487, 'epoch': 21.53}
{'loss': 0.0063, 'grad_norm': 4.237570762634277, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.004503540229052305, 'loss_2': 0.0018053054809570312, 'loss_3': -16.558950424194336, 'loss_4': -0.0914255902171135, 'epoch': 21.53}
{'loss': 0.0055, 'grad_norm': 4.501765251159668, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.0038164688739925623, 'loss_2': 0.001728057861328125, 'loss_3': -16.4277400970459, 'loss_4': -0.12204958498477936, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 13:51:37,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:37,610 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:32<25:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:44,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020876098424196243, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.097, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018335184082388878, 'eval_loss_2': 0.0025409162044525146, 'eval_loss_3': -18.143613815307617, 'eval_loss_4': -0.19078904390335083, 'epoch': 21.54}
{'loss': 0.0088, 'grad_norm': 4.366544246673584, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.004248608835041523, 'loss_2': 0.00457763671875, 'loss_3': -16.26906967163086, 'loss_4': -0.19220036268234253, 'epoch': 21.55}
{'loss': 0.0065, 'grad_norm': 5.307095050811768, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.005636746995151043, 'loss_2': 0.0009098052978515625, 'loss_3': -16.406421661376953, 'loss_4': 0.025883719325065613, 'epoch': 21.55}
{'loss': 0.0061, 'grad_norm': 5.0609259605407715, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.003921291790902615, 'loss_2': 0.00213623046875, 'loss_3': -16.423181533813477, 'loss_4': -0.08565046638250351, 'epoch': 21.56}
{'loss': 0.0084, 'grad_norm': 4.836554050445557, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.005180218257009983, 'loss_2': 0.00318145751953125, 'loss_3': -16.538557052612305, 'loss_4': -0.2955769896507263, 'epoch': 21.56}
{'loss': 0.0178, 'grad_norm': 4.262688636779785, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.007667883299291134, 'loss_2': 0.0101470947265625, 'loss_3': -16.421361923217773, 'loss_4': -0.1644742786884308, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 13:51:44,966 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:44,966 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:39<24:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:52,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01975031942129135, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01691361516714096, 'eval_loss_2': 0.0028367042541503906, 'eval_loss_3': -18.167638778686523, 'eval_loss_4': -0.12193185836076736, 'epoch': 21.57}
{'loss': 0.0095, 'grad_norm': 7.635015964508057, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.009096257388591766, 'loss_2': 0.00037932395935058594, 'loss_3': -16.221691131591797, 'loss_4': -0.08415137231349945, 'epoch': 21.58}
{'loss': 0.0076, 'grad_norm': 5.269989013671875, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.006779052317142487, 'loss_2': 0.0008459091186523438, 'loss_3': -16.513301849365234, 'loss_4': 0.20713365077972412, 'epoch': 21.58}
{'loss': 0.0069, 'grad_norm': 5.653765678405762, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.0058618150651454926, 'loss_2': 0.0010852813720703125, 'loss_3': -16.429649353027344, 'loss_4': 0.19893339276313782, 'epoch': 21.59}
{'loss': 0.0173, 'grad_norm': 7.908698081970215, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.011890582740306854, 'loss_2': 0.00539398193359375, 'loss_3': -16.450191497802734, 'loss_4': 0.05130627751350403, 'epoch': 21.59}
{'loss': 0.0776, 'grad_norm': 19.683969497680664, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.06419306993484497, 'loss_2': 0.01337432861328125, 'loss_3': -16.362537384033203, 'loss_4': 0.30561041831970215, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 13:51:52,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:52,304 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:46<24:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:59,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020556440576910973, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.016852818429470062, 'eval_loss_2': 0.0037036240100860596, 'eval_loss_3': -18.1622371673584, 'eval_loss_4': -0.054385706782341, 'epoch': 21.6}
{'loss': 0.0166, 'grad_norm': 4.824741363525391, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.006130638998001814, 'loss_2': 0.0104522705078125, 'loss_3': -16.523744583129883, 'loss_4': -0.025276869535446167, 'epoch': 21.6}
{'loss': 0.0116, 'grad_norm': 6.993634223937988, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.006931852083653212, 'loss_2': 0.0046844482421875, 'loss_3': -16.429304122924805, 'loss_4': 0.19411416351795197, 'epoch': 21.61}
{'loss': 0.0059, 'grad_norm': 5.022197246551514, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.004744529724121094, 'loss_2': 0.0011157989501953125, 'loss_3': -16.402429580688477, 'loss_4': -0.11116105318069458, 'epoch': 21.62}
{'loss': 0.0175, 'grad_norm': 8.35780143737793, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.01618928276002407, 'loss_2': 0.0013275146484375, 'loss_3': -16.292491912841797, 'loss_4': -0.6053305864334106, 'epoch': 21.62}
{'loss': 0.0095, 'grad_norm': 4.625506401062012, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.0034603208769112825, 'loss_2': 0.00604248046875, 'loss_3': -16.407459259033203, 'loss_4': -0.10060607641935349, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 13:51:59,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:59,647 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:54<24:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:06,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019893597811460495, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.682, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0167752206325531, 'eval_loss_2': 0.003118373453617096, 'eval_loss_3': -18.171836853027344, 'eval_loss_4': -0.07756715267896652, 'epoch': 21.63}
{'loss': 0.0081, 'grad_norm': 5.503765106201172, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.007055915892124176, 'loss_2': 0.001041412353515625, 'loss_3': -16.28050422668457, 'loss_4': 0.018599282950162888, 'epoch': 21.63}
{'loss': 0.0084, 'grad_norm': 5.315857887268066, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.005943612661212683, 'loss_2': 0.00250244140625, 'loss_3': -16.258197784423828, 'loss_4': 0.42073923349380493, 'epoch': 21.64}
{'loss': 0.0161, 'grad_norm': 5.326877117156982, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.011741037480533123, 'loss_2': 0.0043792724609375, 'loss_3': -16.217493057250977, 'loss_4': -0.4078150987625122, 'epoch': 21.65}
{'loss': 0.0137, 'grad_norm': 5.480175971984863, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.007918759249150753, 'loss_2': 0.00579833984375, 'loss_3': -16.27042579650879, 'loss_4': -0.2773495316505432, 'epoch': 21.65}
{'loss': 0.0108, 'grad_norm': 6.136440277099609, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.008285622112452984, 'loss_2': 0.00247955322265625, 'loss_3': -16.258899688720703, 'loss_4': 0.0337713360786438, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 13:52:06,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:06,980 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:32:01<24:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:14,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020941995084285736, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017395125702023506, 'eval_loss_2': 0.003546871244907379, 'eval_loss_3': -18.19120979309082, 'eval_loss_4': -0.11392298340797424, 'epoch': 21.66}
{'loss': 0.0232, 'grad_norm': 9.352947235107422, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.015925735235214233, 'loss_2': 0.007274627685546875, 'loss_3': -16.3884220123291, 'loss_4': -0.16197989881038666, 'epoch': 21.66}
{'loss': 0.0117, 'grad_norm': 5.36166524887085, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.009759019128978252, 'loss_2': 0.0019664764404296875, 'loss_3': -16.329378128051758, 'loss_4': 0.2985772490501404, 'epoch': 21.67}
{'loss': 0.0112, 'grad_norm': 5.246421813964844, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.007722212467342615, 'loss_2': 0.003505706787109375, 'loss_3': -16.350374221801758, 'loss_4': -0.29596054553985596, 'epoch': 21.67}
{'loss': 0.0063, 'grad_norm': 4.876097202301025, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.004460693337023258, 'loss_2': 0.001804351806640625, 'loss_3': -16.46385383605957, 'loss_4': -0.05539489537477493, 'epoch': 21.68}
{'loss': 0.0077, 'grad_norm': 4.520167350769043, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.005432243458926678, 'loss_2': 0.002246856689453125, 'loss_3': -16.310420989990234, 'loss_4': -0.06787335872650146, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 13:52:14,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:14,324 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:08<24:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:21,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01981186494231224, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015478847548365593, 'eval_loss_2': 0.004333019256591797, 'eval_loss_3': -18.20125389099121, 'eval_loss_4': -0.2150668352842331, 'epoch': 21.69}
{'loss': 0.0105, 'grad_norm': 5.258139610290527, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.003517202567309141, 'loss_2': 0.00698089599609375, 'loss_3': -16.464509963989258, 'loss_4': -0.1898098886013031, 'epoch': 21.69}
{'loss': 0.0102, 'grad_norm': 5.087596893310547, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.007911179214715958, 'loss_2': 0.0023365020751953125, 'loss_3': -16.319236755371094, 'loss_4': -0.46363818645477295, 'epoch': 21.7}
{'loss': 0.0159, 'grad_norm': 5.945248126983643, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.007757577113807201, 'loss_2': 0.00818634033203125, 'loss_3': -16.439043045043945, 'loss_4': 0.05946850776672363, 'epoch': 21.7}
{'loss': 0.0131, 'grad_norm': 4.978771209716797, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.003972245380282402, 'loss_2': 0.0091094970703125, 'loss_3': -16.433177947998047, 'loss_4': -0.4019351005554199, 'epoch': 21.71}
{'loss': 0.0126, 'grad_norm': 5.263814449310303, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.005901745054870844, 'loss_2': 0.006725311279296875, 'loss_3': -16.560832977294922, 'loss_4': -0.2500019967556, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 13:52:21,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:21,674 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:16<24:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:29,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018077347427606583, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014557917602360249, 'eval_loss_2': 0.0035194307565689087, 'eval_loss_3': -18.2443904876709, 'eval_loss_4': -0.31007805466651917, 'epoch': 21.72}
{'loss': 0.0102, 'grad_norm': 5.395930290222168, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.007463508751243353, 'loss_2': 0.00278472900390625, 'loss_3': -16.266162872314453, 'loss_4': -0.6695957183837891, 'epoch': 21.72}
{'loss': 0.0075, 'grad_norm': 4.815160274505615, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.007487886119633913, 'loss_2': 2.205371856689453e-05, 'loss_3': -16.39771270751953, 'loss_4': -0.46867090463638306, 'epoch': 21.73}
{'loss': 0.0078, 'grad_norm': 4.689477920532227, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.004773339722305536, 'loss_2': 0.003017425537109375, 'loss_3': -16.25804901123047, 'loss_4': -0.3516213893890381, 'epoch': 21.73}
{'loss': 0.0357, 'grad_norm': 13.677957534790039, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.033049046993255615, 'loss_2': 0.0026702880859375, 'loss_3': -16.54950714111328, 'loss_4': -0.7991877794265747, 'epoch': 21.74}
{'loss': 0.0125, 'grad_norm': 5.705773830413818, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.005675985012203455, 'loss_2': 0.006805419921875, 'loss_3': -16.293535232543945, 'loss_4': 0.14216166734695435, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 13:52:29,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:29,026 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:23<24:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:36,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017808448523283005, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.546, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013140927068889141, 'eval_loss_2': 0.004667520523071289, 'eval_loss_3': -18.263572692871094, 'eval_loss_4': -0.259967178106308, 'epoch': 21.74}
{'loss': 0.0163, 'grad_norm': 4.747764587402344, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.00627717562019825, 'loss_2': 0.0099945068359375, 'loss_3': -16.44474983215332, 'loss_4': -0.4227968454360962, 'epoch': 21.75}
{'loss': 0.0094, 'grad_norm': 4.571665287017822, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.005111992359161377, 'loss_2': 0.0043182373046875, 'loss_3': -16.513229370117188, 'loss_4': -0.5575971603393555, 'epoch': 21.76}
{'loss': 0.01, 'grad_norm': 5.037069797515869, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.008185341954231262, 'loss_2': 0.001804351806640625, 'loss_3': -16.559131622314453, 'loss_4': -0.25432664155960083, 'epoch': 21.76}
{'loss': 0.0163, 'grad_norm': 8.047203063964844, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.01239748764783144, 'loss_2': 0.003948211669921875, 'loss_3': -16.338924407958984, 'loss_4': -0.6142189502716064, 'epoch': 21.77}
{'loss': 0.0083, 'grad_norm': 5.376601696014404, 'learning_rate': 8.25e-06, 'loss_1': 0.006393819581717253, 'loss_2': 0.001953125, 'loss_3': -16.600263595581055, 'loss_4': 0.11849682778120041, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 13:52:36,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:36,375 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:30<24:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:43,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015038342215120792, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010718733072280884, 'eval_loss_2': 0.004319608211517334, 'eval_loss_3': -18.26823616027832, 'eval_loss_4': -0.14513640105724335, 'epoch': 21.77}
{'loss': 0.0123, 'grad_norm': 4.579214096069336, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.006549071986228228, 'loss_2': 0.0057220458984375, 'loss_3': -16.40842056274414, 'loss_4': 0.13370749354362488, 'epoch': 21.78}
{'loss': 0.0164, 'grad_norm': 10.187628746032715, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.015210042707622051, 'loss_2': 0.0012149810791015625, 'loss_3': -16.487781524658203, 'loss_4': 0.043046191334724426, 'epoch': 21.78}
{'loss': 0.0054, 'grad_norm': 4.759555339813232, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.004623231012374163, 'loss_2': 0.0008068084716796875, 'loss_3': -16.383739471435547, 'loss_4': 0.07673226296901703, 'epoch': 21.79}
{'loss': 0.0104, 'grad_norm': 5.130269527435303, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.006421755068004131, 'loss_2': 0.003936767578125, 'loss_3': -16.298044204711914, 'loss_4': 0.4579784870147705, 'epoch': 21.8}
{'loss': 0.0139, 'grad_norm': 7.024593353271484, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.010446872562170029, 'loss_2': 0.00347900390625, 'loss_3': -16.38437271118164, 'loss_4': 0.5958806276321411, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 13:52:43,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:43,717 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:38<24:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:51,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014445167966187, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010476794093847275, 'eval_loss_2': 0.003968372941017151, 'eval_loss_3': -18.281381607055664, 'eval_loss_4': -0.04844997823238373, 'epoch': 21.8}
{'loss': 0.008, 'grad_norm': 4.900774002075195, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.0053279828280210495, 'loss_2': 0.002689361572265625, 'loss_3': -16.468658447265625, 'loss_4': 0.07666638493537903, 'epoch': 21.81}
{'loss': 0.0047, 'grad_norm': 4.782595157623291, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.0044272178784012794, 'loss_2': 0.0003161430358886719, 'loss_3': -16.544490814208984, 'loss_4': 0.2948695719242096, 'epoch': 21.81}
{'loss': 0.0189, 'grad_norm': 7.019012928009033, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.013355438597500324, 'loss_2': 0.0055694580078125, 'loss_3': -16.46406364440918, 'loss_4': -0.3949747085571289, 'epoch': 21.82}
{'loss': 0.0173, 'grad_norm': 6.5236287117004395, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.011165086179971695, 'loss_2': 0.00612640380859375, 'loss_3': -16.491085052490234, 'loss_4': -0.09437467902898788, 'epoch': 21.83}
{'loss': 0.0092, 'grad_norm': 4.714169502258301, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.0049194456078112125, 'loss_2': 0.0042877197265625, 'loss_3': -16.100162506103516, 'loss_4': -0.23657134175300598, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 13:52:51,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:51,055 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:45<24:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:58,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014138838276267052, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.782, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01056086178869009, 'eval_loss_2': 0.003577977418899536, 'eval_loss_3': -18.26350212097168, 'eval_loss_4': -0.015107434242963791, 'epoch': 21.83}
{'loss': 0.0233, 'grad_norm': 10.5170316696167, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.012806639075279236, 'loss_2': 0.01047515869140625, 'loss_3': -16.458215713500977, 'loss_4': 0.4469943940639496, 'epoch': 21.84}
{'loss': 0.0058, 'grad_norm': 4.8754048347473145, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.003824121318757534, 'loss_2': 0.0019321441650390625, 'loss_3': -16.490367889404297, 'loss_4': 0.31962746381759644, 'epoch': 21.84}
{'loss': 0.0253, 'grad_norm': 17.847259521484375, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.023644132539629936, 'loss_2': 0.0016603469848632812, 'loss_3': -16.607105255126953, 'loss_4': 0.185494065284729, 'epoch': 21.85}
{'loss': 0.016, 'grad_norm': 10.54692268371582, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.015717629343271255, 'loss_2': 0.0002551078796386719, 'loss_3': -16.591171264648438, 'loss_4': 0.10750306397676468, 'epoch': 21.85}
{'loss': 0.0157, 'grad_norm': 10.044264793395996, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.01474932674318552, 'loss_2': 0.0009045600891113281, 'loss_3': -16.39525032043457, 'loss_4': -0.03558162972331047, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 13:52:58,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:58,386 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:52<24:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:05,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013950771652162075, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010693837888538837, 'eval_loss_2': 0.0032569319009780884, 'eval_loss_3': -18.26128578186035, 'eval_loss_4': 0.11424185335636139, 'epoch': 21.86}
{'loss': 0.0159, 'grad_norm': 7.854792594909668, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.01581163890659809, 'loss_2': 0.00011587142944335938, 'loss_3': -16.33820343017578, 'loss_4': -0.14650386571884155, 'epoch': 21.87}
{'loss': 0.0117, 'grad_norm': 6.348176002502441, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.005456604529172182, 'loss_2': 0.00623321533203125, 'loss_3': -16.173152923583984, 'loss_4': 0.3529645800590515, 'epoch': 21.87}
{'loss': 0.0143, 'grad_norm': 6.01442813873291, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.007707590702921152, 'loss_2': 0.006626129150390625, 'loss_3': -16.45330238342285, 'loss_4': 0.5985242128372192, 'epoch': 21.88}
{'loss': 0.0079, 'grad_norm': 4.32818603515625, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.004456239752471447, 'loss_2': 0.0034542083740234375, 'loss_3': -16.55231475830078, 'loss_4': 0.2681540250778198, 'epoch': 21.88}
{'loss': 0.0087, 'grad_norm': 4.720346927642822, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.005031210370361805, 'loss_2': 0.0036411285400390625, 'loss_3': -16.43043327331543, 'loss_4': 0.6526343822479248, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 13:53:05,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:05,726 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:33:00<24:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:13,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012964999303221703, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.667, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009827849455177784, 'eval_loss_2': 0.003137148916721344, 'eval_loss_3': -18.26786231994629, 'eval_loss_4': 0.35889944434165955, 'epoch': 21.89}
{'loss': 0.009, 'grad_norm': 4.425527095794678, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.004903680644929409, 'loss_2': 0.004131317138671875, 'loss_3': -16.463150024414062, 'loss_4': 0.2630588710308075, 'epoch': 21.9}
{'loss': 0.0066, 'grad_norm': 4.0474090576171875, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0035788812674582005, 'loss_2': 0.0029926300048828125, 'loss_3': -16.462677001953125, 'loss_4': 0.6445609331130981, 'epoch': 21.9}
{'loss': 0.0102, 'grad_norm': 4.6274285316467285, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.006859839893877506, 'loss_2': 0.0033130645751953125, 'loss_3': -16.429275512695312, 'loss_4': 0.5566695928573608, 'epoch': 21.91}
{'loss': 0.0117, 'grad_norm': 5.280947208404541, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.009539314545691013, 'loss_2': 0.002201080322265625, 'loss_3': -16.307456970214844, 'loss_4': 0.7177054286003113, 'epoch': 21.91}
{'loss': 0.0153, 'grad_norm': 4.5601277351379395, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.00462311552837491, 'loss_2': 0.010711669921875, 'loss_3': -16.880680084228516, 'loss_4': 0.5340023636817932, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 13:53:13,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:13,065 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:07<23:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:20,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01278775930404663, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009726564399898052, 'eval_loss_2': 0.003061193972826004, 'eval_loss_3': -18.276540756225586, 'eval_loss_4': 0.5375334024429321, 'epoch': 21.92}
{'loss': 0.005, 'grad_norm': 4.876339435577393, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.005001212004572153, 'loss_2': 3.325939178466797e-05, 'loss_3': -16.525001525878906, 'loss_4': 0.3120184540748596, 'epoch': 21.92}
{'loss': 0.0045, 'grad_norm': 4.722415924072266, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.003671054495498538, 'loss_2': 0.0007944107055664062, 'loss_3': -16.25328254699707, 'loss_4': 0.4046286642551422, 'epoch': 21.93}
{'loss': 0.017, 'grad_norm': 6.2240891456604, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.0127556836232543, 'loss_2': 0.0042266845703125, 'loss_3': -16.167705535888672, 'loss_4': 0.6178140640258789, 'epoch': 21.94}
{'loss': 0.0082, 'grad_norm': 5.264343738555908, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.006672034040093422, 'loss_2': 0.0014801025390625, 'loss_3': -16.542850494384766, 'loss_4': 0.9351378679275513, 'epoch': 21.94}
{'loss': 0.013, 'grad_norm': 5.716734409332275, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.010508336126804352, 'loss_2': 0.00252532958984375, 'loss_3': -16.56243896484375, 'loss_4': 0.6079075932502747, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 13:53:20,412 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:20,412 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:14<23:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:27,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013112617656588554, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.626, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00966642051935196, 'eval_loss_2': 0.0034461989998817444, 'eval_loss_3': -18.270721435546875, 'eval_loss_4': 0.6993443965911865, 'epoch': 21.95}
{'loss': 0.0164, 'grad_norm': 8.39399242401123, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.010897083207964897, 'loss_2': 0.0054779052734375, 'loss_3': -16.523883819580078, 'loss_4': 0.9497573971748352, 'epoch': 21.95}
{'loss': 0.0081, 'grad_norm': 4.859459400177002, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.006556000094860792, 'loss_2': 0.0015392303466796875, 'loss_3': -16.467166900634766, 'loss_4': 0.575374186038971, 'epoch': 21.96}
{'loss': 0.0143, 'grad_norm': 5.64239501953125, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.0058760326355695724, 'loss_2': 0.008392333984375, 'loss_3': -16.648826599121094, 'loss_4': 0.5684409141540527, 'epoch': 21.97}
{'loss': 0.0719, 'grad_norm': 25.21562385559082, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.06943801790475845, 'loss_2': 0.0024967193603515625, 'loss_3': -16.382740020751953, 'loss_4': 0.9002555012702942, 'epoch': 21.97}
{'loss': 0.0149, 'grad_norm': 5.103128910064697, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.004147454630583525, 'loss_2': 0.0107269287109375, 'loss_3': -16.685081481933594, 'loss_4': 0.5013154745101929, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 13:53:27,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:27,755 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:21<22:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:53:34,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014284810051321983, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.514, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01055937074124813, 'eval_loss_2': 0.0037254393100738525, 'eval_loss_3': -18.262727737426758, 'eval_loss_4': 0.711813747882843, 'epoch': 21.98}
{'loss': 0.0126, 'grad_norm': 5.18064022064209, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.007516133598983288, 'loss_2': 0.00505828857421875, 'loss_3': -16.27024269104004, 'loss_4': 1.0172197818756104, 'epoch': 21.98}
{'loss': 0.0114, 'grad_norm': 5.134720325469971, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.009004299528896809, 'loss_2': 0.002353668212890625, 'loss_3': -16.517671585083008, 'loss_4': 0.7608228921890259, 'epoch': 21.99}
{'loss': 0.0074, 'grad_norm': 5.269294738769531, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.0058358944952487946, 'loss_2': 0.0015153884887695312, 'loss_3': -16.28665542602539, 'loss_4': 1.2717366218566895, 'epoch': 21.99}
{'loss': 0.0074, 'grad_norm': 5.737161159515381, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.005990623030811548, 'loss_2': 0.0013875961303710938, 'loss_3': -16.530597686767578, 'loss_4': 1.0655903816223145, 'epoch': 22.0}
{'loss': 0.0101, 'grad_norm': 4.80710506439209, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.0047790538519620895, 'loss_2': 0.00530242919921875, 'loss_3': -16.594341278076172, 'loss_4': 0.8563146591186523, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 13:53:34,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:34,792 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:29<23:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:53:42,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013655904680490494, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010121461935341358, 'eval_loss_2': 0.00353444367647171, 'eval_loss_3': -18.260074615478516, 'eval_loss_4': 0.6696150898933411, 'epoch': 22.01}
{'loss': 0.0189, 'grad_norm': 5.600576400756836, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.009165836498141289, 'loss_2': 0.009735107421875, 'loss_3': -16.476411819458008, 'loss_4': 0.8552877902984619, 'epoch': 22.01}
{'loss': 0.0155, 'grad_norm': 6.320739269256592, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.00954969972372055, 'loss_2': 0.00592041015625, 'loss_3': -16.32316017150879, 'loss_4': 0.9006194472312927, 'epoch': 22.02}
{'loss': 0.0174, 'grad_norm': 5.9159836769104, 'learning_rate': 8e-06, 'loss_1': 0.010331179015338421, 'loss_2': 0.007049560546875, 'loss_3': -16.552894592285156, 'loss_4': 0.4787815809249878, 'epoch': 22.02}
{'loss': 0.0134, 'grad_norm': 5.545955657958984, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.007374148350208998, 'loss_2': 0.006015777587890625, 'loss_3': -16.454742431640625, 'loss_4': 0.6824164986610413, 'epoch': 22.03}
{'loss': 0.0076, 'grad_norm': 4.994571208953857, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.005757446400821209, 'loss_2': 0.0017995834350585938, 'loss_3': -16.335243225097656, 'loss_4': 0.6870191097259521, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 13:53:42,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:42,130 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:36<23:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:49,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012893462553620338, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.068, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00934178102761507, 'eval_loss_2': 0.0035516805946826935, 'eval_loss_3': -18.262897491455078, 'eval_loss_4': 0.6283478140830994, 'epoch': 22.03}
{'loss': 0.0091, 'grad_norm': 4.494072437286377, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.00350403250195086, 'loss_2': 0.00560760498046875, 'loss_3': -16.391719818115234, 'loss_4': 0.4404575824737549, 'epoch': 22.04}
{'loss': 0.0129, 'grad_norm': 6.025697231292725, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.009133781306445599, 'loss_2': 0.0037975311279296875, 'loss_3': -16.581668853759766, 'loss_4': 0.41858434677124023, 'epoch': 22.05}
{'loss': 0.0064, 'grad_norm': 4.8271965980529785, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.0056599900126457214, 'loss_2': 0.0007276535034179688, 'loss_3': -16.680606842041016, 'loss_4': 0.4251644015312195, 'epoch': 22.05}
{'loss': 0.0068, 'grad_norm': 4.670193195343018, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.005828070919960737, 'loss_2': 0.00101470947265625, 'loss_3': -16.631608963012695, 'loss_4': 0.6122772693634033, 'epoch': 22.06}
{'loss': 0.0105, 'grad_norm': 4.7599029541015625, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.004938813857734203, 'loss_2': 0.005523681640625, 'loss_3': -16.393434524536133, 'loss_4': 0.5724219083786011, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 13:53:49,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:49,481 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:43<23:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:56,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013927952386438847, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009927884675562382, 'eval_loss_2': 0.004000067710876465, 'eval_loss_3': -18.25759506225586, 'eval_loss_4': 0.6654219031333923, 'epoch': 22.06}
{'loss': 0.0273, 'grad_norm': 9.74664306640625, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.023727798834443092, 'loss_2': 0.003566741943359375, 'loss_3': -16.579513549804688, 'loss_4': 0.9958574771881104, 'epoch': 22.07}
{'loss': 0.0142, 'grad_norm': 5.310280799865723, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.010720922611653805, 'loss_2': 0.0034332275390625, 'loss_3': -16.610157012939453, 'loss_4': 0.41756540536880493, 'epoch': 22.08}
{'loss': 0.0085, 'grad_norm': 5.093710899353027, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.00731787271797657, 'loss_2': 0.0011987686157226562, 'loss_3': -16.302043914794922, 'loss_4': 0.8869912624359131, 'epoch': 22.08}
{'loss': 0.0105, 'grad_norm': 4.943824768066406, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.0056919013150036335, 'loss_2': 0.00478363037109375, 'loss_3': -16.487642288208008, 'loss_4': 0.538749635219574, 'epoch': 22.09}
{'loss': 0.0162, 'grad_norm': 8.762954711914062, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.013362588360905647, 'loss_2': 0.002826690673828125, 'loss_3': -16.620464324951172, 'loss_4': 0.4897089898586273, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 13:53:56,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:56,820 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:51<23:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:04,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014154325239360332, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.196, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010273108258843422, 'eval_loss_2': 0.003881216049194336, 'eval_loss_3': -18.247665405273438, 'eval_loss_4': 0.68876051902771, 'epoch': 22.09}
{'loss': 0.0163, 'grad_norm': 4.7874627113342285, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.004428280517458916, 'loss_2': 0.0119171142578125, 'loss_3': -16.496763229370117, 'loss_4': 1.070536732673645, 'epoch': 22.1}
{'loss': 0.0088, 'grad_norm': 5.85581636428833, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.008592707104980946, 'loss_2': 0.0002315044403076172, 'loss_3': -16.52505874633789, 'loss_4': 0.4188750982284546, 'epoch': 22.1}
{'loss': 0.012, 'grad_norm': 4.4490485191345215, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.006800706032663584, 'loss_2': 0.00518035888671875, 'loss_3': -16.703693389892578, 'loss_4': 1.0902281999588013, 'epoch': 22.11}
{'loss': 0.0143, 'grad_norm': 4.991909503936768, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.007841518148779869, 'loss_2': 0.00649261474609375, 'loss_3': -16.24178695678711, 'loss_4': 0.9662607908248901, 'epoch': 22.12}
{'loss': 0.0091, 'grad_norm': 4.737358570098877, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.00502528203651309, 'loss_2': 0.00403594970703125, 'loss_3': -16.370595932006836, 'loss_4': 0.4749874472618103, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 13:54:04,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:04,171 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:58<23:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:11,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01302479300647974, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.321, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010495230555534363, 'eval_loss_2': 0.0025295615196228027, 'eval_loss_3': -18.25298309326172, 'eval_loss_4': 0.6172608137130737, 'epoch': 22.12}
{'loss': 0.0218, 'grad_norm': 10.429155349731445, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.02153034508228302, 'loss_2': 0.00024318695068359375, 'loss_3': -16.423812866210938, 'loss_4': 0.9874590635299683, 'epoch': 22.13}
{'loss': 0.004, 'grad_norm': 4.954157829284668, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.0031745568849146366, 'loss_2': 0.000865936279296875, 'loss_3': -16.373281478881836, 'loss_4': 1.021471381187439, 'epoch': 22.13}
{'loss': 0.0134, 'grad_norm': 8.692861557006836, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.010302103124558926, 'loss_2': 0.0030517578125, 'loss_3': -16.469209671020508, 'loss_4': 0.25686976313591003, 'epoch': 22.14}
{'loss': 0.0103, 'grad_norm': 4.5816168785095215, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.006300326902419329, 'loss_2': 0.0039520263671875, 'loss_3': -16.391828536987305, 'loss_4': 0.31197553873062134, 'epoch': 22.15}
{'loss': 0.0524, 'grad_norm': 13.797979354858398, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.05186506360769272, 'loss_2': 0.0005536079406738281, 'loss_3': -16.513263702392578, 'loss_4': 0.9349682331085205, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 13:54:11,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:11,516 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:05<23:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:18,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015331169590353966, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010687699541449547, 'eval_loss_2': 0.004643470048904419, 'eval_loss_3': -18.2552433013916, 'eval_loss_4': 0.4882758557796478, 'epoch': 22.15}
{'loss': 0.0124, 'grad_norm': 4.882126808166504, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.007744121830910444, 'loss_2': 0.004703521728515625, 'loss_3': -16.462247848510742, 'loss_4': 0.3017072379589081, 'epoch': 22.16}
{'loss': 0.0162, 'grad_norm': 4.307401657104492, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.0037496881559491158, 'loss_2': 0.0124664306640625, 'loss_3': -16.443546295166016, 'loss_4': 0.1762217879295349, 'epoch': 22.16}
{'loss': 0.0119, 'grad_norm': 5.0326008796691895, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.005950415972620249, 'loss_2': 0.005985260009765625, 'loss_3': -16.26545524597168, 'loss_4': 0.4149034917354584, 'epoch': 22.17}
{'loss': 0.0143, 'grad_norm': 6.776103496551514, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.012152505107223988, 'loss_2': 0.002124786376953125, 'loss_3': -16.441329956054688, 'loss_4': 0.43134403228759766, 'epoch': 22.17}
{'loss': 0.0153, 'grad_norm': 5.002554416656494, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.005940358154475689, 'loss_2': 0.0093231201171875, 'loss_3': -16.586929321289062, 'loss_4': 0.563644289970398, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 13:54:18,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:18,852 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:13<23:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:54:26,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013444291427731514, 'eval_runtime': 4.0073, 'eval_samples_per_second': 255.537, 'eval_steps_per_second': 3.993, 'eval_loss_1': 0.010166173800826073, 'eval_loss_2': 0.0032781176269054413, 'eval_loss_3': -18.242910385131836, 'eval_loss_4': 0.40178221464157104, 'epoch': 22.18}
{'loss': 0.0139, 'grad_norm': 5.058059215545654, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.005430807825177908, 'loss_2': 0.008514404296875, 'loss_3': -16.36754608154297, 'loss_4': 0.48535579442977905, 'epoch': 22.19}
{'loss': 0.0188, 'grad_norm': 8.781010627746582, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.015142427757382393, 'loss_2': 0.0036411285400390625, 'loss_3': -16.544891357421875, 'loss_4': 0.7611977458000183, 'epoch': 22.19}
{'loss': 0.0096, 'grad_norm': 5.07112979888916, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.004833289887756109, 'loss_2': 0.0047607421875, 'loss_3': -16.35332679748535, 'loss_4': 0.17947626113891602, 'epoch': 22.2}
{'loss': 0.0597, 'grad_norm': 17.428783416748047, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.058970578014850616, 'loss_2': 0.0007581710815429688, 'loss_3': -16.418079376220703, 'loss_4': 0.31318074464797974, 'epoch': 22.2}
{'loss': 0.0078, 'grad_norm': 4.871800899505615, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.006575315725058317, 'loss_2': 0.001251220703125, 'loss_3': -16.376468658447266, 'loss_4': 0.657971978187561, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 13:54:26,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:26,412 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:20<23:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:33,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013549274764955044, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.661, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010911009274423122, 'eval_loss_2': 0.0026382654905319214, 'eval_loss_3': -18.243566513061523, 'eval_loss_4': 0.2820255756378174, 'epoch': 22.21}
{'loss': 0.0118, 'grad_norm': 6.785581111907959, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.008992329239845276, 'loss_2': 0.00279998779296875, 'loss_3': -16.329442977905273, 'loss_4': 0.1233101561665535, 'epoch': 22.22}
{'loss': 0.0125, 'grad_norm': 4.975558280944824, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.005909034516662359, 'loss_2': 0.006561279296875, 'loss_3': -16.241714477539062, 'loss_4': -0.05803436040878296, 'epoch': 22.22}
{'loss': 0.0108, 'grad_norm': 5.835119247436523, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.005203102715313435, 'loss_2': 0.0055999755859375, 'loss_3': -16.618125915527344, 'loss_4': 0.23374804854393005, 'epoch': 22.23}
{'loss': 0.0166, 'grad_norm': 8.99405574798584, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.014486830681562424, 'loss_2': 0.0021533966064453125, 'loss_3': -16.68756103515625, 'loss_4': 0.11952900886535645, 'epoch': 22.23}
{'loss': 0.0356, 'grad_norm': 10.898052215576172, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.027734048664569855, 'loss_2': 0.00783538818359375, 'loss_3': -16.232666015625, 'loss_4': 0.08342350274324417, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 13:54:33,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:33,773 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:28<23:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:41,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015465358272194862, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012689032591879368, 'eval_loss_2': 0.00277632474899292, 'eval_loss_3': -18.235139846801758, 'eval_loss_4': 0.22023339569568634, 'epoch': 22.24}
{'loss': 0.0102, 'grad_norm': 7.005615234375, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.009720362722873688, 'loss_2': 0.00048065185546875, 'loss_3': -16.501758575439453, 'loss_4': 0.0661473274230957, 'epoch': 22.24}
{'loss': 0.0099, 'grad_norm': 6.990501880645752, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.007819447666406631, 'loss_2': 0.0020751953125, 'loss_3': -16.4429931640625, 'loss_4': 0.004386533051729202, 'epoch': 22.25}
{'loss': 0.0096, 'grad_norm': 4.3205060958862305, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.007030990906059742, 'loss_2': 0.002552032470703125, 'loss_3': -16.60251235961914, 'loss_4': 0.6275798678398132, 'epoch': 22.26}
{'loss': 0.0101, 'grad_norm': 7.02537727355957, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.009839430451393127, 'loss_2': 0.00021350383758544922, 'loss_3': -16.330589294433594, 'loss_4': 0.22275671362876892, 'epoch': 22.26}
{'loss': 0.0115, 'grad_norm': 5.541746139526367, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.007462179753929377, 'loss_2': 0.004058837890625, 'loss_3': -16.45922088623047, 'loss_4': 0.05220649018883705, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 13:54:41,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:41,120 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:35<22:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:48,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01606157422065735, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01356338057667017, 'eval_loss_2': 0.0024981945753097534, 'eval_loss_3': -18.223388671875, 'eval_loss_4': 0.1335323601961136, 'epoch': 22.27}
{'loss': 0.0099, 'grad_norm': 4.712534427642822, 'learning_rate': 7.75e-06, 'loss_1': 0.004193048924207687, 'loss_2': 0.005710601806640625, 'loss_3': -16.406557083129883, 'loss_4': -0.18666312098503113, 'epoch': 22.27}
{'loss': 0.0066, 'grad_norm': 4.452213287353516, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.005696076434105635, 'loss_2': 0.0008854866027832031, 'loss_3': -16.487852096557617, 'loss_4': 0.5084516406059265, 'epoch': 22.28}
{'loss': 0.0128, 'grad_norm': 4.887612342834473, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.006509033963084221, 'loss_2': 0.00627899169921875, 'loss_3': -16.535078048706055, 'loss_4': 0.42854830622673035, 'epoch': 22.28}
{'loss': 0.0195, 'grad_norm': 15.972350120544434, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.019199471920728683, 'loss_2': 0.0002846717834472656, 'loss_3': -16.400789260864258, 'loss_4': 0.22439579665660858, 'epoch': 22.29}
{'loss': 0.0066, 'grad_norm': 4.5355658531188965, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.0033509950153529644, 'loss_2': 0.0032634735107421875, 'loss_3': -16.501407623291016, 'loss_4': 0.2761113941669464, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 13:54:48,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:48,467 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:42<22:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:55,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016972612589597702, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013714442029595375, 'eval_loss_2': 0.0032581686973571777, 'eval_loss_3': -18.208717346191406, 'eval_loss_4': 0.08253209292888641, 'epoch': 22.3}
{'loss': 0.0127, 'grad_norm': 5.509331703186035, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.006320967338979244, 'loss_2': 0.006343841552734375, 'loss_3': -16.53502655029297, 'loss_4': -0.09133223444223404, 'epoch': 22.3}
{'loss': 0.0173, 'grad_norm': 8.229972839355469, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.013079352676868439, 'loss_2': 0.004230499267578125, 'loss_3': -16.45319366455078, 'loss_4': -0.17256008088588715, 'epoch': 22.31}
{'loss': 0.0087, 'grad_norm': 4.768609046936035, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.004774113185703754, 'loss_2': 0.003894805908203125, 'loss_3': -16.492801666259766, 'loss_4': 0.05274876579642296, 'epoch': 22.31}
{'loss': 0.0052, 'grad_norm': 4.563003063201904, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.004457746632397175, 'loss_2': 0.0007009506225585938, 'loss_3': -16.557552337646484, 'loss_4': -0.04482709616422653, 'epoch': 22.32}
{'loss': 0.0096, 'grad_norm': 5.480557918548584, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.00801024865359068, 'loss_2': 0.0016021728515625, 'loss_3': -16.551082611083984, 'loss_4': 0.10456028580665588, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 13:54:55,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:55,820 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:50<22:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:03,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01591986045241356, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012877739034593105, 'eval_loss_2': 0.003042120486497879, 'eval_loss_3': -18.21548843383789, 'eval_loss_4': 0.04416020214557648, 'epoch': 22.33}
{'loss': 0.0092, 'grad_norm': 4.701194763183594, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.007125153671950102, 'loss_2': 0.002071380615234375, 'loss_3': -16.060834884643555, 'loss_4': 0.007641635835170746, 'epoch': 22.33}
{'loss': 0.0055, 'grad_norm': 4.540777683258057, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.003355355467647314, 'loss_2': 0.0021648406982421875, 'loss_3': -16.35602569580078, 'loss_4': -0.5472277402877808, 'epoch': 22.34}
{'loss': 0.0107, 'grad_norm': 6.427243232727051, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.00899000559002161, 'loss_2': 0.0016689300537109375, 'loss_3': -16.49920654296875, 'loss_4': -0.46117711067199707, 'epoch': 22.34}
{'loss': 0.0054, 'grad_norm': 4.219600677490234, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.002759817522019148, 'loss_2': 0.0026264190673828125, 'loss_3': -16.523815155029297, 'loss_4': 0.16002735495567322, 'epoch': 22.35}
{'loss': 0.01, 'grad_norm': 4.738570690155029, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.004248850978910923, 'loss_2': 0.00572967529296875, 'loss_3': -16.692142486572266, 'loss_4': 0.38764411211013794, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 13:55:03,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:03,170 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:57<22:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:10,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017071528360247612, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.504, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.013144389726221561, 'eval_loss_2': 0.003927137702703476, 'eval_loss_3': -18.2101993560791, 'eval_loss_4': 0.04292286932468414, 'epoch': 22.35}
{'loss': 0.0057, 'grad_norm': 4.554429531097412, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.005548450630158186, 'loss_2': 0.00018513202667236328, 'loss_3': -16.21949005126953, 'loss_4': 0.2588801980018616, 'epoch': 22.36}
{'loss': 0.0087, 'grad_norm': 4.827498912811279, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.0060288491658866405, 'loss_2': 0.002666473388671875, 'loss_3': -16.36957550048828, 'loss_4': 0.11769401282072067, 'epoch': 22.37}
{'loss': 0.0206, 'grad_norm': 9.963312149047852, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.016015497967600822, 'loss_2': 0.00455474853515625, 'loss_3': -16.431819915771484, 'loss_4': 0.4706207513809204, 'epoch': 22.37}
{'loss': 0.0049, 'grad_norm': 4.603451251983643, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.0030036158859729767, 'loss_2': 0.0019130706787109375, 'loss_3': -16.376588821411133, 'loss_4': 0.20203693211078644, 'epoch': 22.38}
{'loss': 0.0092, 'grad_norm': 4.688704967498779, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.005191099364310503, 'loss_2': 0.0039825439453125, 'loss_3': -16.49504852294922, 'loss_4': 0.026805981993675232, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 13:55:10,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:10,531 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:04<22:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:17,883 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018322112038731575, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013943257741630077, 'eval_loss_2': 0.004378855228424072, 'eval_loss_3': -18.19972801208496, 'eval_loss_4': 0.1091783195734024, 'epoch': 22.38}
{'loss': 0.0089, 'grad_norm': 5.663005828857422, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.005159340333193541, 'loss_2': 0.003753662109375, 'loss_3': -16.56694793701172, 'loss_4': 0.016800228506326675, 'epoch': 22.39}
{'loss': 0.0127, 'grad_norm': 5.105194568634033, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.004437960684299469, 'loss_2': 0.00824737548828125, 'loss_3': -16.520986557006836, 'loss_4': 0.3016622066497803, 'epoch': 22.4}
{'loss': 0.0182, 'grad_norm': 9.778576850891113, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.009467164985835552, 'loss_2': 0.0087127685546875, 'loss_3': -16.39712142944336, 'loss_4': 0.04255466163158417, 'epoch': 22.4}
{'loss': 0.0101, 'grad_norm': 4.451872825622559, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.0026804660446941853, 'loss_2': 0.007415771484375, 'loss_3': -16.544769287109375, 'loss_4': 0.13693921267986298, 'epoch': 22.41}
{'loss': 0.0069, 'grad_norm': 4.695742607116699, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.003774728160351515, 'loss_2': 0.003082275390625, 'loss_3': -16.462913513183594, 'loss_4': 0.023181170225143433, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 13:55:17,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:17,883 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:12<22:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:25,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017393330112099648, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014369886368513107, 'eval_loss_2': 0.0030234456062316895, 'eval_loss_3': -18.209314346313477, 'eval_loss_4': 0.1401352733373642, 'epoch': 22.41}
{'loss': 0.0302, 'grad_norm': 9.81661605834961, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.024056287482380867, 'loss_2': 0.006134033203125, 'loss_3': -16.521949768066406, 'loss_4': 0.22157889604568481, 'epoch': 22.42}
{'loss': 0.0039, 'grad_norm': 4.327086925506592, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.0030805934220552444, 'loss_2': 0.000835418701171875, 'loss_3': -16.495159149169922, 'loss_4': 0.2710132598876953, 'epoch': 22.42}
{'loss': 0.0066, 'grad_norm': 4.757332801818848, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.0038143524434417486, 'loss_2': 0.002826690673828125, 'loss_3': -16.42095184326172, 'loss_4': 0.2285453975200653, 'epoch': 22.43}
{'loss': 0.0115, 'grad_norm': 4.70755672454834, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.007940098643302917, 'loss_2': 0.00354766845703125, 'loss_3': -16.481721878051758, 'loss_4': 0.1125844269990921, 'epoch': 22.44}
{'loss': 0.0048, 'grad_norm': 4.548163890838623, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.00472941342741251, 'loss_2': 3.55839729309082e-05, 'loss_3': -16.3828125, 'loss_4': 0.024921536445617676, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 13:55:25,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:25,228 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:19<22:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:32,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01828702911734581, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01437392458319664, 'eval_loss_2': 0.00391310453414917, 'eval_loss_3': -18.193317413330078, 'eval_loss_4': 0.1884113848209381, 'epoch': 22.44}
{'loss': 0.0033, 'grad_norm': 4.459660053253174, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0030757123604416847, 'loss_2': 0.0002532005310058594, 'loss_3': -16.380863189697266, 'loss_4': 0.01838316023349762, 'epoch': 22.45}
{'loss': 0.005, 'grad_norm': 4.9287190437316895, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.0044511910527944565, 'loss_2': 0.0005826950073242188, 'loss_3': -16.370460510253906, 'loss_4': 0.7999922037124634, 'epoch': 22.45}
{'loss': 0.0063, 'grad_norm': 5.107150554656982, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.0032568620517849922, 'loss_2': 0.0030803680419921875, 'loss_3': -16.31496810913086, 'loss_4': 0.2535313665866852, 'epoch': 22.46}
{'loss': 0.0188, 'grad_norm': 8.146257400512695, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.016369249671697617, 'loss_2': 0.002407073974609375, 'loss_3': -16.48352813720703, 'loss_4': 0.1814829558134079, 'epoch': 22.47}
{'loss': 0.0089, 'grad_norm': 5.0187883377075195, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.005043581128120422, 'loss_2': 0.00384521484375, 'loss_3': -16.45171356201172, 'loss_4': 0.11414843797683716, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 13:55:32,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:32,579 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:26<22:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:39,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018848631531000137, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.372, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014964824542403221, 'eval_loss_2': 0.0038838088512420654, 'eval_loss_3': -18.180349349975586, 'eval_loss_4': 0.2609576880931854, 'epoch': 22.47}
{'loss': 0.0089, 'grad_norm': 5.722625732421875, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.008754728361964226, 'loss_2': 0.00015544891357421875, 'loss_3': -16.182214736938477, 'loss_4': 0.5336105227470398, 'epoch': 22.48}
{'loss': 0.0129, 'grad_norm': 7.542919158935547, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.01222307700663805, 'loss_2': 0.0006914138793945312, 'loss_3': -16.29632568359375, 'loss_4': 0.09724298119544983, 'epoch': 22.48}
{'loss': 0.0091, 'grad_norm': 4.485815525054932, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.0030190511606633663, 'loss_2': 0.00604248046875, 'loss_3': -16.330120086669922, 'loss_4': 0.12174219638109207, 'epoch': 22.49}
{'loss': 0.011, 'grad_norm': 4.53773832321167, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.006015954539179802, 'loss_2': 0.0050201416015625, 'loss_3': -16.34898567199707, 'loss_4': 0.3357246518135071, 'epoch': 22.49}
{'loss': 0.0028, 'grad_norm': 4.442124366760254, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.002476724563166499, 'loss_2': 0.0003085136413574219, 'loss_3': -16.383350372314453, 'loss_4': 0.3838038444519043, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 13:55:39,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:39,927 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:34<22:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:47,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018542496487498283, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.014623909257352352, 'eval_loss_2': 0.003918588161468506, 'eval_loss_3': -18.178146362304688, 'eval_loss_4': 0.2821578085422516, 'epoch': 22.5}
{'loss': 0.008, 'grad_norm': 4.765697002410889, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.006847287528216839, 'loss_2': 0.0011157989501953125, 'loss_3': -16.3832950592041, 'loss_4': 0.4348675608634949, 'epoch': 22.51}
{'loss': 0.0109, 'grad_norm': 4.591385364532471, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.0036535204853862524, 'loss_2': 0.007259368896484375, 'loss_3': -16.38829231262207, 'loss_4': 0.6903512477874756, 'epoch': 22.51}
{'loss': 0.0125, 'grad_norm': 10.610753059387207, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.011485853232443333, 'loss_2': 0.000965118408203125, 'loss_3': -16.448497772216797, 'loss_4': 0.5970203876495361, 'epoch': 22.52}
{'loss': 0.0096, 'grad_norm': 5.533027172088623, 'learning_rate': 7.5e-06, 'loss_1': 0.007431122940033674, 'loss_2': 0.002185821533203125, 'loss_3': -16.391550064086914, 'loss_4': 0.6726412177085876, 'epoch': 22.52}
{'loss': 0.0102, 'grad_norm': 5.393963813781738, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.00858276803046465, 'loss_2': 0.0016565322875976562, 'loss_3': -16.384563446044922, 'loss_4': 0.15128426253795624, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 13:55:47,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:47,283 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:41<22:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:54,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017681322991847992, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.381, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.014508359134197235, 'eval_loss_2': 0.003172963857650757, 'eval_loss_3': -18.161218643188477, 'eval_loss_4': 0.3045892119407654, 'epoch': 22.53}
{'loss': 0.012, 'grad_norm': 6.3873186111450195, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.006935157347470522, 'loss_2': 0.0050811767578125, 'loss_3': -16.370954513549805, 'loss_4': 0.25037163496017456, 'epoch': 22.53}
{'loss': 0.0039, 'grad_norm': 4.225591659545898, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.003489492228254676, 'loss_2': 0.00037407875061035156, 'loss_3': -16.31047821044922, 'loss_4': -0.39681389927864075, 'epoch': 22.54}
{'loss': 0.0112, 'grad_norm': 8.242838859558105, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.010781408287584782, 'loss_2': 0.0003726482391357422, 'loss_3': -16.299039840698242, 'loss_4': 0.1490267813205719, 'epoch': 22.55}
{'loss': 0.0082, 'grad_norm': 4.710163116455078, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.006845449563115835, 'loss_2': 0.0013799667358398438, 'loss_3': -16.474565505981445, 'loss_4': 0.655920684337616, 'epoch': 22.55}
{'loss': 0.0062, 'grad_norm': 5.321006774902344, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.00423046387732029, 'loss_2': 0.0019702911376953125, 'loss_3': -16.31911849975586, 'loss_4': -0.09250134229660034, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 13:55:54,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:54,648 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:49<22:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:02,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01811663806438446, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014553019776940346, 'eval_loss_2': 0.003563620150089264, 'eval_loss_3': -18.166744232177734, 'eval_loss_4': 0.36364278197288513, 'epoch': 22.56}
{'loss': 0.019, 'grad_norm': 16.415924072265625, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.018942100927233696, 'loss_2': 2.6345252990722656e-05, 'loss_3': -16.3420467376709, 'loss_4': 0.27677392959594727, 'epoch': 22.56}
{'loss': 0.0063, 'grad_norm': 5.206639766693115, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.006161765661090612, 'loss_2': 0.0001207590103149414, 'loss_3': -16.37474822998047, 'loss_4': 0.15993157029151917, 'epoch': 22.57}
{'loss': 0.0047, 'grad_norm': 4.2911763191223145, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.0035340783651918173, 'loss_2': 0.0011749267578125, 'loss_3': -16.329143524169922, 'loss_4': 0.43307334184646606, 'epoch': 22.58}
{'loss': 0.0087, 'grad_norm': 4.174576282501221, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.004047578200697899, 'loss_2': 0.00461578369140625, 'loss_3': -16.433448791503906, 'loss_4': 0.5262292623519897, 'epoch': 22.58}
{'loss': 0.0079, 'grad_norm': 4.789008140563965, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.0066256229765713215, 'loss_2': 0.0012912750244140625, 'loss_3': -16.39453887939453, 'loss_4': 0.47175395488739014, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 13:56:02,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:02,005 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:56<21:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:09,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016666654497385025, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.89, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013500201515853405, 'eval_loss_2': 0.0031664520502090454, 'eval_loss_3': -18.175079345703125, 'eval_loss_4': 0.3883034586906433, 'epoch': 22.59}
{'loss': 0.002, 'grad_norm': 4.354897499084473, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.0014661934692412615, 'loss_2': 0.0005731582641601562, 'loss_3': -16.385269165039062, 'loss_4': 0.6574145555496216, 'epoch': 22.59}
{'loss': 0.0071, 'grad_norm': 5.319790363311768, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.006399906240403652, 'loss_2': 0.0006847381591796875, 'loss_3': -16.354991912841797, 'loss_4': 0.39394211769104004, 'epoch': 22.6}
{'loss': 0.0078, 'grad_norm': 4.22853422164917, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.002749544335529208, 'loss_2': 0.00502777099609375, 'loss_3': -16.49173355102539, 'loss_4': -0.024574846029281616, 'epoch': 22.6}
{'loss': 0.0066, 'grad_norm': 5.274153232574463, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.0048645660281181335, 'loss_2': 0.001720428466796875, 'loss_3': -16.480955123901367, 'loss_4': 0.016967684030532837, 'epoch': 22.61}
{'loss': 0.0205, 'grad_norm': 7.362378120422363, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.013968504033982754, 'loss_2': 0.006500244140625, 'loss_3': -16.49106216430664, 'loss_4': 0.4321320950984955, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 13:56:09,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:09,363 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:36:03<21:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:16,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016480781137943268, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.304, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01373306568711996, 'eval_loss_2': 0.0027477145195007324, 'eval_loss_3': -18.178197860717773, 'eval_loss_4': 0.39637115597724915, 'epoch': 22.62}
{'loss': 0.0047, 'grad_norm': 4.615389347076416, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.0036738684866577387, 'loss_2': 0.001071929931640625, 'loss_3': -16.531787872314453, 'loss_4': 0.14889311790466309, 'epoch': 22.62}
{'loss': 0.0064, 'grad_norm': 5.047253131866455, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.00372293870896101, 'loss_2': 0.002674102783203125, 'loss_3': -16.46010971069336, 'loss_4': 0.6020726561546326, 'epoch': 22.63}
{'loss': 0.0117, 'grad_norm': 6.180089473724365, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.006620686035603285, 'loss_2': 0.005084991455078125, 'loss_3': -16.424808502197266, 'loss_4': 0.3279929459095001, 'epoch': 22.63}
{'loss': 0.0071, 'grad_norm': 4.82220983505249, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.00700836256146431, 'loss_2': 0.00011050701141357422, 'loss_3': -16.38686752319336, 'loss_4': 0.28205636143684387, 'epoch': 22.64}
{'loss': 0.0131, 'grad_norm': 5.443511009216309, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.007152179721742868, 'loss_2': 0.005954742431640625, 'loss_3': -16.294477462768555, 'loss_4': 0.08169779926538467, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 13:56:16,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:16,717 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:11<21:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:24,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016077416017651558, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013558582402765751, 'eval_loss_2': 0.0025188326835632324, 'eval_loss_3': -18.17764663696289, 'eval_loss_4': 0.44149306416511536, 'epoch': 22.65}
{'loss': 0.0079, 'grad_norm': 5.312312602996826, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.005293662194162607, 'loss_2': 0.00257110595703125, 'loss_3': -16.45819854736328, 'loss_4': 0.5971986055374146, 'epoch': 22.65}
{'loss': 0.0083, 'grad_norm': 4.159183502197266, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.0033208425156772137, 'loss_2': 0.00502777099609375, 'loss_3': -16.383636474609375, 'loss_4': 0.4298269748687744, 'epoch': 22.66}
{'loss': 0.0077, 'grad_norm': 4.9662957191467285, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.00628259452059865, 'loss_2': 0.0014495849609375, 'loss_3': -16.3525390625, 'loss_4': 0.374406635761261, 'epoch': 22.66}
{'loss': 0.005, 'grad_norm': 4.731255054473877, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.002781105460599065, 'loss_2': 0.0021820068359375, 'loss_3': -16.342479705810547, 'loss_4': 0.12967434525489807, 'epoch': 22.67}
{'loss': 0.0169, 'grad_norm': 4.8590922355651855, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.012048279866576195, 'loss_2': 0.00485992431640625, 'loss_3': -16.594459533691406, 'loss_4': 0.6703105568885803, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 13:56:24,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:24,066 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:18<21:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:31,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014640530571341515, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.996, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012272690422832966, 'eval_loss_2': 0.002367839217185974, 'eval_loss_3': -18.175174713134766, 'eval_loss_4': 0.4582855701446533, 'epoch': 22.67}
{'loss': 0.0055, 'grad_norm': 4.416861057281494, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.0031167608685791492, 'loss_2': 0.00241851806640625, 'loss_3': -16.359891891479492, 'loss_4': 0.7925670146942139, 'epoch': 22.68}
{'loss': 0.0153, 'grad_norm': 9.863752365112305, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.01211352739483118, 'loss_2': 0.0031890869140625, 'loss_3': -16.327152252197266, 'loss_4': 0.5168763995170593, 'epoch': 22.69}
{'loss': 0.0075, 'grad_norm': 5.021110534667969, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.006844835821539164, 'loss_2': 0.000637054443359375, 'loss_3': -16.409564971923828, 'loss_4': -0.016235291957855225, 'epoch': 22.69}
{'loss': 0.0185, 'grad_norm': 6.232244491577148, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.016324201598763466, 'loss_2': 0.002216339111328125, 'loss_3': -16.299091339111328, 'loss_4': 0.4126189649105072, 'epoch': 22.7}
{'loss': 0.0188, 'grad_norm': 7.453986644744873, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.011585094034671783, 'loss_2': 0.007232666015625, 'loss_3': -16.080095291137695, 'loss_4': -0.10188721865415573, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 13:56:31,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:31,419 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:25<21:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:38,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013867620378732681, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.182, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010996862314641476, 'eval_loss_2': 0.002870757132768631, 'eval_loss_3': -18.177900314331055, 'eval_loss_4': 0.40058204531669617, 'epoch': 22.7}
{'loss': 0.009, 'grad_norm': 5.100261211395264, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.005436447914689779, 'loss_2': 0.0036067962646484375, 'loss_3': -16.521738052368164, 'loss_4': 0.08268128335475922, 'epoch': 22.71}
{'loss': 0.0062, 'grad_norm': 4.550604820251465, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.005219064187258482, 'loss_2': 0.0010309219360351562, 'loss_3': -16.358734130859375, 'loss_4': 0.23864847421646118, 'epoch': 22.72}
{'loss': 0.0091, 'grad_norm': 4.853708267211914, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.005946303717792034, 'loss_2': 0.0031585693359375, 'loss_3': -16.450180053710938, 'loss_4': 0.47748205065727234, 'epoch': 22.72}
{'loss': 0.0031, 'grad_norm': 4.410886764526367, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.002698719734326005, 'loss_2': 0.0004076957702636719, 'loss_3': -16.540355682373047, 'loss_4': 0.17291809618473053, 'epoch': 22.73}
{'loss': 0.0078, 'grad_norm': 4.730465888977051, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.004259446635842323, 'loss_2': 0.003566741943359375, 'loss_3': -16.364059448242188, 'loss_4': 0.09629121422767639, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 13:56:38,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:38,770 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:33<21:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:46,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012465815991163254, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010153296403586864, 'eval_loss_2': 0.0023125186562538147, 'eval_loss_3': -18.18394660949707, 'eval_loss_4': 0.27684882283210754, 'epoch': 22.73}
{'loss': 0.012, 'grad_norm': 5.970945358276367, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.011073182336986065, 'loss_2': 0.0009388923645019531, 'loss_3': -16.145832061767578, 'loss_4': -0.0010659433901309967, 'epoch': 22.74}
{'loss': 0.0065, 'grad_norm': 4.479121208190918, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.0037844551261514425, 'loss_2': 0.0027313232421875, 'loss_3': -16.5389404296875, 'loss_4': 0.7226016521453857, 'epoch': 22.74}
{'loss': 0.0092, 'grad_norm': 7.150553226470947, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.008543506264686584, 'loss_2': 0.0006895065307617188, 'loss_3': -16.117996215820312, 'loss_4': 0.07798103988170624, 'epoch': 22.75}
{'loss': 0.0091, 'grad_norm': 4.683351516723633, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.0023676466662436724, 'loss_2': 0.00675201416015625, 'loss_3': -16.368196487426758, 'loss_4': 0.2553350329399109, 'epoch': 22.76}
{'loss': 0.004, 'grad_norm': 4.596853256225586, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.003665622090920806, 'loss_2': 0.0003314018249511719, 'loss_3': -16.351547241210938, 'loss_4': 0.26103872060775757, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 13:56:46,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:46,119 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:40<21:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:53,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013860566541552544, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.089, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010233280248939991, 'eval_loss_2': 0.003627285361289978, 'eval_loss_3': -18.183401107788086, 'eval_loss_4': 0.1943332701921463, 'epoch': 22.76}
{'loss': 0.0149, 'grad_norm': 5.170742511749268, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.0051791914738714695, 'loss_2': 0.00972747802734375, 'loss_3': -16.49372673034668, 'loss_4': -0.24129533767700195, 'epoch': 22.77}
{'loss': 0.0055, 'grad_norm': 4.543388366699219, 'learning_rate': 7.25e-06, 'loss_1': 0.004393489100039005, 'loss_2': 0.0011463165283203125, 'loss_3': -16.514257431030273, 'loss_4': 0.5113108158111572, 'epoch': 22.77}
{'loss': 0.0072, 'grad_norm': 4.606921672821045, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.002346696564927697, 'loss_2': 0.00482940673828125, 'loss_3': -16.525794982910156, 'loss_4': 0.3662436008453369, 'epoch': 22.78}
{'loss': 0.0034, 'grad_norm': 4.465020179748535, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.0032955408096313477, 'loss_2': 0.00014269351959228516, 'loss_3': -16.475364685058594, 'loss_4': 0.26968294382095337, 'epoch': 22.78}
{'loss': 0.0049, 'grad_norm': 4.770562648773193, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.0030123242177069187, 'loss_2': 0.001850128173828125, 'loss_3': -16.175308227539062, 'loss_4': 0.7006096243858337, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 13:56:53,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:53,471 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:47<21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:00,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012644312344491482, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.764, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009502044878900051, 'eval_loss_2': 0.0031422674655914307, 'eval_loss_3': -18.179916381835938, 'eval_loss_4': 0.20645774900913239, 'epoch': 22.79}
{'loss': 0.0748, 'grad_norm': 10.420191764831543, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.06803315132856369, 'loss_2': 0.006717681884765625, 'loss_3': -16.530805587768555, 'loss_4': 0.6406523585319519, 'epoch': 22.8}
{'loss': 0.0131, 'grad_norm': 5.12182092666626, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.005474298261106014, 'loss_2': 0.0076751708984375, 'loss_3': -16.249177932739258, 'loss_4': 0.2571680247783661, 'epoch': 22.8}
{'loss': 0.0159, 'grad_norm': 6.834143161773682, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.008454791270196438, 'loss_2': 0.007415771484375, 'loss_3': -16.18747329711914, 'loss_4': 0.12990230321884155, 'epoch': 22.81}
{'loss': 0.0085, 'grad_norm': 5.270830154418945, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.004467264749109745, 'loss_2': 0.004058837890625, 'loss_3': -16.380359649658203, 'loss_4': 0.14248928427696228, 'epoch': 22.81}
{'loss': 0.0059, 'grad_norm': 4.3976850509643555, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.004889666568487883, 'loss_2': 0.0009646415710449219, 'loss_3': -16.461666107177734, 'loss_4': 0.6875669956207275, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 13:57:00,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:00,829 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:55<21:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:08,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012963373214006424, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.096, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010555255226790905, 'eval_loss_2': 0.0024081170558929443, 'eval_loss_3': -18.188451766967773, 'eval_loss_4': 0.18911364674568176, 'epoch': 22.82}
{'loss': 0.0051, 'grad_norm': 4.305777549743652, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.0032804450020194054, 'loss_2': 0.00183868408203125, 'loss_3': -16.402311325073242, 'loss_4': 0.465711772441864, 'epoch': 22.83}
{'loss': 0.0285, 'grad_norm': 17.438854217529297, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.02116323821246624, 'loss_2': 0.0073394775390625, 'loss_3': -16.26181411743164, 'loss_4': -0.07050170004367828, 'epoch': 22.83}
{'loss': 0.0099, 'grad_norm': 5.175253391265869, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.004175690468400717, 'loss_2': 0.00569915771484375, 'loss_3': -16.49686622619629, 'loss_4': 0.30632483959198, 'epoch': 22.84}
{'loss': 0.0066, 'grad_norm': 5.293667793273926, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.0034155966714024544, 'loss_2': 0.003192901611328125, 'loss_3': -16.640235900878906, 'loss_4': 0.24230536818504333, 'epoch': 22.84}
{'loss': 0.0103, 'grad_norm': 5.523113250732422, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.0065723927691578865, 'loss_2': 0.003681182861328125, 'loss_3': -16.334699630737305, 'loss_4': -0.112861767411232, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 13:57:08,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:08,185 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:37:02<21:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:15,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014702947810292244, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011633256450295448, 'eval_loss_2': 0.0030696913599967957, 'eval_loss_3': -18.17442512512207, 'eval_loss_4': 0.1778966188430786, 'epoch': 22.85}
{'loss': 0.0083, 'grad_norm': 4.554239749908447, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.002983739133924246, 'loss_2': 0.005340576171875, 'loss_3': -16.461456298828125, 'loss_4': 0.08136391639709473, 'epoch': 22.85}
{'loss': 0.0115, 'grad_norm': 5.16886568069458, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.002921399427577853, 'loss_2': 0.00858306884765625, 'loss_3': -16.509363174438477, 'loss_4': 0.21671679615974426, 'epoch': 22.86}
{'loss': 0.0094, 'grad_norm': 5.068002700805664, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.0071016596630215645, 'loss_2': 0.002277374267578125, 'loss_3': -16.281845092773438, 'loss_4': 0.03268054127693176, 'epoch': 22.87}
{'loss': 0.0153, 'grad_norm': 6.8394293785095215, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.011355201713740826, 'loss_2': 0.003932952880859375, 'loss_3': -16.34189796447754, 'loss_4': -0.11283228546380997, 'epoch': 22.87}
{'loss': 0.0038, 'grad_norm': 4.093020915985107, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.002791387727484107, 'loss_2': 0.0010156631469726562, 'loss_3': -16.252593994140625, 'loss_4': 0.2769438922405243, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 13:57:15,540 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:15,540 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:09<21:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:22,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015579676255583763, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012069485150277615, 'eval_loss_2': 0.003510192036628723, 'eval_loss_3': -18.171382904052734, 'eval_loss_4': 0.21399571001529694, 'epoch': 22.88}
{'loss': 0.0064, 'grad_norm': 5.949697494506836, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.006388453301042318, 'loss_2': 5.40614128112793e-05, 'loss_3': -16.520431518554688, 'loss_4': 0.548701286315918, 'epoch': 22.88}
{'loss': 0.0116, 'grad_norm': 6.647717475891113, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.008126256056129932, 'loss_2': 0.00347900390625, 'loss_3': -16.49613380432129, 'loss_4': -0.17319424450397491, 'epoch': 22.89}
{'loss': 0.0039, 'grad_norm': 4.2278828620910645, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.0031142267398536205, 'loss_2': 0.0008287429809570312, 'loss_3': -16.446889877319336, 'loss_4': 0.4749106764793396, 'epoch': 22.9}
{'loss': 0.0105, 'grad_norm': 5.242324352264404, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.010120687074959278, 'loss_2': 0.0004267692565917969, 'loss_3': -16.325929641723633, 'loss_4': 0.016541365534067154, 'epoch': 22.9}
{'loss': 0.0094, 'grad_norm': 5.04292106628418, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.005138316657394171, 'loss_2': 0.00426483154296875, 'loss_3': -16.404096603393555, 'loss_4': 0.25210100412368774, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 13:57:22,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:22,891 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:17<21:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:30,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013616928830742836, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010243485681712627, 'eval_loss_2': 0.003373444080352783, 'eval_loss_3': -18.172542572021484, 'eval_loss_4': 0.0797557681798935, 'epoch': 22.91}
{'loss': 0.0107, 'grad_norm': 4.530586242675781, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.00395600963383913, 'loss_2': 0.0066986083984375, 'loss_3': -16.39032745361328, 'loss_4': 0.140266552567482, 'epoch': 22.91}
{'loss': 0.0061, 'grad_norm': 5.5511860847473145, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.004235907457768917, 'loss_2': 0.0018787384033203125, 'loss_3': -16.451019287109375, 'loss_4': -0.05957213044166565, 'epoch': 22.92}
{'loss': 0.0067, 'grad_norm': 4.499811172485352, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.004674119409173727, 'loss_2': 0.002017974853515625, 'loss_3': -16.635744094848633, 'loss_4': -0.4000215530395508, 'epoch': 22.92}
{'loss': 0.0109, 'grad_norm': 5.815385818481445, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.009483602829277515, 'loss_2': 0.0013675689697265625, 'loss_3': -16.307388305664062, 'loss_4': 0.17041422426700592, 'epoch': 22.93}
{'loss': 0.0112, 'grad_norm': 4.611647605895996, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.004498236812651157, 'loss_2': 0.0067138671875, 'loss_3': -16.41366958618164, 'loss_4': -0.07544463872909546, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 13:57:30,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:30,237 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:24<20:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:37,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013187947683036327, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009878712706267834, 'eval_loss_2': 0.0033092349767684937, 'eval_loss_3': -18.169998168945312, 'eval_loss_4': -0.020734433084726334, 'epoch': 22.94}
{'loss': 0.0106, 'grad_norm': 4.89948034286499, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.0024843323044478893, 'loss_2': 0.00809478759765625, 'loss_3': -16.50606346130371, 'loss_4': 0.12435407936573029, 'epoch': 22.94}
{'loss': 0.0092, 'grad_norm': 4.270558834075928, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.002611713018268347, 'loss_2': 0.006591796875, 'loss_3': -16.347217559814453, 'loss_4': 0.16306334733963013, 'epoch': 22.95}
{'loss': 0.0115, 'grad_norm': 4.645443439483643, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.003643395844846964, 'loss_2': 0.007843017578125, 'loss_3': -16.162574768066406, 'loss_4': -0.35657966136932373, 'epoch': 22.95}
{'loss': 0.0199, 'grad_norm': 8.501358032226562, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.010387699119746685, 'loss_2': 0.00946807861328125, 'loss_3': -16.42601203918457, 'loss_4': 0.04769086092710495, 'epoch': 22.96}
{'loss': 0.0031, 'grad_norm': 4.373102188110352, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.0028121941722929478, 'loss_2': 0.0003161430358886719, 'loss_3': -16.43292999267578, 'loss_4': -0.044283632189035416, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 13:57:37,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:37,579 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:31<20:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:57:44,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013769624754786491, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010058713145554066, 'eval_loss_2': 0.003710910677909851, 'eval_loss_3': -18.181114196777344, 'eval_loss_4': -0.06281530112028122, 'epoch': 22.97}
{'loss': 0.0148, 'grad_norm': 5.714375972747803, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.011006428860127926, 'loss_2': 0.003772735595703125, 'loss_3': -16.25747299194336, 'loss_4': 0.2670043706893921, 'epoch': 22.97}
{'loss': 0.0106, 'grad_norm': 5.242532253265381, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.008995234034955502, 'loss_2': 0.001556396484375, 'loss_3': -16.383312225341797, 'loss_4': -0.03678648918867111, 'epoch': 22.98}
{'loss': 0.0043, 'grad_norm': 4.909961223602295, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.004045920446515083, 'loss_2': 0.0002713203430175781, 'loss_3': -16.389938354492188, 'loss_4': 0.14482033252716064, 'epoch': 22.98}
{'loss': 0.0113, 'grad_norm': 4.565712928771973, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.006000372115522623, 'loss_2': 0.005321502685546875, 'loss_3': -16.451847076416016, 'loss_4': -0.0436704084277153, 'epoch': 22.99}
{'loss': 0.0079, 'grad_norm': 5.307265281677246, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.0045380424708127975, 'loss_2': 0.003398895263671875, 'loss_3': -16.53739356994629, 'loss_4': -0.2693500220775604, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 13:57:44,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:44,907 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:39<20:22,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:57:51,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01350175216794014, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.672, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009889354929327965, 'eval_loss_2': 0.0036123991012573242, 'eval_loss_3': -18.183448791503906, 'eval_loss_4': -0.11345119774341583, 'epoch': 22.99}
{'loss': 0.0067, 'grad_norm': 5.7714338302612305, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.0032320839818567038, 'loss_2': 0.003437042236328125, 'loss_3': -16.24356460571289, 'loss_4': -0.3060123026371002, 'epoch': 23.0}
{'loss': 0.0043, 'grad_norm': 4.631382942199707, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.0022986859548836946, 'loss_2': 0.001995086669921875, 'loss_3': -16.502822875976562, 'loss_4': -0.3123256266117096, 'epoch': 23.01}
{'loss': 0.0254, 'grad_norm': 13.005331039428711, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.021983306854963303, 'loss_2': 0.003376007080078125, 'loss_3': -16.412675857543945, 'loss_4': -0.4776543080806732, 'epoch': 23.01}
{'loss': 0.0104, 'grad_norm': 6.769511699676514, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.007813083939254284, 'loss_2': 0.0025482177734375, 'loss_3': -16.33576774597168, 'loss_4': 0.38822370767593384, 'epoch': 23.02}
{'loss': 0.0057, 'grad_norm': 4.681825160980225, 'learning_rate': 7e-06, 'loss_1': 0.002373185008764267, 'loss_2': 0.003326416015625, 'loss_3': -16.50259017944336, 'loss_4': 0.11841435730457306, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 13:57:51,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:51,973 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:46<20:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:57:59,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014071337878704071, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01021365076303482, 'eval_loss_2': 0.0038576871156692505, 'eval_loss_3': -18.175575256347656, 'eval_loss_4': -0.11712297797203064, 'epoch': 23.02}
{'loss': 0.0296, 'grad_norm': 13.585391998291016, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.023499757051467896, 'loss_2': 0.0061492919921875, 'loss_3': -16.33062171936035, 'loss_4': -0.5419849753379822, 'epoch': 23.03}
{'loss': 0.0067, 'grad_norm': 5.122002601623535, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.0050833686254918575, 'loss_2': 0.00157928466796875, 'loss_3': -16.173545837402344, 'loss_4': -0.5467278957366943, 'epoch': 23.03}
{'loss': 0.0077, 'grad_norm': 7.664604663848877, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.006898291874676943, 'loss_2': 0.0007848739624023438, 'loss_3': -16.439260482788086, 'loss_4': 0.434356689453125, 'epoch': 23.04}
{'loss': 0.016, 'grad_norm': 4.679642677307129, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.005413581617176533, 'loss_2': 0.0105743408203125, 'loss_3': -16.319910049438477, 'loss_4': -0.06971552222967148, 'epoch': 23.05}
{'loss': 0.0104, 'grad_norm': 4.82696533203125, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.004399177618324757, 'loss_2': 0.00605010986328125, 'loss_3': -16.274066925048828, 'loss_4': -0.14212580025196075, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 13:57:59,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:59,321 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:53<20:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:06,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015984421595931053, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010188375599682331, 'eval_loss_2': 0.0057960450649261475, 'eval_loss_3': -18.171173095703125, 'eval_loss_4': -0.1582104116678238, 'epoch': 23.05}
{'loss': 0.0076, 'grad_norm': 4.544271469116211, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.003922757226973772, 'loss_2': 0.0037097930908203125, 'loss_3': -16.621559143066406, 'loss_4': -0.35113686323165894, 'epoch': 23.06}
{'loss': 0.0187, 'grad_norm': 7.435657978057861, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.013920744881033897, 'loss_2': 0.0047454833984375, 'loss_3': -16.221956253051758, 'loss_4': -0.1011580377817154, 'epoch': 23.06}
{'loss': 0.0035, 'grad_norm': 4.466475009918213, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.0026481663808226585, 'loss_2': 0.0008668899536132812, 'loss_3': -16.38227081298828, 'loss_4': -0.24418076872825623, 'epoch': 23.07}
{'loss': 0.0221, 'grad_norm': 11.399147987365723, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.01483768131583929, 'loss_2': 0.00730133056640625, 'loss_3': -16.14619255065918, 'loss_4': 0.022797107696533203, 'epoch': 23.08}
{'loss': 0.0182, 'grad_norm': 5.537417888641357, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.006152428220957518, 'loss_2': 0.01201629638671875, 'loss_3': -16.574127197265625, 'loss_4': -0.5408768057823181, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 13:58:06,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:06,667 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:38:01<20:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:14,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01590883731842041, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01082814484834671, 'eval_loss_2': 0.0050806924700737, 'eval_loss_3': -18.170799255371094, 'eval_loss_4': -0.17243894934654236, 'epoch': 23.08}
{'loss': 0.0057, 'grad_norm': 4.442632675170898, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.002525446703657508, 'loss_2': 0.003177642822265625, 'loss_3': -16.58056640625, 'loss_4': -0.046588361263275146, 'epoch': 23.09}
{'loss': 0.005, 'grad_norm': 4.147104740142822, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.0026547482702881098, 'loss_2': 0.0023651123046875, 'loss_3': -16.38121795654297, 'loss_4': -0.05663977563381195, 'epoch': 23.09}
{'loss': 0.0061, 'grad_norm': 4.884162425994873, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.0033705991227179766, 'loss_2': 0.00270843505859375, 'loss_3': -16.362205505371094, 'loss_4': -0.5771575570106506, 'epoch': 23.1}
{'loss': 0.0097, 'grad_norm': 5.425442218780518, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.005790398921817541, 'loss_2': 0.0038604736328125, 'loss_3': -16.22195816040039, 'loss_4': -0.536377489566803, 'epoch': 23.1}
{'loss': 0.023, 'grad_norm': 12.50333309173584, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.020965037867426872, 'loss_2': 0.002002716064453125, 'loss_3': -16.40943717956543, 'loss_4': 0.04100160300731659, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 13:58:14,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:14,012 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:08<20:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:21,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01410666760057211, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010930569842457771, 'eval_loss_2': 0.0031760968267917633, 'eval_loss_3': -18.16165542602539, 'eval_loss_4': -0.2035529911518097, 'epoch': 23.11}
{'loss': 0.0258, 'grad_norm': 11.794243812561035, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.02524579130113125, 'loss_2': 0.0005559921264648438, 'loss_3': -16.277507781982422, 'loss_4': -0.14669674634933472, 'epoch': 23.12}
{'loss': 0.0046, 'grad_norm': 4.5429792404174805, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.002559326821938157, 'loss_2': 0.0020427703857421875, 'loss_3': -16.51964569091797, 'loss_4': -0.16715916991233826, 'epoch': 23.12}
{'loss': 0.0031, 'grad_norm': 4.792172908782959, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.0023694969713687897, 'loss_2': 0.0007600784301757812, 'loss_3': -16.47960662841797, 'loss_4': 0.046954646706581116, 'epoch': 23.13}
{'loss': 0.0088, 'grad_norm': 4.831088066101074, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.005140886176377535, 'loss_2': 0.003681182861328125, 'loss_3': -16.40591049194336, 'loss_4': -0.5466551184654236, 'epoch': 23.13}
{'loss': 0.0606, 'grad_norm': 16.02242660522461, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.05875251442193985, 'loss_2': 0.0018939971923828125, 'loss_3': -16.504837036132812, 'loss_4': 0.2690620422363281, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 13:58:21,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:21,353 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:15<20:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:28,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014704941771924496, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.635, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010827898047864437, 'eval_loss_2': 0.0038770437240600586, 'eval_loss_3': -18.164745330810547, 'eval_loss_4': -0.22238686680793762, 'epoch': 23.14}
{'loss': 0.0218, 'grad_norm': 15.555339813232422, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.02001858688890934, 'loss_2': 0.0018215179443359375, 'loss_3': -16.40830421447754, 'loss_4': 0.3796425461769104, 'epoch': 23.15}
{'loss': 0.0117, 'grad_norm': 4.753642559051514, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.004211734980344772, 'loss_2': 0.00743865966796875, 'loss_3': -16.485570907592773, 'loss_4': -0.2240181714296341, 'epoch': 23.15}
{'loss': 0.0048, 'grad_norm': 4.16332483291626, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.0024720702785998583, 'loss_2': 0.002323150634765625, 'loss_3': -16.575218200683594, 'loss_4': 0.136210098862648, 'epoch': 23.16}
{'loss': 0.0095, 'grad_norm': 4.344621181488037, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.004546470008790493, 'loss_2': 0.00494384765625, 'loss_3': -16.450368881225586, 'loss_4': 0.08605405688285828, 'epoch': 23.16}
{'loss': 0.0086, 'grad_norm': 5.122024059295654, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.004140459466725588, 'loss_2': 0.004474639892578125, 'loss_3': -16.356740951538086, 'loss_4': -0.26137763261795044, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 13:58:28,699 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:28,699 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:23<20:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:36,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014157210476696491, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010809172876179218, 'eval_loss_2': 0.003348037600517273, 'eval_loss_3': -18.176124572753906, 'eval_loss_4': -0.27561700344085693, 'epoch': 23.17}
{'loss': 0.0044, 'grad_norm': 6.029214859008789, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.004174991510808468, 'loss_2': 0.0002435445785522461, 'loss_3': -16.30484390258789, 'loss_4': -0.15331709384918213, 'epoch': 23.17}
{'loss': 0.0075, 'grad_norm': 4.558536529541016, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.003156827762722969, 'loss_2': 0.004375457763671875, 'loss_3': -16.432430267333984, 'loss_4': -0.28756266832351685, 'epoch': 23.18}
{'loss': 0.0099, 'grad_norm': 5.426732063293457, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.008200044743716717, 'loss_2': 0.0017480850219726562, 'loss_3': -16.486492156982422, 'loss_4': -0.6300086975097656, 'epoch': 23.19}
{'loss': 0.0078, 'grad_norm': 4.567865371704102, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.005718927830457687, 'loss_2': 0.0020465850830078125, 'loss_3': -16.287729263305664, 'loss_4': -0.099114790558815, 'epoch': 23.19}
{'loss': 0.0081, 'grad_norm': 5.080448627471924, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.004379099700599909, 'loss_2': 0.0037097930908203125, 'loss_3': -16.47401237487793, 'loss_4': -0.1651727259159088, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 13:58:36,046 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:36,046 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:30<20:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:43,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014998079277575016, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010926203802227974, 'eval_loss_2': 0.004071876406669617, 'eval_loss_3': -18.169479370117188, 'eval_loss_4': -0.31058168411254883, 'epoch': 23.2}
{'loss': 0.0118, 'grad_norm': 5.580160140991211, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.0065268222242593765, 'loss_2': 0.005306243896484375, 'loss_3': -16.355365753173828, 'loss_4': -0.12297545373439789, 'epoch': 23.2}
{'loss': 0.0059, 'grad_norm': 4.788644313812256, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.004471376072615385, 'loss_2': 0.00145721435546875, 'loss_3': -16.387603759765625, 'loss_4': -0.2999202609062195, 'epoch': 23.21}
{'loss': 0.0148, 'grad_norm': 7.83513069152832, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.01051534153521061, 'loss_2': 0.0042724609375, 'loss_3': -16.466293334960938, 'loss_4': -0.397024005651474, 'epoch': 23.22}
{'loss': 0.0075, 'grad_norm': 5.385905742645264, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.005390722304582596, 'loss_2': 0.002140045166015625, 'loss_3': -16.395626068115234, 'loss_4': -0.38455936312675476, 'epoch': 23.22}
{'loss': 0.0138, 'grad_norm': 6.0065436363220215, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.007787749636918306, 'loss_2': 0.006011962890625, 'loss_3': -16.432802200317383, 'loss_4': -0.0415392741560936, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 13:58:43,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:43,394 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:37<20:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:50,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014981819316744804, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.571, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011403214186429977, 'eval_loss_2': 0.0035786032676696777, 'eval_loss_3': -18.175498962402344, 'eval_loss_4': -0.26975372433662415, 'epoch': 23.23}
{'loss': 0.0067, 'grad_norm': 5.58678674697876, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.005938178393989801, 'loss_2': 0.0007405281066894531, 'loss_3': -16.537763595581055, 'loss_4': -0.08373308181762695, 'epoch': 23.23}
{'loss': 0.0089, 'grad_norm': 5.116689205169678, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.007129603996872902, 'loss_2': 0.0018110275268554688, 'loss_3': -16.35630226135254, 'loss_4': 0.018180496990680695, 'epoch': 23.24}
{'loss': 0.0072, 'grad_norm': 4.315902233123779, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.005380168557167053, 'loss_2': 0.001781463623046875, 'loss_3': -16.462574005126953, 'loss_4': -0.4118773937225342, 'epoch': 23.24}
{'loss': 0.0072, 'grad_norm': 5.17238187789917, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.005156476050615311, 'loss_2': 0.002063751220703125, 'loss_3': -16.43848419189453, 'loss_4': -0.5077752470970154, 'epoch': 23.25}
{'loss': 0.0104, 'grad_norm': 5.461823463439941, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.005585719831287861, 'loss_2': 0.0047760009765625, 'loss_3': -16.301990509033203, 'loss_4': 0.22722002863883972, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 13:58:50,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:50,732 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:45<19:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:58,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015002841129899025, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.229, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011172110214829445, 'eval_loss_2': 0.00383073091506958, 'eval_loss_3': -18.176034927368164, 'eval_loss_4': -0.19793947041034698, 'epoch': 23.26}
{'loss': 0.0078, 'grad_norm': 5.142545223236084, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.006053779739886522, 'loss_2': 0.0016984939575195312, 'loss_3': -16.34625244140625, 'loss_4': -0.25287917256355286, 'epoch': 23.26}
{'loss': 0.0032, 'grad_norm': 4.978923797607422, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.002749226987361908, 'loss_2': 0.0004892349243164062, 'loss_3': -16.429351806640625, 'loss_4': -0.027793362736701965, 'epoch': 23.27}
{'loss': 0.0046, 'grad_norm': 4.865243434906006, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.00364122586324811, 'loss_2': 0.0009832382202148438, 'loss_3': -16.286596298217773, 'loss_4': -0.5000408291816711, 'epoch': 23.27}
{'loss': 0.0085, 'grad_norm': 5.090511798858643, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.00303113111294806, 'loss_2': 0.0055084228515625, 'loss_3': -16.436979293823242, 'loss_4': 0.15892735123634338, 'epoch': 23.28}
{'loss': 0.0185, 'grad_norm': 6.564362525939941, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.013850604183971882, 'loss_2': 0.0046539306640625, 'loss_3': -16.29548454284668, 'loss_4': -0.5831573009490967, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 13:58:58,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:58,076 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:52<19:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:05,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014518479816615582, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010466317646205425, 'eval_loss_2': 0.004052162170410156, 'eval_loss_3': -18.18096923828125, 'eval_loss_4': -0.15270112454891205, 'epoch': 23.28}
{'loss': 0.0141, 'grad_norm': 5.98360538482666, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.008825631812214851, 'loss_2': 0.005279541015625, 'loss_3': -16.2919864654541, 'loss_4': -0.2397436946630478, 'epoch': 23.29}
{'loss': 0.0157, 'grad_norm': 9.861974716186523, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.01509875152260065, 'loss_2': 0.0006084442138671875, 'loss_3': -16.254398345947266, 'loss_4': -0.08280415832996368, 'epoch': 23.3}
{'loss': 0.0043, 'grad_norm': 4.516234874725342, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.003460729494690895, 'loss_2': 0.0008211135864257812, 'loss_3': -16.485687255859375, 'loss_4': 0.21500247716903687, 'epoch': 23.3}
{'loss': 0.0072, 'grad_norm': 4.352978706359863, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.0024785241112113, 'loss_2': 0.0047607421875, 'loss_3': -16.46136474609375, 'loss_4': -0.17724239826202393, 'epoch': 23.31}
{'loss': 0.0126, 'grad_norm': 6.693492889404297, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.009510575793683529, 'loss_2': 0.00310516357421875, 'loss_3': -16.224018096923828, 'loss_4': -0.272438645362854, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 13:59:05,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:05,417 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:59<19:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:12,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014101631008088589, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010211847722530365, 'eval_loss_2': 0.0038897842168807983, 'eval_loss_3': -18.180795669555664, 'eval_loss_4': -0.04254768043756485, 'epoch': 23.31}
{'loss': 0.0065, 'grad_norm': 4.496230125427246, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.003408973105251789, 'loss_2': 0.0031280517578125, 'loss_3': -16.213550567626953, 'loss_4': 0.007458239793777466, 'epoch': 23.32}
{'loss': 0.009, 'grad_norm': 6.465695381164551, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.008631834760308266, 'loss_2': 0.0003705024719238281, 'loss_3': -16.408462524414062, 'loss_4': 0.3243626654148102, 'epoch': 23.33}
{'loss': 0.0043, 'grad_norm': 4.611323356628418, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.0019649749156087637, 'loss_2': 0.0023059844970703125, 'loss_3': -16.560718536376953, 'loss_4': 0.08470723778009415, 'epoch': 23.33}
{'loss': 0.0044, 'grad_norm': 4.28463888168335, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.003913210704922676, 'loss_2': 0.00045180320739746094, 'loss_3': -16.429546356201172, 'loss_4': 0.3076116442680359, 'epoch': 23.34}
{'loss': 0.0135, 'grad_norm': 5.274028301239014, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.005796719342470169, 'loss_2': 0.00774383544921875, 'loss_3': -16.412080764770508, 'loss_4': 0.1303524523973465, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 13:59:12,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:12,766 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:07<19:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:20,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014557937160134315, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.761, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009920560754835606, 'eval_loss_2': 0.004637375473976135, 'eval_loss_3': -18.185935974121094, 'eval_loss_4': -0.006604943424463272, 'epoch': 23.34}
{'loss': 0.0039, 'grad_norm': 4.269358158111572, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.0020021607633680105, 'loss_2': 0.0019388198852539062, 'loss_3': -16.49475860595703, 'loss_4': -0.1581188440322876, 'epoch': 23.35}
{'loss': 0.0082, 'grad_norm': 5.051977634429932, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.003038704628124833, 'loss_2': 0.00514984130859375, 'loss_3': -16.352680206298828, 'loss_4': -0.11806771159172058, 'epoch': 23.35}
{'loss': 0.0086, 'grad_norm': 5.602416515350342, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.006685625296086073, 'loss_2': 0.001941680908203125, 'loss_3': -16.461687088012695, 'loss_4': 0.165968656539917, 'epoch': 23.36}
{'loss': 0.0076, 'grad_norm': 5.628499984741211, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.0042388467118144035, 'loss_2': 0.0034027099609375, 'loss_3': -16.32793426513672, 'loss_4': -0.13672563433647156, 'epoch': 23.37}
{'loss': 0.0316, 'grad_norm': 18.775753021240234, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.028538377955555916, 'loss_2': 0.0030918121337890625, 'loss_3': -16.335163116455078, 'loss_4': -0.40381550788879395, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 13:59:20,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:20,121 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:14<19:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:27,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014462854713201523, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009907227009534836, 'eval_loss_2': 0.004555627703666687, 'eval_loss_3': -18.19045639038086, 'eval_loss_4': 0.013848874717950821, 'epoch': 23.37}
{'loss': 0.008, 'grad_norm': 6.716997146606445, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.007106559816747904, 'loss_2': 0.0009431838989257812, 'loss_3': -16.48055648803711, 'loss_4': -0.02638976275920868, 'epoch': 23.38}
{'loss': 0.0108, 'grad_norm': 4.330716133117676, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.005993800703436136, 'loss_2': 0.0047607421875, 'loss_3': -16.23113250732422, 'loss_4': 0.4005795121192932, 'epoch': 23.38}
{'loss': 0.0043, 'grad_norm': 4.544929027557373, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.0027978166472166777, 'loss_2': 0.0014562606811523438, 'loss_3': -16.397281646728516, 'loss_4': 0.15708671510219574, 'epoch': 23.39}
{'loss': 0.0056, 'grad_norm': 4.357180118560791, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.00498570641502738, 'loss_2': 0.00061798095703125, 'loss_3': -16.436317443847656, 'loss_4': -0.10817581415176392, 'epoch': 23.4}
{'loss': 0.0071, 'grad_norm': 6.769869804382324, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.0049878195859491825, 'loss_2': 0.00213623046875, 'loss_3': -16.286497116088867, 'loss_4': 0.18849369883537292, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 13:59:27,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:27,463 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:21<19:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:34,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014721548184752464, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.675, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009811227209866047, 'eval_loss_2': 0.004910320043563843, 'eval_loss_3': -18.194339752197266, 'eval_loss_4': 0.03534742444753647, 'epoch': 23.4}
{'loss': 0.0085, 'grad_norm': 5.288625717163086, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.0036962609738111496, 'loss_2': 0.0047760009765625, 'loss_3': -16.358985900878906, 'loss_4': 0.18377134203910828, 'epoch': 23.41}
{'loss': 0.0082, 'grad_norm': 5.004505634307861, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.004798201844096184, 'loss_2': 0.0033969879150390625, 'loss_3': -16.320568084716797, 'loss_4': -0.0035301148891448975, 'epoch': 23.41}
{'loss': 0.0104, 'grad_norm': 4.642094612121582, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.0020421678200364113, 'loss_2': 0.0083465576171875, 'loss_3': -16.467243194580078, 'loss_4': 0.17423909902572632, 'epoch': 23.42}
{'loss': 0.0081, 'grad_norm': 8.210994720458984, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.006209764629602432, 'loss_2': 0.001888275146484375, 'loss_3': -16.403003692626953, 'loss_4': 0.15915802121162415, 'epoch': 23.42}
{'loss': 0.002, 'grad_norm': 4.6965718269348145, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.0015586980152875185, 'loss_2': 0.000431060791015625, 'loss_3': -16.301742553710938, 'loss_4': -0.13289830088615417, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 13:59:34,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:34,804 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:29<19:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:42,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016030892729759216, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.897, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010389253497123718, 'eval_loss_2': 0.005641639232635498, 'eval_loss_3': -18.208370208740234, 'eval_loss_4': 0.02776312455534935, 'epoch': 23.43}
{'loss': 0.0064, 'grad_norm': 4.06189489364624, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.0027624256908893585, 'loss_2': 0.003620147705078125, 'loss_3': -16.651599884033203, 'loss_4': 0.5152932405471802, 'epoch': 23.44}
{'loss': 0.0051, 'grad_norm': 5.190732479095459, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.004283790476620197, 'loss_2': 0.0008592605590820312, 'loss_3': -16.49584197998047, 'loss_4': 0.16410508751869202, 'epoch': 23.44}
{'loss': 0.0103, 'grad_norm': 5.187587738037109, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.004479588475078344, 'loss_2': 0.005809783935546875, 'loss_3': -16.368223190307617, 'loss_4': 0.1747487187385559, 'epoch': 23.45}
{'loss': 0.0172, 'grad_norm': 5.217991352081299, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.006135418079793453, 'loss_2': 0.0111083984375, 'loss_3': -16.134422302246094, 'loss_4': 0.664147138595581, 'epoch': 23.45}
{'loss': 0.0133, 'grad_norm': 6.059549331665039, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.00931231863796711, 'loss_2': 0.00395965576171875, 'loss_3': -16.506437301635742, 'loss_4': -0.07172318547964096, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 13:59:42,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:42,137 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:36<19:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:49,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015732211992144585, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.775, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009984474629163742, 'eval_loss_2': 0.005747735500335693, 'eval_loss_3': -18.216720581054688, 'eval_loss_4': 0.013205837458372116, 'epoch': 23.46}
{'loss': 0.0129, 'grad_norm': 5.057590484619141, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.008242479525506496, 'loss_2': 0.0046539306640625, 'loss_3': -16.525836944580078, 'loss_4': -0.12272265553474426, 'epoch': 23.47}
{'loss': 0.0609, 'grad_norm': 10.918449401855469, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.059316061437129974, 'loss_2': 0.0015964508056640625, 'loss_3': -16.388402938842773, 'loss_4': 0.11827105283737183, 'epoch': 23.47}
{'loss': 0.0191, 'grad_norm': 7.440469264984131, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.01169298030436039, 'loss_2': 0.007366180419921875, 'loss_3': -16.42596435546875, 'loss_4': 0.08153076469898224, 'epoch': 23.48}
{'loss': 0.0159, 'grad_norm': 6.777443885803223, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.01337446179240942, 'loss_2': 0.0025177001953125, 'loss_3': -16.47100257873535, 'loss_4': 0.014762312173843384, 'epoch': 23.48}
{'loss': 0.0127, 'grad_norm': 5.1517510414123535, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.0067087197676301, 'loss_2': 0.006011962890625, 'loss_3': -16.261672973632812, 'loss_4': -0.08217760920524597, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 13:59:49,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:49,478 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:43<19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:56,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014207704924046993, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009890824556350708, 'eval_loss_2': 0.00431688129901886, 'eval_loss_3': -18.206283569335938, 'eval_loss_4': 0.05243026465177536, 'epoch': 23.49}
{'loss': 0.0047, 'grad_norm': 4.484324932098389, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.00350010534748435, 'loss_2': 0.001190185546875, 'loss_3': -16.266040802001953, 'loss_4': 0.4063672721385956, 'epoch': 23.49}
{'loss': 0.0104, 'grad_norm': 5.965230941772461, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.007232995703816414, 'loss_2': 0.00312042236328125, 'loss_3': -16.335542678833008, 'loss_4': 0.04709204286336899, 'epoch': 23.5}
{'loss': 0.0219, 'grad_norm': 17.291200637817383, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.021796241402626038, 'loss_2': 0.00014281272888183594, 'loss_3': -16.633813858032227, 'loss_4': 0.520462155342102, 'epoch': 23.51}
{'loss': 0.0057, 'grad_norm': 4.39459753036499, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.0028531192801892757, 'loss_2': 0.0028533935546875, 'loss_3': -16.439428329467773, 'loss_4': 0.35876888036727905, 'epoch': 23.51}
{'loss': 0.0161, 'grad_norm': 7.501054286956787, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.012177624739706516, 'loss_2': 0.00396728515625, 'loss_3': -16.44061851501465, 'loss_4': 0.27312061190605164, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 13:59:56,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:56,822 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:51<19:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:04,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01414184458553791, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010653006844222546, 'eval_loss_2': 0.0034888386726379395, 'eval_loss_3': -18.200439453125, 'eval_loss_4': 0.07086525857448578, 'epoch': 23.52}
{'loss': 0.0164, 'grad_norm': 14.333489418029785, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.014915859326720238, 'loss_2': 0.0015087127685546875, 'loss_3': -16.463150024414062, 'loss_4': 0.11368753761053085, 'epoch': 23.52}
{'loss': 0.0022, 'grad_norm': 4.646819114685059, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.0020234500989317894, 'loss_2': 0.00014543533325195312, 'loss_3': -16.486404418945312, 'loss_4': -0.02743634209036827, 'epoch': 23.53}
{'loss': 0.0085, 'grad_norm': 5.002970218658447, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.004385313019156456, 'loss_2': 0.00406646728515625, 'loss_3': -16.409923553466797, 'loss_4': 0.005246244370937347, 'epoch': 23.53}
{'loss': 0.005, 'grad_norm': 4.780712127685547, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.0046394383534789085, 'loss_2': 0.0003132820129394531, 'loss_3': -16.22241973876953, 'loss_4': -0.14597785472869873, 'epoch': 23.54}
{'loss': 0.0053, 'grad_norm': 4.868922233581543, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.002147038234397769, 'loss_2': 0.003200531005859375, 'loss_3': -16.354145050048828, 'loss_4': -0.11079321801662445, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 14:00:04,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:04,163 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:58<19:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:11,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0143104437738657, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.671, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010509917512536049, 'eval_loss_2': 0.003800526261329651, 'eval_loss_3': -18.186477661132812, 'eval_loss_4': 0.07578393816947937, 'epoch': 23.55}
{'loss': 0.0203, 'grad_norm': 7.908308506011963, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.017473677173256874, 'loss_2': 0.002857208251953125, 'loss_3': -16.629629135131836, 'loss_4': -0.1304708570241928, 'epoch': 23.55}
{'loss': 0.0062, 'grad_norm': 4.944798946380615, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.004224757663905621, 'loss_2': 0.00200653076171875, 'loss_3': -16.387977600097656, 'loss_4': -0.16071826219558716, 'epoch': 23.56}
{'loss': 0.0044, 'grad_norm': 4.482790470123291, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.0030302945524454117, 'loss_2': 0.001354217529296875, 'loss_3': -16.354387283325195, 'loss_4': 0.4354030191898346, 'epoch': 23.56}
{'loss': 0.0073, 'grad_norm': 5.450512886047363, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.0042634084820747375, 'loss_2': 0.0030841827392578125, 'loss_3': -16.288719177246094, 'loss_4': 0.42587602138519287, 'epoch': 23.57}
{'loss': 0.0099, 'grad_norm': 5.041304588317871, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.005596175789833069, 'loss_2': 0.00426483154296875, 'loss_3': -16.277360916137695, 'loss_4': -1.6391277313232422e-07, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 14:00:11,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:11,499 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:05<18:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:18,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014347193762660027, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.636, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010513811372220516, 'eval_loss_2': 0.003833383321762085, 'eval_loss_3': -18.18361473083496, 'eval_loss_4': 0.07382342219352722, 'epoch': 23.58}
{'loss': 0.0086, 'grad_norm': 5.168076515197754, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.0059443251229822636, 'loss_2': 0.0026073455810546875, 'loss_3': -16.331851959228516, 'loss_4': -0.08350227028131485, 'epoch': 23.58}
{'loss': 0.0098, 'grad_norm': 4.617791175842285, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.003924076911062002, 'loss_2': 0.00588226318359375, 'loss_3': -16.422639846801758, 'loss_4': -0.3322252035140991, 'epoch': 23.59}
{'loss': 0.01, 'grad_norm': 4.3711748123168945, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.0037781803403049707, 'loss_2': 0.00623321533203125, 'loss_3': -16.49694061279297, 'loss_4': -0.00466841459274292, 'epoch': 23.59}
{'loss': 0.0088, 'grad_norm': 4.3749284744262695, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.001817508484236896, 'loss_2': 0.00701141357421875, 'loss_3': -16.41297149658203, 'loss_4': -0.16696491837501526, 'epoch': 23.6}
{'loss': 0.0049, 'grad_norm': 4.6394429206848145, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.003988779615610838, 'loss_2': 0.0009441375732421875, 'loss_3': -16.486419677734375, 'loss_4': -0.31976231932640076, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 14:00:18,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:18,833 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:13<18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:26,166 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01421810220927, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.734, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010703524574637413, 'eval_loss_2': 0.003514576703310013, 'eval_loss_3': -18.180299758911133, 'eval_loss_4': 0.0815986916422844, 'epoch': 23.6}
{'loss': 0.0069, 'grad_norm': 5.643057823181152, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.0062461295165121555, 'loss_2': 0.0006580352783203125, 'loss_3': -16.48889923095703, 'loss_4': -0.09370772540569305, 'epoch': 23.61}
{'loss': 0.0074, 'grad_norm': 4.477818965911865, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.0049471682868897915, 'loss_2': 0.002483367919921875, 'loss_3': -16.44397735595703, 'loss_4': -0.22250111401081085, 'epoch': 23.62}
{'loss': 0.0137, 'grad_norm': 5.502867221832275, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.004346721339970827, 'loss_2': 0.0093231201171875, 'loss_3': -16.129337310791016, 'loss_4': 0.13853754103183746, 'epoch': 23.62}
{'loss': 0.0073, 'grad_norm': 4.611160755157471, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.004898276180028915, 'loss_2': 0.00237274169921875, 'loss_3': -16.32235336303711, 'loss_4': -0.13004174828529358, 'epoch': 23.63}
{'loss': 0.0076, 'grad_norm': 4.972524166107178, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.0028877391014248133, 'loss_2': 0.00469970703125, 'loss_3': -16.4581241607666, 'loss_4': -0.11066467314958572, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 14:00:26,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:26,166 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:20<18:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:33,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01546480879187584, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.557, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010835808701813221, 'eval_loss_2': 0.004629001021385193, 'eval_loss_3': -18.17829132080078, 'eval_loss_4': 0.09651437401771545, 'epoch': 23.63}
{'loss': 0.0196, 'grad_norm': 7.888982772827148, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.011911402456462383, 'loss_2': 0.00765228271484375, 'loss_3': -16.52873992919922, 'loss_4': -0.25864338874816895, 'epoch': 23.64}
{'loss': 0.0054, 'grad_norm': 4.56406307220459, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.0033156394492834806, 'loss_2': 0.0021114349365234375, 'loss_3': -16.394886016845703, 'loss_4': 0.16123096644878387, 'epoch': 23.65}
{'loss': 0.0403, 'grad_norm': 18.593046188354492, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.035915765911340714, 'loss_2': 0.004413604736328125, 'loss_3': -16.37129020690918, 'loss_4': 0.09241043031215668, 'epoch': 23.65}
{'loss': 0.0086, 'grad_norm': 4.572695255279541, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.0020386185497045517, 'loss_2': 0.006572723388671875, 'loss_3': -16.506046295166016, 'loss_4': -0.0487099215388298, 'epoch': 23.66}
{'loss': 0.0052, 'grad_norm': 5.135593891143799, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.003131614299491048, 'loss_2': 0.00209808349609375, 'loss_3': -16.62540054321289, 'loss_4': -0.33455395698547363, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 14:00:33,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:33,509 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:27<18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:40,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01537182368338108, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.942, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011428961530327797, 'eval_loss_2': 0.003942862153053284, 'eval_loss_3': -18.162382125854492, 'eval_loss_4': 0.08347705751657486, 'epoch': 23.66}
{'loss': 0.0125, 'grad_norm': 6.132238864898682, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.0071077607572078705, 'loss_2': 0.00537872314453125, 'loss_3': -16.35055160522461, 'loss_4': -0.3389400541782379, 'epoch': 23.67}
{'loss': 0.0155, 'grad_norm': 11.718368530273438, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.01204790361225605, 'loss_2': 0.0034427642822265625, 'loss_3': -16.430320739746094, 'loss_4': -0.03560864180326462, 'epoch': 23.67}
{'loss': 0.0093, 'grad_norm': 6.407749176025391, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.007489313837140799, 'loss_2': 0.0017719268798828125, 'loss_3': -16.362276077270508, 'loss_4': 0.0695844441652298, 'epoch': 23.68}
{'loss': 0.01, 'grad_norm': 6.429759979248047, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.006378862541168928, 'loss_2': 0.0036563873291015625, 'loss_3': -16.465709686279297, 'loss_4': -0.10964682698249817, 'epoch': 23.69}
{'loss': 0.0072, 'grad_norm': 4.706676483154297, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.0025840159505605698, 'loss_2': 0.00460052490234375, 'loss_3': -16.37850570678711, 'loss_4': 0.19747300446033478, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 14:00:40,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:40,861 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:35<18:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:48,208 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016680657863616943, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011946022510528564, 'eval_loss_2': 0.004734635353088379, 'eval_loss_3': -18.154762268066406, 'eval_loss_4': 0.04034402221441269, 'epoch': 23.69}
{'loss': 0.0078, 'grad_norm': 4.481204032897949, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.0038772497791796923, 'loss_2': 0.003879547119140625, 'loss_3': -16.450912475585938, 'loss_4': 0.0960884541273117, 'epoch': 23.7}
{'loss': 0.018, 'grad_norm': 4.875271320343018, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.004640317987650633, 'loss_2': 0.01336669921875, 'loss_3': -16.50333023071289, 'loss_4': -0.20452536642551422, 'epoch': 23.7}
{'loss': 0.0482, 'grad_norm': 8.220291137695312, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.04529808089137077, 'loss_2': 0.002902984619140625, 'loss_3': -16.482646942138672, 'loss_4': 0.18981945514678955, 'epoch': 23.71}
{'loss': 0.0031, 'grad_norm': 4.961653709411621, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.0025506303645670414, 'loss_2': 0.0005712509155273438, 'loss_3': -16.373727798461914, 'loss_4': 0.048209890723228455, 'epoch': 23.72}
{'loss': 0.0143, 'grad_norm': 4.9450788497924805, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.0034380625002086163, 'loss_2': 0.0108489990234375, 'loss_3': -16.333404541015625, 'loss_4': 0.21527981758117676, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 14:00:48,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:48,209 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:42<18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:55,551 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01629384234547615, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.261, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012145398184657097, 'eval_loss_2': 0.004148442298173904, 'eval_loss_3': -18.16628074645996, 'eval_loss_4': -0.02030845917761326, 'epoch': 23.72}
{'loss': 0.0076, 'grad_norm': 4.883993625640869, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.004940878599882126, 'loss_2': 0.002643585205078125, 'loss_3': -16.31012535095215, 'loss_4': 0.23575837910175323, 'epoch': 23.73}
{'loss': 0.0054, 'grad_norm': 4.787687301635742, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.0022641709074378014, 'loss_2': 0.0031833648681640625, 'loss_3': -16.389144897460938, 'loss_4': 0.14451386034488678, 'epoch': 23.73}
{'loss': 0.0244, 'grad_norm': 10.533949851989746, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.02091345563530922, 'loss_2': 0.003459930419921875, 'loss_3': -16.453231811523438, 'loss_4': -0.12365452200174332, 'epoch': 23.74}
{'loss': 0.0111, 'grad_norm': 5.902188777923584, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.009769204072654247, 'loss_2': 0.00135040283203125, 'loss_3': -16.384624481201172, 'loss_4': 0.3643549680709839, 'epoch': 23.74}
{'loss': 0.0077, 'grad_norm': 5.410676956176758, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.007007273379713297, 'loss_2': 0.000713348388671875, 'loss_3': -16.461750030517578, 'loss_4': -0.016790002584457397, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 14:00:55,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:55,552 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:49<18:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:02,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015868812799453735, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.891, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011250707320868969, 'eval_loss_2': 0.004618104547262192, 'eval_loss_3': -18.174108505249023, 'eval_loss_4': -0.10005933046340942, 'epoch': 23.75}
{'loss': 0.0117, 'grad_norm': 5.15763521194458, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.0062323943711817265, 'loss_2': 0.00550079345703125, 'loss_3': -16.45178985595703, 'loss_4': -0.012409120798110962, 'epoch': 23.76}
{'loss': 0.0047, 'grad_norm': 4.453938961029053, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.0038118124939501286, 'loss_2': 0.0008516311645507812, 'loss_3': -16.176013946533203, 'loss_4': -0.26916128396987915, 'epoch': 23.76}
{'loss': 0.0025, 'grad_norm': 4.715801239013672, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.002435520524159074, 'loss_2': 6.008148193359375e-05, 'loss_3': -16.508697509765625, 'loss_4': -0.2714156210422516, 'epoch': 23.77}
{'loss': 0.0142, 'grad_norm': 5.182656288146973, 'learning_rate': 6.25e-06, 'loss_1': 0.004274314735084772, 'loss_2': 0.00994873046875, 'loss_3': -16.278636932373047, 'loss_4': -0.012893006205558777, 'epoch': 23.77}
{'loss': 0.0059, 'grad_norm': 4.275142669677734, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.002611270872876048, 'loss_2': 0.003292083740234375, 'loss_3': -16.48682403564453, 'loss_4': -0.7799875736236572, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 14:01:02,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:02,886 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:57<18:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:10,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014817532151937485, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.449, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01074856985360384, 'eval_loss_2': 0.0040689632296562195, 'eval_loss_3': -18.180295944213867, 'eval_loss_4': -0.1082092821598053, 'epoch': 23.78}
{'loss': 0.0042, 'grad_norm': 4.5650315284729, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.00394710386171937, 'loss_2': 0.00026798248291015625, 'loss_3': -16.433610916137695, 'loss_4': -0.41110116243362427, 'epoch': 23.78}
{'loss': 0.0064, 'grad_norm': 4.793453216552734, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.006338194943964481, 'loss_2': 0.00011020898818969727, 'loss_3': -16.339012145996094, 'loss_4': 0.07453823834657669, 'epoch': 23.79}
{'loss': 0.0095, 'grad_norm': 4.6579790115356445, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.0028443613555282354, 'loss_2': 0.0066070556640625, 'loss_3': -16.416105270385742, 'loss_4': 0.17031727731227875, 'epoch': 23.8}
{'loss': 0.0125, 'grad_norm': 7.1977009773254395, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.009570627473294735, 'loss_2': 0.0029144287109375, 'loss_3': -16.331899642944336, 'loss_4': -0.09738315641880035, 'epoch': 23.8}
{'loss': 0.0215, 'grad_norm': 10.916668891906738, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.015577420592308044, 'loss_2': 0.00592803955078125, 'loss_3': -16.498046875, 'loss_4': -0.10895906388759613, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 14:01:10,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:10,227 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:04<18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:17,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013989262282848358, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.015, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010331682860851288, 'eval_loss_2': 0.0036575794219970703, 'eval_loss_3': -18.17639923095703, 'eval_loss_4': -0.0928698182106018, 'epoch': 23.81}
{'loss': 0.0304, 'grad_norm': 16.986671447753906, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.027077244594693184, 'loss_2': 0.00334930419921875, 'loss_3': -16.604280471801758, 'loss_4': -0.05116558074951172, 'epoch': 23.81}
{'loss': 0.0089, 'grad_norm': 4.5928497314453125, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.006149331107735634, 'loss_2': 0.0027561187744140625, 'loss_3': -16.40127944946289, 'loss_4': -0.32699525356292725, 'epoch': 23.82}
{'loss': 0.0054, 'grad_norm': 4.390339374542236, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.00361451948992908, 'loss_2': 0.0018253326416015625, 'loss_3': -16.5678768157959, 'loss_4': 0.01462177187204361, 'epoch': 23.83}
{'loss': 0.0103, 'grad_norm': 4.837257385253906, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.005269599612802267, 'loss_2': 0.005046844482421875, 'loss_3': -16.33807373046875, 'loss_4': -0.32939884066581726, 'epoch': 23.83}
{'loss': 0.0109, 'grad_norm': 5.646851539611816, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.005049525760114193, 'loss_2': 0.005889892578125, 'loss_3': -16.37384605407715, 'loss_4': 0.21536798775196075, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 14:01:17,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:17,580 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:11<18:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:24,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014173217117786407, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010689117014408112, 'eval_loss_2': 0.003484100103378296, 'eval_loss_3': -18.186208724975586, 'eval_loss_4': -0.0526948906481266, 'epoch': 23.84}
{'loss': 0.0101, 'grad_norm': 4.761800289154053, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.004326166585087776, 'loss_2': 0.00577545166015625, 'loss_3': -16.596555709838867, 'loss_4': 0.02328389883041382, 'epoch': 23.84}
{'loss': 0.0037, 'grad_norm': 3.9594297409057617, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.0020691589452326298, 'loss_2': 0.0016422271728515625, 'loss_3': -16.58287239074707, 'loss_4': -0.06698328256607056, 'epoch': 23.85}
{'loss': 0.0099, 'grad_norm': 5.578161239624023, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.00753033347427845, 'loss_2': 0.0023212432861328125, 'loss_3': -16.155580520629883, 'loss_4': 0.20370467007160187, 'epoch': 23.85}
{'loss': 0.0067, 'grad_norm': 5.0166826248168945, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.004057271406054497, 'loss_2': 0.002658843994140625, 'loss_3': -16.60778045654297, 'loss_4': -0.3669660687446594, 'epoch': 23.86}
{'loss': 0.004, 'grad_norm': 4.952922344207764, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.0035224203020334244, 'loss_2': 0.0004401206970214844, 'loss_3': -16.432727813720703, 'loss_4': -0.30441784858703613, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 14:01:24,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:24,927 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:19<18:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:32,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014889787882566452, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011418294161558151, 'eval_loss_2': 0.0034714937210083008, 'eval_loss_3': -18.17972755432129, 'eval_loss_4': -0.056846603751182556, 'epoch': 23.87}
{'loss': 0.0071, 'grad_norm': 4.6371169090271, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.0034241294488310814, 'loss_2': 0.00366973876953125, 'loss_3': -16.48069953918457, 'loss_4': -0.1936769187450409, 'epoch': 23.87}
{'loss': 0.0283, 'grad_norm': 18.058839797973633, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.0221313014626503, 'loss_2': 0.00615692138671875, 'loss_3': -16.535186767578125, 'loss_4': 0.042609188705682755, 'epoch': 23.88}
{'loss': 0.0083, 'grad_norm': 4.404821395874023, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.0033158862497657537, 'loss_2': 0.00501251220703125, 'loss_3': -16.444334030151367, 'loss_4': -0.25347593426704407, 'epoch': 23.88}
{'loss': 0.0052, 'grad_norm': 4.440554141998291, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.0039078970439732075, 'loss_2': 0.0013189315795898438, 'loss_3': -16.391082763671875, 'loss_4': -0.14729256927967072, 'epoch': 23.89}
{'loss': 0.0197, 'grad_norm': 10.454730987548828, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.013348412699997425, 'loss_2': 0.006320953369140625, 'loss_3': -16.485469818115234, 'loss_4': -0.037554189562797546, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 14:01:32,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:32,276 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:26<18:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:39,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015201229602098465, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.607, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011331695131957531, 'eval_loss_2': 0.0038695335388183594, 'eval_loss_3': -18.17337989807129, 'eval_loss_4': -0.02704937383532524, 'epoch': 23.9}
{'loss': 0.012, 'grad_norm': 5.1279425621032715, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.007378532085567713, 'loss_2': 0.0046539306640625, 'loss_3': -16.46188735961914, 'loss_4': -0.09280692785978317, 'epoch': 23.9}
{'loss': 0.0127, 'grad_norm': 6.656702518463135, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.008360023610293865, 'loss_2': 0.00437164306640625, 'loss_3': -16.344594955444336, 'loss_4': 0.15544746816158295, 'epoch': 23.91}
{'loss': 0.008, 'grad_norm': 5.515294551849365, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.0061751496978104115, 'loss_2': 0.001861572265625, 'loss_3': -16.370168685913086, 'loss_4': -0.15134233236312866, 'epoch': 23.91}
{'loss': 0.0084, 'grad_norm': 6.193770885467529, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.007305502891540527, 'loss_2': 0.001094818115234375, 'loss_3': -16.429061889648438, 'loss_4': 0.155393585562706, 'epoch': 23.92}
{'loss': 0.0093, 'grad_norm': 6.093025207519531, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.0070824939757585526, 'loss_2': 0.002197265625, 'loss_3': -16.43035125732422, 'loss_4': -0.2250460982322693, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 14:01:39,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:39,618 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:34<17:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:46,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015130605548620224, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01117401197552681, 'eval_loss_2': 0.003956593573093414, 'eval_loss_3': -18.163307189941406, 'eval_loss_4': -0.0509505495429039, 'epoch': 23.92}
{'loss': 0.0034, 'grad_norm': 4.72208833694458, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.00306192459538579, 'loss_2': 0.0003352165222167969, 'loss_3': -16.583003997802734, 'loss_4': 0.3492318093776703, 'epoch': 23.93}
{'loss': 0.0054, 'grad_norm': 4.551510334014893, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.00520692253485322, 'loss_2': 0.00020694732666015625, 'loss_3': -16.492332458496094, 'loss_4': -0.16775192320346832, 'epoch': 23.94}
{'loss': 0.0166, 'grad_norm': 7.3643012046813965, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.011522282846271992, 'loss_2': 0.00510406494140625, 'loss_3': -16.56380271911621, 'loss_4': -0.02767883986234665, 'epoch': 23.94}
{'loss': 0.006, 'grad_norm': 4.585545063018799, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.0028893128037452698, 'loss_2': 0.0031375885009765625, 'loss_3': -16.381694793701172, 'loss_4': 0.29140418767929077, 'epoch': 23.95}
{'loss': 0.0052, 'grad_norm': 4.324615955352783, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.004545894451439381, 'loss_2': 0.0006551742553710938, 'loss_3': -16.402324676513672, 'loss_4': -0.6420431137084961, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 14:01:46,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:46,961 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:41<17:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:54,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014620605856180191, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011178644374012947, 'eval_loss_2': 0.0034419596195220947, 'eval_loss_3': -18.16728401184082, 'eval_loss_4': -0.12004704773426056, 'epoch': 23.95}
{'loss': 0.0132, 'grad_norm': 5.042049884796143, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.005515508819371462, 'loss_2': 0.007663726806640625, 'loss_3': -16.431644439697266, 'loss_4': -0.03979799151420593, 'epoch': 23.96}
{'loss': 0.017, 'grad_norm': 10.127143859863281, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.014007195830345154, 'loss_2': 0.002994537353515625, 'loss_3': -16.428895950317383, 'loss_4': -0.016894422471523285, 'epoch': 23.97}
{'loss': 0.0095, 'grad_norm': 4.860567092895508, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.0054682097397744656, 'loss_2': 0.004058837890625, 'loss_3': -16.48689842224121, 'loss_4': -0.00864499807357788, 'epoch': 23.97}
{'loss': 0.0087, 'grad_norm': 5.238907337188721, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.004259406588971615, 'loss_2': 0.004451751708984375, 'loss_3': -16.456581115722656, 'loss_4': 0.2723880410194397, 'epoch': 23.98}
{'loss': 0.0077, 'grad_norm': 5.1106486320495605, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.005622800439596176, 'loss_2': 0.002117156982421875, 'loss_3': -16.402151107788086, 'loss_4': -0.5197996497154236, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 14:01:54,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:54,300 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:48<17:03,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 14:02:01,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01581311598420143, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011798929423093796, 'eval_loss_2': 0.0040141865611076355, 'eval_loss_3': -18.15283203125, 'eval_loss_4': -0.1635741889476776, 'epoch': 23.98}
{'loss': 0.0098, 'grad_norm': 4.522424221038818, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.003322399454191327, 'loss_2': 0.00650787353515625, 'loss_3': -16.367464065551758, 'loss_4': 0.042073193937540054, 'epoch': 23.99}
{'loss': 0.0028, 'grad_norm': 4.484742641448975, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.0017958128591999412, 'loss_2': 0.0009813308715820312, 'loss_3': -16.358905792236328, 'loss_4': 0.1509912610054016, 'epoch': 23.99}
{'loss': 0.0078, 'grad_norm': 6.290306091308594, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.0020494437776505947, 'loss_2': 0.005764007568359375, 'loss_3': -16.52851676940918, 'loss_4': 0.6397538185119629, 'epoch': 24.0}
{'loss': 0.0084, 'grad_norm': 4.653251647949219, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.004174310248345137, 'loss_2': 0.0041961669921875, 'loss_3': -16.49048614501953, 'loss_4': -0.5356821417808533, 'epoch': 24.01}
{'loss': 0.0063, 'grad_norm': 3.9044435024261475, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.004896295722573996, 'loss_2': 0.0013580322265625, 'loss_3': -16.43402862548828, 'loss_4': -0.27680131793022156, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 14:02:01,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:01,330 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:55<17:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:08,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017686598002910614, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.968, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012335755862295628, 'eval_loss_2': 0.005350843071937561, 'eval_loss_3': -18.152786254882812, 'eval_loss_4': -0.17775669693946838, 'epoch': 24.01}
{'loss': 0.0171, 'grad_norm': 5.090500354766846, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.009802770800888538, 'loss_2': 0.007293701171875, 'loss_3': -16.395944595336914, 'loss_4': 0.11712922900915146, 'epoch': 24.02}
{'loss': 0.0147, 'grad_norm': 7.283486366271973, 'learning_rate': 6e-06, 'loss_1': 0.010281544178724289, 'loss_2': 0.004425048828125, 'loss_3': -16.40581703186035, 'loss_4': 0.03415851294994354, 'epoch': 24.02}
{'loss': 0.0072, 'grad_norm': 4.769728183746338, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.005121846217662096, 'loss_2': 0.002033233642578125, 'loss_3': -16.547880172729492, 'loss_4': -0.6930749416351318, 'epoch': 24.03}
{'loss': 0.0242, 'grad_norm': 9.583351135253906, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.017137613147497177, 'loss_2': 0.00710296630859375, 'loss_3': -16.416515350341797, 'loss_4': 0.15502819418907166, 'epoch': 24.03}
{'loss': 0.0086, 'grad_norm': 4.936523914337158, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.0046891020610928535, 'loss_2': 0.00389862060546875, 'loss_3': -16.313335418701172, 'loss_4': -0.588777482509613, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 14:02:08,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:08,670 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:42:03<17:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:16,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01733429729938507, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012722537852823734, 'eval_loss_2': 0.004611760377883911, 'eval_loss_3': -18.16663360595703, 'eval_loss_4': -0.20141702890396118, 'epoch': 24.04}
{'loss': 0.0085, 'grad_norm': 4.978487014770508, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.006013849284499884, 'loss_2': 0.002529144287109375, 'loss_3': -16.52989959716797, 'loss_4': -0.42294880747795105, 'epoch': 24.05}
{'loss': 0.0292, 'grad_norm': 12.611395835876465, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.028108319267630577, 'loss_2': 0.0010852813720703125, 'loss_3': -16.46426010131836, 'loss_4': -0.05162493884563446, 'epoch': 24.05}
{'loss': 0.0048, 'grad_norm': 4.6149115562438965, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.0029900064691901207, 'loss_2': 0.0017948150634765625, 'loss_3': -16.250152587890625, 'loss_4': -0.3745969533920288, 'epoch': 24.06}
{'loss': 0.0111, 'grad_norm': 5.323103427886963, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.00663596810773015, 'loss_2': 0.004467010498046875, 'loss_3': -16.47408676147461, 'loss_4': -0.43509429693222046, 'epoch': 24.06}
{'loss': 0.0103, 'grad_norm': 6.015651702880859, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.00866091437637806, 'loss_2': 0.001621246337890625, 'loss_3': -16.40244483947754, 'loss_4': -1.133910894393921, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 14:02:16,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:16,010 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:10<17:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:23,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01647189073264599, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013073618523776531, 'eval_loss_2': 0.0033982694149017334, 'eval_loss_3': -18.157489776611328, 'eval_loss_4': -0.29382801055908203, 'epoch': 24.07}
{'loss': 0.0046, 'grad_norm': 5.4264020919799805, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.003645652672275901, 'loss_2': 0.00091552734375, 'loss_3': -16.456897735595703, 'loss_4': -0.0013893842697143555, 'epoch': 24.08}
{'loss': 0.0064, 'grad_norm': 5.1644062995910645, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.006031797267496586, 'loss_2': 0.0003752708435058594, 'loss_3': -16.38893699645996, 'loss_4': -0.6583953499794006, 'epoch': 24.08}
{'loss': 0.0085, 'grad_norm': 4.719186782836914, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.004422428086400032, 'loss_2': 0.00412750244140625, 'loss_3': -16.383785247802734, 'loss_4': -0.27112823724746704, 'epoch': 24.09}
{'loss': 0.0111, 'grad_norm': 5.045749187469482, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.006809167563915253, 'loss_2': 0.00431060791015625, 'loss_3': -16.47918701171875, 'loss_4': -0.36329424381256104, 'epoch': 24.09}
{'loss': 0.0159, 'grad_norm': 6.779624938964844, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.009819955565035343, 'loss_2': 0.006103515625, 'loss_3': -16.414480209350586, 'loss_4': -0.36843201518058777, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 14:02:23,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:23,349 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:17<17:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:30,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0177791565656662, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013951520435512066, 'eval_loss_2': 0.0038276389241218567, 'eval_loss_3': -18.15187644958496, 'eval_loss_4': -0.3455967903137207, 'epoch': 24.1}
{'loss': 0.0117, 'grad_norm': 4.685154438018799, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.0067563424818217754, 'loss_2': 0.004974365234375, 'loss_3': -16.48931884765625, 'loss_4': -0.9614958763122559, 'epoch': 24.1}
{'loss': 0.0216, 'grad_norm': 8.378264427185059, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.013532929122447968, 'loss_2': 0.008087158203125, 'loss_3': -16.296371459960938, 'loss_4': -0.2968088984489441, 'epoch': 24.11}
{'loss': 0.0072, 'grad_norm': 5.194850444793701, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.005565003026276827, 'loss_2': 0.0016145706176757812, 'loss_3': -16.40116310119629, 'loss_4': -0.20047535002231598, 'epoch': 24.12}
{'loss': 0.0185, 'grad_norm': 8.377854347229004, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.012555795721709728, 'loss_2': 0.00595855712890625, 'loss_3': -16.435070037841797, 'loss_4': -0.14280283451080322, 'epoch': 24.12}
{'loss': 0.0083, 'grad_norm': 4.959200382232666, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.007570712361484766, 'loss_2': 0.0007734298706054688, 'loss_3': -16.43547821044922, 'loss_4': -0.2888515591621399, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 14:02:30,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:30,682 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:25<17:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:38,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019749730825424194, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.907, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016251027584075928, 'eval_loss_2': 0.0034987032413482666, 'eval_loss_3': -18.137941360473633, 'eval_loss_4': -0.35303255915641785, 'epoch': 24.13}
{'loss': 0.0076, 'grad_norm': 4.579623699188232, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.00376148778013885, 'loss_2': 0.00383758544921875, 'loss_3': -16.730323791503906, 'loss_4': -0.525564432144165, 'epoch': 24.13}
{'loss': 0.0126, 'grad_norm': 5.388784408569336, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.008767396211624146, 'loss_2': 0.003795623779296875, 'loss_3': -16.476919174194336, 'loss_4': -0.08547225594520569, 'epoch': 24.14}
{'loss': 0.0116, 'grad_norm': 4.900827884674072, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.0052472809329628944, 'loss_2': 0.006366729736328125, 'loss_3': -16.652324676513672, 'loss_4': -0.534670352935791, 'epoch': 24.15}
{'loss': 0.012, 'grad_norm': 5.769522666931152, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.006511478219181299, 'loss_2': 0.0054473876953125, 'loss_3': -16.42152976989746, 'loss_4': 0.014441177248954773, 'epoch': 24.15}
{'loss': 0.0103, 'grad_norm': 6.573167324066162, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.0075548915192484856, 'loss_2': 0.002765655517578125, 'loss_3': -16.632688522338867, 'loss_4': -0.4935552775859833, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 14:02:38,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:38,035 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:32<17:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:45,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021337438374757767, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01789305917918682, 'eval_loss_2': 0.003444381058216095, 'eval_loss_3': -18.117408752441406, 'eval_loss_4': -0.3144514560699463, 'epoch': 24.16}
{'loss': 0.0053, 'grad_norm': 4.660215854644775, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.0041779703460633755, 'loss_2': 0.0010738372802734375, 'loss_3': -16.345050811767578, 'loss_4': -0.5301476716995239, 'epoch': 24.16}
{'loss': 0.0049, 'grad_norm': 4.719733715057373, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.0025657492224127054, 'loss_2': 0.002323150634765625, 'loss_3': -16.54207992553711, 'loss_4': -0.3634715974330902, 'epoch': 24.17}
{'loss': 0.0056, 'grad_norm': 4.708159923553467, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.005506847053766251, 'loss_2': 0.00011324882507324219, 'loss_3': -16.460887908935547, 'loss_4': -0.30741560459136963, 'epoch': 24.17}
{'loss': 0.0087, 'grad_norm': 4.6829400062561035, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.004359319806098938, 'loss_2': 0.004364013671875, 'loss_3': -16.542774200439453, 'loss_4': -0.0161922387778759, 'epoch': 24.18}
{'loss': 0.0096, 'grad_norm': 5.777284145355225, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.00857978593558073, 'loss_2': 0.001003265380859375, 'loss_3': -16.284637451171875, 'loss_4': -0.41050517559051514, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 14:02:45,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:45,387 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:39<17:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:52,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021638337522745132, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017649125307798386, 'eval_loss_2': 0.003989212214946747, 'eval_loss_3': -18.11187171936035, 'eval_loss_4': -0.2294493019580841, 'epoch': 24.19}
{'loss': 0.0047, 'grad_norm': 4.73499870300293, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.002707103732973337, 'loss_2': 0.0020198822021484375, 'loss_3': -16.445344924926758, 'loss_4': -0.28534507751464844, 'epoch': 24.19}
{'loss': 0.0701, 'grad_norm': 17.714160919189453, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.06760289520025253, 'loss_2': 0.002483367919921875, 'loss_3': -16.373872756958008, 'loss_4': 0.3856962323188782, 'epoch': 24.2}
{'loss': 0.0058, 'grad_norm': 4.920396327972412, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.0034054843708872795, 'loss_2': 0.00240325927734375, 'loss_3': -16.54888343811035, 'loss_4': -0.3068601191043854, 'epoch': 24.2}
{'loss': 0.0081, 'grad_norm': 4.56943941116333, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.006251598708331585, 'loss_2': 0.0018138885498046875, 'loss_3': -16.360891342163086, 'loss_4': 0.5006531476974487, 'epoch': 24.21}
{'loss': 0.0106, 'grad_norm': 6.191769123077393, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.010286020115017891, 'loss_2': 0.00029158592224121094, 'loss_3': -16.525772094726562, 'loss_4': -0.25792402029037476, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 14:02:52,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:52,730 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:47<17:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:00,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020570319145917892, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.551, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01703009568154812, 'eval_loss_2': 0.0035402216017246246, 'eval_loss_3': -18.11362648010254, 'eval_loss_4': -0.14649321138858795, 'epoch': 24.22}
{'loss': 0.0105, 'grad_norm': 4.5333051681518555, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.004431806039065123, 'loss_2': 0.006072998046875, 'loss_3': -16.536819458007812, 'loss_4': -0.4653369188308716, 'epoch': 24.22}
{'loss': 0.0227, 'grad_norm': 8.622709274291992, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.014837320894002914, 'loss_2': 0.00789642333984375, 'loss_3': -16.431068420410156, 'loss_4': -0.44556909799575806, 'epoch': 24.23}
{'loss': 0.0076, 'grad_norm': 4.4679718017578125, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.0018076016567647457, 'loss_2': 0.005828857421875, 'loss_3': -16.271333694458008, 'loss_4': -0.27805864810943604, 'epoch': 24.23}
{'loss': 0.025, 'grad_norm': 13.544417381286621, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.01801305264234543, 'loss_2': 0.00702667236328125, 'loss_3': -16.249109268188477, 'loss_4': -0.18557991087436676, 'epoch': 24.24}
{'loss': 0.014, 'grad_norm': 6.21161413192749, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.011892734095454216, 'loss_2': 0.002147674560546875, 'loss_3': -16.544538497924805, 'loss_4': 0.1372658610343933, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 14:03:00,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:00,076 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:54<17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:07,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019848208874464035, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.564, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01647738553583622, 'eval_loss_2': 0.003370821475982666, 'eval_loss_3': -18.106534957885742, 'eval_loss_4': -0.09058760106563568, 'epoch': 24.24}
{'loss': 0.0168, 'grad_norm': 8.173129081726074, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.015431941486895084, 'loss_2': 0.0014028549194335938, 'loss_3': -16.316068649291992, 'loss_4': -0.25353699922561646, 'epoch': 24.25}
{'loss': 0.0103, 'grad_norm': 6.918695449829102, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.009063859470188618, 'loss_2': 0.0012683868408203125, 'loss_3': -16.37902069091797, 'loss_4': -0.30443501472473145, 'epoch': 24.26}
{'loss': 0.0092, 'grad_norm': 4.740042209625244, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.005540880840271711, 'loss_2': 0.003631591796875, 'loss_3': -16.591320037841797, 'loss_4': 0.1816951334476471, 'epoch': 24.26}
{'loss': 0.01, 'grad_norm': 4.885720729827881, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.004362117033451796, 'loss_2': 0.0056610107421875, 'loss_3': -16.37360954284668, 'loss_4': -0.2542918920516968, 'epoch': 24.27}
{'loss': 0.0061, 'grad_norm': 4.771730899810791, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.004771048668771982, 'loss_2': 0.0013608932495117188, 'loss_3': -16.351360321044922, 'loss_4': 0.3074268698692322, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 14:03:07,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:07,420 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:43:01<16:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:14,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019557936117053032, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01609727367758751, 'eval_loss_2': 0.0034606605768203735, 'eval_loss_3': -18.088979721069336, 'eval_loss_4': -0.0749569907784462, 'epoch': 24.27}
{'loss': 0.0027, 'grad_norm': 4.348664283752441, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.002485570963472128, 'loss_2': 0.00018966197967529297, 'loss_3': -16.21489715576172, 'loss_4': 0.04179544746875763, 'epoch': 24.28}
{'loss': 0.0093, 'grad_norm': 5.240633487701416, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.006381082348525524, 'loss_2': 0.00292205810546875, 'loss_3': -16.210086822509766, 'loss_4': -0.1300567388534546, 'epoch': 24.28}
{'loss': 0.0131, 'grad_norm': 5.197326183319092, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.007011722307652235, 'loss_2': 0.006072998046875, 'loss_3': -16.44226837158203, 'loss_4': -0.21231338381767273, 'epoch': 24.29}
{'loss': 0.0144, 'grad_norm': 4.8620076179504395, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.0050796521827578545, 'loss_2': 0.00934600830078125, 'loss_3': -16.309783935546875, 'loss_4': 0.3937118649482727, 'epoch': 24.3}
{'loss': 0.0061, 'grad_norm': 4.493107318878174, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.005414552055299282, 'loss_2': 0.0006542205810546875, 'loss_3': -16.261016845703125, 'loss_4': 0.40673351287841797, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 14:03:14,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:14,759 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:09<16:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:22,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02023504115641117, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.016768958419561386, 'eval_loss_2': 0.003466084599494934, 'eval_loss_3': -18.082237243652344, 'eval_loss_4': -0.07139895856380463, 'epoch': 24.3}
{'loss': 0.0062, 'grad_norm': 5.983504772186279, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.006022552959620953, 'loss_2': 0.00019657611846923828, 'loss_3': -16.50497055053711, 'loss_4': 0.35774096846580505, 'epoch': 24.31}
{'loss': 0.0098, 'grad_norm': 4.903631687164307, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.005237155593931675, 'loss_2': 0.004581451416015625, 'loss_3': -16.535621643066406, 'loss_4': -0.4631720781326294, 'epoch': 24.31}
{'loss': 0.0089, 'grad_norm': 5.097846031188965, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.007414419203996658, 'loss_2': 0.0014448165893554688, 'loss_3': -16.433202743530273, 'loss_4': -0.09055796265602112, 'epoch': 24.32}
{'loss': 0.0062, 'grad_norm': 4.332742214202881, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.0026389816775918007, 'loss_2': 0.003582000732421875, 'loss_3': -16.533283233642578, 'loss_4': -0.28099390864372253, 'epoch': 24.33}
{'loss': 0.0098, 'grad_norm': 4.95902156829834, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.007006746716797352, 'loss_2': 0.00276947021484375, 'loss_3': -16.271303176879883, 'loss_4': -0.35794562101364136, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 14:03:22,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:22,105 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:16<17:00,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:03:29,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02020704746246338, 'eval_runtime': 3.9996, 'eval_samples_per_second': 256.024, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.016977913677692413, 'eval_loss_2': 0.0032291337847709656, 'eval_loss_3': -18.0841121673584, 'eval_loss_4': -0.08841384947299957, 'epoch': 24.33}
{'loss': 0.0059, 'grad_norm': 4.215230464935303, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.0044355690479278564, 'loss_2': 0.0015134811401367188, 'loss_3': -16.424095153808594, 'loss_4': -0.11013146489858627, 'epoch': 24.34}
{'loss': 0.0037, 'grad_norm': 4.650512218475342, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.003642319468781352, 'loss_2': 7.617473602294922e-05, 'loss_3': -16.665016174316406, 'loss_4': 0.2920380234718323, 'epoch': 24.34}
{'loss': 0.0126, 'grad_norm': 4.790876388549805, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.005946463905274868, 'loss_2': 0.00667572021484375, 'loss_3': -16.241865158081055, 'loss_4': -0.4292854368686676, 'epoch': 24.35}
{'loss': 0.0154, 'grad_norm': 4.395605087280273, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.005974199157208204, 'loss_2': 0.00937652587890625, 'loss_3': -16.455188751220703, 'loss_4': -0.19492840766906738, 'epoch': 24.35}
{'loss': 0.0201, 'grad_norm': 7.295965194702148, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.01331096887588501, 'loss_2': 0.006755828857421875, 'loss_3': -16.3786678314209, 'loss_4': -0.07589931786060333, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 14:03:29,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:29,648 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:24<16:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:36,989 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022167451679706573, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.368, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018720757216215134, 'eval_loss_2': 0.00344669446349144, 'eval_loss_3': -18.06821060180664, 'eval_loss_4': -0.07872156798839569, 'epoch': 24.36}
{'loss': 0.0105, 'grad_norm': 4.781112194061279, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.005337274167686701, 'loss_2': 0.005126953125, 'loss_3': -16.45294761657715, 'loss_4': -0.17092609405517578, 'epoch': 24.37}
{'loss': 0.0033, 'grad_norm': 4.698278903961182, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.003080145688727498, 'loss_2': 0.0002048015594482422, 'loss_3': -16.427845001220703, 'loss_4': -0.48726886510849, 'epoch': 24.37}
{'loss': 0.0605, 'grad_norm': 10.045435905456543, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.059324439615011215, 'loss_2': 0.001216888427734375, 'loss_3': -16.578712463378906, 'loss_4': -0.3742447793483734, 'epoch': 24.38}
{'loss': 0.0073, 'grad_norm': 4.269921779632568, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.004014467354863882, 'loss_2': 0.0033111572265625, 'loss_3': -16.524211883544922, 'loss_4': 0.07021208107471466, 'epoch': 24.38}
{'loss': 0.016, 'grad_norm': 6.0788140296936035, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.0076210880652070045, 'loss_2': 0.0084075927734375, 'loss_3': -16.45964813232422, 'loss_4': 0.037838444113731384, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 14:03:36,989 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:36,989 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:31<16:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:44,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02285534143447876, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018954113125801086, 'eval_loss_2': 0.0039012283086776733, 'eval_loss_3': -18.07683563232422, 'eval_loss_4': -0.07235458493232727, 'epoch': 24.39}
{'loss': 0.0055, 'grad_norm': 6.141916275024414, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0054708910174667835, 'loss_2': 4.851818084716797e-05, 'loss_3': -16.422616958618164, 'loss_4': -0.23887373507022858, 'epoch': 24.4}
{'loss': 0.0112, 'grad_norm': 5.028866291046143, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.0027346520218998194, 'loss_2': 0.00843048095703125, 'loss_3': -16.499221801757812, 'loss_4': -0.1963099241256714, 'epoch': 24.4}
{'loss': 0.0103, 'grad_norm': 5.356118202209473, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.005947335623204708, 'loss_2': 0.004360198974609375, 'loss_3': -16.616004943847656, 'loss_4': -0.0778011828660965, 'epoch': 24.41}
{'loss': 0.003, 'grad_norm': 4.6753973960876465, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.0028446069918572903, 'loss_2': 0.00020170211791992188, 'loss_3': -16.356163024902344, 'loss_4': 0.041732318699359894, 'epoch': 24.41}
{'loss': 0.0292, 'grad_norm': 18.070619583129883, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.02598867379128933, 'loss_2': 0.00316619873046875, 'loss_3': -16.371801376342773, 'loss_4': -0.4103041887283325, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 14:03:44,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:44,336 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:38<16:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:51,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020849963650107384, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.487, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016992591321468353, 'eval_loss_2': 0.0038573741912841797, 'eval_loss_3': -18.08985137939453, 'eval_loss_4': -0.11754919588565826, 'epoch': 24.42}
{'loss': 0.0173, 'grad_norm': 10.605600357055664, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.017020057886838913, 'loss_2': 0.0002989768981933594, 'loss_3': -16.535205841064453, 'loss_4': -0.00801929086446762, 'epoch': 24.42}
{'loss': 0.0106, 'grad_norm': 4.796996116638184, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.005332466680556536, 'loss_2': 0.00525665283203125, 'loss_3': -16.499126434326172, 'loss_4': -0.09242680668830872, 'epoch': 24.43}
{'loss': 0.0029, 'grad_norm': 4.685122489929199, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.0028671957552433014, 'loss_2': 4.404783248901367e-05, 'loss_3': -16.32275390625, 'loss_4': -0.6570565700531006, 'epoch': 24.44}
{'loss': 0.0035, 'grad_norm': 4.425993919372559, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.002486912067979574, 'loss_2': 0.0009660720825195312, 'loss_3': -16.414440155029297, 'loss_4': 0.14658315479755402, 'epoch': 24.44}
{'loss': 0.0232, 'grad_norm': 7.5017476081848145, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.014205994084477425, 'loss_2': 0.00894927978515625, 'loss_3': -16.464588165283203, 'loss_4': -0.1948576271533966, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 14:03:51,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:51,676 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:46<16:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:59,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021013278514146805, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016900379210710526, 'eval_loss_2': 0.004112899303436279, 'eval_loss_3': -18.094219207763672, 'eval_loss_4': -0.14074143767356873, 'epoch': 24.45}
{'loss': 0.0072, 'grad_norm': 4.713838577270508, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.0033097676932811737, 'loss_2': 0.00389862060546875, 'loss_3': -16.491018295288086, 'loss_4': -0.4911558926105499, 'epoch': 24.45}
{'loss': 0.0065, 'grad_norm': 4.37750244140625, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.004302178043872118, 'loss_2': 0.002155303955078125, 'loss_3': -16.487205505371094, 'loss_4': -0.18422934412956238, 'epoch': 24.46}
{'loss': 0.0083, 'grad_norm': 5.139674186706543, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.0048278626054525375, 'loss_2': 0.003509521484375, 'loss_3': -16.44448471069336, 'loss_4': -0.4212765395641327, 'epoch': 24.47}
{'loss': 0.008, 'grad_norm': 5.283134460449219, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.008006228134036064, 'loss_2': 3.0875205993652344e-05, 'loss_3': -16.620338439941406, 'loss_4': -0.2866777777671814, 'epoch': 24.47}
{'loss': 0.0056, 'grad_norm': 4.719599723815918, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.0030444003641605377, 'loss_2': 0.002582550048828125, 'loss_3': -16.357563018798828, 'loss_4': 0.06191026419401169, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 14:03:59,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:59,028 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:53<16:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:06,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02100597321987152, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.125, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01678900420665741, 'eval_loss_2': 0.004216969013214111, 'eval_loss_3': -18.091218948364258, 'eval_loss_4': -0.18353036046028137, 'epoch': 24.48}
{'loss': 0.0093, 'grad_norm': 5.587871551513672, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.008230667561292648, 'loss_2': 0.0010290145874023438, 'loss_3': -16.435016632080078, 'loss_4': -0.43566668033599854, 'epoch': 24.48}
{'loss': 0.0062, 'grad_norm': 4.631051540374756, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.005968190263956785, 'loss_2': 0.00021266937255859375, 'loss_3': -16.51826286315918, 'loss_4': -0.32817506790161133, 'epoch': 24.49}
{'loss': 0.0082, 'grad_norm': 7.044551372528076, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.006952016148716211, 'loss_2': 0.0012712478637695312, 'loss_3': -16.332881927490234, 'loss_4': -0.14302703738212585, 'epoch': 24.49}
{'loss': 0.006, 'grad_norm': 5.877355098724365, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.005793259013444185, 'loss_2': 0.00017786026000976562, 'loss_3': -16.385120391845703, 'loss_4': -0.23521992564201355, 'epoch': 24.5}
{'loss': 0.0039, 'grad_norm': 4.408895969390869, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.001435604295693338, 'loss_2': 0.002468109130859375, 'loss_3': -16.60067367553711, 'loss_4': -0.06082068383693695, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 14:04:06,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:06,377 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:44:00<16:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:13,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022534765303134918, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018165983259677887, 'eval_loss_2': 0.004368782043457031, 'eval_loss_3': -18.087892532348633, 'eval_loss_4': -0.18275658786296844, 'epoch': 24.51}
{'loss': 0.0095, 'grad_norm': 4.7881855964660645, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.003561729798093438, 'loss_2': 0.005970001220703125, 'loss_3': -16.435283660888672, 'loss_4': -0.23313629627227783, 'epoch': 24.51}
{'loss': 0.0076, 'grad_norm': 5.258451461791992, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.004665984772145748, 'loss_2': 0.0029144287109375, 'loss_3': -16.42176055908203, 'loss_4': -0.2917375862598419, 'epoch': 24.52}
{'loss': 0.0115, 'grad_norm': 5.48329496383667, 'learning_rate': 5.5e-06, 'loss_1': 0.007016237359493971, 'loss_2': 0.004459381103515625, 'loss_3': -16.54641342163086, 'loss_4': -0.2265165001153946, 'epoch': 24.52}
{'loss': 0.0342, 'grad_norm': 6.438265800476074, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.033911723643541336, 'loss_2': 0.00028896331787109375, 'loss_3': -16.354869842529297, 'loss_4': -0.5073188543319702, 'epoch': 24.53}
{'loss': 0.0074, 'grad_norm': 5.043144702911377, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.004410623572766781, 'loss_2': 0.0029697418212890625, 'loss_3': -16.39327049255371, 'loss_4': -0.26695361733436584, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 14:04:13,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:13,717 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:08<16:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:21,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024576973170042038, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.020264115184545517, 'eval_loss_2': 0.004312857985496521, 'eval_loss_3': -18.06513214111328, 'eval_loss_4': -0.1417943239212036, 'epoch': 24.53}
{'loss': 0.0222, 'grad_norm': 19.50768280029297, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.021251948550343513, 'loss_2': 0.0009927749633789062, 'loss_3': -16.440654754638672, 'loss_4': -0.29820021986961365, 'epoch': 24.54}
{'loss': 0.0081, 'grad_norm': 5.337037563323975, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.008045556023716927, 'loss_2': 4.410743713378906e-05, 'loss_3': -16.490680694580078, 'loss_4': -0.49811288714408875, 'epoch': 24.55}
{'loss': 0.0171, 'grad_norm': 4.615797519683838, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.00768145639449358, 'loss_2': 0.0093841552734375, 'loss_3': -16.272287368774414, 'loss_4': -0.040090542286634445, 'epoch': 24.55}
{'loss': 0.0155, 'grad_norm': 4.980173110961914, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.005913036409765482, 'loss_2': 0.0095977783203125, 'loss_3': -16.452316284179688, 'loss_4': -0.49401071667671204, 'epoch': 24.56}
{'loss': 0.0084, 'grad_norm': 6.506920337677002, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.007332972716540098, 'loss_2': 0.0010919570922851562, 'loss_3': -16.334178924560547, 'loss_4': 0.22551646828651428, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 14:04:21,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:21,062 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:15<16:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:28,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025259047746658325, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.613, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02129019983112812, 'eval_loss_2': 0.003968849778175354, 'eval_loss_3': -18.044790267944336, 'eval_loss_4': -0.05895509198307991, 'epoch': 24.56}
{'loss': 0.0088, 'grad_norm': 4.724833011627197, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.006782846059650183, 'loss_2': 0.002048492431640625, 'loss_3': -16.261960983276367, 'loss_4': 0.16524818539619446, 'epoch': 24.57}
{'loss': 0.0142, 'grad_norm': 4.65212345123291, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.005861462559551001, 'loss_2': 0.00836181640625, 'loss_3': -16.410554885864258, 'loss_4': -0.44582319259643555, 'epoch': 24.58}
{'loss': 0.0091, 'grad_norm': 4.703851222991943, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.004124782979488373, 'loss_2': 0.00494384765625, 'loss_3': -16.60332679748535, 'loss_4': -0.20361647009849548, 'epoch': 24.58}
{'loss': 0.0087, 'grad_norm': 4.283890724182129, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.0028759099077433348, 'loss_2': 0.00580596923828125, 'loss_3': -16.250408172607422, 'loss_4': -0.02976539358496666, 'epoch': 24.59}
{'loss': 0.005, 'grad_norm': 5.050671100616455, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.004239690490067005, 'loss_2': 0.0007238388061523438, 'loss_3': -16.235868453979492, 'loss_4': 0.18395136296749115, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 14:04:28,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:28,398 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:22<16:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:35,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026393601670861244, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02303071692585945, 'eval_loss_2': 0.0033628828823566437, 'eval_loss_3': -18.03453254699707, 'eval_loss_4': 0.013199763372540474, 'epoch': 24.59}
{'loss': 0.0056, 'grad_norm': 4.626309871673584, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.0026060070376843214, 'loss_2': 0.0030422210693359375, 'loss_3': -16.325803756713867, 'loss_4': -0.1541096717119217, 'epoch': 24.6}
{'loss': 0.0061, 'grad_norm': 5.6158976554870605, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.004820649977773428, 'loss_2': 0.00130462646484375, 'loss_3': -16.360143661499023, 'loss_4': 0.13840647041797638, 'epoch': 24.6}
{'loss': 0.011, 'grad_norm': 6.0280938148498535, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.008889195509254932, 'loss_2': 0.00209808349609375, 'loss_3': -16.445425033569336, 'loss_4': 0.07023948431015015, 'epoch': 24.61}
{'loss': 0.01, 'grad_norm': 4.479388236999512, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.003162969369441271, 'loss_2': 0.0068511962890625, 'loss_3': -16.399398803710938, 'loss_4': -0.2825421690940857, 'epoch': 24.62}
{'loss': 0.0115, 'grad_norm': 5.9071946144104, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.006089627277106047, 'loss_2': 0.00536346435546875, 'loss_3': -16.28714942932129, 'loss_4': -0.06782810389995575, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 14:04:35,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:35,747 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:30<15:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:43,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027092499658465385, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.023792318999767303, 'eval_loss_2': 0.003300182521343231, 'eval_loss_3': -18.041217803955078, 'eval_loss_4': 0.0615597702562809, 'epoch': 24.62}
{'loss': 0.023, 'grad_norm': 11.46013355255127, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.02179330214858055, 'loss_2': 0.00121307373046875, 'loss_3': -16.237674713134766, 'loss_4': 0.39325690269470215, 'epoch': 24.63}
{'loss': 0.0062, 'grad_norm': 5.587639331817627, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.0024399433750659227, 'loss_2': 0.0037708282470703125, 'loss_3': -16.24981689453125, 'loss_4': 0.2745366394519806, 'epoch': 24.63}
{'loss': 0.0074, 'grad_norm': 5.059552192687988, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.0032976591028273106, 'loss_2': 0.004150390625, 'loss_3': -16.454118728637695, 'loss_4': -0.1673603653907776, 'epoch': 24.64}
{'loss': 0.0622, 'grad_norm': 18.07197380065918, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.06214708089828491, 'loss_2': 6.836652755737305e-05, 'loss_3': -16.492115020751953, 'loss_4': 0.6286935210227966, 'epoch': 24.65}
{'loss': 0.0066, 'grad_norm': 5.395759582519531, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.0039005079306662083, 'loss_2': 0.002742767333984375, 'loss_3': -16.238903045654297, 'loss_4': -0.23568323254585266, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 14:04:43,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:43,099 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:37<15:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:50,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025528669357299805, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.418, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.021756628528237343, 'eval_loss_2': 0.003772042691707611, 'eval_loss_3': -18.059762954711914, 'eval_loss_4': 0.07819323986768723, 'epoch': 24.65}
{'loss': 0.0145, 'grad_norm': 6.873970031738281, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.010864224284887314, 'loss_2': 0.0036563873291015625, 'loss_3': -16.259859085083008, 'loss_4': -0.03502197563648224, 'epoch': 24.66}
{'loss': 0.0057, 'grad_norm': 4.4627814292907715, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.0029847854748368263, 'loss_2': 0.00272369384765625, 'loss_3': -16.358829498291016, 'loss_4': 0.5104949474334717, 'epoch': 24.66}
{'loss': 0.0104, 'grad_norm': 7.874442100524902, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.008410793729126453, 'loss_2': 0.0020008087158203125, 'loss_3': -16.394067764282227, 'loss_4': 0.2245941460132599, 'epoch': 24.67}
{'loss': 0.0065, 'grad_norm': 4.959610462188721, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.00530460337176919, 'loss_2': 0.0011959075927734375, 'loss_3': -16.39614486694336, 'loss_4': -0.10545619577169418, 'epoch': 24.67}
{'loss': 0.0072, 'grad_norm': 4.907331943511963, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.003316697431728244, 'loss_2': 0.0038585662841796875, 'loss_3': -16.607425689697266, 'loss_4': 0.29070425033569336, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 14:04:50,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:50,441 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:44<15:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:57,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02269977331161499, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.55, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018745271489024162, 'eval_loss_2': 0.003954499959945679, 'eval_loss_3': -18.069934844970703, 'eval_loss_4': 0.0857292041182518, 'epoch': 24.68}
{'loss': 0.0118, 'grad_norm': 5.758998394012451, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.007560911122709513, 'loss_2': 0.0041961669921875, 'loss_3': -16.233551025390625, 'loss_4': -0.38476917147636414, 'epoch': 24.69}
{'loss': 0.022, 'grad_norm': 7.616320610046387, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.015181108377873898, 'loss_2': 0.0067901611328125, 'loss_3': -16.281328201293945, 'loss_4': -0.5284510850906372, 'epoch': 24.69}
{'loss': 0.013, 'grad_norm': 6.679020881652832, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.0065390379168093204, 'loss_2': 0.00641632080078125, 'loss_3': -16.32906723022461, 'loss_4': 0.29833078384399414, 'epoch': 24.7}
{'loss': 0.0062, 'grad_norm': 4.7436652183532715, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.004466187208890915, 'loss_2': 0.00174713134765625, 'loss_3': -16.203998565673828, 'loss_4': 0.19997543096542358, 'epoch': 24.7}
{'loss': 0.0089, 'grad_norm': 5.362046241760254, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.005434603895992041, 'loss_2': 0.003459930419921875, 'loss_3': -16.318994522094727, 'loss_4': 0.12087523192167282, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 14:04:57,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:57,780 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:52<15:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:05,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022285625338554382, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.536, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018611028790473938, 'eval_loss_2': 0.0036745965480804443, 'eval_loss_3': -18.068675994873047, 'eval_loss_4': 0.1452912837266922, 'epoch': 24.71}
{'loss': 0.0049, 'grad_norm': 4.426909923553467, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.004501740448176861, 'loss_2': 0.0003609657287597656, 'loss_3': -16.402843475341797, 'loss_4': -0.006697222590446472, 'epoch': 24.72}
{'loss': 0.0041, 'grad_norm': 6.459249973297119, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.0032607463654130697, 'loss_2': 0.0008516311645507812, 'loss_3': -16.37286376953125, 'loss_4': 0.03605931997299194, 'epoch': 24.72}
{'loss': 0.0066, 'grad_norm': 5.804961681365967, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.005976568441838026, 'loss_2': 0.0005922317504882812, 'loss_3': -16.1586971282959, 'loss_4': 0.3349142074584961, 'epoch': 24.73}
{'loss': 0.0078, 'grad_norm': 5.587917804718018, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.007763440255075693, 'loss_2': 4.589557647705078e-05, 'loss_3': -16.433826446533203, 'loss_4': 0.3675767779350281, 'epoch': 24.73}
{'loss': 0.0112, 'grad_norm': 5.648276329040527, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.008045457303524017, 'loss_2': 0.00316619873046875, 'loss_3': -16.318979263305664, 'loss_4': 0.13507698476314545, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 14:05:05,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:05,123 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:59<15:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:12,456 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020900294184684753, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.733, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01738336682319641, 'eval_loss_2': 0.0035169273614883423, 'eval_loss_3': -18.08309555053711, 'eval_loss_4': 0.2390405386686325, 'epoch': 24.74}
{'loss': 0.0076, 'grad_norm': 4.244121074676514, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.0037374815437942743, 'loss_2': 0.003814697265625, 'loss_3': -16.411218643188477, 'loss_4': 0.006485745310783386, 'epoch': 24.74}
{'loss': 0.009, 'grad_norm': 4.517775535583496, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.004140049684792757, 'loss_2': 0.004817962646484375, 'loss_3': -16.416568756103516, 'loss_4': 0.4849172830581665, 'epoch': 24.75}
{'loss': 0.004, 'grad_norm': 4.639692783355713, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.0029283317271620035, 'loss_2': 0.001033782958984375, 'loss_3': -16.277942657470703, 'loss_4': 0.7148312330245972, 'epoch': 24.76}
{'loss': 0.0046, 'grad_norm': 4.6288652420043945, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.002803332405164838, 'loss_2': 0.0017910003662109375, 'loss_3': -16.25719451904297, 'loss_4': -0.08082196861505508, 'epoch': 24.76}
{'loss': 0.006, 'grad_norm': 5.614350318908691, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.005758209154009819, 'loss_2': 0.0002505779266357422, 'loss_3': -16.226289749145508, 'loss_4': 0.29697751998901367, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 14:05:12,456 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:12,456 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:06<15:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:19,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021213091909885406, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01783932000398636, 'eval_loss_2': 0.003373771905899048, 'eval_loss_3': -18.069026947021484, 'eval_loss_4': 0.37782952189445496, 'epoch': 24.77}
{'loss': 0.0108, 'grad_norm': 4.583776950836182, 'learning_rate': 5.25e-06, 'loss_1': 0.004310129676014185, 'loss_2': 0.0064849853515625, 'loss_3': -16.258882522583008, 'loss_4': 0.33390572667121887, 'epoch': 24.77}
{'loss': 0.0105, 'grad_norm': 4.76659631729126, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.006493597757071257, 'loss_2': 0.004055023193359375, 'loss_3': -16.428524017333984, 'loss_4': 0.7593923211097717, 'epoch': 24.78}
{'loss': 0.0035, 'grad_norm': 4.8512492179870605, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.0030306256376206875, 'loss_2': 0.00046563148498535156, 'loss_3': -16.436464309692383, 'loss_4': 0.9920201301574707, 'epoch': 24.78}
{'loss': 0.0092, 'grad_norm': 5.0127034187316895, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.005852712783962488, 'loss_2': 0.003368377685546875, 'loss_3': -16.45250701904297, 'loss_4': 0.0008907318115234375, 'epoch': 24.79}
{'loss': 0.0066, 'grad_norm': 5.057544708251953, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.004652570001780987, 'loss_2': 0.0019006729125976562, 'loss_3': -16.54326629638672, 'loss_4': 0.6778264045715332, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 14:05:19,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:19,803 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:14<15:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:27,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019632898271083832, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.016897622495889664, 'eval_loss_2': 0.0027352720499038696, 'eval_loss_3': -18.068195343017578, 'eval_loss_4': 0.4531816244125366, 'epoch': 24.8}
{'loss': 0.0095, 'grad_norm': 5.051733493804932, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.005749780219048262, 'loss_2': 0.00373077392578125, 'loss_3': -16.357513427734375, 'loss_4': 0.4318341612815857, 'epoch': 24.8}
{'loss': 0.0052, 'grad_norm': 4.557651519775391, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.0023085528519004583, 'loss_2': 0.0028896331787109375, 'loss_3': -16.3582763671875, 'loss_4': 0.33624815940856934, 'epoch': 24.81}
{'loss': 0.0087, 'grad_norm': 6.900533199310303, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.008392359130084515, 'loss_2': 0.00032901763916015625, 'loss_3': -16.50459861755371, 'loss_4': 0.08733642101287842, 'epoch': 24.81}
{'loss': 0.0129, 'grad_norm': 5.336407661437988, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.0075066848658025265, 'loss_2': 0.005401611328125, 'loss_3': -16.234243392944336, 'loss_4': 0.03273500129580498, 'epoch': 24.82}
{'loss': 0.0093, 'grad_norm': 4.59547233581543, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.003791708732023835, 'loss_2': 0.005462646484375, 'loss_3': -16.637964248657227, 'loss_4': 1.1042582988739014, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 14:05:27,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:27,151 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:21<15:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:34,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017774753272533417, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.946, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.014885418117046356, 'eval_loss_2': 0.0028893351554870605, 'eval_loss_3': -18.08966064453125, 'eval_loss_4': 0.49505841732025146, 'epoch': 24.83}
{'loss': 0.0029, 'grad_norm': 4.718972206115723, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0025421588215976954, 'loss_2': 0.00031113624572753906, 'loss_3': -16.368724822998047, 'loss_4': 0.8243830800056458, 'epoch': 24.83}
{'loss': 0.0046, 'grad_norm': 4.7977375984191895, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.003771953284740448, 'loss_2': 0.0008020401000976562, 'loss_3': -16.52853775024414, 'loss_4': 0.5821866989135742, 'epoch': 24.84}
{'loss': 0.0111, 'grad_norm': 5.5082573890686035, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.00854057539254427, 'loss_2': 0.0026035308837890625, 'loss_3': -16.395845413208008, 'loss_4': 0.007447443902492523, 'epoch': 24.84}
{'loss': 0.0066, 'grad_norm': 4.758237838745117, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.0034921756014227867, 'loss_2': 0.003078460693359375, 'loss_3': -16.488628387451172, 'loss_4': 0.42621585726737976, 'epoch': 24.85}
{'loss': 0.0251, 'grad_norm': 12.854008674621582, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.02358361892402172, 'loss_2': 0.001552581787109375, 'loss_3': -16.36387062072754, 'loss_4': 0.5450246334075928, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 14:05:34,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:34,496 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:28<15:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:41,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017962170764803886, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.478, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01502055861055851, 'eval_loss_2': 0.0029416121542453766, 'eval_loss_3': -18.09427833557129, 'eval_loss_4': 0.5249876976013184, 'epoch': 24.85}
{'loss': 0.0088, 'grad_norm': 4.901866436004639, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.007368952501565218, 'loss_2': 0.0014467239379882812, 'loss_3': -16.365234375, 'loss_4': 0.5725799798965454, 'epoch': 24.86}
{'loss': 0.009, 'grad_norm': 5.016312599182129, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.006185188889503479, 'loss_2': 0.002803802490234375, 'loss_3': -16.31117057800293, 'loss_4': 0.6566761136054993, 'epoch': 24.87}
{'loss': 0.0051, 'grad_norm': 4.423323154449463, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.0032365741208195686, 'loss_2': 0.0019016265869140625, 'loss_3': -16.287477493286133, 'loss_4': 0.29636630415916443, 'epoch': 24.87}
{'loss': 0.0098, 'grad_norm': 4.561955451965332, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.004020228516310453, 'loss_2': 0.0057830810546875, 'loss_3': -16.351266860961914, 'loss_4': 0.4749835133552551, 'epoch': 24.88}
{'loss': 0.0094, 'grad_norm': 5.230747222900391, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.008609910495579243, 'loss_2': 0.0008192062377929688, 'loss_3': -16.415292739868164, 'loss_4': 0.7134840488433838, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 14:05:41,842 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:41,842 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:36<15:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:49,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021305140107870102, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.881, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0181288979947567, 'eval_loss_2': 0.0031762421131134033, 'eval_loss_3': -18.083175659179688, 'eval_loss_4': 0.560927152633667, 'epoch': 24.88}
{'loss': 0.0094, 'grad_norm': 5.369016170501709, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.005310720298439264, 'loss_2': 0.00412750244140625, 'loss_3': -16.54140281677246, 'loss_4': 0.8085746765136719, 'epoch': 24.89}
{'loss': 0.008, 'grad_norm': 5.250319480895996, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.007131545804440975, 'loss_2': 0.0008816719055175781, 'loss_3': -16.315105438232422, 'loss_4': 0.5088810920715332, 'epoch': 24.9}
{'loss': 0.0087, 'grad_norm': 7.092319965362549, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.008557198569178581, 'loss_2': 0.0001914501190185547, 'loss_3': -16.38890838623047, 'loss_4': 0.8063063621520996, 'epoch': 24.9}
{'loss': 0.0055, 'grad_norm': 4.657714366912842, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.0028832608368247747, 'loss_2': 0.002666473388671875, 'loss_3': -16.459320068359375, 'loss_4': 0.6823348999023438, 'epoch': 24.91}
{'loss': 0.0105, 'grad_norm': 5.322853088378906, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.006530218292027712, 'loss_2': 0.0040130615234375, 'loss_3': -16.37755584716797, 'loss_4': 0.46876129508018494, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 14:05:49,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:49,180 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:43<15:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:56,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026219617575407028, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.767, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02256707474589348, 'eval_loss_2': 0.00365254282951355, 'eval_loss_3': -18.046091079711914, 'eval_loss_4': 0.636508047580719, 'epoch': 24.91}
{'loss': 0.0146, 'grad_norm': 5.342775344848633, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.008618361316621304, 'loss_2': 0.00597381591796875, 'loss_3': -16.31747055053711, 'loss_4': 0.33275020122528076, 'epoch': 24.92}
{'loss': 0.0084, 'grad_norm': 4.909474849700928, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.0063578346744179726, 'loss_2': 0.0020294189453125, 'loss_3': -16.470813751220703, 'loss_4': 0.6685115098953247, 'epoch': 24.92}
{'loss': 0.0165, 'grad_norm': 9.471476554870605, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.012063683941960335, 'loss_2': 0.00441741943359375, 'loss_3': -16.4952392578125, 'loss_4': 0.8293848037719727, 'epoch': 24.93}
{'loss': 0.0054, 'grad_norm': 4.727534294128418, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.004360083490610123, 'loss_2': 0.0010862350463867188, 'loss_3': -16.449630737304688, 'loss_4': 0.5182375907897949, 'epoch': 24.94}
{'loss': 0.0087, 'grad_norm': 4.989234924316406, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.005445195361971855, 'loss_2': 0.00327301025390625, 'loss_3': -16.484582901000977, 'loss_4': 0.48061710596084595, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 14:05:56,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:56,522 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:50<14:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:03,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027962960302829742, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.023692764341831207, 'eval_loss_2': 0.004270195960998535, 'eval_loss_3': -18.020898818969727, 'eval_loss_4': 0.7296923995018005, 'epoch': 24.94}
{'loss': 0.0088, 'grad_norm': 5.072523593902588, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.007119194138795137, 'loss_2': 0.001720428466796875, 'loss_3': -16.27547836303711, 'loss_4': 1.290642261505127, 'epoch': 24.95}
{'loss': 0.0217, 'grad_norm': 6.500507354736328, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.015725115314126015, 'loss_2': 0.00600433349609375, 'loss_3': -16.3479061126709, 'loss_4': 1.2747676372528076, 'epoch': 24.95}
{'loss': 0.0036, 'grad_norm': 4.355721950531006, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.0036086104810237885, 'loss_2': 2.276897430419922e-05, 'loss_3': -16.479597091674805, 'loss_4': 0.6664667129516602, 'epoch': 24.96}
{'loss': 0.0107, 'grad_norm': 4.548916816711426, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.0047475602477788925, 'loss_2': 0.0059814453125, 'loss_3': -16.41939926147461, 'loss_4': 0.7431460618972778, 'epoch': 24.97}
{'loss': 0.0056, 'grad_norm': 4.184305191040039, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.0035945349372923374, 'loss_2': 0.002040863037109375, 'loss_3': -16.403438568115234, 'loss_4': 0.6140114665031433, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 14:06:03,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:03,865 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:57<13:22,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:06:10,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03110944852232933, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.026645537465810776, 'eval_loss_2': 0.004463911056518555, 'eval_loss_3': -18.00372886657715, 'eval_loss_4': 0.7612313628196716, 'epoch': 24.97}
{'loss': 0.0117, 'grad_norm': 5.330379009246826, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.007464197464287281, 'loss_2': 0.00428009033203125, 'loss_3': -16.504358291625977, 'loss_4': 0.6323277354240417, 'epoch': 24.98}
{'loss': 0.0107, 'grad_norm': 5.99131441116333, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.010598666034638882, 'loss_2': 0.00014448165893554688, 'loss_3': -16.054487228393555, 'loss_4': 0.5282618999481201, 'epoch': 24.98}
{'loss': 0.0084, 'grad_norm': 4.856988906860352, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.0068577975034713745, 'loss_2': 0.0015773773193359375, 'loss_3': -16.27648162841797, 'loss_4': 0.7623834609985352, 'epoch': 24.99}
{'loss': 0.0108, 'grad_norm': 4.629865646362305, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.0056100813671946526, 'loss_2': 0.00514984130859375, 'loss_3': -16.290206909179688, 'loss_4': 1.5731804370880127, 'epoch': 24.99}
{'loss': 0.0099, 'grad_norm': 6.356130599975586, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0027139235753566027, 'loss_2': 0.0072021484375, 'loss_3': -16.095874786376953, 'loss_4': 1.2010291814804077, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 14:06:10,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:10,856 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:46:05<14:35,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:06:18,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034344982355833054, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.077, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.030978549271821976, 'eval_loss_2': 0.003366433084011078, 'eval_loss_3': -17.976491928100586, 'eval_loss_4': 0.758933961391449, 'epoch': 25.0}
{'loss': 0.0219, 'grad_norm': 9.834267616271973, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.017650475725531578, 'loss_2': 0.00423431396484375, 'loss_3': -16.421871185302734, 'loss_4': 0.6572241187095642, 'epoch': 25.01}
{'loss': 0.0139, 'grad_norm': 5.233884334564209, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.009579656645655632, 'loss_2': 0.0043487548828125, 'loss_3': -16.22274398803711, 'loss_4': 0.793165922164917, 'epoch': 25.01}
{'loss': 0.0308, 'grad_norm': 9.855259895324707, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.02976270206272602, 'loss_2': 0.0010461807250976562, 'loss_3': -16.266334533691406, 'loss_4': 0.7787604331970215, 'epoch': 25.02}
{'loss': 0.0133, 'grad_norm': 6.575104236602783, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.011436362750828266, 'loss_2': 0.0018835067749023438, 'loss_3': -16.393415451049805, 'loss_4': 0.7673985362052917, 'epoch': 25.02}
{'loss': 0.0793, 'grad_norm': 48.44670104980469, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.06365601718425751, 'loss_2': 0.01560211181640625, 'loss_3': -16.445484161376953, 'loss_4': 0.9868407249450684, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 14:06:18,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:18,250 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:12<14:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:25,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025837436318397522, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02194943279027939, 'eval_loss_2': 0.003887999802827835, 'eval_loss_3': -18.01586151123047, 'eval_loss_4': 0.7104483842849731, 'epoch': 25.03}
{'loss': 0.0271, 'grad_norm': 6.898348331451416, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.016785241663455963, 'loss_2': 0.01029205322265625, 'loss_3': -16.561336517333984, 'loss_4': 1.2693672180175781, 'epoch': 25.03}
{'loss': 0.009, 'grad_norm': 4.6529998779296875, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.0069960253313183784, 'loss_2': 0.001995086669921875, 'loss_3': -16.386184692382812, 'loss_4': 0.5944188833236694, 'epoch': 25.04}
{'loss': 0.0136, 'grad_norm': 9.009349822998047, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.008163794875144958, 'loss_2': 0.00542449951171875, 'loss_3': -16.47051239013672, 'loss_4': 0.48347774147987366, 'epoch': 25.05}
{'loss': 0.0141, 'grad_norm': 5.2878217697143555, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.00789579190313816, 'loss_2': 0.00617218017578125, 'loss_3': -16.447345733642578, 'loss_4': 0.9890021085739136, 'epoch': 25.05}
{'loss': 0.0077, 'grad_norm': 5.234033107757568, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.005865512415766716, 'loss_2': 0.0018215179443359375, 'loss_3': -16.29931640625, 'loss_4': 0.7445268034934998, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 14:06:25,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:25,591 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:19<14:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:32,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01783769577741623, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013645478524267673, 'eval_loss_2': 0.00419221818447113, 'eval_loss_3': -18.0685977935791, 'eval_loss_4': 0.6176180243492126, 'epoch': 25.06}
{'loss': 0.0178, 'grad_norm': 4.850924968719482, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.006097911857068539, 'loss_2': 0.01174163818359375, 'loss_3': -16.403858184814453, 'loss_4': 0.4548310339450836, 'epoch': 25.06}
{'loss': 0.0057, 'grad_norm': 4.559479713439941, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.0037343951407819986, 'loss_2': 0.002002716064453125, 'loss_3': -16.40364646911621, 'loss_4': 0.7295898199081421, 'epoch': 25.07}
{'loss': 0.0127, 'grad_norm': 5.908365726470947, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.008345342241227627, 'loss_2': 0.00434112548828125, 'loss_3': -16.56648063659668, 'loss_4': 0.5306381583213806, 'epoch': 25.08}
{'loss': 0.0166, 'grad_norm': 4.467335224151611, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.0024074402172118425, 'loss_2': 0.01422882080078125, 'loss_3': -16.335481643676758, 'loss_4': 0.8206201791763306, 'epoch': 25.08}
{'loss': 0.0125, 'grad_norm': 7.656189918518066, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.012064727954566479, 'loss_2': 0.00042057037353515625, 'loss_3': -16.353845596313477, 'loss_4': 0.4852254390716553, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 14:06:32,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:32,935 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:27<14:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:40,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013722902163863182, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01059479359537363, 'eval_loss_2': 0.003128107637166977, 'eval_loss_3': -18.09038543701172, 'eval_loss_4': 0.5876045823097229, 'epoch': 25.09}
{'loss': 0.0101, 'grad_norm': 4.955111503601074, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.0062823789194226265, 'loss_2': 0.00383758544921875, 'loss_3': -16.27685546875, 'loss_4': 0.7412667274475098, 'epoch': 25.09}
{'loss': 0.0049, 'grad_norm': 4.6424360275268555, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.004305711947381496, 'loss_2': 0.0005755424499511719, 'loss_3': -16.353515625, 'loss_4': 1.0830214023590088, 'epoch': 25.1}
{'loss': 0.0046, 'grad_norm': 4.573326110839844, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.0038639805279672146, 'loss_2': 0.0007390975952148438, 'loss_3': -16.669517517089844, 'loss_4': 0.5071656107902527, 'epoch': 25.1}
{'loss': 0.0051, 'grad_norm': 4.723081588745117, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.004447031766176224, 'loss_2': 0.0006661415100097656, 'loss_3': -16.45642852783203, 'loss_4': 0.3858916461467743, 'epoch': 25.11}
{'loss': 0.0136, 'grad_norm': 6.449695110321045, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.00777085917070508, 'loss_2': 0.00579071044921875, 'loss_3': -16.294719696044922, 'loss_4': 0.9800955653190613, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 14:06:40,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:40,279 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:34<14:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:47,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013684460893273354, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010520090349018574, 'eval_loss_2': 0.003164369612932205, 'eval_loss_3': -18.105731964111328, 'eval_loss_4': 0.5338552594184875, 'epoch': 25.12}
{'loss': 0.0065, 'grad_norm': 4.358628749847412, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.0038534575141966343, 'loss_2': 0.0026187896728515625, 'loss_3': -16.32849884033203, 'loss_4': 0.42205610871315, 'epoch': 25.12}
{'loss': 0.0082, 'grad_norm': 4.99538516998291, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.005276206880807877, 'loss_2': 0.002902984619140625, 'loss_3': -16.537763595581055, 'loss_4': 0.4835708737373352, 'epoch': 25.13}
{'loss': 0.013, 'grad_norm': 4.957090377807617, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.007785004563629627, 'loss_2': 0.0052032470703125, 'loss_3': -16.42877960205078, 'loss_4': 0.7856639623641968, 'epoch': 25.13}
{'loss': 0.0083, 'grad_norm': 4.668303966522217, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.0046733892522752285, 'loss_2': 0.0035800933837890625, 'loss_3': -16.29585838317871, 'loss_4': -0.0061345696449279785, 'epoch': 25.14}
{'loss': 0.0115, 'grad_norm': 5.782391548156738, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.009600231423974037, 'loss_2': 0.0019092559814453125, 'loss_3': -16.48874855041504, 'loss_4': 0.40320414304733276, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 14:06:47,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:47,631 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:42<14:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:54,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013159258291125298, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.574, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010049020871520042, 'eval_loss_2': 0.003110237419605255, 'eval_loss_3': -18.12732696533203, 'eval_loss_4': 0.4211518466472626, 'epoch': 25.15}
{'loss': 0.0069, 'grad_norm': 4.168249607086182, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.00293439207598567, 'loss_2': 0.00397491455078125, 'loss_3': -16.37581443786621, 'loss_4': 0.22506949305534363, 'epoch': 25.15}
{'loss': 0.0073, 'grad_norm': 4.661684513092041, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.004157029092311859, 'loss_2': 0.00318145751953125, 'loss_3': -16.55568504333496, 'loss_4': 0.3429323434829712, 'epoch': 25.16}
{'loss': 0.0091, 'grad_norm': 4.425833702087402, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.0041074082255363464, 'loss_2': 0.0050048828125, 'loss_3': -16.278606414794922, 'loss_4': 0.5238319635391235, 'epoch': 25.16}
{'loss': 0.008, 'grad_norm': 4.56077766418457, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.0022147921845316887, 'loss_2': 0.005767822265625, 'loss_3': -16.702363967895508, 'loss_4': 0.2627260684967041, 'epoch': 25.17}
{'loss': 0.012, 'grad_norm': 4.870407581329346, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.00968518853187561, 'loss_2': 0.002361297607421875, 'loss_3': -16.54726219177246, 'loss_4': 0.4974401295185089, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 14:06:54,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:54,977 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:49<14:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:02,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013375385664403439, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009782833978533745, 'eval_loss_2': 0.003592550754547119, 'eval_loss_3': -18.13899040222168, 'eval_loss_4': 0.3338710367679596, 'epoch': 25.17}
{'loss': 0.0061, 'grad_norm': 4.555359363555908, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.0025334502570331097, 'loss_2': 0.0035247802734375, 'loss_3': -16.536863327026367, 'loss_4': 0.7084017992019653, 'epoch': 25.18}
{'loss': 0.0083, 'grad_norm': 5.220280647277832, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.007364888675510883, 'loss_2': 0.0009131431579589844, 'loss_3': -16.294570922851562, 'loss_4': 0.4469103515148163, 'epoch': 25.19}
{'loss': 0.0063, 'grad_norm': 4.54552698135376, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.00403014337643981, 'loss_2': 0.0022983551025390625, 'loss_3': -16.377830505371094, 'loss_4': 0.1022091805934906, 'epoch': 25.19}
{'loss': 0.0082, 'grad_norm': 5.552431583404541, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.008007334545254707, 'loss_2': 0.0001761913299560547, 'loss_3': -16.16486358642578, 'loss_4': 0.3697352707386017, 'epoch': 25.2}
{'loss': 0.0089, 'grad_norm': 4.519625186920166, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.007473086006939411, 'loss_2': 0.0014057159423828125, 'loss_3': -16.383146286010742, 'loss_4': 0.4509989023208618, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 14:07:02,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:02,316 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:56<14:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:09,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012680615298449993, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008889253251254559, 'eval_loss_2': 0.0037913620471954346, 'eval_loss_3': -18.15448760986328, 'eval_loss_4': 0.29053395986557007, 'epoch': 25.2}
{'loss': 0.0058, 'grad_norm': 4.90059757232666, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.005511054303497076, 'loss_2': 0.00031638145446777344, 'loss_3': -16.347631454467773, 'loss_4': 0.47902339696884155, 'epoch': 25.21}
{'loss': 0.0078, 'grad_norm': 4.6895527839660645, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.004416011739522219, 'loss_2': 0.003337860107421875, 'loss_3': -16.567363739013672, 'loss_4': 0.3198910057544708, 'epoch': 25.22}
{'loss': 0.0073, 'grad_norm': 4.556245803833008, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.005438501015305519, 'loss_2': 0.00183868408203125, 'loss_3': -16.44447898864746, 'loss_4': -0.07744120806455612, 'epoch': 25.22}
{'loss': 0.0084, 'grad_norm': 4.610693454742432, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.002790852915495634, 'loss_2': 0.005588531494140625, 'loss_3': -16.184566497802734, 'loss_4': -0.25741496682167053, 'epoch': 25.23}
{'loss': 0.0066, 'grad_norm': 4.672433376312256, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.004635511431843042, 'loss_2': 0.0019683837890625, 'loss_3': -16.570026397705078, 'loss_4': 0.2818151116371155, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 14:07:09,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:09,655 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:47:04<14:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:17,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012606436386704445, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.462, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00861936155706644, 'eval_loss_2': 0.00398707389831543, 'eval_loss_3': -18.15623664855957, 'eval_loss_4': 0.2945147752761841, 'epoch': 25.23}
{'loss': 0.0074, 'grad_norm': 4.493753433227539, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.003271976485848427, 'loss_2': 0.00411224365234375, 'loss_3': -16.4608097076416, 'loss_4': 0.40390050411224365, 'epoch': 25.24}
{'loss': 0.0101, 'grad_norm': 5.09365177154541, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.006924652960151434, 'loss_2': 0.00318145751953125, 'loss_3': -16.400897979736328, 'loss_4': 0.34715235233306885, 'epoch': 25.24}
{'loss': 0.012, 'grad_norm': 7.018102169036865, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.007928152568638325, 'loss_2': 0.00411224365234375, 'loss_3': -16.370662689208984, 'loss_4': 0.40017077326774597, 'epoch': 25.25}
{'loss': 0.069, 'grad_norm': 18.428186416625977, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.05880365148186684, 'loss_2': 0.01015472412109375, 'loss_3': -16.461606979370117, 'loss_4': 0.6387302875518799, 'epoch': 25.26}
{'loss': 0.0266, 'grad_norm': 6.593156337738037, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.018187642097473145, 'loss_2': 0.0084381103515625, 'loss_3': -16.53567886352539, 'loss_4': 0.2870296239852905, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 14:07:17,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:17,007 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:11<14:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:24,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01242833025753498, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008509056642651558, 'eval_loss_2': 0.003919273614883423, 'eval_loss_3': -18.153505325317383, 'eval_loss_4': 0.34588006138801575, 'epoch': 25.26}
{'loss': 0.0162, 'grad_norm': 6.94364070892334, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.014325392432510853, 'loss_2': 0.00189208984375, 'loss_3': -16.394569396972656, 'loss_4': 0.6285904049873352, 'epoch': 25.27}
{'loss': 0.0165, 'grad_norm': 7.7228684425354, 'learning_rate': 4.75e-06, 'loss_1': 0.015440519899129868, 'loss_2': 0.0010385513305664062, 'loss_3': -16.378211975097656, 'loss_4': 0.8148204684257507, 'epoch': 25.27}
{'loss': 0.014, 'grad_norm': 4.59428596496582, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.003757113590836525, 'loss_2': 0.01024627685546875, 'loss_3': -16.4453125, 'loss_4': 0.4038444757461548, 'epoch': 25.28}
{'loss': 0.0075, 'grad_norm': 4.96828031539917, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.004102691542357206, 'loss_2': 0.0034236907958984375, 'loss_3': -16.296445846557617, 'loss_4': 0.9807836413383484, 'epoch': 25.28}
{'loss': 0.0638, 'grad_norm': 13.302510261535645, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.06155099719762802, 'loss_2': 0.00220489501953125, 'loss_3': -16.238170623779297, 'loss_4': 0.7228666543960571, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 14:07:24,355 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:24,355 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:18<13:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:31,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013076827861368656, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.952, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008688375353813171, 'eval_loss_2': 0.00438845157623291, 'eval_loss_3': -18.14462661743164, 'eval_loss_4': 0.4030349850654602, 'epoch': 25.29}
{'loss': 0.0138, 'grad_norm': 6.9106764793396, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.009896908886730671, 'loss_2': 0.00394439697265625, 'loss_3': -16.4765625, 'loss_4': 1.0111669301986694, 'epoch': 25.3}
{'loss': 0.0129, 'grad_norm': 5.190167427062988, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.008764117024838924, 'loss_2': 0.00414276123046875, 'loss_3': -16.42971420288086, 'loss_4': 0.8012514114379883, 'epoch': 25.3}
{'loss': 0.0042, 'grad_norm': 4.514627933502197, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.0025533984880894423, 'loss_2': 0.0016841888427734375, 'loss_3': -16.43060302734375, 'loss_4': 0.6403414607048035, 'epoch': 25.31}
{'loss': 0.0149, 'grad_norm': 6.7943501472473145, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.008082489483058453, 'loss_2': 0.0067901611328125, 'loss_3': -16.441688537597656, 'loss_4': 0.8758668899536133, 'epoch': 25.31}
{'loss': 0.0084, 'grad_norm': 6.518646717071533, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.007414328400045633, 'loss_2': 0.00099945068359375, 'loss_3': -16.198162078857422, 'loss_4': 0.44099360704421997, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 14:07:31,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:31,712 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:26<13:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:39,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013305393978953362, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009257522411644459, 'eval_loss_2': 0.004047870635986328, 'eval_loss_3': -18.13425636291504, 'eval_loss_4': 0.39944911003112793, 'epoch': 25.32}
{'loss': 0.0034, 'grad_norm': 4.4892072677612305, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.002274436643347144, 'loss_2': 0.0010890960693359375, 'loss_3': -16.346935272216797, 'loss_4': 0.7898309230804443, 'epoch': 25.33}
{'loss': 0.0064, 'grad_norm': 5.4839935302734375, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.006284629460424185, 'loss_2': 0.00012314319610595703, 'loss_3': -16.455913543701172, 'loss_4': 0.527653157711029, 'epoch': 25.33}
{'loss': 0.008, 'grad_norm': 5.128209114074707, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.0058771297335624695, 'loss_2': 0.0020904541015625, 'loss_3': -16.530752182006836, 'loss_4': 0.44024723768234253, 'epoch': 25.34}
{'loss': 0.0094, 'grad_norm': 5.207736968994141, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.0064355493523180485, 'loss_2': 0.0029888153076171875, 'loss_3': -16.375431060791016, 'loss_4': 0.47376176714897156, 'epoch': 25.34}
{'loss': 0.0052, 'grad_norm': 5.530197620391846, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.004999286029487848, 'loss_2': 0.00019693374633789062, 'loss_3': -16.533491134643555, 'loss_4': 0.5942592024803162, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 14:07:39,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:39,055 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:33<13:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:46,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013251036405563354, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0089570302516222, 'eval_loss_2': 0.004294008016586304, 'eval_loss_3': -18.12633514404297, 'eval_loss_4': 0.3745894134044647, 'epoch': 25.35}
{'loss': 0.0109, 'grad_norm': 5.260162353515625, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.0052345129661262035, 'loss_2': 0.00567626953125, 'loss_3': -16.228525161743164, 'loss_4': 0.3408759832382202, 'epoch': 25.35}
{'loss': 0.0221, 'grad_norm': 8.834956169128418, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.019546689465641975, 'loss_2': 0.0025959014892578125, 'loss_3': -16.475168228149414, 'loss_4': 0.7758517861366272, 'epoch': 25.36}
{'loss': 0.0056, 'grad_norm': 4.648961544036865, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.002938060322776437, 'loss_2': 0.0026454925537109375, 'loss_3': -16.476051330566406, 'loss_4': 0.6235660314559937, 'epoch': 25.37}
{'loss': 0.0132, 'grad_norm': 5.723377227783203, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.010269060730934143, 'loss_2': 0.002918243408203125, 'loss_3': -16.458152770996094, 'loss_4': 0.7872328758239746, 'epoch': 25.37}
{'loss': 0.0201, 'grad_norm': 10.542588233947754, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.015397065319120884, 'loss_2': 0.0047149658203125, 'loss_3': -16.293731689453125, 'loss_4': 0.11760666221380234, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 14:07:46,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:46,395 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:40<13:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:53,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01253088191151619, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.339, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00840814784169197, 'eval_loss_2': 0.004122734069824219, 'eval_loss_3': -18.128726959228516, 'eval_loss_4': 0.37729182839393616, 'epoch': 25.38}
{'loss': 0.0116, 'grad_norm': 6.606624603271484, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.011515392921864986, 'loss_2': 0.0001112222671508789, 'loss_3': -16.396034240722656, 'loss_4': 0.3939945697784424, 'epoch': 25.38}
{'loss': 0.0066, 'grad_norm': 4.527705669403076, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.004063411615788937, 'loss_2': 0.00252532958984375, 'loss_3': -16.404125213623047, 'loss_4': 0.5613793134689331, 'epoch': 25.39}
{'loss': 0.0051, 'grad_norm': 4.6061625480651855, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.004438641015440226, 'loss_2': 0.0006923675537109375, 'loss_3': -16.53615951538086, 'loss_4': 0.593735933303833, 'epoch': 25.4}
{'loss': 0.0058, 'grad_norm': 5.813173294067383, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.004506571684032679, 'loss_2': 0.0013065338134765625, 'loss_3': -16.591814041137695, 'loss_4': 0.3335581421852112, 'epoch': 25.4}
{'loss': 0.0117, 'grad_norm': 4.880953788757324, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.004317153710871935, 'loss_2': 0.0073699951171875, 'loss_3': -16.461435317993164, 'loss_4': 0.5733671188354492, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 14:07:53,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:53,738 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:48<13:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:01,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012039192020893097, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.823, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00802052766084671, 'eval_loss_2': 0.004018664360046387, 'eval_loss_3': -18.12960433959961, 'eval_loss_4': 0.33171916007995605, 'epoch': 25.41}
{'loss': 0.0045, 'grad_norm': 4.6695146560668945, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.004380947910249233, 'loss_2': 0.00016117095947265625, 'loss_3': -16.257701873779297, 'loss_4': 0.3862132430076599, 'epoch': 25.41}
{'loss': 0.0072, 'grad_norm': 6.662261486053467, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.004266548436135054, 'loss_2': 0.0029087066650390625, 'loss_3': -16.453128814697266, 'loss_4': 0.23456329107284546, 'epoch': 25.42}
{'loss': 0.006, 'grad_norm': 4.484430313110352, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.0029960605315864086, 'loss_2': 0.003009796142578125, 'loss_3': -16.262897491455078, 'loss_4': 0.36791718006134033, 'epoch': 25.42}
{'loss': 0.0065, 'grad_norm': 5.189563751220703, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.005805667955428362, 'loss_2': 0.0006933212280273438, 'loss_3': -16.42287826538086, 'loss_4': 0.2746914029121399, 'epoch': 25.43}
{'loss': 0.0089, 'grad_norm': 4.761093616485596, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.0038383095525205135, 'loss_2': 0.005096435546875, 'loss_3': -16.490219116210938, 'loss_4': -0.07341259717941284, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 14:08:01,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:01,082 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:55<13:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:08,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01164713129401207, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007883156649768353, 'eval_loss_2': 0.0037639737129211426, 'eval_loss_3': -18.133195877075195, 'eval_loss_4': 0.24817822873592377, 'epoch': 25.44}
{'loss': 0.028, 'grad_norm': 12.796415328979492, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.019644780084490776, 'loss_2': 0.00838470458984375, 'loss_3': -16.362117767333984, 'loss_4': 0.7736968994140625, 'epoch': 25.44}
{'loss': 0.0131, 'grad_norm': 12.313639640808105, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.010764777660369873, 'loss_2': 0.0023345947265625, 'loss_3': -16.566646575927734, 'loss_4': 0.1659596711397171, 'epoch': 25.45}
{'loss': 0.0074, 'grad_norm': 4.756103992462158, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.005304973106831312, 'loss_2': 0.00209808349609375, 'loss_3': -16.356891632080078, 'loss_4': 0.5428426265716553, 'epoch': 25.45}
{'loss': 0.0114, 'grad_norm': 5.212574005126953, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.0070669986307621, 'loss_2': 0.0043182373046875, 'loss_3': -16.41905975341797, 'loss_4': -0.10438284277915955, 'epoch': 25.46}
{'loss': 0.0074, 'grad_norm': 6.116935729980469, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.005656248889863491, 'loss_2': 0.0017805099487304688, 'loss_3': -16.443761825561523, 'loss_4': 0.6989398002624512, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 14:08:08,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:08,430 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:59<13:29,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:08:12,226 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380
[INFO|configuration_utils.py:420] 2025-01-21 14:08:12,227 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380/config.json                                                                            
{'eval_loss': 0.011292370036244392, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007783921901136637, 'eval_loss_2': 0.003508448600769043, 'eval_loss_3': -18.13429832458496, 'eval_loss_4': 0.22501783072948456, 'epoch': 25.47}
[INFO|modeling_utils.py:2988] 2025-01-21 14:08:12,731 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:08:12,733 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:08:12,733 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:08:13,755 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-1740] due to args.save_total_limit
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:48:04<14:52,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 14:08:17,376 >>
{'loss': 0.0057, 'grad_norm': 4.684260368347168, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.0033735481556504965, 'loss_2': 0.002353668212890625, 'loss_3': -16.284208297729492, 'loss_4': 0.15711350739002228, 'epoch': 25.47}
{'loss': 0.0062, 'grad_norm': 5.004733085632324, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.003393760183826089, 'loss_2': 0.002826690673828125, 'loss_3': -16.394147872924805, 'loss_4': -0.012475833296775818, 'epoch': 25.48}
{'loss': 0.0193, 'grad_norm': 9.149012565612793, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.01725807599723339, 'loss_2': 0.0020008087158203125, 'loss_3': -16.437381744384766, 'loss_4': 0.18129870295524597, 'epoch': 25.48}
{'loss': 0.0076, 'grad_norm': 4.62667989730835, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.0047792778350412846, 'loss_2': 0.00284576416015625, 'loss_3': -16.263805389404297, 'loss_4': 0.28057461977005005, 'epoch': 25.49}
{'loss': 0.0054, 'grad_norm': 4.7599196434021, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.005232554394751787, 'loss_2': 0.00017392635345458984, 'loss_3': -16.44002342224121, 'loss_4': 0.2584752142429352, 'epoch': 25.49}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:08:17,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:17,376 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:11<13:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:08:24,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011394567787647247, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.869, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007737062871456146, 'eval_loss_2': 0.003657504916191101, 'eval_loss_3': -18.126502990722656, 'eval_loss_4': 0.2593615651130676, 'epoch': 25.49}
{'loss': 0.0172, 'grad_norm': 6.680825710296631, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.01065193209797144, 'loss_2': 0.00650787353515625, 'loss_3': -16.253480911254883, 'loss_4': 0.3458685874938965, 'epoch': 25.5}
{'loss': 0.0086, 'grad_norm': 4.964284420013428, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.005266569089144468, 'loss_2': 0.00334930419921875, 'loss_3': -16.64724349975586, 'loss_4': 0.4052445888519287, 'epoch': 25.51}
{'loss': 0.0117, 'grad_norm': 4.791892051696777, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.00690710823982954, 'loss_2': 0.004833221435546875, 'loss_3': -16.424837112426758, 'loss_4': 0.05052854120731354, 'epoch': 25.51}
{'loss': 0.0091, 'grad_norm': 5.75300931930542, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.008157426491379738, 'loss_2': 0.0009489059448242188, 'loss_3': -16.44087791442871, 'loss_4': 0.5618765354156494, 'epoch': 25.52}
{'loss': 0.0058, 'grad_norm': 8.346051216125488, 'learning_rate': 4.5e-06, 'loss_1': 0.00411011790856719, 'loss_2': 0.0016918182373046875, 'loss_3': -16.47688102722168, 'loss_4': 0.503084659576416, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 14:08:24,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:24,708 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:19<13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:32,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011378433555364609, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.168, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007484521251171827, 'eval_loss_2': 0.003893911838531494, 'eval_loss_3': -18.10834503173828, 'eval_loss_4': 0.2761797606945038, 'epoch': 25.52}
{'loss': 0.014, 'grad_norm': 12.275751113891602, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.011334791779518127, 'loss_2': 0.002655029296875, 'loss_3': -16.364749908447266, 'loss_4': 0.5747388601303101, 'epoch': 25.53}
{'loss': 0.0041, 'grad_norm': 4.750086784362793, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.0023845203686505556, 'loss_2': 0.00173187255859375, 'loss_3': -16.3893985748291, 'loss_4': 0.14138159155845642, 'epoch': 25.53}
{'loss': 0.0202, 'grad_norm': 13.269231796264648, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.018609458580613136, 'loss_2': 0.0015506744384765625, 'loss_3': -16.484867095947266, 'loss_4': 0.6241368055343628, 'epoch': 25.54}
{'loss': 0.0067, 'grad_norm': 4.84724235534668, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.0032439865171909332, 'loss_2': 0.003448486328125, 'loss_3': -16.4038143157959, 'loss_4': -0.01380826160311699, 'epoch': 25.55}
{'loss': 0.014, 'grad_norm': 5.216673374176025, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.005779129918664694, 'loss_2': 0.0081787109375, 'loss_3': -16.372257232666016, 'loss_4': 0.5140623450279236, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 14:08:32,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:32,040 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:26<13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:39,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011782465502619743, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007618679199367762, 'eval_loss_2': 0.004163786768913269, 'eval_loss_3': -18.112464904785156, 'eval_loss_4': 0.2839399576187134, 'epoch': 25.55}
{'loss': 0.0126, 'grad_norm': 6.7255120277404785, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.008630934171378613, 'loss_2': 0.003932952880859375, 'loss_3': -16.465728759765625, 'loss_4': 0.4726283550262451, 'epoch': 25.56}
{'loss': 0.0057, 'grad_norm': 4.845386028289795, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.004769759718328714, 'loss_2': 0.000946044921875, 'loss_3': -16.369403839111328, 'loss_4': 0.09914582967758179, 'epoch': 25.56}
{'loss': 0.01, 'grad_norm': 4.4931793212890625, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.004918580409139395, 'loss_2': 0.005096435546875, 'loss_3': -16.336687088012695, 'loss_4': 0.41939905285835266, 'epoch': 25.57}
{'loss': 0.0139, 'grad_norm': 5.541207790374756, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.007377746049314737, 'loss_2': 0.00647735595703125, 'loss_3': -16.567138671875, 'loss_4': 0.4191323518753052, 'epoch': 25.58}
{'loss': 0.0149, 'grad_norm': 4.83620548248291, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.007163309492170811, 'loss_2': 0.0077056884765625, 'loss_3': -16.27950096130371, 'loss_4': 0.6914929747581482, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 14:08:39,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:39,373 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:33<13:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:46,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011850357055664062, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007872521877288818, 'eval_loss_2': 0.003977835178375244, 'eval_loss_3': -18.116941452026367, 'eval_loss_4': 0.2729955315589905, 'epoch': 25.58}
{'loss': 0.0091, 'grad_norm': 4.33450174331665, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.0033309822902083397, 'loss_2': 0.005802154541015625, 'loss_3': -16.50983238220215, 'loss_4': 0.7365021109580994, 'epoch': 25.59}
{'loss': 0.0051, 'grad_norm': 4.810428142547607, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.0037141330540180206, 'loss_2': 0.001338958740234375, 'loss_3': -16.349586486816406, 'loss_4': 0.16871605813503265, 'epoch': 25.59}
{'loss': 0.0164, 'grad_norm': 7.8609442710876465, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.014583481475710869, 'loss_2': 0.00185394287109375, 'loss_3': -16.216304779052734, 'loss_4': -0.0629611536860466, 'epoch': 25.6}
{'loss': 0.0153, 'grad_norm': 8.416810989379883, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.015320030972361565, 'loss_2': 2.193450927734375e-05, 'loss_3': -16.35619354248047, 'loss_4': 0.6930948495864868, 'epoch': 25.6}
{'loss': 0.0153, 'grad_norm': 8.65798568725586, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.009604326449334621, 'loss_2': 0.005687713623046875, 'loss_3': -16.323974609375, 'loss_4': 0.7128950953483582, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 14:08:46,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:46,704 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:41<12:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:54,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011496095918118954, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007840572856366634, 'eval_loss_2': 0.0036555230617523193, 'eval_loss_3': -18.112016677856445, 'eval_loss_4': 0.23563960194587708, 'epoch': 25.61}
{'loss': 0.0106, 'grad_norm': 5.257365703582764, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.005924880504608154, 'loss_2': 0.00466156005859375, 'loss_3': -16.27812385559082, 'loss_4': 0.46369561553001404, 'epoch': 25.62}
{'loss': 0.0094, 'grad_norm': 5.2864089012146, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.00654632830992341, 'loss_2': 0.00283050537109375, 'loss_3': -16.45276641845703, 'loss_4': 0.25913918018341064, 'epoch': 25.62}
{'loss': 0.0065, 'grad_norm': 4.723329067230225, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.003513252129778266, 'loss_2': 0.002941131591796875, 'loss_3': -16.23116683959961, 'loss_4': 0.15980151295661926, 'epoch': 25.63}
{'loss': 0.0068, 'grad_norm': 4.786077499389648, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.004871963523328304, 'loss_2': 0.0019025802612304688, 'loss_3': -16.479238510131836, 'loss_4': -0.1315709799528122, 'epoch': 25.63}
{'loss': 0.0121, 'grad_norm': 4.122478008270264, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.004418930970132351, 'loss_2': 0.0077056884765625, 'loss_3': -16.324907302856445, 'loss_4': -0.28651943802833557, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 14:08:54,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:54,045 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:44<12:57,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:08:57,836 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410
[INFO|configuration_utils.py:420] 2025-01-21 14:08:57,838 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410/config.json                                                                            
{'eval_loss': 0.011264578439295292, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.181, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007805303670465946, 'eval_loss_2': 0.0034592747688293457, 'eval_loss_3': -18.104320526123047, 'eval_loss_4': 0.19410327076911926, 'epoch': 25.64}
[INFO|modeling_utils.py:2988] 2025-01-21 14:08:58,324 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:08:58,325 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:08:58,326 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:08:59,356 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4380] due to args.save_total_limit
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:50<14:18,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 14:09:02,985 >>
{'loss': 0.0101, 'grad_norm': 6.398813724517822, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.008665498346090317, 'loss_2': 0.0014562606811523438, 'loss_3': -16.40310287475586, 'loss_4': -0.027395419776439667, 'epoch': 25.65}
{'loss': 0.006, 'grad_norm': 5.052823066711426, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.004905302543193102, 'loss_2': 0.0010499954223632812, 'loss_3': -16.48854637145996, 'loss_4': 0.14781415462493896, 'epoch': 25.65}
{'loss': 0.0194, 'grad_norm': 4.996648788452148, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.009907590225338936, 'loss_2': 0.009490966796875, 'loss_3': -16.569232940673828, 'loss_4': 0.480896532535553, 'epoch': 25.66}
{'loss': 0.0191, 'grad_norm': 7.875547409057617, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.01317072007805109, 'loss_2': 0.00592803955078125, 'loss_3': -16.540403366088867, 'loss_4': 0.06745532155036926, 'epoch': 25.66}
{'loss': 0.0047, 'grad_norm': 4.852838039398193, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.0028169641736894846, 'loss_2': 0.001834869384765625, 'loss_3': -16.55406951904297, 'loss_4': 0.36670491099357605, 'epoch': 25.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:09:02,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:02,986 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:53<14:18,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 14:09:06,786 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415
[INFO|configuration_utils.py:420] 2025-01-21 14:09:06,788 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415/config.json                                                                            
{'eval_loss': 0.011196032166481018, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008039848878979683, 'eval_loss_2': 0.0031561851501464844, 'eval_loss_3': -18.098194122314453, 'eval_loss_4': 0.20432862639427185, 'epoch': 25.67}
[INFO|modeling_utils.py:2988] 2025-01-21 14:09:07,287 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:09:07,288 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:09:07,288 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:09:08,306 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4410] due to args.save_total_limit
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:58<14:26,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 14:09:11,926 >>
{'loss': 0.0071, 'grad_norm': 5.520572662353516, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.007014807779341936, 'loss_2': 0.00010758638381958008, 'loss_3': -16.388038635253906, 'loss_4': 0.29648834466934204, 'epoch': 25.67}
{'loss': 0.0069, 'grad_norm': 4.56317138671875, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.003810298629105091, 'loss_2': 0.00304412841796875, 'loss_3': -16.500896453857422, 'loss_4': 0.7036121487617493, 'epoch': 25.68}
{'loss': 0.0129, 'grad_norm': 4.807920455932617, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.006567221134901047, 'loss_2': 0.00630950927734375, 'loss_3': -16.549375534057617, 'loss_4': 0.7640529870986938, 'epoch': 25.69}
{'loss': 0.0179, 'grad_norm': 5.395358085632324, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.012858756817877293, 'loss_2': 0.004993438720703125, 'loss_3': -16.347400665283203, 'loss_4': 0.07369391620159149, 'epoch': 25.69}
{'loss': 0.0124, 'grad_norm': 4.950766086578369, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.007604343816637993, 'loss_2': 0.00478363037109375, 'loss_3': -16.385080337524414, 'loss_4': 0.10135287791490555, 'epoch': 25.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:09:11,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:11,926 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:49:06<12:58,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:09:19,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011416799388825893, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008243568241596222, 'eval_loss_2': 0.003173232078552246, 'eval_loss_3': -18.10065460205078, 'eval_loss_4': 0.20391488075256348, 'epoch': 25.7}
{'loss': 0.0093, 'grad_norm': 4.697408199310303, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.004998232703655958, 'loss_2': 0.004329681396484375, 'loss_3': -16.29944610595703, 'loss_4': 0.5404033660888672, 'epoch': 25.7}
{'loss': 0.0085, 'grad_norm': 4.665550708770752, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.004509665537625551, 'loss_2': 0.0040283203125, 'loss_3': -16.424118041992188, 'loss_4': 0.4777531921863556, 'epoch': 25.71}
{'loss': 0.0031, 'grad_norm': 3.985396146774292, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.0014688135124742985, 'loss_2': 0.0016002655029296875, 'loss_3': -16.467756271362305, 'loss_4': 0.7478865385055542, 'epoch': 25.72}
{'loss': 0.0052, 'grad_norm': 4.910362720489502, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.0034861601889133453, 'loss_2': 0.00171661376953125, 'loss_3': -16.46700668334961, 'loss_4': 0.43091854453086853, 'epoch': 25.72}
{'loss': 0.007, 'grad_norm': 5.424108505249023, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.006872436031699181, 'loss_2': 0.00017189979553222656, 'loss_3': -16.31647300720215, 'loss_4': -0.10183122754096985, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 14:09:19,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:19,264 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:13<12:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:26,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011821454390883446, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008716036565601826, 'eval_loss_2': 0.0031054168939590454, 'eval_loss_3': -18.10123634338379, 'eval_loss_4': 0.24185581505298615, 'epoch': 25.73}
{'loss': 0.0133, 'grad_norm': 5.860864162445068, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.010713659226894379, 'loss_2': 0.0026073455810546875, 'loss_3': -16.505752563476562, 'loss_4': 0.22921034693717957, 'epoch': 25.73}
{'loss': 0.0096, 'grad_norm': 4.5860819816589355, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.003712400095537305, 'loss_2': 0.00591278076171875, 'loss_3': -16.541065216064453, 'loss_4': 0.2808954417705536, 'epoch': 25.74}
{'loss': 0.0091, 'grad_norm': 4.514726638793945, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.0023801233619451523, 'loss_2': 0.00673675537109375, 'loss_3': -16.486713409423828, 'loss_4': 0.19959665834903717, 'epoch': 25.74}
{'loss': 0.0101, 'grad_norm': 5.284111022949219, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.005353890359401703, 'loss_2': 0.00478363037109375, 'loss_3': -16.45862579345703, 'loss_4': 0.9221883416175842, 'epoch': 25.75}
{'loss': 0.0057, 'grad_norm': 4.552490234375, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.003617731621488929, 'loss_2': 0.0020923614501953125, 'loss_3': -16.295856475830078, 'loss_4': 0.14608505368232727, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 14:09:26,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:26,610 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:21<12:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:33,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011334007605910301, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.685, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008606425486505032, 'eval_loss_2': 0.0027275830507278442, 'eval_loss_3': -18.111907958984375, 'eval_loss_4': 0.2426561862230301, 'epoch': 25.76}
{'loss': 0.01, 'grad_norm': 5.757251262664795, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.004885840229690075, 'loss_2': 0.005126953125, 'loss_3': -16.503541946411133, 'loss_4': 0.1362071931362152, 'epoch': 25.76}
{'loss': 0.0077, 'grad_norm': 4.52618932723999, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.004360580816864967, 'loss_2': 0.003387451171875, 'loss_3': -16.38962745666504, 'loss_4': 0.13958048820495605, 'epoch': 25.77}
{'loss': 0.0122, 'grad_norm': 8.029899597167969, 'learning_rate': 4.25e-06, 'loss_1': 0.008965963497757912, 'loss_2': 0.00325775146484375, 'loss_3': -16.58237075805664, 'loss_4': 0.4532976746559143, 'epoch': 25.77}
{'loss': 0.007, 'grad_norm': 4.862564563751221, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.005665419157594442, 'loss_2': 0.0013322830200195312, 'loss_3': -16.430660247802734, 'loss_4': 0.2145482301712036, 'epoch': 25.78}
{'loss': 0.0055, 'grad_norm': 4.287264823913574, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.0037285478319972754, 'loss_2': 0.0018091201782226562, 'loss_3': -16.32605743408203, 'loss_4': 0.3096746504306793, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 14:09:33,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:33,945 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:28<12:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:41,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011624805629253387, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.317, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008719174191355705, 'eval_loss_2': 0.002905629575252533, 'eval_loss_3': -18.11374282836914, 'eval_loss_4': 0.22134259343147278, 'epoch': 25.78}
{'loss': 0.0079, 'grad_norm': 4.707457542419434, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.004397714510560036, 'loss_2': 0.00345611572265625, 'loss_3': -16.596216201782227, 'loss_4': 0.4486214518547058, 'epoch': 25.79}
{'loss': 0.0199, 'grad_norm': 12.1791353225708, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.016133520752191544, 'loss_2': 0.00372314453125, 'loss_3': -16.389774322509766, 'loss_4': 0.12190833687782288, 'epoch': 25.8}
{'loss': 0.006, 'grad_norm': 5.228845596313477, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.004986782558262348, 'loss_2': 0.0010623931884765625, 'loss_3': -16.368717193603516, 'loss_4': 0.6127960681915283, 'epoch': 25.8}
{'loss': 0.0123, 'grad_norm': 4.7531819343566895, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.008518625982105732, 'loss_2': 0.0037860870361328125, 'loss_3': -16.206462860107422, 'loss_4': 0.046997278928756714, 'epoch': 25.81}
{'loss': 0.0066, 'grad_norm': 5.561350345611572, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.004765917081385851, 'loss_2': 0.001804351806640625, 'loss_3': -16.437898635864258, 'loss_4': 0.13005511462688446, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 14:09:41,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:41,266 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:32<12:24,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 14:09:45,055 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440
[INFO|configuration_utils.py:420] 2025-01-21 14:09:45,056 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440/config.json                                                                            
{'eval_loss': 0.010809039697051048, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.353, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.008134358562529087, 'eval_loss_2': 0.0026746802031993866, 'eval_loss_3': -18.117589950561523, 'eval_loss_4': 0.20422886312007904, 'epoch': 25.81}
[INFO|modeling_utils.py:2988] 2025-01-21 14:09:45,545 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:09:45,546 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:09:45,547 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:09:46,562 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4415] due to args.save_total_limit
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:37<13:42,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 14:09:50,186 >>
{'loss': 0.009, 'grad_norm': 4.553857326507568, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.003753285389393568, 'loss_2': 0.0052490234375, 'loss_3': -16.407798767089844, 'loss_4': 0.15690752863883972, 'epoch': 25.82}
{'loss': 0.0076, 'grad_norm': 5.570285320281982, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.007162305526435375, 'loss_2': 0.0004284381866455078, 'loss_3': -16.351783752441406, 'loss_4': 0.24329166114330292, 'epoch': 25.83}
{'loss': 0.0196, 'grad_norm': 11.722232818603516, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.0170451570302248, 'loss_2': 0.0025501251220703125, 'loss_3': -16.619401931762695, 'loss_4': 0.5658375024795532, 'epoch': 25.83}
{'loss': 0.0067, 'grad_norm': 4.524103164672852, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.0035397785250097513, 'loss_2': 0.0032062530517578125, 'loss_3': -16.317319869995117, 'loss_4': 0.29050391912460327, 'epoch': 25.84}
{'loss': 0.0085, 'grad_norm': 6.025573253631592, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.006246934644877911, 'loss_2': 0.0022449493408203125, 'loss_3': -16.16097640991211, 'loss_4': -0.041121289134025574, 'epoch': 25.84}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:09:50,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:50,186 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:41<13:42,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 14:09:53,979 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445
[INFO|configuration_utils.py:420] 2025-01-21 14:09:53,980 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445/config.json                                                                            
{'eval_loss': 0.010459640994668007, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.047, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0075426106341183186, 'eval_loss_2': 0.0029170289635658264, 'eval_loss_3': -18.131505966186523, 'eval_loss_4': 0.20850513875484467, 'epoch': 25.84}
[INFO|modeling_utils.py:2988] 2025-01-21 14:09:54,477 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:09:54,479 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:09:54,479 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:09:55,525 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4440] due to args.save_total_limit
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:46<13:52,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 14:09:59,153 >>
{'loss': 0.0202, 'grad_norm': 7.43243932723999, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.013055684976279736, 'loss_2': 0.0071868896484375, 'loss_3': -16.407615661621094, 'loss_4': 0.6203956007957458, 'epoch': 25.85}
{'loss': 0.0035, 'grad_norm': 4.406990051269531, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.0017031978350132704, 'loss_2': 0.0018138885498046875, 'loss_3': -16.500810623168945, 'loss_4': -0.005361884832382202, 'epoch': 25.85}
{'loss': 0.0081, 'grad_norm': 4.650380611419678, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.0020473210606724024, 'loss_2': 0.00603485107421875, 'loss_3': -16.44292449951172, 'loss_4': -0.2958424389362335, 'epoch': 25.86}
{'loss': 0.0041, 'grad_norm': 4.571531772613525, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.0035248261410743, 'loss_2': 0.0005464553833007812, 'loss_3': -16.262157440185547, 'loss_4': -0.016229569911956787, 'epoch': 25.87}
{'loss': 0.0225, 'grad_norm': 6.33858585357666, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.011736949905753136, 'loss_2': 0.010772705078125, 'loss_3': -16.39806365966797, 'loss_4': 0.6185911893844604, 'epoch': 25.87}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:09:59,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:59,153 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:53<12:26,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:10:06,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010940183885395527, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007950265891849995, 'eval_loss_2': 0.0029899179935455322, 'eval_loss_3': -18.122325897216797, 'eval_loss_4': 0.21150465309619904, 'epoch': 25.87}
{'loss': 0.0085, 'grad_norm': 5.711996078491211, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.00681514386087656, 'loss_2': 0.00168609619140625, 'loss_3': -16.408924102783203, 'loss_4': 0.420384019613266, 'epoch': 25.88}
{'loss': 0.0037, 'grad_norm': 4.220626354217529, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.003594017121940851, 'loss_2': 9.632110595703125e-05, 'loss_3': -16.36498260498047, 'loss_4': 0.5098477005958557, 'epoch': 25.88}
{'loss': 0.0046, 'grad_norm': 4.641608238220215, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.002835263963788748, 'loss_2': 0.0017375946044921875, 'loss_3': -16.42620086669922, 'loss_4': -0.2085062861442566, 'epoch': 25.89}
{'loss': 0.0111, 'grad_norm': 4.909450531005859, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.006143319420516491, 'loss_2': 0.0049591064453125, 'loss_3': -16.304248809814453, 'loss_4': 0.23484094440937042, 'epoch': 25.9}
{'loss': 0.0068, 'grad_norm': 4.79828405380249, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.0035139690153300762, 'loss_2': 0.0032367706298828125, 'loss_3': -16.279911041259766, 'loss_4': 0.26649245619773865, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 14:10:06,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:06,487 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:50:00<12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:13,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011354126036167145, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008067548274993896, 'eval_loss_2': 0.0032865777611732483, 'eval_loss_3': -18.112293243408203, 'eval_loss_4': 0.20503324270248413, 'epoch': 25.9}
{'loss': 0.0174, 'grad_norm': 9.524596214294434, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.013788445852696896, 'loss_2': 0.003627777099609375, 'loss_3': -16.531513214111328, 'loss_4': 0.24323108792304993, 'epoch': 25.91}
{'loss': 0.0107, 'grad_norm': 5.559482574462891, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.008602294139564037, 'loss_2': 0.0021114349365234375, 'loss_3': -16.40325927734375, 'loss_4': 0.5786847472190857, 'epoch': 25.91}
{'loss': 0.0051, 'grad_norm': 4.185423374176025, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.003551816800609231, 'loss_2': 0.0015430450439453125, 'loss_3': -16.4532470703125, 'loss_4': 0.8425627946853638, 'epoch': 25.92}
{'loss': 0.0181, 'grad_norm': 8.692031860351562, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.016274327412247658, 'loss_2': 0.0018367767333984375, 'loss_3': -16.49339485168457, 'loss_4': 0.14898976683616638, 'epoch': 25.92}
{'loss': 0.0062, 'grad_norm': 4.637781143188477, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.004981559235602617, 'loss_2': 0.0011997222900390625, 'loss_3': -16.44989013671875, 'loss_4': 0.2852059006690979, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 14:10:13,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:13,820 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:50:08<11:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:21,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011743109673261642, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.102, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00824130792170763, 'eval_loss_2': 0.003501802682876587, 'eval_loss_3': -18.114295959472656, 'eval_loss_4': 0.18072609603405, 'epoch': 25.93}
{'loss': 0.0134, 'grad_norm': 7.6928019523620605, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.012186811305582523, 'loss_2': 0.0011816024780273438, 'loss_3': -16.412803649902344, 'loss_4': 0.44148319959640503, 'epoch': 25.94}
{'loss': 0.0058, 'grad_norm': 4.63407564163208, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.005728929303586483, 'loss_2': 6.80685043334961e-05, 'loss_3': -16.485057830810547, 'loss_4': 0.4038272500038147, 'epoch': 25.94}
{'loss': 0.0044, 'grad_norm': 4.584726810455322, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.004332591313868761, 'loss_2': 2.0503997802734375e-05, 'loss_3': -16.51464080810547, 'loss_4': 0.23561686277389526, 'epoch': 25.95}
{'loss': 0.0096, 'grad_norm': 6.081768989562988, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.007185573223978281, 'loss_2': 0.002407073974609375, 'loss_3': -16.42609977722168, 'loss_4': 0.26710134744644165, 'epoch': 25.95}
{'loss': 0.0059, 'grad_norm': 4.775996685028076, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.0036776394117623568, 'loss_2': 0.002262115478515625, 'loss_3': -16.38105583190918, 'loss_4': 0.5061452388763428, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 14:10:21,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:21,136 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:15<11:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:28,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011829757131636143, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.394, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.008225352503359318, 'eval_loss_2': 0.003604404628276825, 'eval_loss_3': -18.119382858276367, 'eval_loss_4': 0.16107359528541565, 'epoch': 25.96}
{'loss': 0.0047, 'grad_norm': 4.390342712402344, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.003104453906416893, 'loss_2': 0.0015583038330078125, 'loss_3': -16.328920364379883, 'loss_4': -0.10686524212360382, 'epoch': 25.97}
{'loss': 0.0208, 'grad_norm': 14.575606346130371, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.02062094211578369, 'loss_2': 0.00018525123596191406, 'loss_3': -16.37760353088379, 'loss_4': 0.2082476019859314, 'epoch': 25.97}
{'loss': 0.0078, 'grad_norm': 4.610720634460449, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.005453910678625107, 'loss_2': 0.0023956298828125, 'loss_3': -16.260812759399414, 'loss_4': 0.04489029198884964, 'epoch': 25.98}
{'loss': 0.0051, 'grad_norm': 4.751148223876953, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.0037730520125478506, 'loss_2': 0.0013370513916015625, 'loss_3': -16.510019302368164, 'loss_4': 0.11602046340703964, 'epoch': 25.98}
{'loss': 0.0076, 'grad_norm': 4.944028377532959, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.003368054749444127, 'loss_2': 0.00420379638671875, 'loss_3': -16.516454696655273, 'loss_4': 0.1671132892370224, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 14:10:28,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:28,453 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:22<11:29,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 14:10:35,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011562341824173927, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.03, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007790421601384878, 'eval_loss_2': 0.003771919757127762, 'eval_loss_3': -18.121070861816406, 'eval_loss_4': 0.16879408061504364, 'epoch': 25.99}
{'loss': 0.0153, 'grad_norm': 5.362183570861816, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.00790661945939064, 'loss_2': 0.00743865966796875, 'loss_3': -16.263200759887695, 'loss_4': 0.2541225552558899, 'epoch': 25.99}
{'loss': 0.0131, 'grad_norm': 6.339978218078613, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.0015501859597861767, 'loss_2': 0.01153564453125, 'loss_3': -16.40515899658203, 'loss_4': 0.48212170600891113, 'epoch': 26.0}
{'loss': 0.0062, 'grad_norm': 4.449294567108154, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.0019367343047633767, 'loss_2': 0.0042572021484375, 'loss_3': -16.480390548706055, 'loss_4': 0.7183599472045898, 'epoch': 26.01}
{'loss': 0.0156, 'grad_norm': 10.354251861572266, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.012502038851380348, 'loss_2': 0.0030975341796875, 'loss_3': -16.53291130065918, 'loss_4': 0.05376170575618744, 'epoch': 26.01}
{'loss': 0.0827, 'grad_norm': 18.95781707763672, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.07107281684875488, 'loss_2': 0.01161956787109375, 'loss_3': -16.43480682373047, 'loss_4': 0.44342371821403503, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 14:10:35,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:35,474 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:29<11:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:42,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011797497048974037, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007910797372460365, 'eval_loss_2': 0.003886699676513672, 'eval_loss_3': -18.1149959564209, 'eval_loss_4': 0.2067120224237442, 'epoch': 26.02}
{'loss': 0.0053, 'grad_norm': 4.7263946533203125, 'learning_rate': 4e-06, 'loss_1': 0.005194493569433689, 'loss_2': 9.644031524658203e-05, 'loss_3': -16.399185180664062, 'loss_4': -0.28994959592819214, 'epoch': 26.02}
{'loss': 0.0059, 'grad_norm': 4.62088680267334, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.004689033608883619, 'loss_2': 0.0012149810791015625, 'loss_3': -16.46590805053711, 'loss_4': 0.49908649921417236, 'epoch': 26.03}
{'loss': 0.0071, 'grad_norm': 5.189641952514648, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.0039028855971992016, 'loss_2': 0.00316619873046875, 'loss_3': -16.540042877197266, 'loss_4': -0.035589367151260376, 'epoch': 26.03}
{'loss': 0.0073, 'grad_norm': 4.270832061767578, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.002537627937272191, 'loss_2': 0.004730224609375, 'loss_3': -16.427658081054688, 'loss_4': 0.6488866209983826, 'epoch': 26.04}
{'loss': 0.0155, 'grad_norm': 6.885372161865234, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.00869819987565279, 'loss_2': 0.006778717041015625, 'loss_3': -16.295480728149414, 'loss_4': 0.19575488567352295, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 14:10:42,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:42,800 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:37<11:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:50,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011233754456043243, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.924, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.007718869484961033, 'eval_loss_2': 0.003514885902404785, 'eval_loss_3': -18.11273193359375, 'eval_loss_4': 0.2396550327539444, 'epoch': 26.05}
{'loss': 0.0262, 'grad_norm': 22.175811767578125, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.02299642004072666, 'loss_2': 0.0032100677490234375, 'loss_3': -16.403457641601562, 'loss_4': -0.20085611939430237, 'epoch': 26.05}
{'loss': 0.0703, 'grad_norm': 8.378418922424316, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.06344036757946014, 'loss_2': 0.0068511962890625, 'loss_3': -16.361717224121094, 'loss_4': 1.1718950271606445, 'epoch': 26.06}
{'loss': 0.0126, 'grad_norm': 9.07601547241211, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.01206919364631176, 'loss_2': 0.0005021095275878906, 'loss_3': -16.572887420654297, 'loss_4': 0.77347731590271, 'epoch': 26.06}
{'loss': 0.0071, 'grad_norm': 4.79371976852417, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.005659818649291992, 'loss_2': 0.0014162063598632812, 'loss_3': -16.320669174194336, 'loss_4': 0.20785169303417206, 'epoch': 26.07}
{'loss': 0.0035, 'grad_norm': 4.5810933113098145, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.002840361325070262, 'loss_2': 0.000698089599609375, 'loss_3': -16.297496795654297, 'loss_4': 0.1971854567527771, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 14:10:50,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:50,131 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:44<11:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:57,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010729661211371422, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.104, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007461387664079666, 'eval_loss_2': 0.0032682716846466064, 'eval_loss_3': -18.116899490356445, 'eval_loss_4': 0.25113365054130554, 'epoch': 26.08}
{'loss': 0.0053, 'grad_norm': 4.81981897354126, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.0032580592669546604, 'loss_2': 0.0020751953125, 'loss_3': -16.419174194335938, 'loss_4': -0.2602221965789795, 'epoch': 26.08}
{'loss': 0.0091, 'grad_norm': 5.203360080718994, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.00675178412348032, 'loss_2': 0.002353668212890625, 'loss_3': -16.480865478515625, 'loss_4': 0.16667574644088745, 'epoch': 26.09}
{'loss': 0.0081, 'grad_norm': 4.698877811431885, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.007762952242046595, 'loss_2': 0.000331878662109375, 'loss_3': -16.480688095092773, 'loss_4': 0.3329828977584839, 'epoch': 26.09}
{'loss': 0.0066, 'grad_norm': 4.573389530181885, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.004941171035170555, 'loss_2': 0.0016384124755859375, 'loss_3': -16.597009658813477, 'loss_4': 0.5797253251075745, 'epoch': 26.1}
{'loss': 0.0051, 'grad_norm': 4.721435546875, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.0026847729459404945, 'loss_2': 0.00240325927734375, 'loss_3': -16.526100158691406, 'loss_4': -0.23844411969184875, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 14:10:57,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:57,457 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:51<11:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:04,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010990260168910027, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007548271678388119, 'eval_loss_2': 0.0034419894218444824, 'eval_loss_3': -18.12411880493164, 'eval_loss_4': 0.2301851511001587, 'epoch': 26.1}
{'loss': 0.0114, 'grad_norm': 7.156155586242676, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.005340967793017626, 'loss_2': 0.0060577392578125, 'loss_3': -16.32103729248047, 'loss_4': 0.0778329074382782, 'epoch': 26.11}
{'loss': 0.0024, 'grad_norm': 4.329245567321777, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.002073834417387843, 'loss_2': 0.0003705024719238281, 'loss_3': -16.50040626525879, 'loss_4': 0.5793539881706238, 'epoch': 26.12}
{'loss': 0.0095, 'grad_norm': 5.441119194030762, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.004948989022523165, 'loss_2': 0.0045013427734375, 'loss_3': -16.460281372070312, 'loss_4': 0.19875077903270721, 'epoch': 26.12}
{'loss': 0.0053, 'grad_norm': 4.372042655944824, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.003697737120091915, 'loss_2': 0.0016193389892578125, 'loss_3': -16.524105072021484, 'loss_4': 0.2823641896247864, 'epoch': 26.13}
{'loss': 0.0057, 'grad_norm': 4.5569682121276855, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.0038193282671272755, 'loss_2': 0.0019207000732421875, 'loss_3': -16.320539474487305, 'loss_4': -0.14405575394630432, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 14:11:04,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:04,793 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:59<11:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:12,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011075388640165329, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00758359907194972, 'eval_loss_2': 0.0034917891025543213, 'eval_loss_3': -18.12578582763672, 'eval_loss_4': 0.22431978583335876, 'epoch': 26.13}
{'loss': 0.0135, 'grad_norm': 5.52680778503418, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.009572760201990604, 'loss_2': 0.0038928985595703125, 'loss_3': -16.272647857666016, 'loss_4': 0.23158428072929382, 'epoch': 26.14}
{'loss': 0.0107, 'grad_norm': 8.536201477050781, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.008893460035324097, 'loss_2': 0.0018405914306640625, 'loss_3': -16.497718811035156, 'loss_4': 0.3119578957557678, 'epoch': 26.15}
{'loss': 0.0044, 'grad_norm': 5.027349948883057, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.0027718525379896164, 'loss_2': 0.0016002655029296875, 'loss_3': -16.420764923095703, 'loss_4': -0.027118824422359467, 'epoch': 26.15}
{'loss': 0.0049, 'grad_norm': 4.612070560455322, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.004669209010899067, 'loss_2': 0.0002079010009765625, 'loss_3': -16.542198181152344, 'loss_4': 0.682553768157959, 'epoch': 26.16}
{'loss': 0.0116, 'grad_norm': 4.135588645935059, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.004674253519624472, 'loss_2': 0.00690460205078125, 'loss_3': -16.442039489746094, 'loss_4': -0.42267686128616333, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 14:11:12,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:12,123 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:51:06<11:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:19,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011426365002989769, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.105, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0076531535014510155, 'eval_loss_2': 0.003773212432861328, 'eval_loss_3': -18.122821807861328, 'eval_loss_4': 0.24415037035942078, 'epoch': 26.16}
{'loss': 0.0042, 'grad_norm': 4.8434553146362305, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.00377341965213418, 'loss_2': 0.0004298686981201172, 'loss_3': -16.716917037963867, 'loss_4': 0.4875768721103668, 'epoch': 26.17}
{'loss': 0.0251, 'grad_norm': 11.094943046569824, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.02028820663690567, 'loss_2': 0.00478363037109375, 'loss_3': -16.385597229003906, 'loss_4': 0.02591761201620102, 'epoch': 26.17}
{'loss': 0.0087, 'grad_norm': 4.619753360748291, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.004453176632523537, 'loss_2': 0.00420379638671875, 'loss_3': -16.4698543548584, 'loss_4': 0.29245442152023315, 'epoch': 26.18}
{'loss': 0.0097, 'grad_norm': 8.691729545593262, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.008866881020367146, 'loss_2': 0.0008764266967773438, 'loss_3': -16.452281951904297, 'loss_4': 0.16621577739715576, 'epoch': 26.19}
{'loss': 0.0043, 'grad_norm': 4.307776927947998, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.0031342513393610716, 'loss_2': 0.0011444091796875, 'loss_3': -16.42156982421875, 'loss_4': 0.4997098445892334, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 14:11:19,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:19,450 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:51:13<11:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:26,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011260630562901497, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.076, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007600876037031412, 'eval_loss_2': 0.003659754991531372, 'eval_loss_3': -18.118160247802734, 'eval_loss_4': 0.2742322087287903, 'epoch': 26.19}
{'loss': 0.0067, 'grad_norm': 4.4802350997924805, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.005169217009097338, 'loss_2': 0.001529693603515625, 'loss_3': -16.442827224731445, 'loss_4': 0.24920488893985748, 'epoch': 26.2}
{'loss': 0.0052, 'grad_norm': 4.913304328918457, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.0023849760182201862, 'loss_2': 0.00283050537109375, 'loss_3': -16.41252899169922, 'loss_4': 0.15883788466453552, 'epoch': 26.2}
{'loss': 0.0098, 'grad_norm': 4.28138542175293, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.00368371675722301, 'loss_2': 0.006076812744140625, 'loss_3': -16.50801658630371, 'loss_4': 0.41594183444976807, 'epoch': 26.21}
{'loss': 0.0126, 'grad_norm': 5.9008708000183105, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.007703830022364855, 'loss_2': 0.00487518310546875, 'loss_3': -16.41888427734375, 'loss_4': 0.18440306186676025, 'epoch': 26.22}
{'loss': 0.0129, 'grad_norm': 4.450027942657471, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.006450730841606855, 'loss_2': 0.00649261474609375, 'loss_3': -16.485504150390625, 'loss_4': 0.26333698630332947, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 14:11:26,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:26,779 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:21<11:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:34,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011108567006886005, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.054, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007520068436861038, 'eval_loss_2': 0.0035884976387023926, 'eval_loss_3': -18.119518280029297, 'eval_loss_4': 0.2463172823190689, 'epoch': 26.22}
{'loss': 0.0109, 'grad_norm': 6.082854270935059, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.009988564066588879, 'loss_2': 0.000926971435546875, 'loss_3': -16.389162063598633, 'loss_4': 0.7334311008453369, 'epoch': 26.23}
{'loss': 0.005, 'grad_norm': 5.280923366546631, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.002392592141404748, 'loss_2': 0.002590179443359375, 'loss_3': -16.625141143798828, 'loss_4': -0.026188470423221588, 'epoch': 26.23}
{'loss': 0.008, 'grad_norm': 4.679351329803467, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.005663533229380846, 'loss_2': 0.002315521240234375, 'loss_3': -16.591514587402344, 'loss_4': 0.1811840534210205, 'epoch': 26.24}
{'loss': 0.0037, 'grad_norm': 4.876577854156494, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.0030413116328418255, 'loss_2': 0.0006628036499023438, 'loss_3': -16.310047149658203, 'loss_4': 0.26122766733169556, 'epoch': 26.24}
{'loss': 0.0073, 'grad_norm': 4.340181350708008, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.0034504772629588842, 'loss_2': 0.003871917724609375, 'loss_3': -16.50776481628418, 'loss_4': 0.2760888934135437, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 14:11:34,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:34,108 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:28<11:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:41,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010875639505684376, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00727054150775075, 'eval_loss_2': 0.003605097532272339, 'eval_loss_3': -18.13378143310547, 'eval_loss_4': 0.16221433877944946, 'epoch': 26.25}
{'loss': 0.0182, 'grad_norm': 5.817333698272705, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.008821073919534683, 'loss_2': 0.0093841552734375, 'loss_3': -16.19448471069336, 'loss_4': 0.056237250566482544, 'epoch': 26.26}
{'loss': 0.0081, 'grad_norm': 4.522608757019043, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.0031333137303590775, 'loss_2': 0.00496673583984375, 'loss_3': -16.415813446044922, 'loss_4': -0.06926426291465759, 'epoch': 26.26}
{'loss': 0.0218, 'grad_norm': 14.755449295043945, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.018060822039842606, 'loss_2': 0.0037841796875, 'loss_3': -16.457630157470703, 'loss_4': 0.6750280857086182, 'epoch': 26.27}
{'loss': 0.0061, 'grad_norm': 5.364893913269043, 'learning_rate': 3.75e-06, 'loss_1': 0.004975761286914349, 'loss_2': 0.0011606216430664062, 'loss_3': -16.408618927001953, 'loss_4': -0.22936546802520752, 'epoch': 26.27}
{'loss': 0.0102, 'grad_norm': 4.692234039306641, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.003716871375218034, 'loss_2': 0.006481170654296875, 'loss_3': -16.34966278076172, 'loss_4': 0.3539643883705139, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 14:11:41,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:41,432 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:35<10:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:48,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01085812970995903, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.143, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007676069159060717, 'eval_loss_2': 0.003182061016559601, 'eval_loss_3': -18.139421463012695, 'eval_loss_4': 0.07702258229255676, 'epoch': 26.28}
{'loss': 0.0092, 'grad_norm': 5.87096643447876, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.008212932385504246, 'loss_2': 0.001026153564453125, 'loss_3': -16.381980895996094, 'loss_4': 0.016163982450962067, 'epoch': 26.28}
{'loss': 0.0059, 'grad_norm': 4.721297264099121, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.003173175733536482, 'loss_2': 0.0027618408203125, 'loss_3': -16.541723251342773, 'loss_4': -0.31951016187667847, 'epoch': 26.29}
{'loss': 0.0708, 'grad_norm': 6.039519309997559, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.06939807534217834, 'loss_2': 0.0013904571533203125, 'loss_3': -16.487030029296875, 'loss_4': -0.13508062064647675, 'epoch': 26.3}
{'loss': 0.0054, 'grad_norm': 4.875282287597656, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.0028354283422231674, 'loss_2': 0.002567291259765625, 'loss_3': -16.32503318786621, 'loss_4': -0.03326040506362915, 'epoch': 26.3}
{'loss': 0.0028, 'grad_norm': 4.420591354370117, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.002622767584398389, 'loss_2': 0.0001404285430908203, 'loss_3': -16.389236450195312, 'loss_4': -0.0029838085174560547, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 14:11:48,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:48,757 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:43<10:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:56,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010891620069742203, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.014, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008012395352125168, 'eval_loss_2': 0.002879224717617035, 'eval_loss_3': -18.14154815673828, 'eval_loss_4': 0.04196326807141304, 'epoch': 26.31}
{'loss': 0.0092, 'grad_norm': 5.652907848358154, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.008976414799690247, 'loss_2': 0.00022530555725097656, 'loss_3': -16.480384826660156, 'loss_4': -0.13495270907878876, 'epoch': 26.31}
{'loss': 0.0135, 'grad_norm': 6.104011058807373, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.011289743706583977, 'loss_2': 0.002170562744140625, 'loss_3': -16.359296798706055, 'loss_4': 0.1776677966117859, 'epoch': 26.32}
{'loss': 0.0135, 'grad_norm': 4.838104724884033, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.004482060205191374, 'loss_2': 0.009063720703125, 'loss_3': -16.536039352416992, 'loss_4': 0.20894856750965118, 'epoch': 26.33}
{'loss': 0.0063, 'grad_norm': 4.708616733551025, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.0041520497761666775, 'loss_2': 0.00215911865234375, 'loss_3': -16.42098617553711, 'loss_4': 0.1244564801454544, 'epoch': 26.33}
{'loss': 0.0069, 'grad_norm': 5.674139022827148, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.00616504717618227, 'loss_2': 0.00070953369140625, 'loss_3': -16.453584671020508, 'loss_4': 0.18333066999912262, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 14:11:56,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:56,089 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:50<10:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:03,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010679623112082481, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.342, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007949966005980968, 'eval_loss_2': 0.0027296580374240875, 'eval_loss_3': -18.144638061523438, 'eval_loss_4': -0.0032788775861263275, 'epoch': 26.34}
{'loss': 0.0039, 'grad_norm': 8.011153221130371, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0021784319542348385, 'loss_2': 0.0017251968383789062, 'loss_3': -16.56180191040039, 'loss_4': 0.09349077939987183, 'epoch': 26.34}
{'loss': 0.0066, 'grad_norm': 4.200049877166748, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.003163868561387062, 'loss_2': 0.003421783447265625, 'loss_3': -16.464149475097656, 'loss_4': -0.00797659158706665, 'epoch': 26.35}
{'loss': 0.0111, 'grad_norm': 6.4476189613342285, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.010196216404438019, 'loss_2': 0.0008897781372070312, 'loss_3': -16.312152862548828, 'loss_4': -0.008169025182723999, 'epoch': 26.35}
{'loss': 0.0111, 'grad_norm': 7.0647053718566895, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.007479359395802021, 'loss_2': 0.0035858154296875, 'loss_3': -16.27290916442871, 'loss_4': 0.24949030578136444, 'epoch': 26.36}
{'loss': 0.0056, 'grad_norm': 4.491601943969727, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.004924990702420473, 'loss_2': 0.0006570816040039062, 'loss_3': -16.482295989990234, 'loss_4': 0.1942213475704193, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 14:12:03,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:03,414 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:57<10:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:10,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010938644409179688, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008010385558009148, 'eval_loss_2': 0.0029282569885253906, 'eval_loss_3': -18.135005950927734, 'eval_loss_4': -0.029054079204797745, 'epoch': 26.37}
{'loss': 0.0094, 'grad_norm': 5.306286334991455, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.008189628832042217, 'loss_2': 0.00124359130859375, 'loss_3': -16.422100067138672, 'loss_4': 0.15418580174446106, 'epoch': 26.37}
{'loss': 0.0051, 'grad_norm': 4.610161781311035, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.003393667982891202, 'loss_2': 0.0016651153564453125, 'loss_3': -16.414779663085938, 'loss_4': 0.08549362421035767, 'epoch': 26.38}
{'loss': 0.0121, 'grad_norm': 5.563305854797363, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.006801221519708633, 'loss_2': 0.0052490234375, 'loss_3': -16.229103088378906, 'loss_4': -0.16245462000370026, 'epoch': 26.38}
{'loss': 0.013, 'grad_norm': 5.199375629425049, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.006801925599575043, 'loss_2': 0.006168365478515625, 'loss_3': -16.3959903717041, 'loss_4': -0.08828923106193542, 'epoch': 26.39}
{'loss': 0.0124, 'grad_norm': 5.362951755523682, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.005817646160721779, 'loss_2': 0.0065765380859375, 'loss_3': -16.380170822143555, 'loss_4': -0.017856553196907043, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 14:12:10,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:10,755 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:52:05<10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:18,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010649462230503559, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007680435664951801, 'eval_loss_2': 0.002969026565551758, 'eval_loss_3': -18.134424209594727, 'eval_loss_4': -0.027130676433444023, 'epoch': 26.4}
{'loss': 0.0032, 'grad_norm': 4.722273826599121, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.002014707075431943, 'loss_2': 0.001163482666015625, 'loss_3': -16.46474838256836, 'loss_4': -0.011469244956970215, 'epoch': 26.4}
{'loss': 0.0155, 'grad_norm': 8.981428146362305, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.010631945915520191, 'loss_2': 0.0048370361328125, 'loss_3': -16.387678146362305, 'loss_4': 0.1499345898628235, 'epoch': 26.41}
{'loss': 0.0092, 'grad_norm': 7.105276107788086, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.008574878796935081, 'loss_2': 0.0006246566772460938, 'loss_3': -16.467945098876953, 'loss_4': -0.25360673666000366, 'epoch': 26.41}
{'loss': 0.0241, 'grad_norm': 17.197324752807617, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.0199192576110363, 'loss_2': 0.00415802001953125, 'loss_3': -16.341524124145508, 'loss_4': 0.05004168301820755, 'epoch': 26.42}
{'loss': 0.0085, 'grad_norm': 4.452805519104004, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0020548910833895206, 'loss_2': 0.0064544677734375, 'loss_3': -16.40645408630371, 'loss_4': 0.16329316794872284, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 14:12:18,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:18,103 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:52:08<10:38,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:12:21,893 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545
[INFO|configuration_utils.py:420] 2025-01-21 14:12:21,894 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545/config.json                                                                            
{'eval_loss': 0.010423422791063786, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.294, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00755348103120923, 'eval_loss_2': 0.002869941294193268, 'eval_loss_3': -18.139896392822266, 'eval_loss_4': -0.04261290282011032, 'epoch': 26.42}
[INFO|modeling_utils.py:2988] 2025-01-21 14:12:22,383 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:12:22,385 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:12:22,385 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:12:23,417 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4445] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:14<11:42,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 14:12:27,034 >>
{'loss': 0.0068, 'grad_norm': 5.119683742523193, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.006212575826793909, 'loss_2': 0.0005679130554199219, 'loss_3': -16.361312866210938, 'loss_4': 0.09833617508411407, 'epoch': 26.43}
{'loss': 0.0032, 'grad_norm': 4.349441051483154, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.0026475873310118914, 'loss_2': 0.0005893707275390625, 'loss_3': -16.251415252685547, 'loss_4': 0.003174133598804474, 'epoch': 26.44}
{'loss': 0.012, 'grad_norm': 7.790167808532715, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.011523086577653885, 'loss_2': 0.0004525184631347656, 'loss_3': -16.541345596313477, 'loss_4': 0.020186912268400192, 'epoch': 26.44}
{'loss': 0.0065, 'grad_norm': 4.469496726989746, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.00462019769474864, 'loss_2': 0.001880645751953125, 'loss_3': -16.358749389648438, 'loss_4': 0.25418326258659363, 'epoch': 26.45}
{'loss': 0.0075, 'grad_norm': 4.772940158843994, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.003238819306716323, 'loss_2': 0.0042877197265625, 'loss_3': -16.675872802734375, 'loss_4': 0.12034231424331665, 'epoch': 26.45}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:12:27,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:27,034 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:18<11:42,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 14:12:31,084 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550
[INFO|configuration_utils.py:420] 2025-01-21 14:12:31,085 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550/config.json                                                                            
{'eval_loss': 0.010343327187001705, 'eval_runtime': 4.0492, 'eval_samples_per_second': 252.888, 'eval_steps_per_second': 3.951, 'eval_loss_1': 0.007260351441800594, 'eval_loss_2': 0.003082975745201111, 'eval_loss_3': -18.131778717041016, 'eval_loss_4': -0.08510222285985947, 'epoch': 26.45}
[INFO|modeling_utils.py:2988] 2025-01-21 14:12:31,580 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:12:31,581 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:12:31,582 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:12:32,632 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4545] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:23<12:00,  1.19s/it][INFO|trainer.py:4226] 2025-01-21 14:12:36,253 >>
{'loss': 0.0058, 'grad_norm': 4.872326850891113, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.0028559574857354164, 'loss_2': 0.00290679931640625, 'loss_3': -16.61740493774414, 'loss_4': 0.16398367285728455, 'epoch': 26.46}
{'loss': 0.0071, 'grad_norm': 5.360356330871582, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0065147727727890015, 'loss_2': 0.000583648681640625, 'loss_3': -16.373029708862305, 'loss_4': -0.2677275538444519, 'epoch': 26.47}
{'loss': 0.0064, 'grad_norm': 5.189695835113525, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.006180034950375557, 'loss_2': 0.0001932382583618164, 'loss_3': -16.260841369628906, 'loss_4': 0.1311260610818863, 'epoch': 26.47}
{'loss': 0.0052, 'grad_norm': 4.540599346160889, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.0049375612288713455, 'loss_2': 0.0002989768981933594, 'loss_3': -16.353267669677734, 'loss_4': -0.39727404713630676, 'epoch': 26.48}
{'loss': 0.0077, 'grad_norm': 5.621840476989746, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.005880273412913084, 'loss_2': 0.001850128173828125, 'loss_3': -16.34653091430664, 'loss_4': 0.09383784234523773, 'epoch': 26.48}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:12:36,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:36,253 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:27<12:00,  1.19s/it][INFO|trainer.py:3910] 2025-01-21 14:12:40,048 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555
[INFO|configuration_utils.py:420] 2025-01-21 14:12:40,049 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555/config.json                                                                            
{'eval_loss': 0.010052996687591076, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.94, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00700859259814024, 'eval_loss_2': 0.003044404089450836, 'eval_loss_3': -18.133731842041016, 'eval_loss_4': -0.1286712884902954, 'epoch': 26.48}
[INFO|modeling_utils.py:2988] 2025-01-21 14:12:40,538 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:12:40,539 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:12:40,539 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:12:41,580 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4550] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:32<11:46,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 14:12:45,205 >>
{'loss': 0.0078, 'grad_norm': 5.062754154205322, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.004234248772263527, 'loss_2': 0.003566741943359375, 'loss_3': -16.453813552856445, 'loss_4': 0.1674465537071228, 'epoch': 26.49}
{'loss': 0.0064, 'grad_norm': 5.262658596038818, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.005115028470754623, 'loss_2': 0.0012378692626953125, 'loss_3': -16.417041778564453, 'loss_4': -0.08789345622062683, 'epoch': 26.49}
{'loss': 0.0112, 'grad_norm': 4.590656280517578, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.004897748585790396, 'loss_2': 0.0062713623046875, 'loss_3': -16.437118530273438, 'loss_4': 0.11471578478813171, 'epoch': 26.5}
{'loss': 0.0088, 'grad_norm': 4.178379535675049, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.0051175975240767, 'loss_2': 0.003650665283203125, 'loss_3': -16.310104370117188, 'loss_4': -0.1005389392375946, 'epoch': 26.51}
{'loss': 0.0036, 'grad_norm': 4.562511920928955, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.0031362278386950493, 'loss_2': 0.00043964385986328125, 'loss_3': -16.410297393798828, 'loss_4': 0.016466841101646423, 'epoch': 26.51}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:12:45,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:45,205 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:39<10:31,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:12:52,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010176979005336761, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007065583020448685, 'eval_loss_2': 0.0031113959848880768, 'eval_loss_3': -18.1315975189209, 'eval_loss_4': -0.15459980070590973, 'epoch': 26.51}
{'loss': 0.0091, 'grad_norm': 5.723081588745117, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.007365191355347633, 'loss_2': 0.0017118453979492188, 'loss_3': -16.42099380493164, 'loss_4': 0.1480797529220581, 'epoch': 26.52}
{'loss': 0.0159, 'grad_norm': 4.479006767272949, 'learning_rate': 3.5e-06, 'loss_1': 0.004530278500169516, 'loss_2': 0.0113983154296875, 'loss_3': -16.296913146972656, 'loss_4': -0.07633360475301743, 'epoch': 26.52}
{'loss': 0.0067, 'grad_norm': 4.858047962188721, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.00485983258113265, 'loss_2': 0.0018138885498046875, 'loss_3': -16.512760162353516, 'loss_4': 0.40085750818252563, 'epoch': 26.53}
{'loss': 0.0041, 'grad_norm': 4.469661235809326, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.003666952485218644, 'loss_2': 0.00046944618225097656, 'loss_3': -16.27991485595703, 'loss_4': -0.0878940224647522, 'epoch': 26.53}
{'loss': 0.0049, 'grad_norm': 4.469781398773193, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.0030896146781742573, 'loss_2': 0.0018301010131835938, 'loss_3': -16.399688720703125, 'loss_4': -0.06280981004238129, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 14:12:52,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:52,534 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:46<10:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:59,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010424526408314705, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.395, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007063941098749638, 'eval_loss_2': 0.0033605843782424927, 'eval_loss_3': -18.13915252685547, 'eval_loss_4': -0.21064795553684235, 'epoch': 26.54}
{'loss': 0.0076, 'grad_norm': 5.096798419952393, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.005513662938028574, 'loss_2': 0.0020751953125, 'loss_3': -16.3951473236084, 'loss_4': 0.033646970987319946, 'epoch': 26.55}
{'loss': 0.0093, 'grad_norm': 4.994244575500488, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.006438643671572208, 'loss_2': 0.002849578857421875, 'loss_3': -16.42320442199707, 'loss_4': -0.7859839200973511, 'epoch': 26.55}
{'loss': 0.01, 'grad_norm': 4.574113845825195, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.004169750493019819, 'loss_2': 0.005825042724609375, 'loss_3': -16.401535034179688, 'loss_4': 0.05131729692220688, 'epoch': 26.56}
{'loss': 0.0082, 'grad_norm': 4.245076656341553, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.002077386947348714, 'loss_2': 0.006072998046875, 'loss_3': -16.39154624938965, 'loss_4': 0.220242440700531, 'epoch': 26.56}
{'loss': 0.0075, 'grad_norm': 6.556617736816406, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.006031844764947891, 'loss_2': 0.00142669677734375, 'loss_3': -16.59209442138672, 'loss_4': -0.2646721303462982, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 14:12:59,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:59,871 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:54<10:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:07,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010386321693658829, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007035065907984972, 'eval_loss_2': 0.003351256251335144, 'eval_loss_3': -18.137271881103516, 'eval_loss_4': -0.22890201210975647, 'epoch': 26.57}
{'loss': 0.0085, 'grad_norm': 5.29754114151001, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.006173142697662115, 'loss_2': 0.002346038818359375, 'loss_3': -16.527353286743164, 'loss_4': -0.5657312870025635, 'epoch': 26.58}
{'loss': 0.046, 'grad_norm': 18.278987884521484, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.04309660941362381, 'loss_2': 0.0028972625732421875, 'loss_3': -16.421194076538086, 'loss_4': 0.03232503682374954, 'epoch': 26.58}
{'loss': 0.0087, 'grad_norm': 7.529723167419434, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.005899416748434305, 'loss_2': 0.002849578857421875, 'loss_3': -16.132495880126953, 'loss_4': -0.015404768288135529, 'epoch': 26.59}
{'loss': 0.0189, 'grad_norm': 13.716886520385742, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.013890826143324375, 'loss_2': 0.005001068115234375, 'loss_3': -16.46149444580078, 'loss_4': 0.11125856637954712, 'epoch': 26.59}
{'loss': 0.0193, 'grad_norm': 10.530406951904297, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.016136592254042625, 'loss_2': 0.003204345703125, 'loss_3': -16.418228149414062, 'loss_4': -0.6595680713653564, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 14:13:07,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:07,201 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:53:01<10:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:14,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010557467117905617, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.125, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007025474216789007, 'eval_loss_2': 0.0035319924354553223, 'eval_loss_3': -18.145076751708984, 'eval_loss_4': -0.2500680088996887, 'epoch': 26.6}
{'loss': 0.0047, 'grad_norm': 4.486661434173584, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.003348726313561201, 'loss_2': 0.0013790130615234375, 'loss_3': -16.480287551879883, 'loss_4': 0.00936184823513031, 'epoch': 26.6}
{'loss': 0.0113, 'grad_norm': 4.611261367797852, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.005371431354433298, 'loss_2': 0.005947113037109375, 'loss_3': -16.34626007080078, 'loss_4': -0.09251102805137634, 'epoch': 26.61}
{'loss': 0.0101, 'grad_norm': 5.193736553192139, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.008276689797639847, 'loss_2': 0.0018320083618164062, 'loss_3': -16.266921997070312, 'loss_4': -0.20854006707668304, 'epoch': 26.62}
{'loss': 0.0101, 'grad_norm': 5.463144779205322, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.007927552796900272, 'loss_2': 0.002166748046875, 'loss_3': -16.414020538330078, 'loss_4': -0.06292485445737839, 'epoch': 26.62}
{'loss': 0.0062, 'grad_norm': 4.739974021911621, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.00396181084215641, 'loss_2': 0.00220489501953125, 'loss_3': -16.131710052490234, 'loss_4': -0.4566941261291504, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 14:13:14,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:14,523 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:53:08<09:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:21,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01029990054666996, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.011, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.006877864245325327, 'eval_loss_2': 0.0034220367670059204, 'eval_loss_3': -18.153701782226562, 'eval_loss_4': -0.24200981855392456, 'epoch': 26.63}
{'loss': 0.0115, 'grad_norm': 6.386641979217529, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.008328564465045929, 'loss_2': 0.003147125244140625, 'loss_3': -16.45409393310547, 'loss_4': -0.2509255111217499, 'epoch': 26.63}
{'loss': 0.012, 'grad_norm': 4.636273384094238, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.004091068170964718, 'loss_2': 0.00795745849609375, 'loss_3': -16.72822380065918, 'loss_4': 0.048183150589466095, 'epoch': 26.64}
{'loss': 0.0056, 'grad_norm': 5.123493194580078, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.005254723131656647, 'loss_2': 0.00037169456481933594, 'loss_3': -16.278139114379883, 'loss_4': -0.38758385181427, 'epoch': 26.65}
{'loss': 0.009, 'grad_norm': 4.779134273529053, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.0032307300716638565, 'loss_2': 0.00577545166015625, 'loss_3': -16.411291122436523, 'loss_4': -0.03345447778701782, 'epoch': 26.65}
{'loss': 0.0142, 'grad_norm': 8.308406829833984, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.01021625380963087, 'loss_2': 0.00395965576171875, 'loss_3': -16.492937088012695, 'loss_4': -0.5811377763748169, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 14:13:21,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:21,850 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:16<09:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:29,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010289277881383896, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.98, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.0071674250066280365, 'eval_loss_2': 0.0031218528747558594, 'eval_loss_3': -18.144805908203125, 'eval_loss_4': -0.22744613885879517, 'epoch': 26.66}
{'loss': 0.0064, 'grad_norm': 4.7715840339660645, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.003698511514812708, 'loss_2': 0.002696990966796875, 'loss_3': -16.614641189575195, 'loss_4': 0.19286088645458221, 'epoch': 26.66}
{'loss': 0.0154, 'grad_norm': 6.842268466949463, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.010670776478946209, 'loss_2': 0.004756927490234375, 'loss_3': -16.293899536132812, 'loss_4': -0.7640169262886047, 'epoch': 26.67}
{'loss': 0.0056, 'grad_norm': 4.670248508453369, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.003259392688050866, 'loss_2': 0.002300262451171875, 'loss_3': -16.355518341064453, 'loss_4': 0.00870165228843689, 'epoch': 26.67}
{'loss': 0.0064, 'grad_norm': 5.287204265594482, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.005963974632322788, 'loss_2': 0.00041961669921875, 'loss_3': -16.467544555664062, 'loss_4': -0.38175302743911743, 'epoch': 26.68}
{'loss': 0.0028, 'grad_norm': 4.359511852264404, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.0023002135567367077, 'loss_2': 0.0005373954772949219, 'loss_3': -16.447574615478516, 'loss_4': 0.08824337273836136, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 14:13:29,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:29,184 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:20<09:50,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:13:32,982 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590
[INFO|configuration_utils.py:420] 2025-01-21 14:13:32,983 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590/config.json                                                                            
{'eval_loss': 0.009718984365463257, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007018871605396271, 'eval_loss_2': 0.002700112760066986, 'eval_loss_3': -18.142087936401367, 'eval_loss_4': -0.21046681702136993, 'epoch': 26.69}
[INFO|modeling_utils.py:2988] 2025-01-21 14:13:33,500 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:13:33,502 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:13:33,502 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:13:34,563 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4555] due to args.save_total_limit
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:25<10:53,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 14:13:38,195 >>
{'loss': 0.0049, 'grad_norm': 4.992812156677246, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.0023886365815997124, 'loss_2': 0.0025501251220703125, 'loss_3': -16.652706146240234, 'loss_4': -0.132470041513443, 'epoch': 26.69}
{'loss': 0.0193, 'grad_norm': 11.014801025390625, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.016327209770679474, 'loss_2': 0.00298309326171875, 'loss_3': -16.42321014404297, 'loss_4': -0.503516674041748, 'epoch': 26.7}
{'loss': 0.0166, 'grad_norm': 6.558797359466553, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.012709000147879124, 'loss_2': 0.00392913818359375, 'loss_3': -16.403703689575195, 'loss_4': 0.24039694666862488, 'epoch': 26.7}
{'loss': 0.02, 'grad_norm': 9.517990112304688, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.01809067837893963, 'loss_2': 0.0018720626831054688, 'loss_3': -16.691543579101562, 'loss_4': -0.4178370535373688, 'epoch': 26.71}
{'loss': 0.0092, 'grad_norm': 5.103915214538574, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.004245232790708542, 'loss_2': 0.00494384765625, 'loss_3': -16.364139556884766, 'loss_4': -0.16343680024147034, 'epoch': 26.72}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:13:38,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:38,196 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:29<10:53,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 14:13:41,982 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595
[INFO|configuration_utils.py:420] 2025-01-21 14:13:41,983 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595/config.json                                                                            
{'eval_loss': 0.009462634101510048, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.493, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0069558266550302505, 'eval_loss_2': 0.0025068074464797974, 'eval_loss_3': -18.14176368713379, 'eval_loss_4': -0.19366730749607086, 'epoch': 26.72}
[INFO|modeling_utils.py:2988] 2025-01-21 14:13:42,484 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:13:42,486 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:13:42,486 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:13:43,539 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4590] due to args.save_total_limit
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:34<10:56,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 14:13:47,151 >>
{'loss': 0.01, 'grad_norm': 4.2423858642578125, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.003263890976086259, 'loss_2': 0.006744384765625, 'loss_3': -16.52700424194336, 'loss_4': -0.10161475837230682, 'epoch': 26.72}
{'loss': 0.0116, 'grad_norm': 5.745960235595703, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.00810884777456522, 'loss_2': 0.003536224365234375, 'loss_3': -16.539505004882812, 'loss_4': 0.13585862517356873, 'epoch': 26.73}
{'loss': 0.0102, 'grad_norm': 5.8125505447387695, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.009844707325100899, 'loss_2': 0.00036907196044921875, 'loss_3': -16.503175735473633, 'loss_4': -0.19804584980010986, 'epoch': 26.73}
{'loss': 0.0085, 'grad_norm': 4.217860698699951, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.003134465077891946, 'loss_2': 0.00533294677734375, 'loss_3': -16.54806900024414, 'loss_4': 0.0684012621641159, 'epoch': 26.74}
{'loss': 0.0097, 'grad_norm': 5.139622688293457, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.006778777111321688, 'loss_2': 0.0029087066650390625, 'loss_3': -16.526615142822266, 'loss_4': -0.2795465886592865, 'epoch': 26.74}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:13:47,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:47,151 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:41<09:47,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:13:54,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00973890908062458, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007265189662575722, 'eval_loss_2': 0.0024737194180488586, 'eval_loss_3': -18.134178161621094, 'eval_loss_4': -0.17465318739414215, 'epoch': 26.74}
{'loss': 0.0106, 'grad_norm': 4.622417449951172, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.007876529358327389, 'loss_2': 0.00274658203125, 'loss_3': -16.27853775024414, 'loss_4': -0.5114381909370422, 'epoch': 26.75}
{'loss': 0.0131, 'grad_norm': 8.119013786315918, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.011224196292459965, 'loss_2': 0.0018854141235351562, 'loss_3': -16.506223678588867, 'loss_4': -0.3747548460960388, 'epoch': 26.76}
{'loss': 0.0048, 'grad_norm': 9.00610065460205, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.0028511506970971823, 'loss_2': 0.0019283294677734375, 'loss_3': -16.577638626098633, 'loss_4': -0.2776539623737335, 'epoch': 26.76}
{'loss': 0.0036, 'grad_norm': 4.680606365203857, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.002884478308260441, 'loss_2': 0.0007152557373046875, 'loss_3': -16.54477310180664, 'loss_4': 0.03812547028064728, 'epoch': 26.77}
{'loss': 0.0082, 'grad_norm': 5.274927139282227, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.004088621586561203, 'loss_2': 0.00415802001953125, 'loss_3': -16.418960571289062, 'loss_4': -0.12254075706005096, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 14:13:54,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:54,470 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:48<09:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:01,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010324791073799133, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.44, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007315471302717924, 'eval_loss_2': 0.003009319305419922, 'eval_loss_3': -18.14118766784668, 'eval_loss_4': -0.14111000299453735, 'epoch': 26.77}
{'loss': 0.0042, 'grad_norm': 4.668710708618164, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.003753461642190814, 'loss_2': 0.00040340423583984375, 'loss_3': -16.40040397644043, 'loss_4': -0.5043762922286987, 'epoch': 26.78}
{'loss': 0.009, 'grad_norm': 4.567666053771973, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.005758883431553841, 'loss_2': 0.003276824951171875, 'loss_3': -16.31995964050293, 'loss_4': -0.211770161986351, 'epoch': 26.78}
{'loss': 0.0121, 'grad_norm': 5.09052038192749, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.0066829570569098, 'loss_2': 0.0054168701171875, 'loss_3': -16.5435848236084, 'loss_4': -0.17159610986709595, 'epoch': 26.79}
{'loss': 0.0127, 'grad_norm': 4.677382946014404, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.004968135617673397, 'loss_2': 0.00772857666015625, 'loss_3': -16.412919998168945, 'loss_4': 0.07934476435184479, 'epoch': 26.8}
{'loss': 0.0096, 'grad_norm': 5.389369487762451, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.0066551826894283295, 'loss_2': 0.002941131591796875, 'loss_3': -16.46585464477539, 'loss_4': -0.21264788508415222, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 14:14:01,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:01,817 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:56<09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:09,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010113071650266647, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007269454188644886, 'eval_loss_2': 0.002843618392944336, 'eval_loss_3': -18.13141632080078, 'eval_loss_4': -0.09536140412092209, 'epoch': 26.8}
{'loss': 0.0128, 'grad_norm': 4.977255344390869, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.004421926103532314, 'loss_2': 0.00836944580078125, 'loss_3': -16.356609344482422, 'loss_4': -0.02387252449989319, 'epoch': 26.81}
{'loss': 0.0108, 'grad_norm': 5.25342321395874, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.009077755734324455, 'loss_2': 0.00176239013671875, 'loss_3': -16.23080825805664, 'loss_4': -0.32708534598350525, 'epoch': 26.81}
{'loss': 0.0088, 'grad_norm': 4.992724895477295, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.004852753132581711, 'loss_2': 0.00391387939453125, 'loss_3': -16.525724411010742, 'loss_4': -0.21728569269180298, 'epoch': 26.82}
{'loss': 0.0087, 'grad_norm': 4.642578125, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.006040477659553289, 'loss_2': 0.002658843994140625, 'loss_3': -16.53538703918457, 'loss_4': 0.14362458884716034, 'epoch': 26.83}
{'loss': 0.0045, 'grad_norm': 4.49359130859375, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.0037265608552843332, 'loss_2': 0.0007524490356445312, 'loss_3': -16.423076629638672, 'loss_4': -0.5021038055419922, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 14:14:09,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:09,159 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:54:03<09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:16,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010410096496343613, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007290837820619345, 'eval_loss_2': 0.00311926007270813, 'eval_loss_3': -18.13514518737793, 'eval_loss_4': -0.08327475190162659, 'epoch': 26.83}
{'loss': 0.0178, 'grad_norm': 8.45186996459961, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.017606159672141075, 'loss_2': 0.00021028518676757812, 'loss_3': -16.449785232543945, 'loss_4': 0.38321632146835327, 'epoch': 26.84}
{'loss': 0.0118, 'grad_norm': 5.228490352630615, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.008150111883878708, 'loss_2': 0.0036334991455078125, 'loss_3': -16.47703742980957, 'loss_4': 0.14166571199893951, 'epoch': 26.84}
{'loss': 0.0054, 'grad_norm': 4.674646854400635, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.004708455875515938, 'loss_2': 0.0007376670837402344, 'loss_3': -16.405452728271484, 'loss_4': -0.09712362289428711, 'epoch': 26.85}
{'loss': 0.0104, 'grad_norm': 4.684630870819092, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.002178270136937499, 'loss_2': 0.00824737548828125, 'loss_3': -16.483640670776367, 'loss_4': 0.024789154529571533, 'epoch': 26.85}
{'loss': 0.0053, 'grad_norm': 4.765336990356445, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.004977148957550526, 'loss_2': 0.0003299713134765625, 'loss_3': -16.310983657836914, 'loss_4': -0.0009412169456481934, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 14:14:16,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:16,493 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:54:10<09:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:23,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01019254419952631, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.888, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007135080173611641, 'eval_loss_2': 0.0030574649572372437, 'eval_loss_3': -18.131122589111328, 'eval_loss_4': -0.08214855939149857, 'epoch': 26.86}
{'loss': 0.0049, 'grad_norm': 4.575428009033203, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.0027156516443938017, 'loss_2': 0.00218963623046875, 'loss_3': -16.233530044555664, 'loss_4': 0.18285897374153137, 'epoch': 26.87}
{'loss': 0.0072, 'grad_norm': 4.604057788848877, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.005279685370624065, 'loss_2': 0.0019245147705078125, 'loss_3': -16.574689865112305, 'loss_4': 0.3925934433937073, 'epoch': 26.87}
{'loss': 0.0057, 'grad_norm': 5.349945545196533, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.004639163613319397, 'loss_2': 0.0010919570922851562, 'loss_3': -16.327064514160156, 'loss_4': -0.1634376347064972, 'epoch': 26.88}
{'loss': 0.0059, 'grad_norm': 4.020946025848389, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.0034708790481090546, 'loss_2': 0.0024127960205078125, 'loss_3': -16.555368423461914, 'loss_4': 0.04016143083572388, 'epoch': 26.88}
{'loss': 0.0103, 'grad_norm': 5.5238237380981445, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.008007853291928768, 'loss_2': 0.0022525787353515625, 'loss_3': -16.53140640258789, 'loss_4': 0.14985473453998566, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 14:14:23,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:23,827 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:54:18<09:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:31,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010319241322577, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.215, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.006757191848009825, 'eval_loss_2': 0.003562048077583313, 'eval_loss_3': -18.133764266967773, 'eval_loss_4': -0.07505692541599274, 'epoch': 26.89}
{'loss': 0.0086, 'grad_norm': 5.78484582901001, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.004872707184404135, 'loss_2': 0.003719329833984375, 'loss_3': -16.465497970581055, 'loss_4': 0.009922869503498077, 'epoch': 26.9}
{'loss': 0.0084, 'grad_norm': 4.314598560333252, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.0035505087580531836, 'loss_2': 0.0048675537109375, 'loss_3': -16.463741302490234, 'loss_4': 0.2694973647594452, 'epoch': 26.9}
{'loss': 0.0084, 'grad_norm': 4.773913860321045, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.004279661923646927, 'loss_2': 0.0041351318359375, 'loss_3': -16.311473846435547, 'loss_4': -0.12464544922113419, 'epoch': 26.91}
{'loss': 0.0097, 'grad_norm': 4.949062347412109, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.004895969294011593, 'loss_2': 0.00481414794921875, 'loss_3': -16.343400955200195, 'loss_4': -0.04040675237774849, 'epoch': 26.91}
{'loss': 0.0131, 'grad_norm': 5.4950947761535645, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.00614060228690505, 'loss_2': 0.00698089599609375, 'loss_3': -16.542118072509766, 'loss_4': -0.06445792317390442, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 14:14:31,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:31,147 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:25<09:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:38,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010118150152266026, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.855, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.006744344253093004, 'eval_loss_2': 0.003373805433511734, 'eval_loss_3': -18.137392044067383, 'eval_loss_4': -0.06066906452178955, 'epoch': 26.92}
{'loss': 0.0067, 'grad_norm': 6.025086402893066, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.006246188655495644, 'loss_2': 0.00045013427734375, 'loss_3': -16.227130889892578, 'loss_4': 0.10064692050218582, 'epoch': 26.92}
{'loss': 0.0061, 'grad_norm': 4.609489917755127, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.003505174070596695, 'loss_2': 0.0025787353515625, 'loss_3': -16.36355209350586, 'loss_4': -0.16639459133148193, 'epoch': 26.93}
{'loss': 0.0091, 'grad_norm': 4.355823993682861, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.0022659788373857737, 'loss_2': 0.006866455078125, 'loss_3': -16.28538703918457, 'loss_4': -0.13596531748771667, 'epoch': 26.94}
{'loss': 0.0074, 'grad_norm': 4.9285502433776855, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.0037615038454532623, 'loss_2': 0.00360107421875, 'loss_3': -16.491315841674805, 'loss_4': 0.10384665429592133, 'epoch': 26.94}
{'loss': 0.0181, 'grad_norm': 8.164116859436035, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.016870906576514244, 'loss_2': 0.0012159347534179688, 'loss_3': -16.230083465576172, 'loss_4': 0.23759154975414276, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 14:14:38,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:38,478 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:32<08:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:45,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009608718566596508, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.98, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006857278756797314, 'eval_loss_2': 0.0027514398097991943, 'eval_loss_3': -18.13300895690918, 'eval_loss_4': -0.07410780340433121, 'epoch': 26.95}
{'loss': 0.0087, 'grad_norm': 5.089800834655762, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.007508664391934872, 'loss_2': 0.001216888427734375, 'loss_3': -16.48954200744629, 'loss_4': -0.37482813000679016, 'epoch': 26.95}
{'loss': 0.0092, 'grad_norm': 5.939174175262451, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.006103935185819864, 'loss_2': 0.00311279296875, 'loss_3': -16.422231674194336, 'loss_4': 0.5012333393096924, 'epoch': 26.96}
{'loss': 0.0129, 'grad_norm': 6.701803207397461, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.012044323608279228, 'loss_2': 0.0008363723754882812, 'loss_3': -16.396265029907227, 'loss_4': 0.06299945712089539, 'epoch': 26.97}
{'loss': 0.008, 'grad_norm': 4.474238872528076, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.0030265566892921925, 'loss_2': 0.0049285888671875, 'loss_3': -16.465484619140625, 'loss_4': 0.2532094717025757, 'epoch': 26.97}
{'loss': 0.0106, 'grad_norm': 4.640310287475586, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.0031628559809178114, 'loss_2': 0.0074462890625, 'loss_3': -16.306798934936523, 'loss_4': -0.401024729013443, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 14:14:45,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:45,809 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:36<08:58,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:14:49,608 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640
[INFO|configuration_utils.py:420] 2025-01-21 14:14:49,610 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640/config.json                                                                            
{'eval_loss': 0.009304268285632133, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.659, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0063936770893633366, 'eval_loss_2': 0.0029105916619300842, 'eval_loss_3': -18.13311767578125, 'eval_loss_4': -0.09296508133411407, 'epoch': 26.98}
[INFO|modeling_utils.py:2988] 2025-01-21 14:14:50,101 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:14:50,102 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:14:50,103 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:14:51,152 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4595] due to args.save_total_limit
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:41<09:22,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 14:14:54,462 >>
{'loss': 0.0072, 'grad_norm': 5.027448654174805, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.007129484787583351, 'loss_2': 0.00011336803436279297, 'loss_3': -16.478364944458008, 'loss_4': 0.19092948734760284, 'epoch': 26.98}
{'loss': 0.0045, 'grad_norm': 4.645909786224365, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0036446629092097282, 'loss_2': 0.0008840560913085938, 'loss_3': -16.305644989013672, 'loss_4': -0.15423502027988434, 'epoch': 26.99}
{'loss': 0.0065, 'grad_norm': 5.118195056915283, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.005951959639787674, 'loss_2': 0.0005164146423339844, 'loss_3': -16.47410011291504, 'loss_4': -0.10292192548513412, 'epoch': 26.99}
{'loss': 0.0158, 'grad_norm': 7.1312479972839355, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.005980259273201227, 'loss_2': 0.009796142578125, 'loss_3': -16.58431053161621, 'loss_4': -0.2027803510427475, 'epoch': 27.0}
{'loss': 0.0035, 'grad_norm': 4.678261756896973, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.0033717083279043436, 'loss_2': 9.077787399291992e-05, 'loss_3': -16.43387222290039, 'loss_4': 0.1356014609336853, 'epoch': 27.01}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:14:54,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:54,462 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:45<09:22,  1.09s/it][INFO|trainer.py:3910] 2025-01-21 14:14:58,261 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645
[INFO|configuration_utils.py:420] 2025-01-21 14:14:58,263 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645/config.json                                                                            
{'eval_loss': 0.009070541709661484, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006192532833665609, 'eval_loss_2': 0.0028780102729797363, 'eval_loss_3': -18.138477325439453, 'eval_loss_4': -0.08258156478404999, 'epoch': 27.01}
[INFO|modeling_utils.py:2988] 2025-01-21 14:14:58,777 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:14:58,778 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:14:58,778 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:14:59,846 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4640] due to args.save_total_limit
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:50<09:54,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 14:15:03,457 >>
{'loss': 0.0154, 'grad_norm': 10.574991226196289, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.013417373411357403, 'loss_2': 0.00202178955078125, 'loss_3': -16.510425567626953, 'loss_4': 0.22732329368591309, 'epoch': 27.01}
{'loss': 0.0045, 'grad_norm': 4.499189376831055, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.002859830856323242, 'loss_2': 0.001674652099609375, 'loss_3': -16.574275970458984, 'loss_4': -0.008277922868728638, 'epoch': 27.02}
{'loss': 0.0163, 'grad_norm': 11.441232681274414, 'learning_rate': 3e-06, 'loss_1': 0.013443154282867908, 'loss_2': 0.00283050537109375, 'loss_3': -16.285541534423828, 'loss_4': -0.15898969769477844, 'epoch': 27.02}
{'loss': 0.0153, 'grad_norm': 8.444436073303223, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.014639087952673435, 'loss_2': 0.00061798095703125, 'loss_3': -16.559906005859375, 'loss_4': -0.19384822249412537, 'epoch': 27.03}
{'loss': 0.0083, 'grad_norm': 6.467907428741455, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.007082358468323946, 'loss_2': 0.0012111663818359375, 'loss_3': -16.27779769897461, 'loss_4': 0.1517454832792282, 'epoch': 27.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:15:03,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:03,457 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:54<09:54,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 14:15:07,250 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650
[INFO|configuration_utils.py:420] 2025-01-21 14:15:07,252 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650/config.json                                                                            
{'eval_loss': 0.008880989626049995, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00624203821644187, 'eval_loss_2': 0.0026389509439468384, 'eval_loss_3': -18.1298885345459, 'eval_loss_4': -0.037394024431705475, 'epoch': 27.03}
[INFO|modeling_utils.py:2988] 2025-01-21 14:15:07,716 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:15:07,717 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:15:07,718 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:15:08,783 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4645] due to args.save_total_limit
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:59<09:52,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 14:15:12,419 >>
{'loss': 0.0084, 'grad_norm': 5.371987342834473, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.006446964107453823, 'loss_2': 0.00197601318359375, 'loss_3': -16.367889404296875, 'loss_4': 0.029656022787094116, 'epoch': 27.04}
{'loss': 0.0053, 'grad_norm': 4.13291597366333, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.002168579725548625, 'loss_2': 0.003082275390625, 'loss_3': -16.50061798095703, 'loss_4': 0.3122670352458954, 'epoch': 27.05}
{'loss': 0.0078, 'grad_norm': 4.768978118896484, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.0035571104381233454, 'loss_2': 0.004253387451171875, 'loss_3': -16.444046020507812, 'loss_4': -0.24605053663253784, 'epoch': 27.05}
{'loss': 0.0041, 'grad_norm': 4.363171577453613, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.0021701122168451548, 'loss_2': 0.001911163330078125, 'loss_3': -16.54094886779785, 'loss_4': -0.29250645637512207, 'epoch': 27.06}
{'loss': 0.018, 'grad_norm': 11.844332695007324, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.01636345311999321, 'loss_2': 0.0016078948974609375, 'loss_3': -16.57792854309082, 'loss_4': 0.26032784581184387, 'epoch': 27.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:15:12,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:12,420 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:55:06<08:48,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:15:19,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009282644838094711, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.281, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0065229167230427265, 'eval_loss_2': 0.002759728580713272, 'eval_loss_3': -18.125455856323242, 'eval_loss_4': -0.005386017262935638, 'epoch': 27.06}
{'loss': 0.0069, 'grad_norm': 4.710130214691162, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.003018014132976532, 'loss_2': 0.0038509368896484375, 'loss_3': -16.33221435546875, 'loss_4': 0.0881652906537056, 'epoch': 27.07}
{'loss': 0.0061, 'grad_norm': 4.473015785217285, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.0025279840920120478, 'loss_2': 0.003582000732421875, 'loss_3': -16.423439025878906, 'loss_4': 0.023750126361846924, 'epoch': 27.08}
{'loss': 0.0073, 'grad_norm': 5.183408260345459, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.004254617728292942, 'loss_2': 0.0029964447021484375, 'loss_3': -16.38109588623047, 'loss_4': -0.04368548467755318, 'epoch': 27.08}
{'loss': 0.0044, 'grad_norm': 4.653826713562012, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.0032414384186267853, 'loss_2': 0.001186370849609375, 'loss_3': -16.268707275390625, 'loss_4': 0.19698955118656158, 'epoch': 27.09}
{'loss': 0.0058, 'grad_norm': 4.643671035766602, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.003034045686945319, 'loss_2': 0.002750396728515625, 'loss_3': -16.358896255493164, 'loss_4': -0.2894957661628723, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 14:15:19,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:19,738 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:55:14<08:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:27,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009800789877772331, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.007152853533625603, 'eval_loss_2': 0.0026479363441467285, 'eval_loss_3': -18.115245819091797, 'eval_loss_4': 0.03418465703725815, 'epoch': 27.09}
{'loss': 0.0114, 'grad_norm': 5.173220634460449, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.005922127980738878, 'loss_2': 0.00548553466796875, 'loss_3': -16.557891845703125, 'loss_4': 0.32743048667907715, 'epoch': 27.1}
{'loss': 0.004, 'grad_norm': 4.834810256958008, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.0036634427960962057, 'loss_2': 0.0003426074981689453, 'loss_3': -16.424755096435547, 'loss_4': -0.11335214227437973, 'epoch': 27.1}
{'loss': 0.0088, 'grad_norm': 5.3248796463012695, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.004743360448628664, 'loss_2': 0.0040435791015625, 'loss_3': -16.269062042236328, 'loss_4': 0.7160141468048096, 'epoch': 27.11}
{'loss': 0.0095, 'grad_norm': 4.106164455413818, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.003371264785528183, 'loss_2': 0.006168365478515625, 'loss_3': -16.401100158691406, 'loss_4': 0.16037636995315552, 'epoch': 27.12}
{'loss': 0.0139, 'grad_norm': 5.415287971496582, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.007438777480274439, 'loss_2': 0.006439208984375, 'loss_3': -16.393646240234375, 'loss_4': 0.09168794751167297, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 14:15:27,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:27,055 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:55:21<08:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:34,380 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010363193228840828, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007305504754185677, 'eval_loss_2': 0.0030576884746551514, 'eval_loss_3': -18.111873626708984, 'eval_loss_4': 0.07666557282209396, 'epoch': 27.12}
{'loss': 0.0067, 'grad_norm': 4.621885776519775, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.0032471842132508755, 'loss_2': 0.0034637451171875, 'loss_3': -16.235694885253906, 'loss_4': -0.005889028310775757, 'epoch': 27.13}
{'loss': 0.007, 'grad_norm': 4.6020917892456055, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.004795133601874113, 'loss_2': 0.002193450927734375, 'loss_3': -16.34644889831543, 'loss_4': 0.26216304302215576, 'epoch': 27.13}
{'loss': 0.0108, 'grad_norm': 4.9502153396606445, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.006619959603995085, 'loss_2': 0.004177093505859375, 'loss_3': -16.370281219482422, 'loss_4': 0.03991636633872986, 'epoch': 27.14}
{'loss': 0.0051, 'grad_norm': 4.93701171875, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.0031476239673793316, 'loss_2': 0.001987457275390625, 'loss_3': -16.55607032775879, 'loss_4': 0.060947395861148834, 'epoch': 27.15}
{'loss': 0.01, 'grad_norm': 5.3541669845581055, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.008715796284377575, 'loss_2': 0.0013217926025390625, 'loss_3': -16.289825439453125, 'loss_4': -0.0685676634311676, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 14:15:34,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:34,381 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:28<08:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:41,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0111197829246521, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007659135386347771, 'eval_loss_2': 0.0034606456756591797, 'eval_loss_3': -18.112886428833008, 'eval_loss_4': 0.11066804826259613, 'epoch': 27.15}
{'loss': 0.0154, 'grad_norm': 5.617147922515869, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.009672444313764572, 'loss_2': 0.00574493408203125, 'loss_3': -16.475555419921875, 'loss_4': 0.45478880405426025, 'epoch': 27.16}
{'loss': 0.0054, 'grad_norm': 4.0918073654174805, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.003238395322114229, 'loss_2': 0.002124786376953125, 'loss_3': -16.431459426879883, 'loss_4': 0.1708892583847046, 'epoch': 27.16}
{'loss': 0.0045, 'grad_norm': 4.812075138092041, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.003547144355252385, 'loss_2': 0.0009675025939941406, 'loss_3': -16.43764877319336, 'loss_4': 0.24985790252685547, 'epoch': 27.17}
{'loss': 0.0073, 'grad_norm': 4.9196577072143555, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.005857683252543211, 'loss_2': 0.0014314651489257812, 'loss_3': -16.235267639160156, 'loss_4': 0.6107193827629089, 'epoch': 27.17}
{'loss': 0.0097, 'grad_norm': 4.797976970672607, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.005965427029877901, 'loss_2': 0.00376129150390625, 'loss_3': -16.396085739135742, 'loss_4': 0.33127361536026, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 14:15:41,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:41,707 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:36<08:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:49,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011022101156413555, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00804994534701109, 'eval_loss_2': 0.002972155809402466, 'eval_loss_3': -18.11496925354004, 'eval_loss_4': 0.13977304100990295, 'epoch': 27.18}
{'loss': 0.014, 'grad_norm': 5.162780284881592, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.005680131260305643, 'loss_2': 0.008270263671875, 'loss_3': -16.30193328857422, 'loss_4': 0.38978657126426697, 'epoch': 27.19}
{'loss': 0.0069, 'grad_norm': 5.430884838104248, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.00645078718662262, 'loss_2': 0.00046753883361816406, 'loss_3': -16.34442901611328, 'loss_4': -0.27689096331596375, 'epoch': 27.19}
{'loss': 0.0117, 'grad_norm': 4.053978443145752, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.003990484867244959, 'loss_2': 0.007755279541015625, 'loss_3': -16.507762908935547, 'loss_4': -0.1066395565867424, 'epoch': 27.2}
{'loss': 0.0098, 'grad_norm': 4.582022666931152, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.004573458805680275, 'loss_2': 0.005214691162109375, 'loss_3': -16.33673667907715, 'loss_4': 0.3542060852050781, 'epoch': 27.2}
{'loss': 0.0034, 'grad_norm': 4.870380878448486, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.001917181070894003, 'loss_2': 0.0014400482177734375, 'loss_3': -16.549720764160156, 'loss_4': 0.19268283247947693, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 14:15:49,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:49,031 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:43<08:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:56,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010842252522706985, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.083, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.007904279977083206, 'eval_loss_2': 0.0029379725456237793, 'eval_loss_3': -18.119749069213867, 'eval_loss_4': 0.15045133233070374, 'epoch': 27.21}
{'loss': 0.0189, 'grad_norm': 10.211359977722168, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.01732383668422699, 'loss_2': 0.001621246337890625, 'loss_3': -16.334335327148438, 'loss_4': -0.05469261109828949, 'epoch': 27.22}
{'loss': 0.007, 'grad_norm': 4.313093662261963, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.005016743205487728, 'loss_2': 0.001953125, 'loss_3': -16.5001220703125, 'loss_4': 0.08458590507507324, 'epoch': 27.22}
{'loss': 0.0092, 'grad_norm': 5.3513617515563965, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.006326816510409117, 'loss_2': 0.002910614013671875, 'loss_3': -16.501461029052734, 'loss_4': 0.4212486743927002, 'epoch': 27.23}
{'loss': 0.0055, 'grad_norm': 4.503611087799072, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.004674187861382961, 'loss_2': 0.0008530616760253906, 'loss_3': -16.61452293395996, 'loss_4': -0.21662849187850952, 'epoch': 27.23}
{'loss': 0.0081, 'grad_norm': 4.625905513763428, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.004288787487894297, 'loss_2': 0.0038604736328125, 'loss_3': -16.64542579650879, 'loss_4': 0.30300599336624146, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 14:15:56,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:56,352 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:50<08:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:03,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01097780093550682, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.267, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007844176143407822, 'eval_loss_2': 0.003133624792098999, 'eval_loss_3': -18.116640090942383, 'eval_loss_4': 0.16934174299240112, 'epoch': 27.24}
{'loss': 0.0118, 'grad_norm': 5.895710468292236, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.00849920604377985, 'loss_2': 0.0033397674560546875, 'loss_3': -16.46920394897461, 'loss_4': -0.22871899604797363, 'epoch': 27.24}
{'loss': 0.0166, 'grad_norm': 7.460504055023193, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.009879887104034424, 'loss_2': 0.0066986083984375, 'loss_3': -16.524803161621094, 'loss_4': 0.4036843180656433, 'epoch': 27.25}
{'loss': 0.0328, 'grad_norm': 11.991430282592773, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.028098763898015022, 'loss_2': 0.0047454833984375, 'loss_3': -16.249868392944336, 'loss_4': 0.317344605922699, 'epoch': 27.26}
{'loss': 0.0076, 'grad_norm': 4.969024658203125, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.00471304077655077, 'loss_2': 0.0029296875, 'loss_3': -16.4578914642334, 'loss_4': 0.3161492645740509, 'epoch': 27.26}
{'loss': 0.0033, 'grad_norm': 4.368322372436523, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.0025692060589790344, 'loss_2': 0.0007038116455078125, 'loss_3': -16.35965347290039, 'loss_4': -0.08118146657943726, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 14:16:03,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:03,675 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:58<08:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:10,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010851642116904259, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.179, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007706870790570974, 'eval_loss_2': 0.003144770860671997, 'eval_loss_3': -18.1201171875, 'eval_loss_4': 0.19037428498268127, 'epoch': 27.27}
{'loss': 0.0109, 'grad_norm': 4.739980697631836, 'learning_rate': 2.75e-06, 'loss_1': 0.00556621327996254, 'loss_2': 0.00533294677734375, 'loss_3': -16.350780487060547, 'loss_4': 0.38042378425598145, 'epoch': 27.27}
{'loss': 0.01, 'grad_norm': 4.670477867126465, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.005724077112972736, 'loss_2': 0.00426483154296875, 'loss_3': -16.471179962158203, 'loss_4': -0.0006505399942398071, 'epoch': 27.28}
{'loss': 0.0089, 'grad_norm': 4.311714172363281, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.003339658258482814, 'loss_2': 0.00560760498046875, 'loss_3': -16.189720153808594, 'loss_4': 0.5287550091743469, 'epoch': 27.28}
{'loss': 0.0076, 'grad_norm': 5.841075420379639, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.006539809051901102, 'loss_2': 0.0010166168212890625, 'loss_3': -16.300151824951172, 'loss_4': -0.10528537631034851, 'epoch': 27.29}
{'loss': 0.0101, 'grad_norm': 5.731774806976318, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.006434143055230379, 'loss_2': 0.0036449432373046875, 'loss_3': -16.329288482666016, 'loss_4': 0.36410123109817505, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 14:16:10,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:10,992 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:56:05<07:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:18,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010439353995025158, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00760468328371644, 'eval_loss_2': 0.0028346702456474304, 'eval_loss_3': -18.123470306396484, 'eval_loss_4': 0.16376937925815582, 'epoch': 27.3}
{'loss': 0.0018, 'grad_norm': 4.14315938949585, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.001731307478621602, 'loss_2': 5.412101745605469e-05, 'loss_3': -16.54718780517578, 'loss_4': 0.540183961391449, 'epoch': 27.3}
{'loss': 0.0709, 'grad_norm': 10.583382606506348, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.07010167092084885, 'loss_2': 0.0008335113525390625, 'loss_3': -16.395288467407227, 'loss_4': 0.11706126481294632, 'epoch': 27.31}
{'loss': 0.0106, 'grad_norm': 4.576425075531006, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.005441111978143454, 'loss_2': 0.0051422119140625, 'loss_3': -16.467548370361328, 'loss_4': 0.0384010449051857, 'epoch': 27.31}
{'loss': 0.0159, 'grad_norm': 6.402683258056641, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.009279873222112656, 'loss_2': 0.006610870361328125, 'loss_3': -16.326751708984375, 'loss_4': 0.5752246379852295, 'epoch': 27.32}
{'loss': 0.0061, 'grad_norm': 5.136863708496094, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.004457836039364338, 'loss_2': 0.0015993118286132812, 'loss_3': -16.300941467285156, 'loss_4': -0.12719246745109558, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 14:16:18,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:18,323 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:56:12<07:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:25,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010103490203619003, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.02, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0074257515370845795, 'eval_loss_2': 0.002677738666534424, 'eval_loss_3': -18.124624252319336, 'eval_loss_4': 0.11580169200897217, 'epoch': 27.33}
{'loss': 0.0121, 'grad_norm': 6.0204691886901855, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.009299974888563156, 'loss_2': 0.002765655517578125, 'loss_3': -16.3204288482666, 'loss_4': -0.03788270056247711, 'epoch': 27.33}
{'loss': 0.0122, 'grad_norm': 5.441958427429199, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.006861917208880186, 'loss_2': 0.00531768798828125, 'loss_3': -16.38434600830078, 'loss_4': 0.11024876683950424, 'epoch': 27.34}
{'loss': 0.0074, 'grad_norm': 5.545158386230469, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.0063921380788087845, 'loss_2': 0.0010395050048828125, 'loss_3': -16.352767944335938, 'loss_4': -0.11212136596441269, 'epoch': 27.34}
{'loss': 0.0072, 'grad_norm': 6.053836345672607, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.004046081565320492, 'loss_2': 0.00312042236328125, 'loss_3': -16.566320419311523, 'loss_4': 0.05168668180704117, 'epoch': 27.35}
{'loss': 0.0124, 'grad_norm': 4.726099967956543, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.005005889572203159, 'loss_2': 0.0074310302734375, 'loss_3': -16.353839874267578, 'loss_4': 0.08445784449577332, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 14:16:25,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:25,650 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:56:20<07:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:32,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010634689591825008, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.899, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007574199698865414, 'eval_loss_2': 0.0030604898929595947, 'eval_loss_3': -18.119701385498047, 'eval_loss_4': 0.07882367074489594, 'epoch': 27.35}
{'loss': 0.0119, 'grad_norm': 4.315520286560059, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.003055260516703129, 'loss_2': 0.0088043212890625, 'loss_3': -16.254323959350586, 'loss_4': 0.05125275254249573, 'epoch': 27.36}
{'loss': 0.0146, 'grad_norm': 4.70412540435791, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.006203206721693277, 'loss_2': 0.00843048095703125, 'loss_3': -16.277645111083984, 'loss_4': -0.02943044900894165, 'epoch': 27.37}
{'loss': 0.0042, 'grad_norm': 4.818747043609619, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.0024192584678530693, 'loss_2': 0.0017518997192382812, 'loss_3': -16.44873809814453, 'loss_4': -0.20975100994110107, 'epoch': 27.37}
{'loss': 0.0051, 'grad_norm': 4.7404375076293945, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.0032340323086827993, 'loss_2': 0.0018749237060546875, 'loss_3': -16.435245513916016, 'loss_4': -0.21632719039916992, 'epoch': 27.38}
{'loss': 0.008, 'grad_norm': 5.597347259521484, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.003888951614499092, 'loss_2': 0.0040740966796875, 'loss_3': -16.19483757019043, 'loss_4': 0.22555014491081238, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 14:16:32,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:32,982 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:56:27<07:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:40,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01065770722925663, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.133, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007674361579120159, 'eval_loss_2': 0.0029833465814590454, 'eval_loss_3': -18.121564865112305, 'eval_loss_4': 0.058696456253528595, 'epoch': 27.38}
{'loss': 0.0109, 'grad_norm': 4.479951858520508, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.005539140198379755, 'loss_2': 0.00533294677734375, 'loss_3': -16.442420959472656, 'loss_4': -0.13064664602279663, 'epoch': 27.39}
{'loss': 0.0082, 'grad_norm': 5.675991058349609, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.007293876726180315, 'loss_2': 0.0009021759033203125, 'loss_3': -16.284442901611328, 'loss_4': 0.11558555066585541, 'epoch': 27.4}
{'loss': 0.0687, 'grad_norm': 16.941972732543945, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.06240592524409294, 'loss_2': 0.006267547607421875, 'loss_3': -16.49250030517578, 'loss_4': 0.7077040076255798, 'epoch': 27.4}
{'loss': 0.0116, 'grad_norm': 5.994526386260986, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.008935889229178429, 'loss_2': 0.002655029296875, 'loss_3': -16.185649871826172, 'loss_4': -0.005393072962760925, 'epoch': 27.41}
{'loss': 0.0074, 'grad_norm': 5.067294597625732, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.006905228830873966, 'loss_2': 0.000453948974609375, 'loss_3': -16.33231544494629, 'loss_4': -0.21873900294303894, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 14:16:40,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:40,309 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:34<07:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:47,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010796608403325081, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.13, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007989334873855114, 'eval_loss_2': 0.0028072744607925415, 'eval_loss_3': -18.127208709716797, 'eval_loss_4': 0.059702999889850616, 'epoch': 27.41}
{'loss': 0.0178, 'grad_norm': 6.859292507171631, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.013315483927726746, 'loss_2': 0.00450897216796875, 'loss_3': -16.302711486816406, 'loss_4': -0.15533661842346191, 'epoch': 27.42}
{'loss': 0.01, 'grad_norm': 5.766974449157715, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.006652376614511013, 'loss_2': 0.0033416748046875, 'loss_3': -16.4342041015625, 'loss_4': 0.028275050222873688, 'epoch': 27.42}
{'loss': 0.021, 'grad_norm': 12.783003807067871, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.02002655901014805, 'loss_2': 0.0009660720825195312, 'loss_3': -16.233142852783203, 'loss_4': -0.07539398223161697, 'epoch': 27.43}
{'loss': 0.0206, 'grad_norm': 8.65034008026123, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.017807936295866966, 'loss_2': 0.002780914306640625, 'loss_3': -16.360368728637695, 'loss_4': 0.44318801164627075, 'epoch': 27.44}
{'loss': 0.0137, 'grad_norm': 10.489025115966797, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.011664001271128654, 'loss_2': 0.001987457275390625, 'loss_3': -16.435312271118164, 'loss_4': 0.1004171073436737, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 14:16:47,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:47,631 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:42<07:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:54,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010457762517035007, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007687987294048071, 'eval_loss_2': 0.002769775688648224, 'eval_loss_3': -18.12665557861328, 'eval_loss_4': 0.036554742604494095, 'epoch': 27.44}
{'loss': 0.0078, 'grad_norm': 5.210794448852539, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.004571310710161924, 'loss_2': 0.003215789794921875, 'loss_3': -16.427169799804688, 'loss_4': -0.21342000365257263, 'epoch': 27.45}
{'loss': 0.0088, 'grad_norm': 4.182662487030029, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.0030673108994960785, 'loss_2': 0.00569915771484375, 'loss_3': -16.34296417236328, 'loss_4': 0.07348515093326569, 'epoch': 27.45}
{'loss': 0.0146, 'grad_norm': 8.69218921661377, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.01431341003626585, 'loss_2': 0.00025916099548339844, 'loss_3': -16.5101375579834, 'loss_4': 0.22993117570877075, 'epoch': 27.46}
{'loss': 0.0078, 'grad_norm': 4.988748073577881, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.004370885901153088, 'loss_2': 0.0034198760986328125, 'loss_3': -16.36992073059082, 'loss_4': 0.010228484869003296, 'epoch': 27.47}
{'loss': 0.01, 'grad_norm': 5.0749125480651855, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.006687931250780821, 'loss_2': 0.0033321380615234375, 'loss_3': -16.40431785583496, 'loss_4': -0.057377442717552185, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 14:16:54,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:54,960 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:49<07:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:02,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010232776403427124, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.78, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00733181880787015, 'eval_loss_2': 0.0029009580612182617, 'eval_loss_3': -18.12436294555664, 'eval_loss_4': 0.013400159776210785, 'epoch': 27.47}
{'loss': 0.0096, 'grad_norm': 5.491995334625244, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.006262863054871559, 'loss_2': 0.003337860107421875, 'loss_3': -16.071935653686523, 'loss_4': -0.21205121278762817, 'epoch': 27.48}
{'loss': 0.0124, 'grad_norm': 5.502961158752441, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.008616168983280659, 'loss_2': 0.003826141357421875, 'loss_3': -16.428220748901367, 'loss_4': 0.027106858789920807, 'epoch': 27.48}
{'loss': 0.0071, 'grad_norm': 4.969827175140381, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.004347235430032015, 'loss_2': 0.0027332305908203125, 'loss_3': -16.306289672851562, 'loss_4': -0.11670484393835068, 'epoch': 27.49}
{'loss': 0.0082, 'grad_norm': 6.6872711181640625, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.008022777736186981, 'loss_2': 0.0002028942108154297, 'loss_3': -16.465131759643555, 'loss_4': 0.0802895650267601, 'epoch': 27.49}
{'loss': 0.0041, 'grad_norm': 4.6218791007995605, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.0028034404385834932, 'loss_2': 0.001312255859375, 'loss_3': -16.494915008544922, 'loss_4': 0.5891695022583008, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 14:17:02,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:02,292 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:56<07:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:09,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010449301451444626, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.982, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.007657412905246019, 'eval_loss_2': 0.002791889011859894, 'eval_loss_3': -18.132125854492188, 'eval_loss_4': 0.01646750047802925, 'epoch': 27.5}
{'loss': 0.0098, 'grad_norm': 5.498784065246582, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.00664024893194437, 'loss_2': 0.00316619873046875, 'loss_3': -16.214014053344727, 'loss_4': 0.33527782559394836, 'epoch': 27.51}
{'loss': 0.0083, 'grad_norm': 5.085366249084473, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0038016438484191895, 'loss_2': 0.004535675048828125, 'loss_3': -16.332439422607422, 'loss_4': 0.05508057773113251, 'epoch': 27.51}
{'loss': 0.0188, 'grad_norm': 9.784441947937012, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.012715891934931278, 'loss_2': 0.00612640380859375, 'loss_3': -16.415191650390625, 'loss_4': 0.570010781288147, 'epoch': 27.52}
{'loss': 0.0044, 'grad_norm': 4.17807674407959, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.0033357057254761457, 'loss_2': 0.001068115234375, 'loss_3': -16.478986740112305, 'loss_4': 0.2521205246448517, 'epoch': 27.52}
{'loss': 0.0098, 'grad_norm': 5.941071510314941, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.0077691818587481976, 'loss_2': 0.002017974853515625, 'loss_3': -16.5150203704834, 'loss_4': 0.0901014506816864, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 14:17:09,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:09,624 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:57:04<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:16,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01005923468619585, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.734, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007531311828643084, 'eval_loss_2': 0.0025279223918914795, 'eval_loss_3': -18.13274383544922, 'eval_loss_4': 0.03150579333305359, 'epoch': 27.53}
{'loss': 0.0108, 'grad_norm': 5.678050994873047, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.006789313163608313, 'loss_2': 0.003997802734375, 'loss_3': -16.18951416015625, 'loss_4': -0.09480102360248566, 'epoch': 27.53}
{'loss': 0.0117, 'grad_norm': 5.0201945304870605, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.006999035365879536, 'loss_2': 0.0046539306640625, 'loss_3': -16.47696304321289, 'loss_4': 0.058649126440286636, 'epoch': 27.54}
{'loss': 0.006, 'grad_norm': 5.190341949462891, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.005596855655312538, 'loss_2': 0.0004177093505859375, 'loss_3': -16.410125732421875, 'loss_4': -0.07893958687782288, 'epoch': 27.55}
{'loss': 0.005, 'grad_norm': 4.977014541625977, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.004032929427921772, 'loss_2': 0.0009393692016601562, 'loss_3': -16.316730499267578, 'loss_4': -0.09856276214122772, 'epoch': 27.55}
{'loss': 0.0046, 'grad_norm': 4.6876912117004395, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.0029720307793468237, 'loss_2': 0.0016021728515625, 'loss_3': -16.464487075805664, 'loss_4': -0.18529270589351654, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 14:17:16,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:16,973 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:57:11<07:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:24,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0100841224193573, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007502181921154261, 'eval_loss_2': 0.0025819391012191772, 'eval_loss_3': -18.129526138305664, 'eval_loss_4': 0.04641576483845711, 'epoch': 27.56}
{'loss': 0.006, 'grad_norm': 4.296483993530273, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.003329266794025898, 'loss_2': 0.002716064453125, 'loss_3': -16.402664184570312, 'loss_4': -0.035692889243364334, 'epoch': 27.56}
{'loss': 0.0145, 'grad_norm': 8.79340648651123, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.010012822225689888, 'loss_2': 0.004482269287109375, 'loss_3': -16.200960159301758, 'loss_4': 0.17468920350074768, 'epoch': 27.57}
{'loss': 0.0075, 'grad_norm': 5.325618743896484, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.005958292633295059, 'loss_2': 0.0015544891357421875, 'loss_3': -16.36730194091797, 'loss_4': -0.038861002773046494, 'epoch': 27.58}
{'loss': 0.0047, 'grad_norm': 4.542232036590576, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.004395992495119572, 'loss_2': 0.00035381317138671875, 'loss_3': -16.330724716186523, 'loss_4': 0.3447457253932953, 'epoch': 27.58}
{'loss': 0.0083, 'grad_norm': 4.773641109466553, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.00541671272367239, 'loss_2': 0.0028533935546875, 'loss_3': -16.295825958251953, 'loss_4': 0.14738211035728455, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 14:17:24,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:24,320 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:57:18<07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:31,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01051880419254303, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.371, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007653340697288513, 'eval_loss_2': 0.0028654634952545166, 'eval_loss_3': -18.125539779663086, 'eval_loss_4': 0.03910744935274124, 'epoch': 27.59}
{'loss': 0.0093, 'grad_norm': 4.783815383911133, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.002852851990610361, 'loss_2': 0.006488800048828125, 'loss_3': -16.316076278686523, 'loss_4': -0.029637154191732407, 'epoch': 27.59}
{'loss': 0.014, 'grad_norm': 9.046304702758789, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.010970068164169788, 'loss_2': 0.00299835205078125, 'loss_3': -16.455829620361328, 'loss_4': 0.06104786694049835, 'epoch': 27.6}
{'loss': 0.004, 'grad_norm': 4.726099491119385, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.00265640951693058, 'loss_2': 0.0013713836669921875, 'loss_3': -16.347814559936523, 'loss_4': -0.13175594806671143, 'epoch': 27.6}
{'loss': 0.0148, 'grad_norm': 9.211459159851074, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.010377587750554085, 'loss_2': 0.00444793701171875, 'loss_3': -16.398727416992188, 'loss_4': 0.29120224714279175, 'epoch': 27.61}
{'loss': 0.0117, 'grad_norm': 4.625781059265137, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.005585470702499151, 'loss_2': 0.006072998046875, 'loss_3': -16.25815200805664, 'loss_4': 0.1487402319908142, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 14:17:31,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:31,667 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:57:26<07:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:39,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01099000871181488, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00792454183101654, 'eval_loss_2': 0.00306546688079834, 'eval_loss_3': -18.126296997070312, 'eval_loss_4': 0.03321664035320282, 'epoch': 27.62}
{'loss': 0.0047, 'grad_norm': 4.856415748596191, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.0036889109760522842, 'loss_2': 0.0010175704956054688, 'loss_3': -16.381881713867188, 'loss_4': 0.18314433097839355, 'epoch': 27.62}
{'loss': 0.008, 'grad_norm': 4.982120037078857, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0035944520495831966, 'loss_2': 0.0044097900390625, 'loss_3': -16.294666290283203, 'loss_4': -0.685814619064331, 'epoch': 27.63}
{'loss': 0.0074, 'grad_norm': 4.340370178222656, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.0030739076901227236, 'loss_2': 0.00429534912109375, 'loss_3': -16.411087036132812, 'loss_4': 0.41530805826187134, 'epoch': 27.63}
{'loss': 0.014, 'grad_norm': 5.23538064956665, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.006700854282826185, 'loss_2': 0.007297515869140625, 'loss_3': -16.333820343017578, 'loss_4': 0.5189550518989563, 'epoch': 27.64}
{'loss': 0.0064, 'grad_norm': 4.531386375427246, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.003910519648343325, 'loss_2': 0.002513885498046875, 'loss_3': -16.38874053955078, 'loss_4': 0.2861694097518921, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 14:17:39,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:39,010 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:33<06:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:46,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010849636979401112, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.529, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007736307568848133, 'eval_loss_2': 0.0031133294105529785, 'eval_loss_3': -18.128602981567383, 'eval_loss_4': 0.04168545454740524, 'epoch': 27.65}
{'loss': 0.0034, 'grad_norm': 4.916337490081787, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.0034269667230546474, 'loss_2': 5.7220458984375e-06, 'loss_3': -16.464811325073242, 'loss_4': 0.18704742193222046, 'epoch': 27.65}
{'loss': 0.0119, 'grad_norm': 6.839216709136963, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.009001616388559341, 'loss_2': 0.002933502197265625, 'loss_3': -16.519271850585938, 'loss_4': 0.5364782810211182, 'epoch': 27.66}
{'loss': 0.0054, 'grad_norm': 5.087435722351074, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.005064370576292276, 'loss_2': 0.00030612945556640625, 'loss_3': -16.40511703491211, 'loss_4': 0.2738313376903534, 'epoch': 27.66}
{'loss': 0.0026, 'grad_norm': 4.862778186798096, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.002458239207044244, 'loss_2': 0.00018787384033203125, 'loss_3': -16.41321563720703, 'loss_4': 0.10509244352579117, 'epoch': 27.67}
{'loss': 0.0036, 'grad_norm': 4.63984489440918, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.002370740519836545, 'loss_2': 0.0012493133544921875, 'loss_3': -16.34223175048828, 'loss_4': 0.19155709445476532, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 14:17:46,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:46,358 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:40<06:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:53,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01100413128733635, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00794138666242361, 'eval_loss_2': 0.003062743693590164, 'eval_loss_3': -18.127330780029297, 'eval_loss_4': 0.033709485083818436, 'epoch': 27.67}
{'loss': 0.0075, 'grad_norm': 4.589977264404297, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.002086356980726123, 'loss_2': 0.00543212890625, 'loss_3': -16.33873748779297, 'loss_4': 0.46122872829437256, 'epoch': 27.68}
{'loss': 0.009, 'grad_norm': 5.296403408050537, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.005341998301446438, 'loss_2': 0.003692626953125, 'loss_3': -16.370935440063477, 'loss_4': 0.5752829909324646, 'epoch': 27.69}
{'loss': 0.0158, 'grad_norm': 5.990481853485107, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.011575327254831791, 'loss_2': 0.004238128662109375, 'loss_3': -16.455875396728516, 'loss_4': -0.2153700590133667, 'epoch': 27.69}
{'loss': 0.0067, 'grad_norm': 4.6392669677734375, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.005162941291928291, 'loss_2': 0.0015811920166015625, 'loss_3': -16.38741111755371, 'loss_4': 0.06931415945291519, 'epoch': 27.7}
{'loss': 0.0108, 'grad_norm': 5.960551738739014, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.008663910441100597, 'loss_2': 0.00211334228515625, 'loss_3': -16.434581756591797, 'loss_4': -0.027129724621772766, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 14:17:53,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:53,700 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:48<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:01,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011395647190511227, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.515, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008414438925683498, 'eval_loss_2': 0.0029812082648277283, 'eval_loss_3': -18.12982177734375, 'eval_loss_4': 0.015529721975326538, 'epoch': 27.7}
{'loss': 0.0094, 'grad_norm': 4.754166603088379, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.003983398899435997, 'loss_2': 0.0054168701171875, 'loss_3': -16.341997146606445, 'loss_4': -0.40914687514305115, 'epoch': 27.71}
{'loss': 0.0066, 'grad_norm': 4.815671443939209, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.0035496135242283344, 'loss_2': 0.003086090087890625, 'loss_3': -16.567113876342773, 'loss_4': -0.1313292235136032, 'epoch': 27.72}
{'loss': 0.005, 'grad_norm': 4.6895294189453125, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.0023893823381513357, 'loss_2': 0.002620697021484375, 'loss_3': -16.71445083618164, 'loss_4': 0.2911040484905243, 'epoch': 27.72}
{'loss': 0.0036, 'grad_norm': 4.650031566619873, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.002060455270111561, 'loss_2': 0.0014944076538085938, 'loss_3': -16.42746353149414, 'loss_4': -0.22093909978866577, 'epoch': 27.73}
{'loss': 0.0092, 'grad_norm': 5.801216125488281, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.006441595498472452, 'loss_2': 0.00275421142578125, 'loss_3': -16.243789672851562, 'loss_4': -0.423250287771225, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 14:18:01,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:01,049 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:55<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:08,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011347919702529907, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00854019820690155, 'eval_loss_2': 0.002807721495628357, 'eval_loss_3': -18.13019371032715, 'eval_loss_4': 0.020551707595586777, 'epoch': 27.73}
{'loss': 0.0059, 'grad_norm': 4.811953544616699, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.0047490568831563, 'loss_2': 0.0011587142944335938, 'loss_3': -16.44025421142578, 'loss_4': 0.3950008153915405, 'epoch': 27.74}
{'loss': 0.0031, 'grad_norm': 5.074686527252197, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.0023451063316315413, 'loss_2': 0.0007567405700683594, 'loss_3': -16.446027755737305, 'loss_4': 0.06987904757261276, 'epoch': 27.74}
{'loss': 0.0044, 'grad_norm': 4.8456034660339355, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.002794478554278612, 'loss_2': 0.0016155242919921875, 'loss_3': -16.269865036010742, 'loss_4': -0.1344587504863739, 'epoch': 27.75}
{'loss': 0.015, 'grad_norm': 4.963943958282471, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.006789473816752434, 'loss_2': 0.00817108154296875, 'loss_3': -16.396167755126953, 'loss_4': 0.41188299655914307, 'epoch': 27.76}
{'loss': 0.0062, 'grad_norm': 4.952042579650879, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.0023893420584499836, 'loss_2': 0.00380706787109375, 'loss_3': -16.37966537475586, 'loss_4': -0.015899166464805603, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 14:18:08,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:08,391 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:58:02<06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:15,746 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011531660333275795, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0086898822337389, 'eval_loss_2': 0.0028417780995368958, 'eval_loss_3': -18.13593292236328, 'eval_loss_4': 0.01751074567437172, 'epoch': 27.76}
{'loss': 0.0079, 'grad_norm': 5.0068745613098145, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.004403580911457539, 'loss_2': 0.003498077392578125, 'loss_3': -16.336803436279297, 'loss_4': 0.0822824090719223, 'epoch': 27.77}
{'loss': 0.0091, 'grad_norm': 5.408539772033691, 'learning_rate': 2.25e-06, 'loss_1': 0.008308186195790768, 'loss_2': 0.0007786750793457031, 'loss_3': -16.389667510986328, 'loss_4': -0.10011697560548782, 'epoch': 27.77}
{'loss': 0.0085, 'grad_norm': 4.403945446014404, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.004823779687285423, 'loss_2': 0.003692626953125, 'loss_3': -16.399425506591797, 'loss_4': -0.4076259732246399, 'epoch': 27.78}
{'loss': 0.0082, 'grad_norm': 4.704037666320801, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.0025484953075647354, 'loss_2': 0.005634307861328125, 'loss_3': -16.383684158325195, 'loss_4': 0.4304995536804199, 'epoch': 27.78}
{'loss': 0.0079, 'grad_norm': 4.681288719177246, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.003089693607762456, 'loss_2': 0.00482177734375, 'loss_3': -16.4017276763916, 'loss_4': -0.3266315460205078, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 14:18:15,746 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:15,746 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:58:10<06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:23,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011439362540841103, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008758063428103924, 'eval_loss_2': 0.0026813000440597534, 'eval_loss_3': -18.13982582092285, 'eval_loss_4': 0.02592012658715248, 'epoch': 27.79}
{'loss': 0.0037, 'grad_norm': 4.613090515136719, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.003672883380204439, 'loss_2': 5.7816505432128906e-05, 'loss_3': -16.420059204101562, 'loss_4': 0.34436672925949097, 'epoch': 27.8}
{'loss': 0.0051, 'grad_norm': 4.955555438995361, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.003601821605116129, 'loss_2': 0.0014791488647460938, 'loss_3': -16.416072845458984, 'loss_4': 0.18564890325069427, 'epoch': 27.8}
{'loss': 0.01, 'grad_norm': 5.102931976318359, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.006044973153620958, 'loss_2': 0.0039215087890625, 'loss_3': -16.28177261352539, 'loss_4': -0.20479494333267212, 'epoch': 27.81}
{'loss': 0.004, 'grad_norm': 4.6830830574035645, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.002931221853941679, 'loss_2': 0.00104522705078125, 'loss_3': -16.50230598449707, 'loss_4': -0.31211915612220764, 'epoch': 27.81}
{'loss': 0.0079, 'grad_norm': 5.0939412117004395, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.005864031612873077, 'loss_2': 0.00205230712890625, 'loss_3': -16.312091827392578, 'loss_4': 0.10623334348201752, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 14:18:23,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:23,084 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:58:17<06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:30,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011485081166028976, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008762178011238575, 'eval_loss_2': 0.002722904086112976, 'eval_loss_3': -18.142906188964844, 'eval_loss_4': 0.029269255697727203, 'epoch': 27.82}
{'loss': 0.0035, 'grad_norm': 4.658688545227051, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.0028848182410001755, 'loss_2': 0.0005927085876464844, 'loss_3': -16.477725982666016, 'loss_4': 0.25671979784965515, 'epoch': 27.83}
{'loss': 0.0099, 'grad_norm': 7.870499610900879, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.0075728148221969604, 'loss_2': 0.002346038818359375, 'loss_3': -16.29759407043457, 'loss_4': 0.046786900609731674, 'epoch': 27.83}
{'loss': 0.0081, 'grad_norm': 4.820563316345215, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.005005624145269394, 'loss_2': 0.0030670166015625, 'loss_3': -16.42341423034668, 'loss_4': 0.11315768957138062, 'epoch': 27.84}
{'loss': 0.047, 'grad_norm': 11.704978942871094, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.035905394703149796, 'loss_2': 0.0111083984375, 'loss_3': -16.50403594970703, 'loss_4': 0.18503378331661224, 'epoch': 27.84}
{'loss': 0.0047, 'grad_norm': 4.876040935516357, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.004189541097730398, 'loss_2': 0.0005030632019042969, 'loss_3': -16.502338409423828, 'loss_4': 0.4181719720363617, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 14:18:30,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:30,423 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:58:24<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:37,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011182229965925217, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008503180928528309, 'eval_loss_2': 0.0026790499687194824, 'eval_loss_3': -18.149627685546875, 'eval_loss_4': 0.03313411399722099, 'epoch': 27.85}
{'loss': 0.0199, 'grad_norm': 7.714111804962158, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.014826557599008083, 'loss_2': 0.005096435546875, 'loss_3': -16.532047271728516, 'loss_4': 0.576779842376709, 'epoch': 27.85}
{'loss': 0.0074, 'grad_norm': 5.046607494354248, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.005287073086947203, 'loss_2': 0.002101898193359375, 'loss_3': -16.332923889160156, 'loss_4': 0.23431116342544556, 'epoch': 27.86}
{'loss': 0.0037, 'grad_norm': 4.608518600463867, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.0022016295697540045, 'loss_2': 0.001537322998046875, 'loss_3': -16.39075469970703, 'loss_4': -0.02236732840538025, 'epoch': 27.87}
{'loss': 0.0069, 'grad_norm': 5.1330695152282715, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.004949950613081455, 'loss_2': 0.001953125, 'loss_3': -16.47601318359375, 'loss_4': 0.31097641587257385, 'epoch': 27.87}
{'loss': 0.0031, 'grad_norm': 4.263905048370361, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.002077347133308649, 'loss_2': 0.0010538101196289062, 'loss_3': -16.491817474365234, 'loss_4': 0.17310091853141785, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 14:18:37,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:37,763 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:32<06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:45,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010957603342831135, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.24, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008104143664240837, 'eval_loss_2': 0.0028534606099128723, 'eval_loss_3': -18.15717315673828, 'eval_loss_4': 0.04178446903824806, 'epoch': 27.88}
{'loss': 0.0029, 'grad_norm': 4.574178218841553, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.002372307935729623, 'loss_2': 0.0005598068237304688, 'loss_3': -16.106679916381836, 'loss_4': -0.1255154311656952, 'epoch': 27.88}
{'loss': 0.0049, 'grad_norm': 5.247762680053711, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.004770783707499504, 'loss_2': 0.00016546249389648438, 'loss_3': -16.2073974609375, 'loss_4': 0.41398781538009644, 'epoch': 27.89}
{'loss': 0.0091, 'grad_norm': 4.822827339172363, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.004190125036984682, 'loss_2': 0.004940032958984375, 'loss_3': -16.29574203491211, 'loss_4': 0.6779311895370483, 'epoch': 27.9}
{'loss': 0.005, 'grad_norm': 4.467138290405273, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.003321480704471469, 'loss_2': 0.0017147064208984375, 'loss_3': -16.323261260986328, 'loss_4': -0.033308736979961395, 'epoch': 27.9}
{'loss': 0.0043, 'grad_norm': 4.523675918579102, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.0031590417493134737, 'loss_2': 0.0011882781982421875, 'loss_3': -16.50007438659668, 'loss_4': 0.0008768290281295776, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 14:18:45,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:45,108 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:39<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:52,464 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011052648536860943, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007697264663875103, 'eval_loss_2': 0.00335538387298584, 'eval_loss_3': -18.157859802246094, 'eval_loss_4': 0.04313258081674576, 'epoch': 27.91}
{'loss': 0.0064, 'grad_norm': 4.995595932006836, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.005588053725659847, 'loss_2': 0.0008254051208496094, 'loss_3': -16.337230682373047, 'loss_4': 0.04774175584316254, 'epoch': 27.91}
{'loss': 0.0103, 'grad_norm': 5.031597137451172, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.0035110218450427055, 'loss_2': 0.006744384765625, 'loss_3': -16.408443450927734, 'loss_4': 0.015708811581134796, 'epoch': 27.92}
{'loss': 0.0104, 'grad_norm': 4.37890100479126, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.0024721394293010235, 'loss_2': 0.00788116455078125, 'loss_3': -16.47604751586914, 'loss_4': 0.20897811651229858, 'epoch': 27.92}
{'loss': 0.0778, 'grad_norm': 12.467591285705566, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.07758437097072601, 'loss_2': 0.00018906593322753906, 'loss_3': -16.46293830871582, 'loss_4': 0.6218366622924805, 'epoch': 27.93}
{'loss': 0.003, 'grad_norm': 4.199246406555176, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.002890442730858922, 'loss_2': 0.00015735626220703125, 'loss_3': -16.321815490722656, 'loss_4': -0.34524455666542053, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 14:18:52,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:52,464 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:46<06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:59,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011548924259841442, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00757180480286479, 'eval_loss_2': 0.0039771199226379395, 'eval_loss_3': -18.154296875, 'eval_loss_4': 0.05074625089764595, 'epoch': 27.94}
{'loss': 0.0045, 'grad_norm': 4.568445205688477, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.0027655945159494877, 'loss_2': 0.0016918182373046875, 'loss_3': -16.45331573486328, 'loss_4': -0.11195506900548935, 'epoch': 27.94}
{'loss': 0.0113, 'grad_norm': 5.410902500152588, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.005556998308748007, 'loss_2': 0.0057373046875, 'loss_3': -16.363189697265625, 'loss_4': 0.5759284496307373, 'epoch': 27.95}
{'loss': 0.0071, 'grad_norm': 4.503010272979736, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.004300729371607304, 'loss_2': 0.0028362274169921875, 'loss_3': -16.66497039794922, 'loss_4': 0.3444122076034546, 'epoch': 27.95}
{'loss': 0.0149, 'grad_norm': 4.503467082977295, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.004526801872998476, 'loss_2': 0.01036834716796875, 'loss_3': -16.326160430908203, 'loss_4': -0.1895170956850052, 'epoch': 27.96}
{'loss': 0.0091, 'grad_norm': 5.696384906768799, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.006848098244518042, 'loss_2': 0.00222015380859375, 'loss_3': -16.29093360900879, 'loss_4': -0.044407084584236145, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 14:18:59,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:59,815 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:54<05:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:19:07,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011611749418079853, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007783461827784777, 'eval_loss_2': 0.003828287124633789, 'eval_loss_3': -18.146142959594727, 'eval_loss_4': 0.05792652815580368, 'epoch': 27.97}
{'loss': 0.0091, 'grad_norm': 4.173854351043701, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.003911799285560846, 'loss_2': 0.005157470703125, 'loss_3': -16.40719223022461, 'loss_4': -0.47458416223526, 'epoch': 27.97}
{'loss': 0.0028, 'grad_norm': 4.401333332061768, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.0026524406857788563, 'loss_2': 0.00013756752014160156, 'loss_3': -16.33856201171875, 'loss_4': -0.1339735984802246, 'epoch': 27.98}
{'loss': 0.0076, 'grad_norm': 5.055803298950195, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.006603069603443146, 'loss_2': 0.00099945068359375, 'loss_3': -16.316974639892578, 'loss_4': -0.018324606120586395, 'epoch': 27.98}
{'loss': 0.0067, 'grad_norm': 4.505337238311768, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.0032537884544581175, 'loss_2': 0.00345611572265625, 'loss_3': -16.503477096557617, 'loss_4': 0.3470577895641327, 'epoch': 27.99}
{'loss': 0.0039, 'grad_norm': 4.736782550811768, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.003333281259983778, 'loss_2': 0.000530242919921875, 'loss_3': -16.333084106445312, 'loss_4': -0.09176055341959, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 14:19:07,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:07,142 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:59:01<05:45,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:19:14,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011399790644645691, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007827729918062687, 'eval_loss_2': 0.0035720616579055786, 'eval_loss_3': -18.142520904541016, 'eval_loss_4': 0.04799892380833626, 'epoch': 27.99}
{'loss': 0.0068, 'grad_norm': 5.845249176025391, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0007520797662436962, 'loss_2': 0.006084442138671875, 'loss_3': -16.457731246948242, 'loss_4': 0.1303262859582901, 'epoch': 28.0}
{'loss': 0.0144, 'grad_norm': 7.880875587463379, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.012756080366671085, 'loss_2': 0.0016002655029296875, 'loss_3': -16.44500160217285, 'loss_4': -0.43063637614250183, 'epoch': 28.01}
{'loss': 0.0087, 'grad_norm': 6.22589111328125, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.008367558009922504, 'loss_2': 0.0003008842468261719, 'loss_3': -16.460662841796875, 'loss_4': 0.19228491187095642, 'epoch': 28.01}
{'loss': 0.0115, 'grad_norm': 8.918059349060059, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.010022228583693504, 'loss_2': 0.0014429092407226562, 'loss_3': -16.31324577331543, 'loss_4': 0.34090185165405273, 'epoch': 28.02}
{'loss': 0.0186, 'grad_norm': 6.430449962615967, 'learning_rate': 2e-06, 'loss_1': 0.015592380426824093, 'loss_2': 0.00296783447265625, 'loss_3': -16.42104721069336, 'loss_4': 0.269353449344635, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 14:19:14,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:14,193 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:59:08<05:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:21,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01143632736057043, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00808393768966198, 'eval_loss_2': 0.0033523887395858765, 'eval_loss_3': -18.143760681152344, 'eval_loss_4': 0.05544448643922806, 'epoch': 28.02}
{'loss': 0.0053, 'grad_norm': 4.443275451660156, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.0018254147144034505, 'loss_2': 0.00350189208984375, 'loss_3': -16.316650390625, 'loss_4': 0.25474411249160767, 'epoch': 28.03}
{'loss': 0.0124, 'grad_norm': 4.127953052520752, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.0018872236832976341, 'loss_2': 0.010528564453125, 'loss_3': -16.610549926757812, 'loss_4': 0.2300373911857605, 'epoch': 28.03}
{'loss': 0.0034, 'grad_norm': 4.269553184509277, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.0032584110740572214, 'loss_2': 0.00013828277587890625, 'loss_3': -16.340904235839844, 'loss_4': 0.09333078563213348, 'epoch': 28.04}
{'loss': 0.0121, 'grad_norm': 4.6368818283081055, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.0031437361612915993, 'loss_2': 0.0089263916015625, 'loss_3': -16.454607009887695, 'loss_4': 0.17522624135017395, 'epoch': 28.05}
{'loss': 0.0033, 'grad_norm': 4.85734748840332, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.0027231054846197367, 'loss_2': 0.0006251335144042969, 'loss_3': -16.50871467590332, 'loss_4': 0.008866727352142334, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 14:19:21,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:21,543 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:59:15<05:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:28,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011257132515311241, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008034942671656609, 'eval_loss_2': 0.0032221898436546326, 'eval_loss_3': -18.1447696685791, 'eval_loss_4': 0.06885318458080292, 'epoch': 28.05}
{'loss': 0.006, 'grad_norm': 5.069506645202637, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.005236796569079161, 'loss_2': 0.000713348388671875, 'loss_3': -16.455411911010742, 'loss_4': -0.22459296882152557, 'epoch': 28.06}
{'loss': 0.0047, 'grad_norm': 4.34469747543335, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.002538074506446719, 'loss_2': 0.002140045166015625, 'loss_3': -16.49482536315918, 'loss_4': 0.5013717412948608, 'epoch': 28.06}
{'loss': 0.0065, 'grad_norm': 4.426886081695557, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.0029962179251015186, 'loss_2': 0.003482818603515625, 'loss_3': -16.55959129333496, 'loss_4': 0.34726661443710327, 'epoch': 28.07}
{'loss': 0.0088, 'grad_norm': 5.912353038787842, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.007431467995047569, 'loss_2': 0.001377105712890625, 'loss_3': -16.351608276367188, 'loss_4': 0.42550501227378845, 'epoch': 28.08}
{'loss': 0.0082, 'grad_norm': 4.478228569030762, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0024495054967701435, 'loss_2': 0.0057220458984375, 'loss_3': -16.396137237548828, 'loss_4': 0.29493820667266846, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 14:19:28,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:28,894 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:59:23<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:36,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011155649088323116, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00802063848823309, 'eval_loss_2': 0.003135010600090027, 'eval_loss_3': -18.14688491821289, 'eval_loss_4': 0.07923473417758942, 'epoch': 28.08}
{'loss': 0.0054, 'grad_norm': 4.753450870513916, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.0029945059213787317, 'loss_2': 0.002429962158203125, 'loss_3': -16.27713966369629, 'loss_4': 0.15449413657188416, 'epoch': 28.09}
{'loss': 0.0095, 'grad_norm': 5.5460920333862305, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.00716149527579546, 'loss_2': 0.00238037109375, 'loss_3': -16.408710479736328, 'loss_4': 0.48551318049430847, 'epoch': 28.09}
{'loss': 0.0098, 'grad_norm': 4.6759443283081055, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.003160463646054268, 'loss_2': 0.006626129150390625, 'loss_3': -16.538284301757812, 'loss_4': -0.022174492478370667, 'epoch': 28.1}
{'loss': 0.0081, 'grad_norm': 4.811008453369141, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.004233762621879578, 'loss_2': 0.00390625, 'loss_3': -16.368759155273438, 'loss_4': 0.07161682844161987, 'epoch': 28.1}
{'loss': 0.0058, 'grad_norm': 4.662867546081543, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.004334327299147844, 'loss_2': 0.0014944076538085938, 'loss_3': -16.30680274963379, 'loss_4': -0.23302489519119263, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 14:19:36,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:36,243 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:30<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:43,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010526668280363083, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.897, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007663737051188946, 'eval_loss_2': 0.0028629302978515625, 'eval_loss_3': -18.148616790771484, 'eval_loss_4': 0.06736354529857635, 'epoch': 28.11}
{'loss': 0.0079, 'grad_norm': 4.9266510009765625, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.003503155428916216, 'loss_2': 0.00438690185546875, 'loss_3': -16.19306755065918, 'loss_4': -0.2384301871061325, 'epoch': 28.12}
{'loss': 0.0027, 'grad_norm': 4.282334804534912, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.0026642153970897198, 'loss_2': 4.684925079345703e-05, 'loss_3': -16.62971305847168, 'loss_4': 0.03953292965888977, 'epoch': 28.12}
{'loss': 0.0051, 'grad_norm': 5.027547836303711, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0030853331554681063, 'loss_2': 0.002010345458984375, 'loss_3': -16.191329956054688, 'loss_4': 0.15667393803596497, 'epoch': 28.13}
{'loss': 0.0326, 'grad_norm': 9.295876502990723, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.02747603878378868, 'loss_2': 0.005157470703125, 'loss_3': -16.49847984313965, 'loss_4': -0.23047545552253723, 'epoch': 28.13}
{'loss': 0.0043, 'grad_norm': 4.352825164794922, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.0027466118335723877, 'loss_2': 0.001556396484375, 'loss_3': -16.47378158569336, 'loss_4': -0.2349444478750229, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 14:19:43,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:43,576 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:37<05:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:50,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010538332164287567, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007596306037157774, 'eval_loss_2': 0.002942025661468506, 'eval_loss_3': -18.149822235107422, 'eval_loss_4': 0.040095869451761246, 'epoch': 28.14}
{'loss': 0.0058, 'grad_norm': 5.1850152015686035, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.005452918820083141, 'loss_2': 0.0003719329833984375, 'loss_3': -16.433670043945312, 'loss_4': -0.02091999351978302, 'epoch': 28.15}
{'loss': 0.0056, 'grad_norm': 3.9415016174316406, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.00285953376442194, 'loss_2': 0.002735137939453125, 'loss_3': -16.368675231933594, 'loss_4': 0.3781226873397827, 'epoch': 28.15}
{'loss': 0.0081, 'grad_norm': 4.887260913848877, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.004479260183870792, 'loss_2': 0.0035724639892578125, 'loss_3': -16.43917465209961, 'loss_4': 0.32585665583610535, 'epoch': 28.16}
{'loss': 0.0653, 'grad_norm': 9.14224624633789, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.06099662184715271, 'loss_2': 0.00433349609375, 'loss_3': -16.367889404296875, 'loss_4': 0.3648233413696289, 'epoch': 28.16}
{'loss': 0.013, 'grad_norm': 4.90354585647583, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.005756794009357691, 'loss_2': 0.00724029541015625, 'loss_3': -16.204551696777344, 'loss_4': -0.09982635825872421, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 14:19:50,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:50,909 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:45<05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:58,256 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010694773867726326, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007734808139503002, 'eval_loss_2': 0.0029599666595458984, 'eval_loss_3': -18.154850006103516, 'eval_loss_4': 0.016362760215997696, 'epoch': 28.17}
{'loss': 0.0107, 'grad_norm': 5.318182945251465, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.00793564785271883, 'loss_2': 0.0027313232421875, 'loss_3': -16.425212860107422, 'loss_4': 0.05989654362201691, 'epoch': 28.17}
{'loss': 0.0058, 'grad_norm': 4.581634521484375, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.00333952228538692, 'loss_2': 0.002471923828125, 'loss_3': -16.395843505859375, 'loss_4': -0.028989620506763458, 'epoch': 28.18}
{'loss': 0.0141, 'grad_norm': 7.030471324920654, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.011186706833541393, 'loss_2': 0.00290679931640625, 'loss_3': -16.25237274169922, 'loss_4': -0.24767044186592102, 'epoch': 28.19}
{'loss': 0.0053, 'grad_norm': 4.676886558532715, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.003001274075359106, 'loss_2': 0.002307891845703125, 'loss_3': -16.28980255126953, 'loss_4': 0.40896373987197876, 'epoch': 28.19}
{'loss': 0.0064, 'grad_norm': 4.8037872314453125, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.0033298851922154427, 'loss_2': 0.003063201904296875, 'loss_3': -16.455047607421875, 'loss_4': 0.17574521899223328, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 14:19:58,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:58,256 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:52<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:05,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01079210452735424, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.707, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007794349454343319, 'eval_loss_2': 0.002997756004333496, 'eval_loss_3': -18.157533645629883, 'eval_loss_4': 0.018161065876483917, 'epoch': 28.2}
{'loss': 0.0063, 'grad_norm': 4.340441703796387, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.0035081300884485245, 'loss_2': 0.0027923583984375, 'loss_3': -16.507400512695312, 'loss_4': 0.08121758699417114, 'epoch': 28.2}
{'loss': 0.0083, 'grad_norm': 4.791752338409424, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.0040877750143408775, 'loss_2': 0.00424957275390625, 'loss_3': -16.480701446533203, 'loss_4': 0.16025923192501068, 'epoch': 28.21}
{'loss': 0.0085, 'grad_norm': 4.9231414794921875, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.004736852832138538, 'loss_2': 0.0038089752197265625, 'loss_3': -16.462495803833008, 'loss_4': 0.35691317915916443, 'epoch': 28.22}
{'loss': 0.0046, 'grad_norm': 4.39983606338501, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.0024348737206310034, 'loss_2': 0.002178192138671875, 'loss_3': -16.188365936279297, 'loss_4': 0.5826199650764465, 'epoch': 28.22}
{'loss': 0.0091, 'grad_norm': 5.161401748657227, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.005441691260784864, 'loss_2': 0.0036449432373046875, 'loss_3': -16.134458541870117, 'loss_4': 0.4205000400543213, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 14:20:05,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:05,605 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [2:00:00<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:12,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010970047675073147, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.94, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007882109843194485, 'eval_loss_2': 0.003087937831878662, 'eval_loss_3': -18.155733108520508, 'eval_loss_4': 0.03415763005614281, 'epoch': 28.23}
{'loss': 0.0051, 'grad_norm': 4.604658603668213, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.002574479440227151, 'loss_2': 0.0025634765625, 'loss_3': -16.559776306152344, 'loss_4': -0.0051616281270980835, 'epoch': 28.23}
{'loss': 0.0088, 'grad_norm': 5.307153701782227, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.0053689973428845406, 'loss_2': 0.0034465789794921875, 'loss_3': -16.519269943237305, 'loss_4': -0.04786960035562515, 'epoch': 28.24}
{'loss': 0.0105, 'grad_norm': 6.709049701690674, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.009045970626175404, 'loss_2': 0.0014467239379882812, 'loss_3': -16.61711883544922, 'loss_4': -0.34331655502319336, 'epoch': 28.24}
{'loss': 0.0088, 'grad_norm': 4.9106550216674805, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.002614411059767008, 'loss_2': 0.00614166259765625, 'loss_3': -16.39942741394043, 'loss_4': 0.014121085405349731, 'epoch': 28.25}
{'loss': 0.0065, 'grad_norm': 4.94315767288208, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.004319390747696161, 'loss_2': 0.002166748046875, 'loss_3': -16.324634552001953, 'loss_4': 0.4101208746433258, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 14:20:12,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:12,959 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [2:00:07<05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:20,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010883336886763573, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.357, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007640873547643423, 'eval_loss_2': 0.0032424628734588623, 'eval_loss_3': -18.15346336364746, 'eval_loss_4': 0.0478966049849987, 'epoch': 28.26}
{'loss': 0.0844, 'grad_norm': 16.08104133605957, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.08179701864719391, 'loss_2': 0.002574920654296875, 'loss_3': -16.468843460083008, 'loss_4': 0.326003760099411, 'epoch': 28.26}
{'loss': 0.0056, 'grad_norm': 4.5711164474487305, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.001671754289418459, 'loss_2': 0.00394439697265625, 'loss_3': -16.548349380493164, 'loss_4': -0.305614173412323, 'epoch': 28.27}
{'loss': 0.0048, 'grad_norm': 4.381049156188965, 'learning_rate': 1.75e-06, 'loss_1': 0.004500375594943762, 'loss_2': 0.0003371238708496094, 'loss_3': -16.312255859375, 'loss_4': 0.33553144335746765, 'epoch': 28.27}
{'loss': 0.0055, 'grad_norm': 4.616893768310547, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.0028917002491652966, 'loss_2': 0.002582550048828125, 'loss_3': -16.35851287841797, 'loss_4': 0.14936846494674683, 'epoch': 28.28}
{'loss': 0.0057, 'grad_norm': 4.445621013641357, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.003914025146514177, 'loss_2': 0.001766204833984375, 'loss_3': -16.134267807006836, 'loss_4': 0.18483829498291016, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 14:20:20,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:20,301 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [2:00:14<05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:27,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0106019526720047, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007461787201464176, 'eval_loss_2': 0.003140166401863098, 'eval_loss_3': -18.156055450439453, 'eval_loss_4': 0.061270661652088165, 'epoch': 28.28}
{'loss': 0.0096, 'grad_norm': 6.134281635284424, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.009570655412971973, 'loss_2': 5.4001808166503906e-05, 'loss_3': -16.3358097076416, 'loss_4': 0.5181334018707275, 'epoch': 28.29}
{'loss': 0.0046, 'grad_norm': 5.097063064575195, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.003691182704642415, 'loss_2': 0.0009493827819824219, 'loss_3': -16.487483978271484, 'loss_4': 0.36851876974105835, 'epoch': 28.3}
{'loss': 0.0129, 'grad_norm': 4.540949821472168, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.00435441080480814, 'loss_2': 0.0085906982421875, 'loss_3': -16.493858337402344, 'loss_4': 0.3939823508262634, 'epoch': 28.3}
{'loss': 0.0071, 'grad_norm': 5.288880825042725, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.005944864358752966, 'loss_2': 0.001178741455078125, 'loss_3': -16.31326675415039, 'loss_4': -0.09229215979576111, 'epoch': 28.31}
{'loss': 0.0086, 'grad_norm': 4.422756195068359, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.003534382674843073, 'loss_2': 0.0050506591796875, 'loss_3': -16.345155715942383, 'loss_4': 0.1431690752506256, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 14:20:27,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:27,637 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [2:00:22<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:34,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010524218901991844, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00736955413594842, 'eval_loss_2': 0.003154665231704712, 'eval_loss_3': -18.15361785888672, 'eval_loss_4': 0.06310476362705231, 'epoch': 28.31}
{'loss': 0.0049, 'grad_norm': 4.838766098022461, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.003110635792836547, 'loss_2': 0.001743316650390625, 'loss_3': -16.58343505859375, 'loss_4': 0.020020198076963425, 'epoch': 28.32}
{'loss': 0.0829, 'grad_norm': 14.642362594604492, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.07949846237897873, 'loss_2': 0.00339508056640625, 'loss_3': -16.140132904052734, 'loss_4': 0.4814358949661255, 'epoch': 28.33}
{'loss': 0.0049, 'grad_norm': 5.071018695831299, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.0032027738634496927, 'loss_2': 0.00168609619140625, 'loss_3': -16.444149017333984, 'loss_4': 0.2319890856742859, 'epoch': 28.33}
{'loss': 0.0076, 'grad_norm': 5.548695087432861, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.005558814387768507, 'loss_2': 0.00199127197265625, 'loss_3': -16.414012908935547, 'loss_4': 0.1841813325881958, 'epoch': 28.34}
{'loss': 0.0076, 'grad_norm': 4.386424541473389, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0027728299610316753, 'loss_2': 0.004833221435546875, 'loss_3': -16.31690216064453, 'loss_4': 0.2233210653066635, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 14:20:34,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:34,976 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:29<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:42,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010485121980309486, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0074191223829984665, 'eval_loss_2': 0.00306599959731102, 'eval_loss_3': -18.156082153320312, 'eval_loss_4': 0.06885635852813721, 'epoch': 28.34}
{'loss': 0.0058, 'grad_norm': 4.629230976104736, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.0028346083126962185, 'loss_2': 0.002933502197265625, 'loss_3': -16.375003814697266, 'loss_4': 0.7686322927474976, 'epoch': 28.35}
{'loss': 0.0062, 'grad_norm': 5.0161237716674805, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.002639013808220625, 'loss_2': 0.00356292724609375, 'loss_3': -16.478160858154297, 'loss_4': -0.018247172236442566, 'epoch': 28.35}
{'loss': 0.01, 'grad_norm': 4.973421573638916, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.004510030150413513, 'loss_2': 0.005462646484375, 'loss_3': -16.317983627319336, 'loss_4': 0.8032846450805664, 'epoch': 28.36}
{'loss': 0.0069, 'grad_norm': 4.474080562591553, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.0027560691814869642, 'loss_2': 0.004184722900390625, 'loss_3': -16.18582534790039, 'loss_4': 0.14908599853515625, 'epoch': 28.37}
{'loss': 0.0119, 'grad_norm': 5.604578971862793, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.00519065884873271, 'loss_2': 0.006717681884765625, 'loss_3': -16.339183807373047, 'loss_4': -0.43681085109710693, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 14:20:42,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:42,326 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:36<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:49,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010259877890348434, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007323395926505327, 'eval_loss_2': 0.0029364824295043945, 'eval_loss_3': -18.154895782470703, 'eval_loss_4': 0.06042642146348953, 'epoch': 28.37}
{'loss': 0.0053, 'grad_norm': 4.438510894775391, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.003335739253088832, 'loss_2': 0.0019159317016601562, 'loss_3': -16.359516143798828, 'loss_4': -0.14340521395206451, 'epoch': 28.38}
{'loss': 0.0041, 'grad_norm': 4.774592399597168, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0014760923804715276, 'loss_2': 0.0025844573974609375, 'loss_3': -16.517213821411133, 'loss_4': 0.018845953047275543, 'epoch': 28.38}
{'loss': 0.0058, 'grad_norm': 4.637543678283691, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.0031064630020409822, 'loss_2': 0.002681732177734375, 'loss_3': -16.376564025878906, 'loss_4': 0.39897075295448303, 'epoch': 28.39}
{'loss': 0.005, 'grad_norm': 4.7061052322387695, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.002957115415483713, 'loss_2': 0.002033233642578125, 'loss_3': -16.420780181884766, 'loss_4': -0.02393287420272827, 'epoch': 28.4}
{'loss': 0.0082, 'grad_norm': 4.921332359313965, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.003529080655425787, 'loss_2': 0.00469207763671875, 'loss_3': -16.186920166015625, 'loss_4': 0.4258691668510437, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 14:20:49,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:49,671 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:44<04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:57,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010195445269346237, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.355, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007207613438367844, 'eval_loss_2': 0.0029878318309783936, 'eval_loss_3': -18.15702247619629, 'eval_loss_4': 0.045991186052560806, 'epoch': 28.4}
{'loss': 0.0035, 'grad_norm': 4.770619869232178, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.0026638696435838938, 'loss_2': 0.0008449554443359375, 'loss_3': -16.475257873535156, 'loss_4': 0.20634765923023224, 'epoch': 28.41}
{'loss': 0.0087, 'grad_norm': 4.606960773468018, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.0031604741234332323, 'loss_2': 0.005573272705078125, 'loss_3': -16.296035766601562, 'loss_4': -0.43078774213790894, 'epoch': 28.41}
{'loss': 0.0144, 'grad_norm': 4.384562015533447, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.005035281181335449, 'loss_2': 0.00933837890625, 'loss_3': -16.28731346130371, 'loss_4': 0.23984263837337494, 'epoch': 28.42}
{'loss': 0.0024, 'grad_norm': 4.359488010406494, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.0023469978477805853, 'loss_2': 5.316734313964844e-05, 'loss_3': -16.48212432861328, 'loss_4': 0.12586548924446106, 'epoch': 28.42}
{'loss': 0.0042, 'grad_norm': 4.967838764190674, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.0031732453498989344, 'loss_2': 0.0010023117065429688, 'loss_3': -16.514074325561523, 'loss_4': -0.4384538531303406, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 14:20:57,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:57,038 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:51<04:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:04,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00998727697879076, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0069859703071415424, 'eval_loss_2': 0.0030013062059879303, 'eval_loss_3': -18.161550521850586, 'eval_loss_4': 0.034171927720308304, 'epoch': 28.43}
{'loss': 0.0129, 'grad_norm': 8.536491394042969, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.008887985721230507, 'loss_2': 0.00402069091796875, 'loss_3': -16.51581573486328, 'loss_4': 0.208301842212677, 'epoch': 28.44}
{'loss': 0.0061, 'grad_norm': 4.907325744628906, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.001206325483508408, 'loss_2': 0.004917144775390625, 'loss_3': -16.51123809814453, 'loss_4': 0.2029622495174408, 'epoch': 28.44}
{'loss': 0.0075, 'grad_norm': 5.664411544799805, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.00583783769980073, 'loss_2': 0.0016946792602539062, 'loss_3': -16.34772491455078, 'loss_4': -0.04741890728473663, 'epoch': 28.45}
{'loss': 0.0084, 'grad_norm': 4.680379867553711, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.002411792054772377, 'loss_2': 0.006011962890625, 'loss_3': -16.451257705688477, 'loss_4': 0.3462141156196594, 'epoch': 28.45}
{'loss': 0.0046, 'grad_norm': 4.938003063201904, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.004118729382753372, 'loss_2': 0.0005254745483398438, 'loss_3': -16.51004409790039, 'loss_4': -0.11524288356304169, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 14:21:04,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:04,386 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:58<04:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:11,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010153473354876041, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007128780707716942, 'eval_loss_2': 0.003024693578481674, 'eval_loss_3': -18.165245056152344, 'eval_loss_4': 0.017890464514493942, 'epoch': 28.46}
{'loss': 0.0041, 'grad_norm': 5.084381103515625, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.0029711418319493532, 'loss_2': 0.0010814666748046875, 'loss_3': -16.426494598388672, 'loss_4': 0.21784931421279907, 'epoch': 28.47}
{'loss': 0.0111, 'grad_norm': 5.330660820007324, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.009642071090638638, 'loss_2': 0.0014629364013671875, 'loss_3': -16.42105484008789, 'loss_4': -0.19063061475753784, 'epoch': 28.47}
{'loss': 0.0092, 'grad_norm': 4.934937953948975, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.007089835591614246, 'loss_2': 0.002086639404296875, 'loss_3': -16.2705078125, 'loss_4': 0.3031875789165497, 'epoch': 28.48}
{'loss': 0.0098, 'grad_norm': 5.54172420501709, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.006616841536015272, 'loss_2': 0.00313568115234375, 'loss_3': -16.333477020263672, 'loss_4': 0.392764151096344, 'epoch': 28.48}
{'loss': 0.0084, 'grad_norm': 5.270076751708984, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.007514741737395525, 'loss_2': 0.000926971435546875, 'loss_3': -16.46258544921875, 'loss_4': -0.015222504734992981, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 14:21:11,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:11,744 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:01:06<04:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:19,101 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0104898102581501, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007368724327534437, 'eval_loss_2': 0.0031210854649543762, 'eval_loss_3': -18.168624877929688, 'eval_loss_4': 0.005271933972835541, 'epoch': 28.49}
{'loss': 0.0108, 'grad_norm': 4.820311546325684, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.007053128909319639, 'loss_2': 0.00371551513671875, 'loss_3': -16.534692764282227, 'loss_4': 0.461050808429718, 'epoch': 28.49}
{'loss': 0.0039, 'grad_norm': 4.597455024719238, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0024676041211932898, 'loss_2': 0.0014410018920898438, 'loss_3': -16.39879035949707, 'loss_4': 0.03273969888687134, 'epoch': 28.5}
{'loss': 0.0108, 'grad_norm': 4.923631191253662, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.0032886401750147343, 'loss_2': 0.0074615478515625, 'loss_3': -16.35457420349121, 'loss_4': -0.4772637188434601, 'epoch': 28.51}
{'loss': 0.0043, 'grad_norm': 4.327954292297363, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0019034496508538723, 'loss_2': 0.002384185791015625, 'loss_3': -16.468128204345703, 'loss_4': 0.3385540246963501, 'epoch': 28.51}
{'loss': 0.0062, 'grad_norm': 6.208217144012451, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.00572355417534709, 'loss_2': 0.0004558563232421875, 'loss_3': -16.500852584838867, 'loss_4': 0.2022542506456375, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 14:21:19,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:19,101 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:01:13<04:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:26,464 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010446863248944283, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.324, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007239991333335638, 'eval_loss_2': 0.003206871449947357, 'eval_loss_3': -18.167158126831055, 'eval_loss_4': -0.012926053255796432, 'epoch': 28.52}
{'loss': 0.0089, 'grad_norm': 4.309494495391846, 'learning_rate': 1.5e-06, 'loss_1': 0.0012641107896342874, 'loss_2': 0.00762176513671875, 'loss_3': -16.429386138916016, 'loss_4': -0.20884768664836884, 'epoch': 28.52}
{'loss': 0.0093, 'grad_norm': 4.614680767059326, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.005835201125591993, 'loss_2': 0.003498077392578125, 'loss_3': -16.52922248840332, 'loss_4': -0.20751555263996124, 'epoch': 28.53}
{'loss': 0.0108, 'grad_norm': 5.412717342376709, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.007287574000656605, 'loss_2': 0.00351715087890625, 'loss_3': -16.495708465576172, 'loss_4': 0.12849700450897217, 'epoch': 28.53}
{'loss': 0.014, 'grad_norm': 8.353389739990234, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.0097236018627882, 'loss_2': 0.004276275634765625, 'loss_3': -16.46267318725586, 'loss_4': -0.20590749382972717, 'epoch': 28.54}
{'loss': 0.0241, 'grad_norm': 9.949502944946289, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.015171636827290058, 'loss_2': 0.0088958740234375, 'loss_3': -16.46912384033203, 'loss_4': 0.32221823930740356, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 14:21:26,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:26,464 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:01:20<04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:33,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010425351560115814, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.547, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007296279538422823, 'eval_loss_2': 0.0031290724873542786, 'eval_loss_3': -18.163904190063477, 'eval_loss_4': -0.01967216096818447, 'epoch': 28.55}
{'loss': 0.0056, 'grad_norm': 5.442468643188477, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.005086236633360386, 'loss_2': 0.0004658699035644531, 'loss_3': -16.458547592163086, 'loss_4': 0.227306067943573, 'epoch': 28.55}
{'loss': 0.0079, 'grad_norm': 4.624392986297607, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0027417964302003384, 'loss_2': 0.005146026611328125, 'loss_3': -16.354990005493164, 'loss_4': -0.022848322987556458, 'epoch': 28.56}
{'loss': 0.0119, 'grad_norm': 7.5333733558654785, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.007975569926202297, 'loss_2': 0.00391387939453125, 'loss_3': -16.30133819580078, 'loss_4': -0.009889766573905945, 'epoch': 28.56}
{'loss': 0.0165, 'grad_norm': 6.9989752769470215, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.010776174254715443, 'loss_2': 0.0056915283203125, 'loss_3': -16.381107330322266, 'loss_4': 0.16771741211414337, 'epoch': 28.57}
{'loss': 0.0115, 'grad_norm': 4.673520088195801, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.005947371479123831, 'loss_2': 0.0055084228515625, 'loss_3': -16.45926284790039, 'loss_4': 0.4882875084877014, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 14:21:33,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:33,822 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:28<04:16,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 14:21:41,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010210458189249039, 'eval_runtime': 3.8182, 'eval_samples_per_second': 268.192, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007221895270049572, 'eval_loss_2': 0.002988561987876892, 'eval_loss_3': -18.16520118713379, 'eval_loss_4': -0.020651711151003838, 'epoch': 28.58}
{'loss': 0.0078, 'grad_norm': 4.278928279876709, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.003593358676880598, 'loss_2': 0.00423431396484375, 'loss_3': -16.301925659179688, 'loss_4': -0.02198806405067444, 'epoch': 28.58}
{'loss': 0.0071, 'grad_norm': 4.800826072692871, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.0038461775984615088, 'loss_2': 0.003261566162109375, 'loss_3': -16.330280303955078, 'loss_4': 0.09824557602405548, 'epoch': 28.59}
{'loss': 0.0101, 'grad_norm': 4.958060264587402, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.005157079081982374, 'loss_2': 0.004913330078125, 'loss_3': -16.41755485534668, 'loss_4': 0.45571619272232056, 'epoch': 28.59}
{'loss': 0.0077, 'grad_norm': 4.948945999145508, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.003780683735385537, 'loss_2': 0.00394439697265625, 'loss_3': -16.450515747070312, 'loss_4': -0.22854718565940857, 'epoch': 28.6}
{'loss': 0.0069, 'grad_norm': 5.193175792694092, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.00628442969173193, 'loss_2': 0.0006017684936523438, 'loss_3': -16.472742080688477, 'loss_4': 0.2896360754966736, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 14:21:41,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:41,393 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:35<04:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:48,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009904555976390839, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0069819167256355286, 'eval_loss_2': 0.00292263925075531, 'eval_loss_3': -18.162267684936523, 'eval_loss_4': -0.03329288959503174, 'epoch': 28.6}
{'loss': 0.0017, 'grad_norm': 4.483054161071777, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0015729408478364348, 'loss_2': 0.00012302398681640625, 'loss_3': -16.485069274902344, 'loss_4': 0.2463427484035492, 'epoch': 28.61}
{'loss': 0.0056, 'grad_norm': 5.406814098358154, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.004963081795722246, 'loss_2': 0.0006270408630371094, 'loss_3': -16.26846694946289, 'loss_4': 0.14427855610847473, 'epoch': 28.62}
{'loss': 0.0103, 'grad_norm': 5.520562171936035, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.008193275891244411, 'loss_2': 0.002063751220703125, 'loss_3': -16.476234436035156, 'loss_4': -0.33277636766433716, 'epoch': 28.62}
{'loss': 0.0089, 'grad_norm': 4.980992794036865, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.003151046810671687, 'loss_2': 0.005794525146484375, 'loss_3': -16.386077880859375, 'loss_4': -0.2919479012489319, 'epoch': 28.63}
{'loss': 0.0031, 'grad_norm': 4.787758827209473, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.002393006347119808, 'loss_2': 0.0007314682006835938, 'loss_3': -16.448162078857422, 'loss_4': 0.16240975260734558, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 14:21:48,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:48,744 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:43<03:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:56,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010131100192666054, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007061521522700787, 'eval_loss_2': 0.003069579601287842, 'eval_loss_3': -18.1624755859375, 'eval_loss_4': -0.051393453031778336, 'epoch': 28.63}
{'loss': 0.0032, 'grad_norm': 4.740660190582275, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.0019121216610074043, 'loss_2': 0.00128173828125, 'loss_3': -16.463863372802734, 'loss_4': -0.35413873195648193, 'epoch': 28.64}
{'loss': 0.0182, 'grad_norm': 5.868687152862549, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.0097060427069664, 'loss_2': 0.00849151611328125, 'loss_3': -16.44586181640625, 'loss_4': 0.030961833894252777, 'epoch': 28.65}
{'loss': 0.0144, 'grad_norm': 4.818749904632568, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.006242373958230019, 'loss_2': 0.0081787109375, 'loss_3': -16.399032592773438, 'loss_4': -0.3864375352859497, 'epoch': 28.65}
{'loss': 0.0065, 'grad_norm': 4.588129043579102, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.004105337895452976, 'loss_2': 0.00241851806640625, 'loss_3': -16.26003646850586, 'loss_4': -0.14471811056137085, 'epoch': 28.66}
{'loss': 0.0066, 'grad_norm': 4.453715801239014, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.003469168208539486, 'loss_2': 0.00315093994140625, 'loss_3': -16.46725845336914, 'loss_4': 0.6383322477340698, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 14:21:56,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:56,093 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:50<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:03,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010035212151706219, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007012734655290842, 'eval_loss_2': 0.0030224770307540894, 'eval_loss_3': -18.165687561035156, 'eval_loss_4': -0.060283634811639786, 'epoch': 28.66}
{'loss': 0.0075, 'grad_norm': 4.534671306610107, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.003754436271265149, 'loss_2': 0.003704071044921875, 'loss_3': -16.358156204223633, 'loss_4': 0.02003663405776024, 'epoch': 28.67}
{'loss': 0.0125, 'grad_norm': 4.961921215057373, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.006348218768835068, 'loss_2': 0.00611114501953125, 'loss_3': -16.414941787719727, 'loss_4': 0.1801915168762207, 'epoch': 28.67}
{'loss': 0.0092, 'grad_norm': 6.038795471191406, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.006183933932334185, 'loss_2': 0.003025054931640625, 'loss_3': -16.374340057373047, 'loss_4': 0.33644330501556396, 'epoch': 28.68}
{'loss': 0.0107, 'grad_norm': 6.7894697189331055, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.007867243140935898, 'loss_2': 0.002796173095703125, 'loss_3': -16.230709075927734, 'loss_4': -0.11229420453310013, 'epoch': 28.69}
{'loss': 0.0072, 'grad_norm': 4.737990379333496, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.006695257034152746, 'loss_2': 0.0004761219024658203, 'loss_3': -16.26893424987793, 'loss_4': -0.06338483095169067, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 14:22:03,447 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:03,447 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:57<03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:10,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010037465021014214, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007014406844973564, 'eval_loss_2': 0.0030230581760406494, 'eval_loss_3': -18.165977478027344, 'eval_loss_4': -0.044467467814683914, 'epoch': 28.69}
{'loss': 0.006, 'grad_norm': 4.979713439941406, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.002525532618165016, 'loss_2': 0.00348663330078125, 'loss_3': -16.362037658691406, 'loss_4': -0.05872756987810135, 'epoch': 28.7}
{'loss': 0.0031, 'grad_norm': 4.533528804779053, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.002596251666545868, 'loss_2': 0.0005497932434082031, 'loss_3': -16.36398696899414, 'loss_4': -0.2073911726474762, 'epoch': 28.7}
{'loss': 0.0147, 'grad_norm': 7.235666751861572, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.009160693734884262, 'loss_2': 0.005584716796875, 'loss_3': -16.33001708984375, 'loss_4': -0.3014194667339325, 'epoch': 28.71}
{'loss': 0.0041, 'grad_norm': 4.529581069946289, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.0032663478050380945, 'loss_2': 0.000789642333984375, 'loss_3': -16.568315505981445, 'loss_4': -0.22406622767448425, 'epoch': 28.72}
{'loss': 0.002, 'grad_norm': 4.515298366546631, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.0018335575005039573, 'loss_2': 0.0001761913299560547, 'loss_3': -16.579143524169922, 'loss_4': -0.021455153822898865, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 14:22:10,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:10,800 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:02:05<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:18,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010138174518942833, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.802, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006994760129600763, 'eval_loss_2': 0.003143414855003357, 'eval_loss_3': -18.165302276611328, 'eval_loss_4': -0.018626274541020393, 'epoch': 28.72}
{'loss': 0.0141, 'grad_norm': 6.292812824249268, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.007844630628824234, 'loss_2': 0.00624847412109375, 'loss_3': -16.365060806274414, 'loss_4': -0.3525298833847046, 'epoch': 28.73}
{'loss': 0.0062, 'grad_norm': 4.565369129180908, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.0012808687752112746, 'loss_2': 0.00493621826171875, 'loss_3': -16.319210052490234, 'loss_4': 0.42328310012817383, 'epoch': 28.73}
{'loss': 0.0153, 'grad_norm': 4.51153039932251, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.006449500098824501, 'loss_2': 0.008819580078125, 'loss_3': -16.379283905029297, 'loss_4': -0.29066115617752075, 'epoch': 28.74}
{'loss': 0.0044, 'grad_norm': 4.5831780433654785, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.0033242609351873398, 'loss_2': 0.0010747909545898438, 'loss_3': -16.54025650024414, 'loss_4': 0.15763837099075317, 'epoch': 28.74}
{'loss': 0.0027, 'grad_norm': 4.566948413848877, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.002384212799370289, 'loss_2': 0.00031566619873046875, 'loss_3': -16.14545440673828, 'loss_4': 0.10227155685424805, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 14:22:18,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:18,152 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:02:12<03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:25,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009955382905900478, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006814127787947655, 'eval_loss_2': 0.003141254186630249, 'eval_loss_3': -18.166519165039062, 'eval_loss_4': -0.01036842167377472, 'epoch': 28.75}
{'loss': 0.0051, 'grad_norm': 4.687997817993164, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.0025526918470859528, 'loss_2': 0.002590179443359375, 'loss_3': -16.562694549560547, 'loss_4': 0.08515620231628418, 'epoch': 28.76}
{'loss': 0.0041, 'grad_norm': 4.61863374710083, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.002912727417424321, 'loss_2': 0.001171112060546875, 'loss_3': -16.476337432861328, 'loss_4': -0.07765887677669525, 'epoch': 28.76}
{'loss': 0.0051, 'grad_norm': 5.105288505554199, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.0043699974194169044, 'loss_2': 0.0007333755493164062, 'loss_3': -16.432273864746094, 'loss_4': -0.44250941276550293, 'epoch': 28.77}
{'loss': 0.0049, 'grad_norm': 4.636153697967529, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.004512767773121595, 'loss_2': 0.0003647804260253906, 'loss_3': -16.270357131958008, 'loss_4': 0.2470526546239853, 'epoch': 28.77}
{'loss': 0.0079, 'grad_norm': 4.752781867980957, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.0040076663717627525, 'loss_2': 0.00392913818359375, 'loss_3': -16.37700080871582, 'loss_4': 0.43577665090560913, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 14:22:25,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:25,506 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:02:19<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:32,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009888790547847748, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.987, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00670255720615387, 'eval_loss_2': 0.003186233341693878, 'eval_loss_3': -18.170597076416016, 'eval_loss_4': -0.02141629531979561, 'epoch': 28.78}
{'loss': 0.0151, 'grad_norm': 7.239068031311035, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.01120475959032774, 'loss_2': 0.0038547515869140625, 'loss_3': -16.519668579101562, 'loss_4': 0.27900955080986023, 'epoch': 28.78}
{'loss': 0.0084, 'grad_norm': 5.453845500946045, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.0066090659238398075, 'loss_2': 0.0018186569213867188, 'loss_3': -16.410423278808594, 'loss_4': 0.4849451780319214, 'epoch': 28.79}
{'loss': 0.0052, 'grad_norm': 4.954327583312988, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.003025127574801445, 'loss_2': 0.0021266937255859375, 'loss_3': -16.419185638427734, 'loss_4': -0.12890763580799103, 'epoch': 28.8}
{'loss': 0.0094, 'grad_norm': 5.022977352142334, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.004565507173538208, 'loss_2': 0.00481414794921875, 'loss_3': -16.311716079711914, 'loss_4': -0.5082893371582031, 'epoch': 28.8}
{'loss': 0.0173, 'grad_norm': 8.738457679748535, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.01589716225862503, 'loss_2': 0.0013933181762695312, 'loss_3': -16.381040573120117, 'loss_4': 0.2255377471446991, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 14:22:32,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:32,855 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:02:27<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:40,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009796392172574997, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.449, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006604998838156462, 'eval_loss_2': 0.003191392868757248, 'eval_loss_3': -18.169403076171875, 'eval_loss_4': -0.03367939963936806, 'epoch': 28.81}
{'loss': 0.0098, 'grad_norm': 5.014387607574463, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.006278711371123791, 'loss_2': 0.0035266876220703125, 'loss_3': -16.320322036743164, 'loss_4': -0.3459538519382477, 'epoch': 28.81}
{'loss': 0.0074, 'grad_norm': 5.6573052406311035, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.0038931092713028193, 'loss_2': 0.00348663330078125, 'loss_3': -16.40496826171875, 'loss_4': -0.27843570709228516, 'epoch': 28.82}
{'loss': 0.0083, 'grad_norm': 4.300149440765381, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.0031904198694974184, 'loss_2': 0.00514984130859375, 'loss_3': -16.368377685546875, 'loss_4': 0.17507679760456085, 'epoch': 28.83}
{'loss': 0.0139, 'grad_norm': 5.238825798034668, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.00374119495972991, 'loss_2': 0.01019287109375, 'loss_3': -16.301517486572266, 'loss_4': -0.38040682673454285, 'epoch': 28.83}
{'loss': 0.0078, 'grad_norm': 4.760654449462891, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.0032903319224715233, 'loss_2': 0.004550933837890625, 'loss_3': -16.345413208007812, 'loss_4': -0.020468801259994507, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 14:22:40,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:40,205 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:34<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:47,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009999146685004234, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006711682770401239, 'eval_loss_2': 0.0032874643802642822, 'eval_loss_3': -18.167587280273438, 'eval_loss_4': -0.04115819185972214, 'epoch': 28.84}
{'loss': 0.0158, 'grad_norm': 6.968020915985107, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.011504429392516613, 'loss_2': 0.0043182373046875, 'loss_3': -16.409202575683594, 'loss_4': -0.2914651036262512, 'epoch': 28.84}
{'loss': 0.0068, 'grad_norm': 5.150554180145264, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.0062795365229249, 'loss_2': 0.0005321502685546875, 'loss_3': -16.327239990234375, 'loss_4': -0.3010881841182709, 'epoch': 28.85}
{'loss': 0.006, 'grad_norm': 4.853694438934326, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.004909108858555555, 'loss_2': 0.0010471343994140625, 'loss_3': -16.323043823242188, 'loss_4': 0.2015068233013153, 'epoch': 28.85}
{'loss': 0.0097, 'grad_norm': 6.648057460784912, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.00826779380440712, 'loss_2': 0.0014801025390625, 'loss_3': -16.437705993652344, 'loss_4': -0.20137418806552887, 'epoch': 28.86}
{'loss': 0.004, 'grad_norm': 4.622865676879883, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.003921640105545521, 'loss_2': 9.715557098388672e-05, 'loss_3': -16.485820770263672, 'loss_4': -0.5601954460144043, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 14:22:47,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:47,552 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:41<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:54,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010023328475654125, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006812887731939554, 'eval_loss_2': 0.0032104402780532837, 'eval_loss_3': -18.16745948791504, 'eval_loss_4': -0.04916848987340927, 'epoch': 28.87}
{'loss': 0.0052, 'grad_norm': 5.427849292755127, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.005005691200494766, 'loss_2': 0.00014710426330566406, 'loss_3': -16.523887634277344, 'loss_4': -0.2574862241744995, 'epoch': 28.87}
{'loss': 0.0249, 'grad_norm': 9.970785140991211, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.02291896939277649, 'loss_2': 0.0019989013671875, 'loss_3': -16.319915771484375, 'loss_4': 0.111046202480793, 'epoch': 28.88}
{'loss': 0.0118, 'grad_norm': 4.685317039489746, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.002020149724557996, 'loss_2': 0.0097503662109375, 'loss_3': -16.446224212646484, 'loss_4': -0.1260460466146469, 'epoch': 28.88}
{'loss': 0.0091, 'grad_norm': 6.751065254211426, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.009064615704119205, 'loss_2': 6.079673767089844e-05, 'loss_3': -16.5124568939209, 'loss_4': -0.10931821912527084, 'epoch': 28.89}
{'loss': 0.0121, 'grad_norm': 5.028708457946777, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.010270725004374981, 'loss_2': 0.0018329620361328125, 'loss_3': -16.344449996948242, 'loss_4': -0.29461967945098877, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 14:22:54,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:54,898 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:49<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:02,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009807724505662918, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0067808665335178375, 'eval_loss_2': 0.0030268579721450806, 'eval_loss_3': -18.16431999206543, 'eval_loss_4': -0.05042333900928497, 'epoch': 28.9}
{'loss': 0.0038, 'grad_norm': 4.705441474914551, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.0032118966337293386, 'loss_2': 0.0005884170532226562, 'loss_3': -16.294445037841797, 'loss_4': -0.1403104066848755, 'epoch': 28.9}
{'loss': 0.0097, 'grad_norm': 6.029266357421875, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.00714105786755681, 'loss_2': 0.0025310516357421875, 'loss_3': -16.49144744873047, 'loss_4': -0.09758643805980682, 'epoch': 28.91}
{'loss': 0.0061, 'grad_norm': 4.49777889251709, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.004476584494113922, 'loss_2': 0.0016450881958007812, 'loss_3': -16.216350555419922, 'loss_4': -0.08507643640041351, 'epoch': 28.91}
{'loss': 0.002, 'grad_norm': 4.588817596435547, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.0018219772027805448, 'loss_2': 0.00013828277587890625, 'loss_3': -16.573314666748047, 'loss_4': -0.16375645995140076, 'epoch': 28.92}
{'loss': 0.0067, 'grad_norm': 5.104787826538086, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.003572358749806881, 'loss_2': 0.0031490325927734375, 'loss_3': -16.392112731933594, 'loss_4': 0.2616654336452484, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 14:23:02,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:02,243 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:56<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:09,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009695209562778473, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0067414576187729836, 'eval_loss_2': 0.002953752875328064, 'eval_loss_3': -18.16421127319336, 'eval_loss_4': -0.04145348072052002, 'epoch': 28.92}
{'loss': 0.0132, 'grad_norm': 5.935710906982422, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.006775295827537775, 'loss_2': 0.00638580322265625, 'loss_3': -16.043697357177734, 'loss_4': 0.3105757236480713, 'epoch': 28.93}
{'loss': 0.0028, 'grad_norm': 4.591886520385742, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.002438605995848775, 'loss_2': 0.0003535747528076172, 'loss_3': -16.424325942993164, 'loss_4': 0.3231133818626404, 'epoch': 28.94}
{'loss': 0.0033, 'grad_norm': 4.770299434661865, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.002991166664287448, 'loss_2': 0.00033783912658691406, 'loss_3': -16.254573822021484, 'loss_4': -0.3217097520828247, 'epoch': 28.94}
{'loss': 0.0114, 'grad_norm': 5.149359703063965, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.008544030599296093, 'loss_2': 0.00289154052734375, 'loss_3': -16.36286163330078, 'loss_4': 0.6249154806137085, 'epoch': 28.95}
{'loss': 0.0083, 'grad_norm': 5.043550491333008, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.005479660350829363, 'loss_2': 0.002777099609375, 'loss_3': -16.548437118530273, 'loss_4': -0.18198412656784058, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 14:23:09,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:09,579 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:03:03<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:16,924 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009915094822645187, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006854150909930468, 'eval_loss_2': 0.003060944378376007, 'eval_loss_3': -18.1629638671875, 'eval_loss_4': -0.03922406956553459, 'epoch': 28.95}
{'loss': 0.0046, 'grad_norm': 4.650325775146484, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.0026960442773997784, 'loss_2': 0.0018968582153320312, 'loss_3': -16.619644165039062, 'loss_4': 0.13316693902015686, 'epoch': 28.96}
{'loss': 0.0063, 'grad_norm': 4.574552059173584, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.003230399452149868, 'loss_2': 0.003055572509765625, 'loss_3': -16.429580688476562, 'loss_4': -0.1209738478064537, 'epoch': 28.97}
{'loss': 0.0051, 'grad_norm': 5.084994316101074, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0038049842696636915, 'loss_2': 0.0012760162353515625, 'loss_3': -16.44062042236328, 'loss_4': 0.31283459067344666, 'epoch': 28.97}
{'loss': 0.0058, 'grad_norm': 4.562058925628662, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.002556469989940524, 'loss_2': 0.0032196044921875, 'loss_3': -16.506019592285156, 'loss_4': -0.5726930499076843, 'epoch': 28.98}
{'loss': 0.0077, 'grad_norm': 4.991608142852783, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0039316522888839245, 'loss_2': 0.003780364990234375, 'loss_3': -16.321496963500977, 'loss_4': 0.1680685430765152, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 14:23:16,924 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:16,925 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:03:11<02:49,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 14:23:23,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009975285269320011, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.347, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0069119567051529884, 'eval_loss_2': 0.0030633285641670227, 'eval_loss_3': -18.16390037536621, 'eval_loss_4': -0.04734781011939049, 'epoch': 28.98}
{'loss': 0.0064, 'grad_norm': 4.609813213348389, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.004637939855456352, 'loss_2': 0.001766204833984375, 'loss_3': -16.509037017822266, 'loss_4': -0.14005503058433533, 'epoch': 28.99}
{'loss': 0.0067, 'grad_norm': 4.618551731109619, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.0028893027920275927, 'loss_2': 0.00380706787109375, 'loss_3': -16.329364776611328, 'loss_4': 0.0909406840801239, 'epoch': 28.99}
{'loss': 0.0316, 'grad_norm': 17.21533966064453, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.017498500645160675, 'loss_2': 0.014068603515625, 'loss_3': -16.040740966796875, 'loss_4': 0.03750503808259964, 'epoch': 29.0}
{'loss': 0.0052, 'grad_norm': 5.334521293640137, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.0020411196164786816, 'loss_2': 0.0031757354736328125, 'loss_3': -16.49275779724121, 'loss_4': 0.49289408326148987, 'epoch': 29.01}
{'loss': 0.0077, 'grad_norm': 4.487822532653809, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.005245056003332138, 'loss_2': 0.00246429443359375, 'loss_3': -16.410343170166016, 'loss_4': 0.01704743504524231, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 14:23:23,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:23,958 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:03:18<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:23:31,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009971894323825836, 'eval_runtime': 3.823, 'eval_samples_per_second': 267.851, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.006896153558045626, 'eval_loss_2': 0.003075741231441498, 'eval_loss_3': -18.165742874145508, 'eval_loss_4': -0.0585624985396862, 'epoch': 29.01}
{'loss': 0.0021, 'grad_norm': 4.443330764770508, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.0016973692690953612, 'loss_2': 0.0004343986511230469, 'loss_3': -16.774526596069336, 'loss_4': -0.13909335434436798, 'epoch': 29.02}
{'loss': 0.0085, 'grad_norm': 5.636758804321289, 'learning_rate': 1e-06, 'loss_1': 0.0041038780473172665, 'loss_2': 0.0044097900390625, 'loss_3': -16.36543846130371, 'loss_4': 0.23581023514270782, 'epoch': 29.02}
{'loss': 0.0095, 'grad_norm': 5.078741073608398, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.004738678690046072, 'loss_2': 0.00475311279296875, 'loss_3': -16.40082550048828, 'loss_4': 0.4676326513290405, 'epoch': 29.03}
{'loss': 0.0065, 'grad_norm': 4.755997657775879, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.0026565673761069775, 'loss_2': 0.00383758544921875, 'loss_3': -16.52956771850586, 'loss_4': -0.462738573551178, 'epoch': 29.03}
{'loss': 0.0052, 'grad_norm': 4.140172481536865, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.002993379719555378, 'loss_2': 0.0021724700927734375, 'loss_3': -16.426593780517578, 'loss_4': -0.4682334363460541, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 14:23:31,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:31,328 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:03:25<02:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:38,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009779518470168114, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006774981506168842, 'eval_loss_2': 0.0030045360326766968, 'eval_loss_3': -18.166921615600586, 'eval_loss_4': -0.055751100182533264, 'epoch': 29.04}
{'loss': 0.008, 'grad_norm': 4.782097339630127, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.005406496115028858, 'loss_2': 0.002605438232421875, 'loss_3': -16.409242630004883, 'loss_4': -0.18495123088359833, 'epoch': 29.05}
{'loss': 0.0036, 'grad_norm': 4.81605339050293, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.0033192995470017195, 'loss_2': 0.00025177001953125, 'loss_3': -16.201099395751953, 'loss_4': -0.1737903654575348, 'epoch': 29.05}
{'loss': 0.0077, 'grad_norm': 4.543379783630371, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.0037778180558234453, 'loss_2': 0.00396728515625, 'loss_3': -16.313140869140625, 'loss_4': 0.24236224591732025, 'epoch': 29.06}
{'loss': 0.0135, 'grad_norm': 6.412587642669678, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.008876393549144268, 'loss_2': 0.004669189453125, 'loss_3': -16.12834930419922, 'loss_4': -0.23650357127189636, 'epoch': 29.06}
{'loss': 0.0072, 'grad_norm': 4.419060230255127, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0014357492327690125, 'loss_2': 0.005764007568359375, 'loss_3': -16.480743408203125, 'loss_4': 0.15592682361602783, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 14:23:38,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:38,676 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:33<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:46,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009782413020730019, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.488, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0067488569766283035, 'eval_loss_2': 0.003033556044101715, 'eval_loss_3': -18.16814613342285, 'eval_loss_4': -0.059860751032829285, 'epoch': 29.07}
{'loss': 0.0053, 'grad_norm': 4.646411895751953, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.004143186379224062, 'loss_2': 0.0011577606201171875, 'loss_3': -16.391040802001953, 'loss_4': 0.2785147726535797, 'epoch': 29.08}
{'loss': 0.0065, 'grad_norm': 4.342234134674072, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.002734934678301215, 'loss_2': 0.0037975311279296875, 'loss_3': -16.659090042114258, 'loss_4': -0.35493242740631104, 'epoch': 29.08}
{'loss': 0.0113, 'grad_norm': 4.550526142120361, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.00866085197776556, 'loss_2': 0.002613067626953125, 'loss_3': -16.2981014251709, 'loss_4': 0.2189878225326538, 'epoch': 29.09}
{'loss': 0.0767, 'grad_norm': 22.30144691467285, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.07566402852535248, 'loss_2': 0.001026153564453125, 'loss_3': -16.37590789794922, 'loss_4': 0.7527382373809814, 'epoch': 29.09}
{'loss': 0.0061, 'grad_norm': 4.151976108551025, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.0035412211436778307, 'loss_2': 0.002605438232421875, 'loss_3': -16.516691207885742, 'loss_4': 0.2835124135017395, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 14:23:46,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:46,019 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:40<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:53,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00983334332704544, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006790262646973133, 'eval_loss_2': 0.003043081611394882, 'eval_loss_3': -18.169055938720703, 'eval_loss_4': -0.06434551626443863, 'epoch': 29.1}
{'loss': 0.0215, 'grad_norm': 15.764002799987793, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.019426429644227028, 'loss_2': 0.0021209716796875, 'loss_3': -16.479305267333984, 'loss_4': -0.13826529681682587, 'epoch': 29.1}
{'loss': 0.0056, 'grad_norm': 4.7845869064331055, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.0019684017170220613, 'loss_2': 0.0036449432373046875, 'loss_3': -16.287567138671875, 'loss_4': 0.11526414006948471, 'epoch': 29.11}
{'loss': 0.0205, 'grad_norm': 11.021291732788086, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.015138260088860989, 'loss_2': 0.00534820556640625, 'loss_3': -16.36826515197754, 'loss_4': 0.057419225573539734, 'epoch': 29.12}
{'loss': 0.0092, 'grad_norm': 4.455339431762695, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.0029873789753764868, 'loss_2': 0.00618743896484375, 'loss_3': -16.431848526000977, 'loss_4': -0.15656736493110657, 'epoch': 29.12}
{'loss': 0.0083, 'grad_norm': 4.346055507659912, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.002368188463151455, 'loss_2': 0.00588226318359375, 'loss_3': -16.533344268798828, 'loss_4': 0.3256448805332184, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 14:23:53,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:53,362 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:47<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:00,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009964661672711372, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.492, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006983259692788124, 'eval_loss_2': 0.0029814019799232483, 'eval_loss_3': -18.169157028198242, 'eval_loss_4': -0.06924843043088913, 'epoch': 29.13}
{'loss': 0.0102, 'grad_norm': 4.870029449462891, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.0067701805382966995, 'loss_2': 0.003383636474609375, 'loss_3': -16.39126205444336, 'loss_4': 0.22648435831069946, 'epoch': 29.13}
{'loss': 0.0044, 'grad_norm': 4.902403831481934, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.002520872512832284, 'loss_2': 0.001903533935546875, 'loss_3': -16.506366729736328, 'loss_4': -0.0591207779943943, 'epoch': 29.14}
{'loss': 0.0081, 'grad_norm': 6.0476579666137695, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.007370959501713514, 'loss_2': 0.00074005126953125, 'loss_3': -16.33083152770996, 'loss_4': 0.11925750225782394, 'epoch': 29.15}
{'loss': 0.0099, 'grad_norm': 5.279264450073242, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.007115535903722048, 'loss_2': 0.002777099609375, 'loss_3': -16.55600929260254, 'loss_4': 0.09915859997272491, 'epoch': 29.15}
{'loss': 0.0022, 'grad_norm': 4.529075622558594, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.002149158390238881, 'loss_2': 1.6987323760986328e-05, 'loss_3': -16.576988220214844, 'loss_4': -0.17935559153556824, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 14:24:00,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:00,702 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:55<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:08,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010077746585011482, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.804, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007100286427885294, 'eval_loss_2': 0.0029774606227874756, 'eval_loss_3': -18.168621063232422, 'eval_loss_4': -0.0790080651640892, 'epoch': 29.16}
{'loss': 0.0039, 'grad_norm': 5.034773826599121, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.003282651538029313, 'loss_2': 0.0006356239318847656, 'loss_3': -16.26095199584961, 'loss_4': 0.24544411897659302, 'epoch': 29.16}
{'loss': 0.0035, 'grad_norm': 4.925857067108154, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.0033398244995623827, 'loss_2': 0.00015211105346679688, 'loss_3': -16.441898345947266, 'loss_4': -0.05653880536556244, 'epoch': 29.17}
{'loss': 0.0086, 'grad_norm': 4.877315521240234, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.005857191979885101, 'loss_2': 0.0027446746826171875, 'loss_3': -16.28854751586914, 'loss_4': -0.10623344779014587, 'epoch': 29.17}
{'loss': 0.0069, 'grad_norm': 4.586184978485107, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.003793452400714159, 'loss_2': 0.003154754638671875, 'loss_3': -16.450706481933594, 'loss_4': 0.1845061480998993, 'epoch': 29.18}
{'loss': 0.0123, 'grad_norm': 4.571714401245117, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.002700233832001686, 'loss_2': 0.00962066650390625, 'loss_3': -16.28912353515625, 'loss_4': -0.11873084306716919, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 14:24:08,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:08,058 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:04:02<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:15,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010184301063418388, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007220475468784571, 'eval_loss_2': 0.002963826060295105, 'eval_loss_3': -18.170927047729492, 'eval_loss_4': -0.09009954333305359, 'epoch': 29.19}
{'loss': 0.0257, 'grad_norm': 14.193973541259766, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.022241296246647835, 'loss_2': 0.003448486328125, 'loss_3': -16.392736434936523, 'loss_4': 0.0193912535905838, 'epoch': 29.19}
{'loss': 0.0047, 'grad_norm': 4.281108379364014, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.002478918293491006, 'loss_2': 0.002208709716796875, 'loss_3': -16.347522735595703, 'loss_4': 0.5944358110427856, 'epoch': 29.2}
{'loss': 0.0139, 'grad_norm': 6.586799144744873, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.009173683822154999, 'loss_2': 0.00476837158203125, 'loss_3': -16.29355239868164, 'loss_4': 0.04345227777957916, 'epoch': 29.2}
{'loss': 0.0038, 'grad_norm': 4.495162487030029, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.002673153532668948, 'loss_2': 0.0011577606201171875, 'loss_3': -16.363658905029297, 'loss_4': -0.22919030487537384, 'epoch': 29.21}
{'loss': 0.0174, 'grad_norm': 12.937758445739746, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.01595219597220421, 'loss_2': 0.00145721435546875, 'loss_3': -16.488170623779297, 'loss_4': 0.2882256507873535, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 14:24:15,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:15,411 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:04:09<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:22,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010360736399888992, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.24, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0073457146063447, 'eval_loss_2': 0.003015022724866867, 'eval_loss_3': -18.172178268432617, 'eval_loss_4': -0.09571938961744308, 'epoch': 29.22}
{'loss': 0.0064, 'grad_norm': 4.5255632400512695, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0029737630393356085, 'loss_2': 0.00341796875, 'loss_3': -16.48831558227539, 'loss_4': -0.19553568959236145, 'epoch': 29.22}
{'loss': 0.0082, 'grad_norm': 5.471216678619385, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.00544130802154541, 'loss_2': 0.0027370452880859375, 'loss_3': -16.306598663330078, 'loss_4': -0.27317309379577637, 'epoch': 29.23}
{'loss': 0.0097, 'grad_norm': 4.569738864898682, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.0031835108529776335, 'loss_2': 0.00647735595703125, 'loss_3': -16.555635452270508, 'loss_4': -0.0593370720744133, 'epoch': 29.23}
{'loss': 0.003, 'grad_norm': 4.72930908203125, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.002264798851683736, 'loss_2': 0.0007848739624023438, 'loss_3': -16.06838607788086, 'loss_4': -0.2717440724372864, 'epoch': 29.24}
{'loss': 0.0031, 'grad_norm': 4.193634986877441, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.0017838209168985486, 'loss_2': 0.0012683868408203125, 'loss_3': -16.447444915771484, 'loss_4': -0.04318563640117645, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 14:24:22,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:22,758 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:04:17<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:30,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01040533185005188, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007318019401282072, 'eval_loss_2': 0.0030873119831085205, 'eval_loss_3': -18.17041015625, 'eval_loss_4': -0.10833550989627838, 'epoch': 29.24}
{'loss': 0.0122, 'grad_norm': 4.4969072341918945, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.006431260146200657, 'loss_2': 0.00579833984375, 'loss_3': -16.166675567626953, 'loss_4': -0.26469093561172485, 'epoch': 29.25}
{'loss': 0.0289, 'grad_norm': 10.325285911560059, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.023109599947929382, 'loss_2': 0.005779266357421875, 'loss_3': -16.450592041015625, 'loss_4': -0.04218469560146332, 'epoch': 29.26}
{'loss': 0.0616, 'grad_norm': 8.335221290588379, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.060105737298727036, 'loss_2': 0.0014829635620117188, 'loss_3': -16.26561164855957, 'loss_4': 0.14490656554698944, 'epoch': 29.26}
{'loss': 0.0104, 'grad_norm': 4.641473293304443, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0070454771630465984, 'loss_2': 0.00334930419921875, 'loss_3': -16.3211669921875, 'loss_4': -0.4749445617198944, 'epoch': 29.27}
{'loss': 0.0061, 'grad_norm': 5.073485374450684, 'learning_rate': 7.5e-07, 'loss_1': 0.005875193048268557, 'loss_2': 0.00025844573974609375, 'loss_3': -16.464317321777344, 'loss_4': -0.51725172996521, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 14:24:30,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:30,108 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:04:24<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:37,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010425777174532413, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007360399700701237, 'eval_loss_2': 0.0030653774738311768, 'eval_loss_3': -18.168214797973633, 'eval_loss_4': -0.11927499622106552, 'epoch': 29.27}
{'loss': 0.0067, 'grad_norm': 4.650186538696289, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.001594556961208582, 'loss_2': 0.0051422119140625, 'loss_3': -16.501888275146484, 'loss_4': 0.09930264949798584, 'epoch': 29.28}
{'loss': 0.0063, 'grad_norm': 4.765751361846924, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.005259902682155371, 'loss_2': 0.0010280609130859375, 'loss_3': -16.421340942382812, 'loss_4': -0.5740057826042175, 'epoch': 29.28}
{'loss': 0.009, 'grad_norm': 4.638254642486572, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.004555203020572662, 'loss_2': 0.00447845458984375, 'loss_3': -16.45249366760254, 'loss_4': -0.14830070734024048, 'epoch': 29.29}
{'loss': 0.0032, 'grad_norm': 4.423779487609863, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.0022901687771081924, 'loss_2': 0.0009012222290039062, 'loss_3': -16.36102294921875, 'loss_4': 0.24629461765289307, 'epoch': 29.3}
{'loss': 0.0052, 'grad_norm': 4.335986137390137, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.0019158662762492895, 'loss_2': 0.003253936767578125, 'loss_3': -16.662761688232422, 'loss_4': -0.2578732669353485, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 14:24:37,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:37,453 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:31<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:44,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010562561452388763, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.329, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007427282631397247, 'eval_loss_2': 0.003135278820991516, 'eval_loss_3': -18.165502548217773, 'eval_loss_4': -0.12129712104797363, 'epoch': 29.3}
{'loss': 0.0056, 'grad_norm': 4.686272144317627, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.0019382997415959835, 'loss_2': 0.00366973876953125, 'loss_3': -16.51746368408203, 'loss_4': -0.08215653151273727, 'epoch': 29.31}
{'loss': 0.0195, 'grad_norm': 9.822061538696289, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.012869125232100487, 'loss_2': 0.006656646728515625, 'loss_3': -16.279525756835938, 'loss_4': 0.18475350737571716, 'epoch': 29.31}
{'loss': 0.0118, 'grad_norm': 6.3685455322265625, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.011043857783079147, 'loss_2': 0.0007596015930175781, 'loss_3': -16.408676147460938, 'loss_4': 0.03722107410430908, 'epoch': 29.32}
{'loss': 0.0111, 'grad_norm': 5.781556129455566, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.008188240230083466, 'loss_2': 0.002960205078125, 'loss_3': -16.091251373291016, 'loss_4': -0.22052256762981415, 'epoch': 29.33}
{'loss': 0.0092, 'grad_norm': 5.5148420333862305, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.004047767259180546, 'loss_2': 0.005199432373046875, 'loss_3': -16.499040603637695, 'loss_4': -0.530646026134491, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 14:24:44,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:44,801 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:39<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:52,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010727878659963608, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.738, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007528247777372599, 'eval_loss_2': 0.003199629485607147, 'eval_loss_3': -18.164161682128906, 'eval_loss_4': -0.12421119958162308, 'epoch': 29.33}
{'loss': 0.0037, 'grad_norm': 4.54166316986084, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.0019805917982012033, 'loss_2': 0.001712799072265625, 'loss_3': -16.402559280395508, 'loss_4': -0.09953241795301437, 'epoch': 29.34}
{'loss': 0.0075, 'grad_norm': 5.281804084777832, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.004824861418455839, 'loss_2': 0.002658843994140625, 'loss_3': -16.28277015686035, 'loss_4': -0.11390990018844604, 'epoch': 29.34}
{'loss': 0.012, 'grad_norm': 5.428381443023682, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.007300299592316151, 'loss_2': 0.00469970703125, 'loss_3': -16.34800148010254, 'loss_4': -0.32094040513038635, 'epoch': 29.35}
{'loss': 0.008, 'grad_norm': 4.759165287017822, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.005480247549712658, 'loss_2': 0.0024776458740234375, 'loss_3': -16.439926147460938, 'loss_4': 0.31167858839035034, 'epoch': 29.35}
{'loss': 0.0042, 'grad_norm': 4.401319980621338, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.0031262352131307125, 'loss_2': 0.00106048583984375, 'loss_3': -16.233657836914062, 'loss_4': 0.2013682723045349, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 14:24:52,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:52,154 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:46<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:59,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010867249220609665, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007674547377973795, 'eval_loss_2': 0.003192700445652008, 'eval_loss_3': -18.165679931640625, 'eval_loss_4': -0.1349858045578003, 'epoch': 29.36}
{'loss': 0.0097, 'grad_norm': 4.5158772468566895, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.003028901992365718, 'loss_2': 0.006649017333984375, 'loss_3': -16.440813064575195, 'loss_4': 0.1139611005783081, 'epoch': 29.37}
{'loss': 0.0024, 'grad_norm': 4.712499141693115, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0017685587517917156, 'loss_2': 0.00066375732421875, 'loss_3': -16.312870025634766, 'loss_4': 0.04155498743057251, 'epoch': 29.37}
{'loss': 0.0161, 'grad_norm': 6.92611026763916, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.010709484107792377, 'loss_2': 0.00536346435546875, 'loss_3': -16.489524841308594, 'loss_4': 0.33068159222602844, 'epoch': 29.38}
{'loss': 0.0087, 'grad_norm': 5.364495277404785, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.005290142260491848, 'loss_2': 0.00342559814453125, 'loss_3': -16.353191375732422, 'loss_4': -0.412487268447876, 'epoch': 29.38}
{'loss': 0.0083, 'grad_norm': 4.896141052246094, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.00519939698278904, 'loss_2': 0.0031375885009765625, 'loss_3': -16.461660385131836, 'loss_4': 0.24082998931407928, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 14:24:59,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:59,499 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:53<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:06,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010967152193188667, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007737145759165287, 'eval_loss_2': 0.0032300055027008057, 'eval_loss_3': -18.16690444946289, 'eval_loss_4': -0.14798232913017273, 'epoch': 29.39}
{'loss': 0.0029, 'grad_norm': 4.139836311340332, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0015340266982093453, 'loss_2': 0.001399993896484375, 'loss_3': -16.42224884033203, 'loss_4': -0.10712680965662003, 'epoch': 29.4}
{'loss': 0.0104, 'grad_norm': 5.834385871887207, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.008554542437195778, 'loss_2': 0.001796722412109375, 'loss_3': -16.52090072631836, 'loss_4': 0.20260877907276154, 'epoch': 29.4}
{'loss': 0.0055, 'grad_norm': 4.7863922119140625, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.004754336085170507, 'loss_2': 0.0007534027099609375, 'loss_3': -16.327739715576172, 'loss_4': -0.2147407978773117, 'epoch': 29.41}
{'loss': 0.0041, 'grad_norm': 4.726080894470215, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.003836538642644882, 'loss_2': 0.00029730796813964844, 'loss_3': -16.354110717773438, 'loss_4': -0.4043259620666504, 'epoch': 29.41}
{'loss': 0.0038, 'grad_norm': 4.748712062835693, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.002880940679460764, 'loss_2': 0.0009603500366210938, 'loss_3': -16.630573272705078, 'loss_4': -0.19618065655231476, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 14:25:06,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:06,839 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:05:01<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:14,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010969706811010838, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.405, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007738076616078615, 'eval_loss_2': 0.003231629729270935, 'eval_loss_3': -18.165739059448242, 'eval_loss_4': -0.15422649681568146, 'epoch': 29.42}
{'loss': 0.0039, 'grad_norm': 4.88217306137085, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0034251329489052296, 'loss_2': 0.000518798828125, 'loss_3': -16.620460510253906, 'loss_4': -0.35168197751045227, 'epoch': 29.42}
{'loss': 0.0073, 'grad_norm': 3.952260732650757, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.0034610929433256388, 'loss_2': 0.003849029541015625, 'loss_3': -16.501476287841797, 'loss_4': -0.1547064483165741, 'epoch': 29.43}
{'loss': 0.0077, 'grad_norm': 4.456256866455078, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.003332720836624503, 'loss_2': 0.0043792724609375, 'loss_3': -16.434436798095703, 'loss_4': 0.08732982724905014, 'epoch': 29.44}
{'loss': 0.0043, 'grad_norm': 4.927615165710449, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.002062770538032055, 'loss_2': 0.002197265625, 'loss_3': -16.385589599609375, 'loss_4': 0.09874282032251358, 'epoch': 29.44}
{'loss': 0.0085, 'grad_norm': 5.471432685852051, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.006869375705718994, 'loss_2': 0.0015964508056640625, 'loss_3': -16.48999786376953, 'loss_4': -0.006963804364204407, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 14:25:14,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:14,198 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:05:08<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:21,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0107954703271389, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007660366594791412, 'eval_loss_2': 0.0031351037323474884, 'eval_loss_3': -18.1649227142334, 'eval_loss_4': -0.15442071855068207, 'epoch': 29.45}
{'loss': 0.0134, 'grad_norm': 4.823169231414795, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0036115546245127916, 'loss_2': 0.00982666015625, 'loss_3': -16.560373306274414, 'loss_4': -0.11463223397731781, 'epoch': 29.45}
{'loss': 0.0088, 'grad_norm': 4.906147003173828, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.0038458455819636583, 'loss_2': 0.004913330078125, 'loss_3': -16.429351806640625, 'loss_4': -0.20254088938236237, 'epoch': 29.46}
{'loss': 0.0054, 'grad_norm': 4.510569095611572, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.003204048378393054, 'loss_2': 0.002147674560546875, 'loss_3': -16.467037200927734, 'loss_4': 0.36512094736099243, 'epoch': 29.47}
{'loss': 0.0095, 'grad_norm': 5.939676761627197, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.006462848279625177, 'loss_2': 0.003040313720703125, 'loss_3': -16.45208168029785, 'loss_4': -0.027881160378456116, 'epoch': 29.47}
{'loss': 0.0071, 'grad_norm': 4.750110626220703, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.004736059810966253, 'loss_2': 0.00238800048828125, 'loss_3': -16.34317970275879, 'loss_4': -0.5158562660217285, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 14:25:21,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:21,542 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:05:15<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:28,906 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010755946859717369, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.62, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0075974371284246445, 'eval_loss_2': 0.0031585097312927246, 'eval_loss_3': -18.165706634521484, 'eval_loss_4': -0.15154796838760376, 'epoch': 29.48}
{'loss': 0.0077, 'grad_norm': 5.727642059326172, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.006043269764631987, 'loss_2': 0.0017032623291015625, 'loss_3': -16.441089630126953, 'loss_4': -0.12098146975040436, 'epoch': 29.48}
{'loss': 0.0111, 'grad_norm': 5.321794509887695, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.005980164743959904, 'loss_2': 0.0050811767578125, 'loss_3': -16.275575637817383, 'loss_4': -0.2069474160671234, 'epoch': 29.49}
{'loss': 0.009, 'grad_norm': 6.163582801818848, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.007533976808190346, 'loss_2': 0.0014400482177734375, 'loss_3': -16.270341873168945, 'loss_4': -0.06633813679218292, 'epoch': 29.49}
{'loss': 0.0063, 'grad_norm': 4.8647141456604, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.002804545918479562, 'loss_2': 0.003490447998046875, 'loss_3': -16.471281051635742, 'loss_4': 0.09924890100955963, 'epoch': 29.5}
{'loss': 0.0143, 'grad_norm': 4.080111026763916, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.0032330588437616825, 'loss_2': 0.01107025146484375, 'loss_3': -16.333162307739258, 'loss_4': -0.2120429426431656, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 14:25:28,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:28,907 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:05:23<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:36,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01075610239058733, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00758363027125597, 'eval_loss_2': 0.00317247211933136, 'eval_loss_3': -18.166606903076172, 'eval_loss_4': -0.1458553671836853, 'epoch': 29.51}
{'loss': 0.01, 'grad_norm': 5.809332370758057, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.007533634081482887, 'loss_2': 0.002475738525390625, 'loss_3': -16.429180145263672, 'loss_4': 0.37269002199172974, 'epoch': 29.51}
{'loss': 0.0053, 'grad_norm': 4.864687919616699, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.003327088663354516, 'loss_2': 0.002017974853515625, 'loss_3': -16.34619903564453, 'loss_4': -0.18612442910671234, 'epoch': 29.52}
{'loss': 0.0112, 'grad_norm': 4.792565822601318, 'learning_rate': 5e-07, 'loss_1': 0.004597966559231281, 'loss_2': 0.0065765380859375, 'loss_3': -16.586034774780273, 'loss_4': -0.06244906783103943, 'epoch': 29.52}
{'loss': 0.0096, 'grad_norm': 4.565983295440674, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.0014232683461159468, 'loss_2': 0.0081787109375, 'loss_3': -16.528675079345703, 'loss_4': 0.05881165713071823, 'epoch': 29.53}
{'loss': 0.0086, 'grad_norm': 5.221106052398682, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.006150517612695694, 'loss_2': 0.00249481201171875, 'loss_3': -16.406246185302734, 'loss_4': -0.46198564767837524, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 14:25:36,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:36,250 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:30<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:43,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010776479728519917, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.74, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007600513286888599, 'eval_loss_2': 0.003175966441631317, 'eval_loss_3': -18.1656551361084, 'eval_loss_4': -0.1479162722826004, 'epoch': 29.53}
{'loss': 0.0049, 'grad_norm': 4.153189182281494, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.0020626806654036045, 'loss_2': 0.002834320068359375, 'loss_3': -16.50926971435547, 'loss_4': -0.16412124037742615, 'epoch': 29.54}
{'loss': 0.006, 'grad_norm': 4.9388275146484375, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.004551427438855171, 'loss_2': 0.0014019012451171875, 'loss_3': -16.32970428466797, 'loss_4': 0.006771177053451538, 'epoch': 29.55}
{'loss': 0.0051, 'grad_norm': 4.40066385269165, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.0021225609816610813, 'loss_2': 0.00293731689453125, 'loss_3': -16.349849700927734, 'loss_4': 0.38952136039733887, 'epoch': 29.55}
{'loss': 0.0022, 'grad_norm': 4.693890571594238, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0012108995579183102, 'loss_2': 0.001026153564453125, 'loss_3': -16.62139892578125, 'loss_4': -0.27178147435188293, 'epoch': 29.56}
{'loss': 0.0061, 'grad_norm': 7.148415565490723, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.005218563135713339, 'loss_2': 0.0008792877197265625, 'loss_3': -16.447521209716797, 'loss_4': 0.07090560346841812, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 14:25:43,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:43,592 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:37<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:50,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010767603293061256, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007576578762382269, 'eval_loss_2': 0.0031910240650177, 'eval_loss_3': -18.165807723999023, 'eval_loss_4': -0.15365749597549438, 'epoch': 29.56}
{'loss': 0.0047, 'grad_norm': 4.98280668258667, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0015192074934020638, 'loss_2': 0.0031585693359375, 'loss_3': -16.69359588623047, 'loss_4': 0.0719369649887085, 'epoch': 29.57}
{'loss': 0.005, 'grad_norm': 4.764684200286865, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.003854418871924281, 'loss_2': 0.00115203857421875, 'loss_3': -16.424030303955078, 'loss_4': -0.4947283864021301, 'epoch': 29.58}
{'loss': 0.0132, 'grad_norm': 6.036092758178711, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.012494665570557117, 'loss_2': 0.0006556510925292969, 'loss_3': -16.09602928161621, 'loss_4': 0.2825941741466522, 'epoch': 29.58}
{'loss': 0.0042, 'grad_norm': 4.989360332489014, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.003453875193372369, 'loss_2': 0.0007772445678710938, 'loss_3': -16.446483612060547, 'loss_4': 0.028157353401184082, 'epoch': 29.59}
{'loss': 0.0069, 'grad_norm': 6.701472282409668, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.00600943760946393, 'loss_2': 0.0009222030639648438, 'loss_3': -16.42959976196289, 'loss_4': -0.4094371199607849, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 14:25:50,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:50,931 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:45<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:58,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010773399844765663, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007600376848131418, 'eval_loss_2': 0.0031730234622955322, 'eval_loss_3': -18.166217803955078, 'eval_loss_4': -0.15536220371723175, 'epoch': 29.59}
{'loss': 0.0078, 'grad_norm': 5.920210361480713, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.005636748857796192, 'loss_2': 0.002208709716796875, 'loss_3': -16.415626525878906, 'loss_4': -0.22133970260620117, 'epoch': 29.6}
{'loss': 0.0048, 'grad_norm': 4.887899398803711, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.0031293835490942, 'loss_2': 0.0016880035400390625, 'loss_3': -16.50225067138672, 'loss_4': 0.15790770947933197, 'epoch': 29.6}
{'loss': 0.0048, 'grad_norm': 4.743332386016846, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0022939234040677547, 'loss_2': 0.00251007080078125, 'loss_3': -16.441476821899414, 'loss_4': -0.04384461045265198, 'epoch': 29.61}
{'loss': 0.0054, 'grad_norm': 4.7973737716674805, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.004130891058593988, 'loss_2': 0.0012531280517578125, 'loss_3': -16.466751098632812, 'loss_4': -0.26502344012260437, 'epoch': 29.62}
{'loss': 0.0061, 'grad_norm': 5.57424783706665, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.005939485039561987, 'loss_2': 0.0001461505889892578, 'loss_3': -16.348438262939453, 'loss_4': 0.27108871936798096, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 14:25:58,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:58,279 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:52<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:05,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010732234455645084, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.198, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0075779869221150875, 'eval_loss_2': 0.003154247999191284, 'eval_loss_3': -18.166851043701172, 'eval_loss_4': -0.1576664298772812, 'epoch': 29.62}
{'loss': 0.0028, 'grad_norm': 4.616296291351318, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.0021621733903884888, 'loss_2': 0.00063323974609375, 'loss_3': -16.442352294921875, 'loss_4': -0.049214642494916916, 'epoch': 29.63}
{'loss': 0.0137, 'grad_norm': 4.71684455871582, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.004631076939404011, 'loss_2': 0.00911712646484375, 'loss_3': -16.39365005493164, 'loss_4': 0.25020015239715576, 'epoch': 29.63}
{'loss': 0.005, 'grad_norm': 4.720953464508057, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.004946522414684296, 'loss_2': 4.0531158447265625e-05, 'loss_3': -16.438919067382812, 'loss_4': 0.3118773400783539, 'epoch': 29.64}
{'loss': 0.0036, 'grad_norm': 4.553335189819336, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.0035523748956620693, 'loss_2': 6.03795051574707e-05, 'loss_3': -16.147415161132812, 'loss_4': 0.6790897250175476, 'epoch': 29.65}
{'loss': 0.0234, 'grad_norm': 10.899632453918457, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.01687535271048546, 'loss_2': 0.00650787353515625, 'loss_3': -16.291973114013672, 'loss_4': -0.3291521668434143, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 14:26:05,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:05,621 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:06:00<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:12,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010694282129406929, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007553238421678543, 'eval_loss_2': 0.003141045570373535, 'eval_loss_3': -18.167064666748047, 'eval_loss_4': -0.16121748089790344, 'epoch': 29.65}
{'loss': 0.0082, 'grad_norm': 5.3326334953308105, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.004936025012284517, 'loss_2': 0.003265380859375, 'loss_3': -16.427810668945312, 'loss_4': 0.22912374138832092, 'epoch': 29.66}
{'loss': 0.0049, 'grad_norm': 4.267633438110352, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.004439002834260464, 'loss_2': 0.0004978179931640625, 'loss_3': -16.331859588623047, 'loss_4': 0.2456095814704895, 'epoch': 29.66}
{'loss': 0.005, 'grad_norm': 5.210166931152344, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.004612261895090342, 'loss_2': 0.0003600120544433594, 'loss_3': -16.422990798950195, 'loss_4': -0.4533986449241638, 'epoch': 29.67}
{'loss': 0.0173, 'grad_norm': 7.391839981079102, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.012570981867611408, 'loss_2': 0.004730224609375, 'loss_3': -16.61313247680664, 'loss_4': -0.09134078025817871, 'epoch': 29.67}
{'loss': 0.0089, 'grad_norm': 6.8148722648620605, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.006584866903722286, 'loss_2': 0.00235748291015625, 'loss_3': -16.397743225097656, 'loss_4': -0.3265262842178345, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 14:26:12,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:12,961 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:06:07<00:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:20,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010733525268733501, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007612074725329876, 'eval_loss_2': 0.0031214505434036255, 'eval_loss_3': -18.16766357421875, 'eval_loss_4': -0.16438689827919006, 'epoch': 29.68}
{'loss': 0.009, 'grad_norm': 5.172577381134033, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.00500504719093442, 'loss_2': 0.003997802734375, 'loss_3': -16.294118881225586, 'loss_4': -0.07911062985658646, 'epoch': 29.69}
{'loss': 0.0092, 'grad_norm': 4.539802551269531, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.002538474975153804, 'loss_2': 0.00662994384765625, 'loss_3': -16.382312774658203, 'loss_4': -0.0731009766459465, 'epoch': 29.69}
{'loss': 0.024, 'grad_norm': 11.579081535339355, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.013673529028892517, 'loss_2': 0.0102996826171875, 'loss_3': -16.331321716308594, 'loss_4': -0.4980839788913727, 'epoch': 29.7}
{'loss': 0.0075, 'grad_norm': 4.827345848083496, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.003885521087795496, 'loss_2': 0.003589630126953125, 'loss_3': -16.329803466796875, 'loss_4': -0.1956617832183838, 'epoch': 29.7}
{'loss': 0.0092, 'grad_norm': 4.728839874267578, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.004187324550002813, 'loss_2': 0.0050048828125, 'loss_3': -16.359167098999023, 'loss_4': 0.23014096915721893, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 14:26:20,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:20,307 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:06:14<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:27,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010729402303695679, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0076250722631812096, 'eval_loss_2': 0.0031043291091918945, 'eval_loss_3': -18.16705894470215, 'eval_loss_4': -0.16626155376434326, 'epoch': 29.71}
{'loss': 0.0056, 'grad_norm': 5.476780414581299, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.005420889239758253, 'loss_2': 0.00014698505401611328, 'loss_3': -16.18376350402832, 'loss_4': -0.4807804226875305, 'epoch': 29.72}
{'loss': 0.0193, 'grad_norm': 9.833721160888672, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.01625596545636654, 'loss_2': 0.0030364990234375, 'loss_3': -16.386459350585938, 'loss_4': 0.3403133749961853, 'epoch': 29.72}
{'loss': 0.0063, 'grad_norm': 5.1329169273376465, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.004487020894885063, 'loss_2': 0.001834869384765625, 'loss_3': -16.366601943969727, 'loss_4': 0.40657374262809753, 'epoch': 29.73}
{'loss': 0.0159, 'grad_norm': 4.870560646057129, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.006428117863833904, 'loss_2': 0.00946044921875, 'loss_3': -16.2147159576416, 'loss_4': -0.2898169159889221, 'epoch': 29.73}
{'loss': 0.0158, 'grad_norm': 19.698028564453125, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.014133734628558159, 'loss_2': 0.0017108917236328125, 'loss_3': -16.42923355102539, 'loss_4': 0.5516772270202637, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 14:26:27,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:27,666 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:06:22<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:35,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01077115349471569, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007644830271601677, 'eval_loss_2': 0.0031263232231140137, 'eval_loss_3': -18.16619110107422, 'eval_loss_4': -0.16578391194343567, 'epoch': 29.74}
{'loss': 0.0055, 'grad_norm': 4.602342128753662, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.0030672033317387104, 'loss_2': 0.00240325927734375, 'loss_3': -16.277027130126953, 'loss_4': -0.13122612237930298, 'epoch': 29.74}
{'loss': 0.0063, 'grad_norm': 4.762343883514404, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.003286705119535327, 'loss_2': 0.003047943115234375, 'loss_3': -16.37154769897461, 'loss_4': -0.0815417617559433, 'epoch': 29.75}
{'loss': 0.0124, 'grad_norm': 4.8979811668396, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.00563911534845829, 'loss_2': 0.006805419921875, 'loss_3': -16.4237117767334, 'loss_4': 0.07446519285440445, 'epoch': 29.76}
{'loss': 0.0035, 'grad_norm': 4.507176876068115, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.0025707900058478117, 'loss_2': 0.0009107589721679688, 'loss_3': -16.638042449951172, 'loss_4': 0.2933327555656433, 'epoch': 29.76}
{'loss': 0.0072, 'grad_norm': 5.464873790740967, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.005689800716936588, 'loss_2': 0.0014791488647460938, 'loss_3': -16.442880630493164, 'loss_4': 0.2189210206270218, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 14:26:35,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:35,016 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:29<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:42,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01083933375775814, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.007, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007710298988968134, 'eval_loss_2': 0.003129035234451294, 'eval_loss_3': -18.165515899658203, 'eval_loss_4': -0.16558054089546204, 'epoch': 29.77}
{'loss': 0.0055, 'grad_norm': 4.576792240142822, 'learning_rate': 2.5e-07, 'loss_1': 0.0030868640169501305, 'loss_2': 0.002384185791015625, 'loss_3': -16.300251007080078, 'loss_4': -0.37174296379089355, 'epoch': 29.77}
{'loss': 0.0749, 'grad_norm': 13.745580673217773, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.0671749860048294, 'loss_2': 0.00769805908203125, 'loss_3': -16.57842254638672, 'loss_4': -0.12827537953853607, 'epoch': 29.78}
{'loss': 0.004, 'grad_norm': 3.9921131134033203, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.0027760460507124662, 'loss_2': 0.0011882781982421875, 'loss_3': -16.403942108154297, 'loss_4': 0.013084664940834045, 'epoch': 29.78}
{'loss': 0.0078, 'grad_norm': 4.509410381317139, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.0032237316481769085, 'loss_2': 0.004535675048828125, 'loss_3': -16.58819007873535, 'loss_4': 0.028514526784420013, 'epoch': 29.79}
{'loss': 0.0151, 'grad_norm': 6.167572498321533, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.00788235291838646, 'loss_2': 0.00717926025390625, 'loss_3': -16.458251953125, 'loss_4': -0.026026934385299683, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 14:26:42,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:42,364 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:36<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:49,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010840053670108318, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007738273125141859, 'eval_loss_2': 0.0031017810106277466, 'eval_loss_3': -18.164749145507812, 'eval_loss_4': -0.16508331894874573, 'epoch': 29.8}
{'loss': 0.0084, 'grad_norm': 5.888427734375, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.007454720325767994, 'loss_2': 0.0009274482727050781, 'loss_3': -16.472261428833008, 'loss_4': -0.22907400131225586, 'epoch': 29.8}
{'loss': 0.011, 'grad_norm': 4.1432785987854, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.002847739029675722, 'loss_2': 0.0081024169921875, 'loss_3': -16.519664764404297, 'loss_4': 0.0921064168214798, 'epoch': 29.81}
{'loss': 0.0075, 'grad_norm': 5.156407356262207, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.0059425183571875095, 'loss_2': 0.0015850067138671875, 'loss_3': -16.31989288330078, 'loss_4': -0.5783660411834717, 'epoch': 29.81}
{'loss': 0.0078, 'grad_norm': 4.4534687995910645, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0025115939788520336, 'loss_2': 0.005329132080078125, 'loss_3': -16.332340240478516, 'loss_4': 0.11471763253211975, 'epoch': 29.82}
{'loss': 0.0175, 'grad_norm': 10.018704414367676, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.012014871463179588, 'loss_2': 0.005527496337890625, 'loss_3': -16.247421264648438, 'loss_4': 0.022479698061943054, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 14:26:49,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:49,713 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:44<00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:57,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010825322940945625, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007759834639728069, 'eval_loss_2': 0.0030654892325401306, 'eval_loss_3': -18.16421127319336, 'eval_loss_4': -0.1636693775653839, 'epoch': 29.83}
{'loss': 0.0036, 'grad_norm': 4.389164924621582, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.002244130242615938, 'loss_2': 0.001384735107421875, 'loss_3': -16.396087646484375, 'loss_4': -0.23525121808052063, 'epoch': 29.83}
{'loss': 0.0043, 'grad_norm': 4.569103240966797, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.0032843102235347033, 'loss_2': 0.00106048583984375, 'loss_3': -16.372787475585938, 'loss_4': -0.4544677734375, 'epoch': 29.84}
{'loss': 0.0095, 'grad_norm': 5.52631950378418, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.005014700815081596, 'loss_2': 0.004505157470703125, 'loss_3': -16.48154067993164, 'loss_4': -0.18002255260944366, 'epoch': 29.84}
{'loss': 0.0056, 'grad_norm': 4.3203020095825195, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.003738199593499303, 'loss_2': 0.0018825531005859375, 'loss_3': -16.54485321044922, 'loss_4': -0.4983603358268738, 'epoch': 29.85}
{'loss': 0.0125, 'grad_norm': 7.576207637786865, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.006358875893056393, 'loss_2': 0.006130218505859375, 'loss_3': -16.392671585083008, 'loss_4': -0.7465946674346924, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 14:26:57,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:57,064 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:51<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:04,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010828757658600807, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007767285220324993, 'eval_loss_2': 0.0030614733695983887, 'eval_loss_3': -18.163875579833984, 'eval_loss_4': -0.16233587265014648, 'epoch': 29.85}
{'loss': 0.0194, 'grad_norm': 5.942850112915039, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.01685447432100773, 'loss_2': 0.0025615692138671875, 'loss_3': -16.422325134277344, 'loss_4': -0.3322111964225769, 'epoch': 29.86}
{'loss': 0.0226, 'grad_norm': 14.178994178771973, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.02176489494740963, 'loss_2': 0.0008039474487304688, 'loss_3': -16.394943237304688, 'loss_4': 0.1246798038482666, 'epoch': 29.87}
{'loss': 0.0138, 'grad_norm': 5.798945426940918, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.007775962818413973, 'loss_2': 0.0060272216796875, 'loss_3': -16.237762451171875, 'loss_4': -0.20759299397468567, 'epoch': 29.87}
{'loss': 0.004, 'grad_norm': 4.816707134246826, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.0034024929627776146, 'loss_2': 0.0005645751953125, 'loss_3': -16.296689987182617, 'loss_4': 0.3115350008010864, 'epoch': 29.88}
{'loss': 0.0035, 'grad_norm': 4.416461944580078, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.0033674133010208607, 'loss_2': 0.0001251697540283203, 'loss_3': -16.36998748779297, 'loss_4': -0.11634432524442673, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 14:27:04,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:04,399 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:58<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:11,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010833102278411388, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007786992471665144, 'eval_loss_2': 0.0030461102724075317, 'eval_loss_3': -18.16422462463379, 'eval_loss_4': -0.15909001231193542, 'epoch': 29.88}
{'loss': 0.0066, 'grad_norm': 5.34572172164917, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.002893764292821288, 'loss_2': 0.003753662109375, 'loss_3': -16.4355411529541, 'loss_4': -0.4324427843093872, 'epoch': 29.89}
{'loss': 0.0138, 'grad_norm': 6.251130104064941, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.011908037588000298, 'loss_2': 0.0019159317016601562, 'loss_3': -16.47752571105957, 'loss_4': 0.08130508661270142, 'epoch': 29.9}
{'loss': 0.0134, 'grad_norm': 8.566353797912598, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.013102155178785324, 'loss_2': 0.00026869773864746094, 'loss_3': -16.346071243286133, 'loss_4': -0.3275594711303711, 'epoch': 29.9}
{'loss': 0.0056, 'grad_norm': 4.5083909034729, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.004349343478679657, 'loss_2': 0.0012578964233398438, 'loss_3': -16.44988441467285, 'loss_4': 0.4724905490875244, 'epoch': 29.91}
{'loss': 0.0048, 'grad_norm': 4.8024983406066895, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.0037407507188618183, 'loss_2': 0.0010843276977539062, 'loss_3': -16.284896850585938, 'loss_4': -0.13599777221679688, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 14:27:11,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:11,745 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:07:06<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:19,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010843471623957157, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007788621820509434, 'eval_loss_2': 0.0030548498034477234, 'eval_loss_3': -18.163984298706055, 'eval_loss_4': -0.15724095702171326, 'epoch': 29.91}
{'loss': 0.0085, 'grad_norm': 4.151594638824463, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.0021653559524565935, 'loss_2': 0.00634765625, 'loss_3': -16.382720947265625, 'loss_4': -0.19955676794052124, 'epoch': 29.92}
{'loss': 0.0063, 'grad_norm': 4.827381134033203, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.0035926918499171734, 'loss_2': 0.002704620361328125, 'loss_3': -16.4288330078125, 'loss_4': -0.4421645700931549, 'epoch': 29.92}
{'loss': 0.0153, 'grad_norm': 8.11251163482666, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.00991135835647583, 'loss_2': 0.0054168701171875, 'loss_3': -16.234901428222656, 'loss_4': -0.05782638490200043, 'epoch': 29.93}
{'loss': 0.0144, 'grad_norm': 6.468731880187988, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.009361304342746735, 'loss_2': 0.00502777099609375, 'loss_3': -16.139169692993164, 'loss_4': -0.029220759868621826, 'epoch': 29.94}
{'loss': 0.0048, 'grad_norm': 4.918276786804199, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.004463795106858015, 'loss_2': 0.00037550926208496094, 'loss_3': -16.433311462402344, 'loss_4': -0.46449604630470276, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 14:27:19,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:19,093 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:07:13<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:26,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010822493582963943, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0077786496840417385, 'eval_loss_2': 0.003043845295906067, 'eval_loss_3': -18.1646671295166, 'eval_loss_4': -0.15674635767936707, 'epoch': 29.94}
{'loss': 0.009, 'grad_norm': 4.5055670738220215, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.0024639011826366186, 'loss_2': 0.006561279296875, 'loss_3': -16.315757751464844, 'loss_4': -0.24318553507328033, 'epoch': 29.95}
{'loss': 0.0137, 'grad_norm': 5.710031986236572, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.006155089475214481, 'loss_2': 0.007568359375, 'loss_3': -16.3824462890625, 'loss_4': -0.05338875576853752, 'epoch': 29.95}
{'loss': 0.0101, 'grad_norm': 5.284462928771973, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.006848367862403393, 'loss_2': 0.003223419189453125, 'loss_3': -16.50213623046875, 'loss_4': -0.2645018398761749, 'epoch': 29.96}
{'loss': 0.0023, 'grad_norm': 4.694817543029785, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0018253982998430729, 'loss_2': 0.0005197525024414062, 'loss_3': -16.449905395507812, 'loss_4': -0.19214478135108948, 'epoch': 29.97}
{'loss': 0.0124, 'grad_norm': 4.987711429595947, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.00719858892261982, 'loss_2': 0.0051727294921875, 'loss_3': -16.458003997802734, 'loss_4': -0.7175806760787964, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 14:27:26,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:26,441 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:20<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:27:33,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010816510766744614, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00776785658672452, 'eval_loss_2': 0.0030486546456813812, 'eval_loss_3': -18.16412353515625, 'eval_loss_4': -0.15588143467903137, 'epoch': 29.97}
{'loss': 0.0035, 'grad_norm': 4.582696437835693, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.0029690496157854795, 'loss_2': 0.0005488395690917969, 'loss_3': -16.267513275146484, 'loss_4': -0.5372558832168579, 'epoch': 29.98}
{'loss': 0.0355, 'grad_norm': 16.693960189819336, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.03145093098282814, 'loss_2': 0.00403594970703125, 'loss_3': -16.26375961303711, 'loss_4': 0.4063313603401184, 'epoch': 29.98}
{'loss': 0.0044, 'grad_norm': 4.400428295135498, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.00392107805237174, 'loss_2': 0.000461578369140625, 'loss_3': -16.403545379638672, 'loss_4': 0.09291565418243408, 'epoch': 29.99}
{'loss': 0.0072, 'grad_norm': 4.908041954040527, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.002930290764197707, 'loss_2': 0.0042877197265625, 'loss_3': -16.410966873168945, 'loss_4': 0.5061578750610352, 'epoch': 29.99}
{'loss': 0.0144, 'grad_norm': 6.878316879272461, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.0029620288405567408, 'loss_2': 0.011444091796875, 'loss_3': -16.494428634643555, 'loss_4': -0.426654189825058, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 14:27:33,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:33,430 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:24<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 14:27:37,241 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.010827441699802876, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007774991448968649, 'eval_loss_2': 0.003052450716495514, 'eval_loss_3': -18.163787841796875, 'eval_loss_4': -0.1556035429239273, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 14:27:37,241 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/checkpoint-4650 (score: 0.008880989626049995).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:24<00:00,  1.48s/it]
{'train_runtime': 7645.2534, 'train_samples_per_second': 43.078, 'train_steps_per_second': 0.675, 'train_loss': 0.03843063892489353, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 14:27:37,331 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32
[INFO|configuration_utils.py:420] 2025-01-21 14:27:37,332 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 14:27:37,858 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:27:37,859 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:27:37,859 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg32/special_tokens_map.json
01/21/2025 14:27:37 - INFO - __main__ -   ***** Train results *****
01/21/2025 14:27:37 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:37 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 14:27:37 - INFO - __main__ -     train_loss = 0.03843063892489353
01/21/2025 14:27:37 - INFO - __main__ -     train_runtime = 7645.2534
01/21/2025 14:27:37 - INFO - __main__ -     train_samples_per_second = 43.078
01/21/2025 14:27:37 - INFO - __main__ -     train_steps_per_second = 0.675
01/21/2025 14:27:38 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 14:27:38,085 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:27:38,085 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:38,085 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.56it/s]
01/21/2025 14:27:41 - INFO - __main__ -   ***** Eval results *****
01/21/2025 14:27:41 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:41 - INFO - __main__ -     eval_loss = 0.008880989626049995
01/21/2025 14:27:41 - INFO - __main__ -     eval_loss_1 = 0.00624203821644187
01/21/2025 14:27:41 - INFO - __main__ -     eval_loss_2 = 0.0026389509439468384
01/21/2025 14:27:41 - INFO - __main__ -     eval_loss_3 = -18.1298885345459
01/21/2025 14:27:41 - INFO - __main__ -     eval_loss_4 = -0.037394024431705475
01/21/2025 14:27:41 - INFO - __main__ -     eval_runtime = 3.7954
01/21/2025 14:27:41 - INFO - __main__ -     eval_samples_per_second = 269.797
01/21/2025 14:27:41 - INFO - __main__ -     eval_steps_per_second = 4.216
