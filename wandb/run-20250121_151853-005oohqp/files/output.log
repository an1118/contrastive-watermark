  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 15:18:54,608 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:05:35,  1.31it/s][INFO|trainer.py:4226] 2025-01-21 15:18:58,755 >>
{'loss': 3.9044, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.8275959491729736, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 4.2328, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 4.149497032165527, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 4.2044, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 4.135550498962402, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.7791, 'grad_norm': 136.07125854492188, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.712456464767456, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 4.2097, 'grad_norm': 112.47706604003906, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 4.137207984924316, 'loss_2': 0.07244873046875, 'loss_3': -13.623401641845703, 'loss_4': 9.391799926757812, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:58,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:58,755 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:05:35,  1.31it/s][INFO|trainer.py:3910] 2025-01-21 15:19:02,542 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 15:19:02,544 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5/config.json                                                                               
{'eval_loss': 2.103508710861206, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.517, 'eval_steps_per_second': 4.227, 'eval_loss_1': 2.045921802520752, 'eval_loss_2': 0.057586669921875, 'eval_loss_3': -17.856367111206055, 'eval_loss_4': 7.561459064483643, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:02,982 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:02,984 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:02,984 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:33:09,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 15:19:07,269 >>
{'loss': 3.9193, 'grad_norm': 130.51626586914062, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.861785888671875, 'loss_2': 0.05755615234375, 'loss_3': -13.962455749511719, 'loss_4': 8.161943435668945, 'epoch': 0.03}
{'loss': 3.5369, 'grad_norm': 129.16555786132812, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.4988491535186768, 'loss_2': 0.038055419921875, 'loss_3': -14.44304084777832, 'loss_4': 8.031900405883789, 'epoch': 0.04}
{'loss': 3.3537, 'grad_norm': 112.93692016601562, 'learning_rate': 2.997093023255814e-05, 'loss_1': 3.319798469543457, 'loss_2': 0.033935546875, 'loss_3': -14.893640518188477, 'loss_4': 6.727519989013672, 'epoch': 0.05}
{'loss': 3.1839, 'grad_norm': 122.45462799072266, 'learning_rate': 2.996511627906977e-05, 'loss_1': 3.150999069213867, 'loss_2': 0.032928466796875, 'loss_3': -14.869335174560547, 'loss_4': 6.574468612670898, 'epoch': 0.05}
{'loss': 3.0158, 'grad_norm': 127.7447280883789, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.991180896759033, 'loss_2': 0.0246429443359375, 'loss_3': -14.913042068481445, 'loss_4': 6.352126121520996, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:07,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:07,269 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:33:09,  1.09s/it][INFO|trainer.py:3910] 2025-01-21 15:19:11,058 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 15:19:11,060 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10/config.json                                                                              
{'eval_loss': 1.4005550146102905, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.36, 'eval_steps_per_second': 4.224, 'eval_loss_1': 1.3903145790100098, 'eval_loss_2': 0.010240316390991211, 'eval_loss_3': -18.077281951904297, 'eval_loss_4': 5.005828857421875, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:11,560 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:11,561 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:11,561 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:12,340 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:25,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:16,000 >>
{'loss': 2.3898, 'grad_norm': 110.1119384765625, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.372246503829956, 'loss_2': 0.0175323486328125, 'loss_3': -15.279153823852539, 'loss_4': 5.8009114265441895, 'epoch': 0.06}
{'loss': 2.7685, 'grad_norm': 122.7330322265625, 'learning_rate': 2.994767441860465e-05, 'loss_1': 2.7646496295928955, 'loss_2': 0.00382232666015625, 'loss_3': -14.91800594329834, 'loss_4': 4.459012985229492, 'epoch': 0.07}
{'loss': 2.5073, 'grad_norm': 133.16732788085938, 'learning_rate': 2.994186046511628e-05, 'loss_1': 2.50486421585083, 'loss_2': 0.00247955322265625, 'loss_3': -14.818190574645996, 'loss_4': 5.122323989868164, 'epoch': 0.08}
{'loss': 2.3367, 'grad_norm': 113.12008666992188, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 2.334838390350342, 'loss_2': 0.00182342529296875, 'loss_3': -14.984321594238281, 'loss_4': 4.430171966552734, 'epoch': 0.08}
{'loss': 1.9922, 'grad_norm': 126.90869140625, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.982336163520813, 'loss_2': 0.00982666015625, 'loss_3': -15.2836275100708, 'loss_4': 5.393219947814941, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:16,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:16,000 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:25,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:19:19,781 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 15:19:19,783 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15/config.json                                                                              
{'eval_loss': 0.9212101101875305, 'eval_runtime': 3.7804, 'eval_samples_per_second': 270.869, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.9173187613487244, 'eval_loss_2': 0.0038913488388061523, 'eval_loss_3': -18.097562789916992, 'eval_loss_4': 4.465429782867432, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:20,228 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:20,229 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:20,229 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:20,958 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:38:20,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:24,603 >>
{'loss': 1.8353, 'grad_norm': 107.8866958618164, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.8266301155090332, 'loss_2': 0.008697509765625, 'loss_3': -15.150007247924805, 'loss_4': 4.927684783935547, 'epoch': 0.09}
{'loss': 2.0312, 'grad_norm': 112.48973846435547, 'learning_rate': 2.991860465116279e-05, 'loss_1': 2.0215156078338623, 'loss_2': 0.00963592529296875, 'loss_3': -14.988872528076172, 'loss_4': 5.077371597290039, 'epoch': 0.1}
{'loss': 1.8472, 'grad_norm': 135.19435119628906, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.833419919013977, 'loss_2': 0.013763427734375, 'loss_3': -15.232115745544434, 'loss_4': 5.511569976806641, 'epoch': 0.1}
{'loss': 1.6531, 'grad_norm': 135.372314453125, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.646324872970581, 'loss_2': 0.0068206787109375, 'loss_3': -15.14046859741211, 'loss_4': 4.588837623596191, 'epoch': 0.11}
{'loss': 1.3654, 'grad_norm': 118.65641784667969, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 1.3563332557678223, 'loss_2': 0.0090789794921875, 'loss_3': -15.193737030029297, 'loss_4': 4.031440258026123, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:24,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:24,604 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:33<1:38:20,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:19:28,400 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 15:19:28,401 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20/config.json                                                                              
{'eval_loss': 0.40473759174346924, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.859, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.39542803168296814, 'eval_loss_2': 0.009309530258178711, 'eval_loss_3': -18.088706970214844, 'eval_loss_4': 5.2234320640563965, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:28,858 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:28,860 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:28,860 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:29,638 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:38<1:38:44,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:33,289 >>
{'loss': 1.1203, 'grad_norm': 103.63865661621094, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 1.1035404205322266, 'loss_2': 0.0167694091796875, 'loss_3': -15.193267822265625, 'loss_4': 4.775416374206543, 'epoch': 0.12}
{'loss': 0.9928, 'grad_norm': 96.58147430419922, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.9733185768127441, 'loss_2': 0.019500732421875, 'loss_3': -15.133249282836914, 'loss_4': 5.674239635467529, 'epoch': 0.13}
{'loss': 0.8624, 'grad_norm': 89.221435546875, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.8380933403968811, 'loss_2': 0.024261474609375, 'loss_3': -15.327709197998047, 'loss_4': 5.670056343078613, 'epoch': 0.13}
{'loss': 0.9505, 'grad_norm': 100.87149810791016, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.9268302321434021, 'loss_2': 0.023681640625, 'loss_3': -14.993709564208984, 'loss_4': 6.237104415893555, 'epoch': 0.14}
{'loss': 0.8893, 'grad_norm': 113.2546615600586, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.86134934425354, 'loss_2': 0.0279541015625, 'loss_3': -15.166178703308105, 'loss_4': 5.787487983703613, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:33,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:33,289 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:42<1:38:44,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:19:37,093 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 15:19:37,094 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25/config.json                                                                              
{'eval_loss': 0.2712610363960266, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.23723873496055603, 'eval_loss_2': 0.03402233123779297, 'eval_loss_3': -18.008724212646484, 'eval_loss_4': 6.104668140411377, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:37,551 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:37,553 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:37,553 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:38,333 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:38:35,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:41,964 >>
{'loss': 0.7493, 'grad_norm': 89.81806182861328, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.7118068933486938, 'loss_2': 0.0374755859375, 'loss_3': -15.269259452819824, 'loss_4': 6.287839889526367, 'epoch': 0.15}
{'loss': 0.9585, 'grad_norm': 94.60503387451172, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.9210329055786133, 'loss_2': 0.037506103515625, 'loss_3': -15.027109146118164, 'loss_4': 6.6451921463012695, 'epoch': 0.16}
{'loss': 0.814, 'grad_norm': 84.34660339355469, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.7806315422058105, 'loss_2': 0.03338623046875, 'loss_3': -14.956599235534668, 'loss_4': 6.016424655914307, 'epoch': 0.16}
{'loss': 0.6394, 'grad_norm': 88.8279800415039, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.6056941151618958, 'loss_2': 0.03369140625, 'loss_3': -15.124031066894531, 'loss_4': 5.610170841217041, 'epoch': 0.17}
{'loss': 0.5874, 'grad_norm': 82.37947845458984, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.5683874487876892, 'loss_2': 0.0190277099609375, 'loss_3': -15.058022499084473, 'loss_4': 6.502172946929932, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:41,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:41,964 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:51<1:38:35,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:19:45,758 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 15:19:45,760 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30/config.json                                                                              
{'eval_loss': 0.17270603775978088, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.992, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.150050550699234, 'eval_loss_2': 0.022655487060546875, 'eval_loss_3': -17.93486785888672, 'eval_loss_4': 5.287873268127441, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:46,215 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:46,216 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:46,217 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:46,982 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:56<1:38:17,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:50,615 >>
{'loss': 0.7431, 'grad_norm': 86.80229187011719, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.7278602123260498, 'loss_2': 0.01526641845703125, 'loss_3': -14.836485862731934, 'loss_4': 6.596291542053223, 'epoch': 0.18}
{'loss': 0.5192, 'grad_norm': 67.39388275146484, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.4941446781158447, 'loss_2': 0.0250701904296875, 'loss_3': -14.75507926940918, 'loss_4': 4.783058166503906, 'epoch': 0.19}
{'loss': 0.57, 'grad_norm': 84.4948501586914, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.5543646216392517, 'loss_2': 0.0156707763671875, 'loss_3': -14.873674392700195, 'loss_4': 4.633687973022461, 'epoch': 0.19}
{'loss': 0.4496, 'grad_norm': 69.07543182373047, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.4494248926639557, 'loss_2': 0.00019109249114990234, 'loss_3': -14.567523956298828, 'loss_4': 4.104898452758789, 'epoch': 0.2}
{'loss': 0.4416, 'grad_norm': 70.01155853271484, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.4384874105453491, 'loss_2': 0.00311279296875, 'loss_3': -14.770895004272461, 'loss_4': 4.201417446136475, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:50,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:50,615 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:59<1:38:17,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:19:54,411 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 15:19:54,412 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35/config.json                                                                              
{'eval_loss': 0.15796154737472534, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.879, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.1518581509590149, 'eval_loss_2': 0.006103396415710449, 'eval_loss_3': -17.775272369384766, 'eval_loss_4': 3.6002426147460938, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:54,869 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:54,870 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:54,871 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:55,679 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:04<1:38:27,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:59,312 >>
{'loss': 0.3615, 'grad_norm': 59.60040283203125, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.350263774394989, 'loss_2': 0.011199951171875, 'loss_3': -14.669830322265625, 'loss_4': 3.7758543491363525, 'epoch': 0.21}
{'loss': 0.3436, 'grad_norm': 60.586368560791016, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.334405779838562, 'loss_2': 0.0091552734375, 'loss_3': -14.828620910644531, 'loss_4': 3.6427226066589355, 'epoch': 0.22}
{'loss': 0.4809, 'grad_norm': 78.71116638183594, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.4751582443714142, 'loss_2': 0.005706787109375, 'loss_3': -14.703895568847656, 'loss_4': 3.575051784515381, 'epoch': 0.22}
{'loss': 0.2739, 'grad_norm': 43.851409912109375, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.26846620440483093, 'loss_2': 0.0054779052734375, 'loss_3': -14.808330535888672, 'loss_4': 2.2136588096618652, 'epoch': 0.23}
{'loss': 0.3635, 'grad_norm': 52.85078430175781, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.3603416979312897, 'loss_2': 0.003116607666015625, 'loss_3': -14.862765312194824, 'loss_4': 2.6064047813415527, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:59,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:59,313 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:08<1:38:27,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:20:03,106 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40
[INFO|configuration_utils.py:420] 2025-01-21 15:20:03,107 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40/config.json                                                                              
{'eval_loss': 0.10796305537223816, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.046, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.10247442871332169, 'eval_loss_2': 0.00548863410949707, 'eval_loss_3': -17.933757781982422, 'eval_loss_4': 2.63545560836792, 'epoch': 0.23}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:03,567 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:03,568 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:03,568 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:04,340 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-35] due to args.save_total_limit
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:13<1:38:11,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:20:07,974 >>
{'loss': 0.2445, 'grad_norm': 36.9662971496582, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.2385610044002533, 'loss_2': 0.005924224853515625, 'loss_3': -15.208054542541504, 'loss_4': 2.7037196159362793, 'epoch': 0.24}
{'loss': 0.2685, 'grad_norm': 39.83148956298828, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.261861652135849, 'loss_2': 0.00664520263671875, 'loss_3': -14.85107421875, 'loss_4': 2.052546977996826, 'epoch': 0.24}
{'loss': 0.339, 'grad_norm': 54.47209167480469, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.3211910128593445, 'loss_2': 0.017852783203125, 'loss_3': -15.07919979095459, 'loss_4': 3.070488691329956, 'epoch': 0.25}
{'loss': 0.4955, 'grad_norm': 66.33146667480469, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.490619957447052, 'loss_2': 0.00485992431640625, 'loss_3': -15.256606101989746, 'loss_4': 4.176702499389648, 'epoch': 0.26}
{'loss': 0.3944, 'grad_norm': 61.893917083740234, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.3890208601951599, 'loss_2': 0.00533294677734375, 'loss_3': -15.13332462310791, 'loss_4': 4.133615970611572, 'epoch': 0.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:20:07,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:07,975 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:17<1:38:11,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:20:11,776 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 15:20:11,778 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45/config.json                                                                              
{'eval_loss': 0.08713841438293457, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.448, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.08106851577758789, 'eval_loss_2': 0.00606989860534668, 'eval_loss_3': -18.14869499206543, 'eval_loss_4': 2.6567468643188477, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:12,237 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:12,238 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:12,238 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:13,021 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-40] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:22<1:37:57,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:20:16,633 >>
{'loss': 0.2801, 'grad_norm': 49.33736801147461, 'learning_rate': 2.975e-05, 'loss_1': 0.2753797769546509, 'loss_2': 0.004764556884765625, 'loss_3': -15.221471786499023, 'loss_4': 2.9835734367370605, 'epoch': 0.27}
{'loss': 0.3021, 'grad_norm': 44.07627487182617, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.2983807623386383, 'loss_2': 0.003704071044921875, 'loss_3': -15.003525733947754, 'loss_4': 2.085958957672119, 'epoch': 0.27}
{'loss': 0.4511, 'grad_norm': 59.83094024658203, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.4435984194278717, 'loss_2': 0.00754547119140625, 'loss_3': -14.969535827636719, 'loss_4': 1.6654940843582153, 'epoch': 0.28}
{'loss': 0.3248, 'grad_norm': 56.63811492919922, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.3183521628379822, 'loss_2': 0.00644683837890625, 'loss_3': -14.900262832641602, 'loss_4': 1.8242627382278442, 'epoch': 0.28}
{'loss': 0.3165, 'grad_norm': 48.83181381225586, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.31004035472869873, 'loss_2': 0.00644683837890625, 'loss_3': -14.877580642700195, 'loss_4': 0.7932610511779785, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:20:16,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:16,634 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:29<1:29:52,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:20:23,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10920560359954834, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.945, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.1030067503452301, 'eval_loss_2': 0.006198853254318237, 'eval_loss_3': -17.8466854095459, 'eval_loss_4': 1.1205689907073975, 'epoch': 0.29}
{'loss': 0.3032, 'grad_norm': 48.71464920043945, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.3012116551399231, 'loss_2': 0.001995086669921875, 'loss_3': -14.9696044921875, 'loss_4': 1.0529969930648804, 'epoch': 0.3}
{'loss': 0.2873, 'grad_norm': 45.159271240234375, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.2751917839050293, 'loss_2': 0.01212310791015625, 'loss_3': -14.902318954467773, 'loss_4': 1.5075325965881348, 'epoch': 0.3}
{'loss': 0.1666, 'grad_norm': 26.426042556762695, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.155882328748703, 'loss_2': 0.010711669921875, 'loss_3': -14.739925384521484, 'loss_4': 1.3307116031646729, 'epoch': 0.31}
{'loss': 0.3947, 'grad_norm': 65.94100952148438, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.38191866874694824, 'loss_2': 0.0127410888671875, 'loss_3': -14.448405265808105, 'loss_4': 2.1120240688323975, 'epoch': 0.31}
{'loss': 0.1696, 'grad_norm': 35.01778793334961, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.1589006930589676, 'loss_2': 0.0106964111328125, 'loss_3': -14.63294506072998, 'loss_4': 1.215848445892334, 'epoch': 0.32}
[INFO|trainer.py:4228] 2025-01-21 15:20:23,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:23,968 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:36<1:28:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:31,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1743629276752472, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.726, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.1647959053516388, 'eval_loss_2': 0.009567022323608398, 'eval_loss_3': -17.546783447265625, 'eval_loss_4': 2.1278200149536133, 'epoch': 0.32}
{'loss': 0.2016, 'grad_norm': 36.66069030761719, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.1979072093963623, 'loss_2': 0.0036640167236328125, 'loss_3': -14.676843643188477, 'loss_4': 1.3825645446777344, 'epoch': 0.33}
{'loss': 0.2006, 'grad_norm': 42.379329681396484, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.18310405313968658, 'loss_2': 0.0174713134765625, 'loss_3': -14.620845794677734, 'loss_4': 1.9433969259262085, 'epoch': 0.33}
{'loss': 0.2035, 'grad_norm': 40.01305389404297, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.19496285915374756, 'loss_2': 0.0085601806640625, 'loss_3': -14.607749938964844, 'loss_4': 1.4221874475479126, 'epoch': 0.34}
{'loss': 0.1962, 'grad_norm': 42.09396743774414, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.19096794724464417, 'loss_2': 0.005237579345703125, 'loss_3': -14.661340713500977, 'loss_4': 1.7941795587539673, 'epoch': 0.34}
{'loss': 0.1407, 'grad_norm': 33.75204086303711, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.13768690824508667, 'loss_2': 0.00301361083984375, 'loss_3': -14.778621673583984, 'loss_4': 1.5992318391799927, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 15:20:31,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:31,309 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:40<1:28:23,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:20:35,108 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 15:20:35,110 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60/config.json                                                                              
{'eval_loss': 0.05941154435276985, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.055203620344400406, 'eval_loss_2': 0.004207924008369446, 'eval_loss_3': -17.862247467041016, 'eval_loss_4': 2.0357182025909424, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:35,586 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:35,587 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:35,587 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:36,372 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-45] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:45<1:36:24,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:20:40,004 >>
{'loss': 0.1996, 'grad_norm': 43.03902053833008, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.1974530816078186, 'loss_2': 0.00212860107421875, 'loss_3': -14.678348541259766, 'loss_4': 2.031972646713257, 'epoch': 0.35}
{'loss': 0.1715, 'grad_norm': 30.4137020111084, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.17071250081062317, 'loss_2': 0.0007781982421875, 'loss_3': -14.60507869720459, 'loss_4': 2.0825154781341553, 'epoch': 0.36}
{'loss': 0.175, 'grad_norm': 40.08689880371094, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.16299760341644287, 'loss_2': 0.0120086669921875, 'loss_3': -14.998455047607422, 'loss_4': 2.2730884552001953, 'epoch': 0.37}
{'loss': 0.1585, 'grad_norm': 36.348331451416016, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.15443521738052368, 'loss_2': 0.004047393798828125, 'loss_3': -14.910242080688477, 'loss_4': 3.0116426944732666, 'epoch': 0.37}
{'loss': 0.2563, 'grad_norm': 48.19205093383789, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.25119271874427795, 'loss_2': 0.0051422119140625, 'loss_3': -14.739456176757812, 'loss_4': 3.4578590393066406, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:20:40,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:40,005 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:52<1:29:24,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:20:47,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06130904704332352, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.639, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.054778698831796646, 'eval_loss_2': 0.006530344486236572, 'eval_loss_3': -18.043704986572266, 'eval_loss_4': 3.1516990661621094, 'epoch': 0.38}
{'loss': 0.2188, 'grad_norm': 43.588993072509766, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.2132454663515091, 'loss_2': 0.005504608154296875, 'loss_3': -14.975200653076172, 'loss_4': 3.2602765560150146, 'epoch': 0.38}
{'loss': 0.1933, 'grad_norm': 37.4312629699707, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.18481449782848358, 'loss_2': 0.008453369140625, 'loss_3': -14.779189109802246, 'loss_4': 3.8203086853027344, 'epoch': 0.39}
{'loss': 0.2107, 'grad_norm': 38.39015579223633, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.20349864661693573, 'loss_2': 0.00720977783203125, 'loss_3': -14.864200592041016, 'loss_4': 3.5332577228546143, 'epoch': 0.4}
{'loss': 0.2157, 'grad_norm': 35.399009704589844, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.20937460660934448, 'loss_2': 0.00634765625, 'loss_3': -14.736167907714844, 'loss_4': 3.951852321624756, 'epoch': 0.4}
{'loss': 0.1526, 'grad_norm': 32.49947738647461, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.15211574733257294, 'loss_2': 0.0004398822784423828, 'loss_3': -14.918336868286133, 'loss_4': 2.9764270782470703, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 15:20:47,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:47,348 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:56<1:29:24,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 15:20:51,150 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70
[INFO|configuration_utils.py:420] 2025-01-21 15:20:51,152 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70/config.json                                                                              
{'eval_loss': 0.05447179079055786, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0476347953081131, 'eval_loss_2': 0.006836991757154465, 'eval_loss_3': -17.985307693481445, 'eval_loss_4': 2.9723806381225586, 'epoch': 0.41}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:51,623 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:51,624 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:51,625 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:52,404 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-60] due to args.save_total_limit
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:01<1:36:26,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:20:56,040 >>
{'loss': 0.1509, 'grad_norm': 35.94477844238281, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.14999894797801971, 'loss_2': 0.000865936279296875, 'loss_3': -14.718781471252441, 'loss_4': 2.7266249656677246, 'epoch': 0.41}
{'loss': 0.2123, 'grad_norm': 36.50507736206055, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.20621420443058014, 'loss_2': 0.00611114501953125, 'loss_3': -14.867478370666504, 'loss_4': 2.872804641723633, 'epoch': 0.42}
{'loss': 0.1634, 'grad_norm': 30.32933807373047, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.15333133935928345, 'loss_2': 0.01007080078125, 'loss_3': -14.796510696411133, 'loss_4': 3.522695541381836, 'epoch': 0.42}
{'loss': 0.1537, 'grad_norm': 31.8787899017334, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.15008427202701569, 'loss_2': 0.003650665283203125, 'loss_3': -14.573019027709961, 'loss_4': 2.678623676300049, 'epoch': 0.43}
{'loss': 0.1035, 'grad_norm': 21.41531753540039, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.09942938387393951, 'loss_2': 0.0040435791015625, 'loss_3': -14.787633895874023, 'loss_4': 2.8082375526428223, 'epoch': 0.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:20:56,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:56,040 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:08<1:29:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:21:03,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07048502564430237, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.06669702380895615, 'eval_loss_2': 0.003788001835346222, 'eval_loss_3': -17.887231826782227, 'eval_loss_4': 3.142317771911621, 'epoch': 0.44}
{'loss': 0.1249, 'grad_norm': 34.85902404785156, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.12101155519485474, 'loss_2': 0.00392913818359375, 'loss_3': -14.759268760681152, 'loss_4': 3.276806116104126, 'epoch': 0.44}
{'loss': 0.1315, 'grad_norm': 31.347198486328125, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.12960796058177948, 'loss_2': 0.0019359588623046875, 'loss_3': -14.742494583129883, 'loss_4': 2.4708099365234375, 'epoch': 0.45}
{'loss': 0.2113, 'grad_norm': 35.90861129760742, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.20363570749759674, 'loss_2': 0.00762939453125, 'loss_3': -14.731566429138184, 'loss_4': 2.8284244537353516, 'epoch': 0.45}
{'loss': 0.1715, 'grad_norm': 38.45799255371094, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.1582677662372589, 'loss_2': 0.0132293701171875, 'loss_3': -14.795960426330566, 'loss_4': 3.5493664741516113, 'epoch': 0.46}
{'loss': 0.1264, 'grad_norm': 29.573183059692383, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.12076795101165771, 'loss_2': 0.005680084228515625, 'loss_3': -14.937606811523438, 'loss_4': 2.701181173324585, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 15:21:03,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:03,390 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:16<1:28:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:10,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08084976673126221, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.814, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.07314074039459229, 'eval_loss_2': 0.007709026336669922, 'eval_loss_3': -17.839597702026367, 'eval_loss_4': 2.9788901805877686, 'epoch': 0.47}
{'loss': 0.1441, 'grad_norm': 34.79983901977539, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.13950863480567932, 'loss_2': 0.004547119140625, 'loss_3': -14.699469566345215, 'loss_4': 3.161961793899536, 'epoch': 0.47}
{'loss': 0.1765, 'grad_norm': 35.07230758666992, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.17380164563655853, 'loss_2': 0.0026493072509765625, 'loss_3': -14.711076736450195, 'loss_4': 2.54544997215271, 'epoch': 0.48}
{'loss': 0.2093, 'grad_norm': 52.946563720703125, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.20879316329956055, 'loss_2': 0.0005364418029785156, 'loss_3': -14.861937522888184, 'loss_4': 2.6282362937927246, 'epoch': 0.48}
{'loss': 0.1618, 'grad_norm': 34.821773529052734, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.15328533947467804, 'loss_2': 0.0084686279296875, 'loss_3': -15.064882278442383, 'loss_4': 2.9589438438415527, 'epoch': 0.49}
{'loss': 0.2041, 'grad_norm': 43.19929504394531, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.19677656888961792, 'loss_2': 0.00733184814453125, 'loss_3': -14.916657447814941, 'loss_4': 3.4313290119171143, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 15:21:10,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:10,734 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:19<1:28:02,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:21:14,536 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85
[INFO|configuration_utils.py:420] 2025-01-21 15:21:14,537 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85/config.json                                                                              
{'eval_loss': 0.049304790794849396, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.04265593737363815, 'eval_loss_2': 0.006648853421211243, 'eval_loss_3': -18.061145782470703, 'eval_loss_4': 2.6467907428741455, 'epoch': 0.49}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:15,010 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:15,012 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:15,012 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:15,796 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-70] due to args.save_total_limit
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:35:58,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:21:19,430 >>
{'loss': 0.1463, 'grad_norm': 33.626949310302734, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.1406245231628418, 'loss_2': 0.005649566650390625, 'loss_3': -14.755342483520508, 'loss_4': 3.2911338806152344, 'epoch': 0.5}
{'loss': 0.1544, 'grad_norm': 31.247642517089844, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.14063099026679993, 'loss_2': 0.0137481689453125, 'loss_3': -15.280750274658203, 'loss_4': 3.235323429107666, 'epoch': 0.51}
{'loss': 0.2785, 'grad_norm': 43.14909362792969, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.27445071935653687, 'loss_2': 0.004085540771484375, 'loss_3': -14.960235595703125, 'loss_4': 3.2035603523254395, 'epoch': 0.51}
{'loss': 0.164, 'grad_norm': 31.219844818115234, 'learning_rate': 2.95e-05, 'loss_1': 0.16267307102680206, 'loss_2': 0.0013017654418945312, 'loss_3': -14.964420318603516, 'loss_4': 3.0717480182647705, 'epoch': 0.52}
{'loss': 0.1407, 'grad_norm': 28.948087692260742, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.13212551176548004, 'loss_2': 0.00860595703125, 'loss_3': -15.097131729125977, 'loss_4': 3.1183958053588867, 'epoch': 0.52}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:19,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:19,430 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:28<1:35:58,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 15:21:23,223 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90
[INFO|configuration_utils.py:420] 2025-01-21 15:21:23,224 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90/config.json                                                                              
{'eval_loss': 0.041408687829971313, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.079, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0360848531126976, 'eval_loss_2': 0.005323838442564011, 'eval_loss_3': -18.125343322753906, 'eval_loss_4': 2.580709457397461, 'epoch': 0.52}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:23,674 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:23,676 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:23,676 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:24,457 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-85] due to args.save_total_limit
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:33<1:37:05,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:21:28,111 >>
{'loss': 0.2399, 'grad_norm': 59.72078323364258, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.2374633252620697, 'loss_2': 0.002407073974609375, 'loss_3': -15.003532409667969, 'loss_4': 3.4200258255004883, 'epoch': 0.53}
{'loss': 0.1284, 'grad_norm': 28.259403228759766, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.12506604194641113, 'loss_2': 0.00334930419921875, 'loss_3': -15.039129257202148, 'loss_4': 3.310192584991455, 'epoch': 0.53}
{'loss': 0.1449, 'grad_norm': 30.41375160217285, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.1406608521938324, 'loss_2': 0.00424957275390625, 'loss_3': -14.913870811462402, 'loss_4': 2.8506689071655273, 'epoch': 0.54}
{'loss': 0.2536, 'grad_norm': 36.56846618652344, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.2416241466999054, 'loss_2': 0.0120086669921875, 'loss_3': -14.937155723571777, 'loss_4': 2.3499755859375, 'epoch': 0.55}
{'loss': 0.2008, 'grad_norm': 41.94607162475586, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.19873054325580597, 'loss_2': 0.0020599365234375, 'loss_3': -14.848551750183105, 'loss_4': 2.768742799758911, 'epoch': 0.55}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:28,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:28,111 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:40<1:29:08,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:21:35,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04412902146577835, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.593, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03511524945497513, 'eval_loss_2': 0.009013772010803223, 'eval_loss_3': -18.147140502929688, 'eval_loss_4': 2.411620616912842, 'epoch': 0.55}
{'loss': 0.2965, 'grad_norm': 47.437171936035156, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.2959674298763275, 'loss_2': 0.0004851818084716797, 'loss_3': -14.85987377166748, 'loss_4': 2.940394401550293, 'epoch': 0.56}
{'loss': 0.1511, 'grad_norm': 30.5051326751709, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.13632287085056305, 'loss_2': 0.01477813720703125, 'loss_3': -14.764869689941406, 'loss_4': 2.636263608932495, 'epoch': 0.56}
{'loss': 0.2428, 'grad_norm': 48.24864959716797, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.23638343811035156, 'loss_2': 0.00641632080078125, 'loss_3': -14.79214859008789, 'loss_4': 2.5612783432006836, 'epoch': 0.57}
{'loss': 0.2116, 'grad_norm': 45.32863235473633, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.20991435647010803, 'loss_2': 0.0016632080078125, 'loss_3': -14.837085723876953, 'loss_4': 2.7896323204040527, 'epoch': 0.58}
{'loss': 0.2301, 'grad_norm': 39.73368835449219, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.22793984413146973, 'loss_2': 0.00220489501953125, 'loss_3': -14.91564655303955, 'loss_4': 2.838207960128784, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 15:21:35,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:35,457 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:48<1:27:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:42,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05248681828379631, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.175, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.04632687568664551, 'eval_loss_2': 0.006159946322441101, 'eval_loss_3': -18.1055965423584, 'eval_loss_4': 2.51836895942688, 'epoch': 0.58}
{'loss': 0.1483, 'grad_norm': 24.735565185546875, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.14409591257572174, 'loss_2': 0.00415802001953125, 'loss_3': -14.990350723266602, 'loss_4': 2.1422417163848877, 'epoch': 0.59}
{'loss': 0.2093, 'grad_norm': 39.547027587890625, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.20659470558166504, 'loss_2': 0.00274658203125, 'loss_3': -14.791308403015137, 'loss_4': 2.751282215118408, 'epoch': 0.59}
{'loss': 0.2043, 'grad_norm': 37.17949676513672, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.1980767548084259, 'loss_2': 0.00620269775390625, 'loss_3': -14.821544647216797, 'loss_4': 3.859746217727661, 'epoch': 0.6}
{'loss': 0.194, 'grad_norm': 35.81733322143555, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.1835128664970398, 'loss_2': 0.01047515869140625, 'loss_3': -14.759960174560547, 'loss_4': 3.015016794204712, 'epoch': 0.6}
{'loss': 0.1809, 'grad_norm': 41.05256271362305, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.1683228313922882, 'loss_2': 0.01258087158203125, 'loss_3': -15.146774291992188, 'loss_4': 3.6380510330200195, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 15:21:42,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:42,817 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:55<1:27:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:50,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.057078175246715546, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.049227528274059296, 'eval_loss_2': 0.00785064697265625, 'eval_loss_3': -18.120037078857422, 'eval_loss_4': 3.084493637084961, 'epoch': 0.61}
{'loss': 0.1395, 'grad_norm': 30.599010467529297, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.12464477121829987, 'loss_2': 0.0148162841796875, 'loss_3': -15.01152229309082, 'loss_4': 3.13679838180542, 'epoch': 0.62}
{'loss': 0.2883, 'grad_norm': 52.787784576416016, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.2712356150150299, 'loss_2': 0.0170745849609375, 'loss_3': -14.842016220092773, 'loss_4': 3.590665102005005, 'epoch': 0.62}
{'loss': 0.1936, 'grad_norm': 54.001434326171875, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.1902652531862259, 'loss_2': 0.0033111572265625, 'loss_3': -14.93548583984375, 'loss_4': 3.4491448402404785, 'epoch': 0.63}
{'loss': 0.0799, 'grad_norm': 16.656105041503906, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.07790951430797577, 'loss_2': 0.002017974853515625, 'loss_3': -15.14222526550293, 'loss_4': 3.022311210632324, 'epoch': 0.63}
{'loss': 0.2178, 'grad_norm': 40.549068450927734, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.21015095710754395, 'loss_2': 0.00766754150390625, 'loss_3': -14.903922080993652, 'loss_4': 3.676831007003784, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 15:21:50,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:50,168 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:02<1:27:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:57,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05639565736055374, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.794, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0522368922829628, 'eval_loss_2': 0.004158765077590942, 'eval_loss_3': -18.082996368408203, 'eval_loss_4': 3.307025671005249, 'epoch': 0.64}
{'loss': 0.3208, 'grad_norm': 55.516151428222656, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.3140876293182373, 'loss_2': 0.00667572021484375, 'loss_3': -14.763690948486328, 'loss_4': 3.52349853515625, 'epoch': 0.65}
{'loss': 0.243, 'grad_norm': 42.968265533447266, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.2388707995414734, 'loss_2': 0.004116058349609375, 'loss_3': -14.87511157989502, 'loss_4': 3.724705696105957, 'epoch': 0.65}
{'loss': 0.1982, 'grad_norm': 44.25362014770508, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.19648171961307526, 'loss_2': 0.0017547607421875, 'loss_3': -14.824386596679688, 'loss_4': 3.813741683959961, 'epoch': 0.66}
{'loss': 0.1043, 'grad_norm': 22.70781898498535, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.10178668797016144, 'loss_2': 0.0025177001953125, 'loss_3': -14.930240631103516, 'loss_4': 3.4158854484558105, 'epoch': 0.66}
{'loss': 0.1756, 'grad_norm': 37.402645111083984, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.17264963686466217, 'loss_2': 0.002960205078125, 'loss_3': -14.83103084564209, 'loss_4': 3.530789852142334, 'epoch': 0.67}
[INFO|trainer.py:4228] 2025-01-21 15:21:57,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:57,522 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:10<1:27:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:04,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07664380222558975, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.07319687306880951, 'eval_loss_2': 0.003446921706199646, 'eval_loss_3': -17.944019317626953, 'eval_loss_4': 3.440626859664917, 'epoch': 0.67}
{'loss': 0.1812, 'grad_norm': 32.552433013916016, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.18002405762672424, 'loss_2': 0.001224517822265625, 'loss_3': -14.970765113830566, 'loss_4': 3.662217140197754, 'epoch': 0.67}
{'loss': 0.1342, 'grad_norm': 27.969079971313477, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.12626376748085022, 'loss_2': 0.00791168212890625, 'loss_3': -15.001805305480957, 'loss_4': 3.1746325492858887, 'epoch': 0.68}
{'loss': 0.1613, 'grad_norm': 32.86339569091797, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.1562783271074295, 'loss_2': 0.0050506591796875, 'loss_3': -14.881145477294922, 'loss_4': 3.1463470458984375, 'epoch': 0.69}
{'loss': 0.1405, 'grad_norm': 37.360374450683594, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.13456013798713684, 'loss_2': 0.00592041015625, 'loss_3': -14.673282623291016, 'loss_4': 3.060537576675415, 'epoch': 0.69}
{'loss': 0.1662, 'grad_norm': 27.649232864379883, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.15575788915157318, 'loss_2': 0.01047515869140625, 'loss_3': -14.853372573852539, 'loss_4': 2.8440961837768555, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 15:22:04,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:04,877 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:14<1:27:17,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:22:08,681 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120
[INFO|configuration_utils.py:420] 2025-01-21 15:22:08,683 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120/config.json                                                                             
{'eval_loss': 0.04078678786754608, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.035571444779634476, 'eval_loss_2': 0.005215339362621307, 'eval_loss_3': -18.05237579345703, 'eval_loss_4': 2.523543119430542, 'epoch': 0.7}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:09,162 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:09,163 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:09,163 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:09,964 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-90] due to args.save_total_limit
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:19<1:35:25,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:22:13,596 >>
{'loss': 0.0855, 'grad_norm': 21.592159271240234, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.0746644139289856, 'loss_2': 0.01085662841796875, 'loss_3': -14.81203842163086, 'loss_4': 2.4225893020629883, 'epoch': 0.7}
{'loss': 0.0862, 'grad_norm': 24.077465057373047, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.08243092149496078, 'loss_2': 0.0037689208984375, 'loss_3': -14.69692325592041, 'loss_4': 2.5345458984375, 'epoch': 0.71}
{'loss': 0.1145, 'grad_norm': 25.473852157592773, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.10081378370523453, 'loss_2': 0.01372528076171875, 'loss_3': -15.134469985961914, 'loss_4': 2.1005706787109375, 'epoch': 0.72}
{'loss': 0.1933, 'grad_norm': 40.46541976928711, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.17936769127845764, 'loss_2': 0.013916015625, 'loss_3': -15.023630142211914, 'loss_4': 1.9318556785583496, 'epoch': 0.72}
{'loss': 0.0698, 'grad_norm': 18.17253875732422, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.06917547434568405, 'loss_2': 0.000621795654296875, 'loss_3': -14.86062240600586, 'loss_4': 1.979925513267517, 'epoch': 0.73}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:13,596 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:13,596 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:22<1:35:25,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 15:22:17,394 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125
[INFO|configuration_utils.py:420] 2025-01-21 15:22:17,396 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125/config.json                                                                             
{'eval_loss': 0.028553256765007973, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.023669607937335968, 'eval_loss_2': 0.0048836469650268555, 'eval_loss_3': -18.169748306274414, 'eval_loss_4': 2.0118391513824463, 'epoch': 0.73}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:17,853 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:17,854 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:17,855 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:18,661 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-120] due to args.save_total_limit
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:27<1:36:43,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:22:22,312 >>
{'loss': 0.0876, 'grad_norm': 21.850482940673828, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.08647380024194717, 'loss_2': 0.0011196136474609375, 'loss_3': -15.18387508392334, 'loss_4': 1.9627736806869507, 'epoch': 0.73}
{'loss': 0.1329, 'grad_norm': 30.11378288269043, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.1321643888950348, 'loss_2': 0.0007176399230957031, 'loss_3': -14.749744415283203, 'loss_4': 1.9994161128997803, 'epoch': 0.74}
{'loss': 0.1708, 'grad_norm': 28.5764102935791, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.16868406534194946, 'loss_2': 0.002094268798828125, 'loss_3': -14.967142105102539, 'loss_4': 1.7399682998657227, 'epoch': 0.74}
{'loss': 0.1569, 'grad_norm': 31.59246063232422, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.1474674940109253, 'loss_2': 0.00946044921875, 'loss_3': -15.12363052368164, 'loss_4': 2.459251880645752, 'epoch': 0.75}
{'loss': 0.105, 'grad_norm': 20.942163467407227, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.09157951921224594, 'loss_2': 0.01343536376953125, 'loss_3': -15.104870796203613, 'loss_4': 2.0596628189086914, 'epoch': 0.76}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:22,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:22,312 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:35<1:28:38,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:22:29,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028977110981941223, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.024627700448036194, 'eval_loss_2': 0.004349410533905029, 'eval_loss_3': -18.18010139465332, 'eval_loss_4': 1.589858055114746, 'epoch': 0.76}
{'loss': 0.184, 'grad_norm': 44.84364700317383, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.179605633020401, 'loss_2': 0.004425048828125, 'loss_3': -15.152153015136719, 'loss_4': 2.069882869720459, 'epoch': 0.76}
{'loss': 0.1137, 'grad_norm': 27.55368423461914, 'learning_rate': 2.925e-05, 'loss_1': 0.10229215770959854, 'loss_2': 0.01141357421875, 'loss_3': -14.955162048339844, 'loss_4': 1.9637705087661743, 'epoch': 0.77}
{'loss': 0.2162, 'grad_norm': 46.5813102722168, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.20024655759334564, 'loss_2': 0.0159149169921875, 'loss_3': -14.897659301757812, 'loss_4': 1.1946927309036255, 'epoch': 0.77}
{'loss': 0.1042, 'grad_norm': 32.00598907470703, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.09969884902238846, 'loss_2': 0.004486083984375, 'loss_3': -15.151403427124023, 'loss_4': 0.934292733669281, 'epoch': 0.78}
{'loss': 0.1527, 'grad_norm': 33.62480926513672, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.1497243195772171, 'loss_2': 0.003021240234375, 'loss_3': -15.061436653137207, 'loss_4': 1.0282915830612183, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 15:22:29,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:29,662 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:42<1:27:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:37,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029407404363155365, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.025625934824347496, 'eval_loss_2': 0.0037814676761627197, 'eval_loss_3': -18.11803436279297, 'eval_loss_4': 0.7132335901260376, 'epoch': 0.78}
{'loss': 0.0694, 'grad_norm': 16.369773864746094, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.06652373820543289, 'loss_2': 0.002872467041015625, 'loss_3': -15.064950942993164, 'loss_4': 0.5554975867271423, 'epoch': 0.79}
{'loss': 0.1683, 'grad_norm': 37.07429885864258, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.16176940500736237, 'loss_2': 0.0065155029296875, 'loss_3': -14.989224433898926, 'loss_4': 0.9595994353294373, 'epoch': 0.8}
{'loss': 0.1191, 'grad_norm': 27.908279418945312, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.11441420763731003, 'loss_2': 0.00470733642578125, 'loss_3': -14.939258575439453, 'loss_4': 0.7322688102722168, 'epoch': 0.8}
{'loss': 0.0937, 'grad_norm': 19.795217514038086, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.08967053145170212, 'loss_2': 0.004070281982421875, 'loss_3': -15.241559028625488, 'loss_4': 0.3454243242740631, 'epoch': 0.81}
{'loss': 0.0954, 'grad_norm': 20.428665161132812, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.09513738751411438, 'loss_2': 0.00023853778839111328, 'loss_3': -14.993453979492188, 'loss_4': 0.9116781949996948, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 15:22:37,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:37,011 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:49<1:26:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:44,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04726140946149826, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.798, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.04222642630338669, 'eval_loss_2': 0.005034983158111572, 'eval_loss_3': -17.978885650634766, 'eval_loss_4': 0.7212364673614502, 'epoch': 0.81}
{'loss': 0.0896, 'grad_norm': 24.540348052978516, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.08760431408882141, 'loss_2': 0.002033233642578125, 'loss_3': -15.092443466186523, 'loss_4': 0.5457077026367188, 'epoch': 0.82}
{'loss': 0.1158, 'grad_norm': 29.397701263427734, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.1157655119895935, 'loss_2': 6.264448165893555e-05, 'loss_3': -14.908843994140625, 'loss_4': 1.0129765272140503, 'epoch': 0.83}
{'loss': 0.0837, 'grad_norm': 18.429391860961914, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.07219985127449036, 'loss_2': 0.0114898681640625, 'loss_3': -14.923465728759766, 'loss_4': 0.42476826906204224, 'epoch': 0.83}
{'loss': 0.1145, 'grad_norm': 27.779802322387695, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.11020809412002563, 'loss_2': 0.004302978515625, 'loss_3': -15.202470779418945, 'loss_4': 0.6095102429389954, 'epoch': 0.84}
{'loss': 0.0777, 'grad_norm': 22.191280364990234, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.07151716947555542, 'loss_2': 0.006206512451171875, 'loss_3': -14.928028106689453, 'loss_4': 1.4559326171875, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 15:22:44,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:44,356 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:57<1:26:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:51,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.055126383900642395, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0503704659640789, 'eval_loss_2': 0.004755914211273193, 'eval_loss_3': -17.922433853149414, 'eval_loss_4': 1.2454328536987305, 'epoch': 0.84}
{'loss': 0.1626, 'grad_norm': 34.04265213012695, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.15564990043640137, 'loss_2': 0.00698089599609375, 'loss_3': -14.83234691619873, 'loss_4': 1.1099931001663208, 'epoch': 0.85}
{'loss': 0.1512, 'grad_norm': 32.617313385009766, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.1431320160627365, 'loss_2': 0.0080718994140625, 'loss_3': -14.950864791870117, 'loss_4': 1.9209537506103516, 'epoch': 0.85}
{'loss': 0.1364, 'grad_norm': 38.27631378173828, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.1334906816482544, 'loss_2': 0.002899169921875, 'loss_3': -14.792858123779297, 'loss_4': 1.6251394748687744, 'epoch': 0.86}
{'loss': 0.065, 'grad_norm': 16.39399528503418, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.05469340458512306, 'loss_2': 0.0102691650390625, 'loss_3': -15.007125854492188, 'loss_4': 1.5463969707489014, 'epoch': 0.87}
{'loss': 0.1085, 'grad_norm': 29.628664016723633, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.10442798584699631, 'loss_2': 0.004058837890625, 'loss_3': -15.08095932006836, 'loss_4': 1.9183337688446045, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 15:22:51,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:51,707 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:04<1:26:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:59,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035215526819229126, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03171875327825546, 'eval_loss_2': 0.0034967735409736633, 'eval_loss_3': -18.0755615234375, 'eval_loss_4': 2.0362448692321777, 'epoch': 0.87}
{'loss': 0.0873, 'grad_norm': 23.561880111694336, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.08336639404296875, 'loss_2': 0.00392913818359375, 'loss_3': -15.180940628051758, 'loss_4': 1.9931163787841797, 'epoch': 0.88}
{'loss': 0.1324, 'grad_norm': 29.763717651367188, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.12870435416698456, 'loss_2': 0.0036830902099609375, 'loss_3': -15.139930725097656, 'loss_4': 2.343132257461548, 'epoch': 0.88}
{'loss': 0.1069, 'grad_norm': 24.548572540283203, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.10562019795179367, 'loss_2': 0.0013189315795898438, 'loss_3': -15.04530143737793, 'loss_4': 2.284611463546753, 'epoch': 0.89}
{'loss': 0.1925, 'grad_norm': 44.76278305053711, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.18254272639751434, 'loss_2': 0.009979248046875, 'loss_3': -15.042562484741211, 'loss_4': 2.8794503211975098, 'epoch': 0.9}
{'loss': 0.0948, 'grad_norm': 18.09976577758789, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.08232328295707703, 'loss_2': 0.012481689453125, 'loss_3': -15.224626541137695, 'loss_4': 3.2387051582336426, 'epoch': 0.9}
[INFO|trainer.py:4228] 2025-01-21 15:22:59,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:59,056 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:11<1:26:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:06,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03759798780083656, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02674684301018715, 'eval_loss_2': 0.010851144790649414, 'eval_loss_3': -18.150774002075195, 'eval_loss_4': 2.628520965576172, 'epoch': 0.9}
{'loss': 0.091, 'grad_norm': 20.790019989013672, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.07993795722723007, 'loss_2': 0.01110076904296875, 'loss_3': -15.128908157348633, 'loss_4': 2.2251715660095215, 'epoch': 0.91}
{'loss': 0.1304, 'grad_norm': 32.47562789916992, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.12238720804452896, 'loss_2': 0.0080413818359375, 'loss_3': -15.033243179321289, 'loss_4': 3.1451926231384277, 'epoch': 0.91}
{'loss': 0.222, 'grad_norm': 40.34882736206055, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.21243000030517578, 'loss_2': 0.009613037109375, 'loss_3': -15.13886833190918, 'loss_4': 2.826883554458618, 'epoch': 0.92}
{'loss': 0.096, 'grad_norm': 26.988771438598633, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.08973930031061172, 'loss_2': 0.006298065185546875, 'loss_3': -15.142633438110352, 'loss_4': 2.854069709777832, 'epoch': 0.92}
{'loss': 0.0861, 'grad_norm': 21.90321922302246, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.08174951374530792, 'loss_2': 0.004398345947265625, 'loss_3': -15.199182510375977, 'loss_4': 1.7472784519195557, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 15:23:06,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:06,419 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:19<1:26:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:13,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034140996634960175, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02728201635181904, 'eval_loss_2': 0.006858985871076584, 'eval_loss_3': -18.123554229736328, 'eval_loss_4': 2.2064099311828613, 'epoch': 0.93}
{'loss': 0.1298, 'grad_norm': 29.629880905151367, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.12133077532052994, 'loss_2': 0.008453369140625, 'loss_3': -14.998947143554688, 'loss_4': 1.9342387914657593, 'epoch': 0.94}
{'loss': 0.0616, 'grad_norm': 15.066474914550781, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.057329364120960236, 'loss_2': 0.00429534912109375, 'loss_3': -15.3139066696167, 'loss_4': 2.152285099029541, 'epoch': 0.94}
{'loss': 0.0826, 'grad_norm': 25.510236740112305, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.0769912600517273, 'loss_2': 0.005634307861328125, 'loss_3': -15.228635787963867, 'loss_4': 2.1566150188446045, 'epoch': 0.95}
{'loss': 0.0424, 'grad_norm': 10.346741676330566, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.042299721390008926, 'loss_2': 8.07642936706543e-05, 'loss_3': -15.13751220703125, 'loss_4': 1.862183690071106, 'epoch': 0.95}
{'loss': 0.1247, 'grad_norm': 24.368589401245117, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.11935621500015259, 'loss_2': 0.005374908447265625, 'loss_3': -15.380136489868164, 'loss_4': 2.0474772453308105, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 15:23:13,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:13,781 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:26<1:26:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:21,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03174499422311783, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02848721295595169, 'eval_loss_2': 0.0032577812671661377, 'eval_loss_3': -18.114946365356445, 'eval_loss_4': 1.6436333656311035, 'epoch': 0.96}
{'loss': 0.0832, 'grad_norm': 20.245649337768555, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.07987971603870392, 'loss_2': 0.0033111572265625, 'loss_3': -15.234224319458008, 'loss_4': 1.712433099746704, 'epoch': 0.97}
{'loss': 0.1017, 'grad_norm': 24.5809383392334, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.09125702828168869, 'loss_2': 0.010406494140625, 'loss_3': -15.152304649353027, 'loss_4': 1.1581604480743408, 'epoch': 0.97}
{'loss': 0.0887, 'grad_norm': 19.00006675720215, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.07674094289541245, 'loss_2': 0.0120086669921875, 'loss_3': -15.11967658996582, 'loss_4': 1.2893037796020508, 'epoch': 0.98}
{'loss': 0.0936, 'grad_norm': 25.51110076904297, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.09334009140729904, 'loss_2': 0.0003039836883544922, 'loss_3': -15.0973482131958, 'loss_4': 1.2521131038665771, 'epoch': 0.98}
{'loss': 0.1046, 'grad_norm': 27.917572021484375, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.10378144681453705, 'loss_2': 0.0008115768432617188, 'loss_3': -15.220002174377441, 'loss_4': 1.521738052368164, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 15:23:21,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:21,136 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:33<1:23:55,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 15:23:28,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03931582719087601, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.034765250980854034, 'eval_loss_2': 0.004550576210021973, 'eval_loss_3': -18.047405242919922, 'eval_loss_4': 1.3046261072158813, 'epoch': 0.99}
{'loss': 0.0522, 'grad_norm': 12.784834861755371, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.04768475145101547, 'loss_2': 0.0045318603515625, 'loss_3': -15.134847640991211, 'loss_4': 0.853995680809021, 'epoch': 0.99}
{'loss': 0.0384, 'grad_norm': 15.91158390045166, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.03785011172294617, 'loss_2': 0.0005254745483398438, 'loss_3': -15.478198051452637, 'loss_4': 1.3670796155929565, 'epoch': 1.0}
{'loss': 0.1053, 'grad_norm': 27.357412338256836, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.10428027808666229, 'loss_2': 0.000972747802734375, 'loss_3': -15.346359252929688, 'loss_4': 1.1871306896209717, 'epoch': 1.01}
{'loss': 0.1187, 'grad_norm': 27.43859100341797, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.11278025805950165, 'loss_2': 0.00592803955078125, 'loss_3': -15.219697952270508, 'loss_4': 1.1379389762878418, 'epoch': 1.01}
{'loss': 0.0926, 'grad_norm': 28.461650848388672, 'learning_rate': 2.9e-05, 'loss_1': 0.0882476419210434, 'loss_2': 0.004364013671875, 'loss_3': -15.34527587890625, 'loss_4': 1.527118444442749, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 15:23:28,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:28,182 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:40<1:25:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:35,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04981929063796997, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.04440826177597046, 'eval_loss_2': 0.005411028861999512, 'eval_loss_3': -18.013776779174805, 'eval_loss_4': 1.1045026779174805, 'epoch': 1.02}
{'loss': 0.1306, 'grad_norm': 25.38632583618164, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.12378643453121185, 'loss_2': 0.00682830810546875, 'loss_3': -15.251520156860352, 'loss_4': 0.7833735942840576, 'epoch': 1.02}
{'loss': 0.0739, 'grad_norm': 16.18671989440918, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.061738815158605576, 'loss_2': 0.01216888427734375, 'loss_3': -15.06459903717041, 'loss_4': 0.7483725547790527, 'epoch': 1.03}
{'loss': 0.159, 'grad_norm': 42.80885314941406, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.15763120353221893, 'loss_2': 0.0013713836669921875, 'loss_3': -15.275753021240234, 'loss_4': 1.150421380996704, 'epoch': 1.03}
{'loss': 0.1013, 'grad_norm': 31.81473731994629, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.10118678212165833, 'loss_2': 0.0001289844512939453, 'loss_3': -15.213353157043457, 'loss_4': 0.613745927810669, 'epoch': 1.04}
{'loss': 0.2025, 'grad_norm': 41.655487060546875, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.1995518058538437, 'loss_2': 0.002899169921875, 'loss_3': -15.141560554504395, 'loss_4': 0.7215222120285034, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 15:23:35,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:35,543 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:48<1:26:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:42,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.14053386449813843, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.12982779741287231, 'eval_loss_2': 0.010706067085266113, 'eval_loss_3': -17.720884323120117, 'eval_loss_4': 1.2708379030227661, 'epoch': 1.05}
{'loss': 0.1416, 'grad_norm': 31.93361473083496, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.1408519446849823, 'loss_2': 0.0007452964782714844, 'loss_3': -15.194435119628906, 'loss_4': 0.8527486324310303, 'epoch': 1.05}
{'loss': 0.3585, 'grad_norm': 60.95152282714844, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.3486731946468353, 'loss_2': 0.00982666015625, 'loss_3': -14.857401847839355, 'loss_4': 1.752820611000061, 'epoch': 1.06}
{'loss': 0.0841, 'grad_norm': 23.60343360900879, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.07774347066879272, 'loss_2': 0.00630950927734375, 'loss_3': -15.1082124710083, 'loss_4': 1.6276092529296875, 'epoch': 1.06}
{'loss': 0.2214, 'grad_norm': 30.97885513305664, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.20985545217990875, 'loss_2': 0.01158905029296875, 'loss_3': -15.141349792480469, 'loss_4': 1.1232128143310547, 'epoch': 1.07}
{'loss': 0.1117, 'grad_norm': 29.679094314575195, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.10953734815120697, 'loss_2': 0.002208709716796875, 'loss_3': -15.168136596679688, 'loss_4': 1.225480556488037, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 15:23:42,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:42,906 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:55<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:50,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.050290003418922424, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0424046590924263, 'eval_loss_2': 0.007885336875915527, 'eval_loss_3': -18.061683654785156, 'eval_loss_4': 1.3179924488067627, 'epoch': 1.08}
{'loss': 0.0783, 'grad_norm': 23.694746017456055, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.06908925622701645, 'loss_2': 0.00916290283203125, 'loss_3': -15.184684753417969, 'loss_4': 1.081153392791748, 'epoch': 1.08}
{'loss': 0.0953, 'grad_norm': 18.064184188842773, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.08325622975826263, 'loss_2': 0.0120697021484375, 'loss_3': -15.281846046447754, 'loss_4': 1.5729435682296753, 'epoch': 1.09}
{'loss': 0.1936, 'grad_norm': 34.016361236572266, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.19011647999286652, 'loss_2': 0.0034580230712890625, 'loss_3': -15.338415145874023, 'loss_4': 2.222477436065674, 'epoch': 1.09}
{'loss': 0.0797, 'grad_norm': 15.951071739196777, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.07297948002815247, 'loss_2': 0.0067291259765625, 'loss_3': -15.066324234008789, 'loss_4': 2.504765510559082, 'epoch': 1.1}
{'loss': 0.0709, 'grad_norm': 13.96701717376709, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.06001865863800049, 'loss_2': 0.01085662841796875, 'loss_3': -15.165641784667969, 'loss_4': 2.1764373779296875, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 15:23:50,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:50,259 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:03<1:26:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:57,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02894734777510166, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.026572126895189285, 'eval_loss_2': 0.0023752227425575256, 'eval_loss_3': -18.22210121154785, 'eval_loss_4': 3.0100440979003906, 'epoch': 1.1}
{'loss': 0.1062, 'grad_norm': 24.076051712036133, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.10249847173690796, 'loss_2': 0.003665924072265625, 'loss_3': -15.218963623046875, 'loss_4': 3.051434278488159, 'epoch': 1.11}
{'loss': 0.0803, 'grad_norm': 28.52155303955078, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.07702244818210602, 'loss_2': 0.003253936767578125, 'loss_3': -15.450082778930664, 'loss_4': 3.7016849517822266, 'epoch': 1.12}
{'loss': 0.1763, 'grad_norm': 38.14967727661133, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.16920419037342072, 'loss_2': 0.00711822509765625, 'loss_3': -15.317296981811523, 'loss_4': 4.033052444458008, 'epoch': 1.12}
{'loss': 0.0941, 'grad_norm': 19.91985321044922, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.07504312694072723, 'loss_2': 0.019073486328125, 'loss_3': -15.368743896484375, 'loss_4': 3.4050230979919434, 'epoch': 1.13}
{'loss': 0.0853, 'grad_norm': 24.74489402770996, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.07099351286888123, 'loss_2': 0.0143280029296875, 'loss_3': -15.191129684448242, 'loss_4': 3.1984496116638184, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 15:23:57,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:57,624 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:10<1:25:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:04,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03513149917125702, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.027022168040275574, 'eval_loss_2': 0.008109331130981445, 'eval_loss_3': -18.236499786376953, 'eval_loss_4': 3.0221898555755615, 'epoch': 1.13}
{'loss': 0.0955, 'grad_norm': 23.85910987854004, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.08046991378068924, 'loss_2': 0.014984130859375, 'loss_3': -15.32371711730957, 'loss_4': 2.84622859954834, 'epoch': 1.14}
{'loss': 0.0759, 'grad_norm': 14.72881031036377, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.05907360836863518, 'loss_2': 0.016845703125, 'loss_3': -15.233006477355957, 'loss_4': 3.040130615234375, 'epoch': 1.15}
{'loss': 0.1797, 'grad_norm': 24.9531192779541, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.1656130850315094, 'loss_2': 0.0141143798828125, 'loss_3': -15.231205940246582, 'loss_4': 2.7869229316711426, 'epoch': 1.15}
{'loss': 0.0669, 'grad_norm': 17.364456176757812, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.05915774405002594, 'loss_2': 0.00778961181640625, 'loss_3': -15.250116348266602, 'loss_4': 2.2243270874023438, 'epoch': 1.16}
{'loss': 0.0722, 'grad_norm': 19.27337646484375, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.06769420206546783, 'loss_2': 0.00449371337890625, 'loss_3': -15.089276313781738, 'loss_4': 2.185286521911621, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 15:24:04,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:04,973 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:17<1:25:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:12,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03042428568005562, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.02598453499376774, 'eval_loss_2': 0.004439752548933029, 'eval_loss_3': -18.184078216552734, 'eval_loss_4': 1.9641958475112915, 'epoch': 1.16}
{'loss': 0.0446, 'grad_norm': 9.608449935913086, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.0419098325073719, 'loss_2': 0.0026607513427734375, 'loss_3': -15.294413566589355, 'loss_4': 2.269052505493164, 'epoch': 1.17}
{'loss': 0.1186, 'grad_norm': 41.85191345214844, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.11682628840208054, 'loss_2': 0.0017948150634765625, 'loss_3': -15.179859161376953, 'loss_4': 1.9890918731689453, 'epoch': 1.17}
{'loss': 0.043, 'grad_norm': 12.4052095413208, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.039806850254535675, 'loss_2': 0.003185272216796875, 'loss_3': -15.099987983703613, 'loss_4': 1.6894888877868652, 'epoch': 1.18}
{'loss': 0.1136, 'grad_norm': 30.763078689575195, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.1042928397655487, 'loss_2': 0.00933074951171875, 'loss_3': -15.185227394104004, 'loss_4': 1.475677251815796, 'epoch': 1.19}
{'loss': 0.0597, 'grad_norm': 13.087149620056152, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.04997274652123451, 'loss_2': 0.00972747802734375, 'loss_3': -15.016645431518555, 'loss_4': 1.1038095951080322, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 15:24:12,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:12,325 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:25<1:25:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:19,692 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0414990559220314, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.718, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0381130613386631, 'eval_loss_2': 0.003385990858078003, 'eval_loss_3': -18.056438446044922, 'eval_loss_4': 1.1735203266143799, 'epoch': 1.19}
{'loss': 0.1135, 'grad_norm': 24.251663208007812, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.10344047844409943, 'loss_2': 0.0100555419921875, 'loss_3': -15.179267883300781, 'loss_4': 1.116031289100647, 'epoch': 1.2}
{'loss': 0.0915, 'grad_norm': 23.641569137573242, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.08950657397508621, 'loss_2': 0.0019588470458984375, 'loss_3': -15.130823135375977, 'loss_4': 1.2847650051116943, 'epoch': 1.2}
{'loss': 0.1001, 'grad_norm': 20.846431732177734, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.09801609069108963, 'loss_2': 0.002105712890625, 'loss_3': -15.132637023925781, 'loss_4': 1.3695685863494873, 'epoch': 1.21}
{'loss': 0.0969, 'grad_norm': 25.52716064453125, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.09299876540899277, 'loss_2': 0.0039005279541015625, 'loss_3': -14.862263679504395, 'loss_4': 0.7410837411880493, 'epoch': 1.22}
{'loss': 0.1527, 'grad_norm': 25.95980453491211, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.14484186470508575, 'loss_2': 0.00787353515625, 'loss_3': -14.801568031311035, 'loss_4': 1.2476062774658203, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 15:24:19,692 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:19,692 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:32<1:25:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:27,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07814240455627441, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.322, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.07332035154104233, 'eval_loss_2': 0.004822053015232086, 'eval_loss_3': -17.917423248291016, 'eval_loss_4': 1.3851518630981445, 'epoch': 1.22}
{'loss': 0.1027, 'grad_norm': 25.578107833862305, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.10210952162742615, 'loss_2': 0.000637054443359375, 'loss_3': -14.997072219848633, 'loss_4': 1.5185425281524658, 'epoch': 1.23}
{'loss': 0.1751, 'grad_norm': 38.79356002807617, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.1706065982580185, 'loss_2': 0.00446319580078125, 'loss_3': -15.044200897216797, 'loss_4': 1.9720239639282227, 'epoch': 1.23}
{'loss': 0.0752, 'grad_norm': 18.7517032623291, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.07179969549179077, 'loss_2': 0.0034084320068359375, 'loss_3': -14.73940658569336, 'loss_4': 1.459826946258545, 'epoch': 1.24}
{'loss': 0.1145, 'grad_norm': 25.70458984375, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.10703320801258087, 'loss_2': 0.0074615478515625, 'loss_3': -14.92471694946289, 'loss_4': 1.4511806964874268, 'epoch': 1.24}
{'loss': 0.0715, 'grad_norm': 18.11228370666504, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.06582869589328766, 'loss_2': 0.00568389892578125, 'loss_3': -15.070993423461914, 'loss_4': 1.7079468965530396, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 15:24:27,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:27,073 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:39<1:25:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:34,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06086697801947594, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.67, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.056253816932439804, 'eval_loss_2': 0.004613161087036133, 'eval_loss_3': -17.94443130493164, 'eval_loss_4': 1.4374501705169678, 'epoch': 1.25}
{'loss': 0.0747, 'grad_norm': 21.03333854675293, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.07208925485610962, 'loss_2': 0.0026226043701171875, 'loss_3': -15.107547760009766, 'loss_4': 1.4030189514160156, 'epoch': 1.26}
{'loss': 0.1024, 'grad_norm': 30.44059181213379, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.09657739102840424, 'loss_2': 0.005828857421875, 'loss_3': -15.260506629943848, 'loss_4': 2.132737636566162, 'epoch': 1.26}
{'loss': 0.0846, 'grad_norm': 15.838959693908691, 'learning_rate': 2.875e-05, 'loss_1': 0.07275547832250595, 'loss_2': 0.0117950439453125, 'loss_3': -14.956298828125, 'loss_4': 1.4049865007400513, 'epoch': 1.27}
{'loss': 0.0733, 'grad_norm': 14.624360084533691, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.05268561840057373, 'loss_2': 0.0206451416015625, 'loss_3': -15.268428802490234, 'loss_4': 1.538246750831604, 'epoch': 1.27}
{'loss': 0.0437, 'grad_norm': 17.14240264892578, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.03715023398399353, 'loss_2': 0.006526947021484375, 'loss_3': -15.085970878601074, 'loss_4': 1.2223186492919922, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 15:24:34,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:34,429 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:47<1:25:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:41,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03153903782367706, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.024052811786532402, 'eval_loss_2': 0.007486224174499512, 'eval_loss_3': -18.142906188964844, 'eval_loss_4': 1.113518238067627, 'epoch': 1.28}
{'loss': 0.0936, 'grad_norm': 20.368412017822266, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.08064021915197372, 'loss_2': 0.012969970703125, 'loss_3': -15.072643280029297, 'loss_4': 1.3448054790496826, 'epoch': 1.28}
{'loss': 0.1145, 'grad_norm': 27.153583526611328, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.10094958543777466, 'loss_2': 0.013519287109375, 'loss_3': -15.054048538208008, 'loss_4': 1.726245641708374, 'epoch': 1.29}
{'loss': 0.0737, 'grad_norm': 20.632400512695312, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.0659341812133789, 'loss_2': 0.007732391357421875, 'loss_3': -15.195516586303711, 'loss_4': 1.5722604990005493, 'epoch': 1.3}
{'loss': 0.0406, 'grad_norm': 11.252177238464355, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.039467740803956985, 'loss_2': 0.0011281967163085938, 'loss_3': -15.161538124084473, 'loss_4': 1.1819026470184326, 'epoch': 1.3}
{'loss': 0.1347, 'grad_norm': 28.735305786132812, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.12764780223369598, 'loss_2': 0.007076263427734375, 'loss_3': -15.133834838867188, 'loss_4': 0.8533016443252563, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 15:24:41,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:41,786 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [05:54<1:25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:49,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03565158322453499, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.025142328813672066, 'eval_loss_2': 0.010509252548217773, 'eval_loss_3': -18.126358032226562, 'eval_loss_4': 0.7820766568183899, 'epoch': 1.31}
{'loss': 0.0473, 'grad_norm': 9.609296798706055, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.03761620074510574, 'loss_2': 0.00970458984375, 'loss_3': -15.265817642211914, 'loss_4': 1.069542646408081, 'epoch': 1.31}
{'loss': 0.109, 'grad_norm': 30.587726593017578, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.10246840864419937, 'loss_2': 0.006565093994140625, 'loss_3': -15.179397583007812, 'loss_4': 1.0116373300552368, 'epoch': 1.32}
{'loss': 0.0474, 'grad_norm': 10.426153182983398, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.038389138877391815, 'loss_2': 0.0090484619140625, 'loss_3': -15.156881332397461, 'loss_4': 0.727077841758728, 'epoch': 1.33}
{'loss': 0.0482, 'grad_norm': 13.547237396240234, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.04717090353369713, 'loss_2': 0.0010461807250976562, 'loss_3': -15.219231605529785, 'loss_4': 1.2241761684417725, 'epoch': 1.33}
{'loss': 0.0565, 'grad_norm': 16.709442138671875, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.05433952063322067, 'loss_2': 0.002166748046875, 'loss_3': -14.994560241699219, 'loss_4': 0.3984474539756775, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 15:24:49,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:49,146 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:01<1:25:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:56,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05126731097698212, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.04603787884116173, 'eval_loss_2': 0.00522942841053009, 'eval_loss_3': -17.969266891479492, 'eval_loss_4': 0.7928658723831177, 'epoch': 1.34}
{'loss': 0.0484, 'grad_norm': 11.159256935119629, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.04321865737438202, 'loss_2': 0.005161285400390625, 'loss_3': -14.992303848266602, 'loss_4': 1.1049063205718994, 'epoch': 1.34}
{'loss': 0.1547, 'grad_norm': 21.135665893554688, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.15313471853733063, 'loss_2': 0.0015430450439453125, 'loss_3': -14.955755233764648, 'loss_4': 0.7318888902664185, 'epoch': 1.35}
{'loss': 0.1571, 'grad_norm': 32.65031433105469, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.1470191478729248, 'loss_2': 0.01009368896484375, 'loss_3': -14.96001148223877, 'loss_4': 1.1119351387023926, 'epoch': 1.35}
{'loss': 0.0748, 'grad_norm': 29.104581832885742, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.06647580116987228, 'loss_2': 0.00830078125, 'loss_3': -15.100906372070312, 'loss_4': 1.3383575677871704, 'epoch': 1.36}
{'loss': 0.0539, 'grad_norm': 15.678170204162598, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.046230487525463104, 'loss_2': 0.0077056884765625, 'loss_3': -14.997429847717285, 'loss_4': 1.065222978591919, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 15:24:56,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:56,497 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:09<1:25:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:03,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07771439850330353, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.07256126403808594, 'eval_loss_2': 0.005153130739927292, 'eval_loss_3': -17.784582138061523, 'eval_loss_4': 1.1417980194091797, 'epoch': 1.37}
{'loss': 0.0772, 'grad_norm': 21.532291412353516, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.07169878482818604, 'loss_2': 0.005462646484375, 'loss_3': -14.630066871643066, 'loss_4': 0.6360942125320435, 'epoch': 1.37}
{'loss': 0.0851, 'grad_norm': 25.276742935180664, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.07689832895994186, 'loss_2': 0.00817108154296875, 'loss_3': -14.792950630187988, 'loss_4': 1.4350547790527344, 'epoch': 1.38}
{'loss': 0.0536, 'grad_norm': 14.175507545471191, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.04915269836783409, 'loss_2': 0.00443267822265625, 'loss_3': -15.086618423461914, 'loss_4': 1.2602812051773071, 'epoch': 1.38}
{'loss': 0.0501, 'grad_norm': 17.757919311523438, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.042062655091285706, 'loss_2': 0.00800323486328125, 'loss_3': -14.71126651763916, 'loss_4': 1.0294638872146606, 'epoch': 1.39}
{'loss': 0.106, 'grad_norm': 26.65555763244629, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.09459633380174637, 'loss_2': 0.01139068603515625, 'loss_3': -14.873104095458984, 'loss_4': 1.7839616537094116, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 15:25:03,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:03,854 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:16<1:25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:11,210 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08766916394233704, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.07993051409721375, 'eval_loss_2': 0.007738649845123291, 'eval_loss_3': -17.74635124206543, 'eval_loss_4': 1.312281847000122, 'epoch': 1.4}
{'loss': 0.0817, 'grad_norm': 19.300857543945312, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.07440082728862762, 'loss_2': 0.00727081298828125, 'loss_3': -14.893258094787598, 'loss_4': 1.2633028030395508, 'epoch': 1.4}
{'loss': 0.0426, 'grad_norm': 9.847652435302734, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.03680079057812691, 'loss_2': 0.005817413330078125, 'loss_3': -14.969654083251953, 'loss_4': 1.3127715587615967, 'epoch': 1.41}
{'loss': 0.1809, 'grad_norm': 50.88212203979492, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.16626207530498505, 'loss_2': 0.0146331787109375, 'loss_3': -14.929579734802246, 'loss_4': 1.5922279357910156, 'epoch': 1.41}
{'loss': 0.0489, 'grad_norm': 11.766857147216797, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.04291698709130287, 'loss_2': 0.00597381591796875, 'loss_3': -14.746684074401855, 'loss_4': 1.3657035827636719, 'epoch': 1.42}
{'loss': 0.0409, 'grad_norm': 13.605939865112305, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.03803368657827377, 'loss_2': 0.002872467041015625, 'loss_3': -15.112924575805664, 'loss_4': 1.1027729511260986, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 15:25:11,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:11,210 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:23<1:24:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:18,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.056962303817272186, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.05189918726682663, 'eval_loss_2': 0.005063116550445557, 'eval_loss_3': -17.835588455200195, 'eval_loss_4': 1.4200825691223145, 'epoch': 1.42}
{'loss': 0.0801, 'grad_norm': 23.90938949584961, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.07537878304719925, 'loss_2': 0.00467681884765625, 'loss_3': -14.961901664733887, 'loss_4': 1.9292559623718262, 'epoch': 1.43}
{'loss': 0.1367, 'grad_norm': 30.139144897460938, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.11827906966209412, 'loss_2': 0.01837158203125, 'loss_3': -15.074437141418457, 'loss_4': 1.6348732709884644, 'epoch': 1.44}
{'loss': 0.1427, 'grad_norm': 27.14194107055664, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.1366196721792221, 'loss_2': 0.00611114501953125, 'loss_3': -14.75368595123291, 'loss_4': 1.8044915199279785, 'epoch': 1.44}
{'loss': 0.0573, 'grad_norm': 13.517013549804688, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.043625108897686005, 'loss_2': 0.01364898681640625, 'loss_3': -14.925873756408691, 'loss_4': 1.3091270923614502, 'epoch': 1.45}
{'loss': 0.0969, 'grad_norm': 24.175891876220703, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.07866726815700531, 'loss_2': 0.01824951171875, 'loss_3': -15.10973834991455, 'loss_4': 1.7558104991912842, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 15:25:18,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:18,560 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:31<1:24:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:25,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05766255035996437, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.858, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.05017995834350586, 'eval_loss_2': 0.007482588291168213, 'eval_loss_3': -17.90395736694336, 'eval_loss_4': 1.5945860147476196, 'epoch': 1.45}
{'loss': 0.0796, 'grad_norm': 24.401105880737305, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.068084217607975, 'loss_2': 0.01149749755859375, 'loss_3': -14.793316841125488, 'loss_4': 2.1402947902679443, 'epoch': 1.46}
{'loss': 0.1096, 'grad_norm': 30.26023292541504, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.10382567346096039, 'loss_2': 0.0057830810546875, 'loss_3': -15.010018348693848, 'loss_4': 1.8376867771148682, 'epoch': 1.47}
{'loss': 0.0768, 'grad_norm': 21.381669998168945, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.06524424999952316, 'loss_2': 0.0115509033203125, 'loss_3': -14.996599197387695, 'loss_4': 1.887916922569275, 'epoch': 1.47}
{'loss': 0.1155, 'grad_norm': 36.304840087890625, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.11339937895536423, 'loss_2': 0.002101898193359375, 'loss_3': -14.986751556396484, 'loss_4': 1.6056854724884033, 'epoch': 1.48}
{'loss': 0.0632, 'grad_norm': 16.654712677001953, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.060533881187438965, 'loss_2': 0.002628326416015625, 'loss_3': -15.240362167358398, 'loss_4': 1.6383416652679443, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 15:25:25,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:25,911 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:38<1:24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:33,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.060055747628211975, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.05216897279024124, 'eval_loss_2': 0.007886767387390137, 'eval_loss_3': -17.909826278686523, 'eval_loss_4': 1.3053632974624634, 'epoch': 1.48}
{'loss': 0.0571, 'grad_norm': 15.905324935913086, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.04761379584670067, 'loss_2': 0.00949859619140625, 'loss_3': -15.129435539245605, 'loss_4': 1.012338399887085, 'epoch': 1.49}
{'loss': 0.129, 'grad_norm': 18.979347229003906, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.11716482043266296, 'loss_2': 0.011871337890625, 'loss_3': -14.930302619934082, 'loss_4': 1.3494148254394531, 'epoch': 1.49}
{'loss': 0.0689, 'grad_norm': 20.790653228759766, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.06731722503900528, 'loss_2': 0.0016021728515625, 'loss_3': -15.07779312133789, 'loss_4': 1.5326948165893555, 'epoch': 1.5}
{'loss': 0.0682, 'grad_norm': 14.988041877746582, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.061517421156167984, 'loss_2': 0.00664520263671875, 'loss_3': -15.098730087280273, 'loss_4': 1.7486436367034912, 'epoch': 1.51}
{'loss': 0.1507, 'grad_norm': 37.711673736572266, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.13488751649856567, 'loss_2': 0.01580810546875, 'loss_3': -15.05842399597168, 'loss_4': 2.1640443801879883, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 15:25:33,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:33,268 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:46<1:24:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:40,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031060315668582916, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.026951350271701813, 'eval_loss_2': 0.0041089653968811035, 'eval_loss_3': -18.03191375732422, 'eval_loss_4': 1.5729172229766846, 'epoch': 1.51}
{'loss': 0.0397, 'grad_norm': 13.100072860717773, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.03705688565969467, 'loss_2': 0.0026302337646484375, 'loss_3': -15.018913269042969, 'loss_4': 2.0964088439941406, 'epoch': 1.52}
{'loss': 0.0841, 'grad_norm': 25.581335067749023, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.08073394000530243, 'loss_2': 0.003322601318359375, 'loss_3': -15.153280258178711, 'loss_4': 2.0392675399780273, 'epoch': 1.52}
{'loss': 0.1006, 'grad_norm': 31.372577667236328, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.09933685511350632, 'loss_2': 0.0012865066528320312, 'loss_3': -15.083233833312988, 'loss_4': 2.415005683898926, 'epoch': 1.53}
{'loss': 0.0605, 'grad_norm': 15.732669830322266, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.06043022498488426, 'loss_2': 7.599592208862305e-05, 'loss_3': -14.928647994995117, 'loss_4': 2.0484232902526855, 'epoch': 1.53}
{'loss': 0.0458, 'grad_norm': 9.656976699829102, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.03587308153510094, 'loss_2': 0.00997161865234375, 'loss_3': -15.16076374053955, 'loss_4': 1.7567558288574219, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 15:25:40,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:40,614 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [06:53<1:24:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:47,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03225910663604736, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.878, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.026531878858804703, 'eval_loss_2': 0.005727231502532959, 'eval_loss_3': -18.10089874267578, 'eval_loss_4': 1.3695884943008423, 'epoch': 1.54}
{'loss': 0.1704, 'grad_norm': 45.845638275146484, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.1531602144241333, 'loss_2': 0.017242431640625, 'loss_3': -15.182559967041016, 'loss_4': 2.657013416290283, 'epoch': 1.55}
{'loss': 0.1353, 'grad_norm': 33.1591911315918, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.13513058423995972, 'loss_2': 0.00017118453979492188, 'loss_3': -15.165462493896484, 'loss_4': 1.5512813329696655, 'epoch': 1.55}
{'loss': 0.0606, 'grad_norm': 11.599575996398926, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.04608004912734032, 'loss_2': 0.0145416259765625, 'loss_3': -15.235055923461914, 'loss_4': 1.0294686555862427, 'epoch': 1.56}
{'loss': 0.109, 'grad_norm': 42.17702102661133, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.10574173927307129, 'loss_2': 0.0032806396484375, 'loss_3': -15.09849739074707, 'loss_4': 1.3765199184417725, 'epoch': 1.56}
{'loss': 0.0807, 'grad_norm': 24.673105239868164, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.07577288895845413, 'loss_2': 0.004886627197265625, 'loss_3': -15.163742065429688, 'loss_4': 0.8913848996162415, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 15:25:47,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:47,968 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:00<1:24:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:55,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033762603998184204, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.583, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.026096343994140625, 'eval_loss_2': 0.007666260004043579, 'eval_loss_3': -18.04816436767578, 'eval_loss_4': 0.4711551070213318, 'epoch': 1.57}
{'loss': 0.0424, 'grad_norm': 9.123543739318848, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.03399959206581116, 'loss_2': 0.00836181640625, 'loss_3': -15.387069702148438, 'loss_4': 0.49655023217201233, 'epoch': 1.58}
{'loss': 0.0707, 'grad_norm': 16.298391342163086, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.05884999781847, 'loss_2': 0.0118865966796875, 'loss_3': -15.15070915222168, 'loss_4': 0.48023125529289246, 'epoch': 1.58}
{'loss': 0.1005, 'grad_norm': 19.960874557495117, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.09601811319589615, 'loss_2': 0.0045013427734375, 'loss_3': -15.335100173950195, 'loss_4': 0.7731209397315979, 'epoch': 1.59}
{'loss': 0.0581, 'grad_norm': 10.915045738220215, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.044464170932769775, 'loss_2': 0.0136260986328125, 'loss_3': -15.53445053100586, 'loss_4': 1.2635397911071777, 'epoch': 1.59}
{'loss': 0.094, 'grad_norm': 20.65777015686035, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.08814387023448944, 'loss_2': 0.0058441162109375, 'loss_3': -14.835583686828613, 'loss_4': 0.4868975877761841, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 15:25:55,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:55,310 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:08<1:24:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:02,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04902314022183418, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04056965187191963, 'eval_loss_2': 0.00845348834991455, 'eval_loss_3': -17.890460968017578, 'eval_loss_4': 0.7442643642425537, 'epoch': 1.6}
{'loss': 0.1053, 'grad_norm': 26.725744247436523, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.10011078417301178, 'loss_2': 0.0052337646484375, 'loss_3': -15.04554557800293, 'loss_4': 0.9811854362487793, 'epoch': 1.6}
{'loss': 0.0668, 'grad_norm': 27.01079559326172, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.06388109922409058, 'loss_2': 0.00292205810546875, 'loss_3': -15.208669662475586, 'loss_4': 0.6685954928398132, 'epoch': 1.61}
{'loss': 0.0787, 'grad_norm': 17.21944808959961, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.07191687822341919, 'loss_2': 0.006778717041015625, 'loss_3': -14.955869674682617, 'loss_4': 0.8586457967758179, 'epoch': 1.62}
{'loss': 0.1438, 'grad_norm': 34.4965934753418, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.14058935642242432, 'loss_2': 0.0032482147216796875, 'loss_3': -15.041336059570312, 'loss_4': 1.2036449909210205, 'epoch': 1.62}
{'loss': 0.1007, 'grad_norm': 21.64443588256836, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.09428713470697403, 'loss_2': 0.00637054443359375, 'loss_3': -15.23520565032959, 'loss_4': 1.5251213312149048, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 15:26:02,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:02,666 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:15<1:24:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:10,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.045991189777851105, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.417, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03582096844911575, 'eval_loss_2': 0.010170221328735352, 'eval_loss_3': -17.933732986450195, 'eval_loss_4': 1.2712393999099731, 'epoch': 1.63}
{'loss': 0.0536, 'grad_norm': 11.696382522583008, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.04387637600302696, 'loss_2': 0.009765625, 'loss_3': -15.253881454467773, 'loss_4': 1.392066478729248, 'epoch': 1.63}
{'loss': 0.1336, 'grad_norm': 21.55059242248535, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.12633883953094482, 'loss_2': 0.00725555419921875, 'loss_3': -15.031381607055664, 'loss_4': 1.1324379444122314, 'epoch': 1.64}
{'loss': 0.07, 'grad_norm': 19.5102481842041, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.06142047047615051, 'loss_2': 0.00860595703125, 'loss_3': -15.108427047729492, 'loss_4': 1.25346040725708, 'epoch': 1.65}
{'loss': 0.0967, 'grad_norm': 21.774951934814453, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.09090898931026459, 'loss_2': 0.0057525634765625, 'loss_3': -15.208168029785156, 'loss_4': 1.9772837162017822, 'epoch': 1.65}
{'loss': 0.0942, 'grad_norm': 24.661518096923828, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.08103467524051666, 'loss_2': 0.0131683349609375, 'loss_3': -15.122770309448242, 'loss_4': 1.024118185043335, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 15:26:10,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:10,016 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:22<1:24:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:17,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03167802095413208, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.025440307334065437, 'eval_loss_2': 0.006237715482711792, 'eval_loss_3': -18.04334259033203, 'eval_loss_4': 0.9144613146781921, 'epoch': 1.66}
{'loss': 0.0756, 'grad_norm': 20.968406677246094, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.07433142513036728, 'loss_2': 0.0013065338134765625, 'loss_3': -15.13299560546875, 'loss_4': 1.592529535293579, 'epoch': 1.66}
{'loss': 0.0645, 'grad_norm': 18.699277877807617, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.06053408980369568, 'loss_2': 0.0039215087890625, 'loss_3': -14.843461990356445, 'loss_4': 0.4836351275444031, 'epoch': 1.67}
{'loss': 0.0716, 'grad_norm': 22.050168991088867, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.06650543212890625, 'loss_2': 0.0050506591796875, 'loss_3': -14.96334457397461, 'loss_4': 0.8451802134513855, 'epoch': 1.67}
{'loss': 0.133, 'grad_norm': 35.934730529785156, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.1263362318277359, 'loss_2': 0.00664520263671875, 'loss_3': -15.309199333190918, 'loss_4': 1.3672564029693604, 'epoch': 1.68}
{'loss': 0.0369, 'grad_norm': 10.297938346862793, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.030249087139964104, 'loss_2': 0.00669097900390625, 'loss_3': -15.171107292175293, 'loss_4': 1.0467724800109863, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 15:26:17,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:17,359 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:30<1:24:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:24,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02861056476831436, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019550776109099388, 'eval_loss_2': 0.009059786796569824, 'eval_loss_3': -18.13802719116211, 'eval_loss_4': 0.5753248333930969, 'epoch': 1.69}
{'loss': 0.1099, 'grad_norm': 25.286054611206055, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.10973583161830902, 'loss_2': 0.00015437602996826172, 'loss_3': -15.263960838317871, 'loss_4': 1.1063743829727173, 'epoch': 1.69}
{'loss': 0.0664, 'grad_norm': 18.71776580810547, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.05796544998884201, 'loss_2': 0.008453369140625, 'loss_3': -15.151918411254883, 'loss_4': 0.648583173751831, 'epoch': 1.7}
{'loss': 0.1594, 'grad_norm': 34.59974670410156, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.14713412523269653, 'loss_2': 0.01226043701171875, 'loss_3': -15.171835899353027, 'loss_4': 0.7439610362052917, 'epoch': 1.7}
{'loss': 0.1175, 'grad_norm': 29.581022262573242, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.10422839969396591, 'loss_2': 0.013275146484375, 'loss_3': -15.438000679016113, 'loss_4': 0.5462809205055237, 'epoch': 1.71}
{'loss': 0.1687, 'grad_norm': 28.322919845581055, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.16153249144554138, 'loss_2': 0.0071563720703125, 'loss_3': -15.182761192321777, 'loss_4': 0.5303558707237244, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 15:26:24,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:24,714 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:37<1:24:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:32,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03788576275110245, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01974831148982048, 'eval_loss_2': 0.018137454986572266, 'eval_loss_3': -18.165008544921875, 'eval_loss_4': 0.3417876660823822, 'epoch': 1.72}
{'loss': 0.0971, 'grad_norm': 27.639034271240234, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.08433961868286133, 'loss_2': 0.0127410888671875, 'loss_3': -15.106012344360352, 'loss_4': 0.3106377124786377, 'epoch': 1.72}
{'loss': 0.0818, 'grad_norm': 15.08736515045166, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.06442486494779587, 'loss_2': 0.0174102783203125, 'loss_3': -15.019432067871094, 'loss_4': -0.44926875829696655, 'epoch': 1.73}
{'loss': 0.0397, 'grad_norm': 10.439791679382324, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.03551751375198364, 'loss_2': 0.00418853759765625, 'loss_3': -15.231945037841797, 'loss_4': 0.357980340719223, 'epoch': 1.73}
{'loss': 0.0546, 'grad_norm': 18.921281814575195, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.05097734183073044, 'loss_2': 0.0036163330078125, 'loss_3': -15.316038131713867, 'loss_4': 0.39907941222190857, 'epoch': 1.74}
{'loss': 0.0805, 'grad_norm': 18.21817970275879, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.07363895326852798, 'loss_2': 0.0068359375, 'loss_3': -15.265512466430664, 'loss_4': 0.0943635106086731, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 15:26:32,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:32,068 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:41<1:24:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:26:35,867 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300
[INFO|configuration_utils.py:420] 2025-01-21 15:26:35,868 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300/config.json                                                                             
{'eval_loss': 0.028300832957029343, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.635, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.024659615010023117, 'eval_loss_2': 0.0036412179470062256, 'eval_loss_3': -18.182228088378906, 'eval_loss_4': 0.44236135482788086, 'epoch': 1.74}
[INFO|modeling_utils.py:2988] 2025-01-21 15:26:36,342 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:26:36,343 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:26:36,344 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:26:37,101 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-125] due to args.save_total_limit
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:46<1:32:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:26:40,917 >>
{'loss': 0.114, 'grad_norm': 28.89581871032715, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.109619140625, 'loss_2': 0.00438690185546875, 'loss_3': -15.29313850402832, 'loss_4': 0.45248737931251526, 'epoch': 1.75}
{'loss': 0.0479, 'grad_norm': 10.313063621520996, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.039144281297922134, 'loss_2': 0.0087432861328125, 'loss_3': -15.492416381835938, 'loss_4': 0.34851279854774475, 'epoch': 1.76}
{'loss': 0.0857, 'grad_norm': 21.89846420288086, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.07125091552734375, 'loss_2': 0.014495849609375, 'loss_3': -15.163707733154297, 'loss_4': 0.6716774106025696, 'epoch': 1.76}
{'loss': 0.0883, 'grad_norm': 29.017362594604492, 'learning_rate': 2.825e-05, 'loss_1': 0.07910606265068054, 'loss_2': 0.0091705322265625, 'loss_3': -15.179433822631836, 'loss_4': 0.8173935413360596, 'epoch': 1.77}
{'loss': 0.1331, 'grad_norm': 27.644020080566406, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.1234450563788414, 'loss_2': 0.00970458984375, 'loss_3': -15.39084243774414, 'loss_4': 0.4970802962779999, 'epoch': 1.77}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:26:40,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:40,917 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [07:53<1:25:23,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:26:48,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03782181441783905, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.894, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.027102038264274597, 'eval_loss_2': 0.010719776153564453, 'eval_loss_3': -18.123321533203125, 'eval_loss_4': 0.6301571130752563, 'epoch': 1.77}
{'loss': 0.1634, 'grad_norm': 34.60321807861328, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.15131565928459167, 'loss_2': 0.01210784912109375, 'loss_3': -14.903650283813477, 'loss_4': 0.6643988490104675, 'epoch': 1.78}
{'loss': 0.1086, 'grad_norm': 28.422029495239258, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.09211661666631699, 'loss_2': 0.016448974609375, 'loss_3': -15.19361686706543, 'loss_4': 0.3453136682510376, 'epoch': 1.78}
{'loss': 0.0615, 'grad_norm': 12.060083389282227, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.050084881484508514, 'loss_2': 0.011444091796875, 'loss_3': -15.363287925720215, 'loss_4': 0.4366428852081299, 'epoch': 1.79}
{'loss': 0.0895, 'grad_norm': 18.700910568237305, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.07608035951852798, 'loss_2': 0.013397216796875, 'loss_3': -15.324596405029297, 'loss_4': 0.39073342084884644, 'epoch': 1.8}
{'loss': 0.0835, 'grad_norm': 17.9727840423584, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.0774187371134758, 'loss_2': 0.00604248046875, 'loss_3': -15.375082015991211, 'loss_4': 0.2495259791612625, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 15:26:48,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:48,260 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:01<1:24:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:55,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037101708352565765, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.659, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.03135760873556137, 'eval_loss_2': 0.0057440996170043945, 'eval_loss_3': -18.10842514038086, 'eval_loss_4': 0.775199830532074, 'epoch': 1.8}
{'loss': 0.0375, 'grad_norm': 9.403966903686523, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.032055072486400604, 'loss_2': 0.005462646484375, 'loss_3': -15.256999969482422, 'loss_4': 0.5409864187240601, 'epoch': 1.81}
{'loss': 0.0801, 'grad_norm': 20.438199996948242, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.072951540350914, 'loss_2': 0.007152557373046875, 'loss_3': -15.347241401672363, 'loss_4': 0.28611767292022705, 'epoch': 1.81}
{'loss': 0.2415, 'grad_norm': 28.365724563598633, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.22588035464286804, 'loss_2': 0.0156097412109375, 'loss_3': -15.137248992919922, 'loss_4': 0.8688591122627258, 'epoch': 1.82}
{'loss': 0.0389, 'grad_norm': 12.883614540100098, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.03595055267214775, 'loss_2': 0.00295257568359375, 'loss_3': -15.360372543334961, 'loss_4': 0.6798524856567383, 'epoch': 1.83}
{'loss': 0.1414, 'grad_norm': 26.798585891723633, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.12959550321102142, 'loss_2': 0.01177978515625, 'loss_3': -15.283838272094727, 'loss_4': 1.0561578273773193, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 15:26:55,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:55,611 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:08<1:23:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:02,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03320389613509178, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.704, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0218731090426445, 'eval_loss_2': 0.011330783367156982, 'eval_loss_3': -18.155128479003906, 'eval_loss_4': 0.8798251748085022, 'epoch': 1.83}
{'loss': 0.1307, 'grad_norm': 29.608076095581055, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.11856997013092041, 'loss_2': 0.0120849609375, 'loss_3': -15.203449249267578, 'loss_4': 1.137091875076294, 'epoch': 1.84}
{'loss': 0.1124, 'grad_norm': 20.039424896240234, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.10632620751857758, 'loss_2': 0.0060882568359375, 'loss_3': -15.417888641357422, 'loss_4': 1.2085022926330566, 'epoch': 1.84}
{'loss': 0.0628, 'grad_norm': 16.162738800048828, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.059269752353429794, 'loss_2': 0.003559112548828125, 'loss_3': -15.276946067810059, 'loss_4': 1.1715285778045654, 'epoch': 1.85}
{'loss': 0.0808, 'grad_norm': 23.393583297729492, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.07942308485507965, 'loss_2': 0.001346588134765625, 'loss_3': -15.286240577697754, 'loss_4': 1.1108816862106323, 'epoch': 1.85}
{'loss': 0.1596, 'grad_norm': 44.971065521240234, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.14451248943805695, 'loss_2': 0.015045166015625, 'loss_3': -15.134529113769531, 'loss_4': 1.1382744312286377, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 15:27:02,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:02,953 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:12<1:23:45,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:27:06,756 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320
[INFO|configuration_utils.py:420] 2025-01-21 15:27:06,757 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320/config.json                                                                             
{'eval_loss': 0.02661181427538395, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02263765037059784, 'eval_loss_2': 0.003974169492721558, 'eval_loss_3': -18.139062881469727, 'eval_loss_4': 1.173885464668274, 'epoch': 1.86}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:07,226 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:07,227 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:07,227 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:08,012 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-300] due to args.save_total_limit
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:17<1:31:31,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:27:11,667 >>
{'loss': 0.038, 'grad_norm': 10.330992698669434, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.03424103930592537, 'loss_2': 0.0037784576416015625, 'loss_3': -15.02550220489502, 'loss_4': 0.6858395338058472, 'epoch': 1.87}
{'loss': 0.0419, 'grad_norm': 11.359762191772461, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.04094114899635315, 'loss_2': 0.0009570121765136719, 'loss_3': -15.244163513183594, 'loss_4': 1.2361608743667603, 'epoch': 1.87}
{'loss': 0.0784, 'grad_norm': 24.54096221923828, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.07450658828020096, 'loss_2': 0.0038547515869140625, 'loss_3': -15.166976928710938, 'loss_4': 1.2095792293548584, 'epoch': 1.88}
{'loss': 0.2188, 'grad_norm': 52.439796447753906, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.21815750002861023, 'loss_2': 0.0006227493286132812, 'loss_3': -15.451238632202148, 'loss_4': 1.6937692165374756, 'epoch': 1.88}
{'loss': 0.0364, 'grad_norm': 10.093421936035156, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.03162478655576706, 'loss_2': 0.00473785400390625, 'loss_3': -15.304359436035156, 'loss_4': 1.0781099796295166, 'epoch': 1.89}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:11,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:11,667 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:24<1:24:50,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:27:19,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03258983790874481, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.755, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.026505662128329277, 'eval_loss_2': 0.006084173917770386, 'eval_loss_3': -18.11739158630371, 'eval_loss_4': 1.258483648300171, 'epoch': 1.89}
{'loss': 0.0418, 'grad_norm': 12.296167373657227, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.03707706928253174, 'loss_2': 0.0047454833984375, 'loss_3': -15.051870346069336, 'loss_4': 1.027963399887085, 'epoch': 1.9}
{'loss': 0.049, 'grad_norm': 14.72835922241211, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.04706834256649017, 'loss_2': 0.00188446044921875, 'loss_3': -15.1612548828125, 'loss_4': 1.305957555770874, 'epoch': 1.9}
{'loss': 0.0598, 'grad_norm': 20.0048770904541, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.056713685393333435, 'loss_2': 0.003082275390625, 'loss_3': -15.346668243408203, 'loss_4': 1.0611324310302734, 'epoch': 1.91}
{'loss': 0.0273, 'grad_norm': 7.4455976486206055, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.024834534153342247, 'loss_2': 0.0024700164794921875, 'loss_3': -15.363506317138672, 'loss_4': 0.6881612539291382, 'epoch': 1.91}
{'loss': 0.0636, 'grad_norm': 16.819026947021484, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.060734253376722336, 'loss_2': 0.0028228759765625, 'loss_3': -15.219571113586426, 'loss_4': 1.008002758026123, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 15:27:19,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:19,009 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:28<1:24:50,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 15:27:22,809 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330
[INFO|configuration_utils.py:420] 2025-01-21 15:27:22,811 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330/config.json                                                                             
{'eval_loss': 0.02413850650191307, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019652526825666428, 'eval_loss_2': 0.004485979676246643, 'eval_loss_3': -18.145402908325195, 'eval_loss_4': 1.2949087619781494, 'epoch': 1.92}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:23,293 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:23,294 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:23,295 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:24,096 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-320] due to args.save_total_limit
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:33<1:31:35,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:27:27,726 >>
{'loss': 0.0469, 'grad_norm': 13.214055061340332, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.03411407396197319, 'loss_2': 0.01276397705078125, 'loss_3': -15.301474571228027, 'loss_4': 1.3647003173828125, 'epoch': 1.92}
{'loss': 0.0754, 'grad_norm': 18.26990509033203, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.07022041082382202, 'loss_2': 0.005157470703125, 'loss_3': -15.090216636657715, 'loss_4': 1.322542428970337, 'epoch': 1.93}
{'loss': 0.0952, 'grad_norm': 25.527116775512695, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.09092164039611816, 'loss_2': 0.004241943359375, 'loss_3': -14.896038055419922, 'loss_4': 0.9529119729995728, 'epoch': 1.94}
{'loss': 0.0832, 'grad_norm': 29.006772994995117, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.0824781060218811, 'loss_2': 0.0007648468017578125, 'loss_3': -15.188891410827637, 'loss_4': 1.2987568378448486, 'epoch': 1.94}
{'loss': 0.082, 'grad_norm': 19.114837646484375, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.08013825118541718, 'loss_2': 0.001850128173828125, 'loss_3': -15.266746520996094, 'loss_4': 1.5579888820648193, 'epoch': 1.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:27,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:27,726 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:40<1:24:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:27:35,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02719118446111679, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.024503430351614952, 'eval_loss_2': 0.0026877522468566895, 'eval_loss_3': -18.092926025390625, 'eval_loss_4': 1.5043619871139526, 'epoch': 1.95}
{'loss': 0.0931, 'grad_norm': 25.46949577331543, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.09086654335260391, 'loss_2': 0.00220489501953125, 'loss_3': -15.122191429138184, 'loss_4': 1.2774083614349365, 'epoch': 1.95}
{'loss': 0.1179, 'grad_norm': 25.81978416442871, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.11632530391216278, 'loss_2': 0.0016117095947265625, 'loss_3': -15.24502182006836, 'loss_4': 1.6623303890228271, 'epoch': 1.96}
{'loss': 0.1407, 'grad_norm': 28.43707275390625, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.14060884714126587, 'loss_2': 9.649991989135742e-05, 'loss_3': -15.148032188415527, 'loss_4': 1.6709260940551758, 'epoch': 1.97}
{'loss': 0.1121, 'grad_norm': 26.373937606811523, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.10986780375242233, 'loss_2': 0.0022125244140625, 'loss_3': -15.312564849853516, 'loss_4': 1.490430235862732, 'epoch': 1.97}
{'loss': 0.0613, 'grad_norm': 13.824213981628418, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.04961274191737175, 'loss_2': 0.0116729736328125, 'loss_3': -15.202598571777344, 'loss_4': 1.8049373626708984, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 15:27:35,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:35,069 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:47<1:18:36,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 15:27:42,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030310863628983498, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.024164672940969467, 'eval_loss_2': 0.00614619255065918, 'eval_loss_3': -18.142566680908203, 'eval_loss_4': 1.516221523284912, 'epoch': 1.98}
{'loss': 0.0502, 'grad_norm': 13.002642631530762, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.048412542790174484, 'loss_2': 0.0017786026000976562, 'loss_3': -15.260993003845215, 'loss_4': 1.5731990337371826, 'epoch': 1.98}
{'loss': 0.076, 'grad_norm': 18.8093204498291, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.0717046707868576, 'loss_2': 0.00426483154296875, 'loss_3': -15.278131484985352, 'loss_4': 1.254530668258667, 'epoch': 1.99}
{'loss': 0.0921, 'grad_norm': 24.647497177124023, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.08208861202001572, 'loss_2': 0.00998687744140625, 'loss_3': -15.109231948852539, 'loss_4': 1.4920074939727783, 'epoch': 1.99}
{'loss': 0.0443, 'grad_norm': 15.924344062805176, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.03651528060436249, 'loss_2': 0.0078277587890625, 'loss_3': -15.448142051696777, 'loss_4': 1.6311285495758057, 'epoch': 2.0}
{'loss': 0.1092, 'grad_norm': 32.12628173828125, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.10547695308923721, 'loss_2': 0.00368499755859375, 'loss_3': -15.079498291015625, 'loss_4': 1.126075029373169, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 15:27:42,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:42,102 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:51<1:18:36,  1.02it/s][INFO|trainer.py:3910] 2025-01-21 15:27:45,911 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345
[INFO|configuration_utils.py:420] 2025-01-21 15:27:45,912 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345/config.json                                                                             
{'eval_loss': 0.023968398571014404, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.901, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.020054101943969727, 'eval_loss_2': 0.003914296627044678, 'eval_loss_3': -18.2056941986084, 'eval_loss_4': 1.6123045682907104, 'epoch': 2.01}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:46,401 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:46,403 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:46,403 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:47,211 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-330] due to args.save_total_limit
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [08:56<1:30:29,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 15:27:50,845 >>
{'loss': 0.0896, 'grad_norm': 20.047245025634766, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.08921525627374649, 'loss_2': 0.0003829002380371094, 'loss_3': -15.256378173828125, 'loss_4': 1.6493797302246094, 'epoch': 2.01}
{'loss': 0.1031, 'grad_norm': 20.684350967407227, 'learning_rate': 2.8e-05, 'loss_1': 0.08514535427093506, 'loss_2': 0.0179290771484375, 'loss_3': -15.197568893432617, 'loss_4': 1.6201503276824951, 'epoch': 2.02}
{'loss': 0.0766, 'grad_norm': 19.438810348510742, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.06070796772837639, 'loss_2': 0.015899658203125, 'loss_3': -15.193315505981445, 'loss_4': 1.0463757514953613, 'epoch': 2.02}
{'loss': 0.0557, 'grad_norm': 12.900833129882812, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.048554677516222, 'loss_2': 0.007183074951171875, 'loss_3': -15.156837463378906, 'loss_4': 1.0606732368469238, 'epoch': 2.03}
{'loss': 0.0524, 'grad_norm': 10.923467636108398, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.04895653948187828, 'loss_2': 0.003406524658203125, 'loss_3': -15.425092697143555, 'loss_4': 1.0172908306121826, 'epoch': 2.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:50,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:50,846 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:00<1:30:29,  1.13s/it][INFO|trainer.py:3910] 2025-01-21 15:27:54,649 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350
[INFO|configuration_utils.py:420] 2025-01-21 15:27:54,651 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350/config.json                                                                             
{'eval_loss': 0.021496908739209175, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01932130940258503, 'eval_loss_2': 0.0021755993366241455, 'eval_loss_3': -18.201648712158203, 'eval_loss_4': 1.4799354076385498, 'epoch': 2.03}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:55,139 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:55,141 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:55,141 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:55,937 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-345] due to args.save_total_limit
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:04<1:32:19,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:27:59,577 >>
{'loss': 0.052, 'grad_norm': 16.020193099975586, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.048645902425050735, 'loss_2': 0.00333404541015625, 'loss_3': -15.348498344421387, 'loss_4': 1.6176121234893799, 'epoch': 2.04}
{'loss': 0.1016, 'grad_norm': 27.4890079498291, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.09236790984869003, 'loss_2': 0.00927734375, 'loss_3': -15.162328720092773, 'loss_4': 1.601473093032837, 'epoch': 2.05}
{'loss': 0.0511, 'grad_norm': 19.930118560791016, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.046808045357465744, 'loss_2': 0.00432586669921875, 'loss_3': -15.247962951660156, 'loss_4': 1.1479789018630981, 'epoch': 2.05}
{'loss': 0.0689, 'grad_norm': 24.382205963134766, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.06666886061429977, 'loss_2': 0.00226593017578125, 'loss_3': -15.268548965454102, 'loss_4': 1.2858531475067139, 'epoch': 2.06}
{'loss': 0.0615, 'grad_norm': 16.436866760253906, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.05093301460146904, 'loss_2': 0.0105743408203125, 'loss_3': -15.182973861694336, 'loss_4': 1.810387134552002, 'epoch': 2.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:59,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:59,577 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:12<1:24:33,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:28:06,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03345874324440956, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017380747944116592, 'eval_loss_2': 0.01607799530029297, 'eval_loss_3': -18.169551849365234, 'eval_loss_4': 1.1821835041046143, 'epoch': 2.06}
{'loss': 0.0585, 'grad_norm': 14.455001831054688, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.0466710589826107, 'loss_2': 0.01184844970703125, 'loss_3': -15.495386123657227, 'loss_4': 1.2708516120910645, 'epoch': 2.07}
{'loss': 0.0898, 'grad_norm': 15.317953109741211, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.08135668933391571, 'loss_2': 0.00847625732421875, 'loss_3': -15.394394874572754, 'loss_4': 0.7562004327774048, 'epoch': 2.08}
{'loss': 0.0755, 'grad_norm': 21.765979766845703, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.06194387376308441, 'loss_2': 0.0135345458984375, 'loss_3': -15.229093551635742, 'loss_4': 0.7943663597106934, 'epoch': 2.08}
{'loss': 0.0476, 'grad_norm': 16.56671142578125, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.03386600688099861, 'loss_2': 0.0137176513671875, 'loss_3': -15.391572952270508, 'loss_4': 1.3794584274291992, 'epoch': 2.09}
{'loss': 0.0392, 'grad_norm': 9.186026573181152, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.030664555728435516, 'loss_2': 0.008575439453125, 'loss_3': -15.34992790222168, 'loss_4': 0.6167932748794556, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 15:28:06,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:06,918 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:19<1:23:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:14,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028522957116365433, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01977967470884323, 'eval_loss_2': 0.0087432861328125, 'eval_loss_3': -18.14196014404297, 'eval_loss_4': 0.7365384697914124, 'epoch': 2.09}
{'loss': 0.0472, 'grad_norm': 12.485404014587402, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.038348231464624405, 'loss_2': 0.00888824462890625, 'loss_3': -15.414176940917969, 'loss_4': 0.9045330286026001, 'epoch': 2.1}
{'loss': 0.1126, 'grad_norm': 26.356605529785156, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.10225803405046463, 'loss_2': 0.0102996826171875, 'loss_3': -15.25337028503418, 'loss_4': 0.6460506319999695, 'epoch': 2.1}
{'loss': 0.0399, 'grad_norm': 15.61910343170166, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.031375158578157425, 'loss_2': 0.0084991455078125, 'loss_3': -15.139143943786621, 'loss_4': 0.7428349256515503, 'epoch': 2.11}
{'loss': 0.0268, 'grad_norm': 11.409090995788574, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.024468595162034035, 'loss_2': 0.00238037109375, 'loss_3': -15.471790313720703, 'loss_4': 0.2682020664215088, 'epoch': 2.12}
{'loss': 0.0422, 'grad_norm': 12.487255096435547, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.038562823086977005, 'loss_2': 0.00362396240234375, 'loss_3': -14.999237060546875, 'loss_4': 0.30905768275260925, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 15:28:14,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:14,261 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:27<1:22:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:21,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030088944360613823, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02034054510295391, 'eval_loss_2': 0.009748399257659912, 'eval_loss_3': -18.087501525878906, 'eval_loss_4': 0.26885470747947693, 'epoch': 2.12}
{'loss': 0.0432, 'grad_norm': 12.277010917663574, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.029231909662485123, 'loss_2': 0.0139312744140625, 'loss_3': -15.138736724853516, 'loss_4': 0.127531960606575, 'epoch': 2.13}
{'loss': 0.0299, 'grad_norm': 8.796558380126953, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.023663343861699104, 'loss_2': 0.00628662109375, 'loss_3': -15.335638999938965, 'loss_4': -0.04366156458854675, 'epoch': 2.13}
{'loss': 0.0742, 'grad_norm': 29.81618309020996, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.06285104155540466, 'loss_2': 0.01129913330078125, 'loss_3': -15.126856803894043, 'loss_4': 0.7310828566551208, 'epoch': 2.14}
{'loss': 0.0383, 'grad_norm': 14.207527160644531, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.03748191520571709, 'loss_2': 0.0008144378662109375, 'loss_3': -15.278931617736816, 'loss_4': 0.22952429950237274, 'epoch': 2.15}
{'loss': 0.0366, 'grad_norm': 13.267439842224121, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.03361349552869797, 'loss_2': 0.00293731689453125, 'loss_3': -15.40225887298584, 'loss_4': -0.019692011177539825, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 15:28:21,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:21,612 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:34<1:22:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:28,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034761011600494385, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.904, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.030412163585424423, 'eval_loss_2': 0.004348844289779663, 'eval_loss_3': -18.06005859375, 'eval_loss_4': -0.01901809498667717, 'epoch': 2.15}
{'loss': 0.0309, 'grad_norm': 10.287199020385742, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.029424674808979034, 'loss_2': 0.0014362335205078125, 'loss_3': -15.230596542358398, 'loss_4': -0.18287745118141174, 'epoch': 2.16}
{'loss': 0.2322, 'grad_norm': 47.693519592285156, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.2275221347808838, 'loss_2': 0.00469970703125, 'loss_3': -15.148225784301758, 'loss_4': -0.6085740327835083, 'epoch': 2.16}
{'loss': 0.0459, 'grad_norm': 16.295927047729492, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.0382753387093544, 'loss_2': 0.007598876953125, 'loss_3': -15.428138732910156, 'loss_4': -0.21842116117477417, 'epoch': 2.17}
{'loss': 0.0332, 'grad_norm': 6.2159600257873535, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.017422229051589966, 'loss_2': 0.0157623291015625, 'loss_3': -15.430418968200684, 'loss_4': -0.03758230060338974, 'epoch': 2.17}
{'loss': 0.0493, 'grad_norm': 8.515880584716797, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.027156587690114975, 'loss_2': 0.02215576171875, 'loss_3': -15.198469161987305, 'loss_4': 0.04544840008020401, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 15:28:28,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:28,960 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:41<1:22:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:36,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03834094852209091, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.395, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.020645523443818092, 'eval_loss_2': 0.01769542694091797, 'eval_loss_3': -18.09051513671875, 'eval_loss_4': 0.1351066678762436, 'epoch': 2.18}
{'loss': 0.0476, 'grad_norm': 9.56869888305664, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.026528311893343925, 'loss_2': 0.02105712890625, 'loss_3': -15.167503356933594, 'loss_4': 0.294546902179718, 'epoch': 2.19}
{'loss': 0.0529, 'grad_norm': 12.492039680480957, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.03622456267476082, 'loss_2': 0.016693115234375, 'loss_3': -15.371024131774902, 'loss_4': 0.047383636236190796, 'epoch': 2.19}
{'loss': 0.046, 'grad_norm': 9.712278366088867, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.03470761328935623, 'loss_2': 0.01128387451171875, 'loss_3': -15.457151412963867, 'loss_4': 0.15627503395080566, 'epoch': 2.2}
{'loss': 0.1148, 'grad_norm': 30.808019638061523, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.10457253456115723, 'loss_2': 0.01021575927734375, 'loss_3': -15.189126968383789, 'loss_4': 0.2641477584838867, 'epoch': 2.2}
{'loss': 0.0478, 'grad_norm': 13.563713073730469, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.04589409381151199, 'loss_2': 0.0018596649169921875, 'loss_3': -15.512310028076172, 'loss_4': 0.2072746455669403, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 15:28:36,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:36,304 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:49<1:22:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:43,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024066664278507233, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.58, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019916720688343048, 'eval_loss_2': 0.004149943590164185, 'eval_loss_3': -18.155227661132812, 'eval_loss_4': 0.43269237875938416, 'epoch': 2.21}
{'loss': 0.1008, 'grad_norm': 14.926630973815918, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.10008715093135834, 'loss_2': 0.0006961822509765625, 'loss_3': -15.489082336425781, 'loss_4': 0.7450001239776611, 'epoch': 2.22}
{'loss': 0.0588, 'grad_norm': 17.593994140625, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.056156136095523834, 'loss_2': 0.0026836395263671875, 'loss_3': -15.442211151123047, 'loss_4': 0.30879640579223633, 'epoch': 2.22}
{'loss': 0.1216, 'grad_norm': 31.760780334472656, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.11575891822576523, 'loss_2': 0.0058746337890625, 'loss_3': -15.132231712341309, 'loss_4': 0.39854443073272705, 'epoch': 2.23}
{'loss': 0.0564, 'grad_norm': 14.021536827087402, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.053903210908174515, 'loss_2': 0.0025348663330078125, 'loss_3': -15.563461303710938, 'loss_4': 0.8116222023963928, 'epoch': 2.23}
{'loss': 0.0776, 'grad_norm': 16.567014694213867, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.07685365527868271, 'loss_2': 0.000701904296875, 'loss_3': -15.612106323242188, 'loss_4': 0.9428292512893677, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 15:28:43,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:43,645 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:56<1:22:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:51,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02702868916094303, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02205195091664791, 'eval_loss_2': 0.004976734519004822, 'eval_loss_3': -18.21154022216797, 'eval_loss_4': 1.0295647382736206, 'epoch': 2.24}
{'loss': 0.0802, 'grad_norm': 20.45426368713379, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.07968225330114365, 'loss_2': 0.00047206878662109375, 'loss_3': -15.624174118041992, 'loss_4': 0.8886861801147461, 'epoch': 2.24}
{'loss': 0.1632, 'grad_norm': 34.177940368652344, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.16164986789226532, 'loss_2': 0.0015621185302734375, 'loss_3': -15.646502494812012, 'loss_4': 1.536402702331543, 'epoch': 2.25}
{'loss': 0.0713, 'grad_norm': 17.83631706237793, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.07085766643285751, 'loss_2': 0.00043272972106933594, 'loss_3': -15.518819808959961, 'loss_4': 1.3770012855529785, 'epoch': 2.26}
{'loss': 0.0619, 'grad_norm': 21.133800506591797, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.058721672743558884, 'loss_2': 0.003204345703125, 'loss_3': -15.60256290435791, 'loss_4': 1.193886637687683, 'epoch': 2.26}
{'loss': 0.0598, 'grad_norm': 14.965812683105469, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.051970455795526505, 'loss_2': 0.00782012939453125, 'loss_3': -15.635031700134277, 'loss_4': 1.270346760749817, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 15:28:51,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:51,007 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:03<1:22:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:58,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022889763116836548, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.248, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018086623400449753, 'eval_loss_2': 0.0048031434416770935, 'eval_loss_3': -18.265308380126953, 'eval_loss_4': 1.1769897937774658, 'epoch': 2.27}
{'loss': 0.0717, 'grad_norm': 13.98105239868164, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.06157127395272255, 'loss_2': 0.0101165771484375, 'loss_3': -15.663705825805664, 'loss_4': 1.111982822418213, 'epoch': 2.27}
{'loss': 0.0584, 'grad_norm': 12.626778602600098, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.05449720844626427, 'loss_2': 0.003948211669921875, 'loss_3': -15.583248138427734, 'loss_4': 1.5582311153411865, 'epoch': 2.28}
{'loss': 0.0423, 'grad_norm': 11.959675788879395, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.040904343128204346, 'loss_2': 0.0014448165893554688, 'loss_3': -15.749422073364258, 'loss_4': 1.1642982959747314, 'epoch': 2.28}
{'loss': 0.0711, 'grad_norm': 25.869430541992188, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.06762697547674179, 'loss_2': 0.0034236907958984375, 'loss_3': -15.640944480895996, 'loss_4': 1.9335993528366089, 'epoch': 2.29}
{'loss': 0.0407, 'grad_norm': 9.256746292114258, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.03189118579030037, 'loss_2': 0.00884246826171875, 'loss_3': -15.651321411132812, 'loss_4': 1.2459652423858643, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 15:28:58,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:58,363 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:11<1:22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:05,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02258780226111412, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018364159390330315, 'eval_loss_2': 0.004223644733428955, 'eval_loss_3': -18.254501342773438, 'eval_loss_4': 1.2739636898040771, 'epoch': 2.3}
{'loss': 0.1181, 'grad_norm': 18.545690536499023, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.11242137849330902, 'loss_2': 0.00565338134765625, 'loss_3': -15.48288345336914, 'loss_4': 1.3443028926849365, 'epoch': 2.3}
{'loss': 0.0386, 'grad_norm': 10.055160522460938, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.035111166536808014, 'loss_2': 0.003467559814453125, 'loss_3': -15.601486206054688, 'loss_4': 1.1991100311279297, 'epoch': 2.31}
{'loss': 0.0654, 'grad_norm': 20.2299747467041, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.059146709740161896, 'loss_2': 0.0062103271484375, 'loss_3': -15.64185619354248, 'loss_4': 1.6084601879119873, 'epoch': 2.31}
{'loss': 0.1368, 'grad_norm': 30.263843536376953, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.131268709897995, 'loss_2': 0.00551605224609375, 'loss_3': -15.502326011657715, 'loss_4': 1.632551670074463, 'epoch': 2.32}
{'loss': 0.1205, 'grad_norm': 15.025148391723633, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.11091313511133194, 'loss_2': 0.0096282958984375, 'loss_3': -15.528382301330566, 'loss_4': 1.526411533355713, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 15:29:05,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:05,715 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:18<1:22:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:13,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032909516245126724, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.919, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.022963527590036392, 'eval_loss_2': 0.009945988655090332, 'eval_loss_3': -18.201412200927734, 'eval_loss_4': 1.4427001476287842, 'epoch': 2.33}
{'loss': 0.09, 'grad_norm': 25.27945327758789, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.08594232052564621, 'loss_2': 0.0040130615234375, 'loss_3': -15.652206420898438, 'loss_4': 1.5407812595367432, 'epoch': 2.33}
{'loss': 0.0586, 'grad_norm': 11.555816650390625, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.04637478291988373, 'loss_2': 0.01220703125, 'loss_3': -15.408459663391113, 'loss_4': 1.2499687671661377, 'epoch': 2.34}
{'loss': 0.0343, 'grad_norm': 8.27724552154541, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.028018424287438393, 'loss_2': 0.006313323974609375, 'loss_3': -15.62204360961914, 'loss_4': 1.1779487133026123, 'epoch': 2.34}
{'loss': 0.0649, 'grad_norm': 13.104424476623535, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.05410642549395561, 'loss_2': 0.01079559326171875, 'loss_3': -15.702394485473633, 'loss_4': 1.5826210975646973, 'epoch': 2.35}
{'loss': 0.0452, 'grad_norm': 13.23680591583252, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.03978128731250763, 'loss_2': 0.00543975830078125, 'loss_3': -15.430121421813965, 'loss_4': 1.6428401470184326, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 15:29:13,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:13,077 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:25<1:22:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:20,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03597910702228546, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.030358927324414253, 'eval_loss_2': 0.005620181560516357, 'eval_loss_3': -18.162609100341797, 'eval_loss_4': 1.5399898290634155, 'epoch': 2.35}
{'loss': 0.0637, 'grad_norm': 18.479089736938477, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.05826003476977348, 'loss_2': 0.005401611328125, 'loss_3': -15.657381057739258, 'loss_4': 1.754431962966919, 'epoch': 2.36}
{'loss': 0.0533, 'grad_norm': 17.132652282714844, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.05148959904909134, 'loss_2': 0.0017719268798828125, 'loss_3': -15.573570251464844, 'loss_4': 1.156394124031067, 'epoch': 2.37}
{'loss': 0.0473, 'grad_norm': 12.865324020385742, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.04027853161096573, 'loss_2': 0.0069732666015625, 'loss_3': -15.33316421508789, 'loss_4': 1.0508043766021729, 'epoch': 2.37}
{'loss': 0.0508, 'grad_norm': 17.44426727294922, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.04219505935907364, 'loss_2': 0.00859832763671875, 'loss_3': -15.593965530395508, 'loss_4': 1.1954309940338135, 'epoch': 2.38}
{'loss': 0.0423, 'grad_norm': 14.543097496032715, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.030567819252610207, 'loss_2': 0.01177978515625, 'loss_3': -15.61642837524414, 'loss_4': 1.873746395111084, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 15:29:20,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:20,419 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:33<1:21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:27,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036071669310331345, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0279435645788908, 'eval_loss_2': 0.008128106594085693, 'eval_loss_3': -18.13929557800293, 'eval_loss_4': 1.3676142692565918, 'epoch': 2.38}
{'loss': 0.1007, 'grad_norm': 24.623369216918945, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.08967269957065582, 'loss_2': 0.0110015869140625, 'loss_3': -15.34672737121582, 'loss_4': 1.5123193264007568, 'epoch': 2.39}
{'loss': 0.1109, 'grad_norm': 28.496950149536133, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.10651147365570068, 'loss_2': 0.00438690185546875, 'loss_3': -15.43693733215332, 'loss_4': 1.1276395320892334, 'epoch': 2.4}
{'loss': 0.0258, 'grad_norm': 9.976426124572754, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.023693174123764038, 'loss_2': 0.0020904541015625, 'loss_3': -15.483488082885742, 'loss_4': 1.1141284704208374, 'epoch': 2.4}
{'loss': 0.0464, 'grad_norm': 17.9464111328125, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.04630940780043602, 'loss_2': 6.604194641113281e-05, 'loss_3': -15.463691711425781, 'loss_4': 0.8438923358917236, 'epoch': 2.41}
{'loss': 0.0416, 'grad_norm': 13.494185447692871, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.03707907721400261, 'loss_2': 0.00452423095703125, 'loss_3': -15.293572425842285, 'loss_4': 0.8311343193054199, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 15:29:27,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:27,755 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:40<1:22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:35,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.045248717069625854, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.537, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03958090394735336, 'eval_loss_2': 0.0056678131222724915, 'eval_loss_3': -18.076953887939453, 'eval_loss_4': 1.2556476593017578, 'epoch': 2.41}
{'loss': 0.0188, 'grad_norm': 5.847293376922607, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.01454042550176382, 'loss_2': 0.00421142578125, 'loss_3': -15.402694702148438, 'loss_4': 1.0221924781799316, 'epoch': 2.42}
{'loss': 0.0331, 'grad_norm': 8.727649688720703, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.030438251793384552, 'loss_2': 0.00264739990234375, 'loss_3': -15.5029296875, 'loss_4': 1.2151638269424438, 'epoch': 2.42}
{'loss': 0.0293, 'grad_norm': 6.971368312835693, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.018993789330124855, 'loss_2': 0.01030731201171875, 'loss_3': -15.527437210083008, 'loss_4': 1.2252649068832397, 'epoch': 2.43}
{'loss': 0.0185, 'grad_norm': 6.7431559562683105, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.016220737248659134, 'loss_2': 0.00232696533203125, 'loss_3': -15.54495620727539, 'loss_4': 0.5836759805679321, 'epoch': 2.44}
{'loss': 0.0606, 'grad_norm': 16.172929763793945, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.05323392152786255, 'loss_2': 0.00733184814453125, 'loss_3': -15.374983787536621, 'loss_4': 1.0010164976119995, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 15:29:35,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:35,112 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:47<1:21:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:42,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0453166738152504, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.037392713129520416, 'eval_loss_2': 0.00792396068572998, 'eval_loss_3': -18.076143264770508, 'eval_loss_4': 1.1190961599349976, 'epoch': 2.44}
{'loss': 0.0409, 'grad_norm': 7.77980375289917, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.02504172921180725, 'loss_2': 0.015899658203125, 'loss_3': -15.491340637207031, 'loss_4': 1.0741405487060547, 'epoch': 2.45}
{'loss': 0.0397, 'grad_norm': 12.99836540222168, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.027012579143047333, 'loss_2': 0.0126800537109375, 'loss_3': -15.498451232910156, 'loss_4': 0.820558488368988, 'epoch': 2.45}
{'loss': 0.0518, 'grad_norm': 13.04720687866211, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.03836585953831673, 'loss_2': 0.0134124755859375, 'loss_3': -15.454611778259277, 'loss_4': 0.7782683372497559, 'epoch': 2.46}
{'loss': 0.0611, 'grad_norm': 19.744230270385742, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.048522934317588806, 'loss_2': 0.01253509521484375, 'loss_3': -15.136188507080078, 'loss_4': 1.1844931840896606, 'epoch': 2.47}
{'loss': 0.0427, 'grad_norm': 9.646244049072266, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.035108841955661774, 'loss_2': 0.00759124755859375, 'loss_3': -15.402095794677734, 'loss_4': 0.5150583982467651, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 15:29:42,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:42,459 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:55<1:21:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:49,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03171877562999725, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02560083568096161, 'eval_loss_2': 0.0061179399490356445, 'eval_loss_3': -18.074853897094727, 'eval_loss_4': 0.7077136039733887, 'epoch': 2.47}
{'loss': 0.0703, 'grad_norm': 31.1812744140625, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.06586804986000061, 'loss_2': 0.004390716552734375, 'loss_3': -15.375295639038086, 'loss_4': 0.408639132976532, 'epoch': 2.48}
{'loss': 0.0312, 'grad_norm': 9.048513412475586, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.02716957964003086, 'loss_2': 0.0040435791015625, 'loss_3': -15.400375366210938, 'loss_4': 0.7925034761428833, 'epoch': 2.48}
{'loss': 0.037, 'grad_norm': 9.375645637512207, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.03285104036331177, 'loss_2': 0.004131317138671875, 'loss_3': -15.281965255737305, 'loss_4': 0.2603480815887451, 'epoch': 2.49}
{'loss': 0.0429, 'grad_norm': 13.486852645874023, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.03831819072365761, 'loss_2': 0.00453948974609375, 'loss_3': -15.517708778381348, 'loss_4': 0.4084876477718353, 'epoch': 2.49}
{'loss': 0.0783, 'grad_norm': 16.37503433227539, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.06979799270629883, 'loss_2': 0.008514404296875, 'loss_3': -15.325557708740234, 'loss_4': 0.3120298981666565, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 15:29:49,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:49,810 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:02<1:21:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:57,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027616068720817566, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02029513195157051, 'eval_loss_2': 0.0073209404945373535, 'eval_loss_3': -18.10260009765625, 'eval_loss_4': 0.5420176982879639, 'epoch': 2.5}
{'loss': 0.0352, 'grad_norm': 11.780464172363281, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.03391353785991669, 'loss_2': 0.0013179779052734375, 'loss_3': -15.352511405944824, 'loss_4': 0.7804968357086182, 'epoch': 2.51}
{'loss': 0.0537, 'grad_norm': 14.972515106201172, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.03812463954091072, 'loss_2': 0.01560211181640625, 'loss_3': -15.435929298400879, 'loss_4': 0.5204519033432007, 'epoch': 2.51}
{'loss': 0.0752, 'grad_norm': 20.027870178222656, 'learning_rate': 2.75e-05, 'loss_1': 0.061496537178754807, 'loss_2': 0.013671875, 'loss_3': -15.4007568359375, 'loss_4': 0.7243026494979858, 'epoch': 2.52}
{'loss': 0.1389, 'grad_norm': 30.652456283569336, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.12204493582248688, 'loss_2': 0.016815185546875, 'loss_3': -15.34881591796875, 'loss_4': 1.155897617340088, 'epoch': 2.52}
{'loss': 0.0339, 'grad_norm': 10.603340148925781, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.027288926765322685, 'loss_2': 0.00659942626953125, 'loss_3': -15.438682556152344, 'loss_4': -0.5000768899917603, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 15:29:57,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:57,156 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:09<1:21:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:04,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02353665977716446, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.264, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01692930795252323, 'eval_loss_2': 0.006607353687286377, 'eval_loss_3': -18.15354347229004, 'eval_loss_4': 0.5554394721984863, 'epoch': 2.53}
{'loss': 0.1743, 'grad_norm': 27.236583709716797, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.16729740798473358, 'loss_2': 0.007007598876953125, 'loss_3': -15.305414199829102, 'loss_4': 0.872897744178772, 'epoch': 2.53}
{'loss': 0.0436, 'grad_norm': 21.611129760742188, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.035757094621658325, 'loss_2': 0.0078582763671875, 'loss_3': -15.519950866699219, 'loss_4': 1.072434663772583, 'epoch': 2.54}
{'loss': 0.068, 'grad_norm': 19.771677017211914, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.06714601069688797, 'loss_2': 0.0008344650268554688, 'loss_3': -15.710699081420898, 'loss_4': 0.7576566934585571, 'epoch': 2.55}
{'loss': 0.1001, 'grad_norm': 21.26124382019043, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.09717684984207153, 'loss_2': 0.002910614013671875, 'loss_3': -15.362058639526367, 'loss_4': 0.8124061822891235, 'epoch': 2.55}
{'loss': 0.0772, 'grad_norm': 16.67705535888672, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.06162850558757782, 'loss_2': 0.0156097412109375, 'loss_3': -15.186066627502441, 'loss_4': 1.071256160736084, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 15:30:04,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:04,513 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:17<1:21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:11,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0248415470123291, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01718287728726864, 'eval_loss_2': 0.007658667862415314, 'eval_loss_3': -18.218469619750977, 'eval_loss_4': 1.0259416103363037, 'epoch': 2.56}
{'loss': 0.0525, 'grad_norm': 14.128043174743652, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.04521600157022476, 'loss_2': 0.007328033447265625, 'loss_3': -15.565141677856445, 'loss_4': 1.0145537853240967, 'epoch': 2.56}
{'loss': 0.0636, 'grad_norm': 25.36758041381836, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.06027950718998909, 'loss_2': 0.003284454345703125, 'loss_3': -15.402469635009766, 'loss_4': 1.0596163272857666, 'epoch': 2.57}
{'loss': 0.0779, 'grad_norm': 21.437299728393555, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.07089123874902725, 'loss_2': 0.0069732666015625, 'loss_3': -15.559442520141602, 'loss_4': 1.2220895290374756, 'epoch': 2.58}
{'loss': 0.0698, 'grad_norm': 17.63654327392578, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.06176484376192093, 'loss_2': 0.0080718994140625, 'loss_3': -15.463974952697754, 'loss_4': 1.357765793800354, 'epoch': 2.58}
{'loss': 0.1027, 'grad_norm': 19.11977767944336, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.09614451974630356, 'loss_2': 0.00652313232421875, 'loss_3': -15.656394004821777, 'loss_4': 1.0686745643615723, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 15:30:11,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:11,860 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:24<1:21:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:19,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02356691285967827, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.494, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.020565129816532135, 'eval_loss_2': 0.003001779317855835, 'eval_loss_3': -18.233318328857422, 'eval_loss_4': 1.3342331647872925, 'epoch': 2.59}
{'loss': 0.0502, 'grad_norm': 16.242218017578125, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.04866441339254379, 'loss_2': 0.0015306472778320312, 'loss_3': -15.623849868774414, 'loss_4': 1.251407504081726, 'epoch': 2.59}
{'loss': 0.0504, 'grad_norm': 14.558759689331055, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.04984304681420326, 'loss_2': 0.0005846023559570312, 'loss_3': -15.445735931396484, 'loss_4': 1.4759001731872559, 'epoch': 2.6}
{'loss': 0.0879, 'grad_norm': 26.03544807434082, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.08674683421850204, 'loss_2': 0.0011959075927734375, 'loss_3': -15.522964477539062, 'loss_4': 1.5035252571105957, 'epoch': 2.6}
{'loss': 0.0407, 'grad_norm': 11.264810562133789, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.038184985518455505, 'loss_2': 0.0024967193603515625, 'loss_3': -15.72622013092041, 'loss_4': 1.1575374603271484, 'epoch': 2.61}
{'loss': 0.0738, 'grad_norm': 19.145444869995117, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.06055828556418419, 'loss_2': 0.01325225830078125, 'loss_3': -15.674440383911133, 'loss_4': 1.302409052848816, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 15:30:19,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:19,223 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:31<1:21:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:26,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03265131264925003, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02236045151948929, 'eval_loss_2': 0.010290861129760742, 'eval_loss_3': -18.184419631958008, 'eval_loss_4': 1.3209959268569946, 'epoch': 2.62}
{'loss': 0.0408, 'grad_norm': 14.726067543029785, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.039768241345882416, 'loss_2': 0.0010080337524414062, 'loss_3': -15.633676528930664, 'loss_4': 1.1446821689605713, 'epoch': 2.62}
{'loss': 0.0865, 'grad_norm': 21.05327796936035, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.07512131333351135, 'loss_2': 0.01136016845703125, 'loss_3': -15.563577651977539, 'loss_4': 1.080483078956604, 'epoch': 2.63}
{'loss': 0.0393, 'grad_norm': 9.424549102783203, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.031525950878858566, 'loss_2': 0.0078125, 'loss_3': -15.570232391357422, 'loss_4': 1.1202104091644287, 'epoch': 2.63}
{'loss': 0.072, 'grad_norm': 25.986995697021484, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.06075461953878403, 'loss_2': 0.011199951171875, 'loss_3': -15.462543487548828, 'loss_4': 1.1105244159698486, 'epoch': 2.64}
{'loss': 0.0374, 'grad_norm': 8.305109977722168, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.025030076503753662, 'loss_2': 0.0124053955078125, 'loss_3': -15.492277145385742, 'loss_4': 0.8766423463821411, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 15:30:26,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:26,573 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:39<1:21:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:33,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04012252390384674, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02997972071170807, 'eval_loss_2': 0.010142803192138672, 'eval_loss_3': -18.056610107421875, 'eval_loss_4': 1.0632994174957275, 'epoch': 2.65}
{'loss': 0.0492, 'grad_norm': 13.656947135925293, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.03531137481331825, 'loss_2': 0.0138702392578125, 'loss_3': -15.734294891357422, 'loss_4': 0.9477767944335938, 'epoch': 2.65}
{'loss': 0.1133, 'grad_norm': 22.487337112426758, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.1112404316663742, 'loss_2': 0.0020580291748046875, 'loss_3': -15.501862525939941, 'loss_4': 1.3881776332855225, 'epoch': 2.66}
{'loss': 0.0941, 'grad_norm': 25.111873626708984, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.09058574587106705, 'loss_2': 0.00354766845703125, 'loss_3': -15.429289817810059, 'loss_4': 0.6505794525146484, 'epoch': 2.66}
{'loss': 0.073, 'grad_norm': 22.545133590698242, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.07169895619153976, 'loss_2': 0.0012607574462890625, 'loss_3': -15.758203506469727, 'loss_4': 1.0088056325912476, 'epoch': 2.67}
{'loss': 0.0987, 'grad_norm': 20.724353790283203, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.09357249736785889, 'loss_2': 0.0051727294921875, 'loss_3': -15.637252807617188, 'loss_4': 1.4231832027435303, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 15:30:33,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:33,929 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:46<1:21:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:41,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02771943435072899, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01926344260573387, 'eval_loss_2': 0.008455991744995117, 'eval_loss_3': -18.109577178955078, 'eval_loss_4': 1.078255534172058, 'epoch': 2.67}
{'loss': 0.0399, 'grad_norm': 8.621569633483887, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.03521723672747612, 'loss_2': 0.00472259521484375, 'loss_3': -15.692657470703125, 'loss_4': 1.1047768592834473, 'epoch': 2.68}
{'loss': 0.0841, 'grad_norm': 20.594755172729492, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.06831343472003937, 'loss_2': 0.0157623291015625, 'loss_3': -15.570108413696289, 'loss_4': 1.1295907497406006, 'epoch': 2.69}
{'loss': 0.0395, 'grad_norm': 7.059774875640869, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.025849903002381325, 'loss_2': 0.013671875, 'loss_3': -15.758694648742676, 'loss_4': 0.7709949016571045, 'epoch': 2.69}
{'loss': 0.1569, 'grad_norm': 39.73544692993164, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.1363324373960495, 'loss_2': 0.0205535888671875, 'loss_3': -15.37418270111084, 'loss_4': 1.6105694770812988, 'epoch': 2.7}
{'loss': 0.087, 'grad_norm': 25.20296287536621, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.07477425038814545, 'loss_2': 0.0122222900390625, 'loss_3': -15.660731315612793, 'loss_4': 1.2958834171295166, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 15:30:41,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:41,283 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:54<1:21:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:48,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03244578093290329, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.021621575579047203, 'eval_loss_2': 0.010824203491210938, 'eval_loss_3': -18.117353439331055, 'eval_loss_4': 1.2441896200180054, 'epoch': 2.7}
{'loss': 0.0215, 'grad_norm': 6.975281238555908, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.018942711874842644, 'loss_2': 0.00260162353515625, 'loss_3': -15.62333869934082, 'loss_4': 1.0732245445251465, 'epoch': 2.71}
{'loss': 0.0385, 'grad_norm': 11.282470703125, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.030992208048701286, 'loss_2': 0.0074920654296875, 'loss_3': -15.361328125, 'loss_4': 1.6276164054870605, 'epoch': 2.72}
{'loss': 0.0575, 'grad_norm': 18.611656188964844, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.054863881319761276, 'loss_2': 0.0026340484619140625, 'loss_3': -15.44837760925293, 'loss_4': 0.9736634492874146, 'epoch': 2.72}
{'loss': 0.0804, 'grad_norm': 21.291988372802734, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.0755569264292717, 'loss_2': 0.00479888916015625, 'loss_3': -15.490701675415039, 'loss_4': 1.1880528926849365, 'epoch': 2.73}
{'loss': 0.0386, 'grad_norm': 8.900367736816406, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.0327669121325016, 'loss_2': 0.005859375, 'loss_3': -15.68144416809082, 'loss_4': 1.2135356664657593, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 15:30:48,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:48,628 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:01<1:20:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:55,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025675715878605843, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019164979457855225, 'eval_loss_2': 0.006510734558105469, 'eval_loss_3': -18.084177017211914, 'eval_loss_4': 1.2412832975387573, 'epoch': 2.73}
{'loss': 0.0898, 'grad_norm': 20.3498477935791, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.07855325192213058, 'loss_2': 0.0112152099609375, 'loss_3': -15.282012939453125, 'loss_4': 1.192808747291565, 'epoch': 2.74}
{'loss': 0.0389, 'grad_norm': 10.622635841369629, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.036650028079748154, 'loss_2': 0.002285003662109375, 'loss_3': -15.578710556030273, 'loss_4': 1.308161735534668, 'epoch': 2.74}
{'loss': 0.0392, 'grad_norm': 11.225616455078125, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.028128057718276978, 'loss_2': 0.0110931396484375, 'loss_3': -15.561186790466309, 'loss_4': 1.5068941116333008, 'epoch': 2.75}
{'loss': 0.0517, 'grad_norm': 14.743906021118164, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.048573050647974014, 'loss_2': 0.0031757354736328125, 'loss_3': -15.501100540161133, 'loss_4': 0.879051685333252, 'epoch': 2.76}
{'loss': 0.1143, 'grad_norm': 28.371225357055664, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.11409422010183334, 'loss_2': 0.00017547607421875, 'loss_3': -15.137876510620117, 'loss_4': 1.3449170589447021, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 15:30:55,970 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:55,970 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:05<1:20:59,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:30:59,775 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475
[INFO|configuration_utils.py:420] 2025-01-21 15:30:59,777 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475/config.json                                                                             
{'eval_loss': 0.018740836530923843, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.174, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01605144701898098, 'eval_loss_2': 0.0026893913745880127, 'eval_loss_3': -18.071918487548828, 'eval_loss_4': 1.374160885810852, 'epoch': 2.76}
[INFO|modeling_utils.py:2988] 2025-01-21 15:31:00,234 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:31:00,235 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:31:00,235 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:31:01,024 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-350] due to args.save_total_limit
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:10<1:28:32,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:31:04,659 >>
{'loss': 0.0714, 'grad_norm': 28.449907302856445, 'learning_rate': 2.725e-05, 'loss_1': 0.07048448920249939, 'loss_2': 0.0009527206420898438, 'loss_3': -15.53420639038086, 'loss_4': 1.2475554943084717, 'epoch': 2.77}
{'loss': 0.0838, 'grad_norm': 16.9960994720459, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.07368545979261398, 'loss_2': 0.01007080078125, 'loss_3': -15.245108604431152, 'loss_4': 1.6288186311721802, 'epoch': 2.77}
{'loss': 0.0496, 'grad_norm': 10.220627784729004, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.04252146556973457, 'loss_2': 0.007099151611328125, 'loss_3': -15.345383644104004, 'loss_4': 1.4325675964355469, 'epoch': 2.78}
{'loss': 0.0417, 'grad_norm': 14.505409240722656, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.03756788745522499, 'loss_2': 0.004180908203125, 'loss_3': -15.321966171264648, 'loss_4': 1.5952664613723755, 'epoch': 2.78}
{'loss': 0.0489, 'grad_norm': 20.697864532470703, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.045026976615190506, 'loss_2': 0.00390625, 'loss_3': -15.210553169250488, 'loss_4': 1.1005213260650635, 'epoch': 2.79}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:31:04,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:04,660 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:17<1:22:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:31:12,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021865978837013245, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015735939145088196, 'eval_loss_2': 0.006130039691925049, 'eval_loss_3': -18.094573974609375, 'eval_loss_4': 1.346267819404602, 'epoch': 2.79}
{'loss': 0.064, 'grad_norm': 20.080013275146484, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.06368573755025864, 'loss_2': 0.0002689361572265625, 'loss_3': -15.27866268157959, 'loss_4': 1.3791964054107666, 'epoch': 2.8}
{'loss': 0.0669, 'grad_norm': 28.719348907470703, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.06562381982803345, 'loss_2': 0.001270294189453125, 'loss_3': -15.436822891235352, 'loss_4': 1.9327366352081299, 'epoch': 2.8}
{'loss': 0.0319, 'grad_norm': 10.276309967041016, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.027652733027935028, 'loss_2': 0.00421905517578125, 'loss_3': -15.322957038879395, 'loss_4': 1.4924845695495605, 'epoch': 2.81}
{'loss': 0.1228, 'grad_norm': 19.114702224731445, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.1142214760184288, 'loss_2': 0.0085906982421875, 'loss_3': -15.359016418457031, 'loss_4': 1.6247766017913818, 'epoch': 2.81}
{'loss': 0.0602, 'grad_norm': 18.29335594177246, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.059327978640794754, 'loss_2': 0.0008792877197265625, 'loss_3': -15.140592575073242, 'loss_4': 1.1075159311294556, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 15:31:12,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:12,003 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:24<1:20:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:19,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02255113050341606, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014954132959246635, 'eval_loss_2': 0.007596999406814575, 'eval_loss_3': -18.094507217407227, 'eval_loss_4': 1.1221970319747925, 'epoch': 2.82}
{'loss': 0.0245, 'grad_norm': 8.835314750671387, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.024279970675706863, 'loss_2': 0.00026988983154296875, 'loss_3': -15.365947723388672, 'loss_4': 1.2936172485351562, 'epoch': 2.83}
{'loss': 0.0642, 'grad_norm': 20.41720962524414, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.05829545482993126, 'loss_2': 0.005931854248046875, 'loss_3': -15.239496231079102, 'loss_4': 0.7701889276504517, 'epoch': 2.83}
{'loss': 0.0187, 'grad_norm': 6.6015944480896, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.017889371141791344, 'loss_2': 0.0007791519165039062, 'loss_3': -15.370348930358887, 'loss_4': 0.7445889115333557, 'epoch': 2.84}
{'loss': 0.0422, 'grad_norm': 13.424467086791992, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.042062144726514816, 'loss_2': 0.00016570091247558594, 'loss_3': -15.165509223937988, 'loss_4': 0.8791139721870422, 'epoch': 2.84}
{'loss': 0.0357, 'grad_norm': 10.3389253616333, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.027491465210914612, 'loss_2': 0.0082244873046875, 'loss_3': -15.50465202331543, 'loss_4': 1.2274349927902222, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 15:31:19,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:19,346 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:32<1:20:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:26,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026773445308208466, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02236033044755459, 'eval_loss_2': 0.004413112998008728, 'eval_loss_3': -18.067893981933594, 'eval_loss_4': 1.1073576211929321, 'epoch': 2.85}
{'loss': 0.0367, 'grad_norm': 15.603387832641602, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.033868562430143356, 'loss_2': 0.002796173095703125, 'loss_3': -15.45284652709961, 'loss_4': 0.8217793107032776, 'epoch': 2.85}
{'loss': 0.0318, 'grad_norm': 14.157294273376465, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.03032401017844677, 'loss_2': 0.0014944076538085938, 'loss_3': -15.35452651977539, 'loss_4': 0.7641403079032898, 'epoch': 2.86}
{'loss': 0.1056, 'grad_norm': 27.156349182128906, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.1046065092086792, 'loss_2': 0.0009593963623046875, 'loss_3': -15.53699779510498, 'loss_4': 1.324681043624878, 'epoch': 2.87}
{'loss': 0.0514, 'grad_norm': 25.323829650878906, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.05044049397110939, 'loss_2': 0.0009508132934570312, 'loss_3': -15.483284950256348, 'loss_4': 0.7630121111869812, 'epoch': 2.87}
{'loss': 0.0316, 'grad_norm': 9.178285598754883, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.02831616811454296, 'loss_2': 0.003238677978515625, 'loss_3': -15.187297821044922, 'loss_4': 1.2086241245269775, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 15:31:26,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:26,689 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:39<1:20:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:34,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032648421823978424, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02952767349779606, 'eval_loss_2': 0.0031207501888275146, 'eval_loss_3': -18.10733413696289, 'eval_loss_4': 1.167978048324585, 'epoch': 2.88}
{'loss': 0.0529, 'grad_norm': 13.498826026916504, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.047933027148246765, 'loss_2': 0.004974365234375, 'loss_3': -15.323184967041016, 'loss_4': 0.6738024353981018, 'epoch': 2.88}
{'loss': 0.0522, 'grad_norm': 17.741107940673828, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.046601004898548126, 'loss_2': 0.005573272705078125, 'loss_3': -15.151121139526367, 'loss_4': 1.2820210456848145, 'epoch': 2.89}
{'loss': 0.0541, 'grad_norm': 16.85411262512207, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.05364938825368881, 'loss_2': 0.0004138946533203125, 'loss_3': -15.388644218444824, 'loss_4': 1.2854046821594238, 'epoch': 2.9}
{'loss': 0.067, 'grad_norm': 18.973907470703125, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.057246383279561996, 'loss_2': 0.009735107421875, 'loss_3': -15.432394981384277, 'loss_4': 1.4308578968048096, 'epoch': 2.9}
{'loss': 0.073, 'grad_norm': 18.044893264770508, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.05954931303858757, 'loss_2': 0.01340484619140625, 'loss_3': -15.596725463867188, 'loss_4': 1.4261415004730225, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 15:31:34,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:34,038 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:46<1:20:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:41,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03448735550045967, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.025179972872138023, 'eval_loss_2': 0.009307384490966797, 'eval_loss_3': -18.156005859375, 'eval_loss_4': 1.3861732482910156, 'epoch': 2.91}
{'loss': 0.0484, 'grad_norm': 13.619071960449219, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.03705970570445061, 'loss_2': 0.01134490966796875, 'loss_3': -15.451955795288086, 'loss_4': 1.3002946376800537, 'epoch': 2.91}
{'loss': 0.0739, 'grad_norm': 22.89211082458496, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.06071986258029938, 'loss_2': 0.01318359375, 'loss_3': -15.24691390991211, 'loss_4': 1.0189193487167358, 'epoch': 2.92}
{'loss': 0.0534, 'grad_norm': 12.607864379882812, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.04474101960659027, 'loss_2': 0.008636474609375, 'loss_3': -15.55649471282959, 'loss_4': 1.114475965499878, 'epoch': 2.92}
{'loss': 0.0551, 'grad_norm': 16.776901245117188, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.05134599655866623, 'loss_2': 0.003711700439453125, 'loss_3': -15.531596183776855, 'loss_4': 1.371720552444458, 'epoch': 2.93}
{'loss': 0.0373, 'grad_norm': 7.895198822021484, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.03308241069316864, 'loss_2': 0.0041961669921875, 'loss_3': -15.450668334960938, 'loss_4': 1.4082574844360352, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 15:31:41,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:41,379 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [12:54<1:20:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:48,720 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028169900178909302, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.022837433964014053, 'eval_loss_2': 0.005332469940185547, 'eval_loss_3': -18.171653747558594, 'eval_loss_4': 1.4412705898284912, 'epoch': 2.94}
{'loss': 0.0745, 'grad_norm': 15.808830261230469, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.06504468619823456, 'loss_2': 0.009429931640625, 'loss_3': -15.42976188659668, 'loss_4': 1.3775157928466797, 'epoch': 2.94}
{'loss': 0.0626, 'grad_norm': 19.45028305053711, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.06046008691191673, 'loss_2': 0.0021820068359375, 'loss_3': -15.388862609863281, 'loss_4': 1.4568192958831787, 'epoch': 2.95}
{'loss': 0.1461, 'grad_norm': 31.830007553100586, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.14175748825073242, 'loss_2': 0.00435638427734375, 'loss_3': -15.273679733276367, 'loss_4': 1.2172528505325317, 'epoch': 2.95}
{'loss': 0.0462, 'grad_norm': 12.364279747009277, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.042402975261211395, 'loss_2': 0.003765106201171875, 'loss_3': -15.351154327392578, 'loss_4': 0.9256840348243713, 'epoch': 2.96}
{'loss': 0.0875, 'grad_norm': 25.90757179260254, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.08385315537452698, 'loss_2': 0.0036468505859375, 'loss_3': -15.415870666503906, 'loss_4': 1.5777932405471802, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 15:31:48,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:48,720 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:01<1:19:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:31:56,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02502559870481491, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.663, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.02154393494129181, 'eval_loss_2': 0.003481663763523102, 'eval_loss_3': -18.184778213500977, 'eval_loss_4': 1.4040369987487793, 'epoch': 2.97}
{'loss': 0.0493, 'grad_norm': 13.739362716674805, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.04185618460178375, 'loss_2': 0.0074615478515625, 'loss_3': -15.349340438842773, 'loss_4': 1.1078182458877563, 'epoch': 2.97}
{'loss': 0.031, 'grad_norm': 8.795201301574707, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.02908613160252571, 'loss_2': 0.00189208984375, 'loss_3': -15.581859588623047, 'loss_4': 1.102452278137207, 'epoch': 2.98}
{'loss': 0.0809, 'grad_norm': 16.586225509643555, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.08052825927734375, 'loss_2': 0.00042057037353515625, 'loss_3': -15.587234497070312, 'loss_4': 2.017746686935425, 'epoch': 2.98}
{'loss': 0.0652, 'grad_norm': 16.286766052246094, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.06441500782966614, 'loss_2': 0.0007982254028320312, 'loss_3': -15.489694595336914, 'loss_4': 1.3608323335647583, 'epoch': 2.99}
{'loss': 0.078, 'grad_norm': 31.467531204223633, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.07748303562402725, 'loss_2': 0.00047659873962402344, 'loss_3': -15.63684368133545, 'loss_4': 1.830176591873169, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 15:31:56,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:56,055 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:08<1:18:40,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:32:03,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03241812437772751, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02821122482419014, 'eval_loss_2': 0.00420689582824707, 'eval_loss_3': -18.188812255859375, 'eval_loss_4': 1.6533761024475098, 'epoch': 2.99}
{'loss': 0.0382, 'grad_norm': 25.262845993041992, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.029429880902171135, 'loss_2': 0.0087432861328125, 'loss_3': -15.743210792541504, 'loss_4': 1.9648597240447998, 'epoch': 3.0}
{'loss': 0.0281, 'grad_norm': 7.390363693237305, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.024697398766875267, 'loss_2': 0.003448486328125, 'loss_3': -15.45942497253418, 'loss_4': 1.7210209369659424, 'epoch': 3.01}
{'loss': 0.0741, 'grad_norm': 27.368000030517578, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.0697813332080841, 'loss_2': 0.004306793212890625, 'loss_3': -15.389521598815918, 'loss_4': 1.9659929275512695, 'epoch': 3.01}
{'loss': 0.0647, 'grad_norm': 14.243365287780762, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.06305181980133057, 'loss_2': 0.001697540283203125, 'loss_3': -15.435147285461426, 'loss_4': 1.845216155052185, 'epoch': 3.02}
{'loss': 0.0759, 'grad_norm': 15.281512260437012, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.06306931376457214, 'loss_2': 0.0128326416015625, 'loss_3': -15.582564353942871, 'loss_4': 1.928283452987671, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 15:32:03,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:03,109 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:15<1:19:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:32:10,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09271252900362015, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.08635101467370987, 'eval_loss_2': 0.006361514329910278, 'eval_loss_3': -18.061004638671875, 'eval_loss_4': 2.5175857543945312, 'epoch': 3.02}
{'loss': 0.0937, 'grad_norm': 18.732093811035156, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.09033163636922836, 'loss_2': 0.0033855438232421875, 'loss_3': -15.4835844039917, 'loss_4': 2.3041911125183105, 'epoch': 3.03}
{'loss': 0.0893, 'grad_norm': 22.27312469482422, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.08735094219446182, 'loss_2': 0.001983642578125, 'loss_3': -15.57231330871582, 'loss_4': 2.591003894805908, 'epoch': 3.03}
{'loss': 0.1657, 'grad_norm': 25.142316818237305, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.15263232588768005, 'loss_2': 0.0130767822265625, 'loss_3': -15.582796096801758, 'loss_4': 2.6888346672058105, 'epoch': 3.04}
{'loss': 0.0529, 'grad_norm': 12.533186912536621, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.04550856351852417, 'loss_2': 0.007389068603515625, 'loss_3': -15.653749465942383, 'loss_4': 2.847904682159424, 'epoch': 3.05}
{'loss': 0.168, 'grad_norm': 30.198760986328125, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.16322281956672668, 'loss_2': 0.0048065185546875, 'loss_3': -15.302871704101562, 'loss_4': 2.983090877532959, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 15:32:10,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:10,454 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:23<1:20:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:17,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08262377232313156, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.07786064594984055, 'eval_loss_2': 0.004763126373291016, 'eval_loss_3': -18.081623077392578, 'eval_loss_4': 2.7921829223632812, 'epoch': 3.05}
{'loss': 0.1031, 'grad_norm': 20.082406997680664, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.09682778269052505, 'loss_2': 0.0063018798828125, 'loss_3': -15.346254348754883, 'loss_4': 2.512272834777832, 'epoch': 3.06}
{'loss': 0.0518, 'grad_norm': 11.845954895019531, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.04678478091955185, 'loss_2': 0.00496673583984375, 'loss_3': -15.563108444213867, 'loss_4': 2.9409680366516113, 'epoch': 3.06}
{'loss': 0.1719, 'grad_norm': 28.238189697265625, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.1716216653585434, 'loss_2': 0.0002989768981933594, 'loss_3': -15.50993824005127, 'loss_4': 2.4606049060821533, 'epoch': 3.07}
{'loss': 0.0495, 'grad_norm': 10.897265434265137, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.04672163352370262, 'loss_2': 0.002765655517578125, 'loss_3': -15.495096206665039, 'loss_4': 2.74981689453125, 'epoch': 3.08}
{'loss': 0.0623, 'grad_norm': 14.30380630493164, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.05536316707730293, 'loss_2': 0.0069122314453125, 'loss_3': -15.77009391784668, 'loss_4': 2.7346649169921875, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 15:32:17,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:17,812 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:30<1:20:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:25,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0365145243704319, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03221726790070534, 'eval_loss_2': 0.0042972564697265625, 'eval_loss_3': -18.20035743713379, 'eval_loss_4': 2.510740280151367, 'epoch': 3.08}
{'loss': 0.1127, 'grad_norm': 30.566957473754883, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.10625137388706207, 'loss_2': 0.00643157958984375, 'loss_3': -15.606805801391602, 'loss_4': 3.1723296642303467, 'epoch': 3.09}
{'loss': 0.0408, 'grad_norm': 15.284750938415527, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.04043402895331383, 'loss_2': 0.0003998279571533203, 'loss_3': -15.675400733947754, 'loss_4': 2.7388689517974854, 'epoch': 3.09}
{'loss': 0.0722, 'grad_norm': 16.786991119384766, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.06690820306539536, 'loss_2': 0.0052490234375, 'loss_3': -15.488792419433594, 'loss_4': 2.1947593688964844, 'epoch': 3.1}
{'loss': 0.0365, 'grad_norm': 10.87244701385498, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.03511221334338188, 'loss_2': 0.0013494491577148438, 'loss_3': -15.632332801818848, 'loss_4': 2.6590940952301025, 'epoch': 3.1}
{'loss': 0.0338, 'grad_norm': 10.647991180419922, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.031798746436834335, 'loss_2': 0.001964569091796875, 'loss_3': -15.645543098449707, 'loss_4': 2.633301019668579, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 15:32:25,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:25,160 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:37<1:20:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:32,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03321211040019989, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.029061902314424515, 'eval_loss_2': 0.004150211811065674, 'eval_loss_3': -18.21616554260254, 'eval_loss_4': 2.7979671955108643, 'epoch': 3.11}
{'loss': 0.1389, 'grad_norm': 50.64193344116211, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.1356962025165558, 'loss_2': 0.0031833648681640625, 'loss_3': -15.554834365844727, 'loss_4': 3.1440629959106445, 'epoch': 3.12}
{'loss': 0.0453, 'grad_norm': 15.735852241516113, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.03838115930557251, 'loss_2': 0.006893157958984375, 'loss_3': -15.707876205444336, 'loss_4': 2.4975790977478027, 'epoch': 3.12}
{'loss': 0.1471, 'grad_norm': 18.605731964111328, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.14315758645534515, 'loss_2': 0.003936767578125, 'loss_3': -15.555257797241211, 'loss_4': 3.150787830352783, 'epoch': 3.13}
{'loss': 0.0559, 'grad_norm': 13.682723045349121, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.04390673339366913, 'loss_2': 0.0119781494140625, 'loss_3': -15.70087718963623, 'loss_4': 3.323049783706665, 'epoch': 3.13}
{'loss': 0.0626, 'grad_norm': 17.461139678955078, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.05859499052166939, 'loss_2': 0.00403594970703125, 'loss_3': -15.773347854614258, 'loss_4': 2.970754384994507, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 15:32:32,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:32,527 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:45<1:19:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:39,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027668580412864685, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02134643867611885, 'eval_loss_2': 0.006322145462036133, 'eval_loss_3': -18.252513885498047, 'eval_loss_4': 2.9611339569091797, 'epoch': 3.14}
{'loss': 0.0467, 'grad_norm': 14.214427947998047, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.04557253047823906, 'loss_2': 0.0011043548583984375, 'loss_3': -15.838726997375488, 'loss_4': 3.18510103225708, 'epoch': 3.15}
{'loss': 0.0497, 'grad_norm': 10.68909740447998, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.04365098103880882, 'loss_2': 0.0060577392578125, 'loss_3': -15.829058647155762, 'loss_4': 3.540184497833252, 'epoch': 3.15}
{'loss': 0.0485, 'grad_norm': 9.930511474609375, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.038148023188114166, 'loss_2': 0.010345458984375, 'loss_3': -15.628646850585938, 'loss_4': 3.2513413429260254, 'epoch': 3.16}
{'loss': 0.0547, 'grad_norm': 15.153027534484863, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.042866289615631104, 'loss_2': 0.01181793212890625, 'loss_3': -15.4970703125, 'loss_4': 2.8475189208984375, 'epoch': 3.16}
{'loss': 0.0368, 'grad_norm': 11.653904914855957, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.029059795662760735, 'loss_2': 0.007781982421875, 'loss_3': -15.622980117797852, 'loss_4': 2.5123369693756104, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 15:32:39,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:39,880 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:52<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:47,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021892353892326355, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.449, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01799663156270981, 'eval_loss_2': 0.0038957223296165466, 'eval_loss_3': -18.22136688232422, 'eval_loss_4': 2.4249165058135986, 'epoch': 3.17}
{'loss': 0.0514, 'grad_norm': 16.360795974731445, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.04186846315860748, 'loss_2': 0.009521484375, 'loss_3': -15.607793807983398, 'loss_4': 2.2629318237304688, 'epoch': 3.17}
{'loss': 0.0458, 'grad_norm': 9.8063383102417, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.03985140845179558, 'loss_2': 0.0059814453125, 'loss_3': -15.677592277526855, 'loss_4': 1.9531755447387695, 'epoch': 3.18}
{'loss': 0.0434, 'grad_norm': 10.514309883117676, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.0407913401722908, 'loss_2': 0.002605438232421875, 'loss_3': -15.211084365844727, 'loss_4': 2.053199529647827, 'epoch': 3.19}
{'loss': 0.0326, 'grad_norm': 8.67678451538086, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.027283912524580956, 'loss_2': 0.00536346435546875, 'loss_3': -15.697426795959473, 'loss_4': 2.463136672973633, 'epoch': 3.19}
{'loss': 0.0858, 'grad_norm': 20.579357147216797, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.08508926630020142, 'loss_2': 0.0007371902465820312, 'loss_3': -15.883434295654297, 'loss_4': 2.3233838081359863, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 15:32:47,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:47,235 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [13:59<1:19:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:54,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0371185764670372, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.027857210487127304, 'eval_loss_2': 0.009261369705200195, 'eval_loss_3': -18.176515579223633, 'eval_loss_4': 2.115032434463501, 'epoch': 3.2}
{'loss': 0.056, 'grad_norm': 16.865867614746094, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.05183221399784088, 'loss_2': 0.0041656494140625, 'loss_3': -15.69826889038086, 'loss_4': 2.442591667175293, 'epoch': 3.2}
{'loss': 0.0515, 'grad_norm': 10.058038711547852, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.03966426104307175, 'loss_2': 0.01183319091796875, 'loss_3': -15.716838836669922, 'loss_4': 2.208120822906494, 'epoch': 3.21}
{'loss': 0.0381, 'grad_norm': 7.464786052703857, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.024530567228794098, 'loss_2': 0.01352691650390625, 'loss_3': -15.675570487976074, 'loss_4': 1.6302134990692139, 'epoch': 3.22}
{'loss': 0.0755, 'grad_norm': 21.942331314086914, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.0709676519036293, 'loss_2': 0.004547119140625, 'loss_3': -15.744866371154785, 'loss_4': 1.7931311130523682, 'epoch': 3.22}
{'loss': 0.0366, 'grad_norm': 11.254134178161621, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.03638628125190735, 'loss_2': 0.0001857280731201172, 'loss_3': -15.699529647827148, 'loss_4': 1.6136589050292969, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 15:32:54,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:54,579 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:07<1:19:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:01,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04392597824335098, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.03940114751458168, 'eval_loss_2': 0.004524827003479004, 'eval_loss_3': -18.125633239746094, 'eval_loss_4': 1.6989927291870117, 'epoch': 3.23}
{'loss': 0.06, 'grad_norm': 23.311796188354492, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.059323154389858246, 'loss_2': 0.0006465911865234375, 'loss_3': -15.691503524780273, 'loss_4': 2.096588134765625, 'epoch': 3.23}
{'loss': 0.0428, 'grad_norm': 14.034122467041016, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.03754137456417084, 'loss_2': 0.005245208740234375, 'loss_3': -15.528389930725098, 'loss_4': 1.7066859006881714, 'epoch': 3.24}
{'loss': 0.0812, 'grad_norm': 16.780458450317383, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.07820876687765121, 'loss_2': 0.003021240234375, 'loss_3': -15.504669189453125, 'loss_4': 1.4411802291870117, 'epoch': 3.24}
{'loss': 0.0427, 'grad_norm': 10.893182754516602, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.03709966316819191, 'loss_2': 0.005550384521484375, 'loss_3': -15.543991088867188, 'loss_4': 1.2936351299285889, 'epoch': 3.25}
{'loss': 0.0145, 'grad_norm': 7.067050457000732, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.014046050608158112, 'loss_2': 0.0004563331604003906, 'loss_3': -15.58670425415039, 'loss_4': 1.1522455215454102, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 15:33:01,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:01,936 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:14<1:19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:09,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04527068883180618, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.257, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.041360534727573395, 'eval_loss_2': 0.003910154104232788, 'eval_loss_3': -18.09947395324707, 'eval_loss_4': 1.1332333087921143, 'epoch': 3.26}
{'loss': 0.0359, 'grad_norm': 9.775415420532227, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.03330887854099274, 'loss_2': 0.00263214111328125, 'loss_3': -15.564460754394531, 'loss_4': 1.1445108652114868, 'epoch': 3.26}
{'loss': 0.035, 'grad_norm': 14.613180160522461, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.03278559446334839, 'loss_2': 0.002208709716796875, 'loss_3': -15.671960830688477, 'loss_4': 1.2728912830352783, 'epoch': 3.27}
{'loss': 0.0351, 'grad_norm': 8.00219440460205, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.024974260479211807, 'loss_2': 0.010162353515625, 'loss_3': -15.682565689086914, 'loss_4': 0.9250057339668274, 'epoch': 3.27}
{'loss': 0.0418, 'grad_norm': 16.867219924926758, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.03384323790669441, 'loss_2': 0.0079193115234375, 'loss_3': -15.684942245483398, 'loss_4': 1.0957963466644287, 'epoch': 3.28}
{'loss': 0.0294, 'grad_norm': 8.744604110717773, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.02526305615901947, 'loss_2': 0.00411224365234375, 'loss_3': -15.36722183227539, 'loss_4': 0.7159064412117004, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 15:33:09,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:09,289 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:22<1:19:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:16,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04439704120159149, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.041163068264722824, 'eval_loss_2': 0.003233976662158966, 'eval_loss_3': -18.089553833007812, 'eval_loss_4': 0.8540463447570801, 'epoch': 3.28}
{'loss': 0.0361, 'grad_norm': 10.66833209991455, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.03263796493411064, 'loss_2': 0.003482818603515625, 'loss_3': -15.566818237304688, 'loss_4': 0.8367809653282166, 'epoch': 3.29}
{'loss': 0.0618, 'grad_norm': 13.015563011169434, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.05546265468001366, 'loss_2': 0.006378173828125, 'loss_3': -15.587177276611328, 'loss_4': 0.9001544117927551, 'epoch': 3.3}
{'loss': 0.0196, 'grad_norm': 8.508380889892578, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.018566085025668144, 'loss_2': 0.001041412353515625, 'loss_3': -15.49544906616211, 'loss_4': 0.5664811134338379, 'epoch': 3.3}
{'loss': 0.0363, 'grad_norm': 11.45617961883545, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.03380227088928223, 'loss_2': 0.00249481201171875, 'loss_3': -15.713735580444336, 'loss_4': 0.6238322854042053, 'epoch': 3.31}
{'loss': 0.0518, 'grad_norm': 17.821453094482422, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.04867081716656685, 'loss_2': 0.003131866455078125, 'loss_3': -15.572916030883789, 'loss_4': 0.7925296425819397, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 15:33:16,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:16,646 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:29<1:19:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:23,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03124704211950302, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.028620338067412376, 'eval_loss_2': 0.0026267021894454956, 'eval_loss_3': -18.141159057617188, 'eval_loss_4': 0.6404268741607666, 'epoch': 3.31}
{'loss': 0.0301, 'grad_norm': 9.134429931640625, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.023053891956806183, 'loss_2': 0.0070037841796875, 'loss_3': -15.509486198425293, 'loss_4': 0.2915607690811157, 'epoch': 3.32}
{'loss': 0.0242, 'grad_norm': 8.555276870727539, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.022574767470359802, 'loss_2': 0.0016345977783203125, 'loss_3': -15.699838638305664, 'loss_4': 0.33548885583877563, 'epoch': 3.33}
{'loss': 0.019, 'grad_norm': 6.100747108459473, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.015438403002917767, 'loss_2': 0.00360107421875, 'loss_3': -15.637335777282715, 'loss_4': 0.38747644424438477, 'epoch': 3.33}
{'loss': 0.051, 'grad_norm': 17.725343704223633, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.0424591489136219, 'loss_2': 0.008514404296875, 'loss_3': -15.686517715454102, 'loss_4': 0.1989438831806183, 'epoch': 3.34}
{'loss': 0.1009, 'grad_norm': 15.818424224853516, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.09113919734954834, 'loss_2': 0.009735107421875, 'loss_3': -15.84593391418457, 'loss_4': 0.413208544254303, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 15:33:23,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:23,994 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:36<1:19:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:31,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028274882584810257, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.023879684507846832, 'eval_loss_2': 0.004395201802253723, 'eval_loss_3': -18.185684204101562, 'eval_loss_4': 0.38692647218704224, 'epoch': 3.34}
{'loss': 0.0574, 'grad_norm': 16.909162521362305, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.05206426605582237, 'loss_2': 0.00530242919921875, 'loss_3': -15.617935180664062, 'loss_4': 0.415566086769104, 'epoch': 3.35}
{'loss': 0.0317, 'grad_norm': 9.337738990783691, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.025679055601358414, 'loss_2': 0.0059967041015625, 'loss_3': -15.568733215332031, 'loss_4': 0.07593022286891937, 'epoch': 3.35}
{'loss': 0.0296, 'grad_norm': 7.362445831298828, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.027651453390717506, 'loss_2': 0.0019321441650390625, 'loss_3': -15.745002746582031, 'loss_4': 0.38010174036026, 'epoch': 3.36}
{'loss': 0.0835, 'grad_norm': 31.265398025512695, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.07802858203649521, 'loss_2': 0.0055084228515625, 'loss_3': -15.639846801757812, 'loss_4': 0.3755069971084595, 'epoch': 3.37}
{'loss': 0.1314, 'grad_norm': 25.40119171142578, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.13049933314323425, 'loss_2': 0.0009450912475585938, 'loss_3': -15.623716354370117, 'loss_4': 0.7572869062423706, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 15:33:31,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:31,339 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:44<1:19:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:38,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035949788987636566, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.025330623611807823, 'eval_loss_2': 0.010619163513183594, 'eval_loss_3': -18.225948333740234, 'eval_loss_4': 0.36318111419677734, 'epoch': 3.37}
{'loss': 0.0662, 'grad_norm': 16.472545623779297, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.05535364896059036, 'loss_2': 0.01087188720703125, 'loss_3': -15.96854019165039, 'loss_4': 0.4340397119522095, 'epoch': 3.38}
{'loss': 0.1196, 'grad_norm': 33.117454528808594, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.11174481362104416, 'loss_2': 0.007843017578125, 'loss_3': -15.912267684936523, 'loss_4': 0.49097132682800293, 'epoch': 3.38}
{'loss': 0.1058, 'grad_norm': 25.01395606994629, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.0914572924375534, 'loss_2': 0.0143890380859375, 'loss_3': -15.600324630737305, 'loss_4': 0.09425400197505951, 'epoch': 3.39}
{'loss': 0.0581, 'grad_norm': 9.99638843536377, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.03594319894909859, 'loss_2': 0.0221710205078125, 'loss_3': -15.872532844543457, 'loss_4': 0.22889328002929688, 'epoch': 3.4}
{'loss': 0.0674, 'grad_norm': 18.930706024169922, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.05649278685450554, 'loss_2': 0.0108642578125, 'loss_3': -15.964509010314941, 'loss_4': 0.42542600631713867, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 15:33:38,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:38,684 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:51<1:19:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:46,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03345135599374771, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.027234116569161415, 'eval_loss_2': 0.006217241287231445, 'eval_loss_3': -18.286527633666992, 'eval_loss_4': 0.49579817056655884, 'epoch': 3.4}
{'loss': 0.0474, 'grad_norm': 11.798567771911621, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.04047694057226181, 'loss_2': 0.0068817138671875, 'loss_3': -15.83086109161377, 'loss_4': 0.3062548041343689, 'epoch': 3.41}
{'loss': 0.0444, 'grad_norm': 10.239788055419922, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.039671242237091064, 'loss_2': 0.004730224609375, 'loss_3': -16.040180206298828, 'loss_4': 0.8376293778419495, 'epoch': 3.41}
{'loss': 0.0476, 'grad_norm': 9.281604766845703, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.045544009655714035, 'loss_2': 0.002010345458984375, 'loss_3': -15.838878631591797, 'loss_4': 0.4887627363204956, 'epoch': 3.42}
{'loss': 0.1172, 'grad_norm': 20.446243286132812, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.11284928023815155, 'loss_2': 0.0043792724609375, 'loss_3': -15.845785140991211, 'loss_4': 0.9074832797050476, 'epoch': 3.42}
{'loss': 0.0364, 'grad_norm': 9.546189308166504, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.033786188811063766, 'loss_2': 0.0025653839111328125, 'loss_3': -15.797117233276367, 'loss_4': 0.5877121686935425, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 15:33:46,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:46,033 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [14:58<1:19:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:53,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029140077531337738, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.025041811168193817, 'eval_loss_2': 0.004098266363143921, 'eval_loss_3': -18.227325439453125, 'eval_loss_4': 0.7616081833839417, 'epoch': 3.43}
{'loss': 0.0838, 'grad_norm': 20.104154586791992, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.08124212175607681, 'loss_2': 0.002532958984375, 'loss_3': -15.884326934814453, 'loss_4': 0.5615224242210388, 'epoch': 3.44}
{'loss': 0.0569, 'grad_norm': 16.05217933654785, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.0550721101462841, 'loss_2': 0.0018739700317382812, 'loss_3': -15.817543029785156, 'loss_4': 0.7760082483291626, 'epoch': 3.44}
{'loss': 0.0489, 'grad_norm': 10.751776695251465, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.041690289974212646, 'loss_2': 0.007205963134765625, 'loss_3': -15.726832389831543, 'loss_4': 0.7679986953735352, 'epoch': 3.45}
{'loss': 0.0456, 'grad_norm': 11.899680137634277, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.04337640479207039, 'loss_2': 0.0022525787353515625, 'loss_3': -15.468189239501953, 'loss_4': 0.9481083154678345, 'epoch': 3.45}
{'loss': 0.0419, 'grad_norm': 19.22732925415039, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.03237293288111687, 'loss_2': 0.00957489013671875, 'loss_3': -15.685173034667969, 'loss_4': 0.8971541523933411, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 15:33:53,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:53,388 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:06<1:18:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:00,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029509326443076134, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02345692180097103, 'eval_loss_2': 0.0060524046421051025, 'eval_loss_3': -18.156084060668945, 'eval_loss_4': 1.0564464330673218, 'epoch': 3.46}
{'loss': 0.0394, 'grad_norm': 12.608034133911133, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.037867430597543716, 'loss_2': 0.0015392303466796875, 'loss_3': -15.589455604553223, 'loss_4': 0.7753996253013611, 'epoch': 3.47}
{'loss': 0.0194, 'grad_norm': 9.391387939453125, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.018365630879998207, 'loss_2': 0.0010814666748046875, 'loss_3': -15.802824020385742, 'loss_4': 1.1711711883544922, 'epoch': 3.47}
{'loss': 0.0431, 'grad_norm': 13.642796516418457, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.04033990204334259, 'loss_2': 0.0028076171875, 'loss_3': -15.553640365600586, 'loss_4': 1.196495532989502, 'epoch': 3.48}
{'loss': 0.0604, 'grad_norm': 18.695331573486328, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.05609511956572533, 'loss_2': 0.00433349609375, 'loss_3': -15.41666316986084, 'loss_4': 0.8999294638633728, 'epoch': 3.48}
{'loss': 0.0163, 'grad_norm': 5.591227054595947, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.014950516633689404, 'loss_2': 0.0013790130615234375, 'loss_3': -15.748188972473145, 'loss_4': 1.0310627222061157, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 15:34:00,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:00,742 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:13<1:18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:08,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03214283287525177, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.023783519864082336, 'eval_loss_2': 0.008359313011169434, 'eval_loss_3': -18.1024227142334, 'eval_loss_4': 1.2625590562820435, 'epoch': 3.49}
{'loss': 0.0171, 'grad_norm': 7.032407760620117, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.015883099287748337, 'loss_2': 0.0012035369873046875, 'loss_3': -15.703264236450195, 'loss_4': 1.0486290454864502, 'epoch': 3.49}
{'loss': 0.0325, 'grad_norm': 9.41877269744873, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.028268110007047653, 'loss_2': 0.004184722900390625, 'loss_3': -15.61427116394043, 'loss_4': 1.4317930936813354, 'epoch': 3.5}
{'loss': 0.0426, 'grad_norm': 13.47418212890625, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.03889982029795647, 'loss_2': 0.0036602020263671875, 'loss_3': -15.704191207885742, 'loss_4': 1.107539176940918, 'epoch': 3.51}
{'loss': 0.0296, 'grad_norm': 8.713404655456543, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.019928349182009697, 'loss_2': 0.0096588134765625, 'loss_3': -15.515181541442871, 'loss_4': 1.5783653259277344, 'epoch': 3.51}
{'loss': 0.0216, 'grad_norm': 11.002446174621582, 'learning_rate': 2.65e-05, 'loss_1': 0.018111329525709152, 'loss_2': 0.003452301025390625, 'loss_3': -15.543505668640137, 'loss_4': 1.3737295866012573, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 15:34:08,098 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:08,098 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:20<1:18:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:15,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026082519441843033, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.02191856876015663, 'eval_loss_2': 0.004163950681686401, 'eval_loss_3': -18.085954666137695, 'eval_loss_4': 1.5348612070083618, 'epoch': 3.52}
{'loss': 0.0189, 'grad_norm': 6.935724258422852, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.01731366105377674, 'loss_2': 0.0015697479248046875, 'loss_3': -15.597456932067871, 'loss_4': 1.6120997667312622, 'epoch': 3.52}
{'loss': 0.0363, 'grad_norm': 9.530255317687988, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.03005344234406948, 'loss_2': 0.0062255859375, 'loss_3': -15.781288146972656, 'loss_4': 1.5184907913208008, 'epoch': 3.53}
{'loss': 0.0348, 'grad_norm': 8.751367568969727, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.02872713841497898, 'loss_2': 0.006114959716796875, 'loss_3': -15.643746376037598, 'loss_4': 1.3512446880340576, 'epoch': 3.53}
{'loss': 0.0358, 'grad_norm': 10.061539649963379, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.028034895658493042, 'loss_2': 0.00780487060546875, 'loss_3': -15.629716873168945, 'loss_4': 1.766430139541626, 'epoch': 3.54}
{'loss': 0.1264, 'grad_norm': 25.66651153564453, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.11568586528301239, 'loss_2': 0.0106658935546875, 'loss_3': -15.645783424377441, 'loss_4': 1.5888614654541016, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 15:34:15,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:15,454 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:28<1:18:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:22,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019939318299293518, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015450865030288696, 'eval_loss_2': 0.004488453269004822, 'eval_loss_3': -18.164119720458984, 'eval_loss_4': 1.3165358304977417, 'epoch': 3.55}
{'loss': 0.0462, 'grad_norm': 17.768590927124023, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.038713857531547546, 'loss_2': 0.00746917724609375, 'loss_3': -15.799161911010742, 'loss_4': 1.6541321277618408, 'epoch': 3.55}
{'loss': 0.0532, 'grad_norm': 10.285910606384277, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.04592717066407204, 'loss_2': 0.007289886474609375, 'loss_3': -15.68559455871582, 'loss_4': 1.6947813034057617, 'epoch': 3.56}
{'loss': 0.0825, 'grad_norm': 25.14168357849121, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.07370401173830032, 'loss_2': 0.0088043212890625, 'loss_3': -15.75299072265625, 'loss_4': 1.5613770484924316, 'epoch': 3.56}
{'loss': 0.0706, 'grad_norm': 19.641124725341797, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.062446895986795425, 'loss_2': 0.00818634033203125, 'loss_3': -15.43631362915039, 'loss_4': 1.5346989631652832, 'epoch': 3.57}
{'loss': 0.0378, 'grad_norm': 11.215039253234863, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.032228659838438034, 'loss_2': 0.00557708740234375, 'loss_3': -15.867639541625977, 'loss_4': 2.2410671710968018, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 15:34:22,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:22,797 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:35<1:18:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:30,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021412331610918045, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.015342403203248978, 'eval_loss_2': 0.006069928407669067, 'eval_loss_3': -18.162322998046875, 'eval_loss_4': 1.3852355480194092, 'epoch': 3.58}
{'loss': 0.0324, 'grad_norm': 13.295592308044434, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.030369719490408897, 'loss_2': 0.001995086669921875, 'loss_3': -15.821922302246094, 'loss_4': 1.7250112295150757, 'epoch': 3.58}
{'loss': 0.0563, 'grad_norm': 24.02977752685547, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.04803672060370445, 'loss_2': 0.00823974609375, 'loss_3': -15.756376266479492, 'loss_4': 1.5704247951507568, 'epoch': 3.59}
{'loss': 0.0638, 'grad_norm': 18.548744201660156, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.06073342636227608, 'loss_2': 0.003078460693359375, 'loss_3': -15.559247970581055, 'loss_4': 1.6743077039718628, 'epoch': 3.59}
{'loss': 0.0478, 'grad_norm': 14.38228988647461, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.04478715732693672, 'loss_2': 0.003002166748046875, 'loss_3': -15.718461990356445, 'loss_4': 1.0925294160842896, 'epoch': 3.6}
{'loss': 0.0248, 'grad_norm': 7.187186241149902, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.02144213393330574, 'loss_2': 0.0033130645751953125, 'loss_3': -15.78438949584961, 'loss_4': 1.3288862705230713, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 15:34:30,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:30,151 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:42<1:18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:37,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026626795530319214, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.847, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01643657684326172, 'eval_loss_2': 0.010190218687057495, 'eval_loss_3': -18.122535705566406, 'eval_loss_4': 0.9690797328948975, 'epoch': 3.6}
{'loss': 0.0309, 'grad_norm': 12.656354904174805, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.027374356985092163, 'loss_2': 0.003498077392578125, 'loss_3': -15.69904899597168, 'loss_4': 1.015000581741333, 'epoch': 3.61}
{'loss': 0.0585, 'grad_norm': 22.134313583374023, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.0581803061068058, 'loss_2': 0.000339508056640625, 'loss_3': -15.631450653076172, 'loss_4': 1.261958360671997, 'epoch': 3.62}
{'loss': 0.0383, 'grad_norm': 8.349064826965332, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.02465091086924076, 'loss_2': 0.01366424560546875, 'loss_3': -15.699727058410645, 'loss_4': 0.9997541308403015, 'epoch': 3.62}
{'loss': 0.0792, 'grad_norm': 17.033203125, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.06636378169059753, 'loss_2': 0.0128173828125, 'loss_3': -15.775396347045898, 'loss_4': 0.4063428044319153, 'epoch': 3.63}
{'loss': 0.1229, 'grad_norm': 28.45975112915039, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.11445432156324387, 'loss_2': 0.0084075927734375, 'loss_3': -15.563295364379883, 'loss_4': 0.6355020999908447, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 15:34:37,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:37,507 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:50<1:18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:44,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031705617904663086, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02516913414001465, 'eval_loss_2': 0.0065364837646484375, 'eval_loss_3': -18.012845993041992, 'eval_loss_4': 0.718840479850769, 'epoch': 3.63}
{'loss': 0.0692, 'grad_norm': 17.43708038330078, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.06218557059764862, 'loss_2': 0.00702667236328125, 'loss_3': -15.761777877807617, 'loss_4': 0.6148515939712524, 'epoch': 3.64}
{'loss': 0.0284, 'grad_norm': 7.255985736846924, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.025882523506879807, 'loss_2': 0.00249481201171875, 'loss_3': -15.896535873413086, 'loss_4': 1.0981882810592651, 'epoch': 3.65}
{'loss': 0.0384, 'grad_norm': 10.36386489868164, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.030913669615983963, 'loss_2': 0.007526397705078125, 'loss_3': -15.6106538772583, 'loss_4': 0.5332241058349609, 'epoch': 3.65}
{'loss': 0.0505, 'grad_norm': 13.73859691619873, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.04583263769745827, 'loss_2': 0.00470733642578125, 'loss_3': -15.606489181518555, 'loss_4': 0.8026316165924072, 'epoch': 3.66}
{'loss': 0.1228, 'grad_norm': 23.81650161743164, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.12021433562040329, 'loss_2': 0.002552032470703125, 'loss_3': -15.473505020141602, 'loss_4': 1.1713166236877441, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 15:34:44,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:44,852 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [15:57<1:18:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:52,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.11182454228401184, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.10379934310913086, 'eval_loss_2': 0.008025191724300385, 'eval_loss_3': -17.76906967163086, 'eval_loss_4': 1.0524343252182007, 'epoch': 3.66}
{'loss': 0.0529, 'grad_norm': 12.336421966552734, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.04453273117542267, 'loss_2': 0.0084075927734375, 'loss_3': -15.40371036529541, 'loss_4': 0.8680407404899597, 'epoch': 3.67}
{'loss': 0.0626, 'grad_norm': 16.574474334716797, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.05443364009261131, 'loss_2': 0.0081634521484375, 'loss_3': -15.635292053222656, 'loss_4': 1.1593800783157349, 'epoch': 3.67}
{'loss': 0.2069, 'grad_norm': 27.108016967773438, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.19867941737174988, 'loss_2': 0.00824737548828125, 'loss_3': -15.37308120727539, 'loss_4': 0.8986404538154602, 'epoch': 3.68}
{'loss': 0.086, 'grad_norm': 20.960594177246094, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.0810440182685852, 'loss_2': 0.00498199462890625, 'loss_3': -15.487228393554688, 'loss_4': 0.9361171126365662, 'epoch': 3.69}
{'loss': 0.0607, 'grad_norm': 16.132837295532227, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.056754205375909805, 'loss_2': 0.0039520263671875, 'loss_3': -15.439743041992188, 'loss_4': 1.09663987159729, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 15:34:52,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:52,205 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:05<1:19:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:34:59,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05622405558824539, 'eval_runtime': 3.9923, 'eval_samples_per_second': 256.495, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.05120079591870308, 'eval_loss_2': 0.005023255944252014, 'eval_loss_3': -17.902786254882812, 'eval_loss_4': 0.871915340423584, 'epoch': 3.69}
{'loss': 0.036, 'grad_norm': 10.817680358886719, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.027824867516756058, 'loss_2': 0.0081939697265625, 'loss_3': -15.498639106750488, 'loss_4': 0.6706864833831787, 'epoch': 3.7}
{'loss': 0.03, 'grad_norm': 8.127318382263184, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.02780093438923359, 'loss_2': 0.0022373199462890625, 'loss_3': -15.380027770996094, 'loss_4': 0.7462316751480103, 'epoch': 3.7}
{'loss': 0.1858, 'grad_norm': 24.284578323364258, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.17753134667873383, 'loss_2': 0.0082550048828125, 'loss_3': -15.388994216918945, 'loss_4': 0.6213619709014893, 'epoch': 3.71}
{'loss': 0.0714, 'grad_norm': 20.622108459472656, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.06954848766326904, 'loss_2': 0.00180816650390625, 'loss_3': -15.700544357299805, 'loss_4': 0.5032593607902527, 'epoch': 3.72}
{'loss': 0.0503, 'grad_norm': 15.169865608215332, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.04575275257229805, 'loss_2': 0.0045166015625, 'loss_3': -15.536192893981934, 'loss_4': 0.888205349445343, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 15:34:59,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:59,739 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:12<1:18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:07,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020752012729644775, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014899017289280891, 'eval_loss_2': 0.005852997303009033, 'eval_loss_3': -18.084360122680664, 'eval_loss_4': 0.44863396883010864, 'epoch': 3.72}
{'loss': 0.0341, 'grad_norm': 11.676203727722168, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.031503692269325256, 'loss_2': 0.0025634765625, 'loss_3': -15.55712890625, 'loss_4': 0.38244205713272095, 'epoch': 3.73}
{'loss': 0.0313, 'grad_norm': 8.933696746826172, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.024778593331575394, 'loss_2': 0.00653839111328125, 'loss_3': -15.492143630981445, 'loss_4': 0.903441309928894, 'epoch': 3.73}
{'loss': 0.1017, 'grad_norm': 33.02545166015625, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.09780869632959366, 'loss_2': 0.003841400146484375, 'loss_3': -15.580156326293945, 'loss_4': 0.6404677629470825, 'epoch': 3.74}
{'loss': 0.0337, 'grad_norm': 12.122088432312012, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.03157232701778412, 'loss_2': 0.002094268798828125, 'loss_3': -15.456574440002441, 'loss_4': 0.2267412543296814, 'epoch': 3.74}
{'loss': 0.0535, 'grad_norm': 23.078617095947266, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.05290038883686066, 'loss_2': 0.0005922317504882812, 'loss_3': -15.731019973754883, 'loss_4': 0.3016946017742157, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 15:35:07,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:07,092 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:16<1:18:20,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:35:10,908 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645
[INFO|configuration_utils.py:420] 2025-01-21 15:35:10,909 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645/config.json                                                                             
{'eval_loss': 0.015689749270677567, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.481, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01137737650424242, 'eval_loss_2': 0.004312373697757721, 'eval_loss_3': -18.114990234375, 'eval_loss_4': 0.38511061668395996, 'epoch': 3.75}
[INFO|modeling_utils.py:2988] 2025-01-21 15:35:11,400 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:35:11,401 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:35:11,402 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:35:12,228 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-475] due to args.save_total_limit
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:21<1:25:43,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:35:15,861 >>
{'loss': 0.0362, 'grad_norm': 10.585470199584961, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.026271307840943336, 'loss_2': 0.00988006591796875, 'loss_3': -15.619165420532227, 'loss_4': 0.61029052734375, 'epoch': 3.76}
{'loss': 0.0221, 'grad_norm': 6.762972354888916, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.015312938950955868, 'loss_2': 0.00682830810546875, 'loss_3': -15.518882751464844, 'loss_4': 0.39412227272987366, 'epoch': 3.76}
{'loss': 0.0888, 'grad_norm': 33.20560836791992, 'learning_rate': 2.625e-05, 'loss_1': 0.07993219792842865, 'loss_2': 0.008819580078125, 'loss_3': -15.673528671264648, 'loss_4': 0.4888315796852112, 'epoch': 3.77}
{'loss': 0.0608, 'grad_norm': 17.7674560546875, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.05691532790660858, 'loss_2': 0.00392913818359375, 'loss_3': -15.53721809387207, 'loss_4': 1.0237531661987305, 'epoch': 3.77}
{'loss': 0.1153, 'grad_norm': 26.661396026611328, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.10966751724481583, 'loss_2': 0.005645751953125, 'loss_3': -15.588350296020508, 'loss_4': 0.6352258324623108, 'epoch': 3.78}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:35:15,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:15,861 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:28<1:19:06,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:35:23,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02031889371573925, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011949567124247551, 'eval_loss_2': 0.0083693265914917, 'eval_loss_3': -18.131969451904297, 'eval_loss_4': 0.44307267665863037, 'epoch': 3.78}
{'loss': 0.0623, 'grad_norm': 22.775564193725586, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.05599363148212433, 'loss_2': 0.00635528564453125, 'loss_3': -15.591083526611328, 'loss_4': 0.686748743057251, 'epoch': 3.78}
{'loss': 0.0459, 'grad_norm': 15.381648063659668, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.04027082771062851, 'loss_2': 0.0056304931640625, 'loss_3': -15.548144340515137, 'loss_4': 0.3158104717731476, 'epoch': 3.79}
{'loss': 0.0296, 'grad_norm': 7.420266628265381, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.02114768885076046, 'loss_2': 0.0084686279296875, 'loss_3': -15.433525085449219, 'loss_4': 0.5162484645843506, 'epoch': 3.8}
{'loss': 0.0505, 'grad_norm': 27.05524444580078, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.04935208708047867, 'loss_2': 0.0011606216430664062, 'loss_3': -15.647383689880371, 'loss_4': 0.7633898258209229, 'epoch': 3.8}
{'loss': 0.0565, 'grad_norm': 16.835224151611328, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.05344763025641441, 'loss_2': 0.0030803680419921875, 'loss_3': -15.362913131713867, 'loss_4': -0.25653406977653503, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 15:35:23,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:23,203 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:35<1:17:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:30,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017940547317266464, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011500265449285507, 'eval_loss_2': 0.006440281867980957, 'eval_loss_3': -18.102460861206055, 'eval_loss_4': 0.010280046612024307, 'epoch': 3.81}
{'loss': 0.0317, 'grad_norm': 7.913438320159912, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.01948191598057747, 'loss_2': 0.012237548828125, 'loss_3': -15.686824798583984, 'loss_4': 0.12797270715236664, 'epoch': 3.81}
{'loss': 0.031, 'grad_norm': 21.69932746887207, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.029778560623526573, 'loss_2': 0.0012302398681640625, 'loss_3': -15.716456413269043, 'loss_4': 0.14730960130691528, 'epoch': 3.82}
{'loss': 0.0305, 'grad_norm': 10.712593078613281, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.02832484059035778, 'loss_2': 0.002178192138671875, 'loss_3': -15.437335014343262, 'loss_4': -0.23509763181209564, 'epoch': 3.83}
{'loss': 0.032, 'grad_norm': 9.105915069580078, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.02931981161236763, 'loss_2': 0.0026836395263671875, 'loss_3': -15.357316017150879, 'loss_4': -0.21443592011928558, 'epoch': 3.83}
{'loss': 0.0657, 'grad_norm': 14.961730003356934, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.05874624103307724, 'loss_2': 0.006927490234375, 'loss_3': -15.521254539489746, 'loss_4': -0.29601022601127625, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 15:35:30,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:30,543 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:43<1:17:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:37,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04207123443484306, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0354008823633194, 'eval_loss_2': 0.006670355796813965, 'eval_loss_3': -17.963769912719727, 'eval_loss_4': 0.08153010904788971, 'epoch': 3.84}
{'loss': 0.0407, 'grad_norm': 16.684791564941406, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.04023754596710205, 'loss_2': 0.0004837512969970703, 'loss_3': -15.834573745727539, 'loss_4': -0.11782145500183105, 'epoch': 3.84}
{'loss': 0.036, 'grad_norm': 12.742602348327637, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.033886075019836426, 'loss_2': 0.00214385986328125, 'loss_3': -15.480865478515625, 'loss_4': -0.09540317952632904, 'epoch': 3.85}
{'loss': 0.0289, 'grad_norm': 11.232247352600098, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.025550412014126778, 'loss_2': 0.0033416748046875, 'loss_3': -15.480690956115723, 'loss_4': 0.22482289373874664, 'epoch': 3.85}
{'loss': 0.0478, 'grad_norm': 15.466533660888672, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.040869638323783875, 'loss_2': 0.00695037841796875, 'loss_3': -15.44723129272461, 'loss_4': -0.09371758252382278, 'epoch': 3.86}
{'loss': 0.0325, 'grad_norm': 9.868515968322754, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.026609396561980247, 'loss_2': 0.005863189697265625, 'loss_3': -15.508869171142578, 'loss_4': 0.479650616645813, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 15:35:37,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:37,893 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:50<1:17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:45,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06603377312421799, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0591236874461174, 'eval_loss_2': 0.006910085678100586, 'eval_loss_3': -17.947843551635742, 'eval_loss_4': 0.6884552836418152, 'epoch': 3.87}
{'loss': 0.0339, 'grad_norm': 9.901288032531738, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.02595183253288269, 'loss_2': 0.00799560546875, 'loss_3': -15.434709548950195, 'loss_4': 0.8100208044052124, 'epoch': 3.87}
{'loss': 0.032, 'grad_norm': 11.079771041870117, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.03147143870592117, 'loss_2': 0.0005664825439453125, 'loss_3': -15.507943153381348, 'loss_4': 0.575100839138031, 'epoch': 3.88}
{'loss': 0.0512, 'grad_norm': 14.208683967590332, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.044888220727443695, 'loss_2': 0.00635528564453125, 'loss_3': -15.560446739196777, 'loss_4': 0.6237821578979492, 'epoch': 3.88}
{'loss': 0.0404, 'grad_norm': 7.982267379760742, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.033338021486997604, 'loss_2': 0.00708770751953125, 'loss_3': -15.536253929138184, 'loss_4': 0.6609164476394653, 'epoch': 3.89}
{'loss': 0.0242, 'grad_norm': 6.1861042976379395, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.019238730892539024, 'loss_2': 0.0049591064453125, 'loss_3': -15.733561515808105, 'loss_4': 0.9494847655296326, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 15:35:45,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:45,239 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [16:58<1:17:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:52,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06295792013406754, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.05837841331958771, 'eval_loss_2': 0.004579506814479828, 'eval_loss_3': -17.954940795898438, 'eval_loss_4': 1.094353437423706, 'epoch': 3.9}
{'loss': 0.0777, 'grad_norm': 12.300895690917969, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.07247699052095413, 'loss_2': 0.00527191162109375, 'loss_3': -15.545461654663086, 'loss_4': 1.166959524154663, 'epoch': 3.9}
{'loss': 0.0407, 'grad_norm': 9.733007431030273, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.030747655779123306, 'loss_2': 0.00994873046875, 'loss_3': -15.302242279052734, 'loss_4': 1.1067217588424683, 'epoch': 3.91}
{'loss': 0.0511, 'grad_norm': 16.573339462280273, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.044361334294080734, 'loss_2': 0.0067291259765625, 'loss_3': -15.526445388793945, 'loss_4': 1.1374326944351196, 'epoch': 3.91}
{'loss': 0.1312, 'grad_norm': 37.99628448486328, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.12425964325666428, 'loss_2': 0.006927490234375, 'loss_3': -15.363760948181152, 'loss_4': 1.4560085535049438, 'epoch': 3.92}
{'loss': 0.0366, 'grad_norm': 13.115849494934082, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.034833330661058426, 'loss_2': 0.0017461776733398438, 'loss_3': -15.58442211151123, 'loss_4': 1.5924264192581177, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 15:35:52,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:52,593 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:05<1:17:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:59,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03325894474983215, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.65, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.028882090002298355, 'eval_loss_2': 0.004376858472824097, 'eval_loss_3': -18.087329864501953, 'eval_loss_4': 1.5764656066894531, 'epoch': 3.92}
{'loss': 0.0243, 'grad_norm': 10.346451759338379, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.024147864431142807, 'loss_2': 0.00019741058349609375, 'loss_3': -15.55434799194336, 'loss_4': 1.5791207551956177, 'epoch': 3.93}
{'loss': 0.0555, 'grad_norm': 14.4404296875, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.04989876598119736, 'loss_2': 0.0055694580078125, 'loss_3': -15.59570598602295, 'loss_4': 1.8618931770324707, 'epoch': 3.94}
{'loss': 0.0526, 'grad_norm': 15.231587409973145, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.046015664935112, 'loss_2': 0.00658416748046875, 'loss_3': -15.691373825073242, 'loss_4': 1.6675645112991333, 'epoch': 3.94}
{'loss': 0.0387, 'grad_norm': 10.598915100097656, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.03064681403338909, 'loss_2': 0.008056640625, 'loss_3': -15.616609573364258, 'loss_4': 1.9478589296340942, 'epoch': 3.95}
{'loss': 0.0691, 'grad_norm': 17.66575813293457, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.05990403890609741, 'loss_2': 0.0092010498046875, 'loss_3': -15.702930450439453, 'loss_4': 2.6861910820007324, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 15:35:59,948 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:59,948 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:12<1:17:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:07,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01903805509209633, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.375, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0133841373026371, 'eval_loss_2': 0.0056539177894592285, 'eval_loss_3': -18.21302604675293, 'eval_loss_4': 2.2088844776153564, 'epoch': 3.95}
{'loss': 0.0608, 'grad_norm': 18.038515090942383, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.06034286320209503, 'loss_2': 0.0004138946533203125, 'loss_3': -15.618555068969727, 'loss_4': 2.0902864933013916, 'epoch': 3.96}
{'loss': 0.0318, 'grad_norm': 9.958852767944336, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.029851442202925682, 'loss_2': 0.0019969940185546875, 'loss_3': -15.443473815917969, 'loss_4': 2.3217949867248535, 'epoch': 3.97}
{'loss': 0.0231, 'grad_norm': 7.608567237854004, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.021819954738020897, 'loss_2': 0.0012483596801757812, 'loss_3': -15.686039924621582, 'loss_4': 1.9941154718399048, 'epoch': 3.97}
{'loss': 0.0258, 'grad_norm': 7.131054401397705, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.01932525634765625, 'loss_2': 0.00649261474609375, 'loss_3': -15.602745056152344, 'loss_4': 2.394697666168213, 'epoch': 3.98}
{'loss': 0.0301, 'grad_norm': 9.440430641174316, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.025907235220074654, 'loss_2': 0.00417327880859375, 'loss_3': -15.608531951904297, 'loss_4': 2.766376256942749, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 15:36:07,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:07,299 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:19<1:14:08,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 15:36:14,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023309387266635895, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012594020925462246, 'eval_loss_2': 0.010715365409851074, 'eval_loss_3': -18.204965591430664, 'eval_loss_4': 2.497649669647217, 'epoch': 3.98}
{'loss': 0.0246, 'grad_norm': 6.582424640655518, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.01644834876060486, 'loss_2': 0.00814056396484375, 'loss_3': -15.743566513061523, 'loss_4': 2.727841377258301, 'epoch': 3.99}
{'loss': 0.0399, 'grad_norm': 8.141718864440918, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.02692737989127636, 'loss_2': 0.01297760009765625, 'loss_3': -15.655630111694336, 'loss_4': 2.588499069213867, 'epoch': 3.99}
{'loss': 0.0217, 'grad_norm': 7.744091987609863, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.011846504174172878, 'loss_2': 0.00989532470703125, 'loss_3': -15.396936416625977, 'loss_4': 2.803346872329712, 'epoch': 4.0}
{'loss': 0.0318, 'grad_norm': 10.161039352416992, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.022487713024020195, 'loss_2': 0.00926971435546875, 'loss_3': -15.629668235778809, 'loss_4': 2.7265968322753906, 'epoch': 4.01}
{'loss': 0.1248, 'grad_norm': 17.29288673400879, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.11741293221712112, 'loss_2': 0.0073699951171875, 'loss_3': -15.748605728149414, 'loss_4': 2.583160400390625, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 15:36:14,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:14,331 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:27<1:16:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:36:21,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016448646783828735, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01232606265693903, 'eval_loss_2': 0.00412258505821228, 'eval_loss_3': -18.16851806640625, 'eval_loss_4': 2.1423697471618652, 'epoch': 4.01}
{'loss': 0.0377, 'grad_norm': 9.886239051818848, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.029327353462576866, 'loss_2': 0.00836181640625, 'loss_3': -15.908638954162598, 'loss_4': 2.6537327766418457, 'epoch': 4.02}
{'loss': 0.0439, 'grad_norm': 18.420873641967773, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.04058443382382393, 'loss_2': 0.00336456298828125, 'loss_3': -15.505399703979492, 'loss_4': 2.3184919357299805, 'epoch': 4.02}
{'loss': 0.0363, 'grad_norm': 11.444201469421387, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.03272675350308418, 'loss_2': 0.0035800933837890625, 'loss_3': -15.499266624450684, 'loss_4': 1.6449705362319946, 'epoch': 4.03}
{'loss': 0.084, 'grad_norm': 20.88056755065918, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.07720600813627243, 'loss_2': 0.00677490234375, 'loss_3': -15.688199043273926, 'loss_4': 1.7171754837036133, 'epoch': 4.03}
{'loss': 0.0481, 'grad_norm': 9.615851402282715, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.02615908719599247, 'loss_2': 0.02191162109375, 'loss_3': -15.457042694091797, 'loss_4': 1.659330129623413, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 15:36:21,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:21,677 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:34<1:17:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:29,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023694191128015518, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.154, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012007865123450756, 'eval_loss_2': 0.011686325073242188, 'eval_loss_3': -18.151958465576172, 'eval_loss_4': 1.6909961700439453, 'epoch': 4.04}
{'loss': 0.0579, 'grad_norm': 16.251230239868164, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.049078598618507385, 'loss_2': 0.0087890625, 'loss_3': -15.74150562286377, 'loss_4': 1.9058723449707031, 'epoch': 4.05}
{'loss': 0.1643, 'grad_norm': 35.819053649902344, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.14849509298801422, 'loss_2': 0.0157928466796875, 'loss_3': -15.487815856933594, 'loss_4': 2.026858329772949, 'epoch': 4.05}
{'loss': 0.0228, 'grad_norm': 8.25086498260498, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.01881006546318531, 'loss_2': 0.0039825439453125, 'loss_3': -15.591262817382812, 'loss_4': 1.2579236030578613, 'epoch': 4.06}
{'loss': 0.0436, 'grad_norm': 8.617269515991211, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.0285833477973938, 'loss_2': 0.0149993896484375, 'loss_3': -15.830972671508789, 'loss_4': 1.843239665031433, 'epoch': 4.06}
{'loss': 0.0282, 'grad_norm': 8.706513404846191, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.026279745623469353, 'loss_2': 0.0019130706787109375, 'loss_3': -15.61474323272705, 'loss_4': 1.2284951210021973, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 15:36:29,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:29,026 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:41<1:17:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:36,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022575702518224716, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0180470272898674, 'eval_loss_2': 0.004528671503067017, 'eval_loss_3': -18.060985565185547, 'eval_loss_4': 1.5022766590118408, 'epoch': 4.07}
{'loss': 0.0294, 'grad_norm': 7.9976487159729, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.028246834874153137, 'loss_2': 0.0011539459228515625, 'loss_3': -15.766048431396484, 'loss_4': 1.692610263824463, 'epoch': 4.08}
{'loss': 0.0442, 'grad_norm': 10.272775650024414, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.036829154938459396, 'loss_2': 0.007335662841796875, 'loss_3': -15.431547164916992, 'loss_4': 1.408853530883789, 'epoch': 4.08}
{'loss': 0.0302, 'grad_norm': 8.716153144836426, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.02873779460787773, 'loss_2': 0.00147247314453125, 'loss_3': -15.77987003326416, 'loss_4': 1.4382091760635376, 'epoch': 4.09}
{'loss': 0.0595, 'grad_norm': 13.453988075256348, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.04688825458288193, 'loss_2': 0.01263427734375, 'loss_3': -15.404600143432617, 'loss_4': 1.2118918895721436, 'epoch': 4.09}
{'loss': 0.0153, 'grad_norm': 5.448139667510986, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.010664480738341808, 'loss_2': 0.00460052490234375, 'loss_3': -15.60046672821045, 'loss_4': 1.049583911895752, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 15:36:36,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:36,388 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:49<1:16:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:43,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039328183978796005, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.024594150483608246, 'eval_loss_2': 0.014734029769897461, 'eval_loss_3': -18.00463104248047, 'eval_loss_4': 1.4001225233078003, 'epoch': 4.1}
{'loss': 0.0678, 'grad_norm': 18.016328811645508, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.05474648252129555, 'loss_2': 0.01309967041015625, 'loss_3': -15.445584297180176, 'loss_4': 1.007948398590088, 'epoch': 4.1}
{'loss': 0.0563, 'grad_norm': 10.71729850769043, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.04031994938850403, 'loss_2': 0.016021728515625, 'loss_3': -15.457436561584473, 'loss_4': 1.1584479808807373, 'epoch': 4.11}
{'loss': 0.0454, 'grad_norm': 10.30379867553711, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.034107502549886703, 'loss_2': 0.01132965087890625, 'loss_3': -15.854230880737305, 'loss_4': 1.7911245822906494, 'epoch': 4.12}
{'loss': 0.0326, 'grad_norm': 7.061702728271484, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.02215498313307762, 'loss_2': 0.01042938232421875, 'loss_3': -15.628328323364258, 'loss_4': 0.42672786116600037, 'epoch': 4.12}
{'loss': 0.0581, 'grad_norm': 21.68587303161621, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.04583856463432312, 'loss_2': 0.0122833251953125, 'loss_3': -15.619403839111328, 'loss_4': 1.2437137365341187, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 15:36:43,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:43,738 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [17:56<1:16:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:51,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024364640936255455, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.291, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018073640763759613, 'eval_loss_2': 0.006291002035140991, 'eval_loss_3': -18.02911376953125, 'eval_loss_4': 0.9892082214355469, 'epoch': 4.13}
{'loss': 0.0584, 'grad_norm': 15.066658020019531, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.051544029265642166, 'loss_2': 0.00688934326171875, 'loss_3': -15.43880558013916, 'loss_4': 1.122807502746582, 'epoch': 4.13}
{'loss': 0.1008, 'grad_norm': 25.837661743164062, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.09368690103292465, 'loss_2': 0.007160186767578125, 'loss_3': -15.620085716247559, 'loss_4': 1.0872838497161865, 'epoch': 4.14}
{'loss': 0.0369, 'grad_norm': 8.756111145019531, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.033014778047800064, 'loss_2': 0.0038433074951171875, 'loss_3': -15.652709007263184, 'loss_4': 0.8384972810745239, 'epoch': 4.15}
{'loss': 0.0356, 'grad_norm': 12.645612716674805, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.03504565730690956, 'loss_2': 0.0005517005920410156, 'loss_3': -15.560707092285156, 'loss_4': 1.0830636024475098, 'epoch': 4.15}
{'loss': 0.0267, 'grad_norm': 7.733667850494385, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.019978618249297142, 'loss_2': 0.00675201416015625, 'loss_3': -15.627479553222656, 'loss_4': 0.5614840388298035, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 15:36:51,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:51,091 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:03<1:16:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:58,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0286903977394104, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.448, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01602274179458618, 'eval_loss_2': 0.012667655944824219, 'eval_loss_3': -18.01901626586914, 'eval_loss_4': 0.5568857789039612, 'epoch': 4.16}
{'loss': 0.0788, 'grad_norm': 19.544658660888672, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.059214942157268524, 'loss_2': 0.019622802734375, 'loss_3': -15.502985000610352, 'loss_4': 0.1255374252796173, 'epoch': 4.16}
{'loss': 0.0414, 'grad_norm': 12.542885780334473, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.02403416857123375, 'loss_2': 0.017333984375, 'loss_3': -15.762863159179688, 'loss_4': 0.29590800404548645, 'epoch': 4.17}
{'loss': 0.0474, 'grad_norm': 12.310054779052734, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.024567782878875732, 'loss_2': 0.0228271484375, 'loss_3': -15.834846496582031, 'loss_4': 0.5035199522972107, 'epoch': 4.17}
{'loss': 0.0313, 'grad_norm': 5.782750129699707, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.012105786241590977, 'loss_2': 0.019195556640625, 'loss_3': -15.549994468688965, 'loss_4': 0.6543281674385071, 'epoch': 4.18}
{'loss': 0.0307, 'grad_norm': 7.042055606842041, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.01336213294416666, 'loss_2': 0.017333984375, 'loss_3': -15.644853591918945, 'loss_4': 0.5590180158615112, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 15:36:58,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:58,444 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:11<1:16:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:05,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02446187287569046, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012900718487799168, 'eval_loss_2': 0.011561155319213867, 'eval_loss_3': -18.057289123535156, 'eval_loss_4': 0.2969059646129608, 'epoch': 4.19}
{'loss': 0.037, 'grad_norm': 8.14087200164795, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.026271741837263107, 'loss_2': 0.010711669921875, 'loss_3': -15.489521980285645, 'loss_4': 0.20115455985069275, 'epoch': 4.19}
{'loss': 0.0203, 'grad_norm': 7.0668535232543945, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.014209544286131859, 'loss_2': 0.006130218505859375, 'loss_3': -15.61622142791748, 'loss_4': 0.04328320175409317, 'epoch': 4.2}
{'loss': 0.027, 'grad_norm': 9.611177444458008, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.02521119825541973, 'loss_2': 0.0017871856689453125, 'loss_3': -15.695829391479492, 'loss_4': 0.007470563054084778, 'epoch': 4.2}
{'loss': 0.0466, 'grad_norm': 12.008390426635742, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.03426634520292282, 'loss_2': 0.01233673095703125, 'loss_3': -15.75678539276123, 'loss_4': 0.5131387710571289, 'epoch': 4.21}
{'loss': 0.0341, 'grad_norm': 9.400886535644531, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.024071458727121353, 'loss_2': 0.01006317138671875, 'loss_3': -15.546157836914062, 'loss_4': -0.08281897753477097, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 15:37:05,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:05,797 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:18<1:16:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:13,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03496946766972542, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.021971717476844788, 'eval_loss_2': 0.012997746467590332, 'eval_loss_3': -18.030391693115234, 'eval_loss_4': 0.28191256523132324, 'epoch': 4.22}
{'loss': 0.0633, 'grad_norm': 14.826423645019531, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.04812303185462952, 'loss_2': 0.01520538330078125, 'loss_3': -15.786857604980469, 'loss_4': 0.31937843561172485, 'epoch': 4.22}
{'loss': 0.0454, 'grad_norm': 10.452605247497559, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.03184818848967552, 'loss_2': 0.013519287109375, 'loss_3': -15.513300895690918, 'loss_4': 0.44577527046203613, 'epoch': 4.23}
{'loss': 0.024, 'grad_norm': 5.283695697784424, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.010771037079393864, 'loss_2': 0.0132293701171875, 'loss_3': -15.861054420471191, 'loss_4': -0.14810773730278015, 'epoch': 4.23}
{'loss': 0.0575, 'grad_norm': 11.640480041503906, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.034785475581884384, 'loss_2': 0.0227508544921875, 'loss_3': -15.72368049621582, 'loss_4': 0.33234143257141113, 'epoch': 4.24}
{'loss': 0.0441, 'grad_norm': 10.381053924560547, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.026422420516610146, 'loss_2': 0.0177154541015625, 'loss_3': -15.741182327270508, 'loss_4': 0.40914666652679443, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 15:37:13,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:13,151 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:25<1:16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:20,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04469180107116699, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.454, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.033033374696969986, 'eval_loss_2': 0.011658430099487305, 'eval_loss_3': -18.014341354370117, 'eval_loss_4': 0.5637447834014893, 'epoch': 4.24}
{'loss': 0.0273, 'grad_norm': 5.44707727432251, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.012525918893516064, 'loss_2': 0.0147705078125, 'loss_3': -15.854269027709961, 'loss_4': 0.49543437361717224, 'epoch': 4.25}
{'loss': 0.0377, 'grad_norm': 7.428140163421631, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.022374697029590607, 'loss_2': 0.015289306640625, 'loss_3': -15.831188201904297, 'loss_4': 0.6140972375869751, 'epoch': 4.26}
{'loss': 0.1412, 'grad_norm': 39.17306137084961, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.14088653028011322, 'loss_2': 0.00027751922607421875, 'loss_3': -15.621007919311523, 'loss_4': 1.0192725658416748, 'epoch': 4.26}
{'loss': 0.0439, 'grad_norm': 16.810068130493164, 'learning_rate': 2.575e-05, 'loss_1': 0.043395161628723145, 'loss_2': 0.0005359649658203125, 'loss_3': -15.688711166381836, 'loss_4': 0.47688066959381104, 'epoch': 4.27}
{'loss': 0.0257, 'grad_norm': 6.576047420501709, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.02324465848505497, 'loss_2': 0.002445220947265625, 'loss_3': -15.628841400146484, 'loss_4': 0.38449808955192566, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 15:37:20,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:20,513 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:33<1:16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:27,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03937329351902008, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.030636565759778023, 'eval_loss_2': 0.008736729621887207, 'eval_loss_3': -18.073060989379883, 'eval_loss_4': 0.7769389748573303, 'epoch': 4.27}
{'loss': 0.0485, 'grad_norm': 10.337119102478027, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.04034062474966049, 'loss_2': 0.0081787109375, 'loss_3': -15.7998628616333, 'loss_4': 0.9479667544364929, 'epoch': 4.28}
{'loss': 0.0497, 'grad_norm': 10.411335945129395, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.036904361099004745, 'loss_2': 0.0128021240234375, 'loss_3': -15.82831859588623, 'loss_4': 0.8049010038375854, 'epoch': 4.28}
{'loss': 0.0883, 'grad_norm': 23.56577491760254, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.07995399087667465, 'loss_2': 0.0083465576171875, 'loss_3': -15.735326766967773, 'loss_4': 1.0594323873519897, 'epoch': 4.29}
{'loss': 0.0479, 'grad_norm': 8.254317283630371, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.032385896891355515, 'loss_2': 0.0155029296875, 'loss_3': -16.037717819213867, 'loss_4': 0.40529561042785645, 'epoch': 4.3}
{'loss': 0.037, 'grad_norm': 10.718549728393555, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.031426846981048584, 'loss_2': 0.00562286376953125, 'loss_3': -15.961715698242188, 'loss_4': 0.9688867330551147, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 15:37:27,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:27,861 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:40<1:16:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:35,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02530844137072563, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01970551535487175, 'eval_loss_2': 0.005602926015853882, 'eval_loss_3': -18.1389217376709, 'eval_loss_4': 0.6828570365905762, 'epoch': 4.3}
{'loss': 0.0456, 'grad_norm': 14.28567886352539, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.04201406240463257, 'loss_2': 0.003627777099609375, 'loss_3': -15.936906814575195, 'loss_4': 0.6786309480667114, 'epoch': 4.31}
{'loss': 0.0463, 'grad_norm': 19.923067092895508, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.04491027072072029, 'loss_2': 0.0013580322265625, 'loss_3': -15.78879165649414, 'loss_4': 0.7839663028717041, 'epoch': 4.31}
{'loss': 0.0204, 'grad_norm': 6.757406234741211, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.01978401467204094, 'loss_2': 0.0005822181701660156, 'loss_3': -15.837614059448242, 'loss_4': 0.3634617328643799, 'epoch': 4.32}
{'loss': 0.0446, 'grad_norm': 9.590458869934082, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.04355305805802345, 'loss_2': 0.00101470947265625, 'loss_3': -15.948223114013672, 'loss_4': 0.7341607809066772, 'epoch': 4.33}
{'loss': 0.0712, 'grad_norm': 18.706623077392578, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.06384492665529251, 'loss_2': 0.007343292236328125, 'loss_3': -15.708793640136719, 'loss_4': 0.22818247973918915, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 15:37:35,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:35,197 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:47<1:16:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:42,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022497430443763733, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019105032086372375, 'eval_loss_2': 0.0033923983573913574, 'eval_loss_3': -18.187644958496094, 'eval_loss_4': 0.7630739212036133, 'epoch': 4.33}
{'loss': 0.0483, 'grad_norm': 11.640841484069824, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.04393230006098747, 'loss_2': 0.004337310791015625, 'loss_3': -16.09923553466797, 'loss_4': 0.9119696617126465, 'epoch': 4.34}
{'loss': 0.0223, 'grad_norm': 7.145708084106445, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.020433124154806137, 'loss_2': 0.0019130706787109375, 'loss_3': -15.937246322631836, 'loss_4': 0.6378031373023987, 'epoch': 4.34}
{'loss': 0.0536, 'grad_norm': 17.18461799621582, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.05274101719260216, 'loss_2': 0.000812530517578125, 'loss_3': -15.73737907409668, 'loss_4': 0.7934888601303101, 'epoch': 4.35}
{'loss': 0.0533, 'grad_norm': 14.551445007324219, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.04570874944329262, 'loss_2': 0.0075836181640625, 'loss_3': -15.859838485717773, 'loss_4': 0.8860501646995544, 'epoch': 4.35}
{'loss': 0.033, 'grad_norm': 9.937671661376953, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.02808220125734806, 'loss_2': 0.0048828125, 'loss_3': -15.993226051330566, 'loss_4': 0.7250792980194092, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 15:37:42,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:42,538 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [18:55<1:16:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:49,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026756875216960907, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.021653423085808754, 'eval_loss_2': 0.005103453993797302, 'eval_loss_3': -18.211692810058594, 'eval_loss_4': 0.7621666193008423, 'epoch': 4.36}
{'loss': 0.0231, 'grad_norm': 7.416391372680664, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.02259189635515213, 'loss_2': 0.000530242919921875, 'loss_3': -16.025821685791016, 'loss_4': 0.9003946781158447, 'epoch': 4.37}
{'loss': 0.0285, 'grad_norm': 6.339571475982666, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.019674884155392647, 'loss_2': 0.008819580078125, 'loss_3': -16.159656524658203, 'loss_4': 0.606024980545044, 'epoch': 4.37}
{'loss': 0.0266, 'grad_norm': 8.954795837402344, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.024800922721624374, 'loss_2': 0.0017852783203125, 'loss_3': -15.976333618164062, 'loss_4': 0.36871856451034546, 'epoch': 4.38}
{'loss': 0.0338, 'grad_norm': 6.470521450042725, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.020968105643987656, 'loss_2': 0.01280975341796875, 'loss_3': -16.062963485717773, 'loss_4': 0.6815574169158936, 'epoch': 4.38}
{'loss': 0.0502, 'grad_norm': 11.259191513061523, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.03848865628242493, 'loss_2': 0.0117340087890625, 'loss_3': -15.929725646972656, 'loss_4': 0.43714961409568787, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 15:37:49,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:49,882 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:02<1:16:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:57,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02664034068584442, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.022074127569794655, 'eval_loss_2': 0.004566214978694916, 'eval_loss_3': -18.22374725341797, 'eval_loss_4': 0.6551147699356079, 'epoch': 4.39}
{'loss': 0.0368, 'grad_norm': 10.443385124206543, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.033155377954244614, 'loss_2': 0.00365447998046875, 'loss_3': -16.07323455810547, 'loss_4': 0.6014478206634521, 'epoch': 4.4}
{'loss': 0.0441, 'grad_norm': 15.484806060791016, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.03797876834869385, 'loss_2': 0.006072998046875, 'loss_3': -16.066967010498047, 'loss_4': 0.8456000685691833, 'epoch': 4.4}
{'loss': 0.0358, 'grad_norm': 8.832094192504883, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.03031439706683159, 'loss_2': 0.00543975830078125, 'loss_3': -16.237878799438477, 'loss_4': 0.5804638862609863, 'epoch': 4.41}
{'loss': 0.0337, 'grad_norm': 10.881223678588867, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.03050883486866951, 'loss_2': 0.0031890869140625, 'loss_3': -15.868448257446289, 'loss_4': 0.0915667712688446, 'epoch': 4.41}
{'loss': 0.0333, 'grad_norm': 8.474932670593262, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.02328280732035637, 'loss_2': 0.00998687744140625, 'loss_3': -15.97287368774414, 'loss_4': 0.36216995120048523, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 15:37:57,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:57,240 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:10<1:16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:04,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03401409089565277, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.023684367537498474, 'eval_loss_2': 0.010329723358154297, 'eval_loss_3': -18.22117805480957, 'eval_loss_4': 0.30726101994514465, 'epoch': 4.42}
{'loss': 0.0403, 'grad_norm': 9.001411437988281, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.02959500253200531, 'loss_2': 0.0106964111328125, 'loss_3': -16.09641456604004, 'loss_4': 0.054617997258901596, 'epoch': 4.42}
{'loss': 0.0436, 'grad_norm': 14.950240135192871, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.035429101437330246, 'loss_2': 0.00818634033203125, 'loss_3': -15.883671760559082, 'loss_4': 0.3870393931865692, 'epoch': 4.43}
{'loss': 0.1438, 'grad_norm': 25.983108520507812, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.13470876216888428, 'loss_2': 0.00910186767578125, 'loss_3': -15.79914379119873, 'loss_4': 0.5351829528808594, 'epoch': 4.44}
{'loss': 0.0755, 'grad_norm': 21.04155921936035, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.06764855980873108, 'loss_2': 0.0078887939453125, 'loss_3': -15.969221115112305, 'loss_4': 0.3344859778881073, 'epoch': 4.44}
{'loss': 0.0313, 'grad_norm': 12.591720581054688, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.027932878583669662, 'loss_2': 0.00336456298828125, 'loss_3': -15.908228874206543, 'loss_4': 0.35523003339767456, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 15:38:04,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:04,587 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:17<1:15:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:11,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07723095268011093, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.07332013547420502, 'eval_loss_2': 0.003910824656486511, 'eval_loss_3': -18.071269989013672, 'eval_loss_4': 0.3064485490322113, 'epoch': 4.45}
{'loss': 0.0192, 'grad_norm': 6.712716579437256, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.016727419570088387, 'loss_2': 0.00251007080078125, 'loss_3': -15.980642318725586, 'loss_4': -0.06525357067584991, 'epoch': 4.45}
{'loss': 0.0584, 'grad_norm': 17.71042251586914, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.057989511638879776, 'loss_2': 0.000415802001953125, 'loss_3': -15.814348220825195, 'loss_4': 0.4431820213794708, 'epoch': 4.46}
{'loss': 0.0223, 'grad_norm': 7.217082500457764, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.022250454872846603, 'loss_2': 7.56978988647461e-05, 'loss_3': -15.845222473144531, 'loss_4': 0.20208744704723358, 'epoch': 4.47}
{'loss': 0.0415, 'grad_norm': 11.115960121154785, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.035281952470541, 'loss_2': 0.0061798095703125, 'loss_3': -15.64748764038086, 'loss_4': 0.24487894773483276, 'epoch': 4.47}
{'loss': 0.2412, 'grad_norm': 50.98793029785156, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.22480808198451996, 'loss_2': 0.0163726806640625, 'loss_3': -15.685504913330078, 'loss_4': -0.10747730731964111, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 15:38:11,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:11,939 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:24<1:15:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:19,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09139125049114227, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.362, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.08011690527200699, 'eval_loss_2': 0.011274337768554688, 'eval_loss_3': -18.026357650756836, 'eval_loss_4': -0.051374152302742004, 'epoch': 4.48}
{'loss': 0.0455, 'grad_norm': 18.373952865600586, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.031420059502124786, 'loss_2': 0.01406097412109375, 'loss_3': -15.370261192321777, 'loss_4': -0.0014348626136779785, 'epoch': 4.48}
{'loss': 0.0459, 'grad_norm': 13.71070671081543, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.030014025047421455, 'loss_2': 0.0158843994140625, 'loss_3': -15.81742000579834, 'loss_4': 0.02764495089650154, 'epoch': 4.49}
{'loss': 0.0507, 'grad_norm': 11.349899291992188, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.03761782869696617, 'loss_2': 0.01309967041015625, 'loss_3': -15.819844245910645, 'loss_4': -0.16585871577262878, 'epoch': 4.49}
{'loss': 0.0486, 'grad_norm': 14.089984893798828, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.024688610807061195, 'loss_2': 0.023895263671875, 'loss_3': -15.9956636428833, 'loss_4': -0.5834687948226929, 'epoch': 4.5}
{'loss': 0.0254, 'grad_norm': 6.157712936401367, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.019264858216047287, 'loss_2': 0.00617218017578125, 'loss_3': -15.91166877746582, 'loss_4': -0.4385140836238861, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 15:38:19,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:19,282 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:32<1:15:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:26,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026220936328172684, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.351, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01780443824827671, 'eval_loss_2': 0.008416496217250824, 'eval_loss_3': -18.243953704833984, 'eval_loss_4': -0.4009495973587036, 'epoch': 4.51}
{'loss': 0.0233, 'grad_norm': 5.954581260681152, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.011528930626809597, 'loss_2': 0.0117645263671875, 'loss_3': -15.660998344421387, 'loss_4': -0.49374672770500183, 'epoch': 4.51}
{'loss': 0.0221, 'grad_norm': 10.816617965698242, 'learning_rate': 2.55e-05, 'loss_1': 0.019995231181383133, 'loss_2': 0.0020809173583984375, 'loss_3': -15.827505111694336, 'loss_4': -0.32053089141845703, 'epoch': 4.52}
{'loss': 0.0229, 'grad_norm': 6.66290283203125, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.0215446799993515, 'loss_2': 0.001338958740234375, 'loss_3': -15.66417407989502, 'loss_4': 0.22797903418540955, 'epoch': 4.52}
{'loss': 0.1521, 'grad_norm': 19.066810607910156, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.1520385891199112, 'loss_2': 6.079673767089844e-05, 'loss_3': -15.788619995117188, 'loss_4': -0.3398107588291168, 'epoch': 4.53}
{'loss': 0.0453, 'grad_norm': 9.87287712097168, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.03278724104166031, 'loss_2': 0.0125274658203125, 'loss_3': -15.718587875366211, 'loss_4': 0.3272104561328888, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 15:38:26,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:26,625 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:39<1:15:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:33,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028045181185007095, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.21, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015027527697384357, 'eval_loss_2': 0.013017654418945312, 'eval_loss_3': -18.27469825744629, 'eval_loss_4': -0.2275465726852417, 'epoch': 4.53}
{'loss': 0.0693, 'grad_norm': 22.868221282958984, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.0536874383687973, 'loss_2': 0.015594482421875, 'loss_3': -15.708780288696289, 'loss_4': 0.22938048839569092, 'epoch': 4.54}
{'loss': 0.0606, 'grad_norm': 14.042726516723633, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.04441617801785469, 'loss_2': 0.0162200927734375, 'loss_3': -15.843400001525879, 'loss_4': 0.26884669065475464, 'epoch': 4.55}
{'loss': 0.0201, 'grad_norm': 5.573221683502197, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.012017539702355862, 'loss_2': 0.0080413818359375, 'loss_3': -16.044445037841797, 'loss_4': -0.1931275725364685, 'epoch': 4.55}
{'loss': 0.0253, 'grad_norm': 6.616407871246338, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.015254880301654339, 'loss_2': 0.01007843017578125, 'loss_3': -15.949310302734375, 'loss_4': -0.6190949082374573, 'epoch': 4.56}
{'loss': 0.0596, 'grad_norm': 23.22435188293457, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.04958353936672211, 'loss_2': 0.0099945068359375, 'loss_3': -15.572868347167969, 'loss_4': -0.17627042531967163, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 15:38:33,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:33,973 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:46<1:15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:41,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025329548865556717, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.235, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.015434314496815205, 'eval_loss_2': 0.009895235300064087, 'eval_loss_3': -18.22389793395996, 'eval_loss_4': -0.5327816009521484, 'epoch': 4.56}
{'loss': 0.0619, 'grad_norm': 15.130067825317383, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.05259086564183235, 'loss_2': 0.00933837890625, 'loss_3': -15.879440307617188, 'loss_4': 0.027838200330734253, 'epoch': 4.57}
{'loss': 0.0183, 'grad_norm': 6.79752779006958, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.01620803400874138, 'loss_2': 0.0020656585693359375, 'loss_3': -15.992109298706055, 'loss_4': -0.6353551745414734, 'epoch': 4.58}
{'loss': 0.0359, 'grad_norm': 10.212984085083008, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.034021228551864624, 'loss_2': 0.0018405914306640625, 'loss_3': -15.895143508911133, 'loss_4': -0.42959511280059814, 'epoch': 4.58}
{'loss': 0.0375, 'grad_norm': 14.467741012573242, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.026211323216557503, 'loss_2': 0.0112457275390625, 'loss_3': -15.808370590209961, 'loss_4': -0.13082079589366913, 'epoch': 4.59}
{'loss': 0.0242, 'grad_norm': 9.476213455200195, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.022627806290984154, 'loss_2': 0.0016021728515625, 'loss_3': -15.630699157714844, 'loss_4': -0.5201960206031799, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 15:38:41,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:41,329 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [19:54<1:15:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:48,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03648536652326584, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.806, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.03313975781202316, 'eval_loss_2': 0.0033456087112426758, 'eval_loss_3': -18.072141647338867, 'eval_loss_4': -0.35851234197616577, 'epoch': 4.59}
{'loss': 0.0701, 'grad_norm': 25.584651947021484, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.06690293550491333, 'loss_2': 0.003147125244140625, 'loss_3': -15.775607109069824, 'loss_4': -0.24381661415100098, 'epoch': 4.6}
{'loss': 0.0202, 'grad_norm': 7.208817958831787, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.01845571957528591, 'loss_2': 0.001739501953125, 'loss_3': -15.62530517578125, 'loss_4': -0.28178176283836365, 'epoch': 4.6}
{'loss': 0.0379, 'grad_norm': 11.181731224060059, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.033828333020210266, 'loss_2': 0.004055023193359375, 'loss_3': -15.704859733581543, 'loss_4': -0.818496584892273, 'epoch': 4.61}
{'loss': 0.026, 'grad_norm': 10.195833206176758, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.019643349573016167, 'loss_2': 0.006328582763671875, 'loss_3': -15.606483459472656, 'loss_4': -0.6855756044387817, 'epoch': 4.62}
{'loss': 0.0122, 'grad_norm': 5.196584701538086, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.007334736175835133, 'loss_2': 0.0048675537109375, 'loss_3': -15.586536407470703, 'loss_4': 0.10143499076366425, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 15:38:48,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:48,676 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:01<1:15:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:56,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09876975417137146, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.09603254497051239, 'eval_loss_2': 0.00273720920085907, 'eval_loss_3': -17.829986572265625, 'eval_loss_4': -0.05571841821074486, 'epoch': 4.62}
{'loss': 0.0893, 'grad_norm': 24.0140323638916, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.0853448435664177, 'loss_2': 0.00397491455078125, 'loss_3': -15.470170974731445, 'loss_4': 0.2808479368686676, 'epoch': 4.63}
{'loss': 0.0256, 'grad_norm': 13.113245010375977, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.024427251890301704, 'loss_2': 0.0011844635009765625, 'loss_3': -15.634801864624023, 'loss_4': -0.39628100395202637, 'epoch': 4.63}
{'loss': 0.0826, 'grad_norm': 21.29291534423828, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.08094847947359085, 'loss_2': 0.0016498565673828125, 'loss_3': -15.644676208496094, 'loss_4': 0.20649954676628113, 'epoch': 4.64}
{'loss': 0.0595, 'grad_norm': 24.54662322998047, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.05119289457798004, 'loss_2': 0.00829315185546875, 'loss_3': -15.377449035644531, 'loss_4': -0.30176249146461487, 'epoch': 4.65}
{'loss': 0.0173, 'grad_norm': 5.571390628814697, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.013743819668889046, 'loss_2': 0.0035877227783203125, 'loss_3': -15.496626853942871, 'loss_4': -0.05469296872615814, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 15:38:56,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:56,015 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:08<1:15:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:03,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.050828225910663605, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.04657069221138954, 'eval_loss_2': 0.004257529973983765, 'eval_loss_3': -17.953187942504883, 'eval_loss_4': 0.016056358814239502, 'epoch': 4.65}
{'loss': 0.0169, 'grad_norm': 5.823594093322754, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.015348557382822037, 'loss_2': 0.0015621185302734375, 'loss_3': -15.72181510925293, 'loss_4': -0.06775225698947906, 'epoch': 4.66}
{'loss': 0.0364, 'grad_norm': 11.371219635009766, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.02520979382097721, 'loss_2': 0.01123046875, 'loss_3': -15.67216968536377, 'loss_4': 0.143827885389328, 'epoch': 4.66}
{'loss': 0.0689, 'grad_norm': 17.4694766998291, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.06521221250295639, 'loss_2': 0.0037059783935546875, 'loss_3': -15.583126068115234, 'loss_4': 0.4537528157234192, 'epoch': 4.67}
{'loss': 0.0419, 'grad_norm': 9.4320068359375, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.03246143460273743, 'loss_2': 0.00942230224609375, 'loss_3': -15.471874237060547, 'loss_4': 0.21097540855407715, 'epoch': 4.67}
{'loss': 0.0341, 'grad_norm': 8.696310997009277, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.021586302667856216, 'loss_2': 0.012542724609375, 'loss_3': -15.352928161621094, 'loss_4': 0.028434425592422485, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 15:39:03,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:03,362 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:16<1:15:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:10,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02978076972067356, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.23, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018458271399140358, 'eval_loss_2': 0.011322498321533203, 'eval_loss_3': -18.0742130279541, 'eval_loss_4': 0.1805461347103119, 'epoch': 4.68}
{'loss': 0.0222, 'grad_norm': 6.63730001449585, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.013673289678990841, 'loss_2': 0.0085601806640625, 'loss_3': -15.49055290222168, 'loss_4': 0.7994725704193115, 'epoch': 4.69}
{'loss': 0.0562, 'grad_norm': 19.79720115661621, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.047622088342905045, 'loss_2': 0.0085296630859375, 'loss_3': -15.338688850402832, 'loss_4': 0.0772179514169693, 'epoch': 4.69}
{'loss': 0.1005, 'grad_norm': 22.068147659301758, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.09276221692562103, 'loss_2': 0.007778167724609375, 'loss_3': -15.525059700012207, 'loss_4': 0.7029565572738647, 'epoch': 4.7}
{'loss': 0.0163, 'grad_norm': 6.637491703033447, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.014074412174522877, 'loss_2': 0.002216339111328125, 'loss_3': -15.5829439163208, 'loss_4': 0.5308812260627747, 'epoch': 4.7}
{'loss': 0.0283, 'grad_norm': 9.830024719238281, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.024929560720920563, 'loss_2': 0.00337982177734375, 'loss_3': -15.601333618164062, 'loss_4': 0.5201001763343811, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 15:39:10,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:10,707 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:23<1:15:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:18,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02363838069140911, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.623, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.018573656678199768, 'eval_loss_2': 0.005064725875854492, 'eval_loss_3': -18.06875228881836, 'eval_loss_4': 0.6855058670043945, 'epoch': 4.71}
{'loss': 0.0267, 'grad_norm': 11.235381126403809, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.023246455937623978, 'loss_2': 0.00342559814453125, 'loss_3': -15.62704086303711, 'loss_4': 0.542109489440918, 'epoch': 4.72}
{'loss': 0.0185, 'grad_norm': 6.563513278961182, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.015138107351958752, 'loss_2': 0.003330230712890625, 'loss_3': -15.779434204101562, 'loss_4': 0.7735126614570618, 'epoch': 4.72}
{'loss': 0.0316, 'grad_norm': 12.057315826416016, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.020420853048563004, 'loss_2': 0.011199951171875, 'loss_3': -15.506448745727539, 'loss_4': 0.8652932643890381, 'epoch': 4.73}
{'loss': 0.0585, 'grad_norm': 16.175355911254883, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.044515300542116165, 'loss_2': 0.01399993896484375, 'loss_3': -15.630632400512695, 'loss_4': 0.6934459209442139, 'epoch': 4.73}
{'loss': 0.0442, 'grad_norm': 13.667158126831055, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.030088502913713455, 'loss_2': 0.0140838623046875, 'loss_3': -15.669784545898438, 'loss_4': 0.6202808022499084, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 15:39:18,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:18,066 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:30<1:15:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:25,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0365639328956604, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02207285538315773, 'eval_loss_2': 0.014491081237792969, 'eval_loss_3': -18.05843162536621, 'eval_loss_4': 0.8821991682052612, 'epoch': 4.74}
{'loss': 0.0411, 'grad_norm': 14.128978729248047, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.030957266688346863, 'loss_2': 0.01016998291015625, 'loss_3': -15.604130744934082, 'loss_4': 0.778167724609375, 'epoch': 4.74}
{'loss': 0.0492, 'grad_norm': 10.522502899169922, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.031892746686935425, 'loss_2': 0.017303466796875, 'loss_3': -15.492456436157227, 'loss_4': 0.4677853584289551, 'epoch': 4.75}
{'loss': 0.0528, 'grad_norm': 12.982444763183594, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.0410454235970974, 'loss_2': 0.01177978515625, 'loss_3': -15.785505294799805, 'loss_4': 0.9527081251144409, 'epoch': 4.76}
{'loss': 0.0696, 'grad_norm': 17.315704345703125, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.0607403963804245, 'loss_2': 0.00882720947265625, 'loss_3': -15.602570533752441, 'loss_4': 0.9308813214302063, 'epoch': 4.76}
{'loss': 0.0382, 'grad_norm': 9.963153839111328, 'learning_rate': 2.525e-05, 'loss_1': 0.030515704303979874, 'loss_2': 0.0076751708984375, 'loss_3': -15.780749320983887, 'loss_4': 0.5904640555381775, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 15:39:25,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:25,414 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:38<1:14:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:32,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03740270808339119, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.031379424035549164, 'eval_loss_2': 0.006023287773132324, 'eval_loss_3': -17.98152732849121, 'eval_loss_4': 0.9425368309020996, 'epoch': 4.77}
{'loss': 0.0501, 'grad_norm': 12.803703308105469, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.039581190794706345, 'loss_2': 0.010498046875, 'loss_3': -15.628418922424316, 'loss_4': 0.7054714560508728, 'epoch': 4.77}
{'loss': 0.0254, 'grad_norm': 6.042604923248291, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.01711442694067955, 'loss_2': 0.008270263671875, 'loss_3': -15.660604476928711, 'loss_4': 0.8752930164337158, 'epoch': 4.78}
{'loss': 0.1479, 'grad_norm': 22.00408363342285, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.14314121007919312, 'loss_2': 0.00472259521484375, 'loss_3': -15.817054748535156, 'loss_4': 1.397815227508545, 'epoch': 4.78}
{'loss': 0.0401, 'grad_norm': 13.054343223571777, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.03326994180679321, 'loss_2': 0.0068359375, 'loss_3': -15.711751937866211, 'loss_4': 0.7117936015129089, 'epoch': 4.79}
{'loss': 0.1021, 'grad_norm': 19.50421714782715, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.08513416349887848, 'loss_2': 0.0169677734375, 'loss_3': -15.63332462310791, 'loss_4': 0.8271491527557373, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 15:39:32,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:32,759 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:45<1:14:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:40,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05050785839557648, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.04212065786123276, 'eval_loss_2': 0.008387207984924316, 'eval_loss_3': -17.99135398864746, 'eval_loss_4': 1.0057916641235352, 'epoch': 4.8}
{'loss': 0.1031, 'grad_norm': 26.312679290771484, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.09032000601291656, 'loss_2': 0.0127716064453125, 'loss_3': -15.503728866577148, 'loss_4': 0.7931011319160461, 'epoch': 4.8}
{'loss': 0.0464, 'grad_norm': 12.633940696716309, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.03813726827502251, 'loss_2': 0.0082550048828125, 'loss_3': -15.647489547729492, 'loss_4': 1.0586034059524536, 'epoch': 4.81}
{'loss': 0.0675, 'grad_norm': 16.00010871887207, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.051390472799539566, 'loss_2': 0.0161590576171875, 'loss_3': -15.583292007446289, 'loss_4': 0.9291785359382629, 'epoch': 4.81}
{'loss': 0.0424, 'grad_norm': 11.975351333618164, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.03688928112387657, 'loss_2': 0.00555419921875, 'loss_3': -15.604911804199219, 'loss_4': 1.0186437368392944, 'epoch': 4.82}
{'loss': 0.0336, 'grad_norm': 8.415037155151367, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.030290840193629265, 'loss_2': 0.00328826904296875, 'loss_3': -15.807289123535156, 'loss_4': 1.2340278625488281, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 15:39:40,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:40,096 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:52<1:14:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:47,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053693365305662155, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.050580866634845734, 'eval_loss_2': 0.003112494945526123, 'eval_loss_3': -17.965953826904297, 'eval_loss_4': 1.3685789108276367, 'epoch': 4.83}
{'loss': 0.0354, 'grad_norm': 12.368501663208008, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.02778993546962738, 'loss_2': 0.0076446533203125, 'loss_3': -15.543777465820312, 'loss_4': 0.9830511212348938, 'epoch': 4.83}
{'loss': 0.063, 'grad_norm': 16.434659957885742, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.05673104152083397, 'loss_2': 0.0062408447265625, 'loss_3': -15.85665512084961, 'loss_4': 1.2846351861953735, 'epoch': 4.84}
{'loss': 0.1011, 'grad_norm': 27.378877639770508, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.09991229325532913, 'loss_2': 0.0011997222900390625, 'loss_3': -15.664530754089355, 'loss_4': 0.9106318950653076, 'epoch': 4.84}
{'loss': 0.0559, 'grad_norm': 14.938583374023438, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.04995419830083847, 'loss_2': 0.005924224853515625, 'loss_3': -15.584016799926758, 'loss_4': 0.9852241277694702, 'epoch': 4.85}
{'loss': 0.0756, 'grad_norm': 31.58713150024414, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.06993170827627182, 'loss_2': 0.00571441650390625, 'loss_3': -15.830480575561523, 'loss_4': 1.4730209112167358, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 15:39:47,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:47,441 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:00<1:14:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:54,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04794767126441002, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.03910750150680542, 'eval_loss_2': 0.008840173482894897, 'eval_loss_3': -18.011795043945312, 'eval_loss_4': 1.3732136487960815, 'epoch': 4.85}
{'loss': 0.0447, 'grad_norm': 10.568887710571289, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.028786683455109596, 'loss_2': 0.015899658203125, 'loss_3': -15.764583587646484, 'loss_4': 1.5739634037017822, 'epoch': 4.86}
{'loss': 0.0513, 'grad_norm': 16.27960777282715, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.050456684082746506, 'loss_2': 0.0008544921875, 'loss_3': -15.702664375305176, 'loss_4': 1.3795239925384521, 'epoch': 4.87}
{'loss': 0.0394, 'grad_norm': 10.287312507629395, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.03254624083638191, 'loss_2': 0.006839752197265625, 'loss_3': -15.703125953674316, 'loss_4': 1.6385973691940308, 'epoch': 4.87}
{'loss': 0.0391, 'grad_norm': 16.408756256103516, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.03170052915811539, 'loss_2': 0.007404327392578125, 'loss_3': -15.808855056762695, 'loss_4': 1.1733973026275635, 'epoch': 4.88}
{'loss': 0.0318, 'grad_norm': 9.41911792755127, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.025458939373493195, 'loss_2': 0.00632476806640625, 'loss_3': -15.738734245300293, 'loss_4': 1.0315850973129272, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 15:39:54,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:54,782 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:07<1:14:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:02,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03002166748046875, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.813, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02359950728714466, 'eval_loss_2': 0.006422162055969238, 'eval_loss_3': -18.06671714782715, 'eval_loss_4': 1.1677429676055908, 'epoch': 4.88}
{'loss': 0.0593, 'grad_norm': 21.097002029418945, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.05642533674836159, 'loss_2': 0.0028667449951171875, 'loss_3': -15.736688613891602, 'loss_4': 1.6535124778747559, 'epoch': 4.89}
{'loss': 0.0233, 'grad_norm': 7.558953762054443, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.020399969071149826, 'loss_2': 0.002933502197265625, 'loss_3': -15.717961311340332, 'loss_4': 1.2235984802246094, 'epoch': 4.9}
{'loss': 0.0252, 'grad_norm': 7.418039798736572, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.019270986318588257, 'loss_2': 0.005889892578125, 'loss_3': -15.786394119262695, 'loss_4': 1.2901153564453125, 'epoch': 4.9}
{'loss': 0.0185, 'grad_norm': 7.394040107727051, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.014793113805353642, 'loss_2': 0.0037403106689453125, 'loss_3': -15.883684158325195, 'loss_4': 1.1053807735443115, 'epoch': 4.91}
{'loss': 0.0579, 'grad_norm': 25.123058319091797, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.05277770012617111, 'loss_2': 0.005100250244140625, 'loss_3': -15.67877197265625, 'loss_4': 1.508723258972168, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 15:40:02,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:02,132 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:14<1:14:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:09,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022697124630212784, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01816532574594021, 'eval_loss_2': 0.004531800746917725, 'eval_loss_3': -18.09752655029297, 'eval_loss_4': 0.8754228353500366, 'epoch': 4.91}
{'loss': 0.0366, 'grad_norm': 8.869766235351562, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.030115218833088875, 'loss_2': 0.006488800048828125, 'loss_3': -15.682772636413574, 'loss_4': 0.6584422588348389, 'epoch': 4.92}
{'loss': 0.0978, 'grad_norm': 27.921491622924805, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.08973610401153564, 'loss_2': 0.00807952880859375, 'loss_3': -15.742900848388672, 'loss_4': 1.1335844993591309, 'epoch': 4.92}
{'loss': 0.0294, 'grad_norm': 8.104427337646484, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.02468862198293209, 'loss_2': 0.0047149658203125, 'loss_3': -15.705873489379883, 'loss_4': 0.8919570446014404, 'epoch': 4.93}
{'loss': 0.0198, 'grad_norm': 7.504047870635986, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.01776231825351715, 'loss_2': 0.0020751953125, 'loss_3': -15.971891403198242, 'loss_4': 0.7807601690292358, 'epoch': 4.94}
{'loss': 0.0387, 'grad_norm': 17.256187438964844, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.033701248466968536, 'loss_2': 0.00496673583984375, 'loss_3': -15.446081161499023, 'loss_4': 0.7952427864074707, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 15:40:09,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:09,478 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:22<1:14:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:16,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020005350932478905, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.375, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016199711710214615, 'eval_loss_2': 0.0038056373596191406, 'eval_loss_3': -18.120914459228516, 'eval_loss_4': 0.7594150304794312, 'epoch': 4.94}
{'loss': 0.0307, 'grad_norm': 8.863693237304688, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.024427764117717743, 'loss_2': 0.00623321533203125, 'loss_3': -15.657493591308594, 'loss_4': 1.2193784713745117, 'epoch': 4.95}
{'loss': 0.0675, 'grad_norm': 25.055137634277344, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.06337296962738037, 'loss_2': 0.00415802001953125, 'loss_3': -15.62672233581543, 'loss_4': 0.8176255226135254, 'epoch': 4.95}
{'loss': 0.0257, 'grad_norm': 6.460888862609863, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.016703542321920395, 'loss_2': 0.0089569091796875, 'loss_3': -15.7715482711792, 'loss_4': 0.6993035674095154, 'epoch': 4.96}
{'loss': 0.0628, 'grad_norm': 21.230844497680664, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.05511711165308952, 'loss_2': 0.00766754150390625, 'loss_3': -15.600685119628906, 'loss_4': 0.6087656021118164, 'epoch': 4.97}
{'loss': 0.0304, 'grad_norm': 11.871744155883789, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.02751779742538929, 'loss_2': 0.002838134765625, 'loss_3': -15.846345901489258, 'loss_4': 1.0129519701004028, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 15:40:16,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:16,816 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:29<1:06:43,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 15:40:23,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021917901933193207, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.645, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0181104838848114, 'eval_loss_2': 0.0038074180483818054, 'eval_loss_3': -18.122760772705078, 'eval_loss_4': 0.7817538976669312, 'epoch': 4.97}
{'loss': 0.0241, 'grad_norm': 7.930050373077393, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.018091494217514992, 'loss_2': 0.005992889404296875, 'loss_3': -15.599061965942383, 'loss_4': 0.7008123397827148, 'epoch': 4.98}
{'loss': 0.1081, 'grad_norm': 23.817867279052734, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.10000912100076675, 'loss_2': 0.008056640625, 'loss_3': -15.606821060180664, 'loss_4': 0.9725440740585327, 'epoch': 4.98}
{'loss': 0.0244, 'grad_norm': 8.630949020385742, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.023237980902194977, 'loss_2': 0.00119781494140625, 'loss_3': -15.833574295043945, 'loss_4': 0.786118745803833, 'epoch': 4.99}
{'loss': 0.0142, 'grad_norm': 6.605465888977051, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.012133989483118057, 'loss_2': 0.0020618438720703125, 'loss_3': -15.866703033447266, 'loss_4': 1.0783469676971436, 'epoch': 4.99}
{'loss': 0.0236, 'grad_norm': 11.434240341186523, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.015661412850022316, 'loss_2': 0.007965087890625, 'loss_3': -15.922051429748535, 'loss_4': 0.5981974601745605, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 15:40:23,794 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:23,794 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:36<1:13:06,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:40:31,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02097981423139572, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.497, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01673395186662674, 'eval_loss_2': 0.004245862364768982, 'eval_loss_3': -18.11081314086914, 'eval_loss_4': 0.8386430144309998, 'epoch': 5.0}
{'loss': 0.0564, 'grad_norm': 13.888020515441895, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.04714052751660347, 'loss_2': 0.00926971435546875, 'loss_3': -15.741157531738281, 'loss_4': 0.7746180295944214, 'epoch': 5.01}
{'loss': 0.0158, 'grad_norm': 5.613511085510254, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.01421415340155363, 'loss_2': 0.001590728759765625, 'loss_3': -15.805545806884766, 'loss_4': 1.0317916870117188, 'epoch': 5.01}
{'loss': 0.0295, 'grad_norm': 9.090615272521973, 'learning_rate': 2.5e-05, 'loss_1': 0.024602631106972694, 'loss_2': 0.004913330078125, 'loss_3': -15.719950675964355, 'loss_4': 0.7465300559997559, 'epoch': 5.02}
{'loss': 0.03, 'grad_norm': 9.735475540161133, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.029637843370437622, 'loss_2': 0.0003256797790527344, 'loss_3': -15.73830795288086, 'loss_4': 0.8813049793243408, 'epoch': 5.02}
{'loss': 0.0325, 'grad_norm': 7.039154529571533, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.023704564198851585, 'loss_2': 0.00881195068359375, 'loss_3': -15.929389953613281, 'loss_4': 0.7463772296905518, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 15:40:31,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:31,171 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:43<1:13:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:40:38,514 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02430535852909088, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.196, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016201766207814217, 'eval_loss_2': 0.008103594183921814, 'eval_loss_3': -18.14304542541504, 'eval_loss_4': 0.8573490977287292, 'epoch': 5.03}
{'loss': 0.0175, 'grad_norm': 7.661893367767334, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.01592155732214451, 'loss_2': 0.001552581787109375, 'loss_3': -15.818073272705078, 'loss_4': 0.8952102661132812, 'epoch': 5.03}
{'loss': 0.041, 'grad_norm': 17.128902435302734, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.03309667482972145, 'loss_2': 0.00792694091796875, 'loss_3': -15.705306053161621, 'loss_4': 0.5768985748291016, 'epoch': 5.04}
{'loss': 0.0321, 'grad_norm': 14.522589683532715, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.029525190591812134, 'loss_2': 0.002590179443359375, 'loss_3': -15.793981552124023, 'loss_4': 1.0476984977722168, 'epoch': 5.05}
{'loss': 0.0446, 'grad_norm': 15.587148666381836, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.03907135874032974, 'loss_2': 0.00551605224609375, 'loss_3': -15.713179588317871, 'loss_4': 1.1583601236343384, 'epoch': 5.05}
{'loss': 0.0387, 'grad_norm': 15.596796989440918, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.033042680472135544, 'loss_2': 0.005645751953125, 'loss_3': -15.811334609985352, 'loss_4': 0.6985591650009155, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 15:40:38,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:38,514 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:51<1:14:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:45,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02066705748438835, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0155818872153759, 'eval_loss_2': 0.005085170269012451, 'eval_loss_3': -18.146663665771484, 'eval_loss_4': 0.8266791701316833, 'epoch': 5.06}
{'loss': 0.0479, 'grad_norm': 14.45942497253418, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.039401616901159286, 'loss_2': 0.008514404296875, 'loss_3': -15.832768440246582, 'loss_4': 1.0661635398864746, 'epoch': 5.06}
{'loss': 0.0507, 'grad_norm': 12.394325256347656, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.04582048952579498, 'loss_2': 0.0048980712890625, 'loss_3': -15.997552871704102, 'loss_4': 0.6128566265106201, 'epoch': 5.07}
{'loss': 0.0414, 'grad_norm': 12.1250581741333, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.03521965444087982, 'loss_2': 0.0061798095703125, 'loss_3': -15.915820121765137, 'loss_4': 0.6128101944923401, 'epoch': 5.08}
{'loss': 0.0396, 'grad_norm': 9.1544189453125, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.02167368307709694, 'loss_2': 0.01788330078125, 'loss_3': -15.958810806274414, 'loss_4': 0.2606867849826813, 'epoch': 5.08}
{'loss': 0.0618, 'grad_norm': 18.5410213470459, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.049942634999752045, 'loss_2': 0.01190185546875, 'loss_3': -15.806330680847168, 'loss_4': 0.8915129899978638, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 15:40:45,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:45,858 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [21:58<1:13:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:53,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020880982279777527, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015956684947013855, 'eval_loss_2': 0.004924297332763672, 'eval_loss_3': -18.156436920166016, 'eval_loss_4': 0.6894341707229614, 'epoch': 5.09}
{'loss': 0.0282, 'grad_norm': 7.41385555267334, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.019324176013469696, 'loss_2': 0.0088958740234375, 'loss_3': -15.823158264160156, 'loss_4': 0.5437014102935791, 'epoch': 5.09}
{'loss': 0.0247, 'grad_norm': 10.378349304199219, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.019410882145166397, 'loss_2': 0.00525665283203125, 'loss_3': -16.000852584838867, 'loss_4': 0.42993050813674927, 'epoch': 5.1}
{'loss': 0.1309, 'grad_norm': 20.222332000732422, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.12838982045650482, 'loss_2': 0.002475738525390625, 'loss_3': -15.731264114379883, 'loss_4': 0.6939181089401245, 'epoch': 5.1}
{'loss': 0.0459, 'grad_norm': 17.13022232055664, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.0453314445912838, 'loss_2': 0.0006160736083984375, 'loss_3': -15.91279411315918, 'loss_4': 0.5647841691970825, 'epoch': 5.11}
{'loss': 0.0168, 'grad_norm': 7.332086563110352, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.012479320168495178, 'loss_2': 0.004322052001953125, 'loss_3': -15.804481506347656, 'loss_4': 0.5038830637931824, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 15:40:53,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:53,195 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:05<1:13:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:00,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02353980392217636, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.51, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.015615605749189854, 'eval_loss_2': 0.007924199104309082, 'eval_loss_3': -18.163646697998047, 'eval_loss_4': 0.5346919298171997, 'epoch': 5.12}
{'loss': 0.0349, 'grad_norm': 11.924452781677246, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.03445959836244583, 'loss_2': 0.0004489421844482422, 'loss_3': -15.79274845123291, 'loss_4': 0.9373946189880371, 'epoch': 5.12}
{'loss': 0.032, 'grad_norm': 6.536797523498535, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.01956685446202755, 'loss_2': 0.01239776611328125, 'loss_3': -15.704933166503906, 'loss_4': 0.5228039026260376, 'epoch': 5.13}
{'loss': 0.0649, 'grad_norm': 18.695297241210938, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.05027318745851517, 'loss_2': 0.0146331787109375, 'loss_3': -15.927154541015625, 'loss_4': 0.31352749466896057, 'epoch': 5.13}
{'loss': 0.1117, 'grad_norm': 23.195072174072266, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.10188745707273483, 'loss_2': 0.009857177734375, 'loss_3': -15.948781967163086, 'loss_4': 0.9991174936294556, 'epoch': 5.14}
{'loss': 0.0323, 'grad_norm': 6.759406566619873, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.016733059659600258, 'loss_2': 0.01556396484375, 'loss_3': -16.04827880859375, 'loss_4': 0.0004254058003425598, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 15:41:00,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:00,547 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:13<1:13:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:07,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030605606734752655, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.349, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016315747052431107, 'eval_loss_2': 0.01428985595703125, 'eval_loss_3': -18.131574630737305, 'eval_loss_4': 0.2765885293483734, 'epoch': 5.15}
{'loss': 0.0451, 'grad_norm': 11.381243705749512, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.02848827838897705, 'loss_2': 0.0166473388671875, 'loss_3': -16.05165672302246, 'loss_4': 0.09566624462604523, 'epoch': 5.15}
{'loss': 0.0256, 'grad_norm': 5.987357139587402, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.015657177194952965, 'loss_2': 0.00997161865234375, 'loss_3': -15.952192306518555, 'loss_4': 0.22722668945789337, 'epoch': 5.16}
{'loss': 0.0373, 'grad_norm': 9.065195083618164, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.023012563586235046, 'loss_2': 0.01430511474609375, 'loss_3': -16.021053314208984, 'loss_4': 0.3753170073032379, 'epoch': 5.16}
{'loss': 0.0605, 'grad_norm': 9.734667778015137, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.04180555045604706, 'loss_2': 0.018707275390625, 'loss_3': -16.089336395263672, 'loss_4': 0.644498884677887, 'epoch': 5.17}
{'loss': 0.0151, 'grad_norm': 6.907785892486572, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.013206777162849903, 'loss_2': 0.0019359588623046875, 'loss_3': -15.98398208618164, 'loss_4': -0.0876712054014206, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 15:41:07,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:07,895 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:20<1:13:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:15,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019025959074497223, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016011187806725502, 'eval_loss_2': 0.00301477313041687, 'eval_loss_3': -18.145788192749023, 'eval_loss_4': 0.28885790705680847, 'epoch': 5.17}
{'loss': 0.0123, 'grad_norm': 6.403299808502197, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.009981382638216019, 'loss_2': 0.002330780029296875, 'loss_3': -15.876083374023438, 'loss_4': 0.07509420067071915, 'epoch': 5.18}
{'loss': 0.0331, 'grad_norm': 20.537050247192383, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.027938473969697952, 'loss_2': 0.0051422119140625, 'loss_3': -15.95520305633545, 'loss_4': 0.2979132831096649, 'epoch': 5.19}
{'loss': 0.0361, 'grad_norm': 14.222615242004395, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.02986714243888855, 'loss_2': 0.006183624267578125, 'loss_3': -15.804746627807617, 'loss_4': 0.2398686408996582, 'epoch': 5.19}
{'loss': 0.0299, 'grad_norm': 9.326739311218262, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.0195847749710083, 'loss_2': 0.010284423828125, 'loss_3': -15.990182876586914, 'loss_4': 0.5924102663993835, 'epoch': 5.2}
{'loss': 0.0463, 'grad_norm': 19.93013572692871, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.03480309993028641, 'loss_2': 0.01151275634765625, 'loss_3': -15.945768356323242, 'loss_4': 0.5026795864105225, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 15:41:15,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:15,232 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:27<1:13:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:22,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02589484117925167, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.832, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015889961272478104, 'eval_loss_2': 0.010004878044128418, 'eval_loss_3': -18.14885902404785, 'eval_loss_4': 0.30890578031539917, 'epoch': 5.2}
{'loss': 0.0519, 'grad_norm': 14.761421203613281, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.040597494691610336, 'loss_2': 0.01125335693359375, 'loss_3': -15.959490776062012, 'loss_4': 0.47572094202041626, 'epoch': 5.21}
{'loss': 0.1392, 'grad_norm': 28.829469680786133, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.12539364397525787, 'loss_2': 0.0138397216796875, 'loss_3': -15.923123359680176, 'loss_4': 0.7580515742301941, 'epoch': 5.22}
{'loss': 0.0844, 'grad_norm': 22.976110458374023, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.07597880810499191, 'loss_2': 0.0084228515625, 'loss_3': -15.93778133392334, 'loss_4': 0.5103063583374023, 'epoch': 5.22}
{'loss': 0.0514, 'grad_norm': 17.798547744750977, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.043527353554964066, 'loss_2': 0.00786590576171875, 'loss_3': -15.777105331420898, 'loss_4': 0.2690497934818268, 'epoch': 5.23}
{'loss': 0.0486, 'grad_norm': 20.289628982543945, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.0446857325732708, 'loss_2': 0.003879547119140625, 'loss_3': -15.801586151123047, 'loss_4': 0.30370157957077026, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 15:41:22,564 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:22,564 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:35<1:13:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:29,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020900828763842583, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016567448154091835, 'eval_loss_2': 0.004333380609750748, 'eval_loss_3': -18.14305877685547, 'eval_loss_4': 0.42557042837142944, 'epoch': 5.23}
{'loss': 0.0276, 'grad_norm': 7.451382637023926, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.017617730423808098, 'loss_2': 0.0100250244140625, 'loss_3': -16.021896362304688, 'loss_4': 0.772943377494812, 'epoch': 5.24}
{'loss': 0.076, 'grad_norm': 27.59425926208496, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.07381833344697952, 'loss_2': 0.002170562744140625, 'loss_3': -15.926132202148438, 'loss_4': 0.7265951633453369, 'epoch': 5.24}
{'loss': 0.0153, 'grad_norm': 8.917176246643066, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.01440152432769537, 'loss_2': 0.0009021759033203125, 'loss_3': -15.926016807556152, 'loss_4': 0.4087405800819397, 'epoch': 5.25}
{'loss': 0.1312, 'grad_norm': 25.973587036132812, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.1291351467370987, 'loss_2': 0.00211334228515625, 'loss_3': -15.949115753173828, 'loss_4': 0.915656328201294, 'epoch': 5.26}
{'loss': 0.0254, 'grad_norm': 9.353409767150879, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.02275463379919529, 'loss_2': 0.0026073455810546875, 'loss_3': -15.98480224609375, 'loss_4': 0.21898490190505981, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 15:41:29,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:29,897 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:42<1:13:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:37,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024623721837997437, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.576, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.016099242493510246, 'eval_loss_2': 0.008524477481842041, 'eval_loss_3': -18.1104679107666, 'eval_loss_4': 0.37842684984207153, 'epoch': 5.26}
{'loss': 0.0227, 'grad_norm': 6.92893123626709, 'learning_rate': 2.475e-05, 'loss_1': 0.017827443778514862, 'loss_2': 0.004825592041015625, 'loss_3': -15.905893325805664, 'loss_4': 0.030982814729213715, 'epoch': 5.27}
{'loss': 0.0417, 'grad_norm': 14.619330406188965, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.0332145094871521, 'loss_2': 0.0084991455078125, 'loss_3': -15.829362869262695, 'loss_4': 0.5669941902160645, 'epoch': 5.27}
{'loss': 0.0245, 'grad_norm': 9.082597732543945, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.019766943529248238, 'loss_2': 0.0047760009765625, 'loss_3': -15.854564666748047, 'loss_4': 0.4163993000984192, 'epoch': 5.28}
{'loss': 0.0525, 'grad_norm': 16.6423397064209, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.05165562778711319, 'loss_2': 0.0008101463317871094, 'loss_3': -15.9391450881958, 'loss_4': 0.5492194890975952, 'epoch': 5.28}
{'loss': 0.0267, 'grad_norm': 10.160575866699219, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.022129373624920845, 'loss_2': 0.004596710205078125, 'loss_3': -15.865751266479492, 'loss_4': 0.4771023392677307, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 15:41:37,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:37,230 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:49<1:13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:44,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024515915662050247, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01835479401051998, 'eval_loss_2': 0.006161123514175415, 'eval_loss_3': -18.096378326416016, 'eval_loss_4': 0.2294640690088272, 'epoch': 5.29}
{'loss': 0.0549, 'grad_norm': 21.97404670715332, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.050517886877059937, 'loss_2': 0.00440216064453125, 'loss_3': -15.714530944824219, 'loss_4': 0.3653451204299927, 'epoch': 5.3}
{'loss': 0.0756, 'grad_norm': 21.025283813476562, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.0695602297782898, 'loss_2': 0.00604248046875, 'loss_3': -15.685051918029785, 'loss_4': 0.1295754611492157, 'epoch': 5.3}
{'loss': 0.0262, 'grad_norm': 8.599593162536621, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.024103330448269844, 'loss_2': 0.002071380615234375, 'loss_3': -15.826543807983398, 'loss_4': 0.17696422338485718, 'epoch': 5.31}
{'loss': 0.0183, 'grad_norm': 6.150951385498047, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.016161683946847916, 'loss_2': 0.0021514892578125, 'loss_3': -15.878766059875488, 'loss_4': 0.18749147653579712, 'epoch': 5.31}
{'loss': 0.0693, 'grad_norm': 15.565393447875977, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.06466371566057205, 'loss_2': 0.00467681884765625, 'loss_3': -15.821106910705566, 'loss_4': 0.08158119022846222, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 15:41:44,564 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:44,564 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [22:57<1:13:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:51,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027280304580926895, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.293, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.02428964152932167, 'eval_loss_2': 0.002990659326314926, 'eval_loss_3': -18.061779022216797, 'eval_loss_4': 0.13660427927970886, 'epoch': 5.32}
{'loss': 0.0176, 'grad_norm': 5.609805107116699, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.015673814341425896, 'loss_2': 0.0019321441650390625, 'loss_3': -15.899116516113281, 'loss_4': 0.2532409429550171, 'epoch': 5.33}
{'loss': 0.0347, 'grad_norm': 12.123093605041504, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.030612431466579437, 'loss_2': 0.00412750244140625, 'loss_3': -15.93199348449707, 'loss_4': -0.18438081443309784, 'epoch': 5.33}
{'loss': 0.0313, 'grad_norm': 8.026640892028809, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.026106037199497223, 'loss_2': 0.00522613525390625, 'loss_3': -15.788719177246094, 'loss_4': 0.06530651450157166, 'epoch': 5.34}
{'loss': 0.0223, 'grad_norm': 7.32811975479126, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.020803943276405334, 'loss_2': 0.001495361328125, 'loss_3': -15.877524375915527, 'loss_4': 0.08497576415538788, 'epoch': 5.34}
{'loss': 0.0344, 'grad_norm': 13.305989265441895, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.029091665521264076, 'loss_2': 0.00528717041015625, 'loss_3': -15.823354721069336, 'loss_4': -0.22756952047348022, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 15:41:51,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:51,905 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:04<1:13:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:59,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03434302657842636, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.064, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.029196076095104218, 'eval_loss_2': 0.0051469504833221436, 'eval_loss_3': -18.03285026550293, 'eval_loss_4': 0.054923538118600845, 'epoch': 5.35}
{'loss': 0.0219, 'grad_norm': 6.532028675079346, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.0193860474973917, 'loss_2': 0.0025272369384765625, 'loss_3': -15.934455871582031, 'loss_4': -0.20910170674324036, 'epoch': 5.35}
{'loss': 0.0257, 'grad_norm': 8.688366889953613, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.02205035835504532, 'loss_2': 0.003658294677734375, 'loss_3': -15.814533233642578, 'loss_4': -0.058533281087875366, 'epoch': 5.36}
{'loss': 0.0294, 'grad_norm': 14.887612342834473, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.02581220120191574, 'loss_2': 0.003631591796875, 'loss_3': -15.829139709472656, 'loss_4': -0.11921177804470062, 'epoch': 5.37}
{'loss': 0.0233, 'grad_norm': 5.85004997253418, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.012249215506017208, 'loss_2': 0.011016845703125, 'loss_3': -15.872542381286621, 'loss_4': -0.4338856339454651, 'epoch': 5.37}
{'loss': 0.0945, 'grad_norm': 19.616191864013672, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.09263553470373154, 'loss_2': 0.0018463134765625, 'loss_3': -15.887925148010254, 'loss_4': 0.34007012844085693, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 15:41:59,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:59,244 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:11<1:12:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:06,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038332290947437286, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.55, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03382064774632454, 'eval_loss_2': 0.004511639475822449, 'eval_loss_3': -18.007503509521484, 'eval_loss_4': -0.10398536920547485, 'epoch': 5.38}
{'loss': 0.0462, 'grad_norm': 12.13713264465332, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.04115833342075348, 'loss_2': 0.0050201416015625, 'loss_3': -15.73221206665039, 'loss_4': 0.0012724921107292175, 'epoch': 5.38}
{'loss': 0.0222, 'grad_norm': 5.970218181610107, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.012295317836105824, 'loss_2': 0.0099029541015625, 'loss_3': -15.795851707458496, 'loss_4': -0.09928096830844879, 'epoch': 5.39}
{'loss': 0.0533, 'grad_norm': 26.28478240966797, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.05233454704284668, 'loss_2': 0.0009765625, 'loss_3': -15.676780700683594, 'loss_4': -0.5516986846923828, 'epoch': 5.4}
{'loss': 0.0275, 'grad_norm': 6.4819512367248535, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.02107992395758629, 'loss_2': 0.0064697265625, 'loss_3': -16.007877349853516, 'loss_4': -0.24846170842647552, 'epoch': 5.4}
{'loss': 0.0356, 'grad_norm': 23.631826400756836, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.0331895649433136, 'loss_2': 0.002437591552734375, 'loss_3': -15.694751739501953, 'loss_4': 0.12046125531196594, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 15:42:06,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:06,577 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:19<1:12:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:13,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04873521625995636, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.04447377845644951, 'eval_loss_2': 0.004261434078216553, 'eval_loss_3': -17.96240997314453, 'eval_loss_4': -0.028318189084529877, 'epoch': 5.41}
{'loss': 0.0333, 'grad_norm': 15.8956880569458, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.02768702246248722, 'loss_2': 0.005657196044921875, 'loss_3': -15.642345428466797, 'loss_4': -0.7205334901809692, 'epoch': 5.41}
{'loss': 0.0097, 'grad_norm': 5.646286487579346, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.008428185246884823, 'loss_2': 0.001251220703125, 'loss_3': -15.631722450256348, 'loss_4': -0.4115946590900421, 'epoch': 5.42}
{'loss': 0.027, 'grad_norm': 7.344886779785156, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.020715879276394844, 'loss_2': 0.00624847412109375, 'loss_3': -15.812833786010742, 'loss_4': -0.24613085389137268, 'epoch': 5.42}
{'loss': 0.02, 'grad_norm': 7.246175289154053, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.01374809630215168, 'loss_2': 0.0062255859375, 'loss_3': -15.8170166015625, 'loss_4': 0.005944561213254929, 'epoch': 5.43}
{'loss': 0.0199, 'grad_norm': 6.984389305114746, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.01888023316860199, 'loss_2': 0.0009889602661132812, 'loss_3': -15.676746368408203, 'loss_4': -0.15108546614646912, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 15:42:13,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:13,912 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:26<1:12:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:21,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06564019620418549, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.06138572096824646, 'eval_loss_2': 0.004254475235939026, 'eval_loss_3': -17.900203704833984, 'eval_loss_4': 0.10392782837152481, 'epoch': 5.44}
{'loss': 0.0136, 'grad_norm': 6.26271390914917, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.01326106395572424, 'loss_2': 0.0003857612609863281, 'loss_3': -15.622272491455078, 'loss_4': 0.20998337864875793, 'epoch': 5.44}
{'loss': 0.0224, 'grad_norm': 9.255411148071289, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.020210053771734238, 'loss_2': 0.002162933349609375, 'loss_3': -15.886819839477539, 'loss_4': 0.06555253267288208, 'epoch': 5.45}
{'loss': 0.048, 'grad_norm': 23.855865478515625, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.04588310047984123, 'loss_2': 0.002132415771484375, 'loss_3': -15.628622055053711, 'loss_4': -0.3199630379676819, 'epoch': 5.45}
{'loss': 0.0522, 'grad_norm': 23.752649307250977, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.051657166332006454, 'loss_2': 0.0005311965942382812, 'loss_3': -15.669326782226562, 'loss_4': 0.441286563873291, 'epoch': 5.46}
{'loss': 0.0347, 'grad_norm': 15.072344779968262, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.029587864875793457, 'loss_2': 0.00510406494140625, 'loss_3': -15.621073722839355, 'loss_4': 0.15189343690872192, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 15:42:21,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:21,251 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:34<1:12:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:28,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05942736566066742, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.65, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0532139390707016, 'eval_loss_2': 0.00621342658996582, 'eval_loss_3': -17.913667678833008, 'eval_loss_4': 0.04110657423734665, 'epoch': 5.47}
{'loss': 0.0419, 'grad_norm': 11.937406539916992, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.03515208512544632, 'loss_2': 0.00679779052734375, 'loss_3': -15.534399032592773, 'loss_4': 0.08710290491580963, 'epoch': 5.47}
{'loss': 0.0302, 'grad_norm': 7.140096187591553, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.01892007328569889, 'loss_2': 0.0113067626953125, 'loss_3': -15.836553573608398, 'loss_4': -0.18403272330760956, 'epoch': 5.48}
{'loss': 0.0219, 'grad_norm': 5.600634574890137, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.012985947541892529, 'loss_2': 0.0089263916015625, 'loss_3': -15.825128555297852, 'loss_4': -0.04637038707733154, 'epoch': 5.48}
{'loss': 0.0486, 'grad_norm': 17.332975387573242, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.045520905405282974, 'loss_2': 0.00307464599609375, 'loss_3': -15.772262573242188, 'loss_4': -0.12382280826568604, 'epoch': 5.49}
{'loss': 0.0605, 'grad_norm': 22.07086753845215, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.05830230191349983, 'loss_2': 0.002216339111328125, 'loss_3': -15.740676879882812, 'loss_4': -0.02063474804162979, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 15:42:28,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:28,590 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:41<1:12:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:35,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.048570819199085236, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04225361719727516, 'eval_loss_2': 0.006317198276519775, 'eval_loss_3': -17.963775634765625, 'eval_loss_4': -0.04144375026226044, 'epoch': 5.49}
{'loss': 0.0333, 'grad_norm': 6.513482570648193, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.019496001303195953, 'loss_2': 0.01380157470703125, 'loss_3': -15.72726058959961, 'loss_4': -0.046089451760053635, 'epoch': 5.5}
{'loss': 0.0345, 'grad_norm': 11.659921646118164, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.028521709144115448, 'loss_2': 0.005950927734375, 'loss_3': -15.960982322692871, 'loss_4': -0.20223510265350342, 'epoch': 5.51}
{'loss': 0.0406, 'grad_norm': 10.481264114379883, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.030476577579975128, 'loss_2': 0.010162353515625, 'loss_3': -15.786327362060547, 'loss_4': -0.5648193359375, 'epoch': 5.51}
{'loss': 0.0224, 'grad_norm': 9.35555648803711, 'learning_rate': 2.45e-05, 'loss_1': 0.02170613594353199, 'loss_2': 0.0006990432739257812, 'loss_3': -15.559396743774414, 'loss_4': 0.02964046597480774, 'epoch': 5.52}
{'loss': 0.0957, 'grad_norm': 19.22507667541504, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.09435009956359863, 'loss_2': 0.00130462646484375, 'loss_3': -15.679709434509277, 'loss_4': -0.42005884647369385, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 15:42:35,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:35,941 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:48<1:12:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:43,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04221591353416443, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03839559480547905, 'eval_loss_2': 0.0038203224539756775, 'eval_loss_3': -17.947860717773438, 'eval_loss_4': -0.33835330605506897, 'epoch': 5.52}
{'loss': 0.1001, 'grad_norm': 19.621152877807617, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.09718269109725952, 'loss_2': 0.0029544830322265625, 'loss_3': -15.927820205688477, 'loss_4': -0.37346768379211426, 'epoch': 5.53}
{'loss': 0.1829, 'grad_norm': 43.85799026489258, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.17884042859077454, 'loss_2': 0.00402069091796875, 'loss_3': -15.655067443847656, 'loss_4': -0.4645238518714905, 'epoch': 5.53}
{'loss': 0.0233, 'grad_norm': 9.293595314025879, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.022764509543776512, 'loss_2': 0.0005526542663574219, 'loss_3': -15.786626815795898, 'loss_4': -0.42552873492240906, 'epoch': 5.54}
{'loss': 0.0188, 'grad_norm': 7.100428581237793, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.01710120029747486, 'loss_2': 0.0016870498657226562, 'loss_3': -15.888679504394531, 'loss_4': -0.4664000868797302, 'epoch': 5.55}
{'loss': 0.0233, 'grad_norm': 7.686192035675049, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.02286091074347496, 'loss_2': 0.0004553794860839844, 'loss_3': -15.853910446166992, 'loss_4': -0.04157701134681702, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 15:42:43,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:43,276 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [23:56<1:12:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:50,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025332560762763023, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.909, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021298643201589584, 'eval_loss_2': 0.00403391569852829, 'eval_loss_3': -18.024667739868164, 'eval_loss_4': -0.5352842211723328, 'epoch': 5.55}
{'loss': 0.0185, 'grad_norm': 6.92366361618042, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.01665445603430271, 'loss_2': 0.0018472671508789062, 'loss_3': -15.432210922241211, 'loss_4': -0.8803176879882812, 'epoch': 5.56}
{'loss': 0.0223, 'grad_norm': 7.540375709533691, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.019544167444109917, 'loss_2': 0.0027675628662109375, 'loss_3': -16.02983856201172, 'loss_4': -0.584417462348938, 'epoch': 5.56}
{'loss': 0.0304, 'grad_norm': 9.615691184997559, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.027004338800907135, 'loss_2': 0.0034027099609375, 'loss_3': -15.876790046691895, 'loss_4': -0.871026873588562, 'epoch': 5.57}
{'loss': 0.0306, 'grad_norm': 10.24736213684082, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.029007146134972572, 'loss_2': 0.0015859603881835938, 'loss_3': -15.630614280700684, 'loss_4': -0.5683859586715698, 'epoch': 5.58}
{'loss': 0.0305, 'grad_norm': 13.177189826965332, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.024629557505249977, 'loss_2': 0.005886077880859375, 'loss_3': -15.909429550170898, 'loss_4': -0.08027365803718567, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 15:42:50,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:50,606 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:03<1:12:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:57,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024860292673110962, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018374713137745857, 'eval_loss_2': 0.006485581398010254, 'eval_loss_3': -18.06500816345215, 'eval_loss_4': -0.4598762094974518, 'epoch': 5.58}
{'loss': 0.0449, 'grad_norm': 17.18230628967285, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.03482374548912048, 'loss_2': 0.01007080078125, 'loss_3': -15.911300659179688, 'loss_4': -0.2613697648048401, 'epoch': 5.59}
{'loss': 0.054, 'grad_norm': 21.06789207458496, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.037891753017902374, 'loss_2': 0.0160980224609375, 'loss_3': -15.845659255981445, 'loss_4': -0.1768215000629425, 'epoch': 5.59}
{'loss': 0.0559, 'grad_norm': 23.08393669128418, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.0509309284389019, 'loss_2': 0.0049896240234375, 'loss_3': -15.714938163757324, 'loss_4': -0.26645949482917786, 'epoch': 5.6}
{'loss': 0.0251, 'grad_norm': 7.471826076507568, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.022126495838165283, 'loss_2': 0.0029430389404296875, 'loss_3': -15.782800674438477, 'loss_4': -0.27234840393066406, 'epoch': 5.6}
{'loss': 0.0289, 'grad_norm': 9.546393394470215, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.02665872313082218, 'loss_2': 0.0022125244140625, 'loss_3': -15.695236206054688, 'loss_4': -0.45512107014656067, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 15:42:57,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:57,940 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:10<1:12:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:05,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02371002733707428, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.018126502633094788, 'eval_loss_2': 0.005583524703979492, 'eval_loss_3': -18.083847045898438, 'eval_loss_4': -0.10216175019741058, 'epoch': 5.61}
{'loss': 0.039, 'grad_norm': 16.609540939331055, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.033349327743053436, 'loss_2': 0.005645751953125, 'loss_3': -15.77078914642334, 'loss_4': 0.04990701749920845, 'epoch': 5.62}
{'loss': 0.0337, 'grad_norm': 9.592885971069336, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.029279066249728203, 'loss_2': 0.00439453125, 'loss_3': -15.772841453552246, 'loss_4': 0.11886920034885406, 'epoch': 5.62}
{'loss': 0.0248, 'grad_norm': 10.144380569458008, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.022180357947945595, 'loss_2': 0.0026035308837890625, 'loss_3': -15.783636093139648, 'loss_4': -0.02989545837044716, 'epoch': 5.63}
{'loss': 0.0176, 'grad_norm': 8.458745002746582, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.016685105860233307, 'loss_2': 0.0009479522705078125, 'loss_3': -15.769763946533203, 'loss_4': 0.03535511717200279, 'epoch': 5.63}
{'loss': 0.0383, 'grad_norm': 12.828385353088379, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.034842491149902344, 'loss_2': 0.0034580230712890625, 'loss_3': -15.585857391357422, 'loss_4': -0.0025343671441078186, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 15:43:05,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:05,271 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:18<1:12:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:12,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026462089270353317, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.884, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019599944353103638, 'eval_loss_2': 0.0068621449172496796, 'eval_loss_3': -18.0845947265625, 'eval_loss_4': 0.1220572292804718, 'epoch': 5.64}
{'loss': 0.0476, 'grad_norm': 9.394495964050293, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.0292326919734478, 'loss_2': 0.0183868408203125, 'loss_3': -15.853960037231445, 'loss_4': 0.054436564445495605, 'epoch': 5.65}
{'loss': 0.0324, 'grad_norm': 11.535667419433594, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.029949728399515152, 'loss_2': 0.00244140625, 'loss_3': -15.731727600097656, 'loss_4': -0.01905093342065811, 'epoch': 5.65}
{'loss': 0.0361, 'grad_norm': 12.750212669372559, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.029615215957164764, 'loss_2': 0.006481170654296875, 'loss_3': -16.039148330688477, 'loss_4': 0.3852907121181488, 'epoch': 5.66}
{'loss': 0.022, 'grad_norm': 6.836222171783447, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.018682897090911865, 'loss_2': 0.00333404541015625, 'loss_3': -15.530546188354492, 'loss_4': 0.06275738775730133, 'epoch': 5.66}
{'loss': 0.0548, 'grad_norm': 16.30455780029297, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.05363764613866806, 'loss_2': 0.0011854171752929688, 'loss_3': -15.720991134643555, 'loss_4': 0.8019235730171204, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 15:43:12,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:12,601 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:25<1:12:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:19,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024159949272871017, 'eval_runtime': 3.8283, 'eval_samples_per_second': 267.48, 'eval_steps_per_second': 4.179, 'eval_loss_1': 0.019482653588056564, 'eval_loss_2': 0.004677295684814453, 'eval_loss_3': -18.13658905029297, 'eval_loss_4': 0.32639390230178833, 'epoch': 5.67}
{'loss': 0.036, 'grad_norm': 7.487189769744873, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.023773251101374626, 'loss_2': 0.01220703125, 'loss_3': -15.70346736907959, 'loss_4': -0.13235533237457275, 'epoch': 5.67}
{'loss': 0.0173, 'grad_norm': 5.350439548492432, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.011023927479982376, 'loss_2': 0.00624847412109375, 'loss_3': -15.881063461303711, 'loss_4': 0.1779724806547165, 'epoch': 5.68}
{'loss': 0.0457, 'grad_norm': 14.383766174316406, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.04339960217475891, 'loss_2': 0.00231170654296875, 'loss_3': -15.816088676452637, 'loss_4': 0.4457550644874573, 'epoch': 5.69}
{'loss': 0.0188, 'grad_norm': 7.069647789001465, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.015961816534399986, 'loss_2': 0.0028247833251953125, 'loss_3': -15.795181274414062, 'loss_4': 0.5433300733566284, 'epoch': 5.69}
{'loss': 0.0232, 'grad_norm': 6.340667247772217, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.01686268113553524, 'loss_2': 0.00630950927734375, 'loss_3': -15.791878700256348, 'loss_4': 0.2585383951663971, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 15:43:19,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:19,973 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:32<1:13:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:43:27,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02205570414662361, 'eval_runtime': 3.991, 'eval_samples_per_second': 256.575, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.01820327900350094, 'eval_loss_2': 0.0038524270057678223, 'eval_loss_3': -18.195175170898438, 'eval_loss_4': 0.41910895705223083, 'epoch': 5.7}
{'loss': 0.0196, 'grad_norm': 6.239805698394775, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.017343267798423767, 'loss_2': 0.002285003662109375, 'loss_3': -15.894074440002441, 'loss_4': 0.2529674172401428, 'epoch': 5.7}
{'loss': 0.0442, 'grad_norm': 15.14222240447998, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.04282494634389877, 'loss_2': 0.0013332366943359375, 'loss_3': -15.831439971923828, 'loss_4': 0.5791314244270325, 'epoch': 5.71}
{'loss': 0.0261, 'grad_norm': 6.749384880065918, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.023441048339009285, 'loss_2': 0.00269317626953125, 'loss_3': -15.609027862548828, 'loss_4': 0.3019281029701233, 'epoch': 5.72}
{'loss': 0.0265, 'grad_norm': 7.571255207061768, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.021181518211960793, 'loss_2': 0.00531768798828125, 'loss_3': -15.943180084228516, 'loss_4': 0.35165077447891235, 'epoch': 5.72}
{'loss': 0.0395, 'grad_norm': 12.763237953186035, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.033725444227457047, 'loss_2': 0.00576019287109375, 'loss_3': -15.672344207763672, 'loss_4': 0.2611999809741974, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 15:43:27,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:27,507 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:40<1:12:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:34,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02507907524704933, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.512, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01967606320977211, 'eval_loss_2': 0.005403012037277222, 'eval_loss_3': -18.19937515258789, 'eval_loss_4': 0.2638840675354004, 'epoch': 5.73}
{'loss': 0.0346, 'grad_norm': 9.271343231201172, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.028776850551366806, 'loss_2': 0.005870819091796875, 'loss_3': -15.910331726074219, 'loss_4': -0.0764608234167099, 'epoch': 5.73}
{'loss': 0.0177, 'grad_norm': 6.279623985290527, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.012821429409086704, 'loss_2': 0.00484466552734375, 'loss_3': -15.850154876708984, 'loss_4': 0.3991459608078003, 'epoch': 5.74}
{'loss': 0.0296, 'grad_norm': 6.680826187133789, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.022480878978967667, 'loss_2': 0.007160186767578125, 'loss_3': -15.823870658874512, 'loss_4': 0.06891551613807678, 'epoch': 5.74}
{'loss': 0.0416, 'grad_norm': 9.263875961303711, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.02896135114133358, 'loss_2': 0.0126190185546875, 'loss_3': -16.029682159423828, 'loss_4': 0.31751739978790283, 'epoch': 5.75}
{'loss': 0.0584, 'grad_norm': 17.16010284423828, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.04514020308852196, 'loss_2': 0.01323699951171875, 'loss_3': -15.941841125488281, 'loss_4': 0.6216108798980713, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 15:43:34,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:34,845 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:47<1:12:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:42,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02479076199233532, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019239064306020737, 'eval_loss_2': 0.005551695823669434, 'eval_loss_3': -18.214475631713867, 'eval_loss_4': 0.19772107899188995, 'epoch': 5.76}
{'loss': 0.0466, 'grad_norm': 10.180902481079102, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.044680267572402954, 'loss_2': 0.0019054412841796875, 'loss_3': -16.058563232421875, 'loss_4': 0.07770681381225586, 'epoch': 5.76}
{'loss': 0.0259, 'grad_norm': 7.845983028411865, 'learning_rate': 2.425e-05, 'loss_1': 0.022738656029105186, 'loss_2': 0.003192901611328125, 'loss_3': -15.929641723632812, 'loss_4': 0.5761388540267944, 'epoch': 5.77}
{'loss': 0.0268, 'grad_norm': 7.536683559417725, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.021919988095760345, 'loss_2': 0.004871368408203125, 'loss_3': -15.891433715820312, 'loss_4': 0.08360692113637924, 'epoch': 5.77}
{'loss': 0.0439, 'grad_norm': 7.987178325653076, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.04151833429932594, 'loss_2': 0.002407073974609375, 'loss_3': -15.904345512390137, 'loss_4': 0.16886356472969055, 'epoch': 5.78}
{'loss': 0.1182, 'grad_norm': 25.781719207763672, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.11536446958780289, 'loss_2': 0.002803802490234375, 'loss_3': -15.881309509277344, 'loss_4': 0.9351357817649841, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 15:43:42,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:42,189 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [24:54<1:11:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:49,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021866969764232635, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01764891855418682, 'eval_loss_2': 0.004218049347400665, 'eval_loss_3': -18.202377319335938, 'eval_loss_4': 0.1527457982301712, 'epoch': 5.78}
{'loss': 0.0437, 'grad_norm': 20.695459365844727, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.040464434772729874, 'loss_2': 0.0031890869140625, 'loss_3': -15.932255744934082, 'loss_4': -0.008866135030984879, 'epoch': 5.79}
{'loss': 0.0182, 'grad_norm': 7.907507419586182, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.016492262482643127, 'loss_2': 0.0017423629760742188, 'loss_3': -16.047395706176758, 'loss_4': 0.31023651361465454, 'epoch': 5.8}
{'loss': 0.0189, 'grad_norm': 10.67499828338623, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.01503845863044262, 'loss_2': 0.003833770751953125, 'loss_3': -15.95389461517334, 'loss_4': 0.6035866141319275, 'epoch': 5.8}
{'loss': 0.0378, 'grad_norm': 11.430526733398438, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.03170580044388771, 'loss_2': 0.006084442138671875, 'loss_3': -15.823187828063965, 'loss_4': 0.07914203405380249, 'epoch': 5.81}
{'loss': 0.0399, 'grad_norm': 19.031469345092773, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.038673385977745056, 'loss_2': 0.0012454986572265625, 'loss_3': -15.814013481140137, 'loss_4': 0.2022925615310669, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 15:43:49,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:49,534 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:02<1:11:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:56,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022181034088134766, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015088498592376709, 'eval_loss_2': 0.007092535495758057, 'eval_loss_3': -18.191631317138672, 'eval_loss_4': 0.2584516108036041, 'epoch': 5.81}
{'loss': 0.0353, 'grad_norm': 10.703361511230469, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.03273514658212662, 'loss_2': 0.00252532958984375, 'loss_3': -15.975159645080566, 'loss_4': 0.5868853330612183, 'epoch': 5.82}
{'loss': 0.0484, 'grad_norm': 11.068034172058105, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.04364718496799469, 'loss_2': 0.004730224609375, 'loss_3': -15.894981384277344, 'loss_4': 0.8288449645042419, 'epoch': 5.83}
{'loss': 0.0241, 'grad_norm': 8.189375877380371, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.02017858810722828, 'loss_2': 0.003875732421875, 'loss_3': -16.086305618286133, 'loss_4': 0.6651400327682495, 'epoch': 5.83}
{'loss': 0.0368, 'grad_norm': 8.151871681213379, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.024864129722118378, 'loss_2': 0.011962890625, 'loss_3': -15.932287216186523, 'loss_4': 0.8742563724517822, 'epoch': 5.84}
{'loss': 0.0294, 'grad_norm': 15.131362915039062, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.02555151656270027, 'loss_2': 0.0038890838623046875, 'loss_3': -15.889880180358887, 'loss_4': 0.9550819993019104, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 15:43:56,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:56,880 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:09<1:11:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:04,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020329127088189125, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01410328783094883, 'eval_loss_2': 0.006225839257240295, 'eval_loss_3': -18.196514129638672, 'eval_loss_4': 0.6332195401191711, 'epoch': 5.84}
{'loss': 0.0438, 'grad_norm': 19.480602264404297, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.040271807461977005, 'loss_2': 0.00347900390625, 'loss_3': -15.981366157531738, 'loss_4': 0.8055476546287537, 'epoch': 5.85}
{'loss': 0.0197, 'grad_norm': 7.441176891326904, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.01825585961341858, 'loss_2': 0.0014400482177734375, 'loss_3': -15.745124816894531, 'loss_4': 0.4044278562068939, 'epoch': 5.85}
{'loss': 0.0348, 'grad_norm': 11.692727088928223, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.03167150542140007, 'loss_2': 0.003143310546875, 'loss_3': -16.032684326171875, 'loss_4': 0.6598176956176758, 'epoch': 5.86}
{'loss': 0.0192, 'grad_norm': 6.085981845855713, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.012912708334624767, 'loss_2': 0.006259918212890625, 'loss_3': -16.034725189208984, 'loss_4': 0.8863189816474915, 'epoch': 5.87}
{'loss': 0.035, 'grad_norm': 14.998384475708008, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.033987876027822495, 'loss_2': 0.0010347366333007812, 'loss_3': -15.84734058380127, 'loss_4': 0.883543074131012, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 15:44:04,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:04,220 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:16<1:11:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:11,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019189709797501564, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014250154606997967, 'eval_loss_2': 0.004939556121826172, 'eval_loss_3': -18.203880310058594, 'eval_loss_4': 0.9651630520820618, 'epoch': 5.87}
{'loss': 0.0335, 'grad_norm': 11.811944961547852, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.028125766664743423, 'loss_2': 0.00533294677734375, 'loss_3': -15.912657737731934, 'loss_4': 1.1197113990783691, 'epoch': 5.88}
{'loss': 0.0269, 'grad_norm': 10.9036865234375, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.02618110179901123, 'loss_2': 0.0006723403930664062, 'loss_3': -15.807320594787598, 'loss_4': 0.8649269342422485, 'epoch': 5.88}
{'loss': 0.015, 'grad_norm': 6.695313453674316, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.014297924935817719, 'loss_2': 0.0006680488586425781, 'loss_3': -16.1221923828125, 'loss_4': 1.418757438659668, 'epoch': 5.89}
{'loss': 0.0534, 'grad_norm': 15.880605697631836, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.04731675237417221, 'loss_2': 0.00604248046875, 'loss_3': -15.98061466217041, 'loss_4': 1.5910835266113281, 'epoch': 5.9}
{'loss': 0.0657, 'grad_norm': 21.45482063293457, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.0594649612903595, 'loss_2': 0.006237030029296875, 'loss_3': -16.033397674560547, 'loss_4': 1.1591851711273193, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 15:44:11,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:11,568 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:24<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:18,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019405651837587357, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.562, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015277822501957417, 'eval_loss_2': 0.004127830266952515, 'eval_loss_3': -18.165897369384766, 'eval_loss_4': 1.230885624885559, 'epoch': 5.9}
{'loss': 0.0396, 'grad_norm': 9.419537544250488, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.038222163915634155, 'loss_2': 0.0013637542724609375, 'loss_3': -15.898435592651367, 'loss_4': 1.332127332687378, 'epoch': 5.91}
{'loss': 0.0737, 'grad_norm': 38.513954162597656, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.07268846780061722, 'loss_2': 0.0010509490966796875, 'loss_3': -15.990715026855469, 'loss_4': 1.6114490032196045, 'epoch': 5.91}
{'loss': 0.0286, 'grad_norm': 11.516651153564453, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.027737906202673912, 'loss_2': 0.0008687973022460938, 'loss_3': -15.909082412719727, 'loss_4': 1.3159046173095703, 'epoch': 5.92}
{'loss': 0.0619, 'grad_norm': 28.30953598022461, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.061818405985832214, 'loss_2': 5.346536636352539e-05, 'loss_3': -15.926094055175781, 'loss_4': 1.4306696653366089, 'epoch': 5.92}
{'loss': 0.0997, 'grad_norm': 29.52161407470703, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.09880878031253815, 'loss_2': 0.0008959770202636719, 'loss_3': -15.736452102661133, 'loss_4': 1.5134154558181763, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 15:44:18,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:18,918 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:31<1:11:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:26,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02089628204703331, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.286, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.016457943245768547, 'eval_loss_2': 0.004438340663909912, 'eval_loss_3': -18.16148567199707, 'eval_loss_4': 1.5419995784759521, 'epoch': 5.93}
{'loss': 0.0875, 'grad_norm': 26.44574737548828, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.08489719033241272, 'loss_2': 0.00261688232421875, 'loss_3': -16.215557098388672, 'loss_4': 2.014047622680664, 'epoch': 5.94}
{'loss': 0.024, 'grad_norm': 8.875079154968262, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.023171531036496162, 'loss_2': 0.0008287429809570312, 'loss_3': -15.81817626953125, 'loss_4': 1.6112202405929565, 'epoch': 5.94}
{'loss': 0.0232, 'grad_norm': 7.174529075622559, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.022738017141819, 'loss_2': 0.0005064010620117188, 'loss_3': -15.769180297851562, 'loss_4': 1.5361745357513428, 'epoch': 5.95}
{'loss': 0.0303, 'grad_norm': 8.835344314575195, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.026639970019459724, 'loss_2': 0.0037021636962890625, 'loss_3': -16.05763816833496, 'loss_4': 1.81766939163208, 'epoch': 5.95}
{'loss': 0.024, 'grad_norm': 12.453794479370117, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.017376668751239777, 'loss_2': 0.006587982177734375, 'loss_3': -15.993748664855957, 'loss_4': 1.4549651145935059, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 15:44:26,269 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:26,269 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:39<1:11:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:33,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02348589152097702, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018258295953273773, 'eval_loss_2': 0.005227595567703247, 'eval_loss_3': -18.15523910522461, 'eval_loss_4': 1.6412075757980347, 'epoch': 5.96}
{'loss': 0.0338, 'grad_norm': 12.30888557434082, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.02726767584681511, 'loss_2': 0.006496429443359375, 'loss_3': -15.890196800231934, 'loss_4': 1.537292242050171, 'epoch': 5.97}
{'loss': 0.0639, 'grad_norm': 34.188926696777344, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.0565815344452858, 'loss_2': 0.00727081298828125, 'loss_3': -16.011531829833984, 'loss_4': 1.9284954071044922, 'epoch': 5.97}
{'loss': 0.0214, 'grad_norm': 7.888035297393799, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.019635871052742004, 'loss_2': 0.00177001953125, 'loss_3': -15.776691436767578, 'loss_4': 1.5573207139968872, 'epoch': 5.98}
{'loss': 0.0214, 'grad_norm': 11.727924346923828, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.02070816047489643, 'loss_2': 0.0007386207580566406, 'loss_3': -15.995314598083496, 'loss_4': 1.1670567989349365, 'epoch': 5.98}
{'loss': 0.0265, 'grad_norm': 8.429228782653809, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.020916476845741272, 'loss_2': 0.0055999755859375, 'loss_3': -15.914854049682617, 'loss_4': 1.376823902130127, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 15:44:33,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:33,631 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:46<1:09:21,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 15:44:40,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01745065115392208, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013143111951649189, 'eval_loss_2': 0.004307538270950317, 'eval_loss_3': -18.14678192138672, 'eval_loss_4': 1.3540446758270264, 'epoch': 5.99}
{'loss': 0.023, 'grad_norm': 7.993597507476807, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.020793333649635315, 'loss_2': 0.002254486083984375, 'loss_3': -15.964391708374023, 'loss_4': 1.2298035621643066, 'epoch': 5.99}
{'loss': 0.0234, 'grad_norm': 24.903005599975586, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.019099988043308258, 'loss_2': 0.004276275634765625, 'loss_3': -15.727783203125, 'loss_4': 1.4701447486877441, 'epoch': 6.0}
{'loss': 0.0277, 'grad_norm': 7.484220504760742, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.011775660328567028, 'loss_2': 0.015899658203125, 'loss_3': -15.923799514770508, 'loss_4': 1.335022211074829, 'epoch': 6.01}
{'loss': 0.0422, 'grad_norm': 10.938984870910645, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.035264212638139725, 'loss_2': 0.00696563720703125, 'loss_3': -15.837702751159668, 'loss_4': 1.4621787071228027, 'epoch': 6.01}
{'loss': 0.0175, 'grad_norm': 7.556363582611084, 'learning_rate': 2.4e-05, 'loss_1': 0.0149679034948349, 'loss_2': 0.002532958984375, 'loss_3': -15.765033721923828, 'loss_4': 1.101491928100586, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 15:44:40,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:40,671 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [25:53<1:10:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:44:48,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01822289638221264, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.65, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01366005651652813, 'eval_loss_2': 0.004562839865684509, 'eval_loss_3': -18.132450103759766, 'eval_loss_4': 0.9919896721839905, 'epoch': 6.02}
{'loss': 0.0287, 'grad_norm': 11.0294771194458, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.02541516162455082, 'loss_2': 0.003326416015625, 'loss_3': -15.83092975616455, 'loss_4': 0.99126136302948, 'epoch': 6.02}
{'loss': 0.0343, 'grad_norm': 12.51438045501709, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.026875464245676994, 'loss_2': 0.00746917724609375, 'loss_3': -16.007720947265625, 'loss_4': 1.292014479637146, 'epoch': 6.03}
{'loss': 0.0236, 'grad_norm': 8.897693634033203, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.017252430319786072, 'loss_2': 0.00634765625, 'loss_3': -15.909226417541504, 'loss_4': 1.098240852355957, 'epoch': 6.03}
{'loss': 0.0174, 'grad_norm': 6.609119415283203, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.01653680019080639, 'loss_2': 0.0008840560913085938, 'loss_3': -15.745336532592773, 'loss_4': 1.321631908416748, 'epoch': 6.04}
{'loss': 0.0223, 'grad_norm': 6.241476535797119, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.014206680469214916, 'loss_2': 0.0081329345703125, 'loss_3': -15.827484130859375, 'loss_4': 1.0550200939178467, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 15:44:48,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:48,007 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:00<1:11:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:55,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0191497802734375, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.488, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013055950403213501, 'eval_loss_2': 0.006093829870223999, 'eval_loss_3': -18.148849487304688, 'eval_loss_4': 0.7707666754722595, 'epoch': 6.05}
{'loss': 0.0323, 'grad_norm': 11.231202125549316, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.02399701438844204, 'loss_2': 0.0082550048828125, 'loss_3': -15.832783699035645, 'loss_4': 0.7845199108123779, 'epoch': 6.05}
{'loss': 0.1034, 'grad_norm': 28.648027420043945, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.09812849014997482, 'loss_2': 0.00525665283203125, 'loss_3': -15.9634370803833, 'loss_4': 1.1320332288742065, 'epoch': 6.06}
{'loss': 0.0338, 'grad_norm': 13.090514183044434, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.03250030428171158, 'loss_2': 0.0012598037719726562, 'loss_3': -15.889840126037598, 'loss_4': 0.6239875555038452, 'epoch': 6.06}
{'loss': 0.0214, 'grad_norm': 10.549131393432617, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.020665569230914116, 'loss_2': 0.0007190704345703125, 'loss_3': -15.897334098815918, 'loss_4': 0.4213833212852478, 'epoch': 6.07}
{'loss': 0.0284, 'grad_norm': 9.491678237915039, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.022968772798776627, 'loss_2': 0.005458831787109375, 'loss_3': -15.87382698059082, 'loss_4': 0.8618330955505371, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 15:44:55,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:55,345 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:08<1:10:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:02,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01796489581465721, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01476813480257988, 'eval_loss_2': 0.0031967610120773315, 'eval_loss_3': -18.103410720825195, 'eval_loss_4': 0.6662750244140625, 'epoch': 6.08}
{'loss': 0.0307, 'grad_norm': 7.270482063293457, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.025325575843453407, 'loss_2': 0.005359649658203125, 'loss_3': -15.718502044677734, 'loss_4': 0.5484011769294739, 'epoch': 6.08}
{'loss': 0.0276, 'grad_norm': 7.0897440910339355, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.020740296691656113, 'loss_2': 0.006839752197265625, 'loss_3': -15.838008880615234, 'loss_4': 0.9669744372367859, 'epoch': 6.09}
{'loss': 0.0197, 'grad_norm': 8.19792366027832, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.01796012930572033, 'loss_2': 0.0017633438110351562, 'loss_3': -15.804875373840332, 'loss_4': 0.6858388185501099, 'epoch': 6.09}
{'loss': 0.022, 'grad_norm': 9.967741012573242, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.020026477053761482, 'loss_2': 0.00197601318359375, 'loss_3': -15.961180686950684, 'loss_4': 0.6458322405815125, 'epoch': 6.1}
{'loss': 0.027, 'grad_norm': 6.271566867828369, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.01905006915330887, 'loss_2': 0.007904052734375, 'loss_3': -15.918008804321289, 'loss_4': 0.026518508791923523, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 15:45:02,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:02,680 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:15<1:10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:10,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03213368356227875, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02372632548213005, 'eval_loss_2': 0.008407354354858398, 'eval_loss_3': -18.06401824951172, 'eval_loss_4': 0.6693660020828247, 'epoch': 6.1}
{'loss': 0.0185, 'grad_norm': 6.058907508850098, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.015965979546308517, 'loss_2': 0.002574920654296875, 'loss_3': -15.760876655578613, 'loss_4': 0.3620339632034302, 'epoch': 6.11}
{'loss': 0.0457, 'grad_norm': 10.322867393493652, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.030487345531582832, 'loss_2': 0.01517486572265625, 'loss_3': -15.83228874206543, 'loss_4': 0.42193472385406494, 'epoch': 6.12}
{'loss': 0.0413, 'grad_norm': 23.356212615966797, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.03997945040464401, 'loss_2': 0.0013256072998046875, 'loss_3': -15.787616729736328, 'loss_4': 0.5970684885978699, 'epoch': 6.12}
{'loss': 0.0462, 'grad_norm': 14.358064651489258, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.03879804536700249, 'loss_2': 0.00737762451171875, 'loss_3': -15.755403518676758, 'loss_4': 0.6282306909561157, 'epoch': 6.13}
{'loss': 0.0194, 'grad_norm': 7.712921619415283, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.018552768975496292, 'loss_2': 0.0008521080017089844, 'loss_3': -15.96042537689209, 'loss_4': 0.9082074761390686, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 15:45:10,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:10,019 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:22<1:10:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:17,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0453682467341423, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.337, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.041672058403491974, 'eval_loss_2': 0.0036961883306503296, 'eval_loss_3': -17.994342803955078, 'eval_loss_4': 0.5570836067199707, 'epoch': 6.13}
{'loss': 0.0155, 'grad_norm': 6.070249557495117, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.014355507679283619, 'loss_2': 0.0011854171752929688, 'loss_3': -15.91707992553711, 'loss_4': 0.4596658945083618, 'epoch': 6.14}
{'loss': 0.0479, 'grad_norm': 16.75119972229004, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.041826024651527405, 'loss_2': 0.0060577392578125, 'loss_3': -15.819477081298828, 'loss_4': 0.5586353540420532, 'epoch': 6.15}
{'loss': 0.0211, 'grad_norm': 11.176109313964844, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.015468568541109562, 'loss_2': 0.00565338134765625, 'loss_3': -16.006589889526367, 'loss_4': 0.4189959466457367, 'epoch': 6.15}
{'loss': 0.0273, 'grad_norm': 6.7653374671936035, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.01704002358019352, 'loss_2': 0.0102386474609375, 'loss_3': -15.895394325256348, 'loss_4': -0.07491452246904373, 'epoch': 6.16}
{'loss': 0.0253, 'grad_norm': 8.388103485107422, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.020028142258524895, 'loss_2': 0.00531005859375, 'loss_3': -15.575994491577148, 'loss_4': 0.4214179515838623, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 15:45:17,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:17,371 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:30<1:10:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:24,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039927028119564056, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.478, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03617752715945244, 'eval_loss_2': 0.0037495046854019165, 'eval_loss_3': -17.975996017456055, 'eval_loss_4': 0.4547264575958252, 'epoch': 6.16}
{'loss': 0.0337, 'grad_norm': 9.751473426818848, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.030589930713176727, 'loss_2': 0.0030670166015625, 'loss_3': -15.692926406860352, 'loss_4': 0.10200527310371399, 'epoch': 6.17}
{'loss': 0.025, 'grad_norm': 8.846274375915527, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.02147171087563038, 'loss_2': 0.003498077392578125, 'loss_3': -15.922748565673828, 'loss_4': 0.7248145341873169, 'epoch': 6.17}
{'loss': 0.0813, 'grad_norm': 22.478261947631836, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.08123546838760376, 'loss_2': 5.4836273193359375e-05, 'loss_3': -15.856853485107422, 'loss_4': 0.5682772994041443, 'epoch': 6.18}
{'loss': 0.0391, 'grad_norm': 12.132756233215332, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.03086240217089653, 'loss_2': 0.00824737548828125, 'loss_3': -15.873641014099121, 'loss_4': 0.5728719830513, 'epoch': 6.19}
{'loss': 0.0174, 'grad_norm': 11.525864601135254, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.01240023598074913, 'loss_2': 0.00499725341796875, 'loss_3': -15.590641021728516, 'loss_4': 0.5142188668251038, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 15:45:24,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:24,711 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:37<1:10:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:32,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03443843871355057, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.731, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.026486940681934357, 'eval_loss_2': 0.007951498031616211, 'eval_loss_3': -17.992156982421875, 'eval_loss_4': 0.6219199299812317, 'epoch': 6.19}
{'loss': 0.033, 'grad_norm': 10.699054718017578, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.0265730582177639, 'loss_2': 0.00640106201171875, 'loss_3': -15.567596435546875, 'loss_4': 0.40988361835479736, 'epoch': 6.2}
{'loss': 0.0161, 'grad_norm': 6.743704319000244, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.012380811385810375, 'loss_2': 0.0037059783935546875, 'loss_3': -15.856135368347168, 'loss_4': 0.256071537733078, 'epoch': 6.2}
{'loss': 0.0214, 'grad_norm': 6.238404273986816, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.012914549559354782, 'loss_2': 0.00844573974609375, 'loss_3': -15.888398170471191, 'loss_4': 0.3973402976989746, 'epoch': 6.21}
{'loss': 0.0222, 'grad_norm': 6.492435455322266, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.012040718458592892, 'loss_2': 0.01019287109375, 'loss_3': -15.887606620788574, 'loss_4': 0.37372270226478577, 'epoch': 6.22}
{'loss': 0.0134, 'grad_norm': 6.904985427856445, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.01198302861303091, 'loss_2': 0.0013723373413085938, 'loss_3': -15.596406936645508, 'loss_4': 0.40116995573043823, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 15:45:32,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:32,049 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:44<1:10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:39,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03160250186920166, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.024616103619337082, 'eval_loss_2': 0.00698639452457428, 'eval_loss_3': -18.039714813232422, 'eval_loss_4': 0.5950652956962585, 'epoch': 6.22}
{'loss': 0.0158, 'grad_norm': 4.9843621253967285, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.006663051433861256, 'loss_2': 0.009124755859375, 'loss_3': -15.935213088989258, 'loss_4': 0.4968664050102234, 'epoch': 6.23}
{'loss': 0.0246, 'grad_norm': 7.47230863571167, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.013180390931665897, 'loss_2': 0.0114593505859375, 'loss_3': -15.676043510437012, 'loss_4': 0.6892008781433105, 'epoch': 6.23}
{'loss': 0.0252, 'grad_norm': 5.843322277069092, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.012900552712380886, 'loss_2': 0.0123443603515625, 'loss_3': -15.743425369262695, 'loss_4': 0.44437628984451294, 'epoch': 6.24}
{'loss': 0.0269, 'grad_norm': 5.377299785614014, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.01046636700630188, 'loss_2': 0.016387939453125, 'loss_3': -15.826190948486328, 'loss_4': 0.5765804648399353, 'epoch': 6.24}
{'loss': 0.0218, 'grad_norm': 8.733688354492188, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.015866387635469437, 'loss_2': 0.00594329833984375, 'loss_3': -15.745573043823242, 'loss_4': 0.9461761713027954, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 15:45:39,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:39,393 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [26:52<1:10:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:46,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03515048697590828, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.025852639228105545, 'eval_loss_2': 0.009297847747802734, 'eval_loss_3': -18.03693199157715, 'eval_loss_4': 0.7888235449790955, 'epoch': 6.25}
{'loss': 0.024, 'grad_norm': 7.681763648986816, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.014736584387719631, 'loss_2': 0.0092315673828125, 'loss_3': -15.71626091003418, 'loss_4': 0.7289671897888184, 'epoch': 6.26}
{'loss': 0.0268, 'grad_norm': 7.602067470550537, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.01664618030190468, 'loss_2': 0.01012420654296875, 'loss_3': -15.730649948120117, 'loss_4': 0.8814358711242676, 'epoch': 6.26}
{'loss': 0.0139, 'grad_norm': 6.670220851898193, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.013835305348038673, 'loss_2': 5.0008296966552734e-05, 'loss_3': -15.794843673706055, 'loss_4': 0.5456668734550476, 'epoch': 6.27}
{'loss': 0.0119, 'grad_norm': 6.444068908691406, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.010195290669798851, 'loss_2': 0.0016574859619140625, 'loss_3': -15.879301071166992, 'loss_4': 0.9150772094726562, 'epoch': 6.27}
{'loss': 0.0363, 'grad_norm': 12.248871803283691, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.02809101901948452, 'loss_2': 0.0081939697265625, 'loss_3': -15.687555313110352, 'loss_4': 1.1642768383026123, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 15:45:46,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:46,742 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [26:59<1:10:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:54,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03601166978478432, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03041914664208889, 'eval_loss_2': 0.005592525005340576, 'eval_loss_3': -17.996606826782227, 'eval_loss_4': 1.03987717628479, 'epoch': 6.28}
{'loss': 0.0166, 'grad_norm': 10.189309120178223, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.014983207918703556, 'loss_2': 0.001575469970703125, 'loss_3': -15.939399719238281, 'loss_4': 0.9259207844734192, 'epoch': 6.28}
{'loss': 0.0192, 'grad_norm': 9.712671279907227, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.017006607726216316, 'loss_2': 0.002166748046875, 'loss_3': -16.105430603027344, 'loss_4': 0.9907363057136536, 'epoch': 6.29}
{'loss': 0.0426, 'grad_norm': 8.946359634399414, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.03200053423643112, 'loss_2': 0.010589599609375, 'loss_3': -15.873533248901367, 'loss_4': 1.145232915878296, 'epoch': 6.3}
{'loss': 0.0443, 'grad_norm': 13.82858657836914, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.03942525386810303, 'loss_2': 0.0048828125, 'loss_3': -15.578948974609375, 'loss_4': 0.6006953716278076, 'epoch': 6.3}
{'loss': 0.0484, 'grad_norm': 19.281417846679688, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.03730907291173935, 'loss_2': 0.01104736328125, 'loss_3': -15.635571479797363, 'loss_4': 1.3062642812728882, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 15:45:54,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:54,095 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:06<1:10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:01,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03469597548246384, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03042631596326828, 'eval_loss_2': 0.004269659519195557, 'eval_loss_3': -18.012941360473633, 'eval_loss_4': 1.090887427330017, 'epoch': 6.31}
{'loss': 0.0842, 'grad_norm': 31.56471061706543, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.07449445873498917, 'loss_2': 0.0097198486328125, 'loss_3': -15.710424423217773, 'loss_4': 1.334168791770935, 'epoch': 6.31}
{'loss': 0.2915, 'grad_norm': 30.6312255859375, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.2862994074821472, 'loss_2': 0.0051727294921875, 'loss_3': -15.659482955932617, 'loss_4': 1.1469677686691284, 'epoch': 6.32}
{'loss': 0.0178, 'grad_norm': 7.238119602203369, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.013451723381876945, 'loss_2': 0.00438690185546875, 'loss_3': -15.665565490722656, 'loss_4': 0.8905479907989502, 'epoch': 6.33}
{'loss': 0.0486, 'grad_norm': 16.831069946289062, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.0484432615339756, 'loss_2': 0.00011026859283447266, 'loss_3': -15.635211944580078, 'loss_4': 1.0664021968841553, 'epoch': 6.33}
{'loss': 0.0175, 'grad_norm': 6.474057674407959, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.013013782911002636, 'loss_2': 0.004482269287109375, 'loss_3': -15.651198387145996, 'loss_4': 1.405088186264038, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 15:46:01,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:01,436 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:14<1:10:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:08,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04040973633527756, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.034472156316041946, 'eval_loss_2': 0.0059375762939453125, 'eval_loss_3': -18.041969299316406, 'eval_loss_4': 1.1805915832519531, 'epoch': 6.34}
{'loss': 0.0524, 'grad_norm': 17.67716407775879, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.0467095822095871, 'loss_2': 0.0057220458984375, 'loss_3': -15.749859809875488, 'loss_4': 0.6866517066955566, 'epoch': 6.34}
{'loss': 0.0182, 'grad_norm': 5.896551132202148, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.014313429594039917, 'loss_2': 0.0039215087890625, 'loss_3': -15.555692672729492, 'loss_4': 0.8705893754959106, 'epoch': 6.35}
{'loss': 0.0197, 'grad_norm': 10.901470184326172, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.01437477208673954, 'loss_2': 0.00528717041015625, 'loss_3': -15.816410064697266, 'loss_4': 0.805479884147644, 'epoch': 6.35}
{'loss': 0.0234, 'grad_norm': 7.870359897613525, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.014124917797744274, 'loss_2': 0.00925445556640625, 'loss_3': -15.775419235229492, 'loss_4': 0.9409736394882202, 'epoch': 6.36}
{'loss': 0.0352, 'grad_norm': 16.134214401245117, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.02586750127375126, 'loss_2': 0.009307861328125, 'loss_3': -15.730393409729004, 'loss_4': 0.9589407444000244, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 15:46:08,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:08,781 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:21<1:10:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:16,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026882518082857132, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021985575556755066, 'eval_loss_2': 0.004896938800811768, 'eval_loss_3': -18.09769058227539, 'eval_loss_4': 1.3479331731796265, 'epoch': 6.37}
{'loss': 0.077, 'grad_norm': 20.92181968688965, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.0701950266957283, 'loss_2': 0.00677490234375, 'loss_3': -15.68597412109375, 'loss_4': 1.6626768112182617, 'epoch': 6.37}
{'loss': 0.0134, 'grad_norm': 5.703746795654297, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.012726265005767345, 'loss_2': 0.00067901611328125, 'loss_3': -15.707926750183105, 'loss_4': 1.5093636512756348, 'epoch': 6.38}
{'loss': 0.0098, 'grad_norm': 5.959945201873779, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.00947666447609663, 'loss_2': 0.0003561973571777344, 'loss_3': -15.92979907989502, 'loss_4': 1.239060640335083, 'epoch': 6.38}
{'loss': 0.035, 'grad_norm': 14.798768043518066, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.033405933529138565, 'loss_2': 0.0015649795532226562, 'loss_3': -15.833131790161133, 'loss_4': 1.4352247714996338, 'epoch': 6.39}
{'loss': 0.0132, 'grad_norm': 5.4661664962768555, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.010731660760939121, 'loss_2': 0.002445220947265625, 'loss_3': -15.633739471435547, 'loss_4': 1.2142856121063232, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 15:46:16,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:16,130 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:28<1:10:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:23,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023434355854988098, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.348, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02071489207446575, 'eval_loss_2': 0.0027194619178771973, 'eval_loss_3': -18.120370864868164, 'eval_loss_4': 1.4802237749099731, 'epoch': 6.4}
{'loss': 0.0493, 'grad_norm': 12.726232528686523, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.04335262253880501, 'loss_2': 0.00589752197265625, 'loss_3': -15.954017639160156, 'loss_4': 1.561147689819336, 'epoch': 6.4}
{'loss': 0.0231, 'grad_norm': 9.758746147155762, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.02204805612564087, 'loss_2': 0.0010557174682617188, 'loss_3': -15.951393127441406, 'loss_4': 1.491854190826416, 'epoch': 6.41}
{'loss': 0.0436, 'grad_norm': 16.731426239013672, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.041305337101221085, 'loss_2': 0.0023097991943359375, 'loss_3': -15.710535049438477, 'loss_4': 1.1297296285629272, 'epoch': 6.41}
{'loss': 0.0206, 'grad_norm': 9.004464149475098, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.020098470151424408, 'loss_2': 0.0004715919494628906, 'loss_3': -15.94427490234375, 'loss_4': 1.3691060543060303, 'epoch': 6.42}
{'loss': 0.0395, 'grad_norm': 10.116952896118164, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.03057216852903366, 'loss_2': 0.00894927978515625, 'loss_3': -15.750469207763672, 'loss_4': 1.6409568786621094, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 15:46:23,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:23,481 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:36<1:10:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:30,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025338144972920418, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020066797733306885, 'eval_loss_2': 0.005271345376968384, 'eval_loss_3': -18.115514755249023, 'eval_loss_4': 1.6660019159317017, 'epoch': 6.42}
{'loss': 0.0349, 'grad_norm': 11.932833671569824, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.029379893094301224, 'loss_2': 0.00547027587890625, 'loss_3': -15.703269004821777, 'loss_4': 1.380922555923462, 'epoch': 6.43}
{'loss': 0.0218, 'grad_norm': 8.072114944458008, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.020618902519345284, 'loss_2': 0.0011463165283203125, 'loss_3': -15.728096008300781, 'loss_4': 1.4679734706878662, 'epoch': 6.44}
{'loss': 0.0509, 'grad_norm': 21.13650894165039, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.04359527677297592, 'loss_2': 0.00727081298828125, 'loss_3': -15.989063262939453, 'loss_4': 2.097323417663574, 'epoch': 6.44}
{'loss': 0.0202, 'grad_norm': 7.091099262237549, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.01666891574859619, 'loss_2': 0.003543853759765625, 'loss_3': -15.720245361328125, 'loss_4': 1.2317965030670166, 'epoch': 6.45}
{'loss': 0.0239, 'grad_norm': 7.821951866149902, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.018987243995070457, 'loss_2': 0.00493621826171875, 'loss_3': -15.73028564453125, 'loss_4': 1.4379353523254395, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 15:46:30,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:30,829 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:43<1:10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:38,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02201981469988823, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01893381029367447, 'eval_loss_2': 0.0030860044062137604, 'eval_loss_3': -18.122434616088867, 'eval_loss_4': 1.6487253904342651, 'epoch': 6.45}
{'loss': 0.0288, 'grad_norm': 8.617934226989746, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.023309288546442986, 'loss_2': 0.005523681640625, 'loss_3': -15.77151107788086, 'loss_4': 1.723923921585083, 'epoch': 6.46}
{'loss': 0.0145, 'grad_norm': 5.577737808227539, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.013679991476237774, 'loss_2': 0.0008301734924316406, 'loss_3': -15.613349914550781, 'loss_4': 1.2942159175872803, 'epoch': 6.47}
{'loss': 0.0305, 'grad_norm': 22.826173782348633, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.028052320703864098, 'loss_2': 0.002437591552734375, 'loss_3': -15.728484153747559, 'loss_4': 1.7545881271362305, 'epoch': 6.47}
{'loss': 0.0331, 'grad_norm': 8.49833869934082, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.02407195419073105, 'loss_2': 0.0090484619140625, 'loss_3': -15.483147621154785, 'loss_4': 1.4502980709075928, 'epoch': 6.48}
{'loss': 0.06, 'grad_norm': 13.99332046508789, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.058958981186151505, 'loss_2': 0.0010662078857421875, 'loss_3': -15.601587295532227, 'loss_4': 1.4269298315048218, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 15:46:38,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:38,185 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [27:50<1:09:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:45,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023517025634646416, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.018358899280428886, 'eval_loss_2': 0.005158126354217529, 'eval_loss_3': -18.131372451782227, 'eval_loss_4': 1.5481555461883545, 'epoch': 6.48}
{'loss': 0.0191, 'grad_norm': 6.563272476196289, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.017645688727498055, 'loss_2': 0.0014801025390625, 'loss_3': -15.788945198059082, 'loss_4': 1.415872573852539, 'epoch': 6.49}
{'loss': 0.0301, 'grad_norm': 7.745363235473633, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.02528976835310459, 'loss_2': 0.004791259765625, 'loss_3': -15.667474746704102, 'loss_4': 1.2754344940185547, 'epoch': 6.49}
{'loss': 0.0647, 'grad_norm': 14.711499214172363, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.05870821326971054, 'loss_2': 0.00603485107421875, 'loss_3': -15.711833953857422, 'loss_4': 1.1069672107696533, 'epoch': 6.5}
{'loss': 0.0139, 'grad_norm': 5.342211723327637, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.010214893147349358, 'loss_2': 0.003662109375, 'loss_3': -15.807276725769043, 'loss_4': 1.1565933227539062, 'epoch': 6.51}
{'loss': 0.0172, 'grad_norm': 8.89233684539795, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.01566411927342415, 'loss_2': 0.0015478134155273438, 'loss_3': -15.902528762817383, 'loss_4': 1.2060205936431885, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 15:46:45,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:45,525 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [27:58<1:09:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:52,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02376432903110981, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.016904311254620552, 'eval_loss_2': 0.006860017776489258, 'eval_loss_3': -18.140043258666992, 'eval_loss_4': 1.2099583148956299, 'epoch': 6.51}
{'loss': 0.0339, 'grad_norm': 8.825154304504395, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.03038874827325344, 'loss_2': 0.0034885406494140625, 'loss_3': -15.913105964660645, 'loss_4': 1.281273365020752, 'epoch': 6.52}
{'loss': 0.0207, 'grad_norm': 5.979562759399414, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.013714117929339409, 'loss_2': 0.007015228271484375, 'loss_3': -15.789693832397461, 'loss_4': 1.0904582738876343, 'epoch': 6.52}
{'loss': 0.0337, 'grad_norm': 14.153692245483398, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.020012997090816498, 'loss_2': 0.013641357421875, 'loss_3': -15.733488082885742, 'loss_4': 1.1664425134658813, 'epoch': 6.53}
{'loss': 0.0893, 'grad_norm': 39.52454376220703, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.06516940891742706, 'loss_2': 0.0241241455078125, 'loss_3': -15.740677833557129, 'loss_4': 1.077846646308899, 'epoch': 6.53}
{'loss': 0.0162, 'grad_norm': 5.0135393142700195, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.01037242729216814, 'loss_2': 0.005832672119140625, 'loss_3': -15.760757446289062, 'loss_4': 1.2488923072814941, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 15:46:52,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:52,869 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:05<1:09:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:00,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024597937241196632, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016909774392843246, 'eval_loss_2': 0.007688164710998535, 'eval_loss_3': -18.128015518188477, 'eval_loss_4': 1.2134332656860352, 'epoch': 6.54}
{'loss': 0.0163, 'grad_norm': 5.333672046661377, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.01152134221047163, 'loss_2': 0.00478363037109375, 'loss_3': -15.872529983520508, 'loss_4': 0.826369047164917, 'epoch': 6.55}
{'loss': 0.0457, 'grad_norm': 10.406071662902832, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.03640991076827049, 'loss_2': 0.009307861328125, 'loss_3': -15.828741073608398, 'loss_4': 1.2436628341674805, 'epoch': 6.55}
{'loss': 0.0246, 'grad_norm': 8.692667007446289, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.01986401155591011, 'loss_2': 0.00478363037109375, 'loss_3': -15.6639404296875, 'loss_4': 0.9055560827255249, 'epoch': 6.56}
{'loss': 0.0303, 'grad_norm': 8.702417373657227, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.025216469541192055, 'loss_2': 0.00510406494140625, 'loss_3': -15.753623962402344, 'loss_4': 1.2206482887268066, 'epoch': 6.56}
{'loss': 0.0181, 'grad_norm': 6.708906650543213, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.015368560329079628, 'loss_2': 0.0027446746826171875, 'loss_3': -15.820154190063477, 'loss_4': 0.9860281348228455, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 15:47:00,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:00,205 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:12<1:09:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:07,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020479440689086914, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016187291592359543, 'eval_loss_2': 0.004292149096727371, 'eval_loss_3': -18.10491180419922, 'eval_loss_4': 1.1268285512924194, 'epoch': 6.57}
{'loss': 0.0289, 'grad_norm': 11.934345245361328, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.026618029922246933, 'loss_2': 0.002262115478515625, 'loss_3': -15.697639465332031, 'loss_4': 0.8554741740226746, 'epoch': 6.58}
{'loss': 0.0314, 'grad_norm': 9.18490982055664, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.029585357755422592, 'loss_2': 0.0017681121826171875, 'loss_3': -15.53857707977295, 'loss_4': 0.6167863607406616, 'epoch': 6.58}
{'loss': 0.0231, 'grad_norm': 5.40955114364624, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.012553995475172997, 'loss_2': 0.01058197021484375, 'loss_3': -15.625970840454102, 'loss_4': 0.942833662033081, 'epoch': 6.59}
{'loss': 0.0691, 'grad_norm': 24.154863357543945, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.06867457926273346, 'loss_2': 0.0004215240478515625, 'loss_3': -15.724390029907227, 'loss_4': 1.2050215005874634, 'epoch': 6.59}
{'loss': 0.0373, 'grad_norm': 8.72507381439209, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.026786938309669495, 'loss_2': 0.01055908203125, 'loss_3': -15.547483444213867, 'loss_4': 0.9553837776184082, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 15:47:07,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:07,548 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:20<1:09:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:14,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01985672116279602, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015421736054122448, 'eval_loss_2': 0.004434984177350998, 'eval_loss_3': -18.106002807617188, 'eval_loss_4': 1.1631642580032349, 'epoch': 6.6}
{'loss': 0.0144, 'grad_norm': 5.2695183753967285, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.013551034964621067, 'loss_2': 0.0008230209350585938, 'loss_3': -15.937591552734375, 'loss_4': 0.9986798763275146, 'epoch': 6.6}
{'loss': 0.033, 'grad_norm': 8.472442626953125, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.02253621630370617, 'loss_2': 0.0104522705078125, 'loss_3': -15.796635627746582, 'loss_4': 1.2016501426696777, 'epoch': 6.61}
{'loss': 0.0344, 'grad_norm': 8.193665504455566, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.02498048171401024, 'loss_2': 0.009429931640625, 'loss_3': -15.478883743286133, 'loss_4': 1.3904486894607544, 'epoch': 6.62}
{'loss': 0.0266, 'grad_norm': 6.5745015144348145, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.015512491576373577, 'loss_2': 0.01113128662109375, 'loss_3': -15.65093994140625, 'loss_4': 1.199631690979004, 'epoch': 6.62}
{'loss': 0.0431, 'grad_norm': 17.970849990844727, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.04126457870006561, 'loss_2': 0.0018463134765625, 'loss_3': -15.665066719055176, 'loss_4': 1.209460735321045, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 15:47:14,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:14,888 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:27<1:09:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:22,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023218804970383644, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015438489615917206, 'eval_loss_2': 0.007780313491821289, 'eval_loss_3': -18.091018676757812, 'eval_loss_4': 1.3209850788116455, 'epoch': 6.63}
{'loss': 0.0927, 'grad_norm': 18.76246452331543, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.08936747163534164, 'loss_2': 0.00330352783203125, 'loss_3': -15.767179489135742, 'loss_4': 1.485437273979187, 'epoch': 6.63}
{'loss': 0.0322, 'grad_norm': 10.61094856262207, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.024585595354437828, 'loss_2': 0.00762939453125, 'loss_3': -15.523744583129883, 'loss_4': 1.036375641822815, 'epoch': 6.64}
{'loss': 0.0248, 'grad_norm': 8.354618072509766, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.018505580723285675, 'loss_2': 0.006328582763671875, 'loss_3': -15.670365333557129, 'loss_4': 1.1596394777297974, 'epoch': 6.65}
{'loss': 0.1615, 'grad_norm': 18.851078033447266, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.149777352809906, 'loss_2': 0.0117340087890625, 'loss_3': -15.64706039428711, 'loss_4': 1.2355886697769165, 'epoch': 6.65}
{'loss': 0.063, 'grad_norm': 23.42170524597168, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.05651894584298134, 'loss_2': 0.006435394287109375, 'loss_3': -15.657297134399414, 'loss_4': 1.1594147682189941, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 15:47:22,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:22,233 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:34<1:09:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:29,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028259487822651863, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.52, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015074462629854679, 'eval_loss_2': 0.01318502426147461, 'eval_loss_3': -18.077190399169922, 'eval_loss_4': 1.395894169807434, 'epoch': 6.66}
{'loss': 0.0469, 'grad_norm': 11.071375846862793, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.03670492395758629, 'loss_2': 0.01019287109375, 'loss_3': -15.796370506286621, 'loss_4': 1.3147096633911133, 'epoch': 6.66}
{'loss': 0.0334, 'grad_norm': 10.033278465270996, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.019240738824009895, 'loss_2': 0.0142059326171875, 'loss_3': -15.751055717468262, 'loss_4': 1.1576550006866455, 'epoch': 6.67}
{'loss': 0.0314, 'grad_norm': 6.4857497215271, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.015407075174152851, 'loss_2': 0.015960693359375, 'loss_3': -15.830053329467773, 'loss_4': 0.8360565900802612, 'epoch': 6.67}
{'loss': 0.0283, 'grad_norm': 13.750327110290527, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.021333545446395874, 'loss_2': 0.006977081298828125, 'loss_3': -15.77446174621582, 'loss_4': 1.5408893823623657, 'epoch': 6.68}
{'loss': 0.0212, 'grad_norm': 6.457235813140869, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.016058219596743584, 'loss_2': 0.00510406494140625, 'loss_3': -15.926648139953613, 'loss_4': 1.0779409408569336, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 15:47:29,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:29,573 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:42<1:09:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:36,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01805787906050682, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.74, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015020843595266342, 'eval_loss_2': 0.0030370354652404785, 'eval_loss_3': -18.049758911132812, 'eval_loss_4': 1.1040862798690796, 'epoch': 6.69}
{'loss': 0.0237, 'grad_norm': 9.277433395385742, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.020901622250676155, 'loss_2': 0.0028171539306640625, 'loss_3': -15.912672996520996, 'loss_4': 0.8739708065986633, 'epoch': 6.69}
{'loss': 0.0368, 'grad_norm': 11.011483192443848, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.033174216747283936, 'loss_2': 0.0035915374755859375, 'loss_3': -16.00060272216797, 'loss_4': 1.0938141345977783, 'epoch': 6.7}
{'loss': 0.0163, 'grad_norm': 5.945961952209473, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.00941549800336361, 'loss_2': 0.006877899169921875, 'loss_3': -15.704269409179688, 'loss_4': 0.3882461190223694, 'epoch': 6.7}
{'loss': 0.041, 'grad_norm': 13.75639533996582, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.03905182704329491, 'loss_2': 0.0019378662109375, 'loss_3': -15.876855850219727, 'loss_4': 1.2087746858596802, 'epoch': 6.71}
{'loss': 0.0459, 'grad_norm': 19.1240177154541, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.04124680906534195, 'loss_2': 0.00469207763671875, 'loss_3': -15.624310493469238, 'loss_4': 1.0154914855957031, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 15:47:36,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:36,916 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [28:49<1:09:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:44,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01915156841278076, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014870431274175644, 'eval_loss_2': 0.004281137138605118, 'eval_loss_3': -18.047718048095703, 'eval_loss_4': 1.0209425687789917, 'epoch': 6.72}
{'loss': 0.0255, 'grad_norm': 7.970150947570801, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.01913337968289852, 'loss_2': 0.006336212158203125, 'loss_3': -15.771439552307129, 'loss_4': 0.7711321115493774, 'epoch': 6.72}
{'loss': 0.0119, 'grad_norm': 5.034936904907227, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.009957821108400822, 'loss_2': 0.001972198486328125, 'loss_3': -15.916045188903809, 'loss_4': 0.4375317692756653, 'epoch': 6.73}
{'loss': 0.0565, 'grad_norm': 7.768563270568848, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.048193108290433884, 'loss_2': 0.0082855224609375, 'loss_3': -15.91083812713623, 'loss_4': 0.2659212350845337, 'epoch': 6.73}
{'loss': 0.2082, 'grad_norm': 25.607757568359375, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.2004626840353012, 'loss_2': 0.0077056884765625, 'loss_3': -15.777055740356445, 'loss_4': 1.2327359914779663, 'epoch': 6.74}
{'loss': 0.0298, 'grad_norm': 8.730217933654785, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.023903027176856995, 'loss_2': 0.00589752197265625, 'loss_3': -15.700701713562012, 'loss_4': 0.6569857597351074, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 15:47:44,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:44,252 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [28:57<1:09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:51,596 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026333792135119438, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01870107278227806, 'eval_loss_2': 0.007632717490196228, 'eval_loss_3': -18.026660919189453, 'eval_loss_4': 0.9262800812721252, 'epoch': 6.74}
{'loss': 0.0219, 'grad_norm': 5.866751670837402, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.015134710818529129, 'loss_2': 0.006755828857421875, 'loss_3': -15.975411415100098, 'loss_4': 0.6306847929954529, 'epoch': 6.75}
{'loss': 0.0353, 'grad_norm': 13.634941101074219, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.02667839452624321, 'loss_2': 0.0086212158203125, 'loss_3': -15.637859344482422, 'loss_4': 0.008424565196037292, 'epoch': 6.76}
{'loss': 0.0407, 'grad_norm': 11.253246307373047, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.03178943693637848, 'loss_2': 0.00893402099609375, 'loss_3': -15.90264892578125, 'loss_4': 0.8519091606140137, 'epoch': 6.76}
{'loss': 0.0384, 'grad_norm': 18.45274543762207, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.033127039670944214, 'loss_2': 0.005275726318359375, 'loss_3': -15.92042350769043, 'loss_4': 0.382820188999176, 'epoch': 6.77}
{'loss': 0.0244, 'grad_norm': 8.43111515045166, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.021458646282553673, 'loss_2': 0.002902984619140625, 'loss_3': -15.70307731628418, 'loss_4': 0.5865442752838135, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 15:47:51,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:51,597 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:04<1:09:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:58,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026348866522312164, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.733, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02214754745364189, 'eval_loss_2': 0.004201322793960571, 'eval_loss_3': -17.98344612121582, 'eval_loss_4': 0.9225051403045654, 'epoch': 6.77}
{'loss': 0.0409, 'grad_norm': 15.109236717224121, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.038747627288103104, 'loss_2': 0.002201080322265625, 'loss_3': -15.895187377929688, 'loss_4': 0.48301395773887634, 'epoch': 6.78}
{'loss': 0.0166, 'grad_norm': 5.795642852783203, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.010920371860265732, 'loss_2': 0.00566864013671875, 'loss_3': -15.81667709350586, 'loss_4': 0.694268524646759, 'epoch': 6.78}
{'loss': 0.0254, 'grad_norm': 5.67379903793335, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.014836964197456837, 'loss_2': 0.0105438232421875, 'loss_3': -15.944744110107422, 'loss_4': 0.9590910077095032, 'epoch': 6.79}
{'loss': 0.0317, 'grad_norm': 12.631792068481445, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.030735015869140625, 'loss_2': 0.0009570121765136719, 'loss_3': -15.948373794555664, 'loss_4': 0.4482555389404297, 'epoch': 6.8}
{'loss': 0.0232, 'grad_norm': 9.585260391235352, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.022668849676847458, 'loss_2': 0.0005540847778320312, 'loss_3': -15.850374221801758, 'loss_4': 0.7654519081115723, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 15:47:58,948 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:58,948 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:11<1:08:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:06,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02670651115477085, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021780677139759064, 'eval_loss_2': 0.004925832152366638, 'eval_loss_3': -18.006088256835938, 'eval_loss_4': 0.9763331413269043, 'epoch': 6.8}
{'loss': 0.0237, 'grad_norm': 6.701462745666504, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.02071569673717022, 'loss_2': 0.003032684326171875, 'loss_3': -15.971395492553711, 'loss_4': 0.8089205622673035, 'epoch': 6.81}
{'loss': 0.0504, 'grad_norm': 14.993557929992676, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.043760426342487335, 'loss_2': 0.006622314453125, 'loss_3': -15.799413681030273, 'loss_4': 0.6488571166992188, 'epoch': 6.81}
{'loss': 0.0157, 'grad_norm': 5.481836795806885, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.012522061355412006, 'loss_2': 0.0031871795654296875, 'loss_3': -15.871905326843262, 'loss_4': 0.4436427652835846, 'epoch': 6.82}
{'loss': 0.02, 'grad_norm': 5.699066638946533, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.013217518106102943, 'loss_2': 0.006744384765625, 'loss_3': -15.740177154541016, 'loss_4': 0.829049825668335, 'epoch': 6.83}
{'loss': 0.0239, 'grad_norm': 8.201870918273926, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.019570007920265198, 'loss_2': 0.0042877197265625, 'loss_3': -16.052841186523438, 'loss_4': 0.05319419503211975, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 15:48:06,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:06,289 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:19<1:08:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:13,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026140809059143066, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.767, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021605942398309708, 'eval_loss_2': 0.004534866660833359, 'eval_loss_3': -17.98760223388672, 'eval_loss_4': 0.911895751953125, 'epoch': 6.83}
{'loss': 0.0196, 'grad_norm': 5.931568145751953, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.011455519124865532, 'loss_2': 0.00818634033203125, 'loss_3': -16.066009521484375, 'loss_4': 0.7123425006866455, 'epoch': 6.84}
{'loss': 0.0304, 'grad_norm': 6.379242897033691, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.017580358311533928, 'loss_2': 0.01282501220703125, 'loss_3': -15.7734375, 'loss_4': 0.8321312665939331, 'epoch': 6.84}
{'loss': 0.0186, 'grad_norm': 6.334284782409668, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.01669658161699772, 'loss_2': 0.0019178390502929688, 'loss_3': -15.95322036743164, 'loss_4': 0.5757048726081848, 'epoch': 6.85}
{'loss': 0.0593, 'grad_norm': 18.719968795776367, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.058448608964681625, 'loss_2': 0.0008029937744140625, 'loss_3': -15.799169540405273, 'loss_4': 1.134577751159668, 'epoch': 6.85}
{'loss': 0.029, 'grad_norm': 10.320167541503906, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.02532007358968258, 'loss_2': 0.00371551513671875, 'loss_3': -15.873900413513184, 'loss_4': 0.4677666425704956, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 15:48:13,627 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:13,627 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:26<1:08:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:20,971 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029640886932611465, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.62, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.023622963577508926, 'eval_loss_2': 0.006017923355102539, 'eval_loss_3': -18.00235939025879, 'eval_loss_4': 0.947115421295166, 'epoch': 6.86}
{'loss': 0.0249, 'grad_norm': 7.605750560760498, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.022486353293061256, 'loss_2': 0.002422332763671875, 'loss_3': -15.68728256225586, 'loss_4': 0.856252133846283, 'epoch': 6.87}
{'loss': 0.1039, 'grad_norm': 17.893953323364258, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.099592424929142, 'loss_2': 0.004344940185546875, 'loss_3': -15.879962921142578, 'loss_4': 1.0122308731079102, 'epoch': 6.87}
{'loss': 0.0185, 'grad_norm': 6.0916314125061035, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.012703309766948223, 'loss_2': 0.0057525634765625, 'loss_3': -16.095352172851562, 'loss_4': 0.7057516574859619, 'epoch': 6.88}
{'loss': 0.0232, 'grad_norm': 6.974281311035156, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.016762923449277878, 'loss_2': 0.0064697265625, 'loss_3': -16.025089263916016, 'loss_4': 0.6926603317260742, 'epoch': 6.88}
{'loss': 0.0326, 'grad_norm': 8.728375434875488, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.02474106475710869, 'loss_2': 0.0078887939453125, 'loss_3': -16.00844955444336, 'loss_4': 0.6033152341842651, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 15:48:20,971 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:20,971 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:33<1:08:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:28,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02914821356534958, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.853, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.025818921625614166, 'eval_loss_2': 0.0033292919397354126, 'eval_loss_3': -17.998363494873047, 'eval_loss_4': 1.0630463361740112, 'epoch': 6.89}
{'loss': 0.0229, 'grad_norm': 6.5333170890808105, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.017602406442165375, 'loss_2': 0.005252838134765625, 'loss_3': -16.14091682434082, 'loss_4': 0.9659450054168701, 'epoch': 6.9}
{'loss': 0.0245, 'grad_norm': 6.928739070892334, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.020776551216840744, 'loss_2': 0.00371551513671875, 'loss_3': -15.772791862487793, 'loss_4': 0.9161517024040222, 'epoch': 6.9}
{'loss': 0.0329, 'grad_norm': 15.120161056518555, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.025856569409370422, 'loss_2': 0.007068634033203125, 'loss_3': -16.004417419433594, 'loss_4': 0.8372864127159119, 'epoch': 6.91}
{'loss': 0.0272, 'grad_norm': 9.452502250671387, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.027118373662233353, 'loss_2': 6.35385513305664e-05, 'loss_3': -16.213626861572266, 'loss_4': 1.1347053050994873, 'epoch': 6.91}
{'loss': 0.0927, 'grad_norm': 30.514076232910156, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.09145309031009674, 'loss_2': 0.0012664794921875, 'loss_3': -15.877593040466309, 'loss_4': 1.0812265872955322, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 15:48:28,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:28,312 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:41<1:08:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:35,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02715495228767395, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.024054963141679764, 'eval_loss_2': 0.003099992871284485, 'eval_loss_3': -18.045581817626953, 'eval_loss_4': 1.0630015134811401, 'epoch': 6.92}
{'loss': 0.0471, 'grad_norm': 15.332229614257812, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.04648774862289429, 'loss_2': 0.0005664825439453125, 'loss_3': -16.01117706298828, 'loss_4': 1.0084571838378906, 'epoch': 6.92}
{'loss': 0.0681, 'grad_norm': 30.2567081451416, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.06799473613500595, 'loss_2': 9.250640869140625e-05, 'loss_3': -15.753690719604492, 'loss_4': 0.8615099191665649, 'epoch': 6.93}
{'loss': 0.0199, 'grad_norm': 9.87904167175293, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.017839817330241203, 'loss_2': 0.002105712890625, 'loss_3': -16.122663497924805, 'loss_4': 0.6965996026992798, 'epoch': 6.94}
{'loss': 0.033, 'grad_norm': 7.854133605957031, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.024737194180488586, 'loss_2': 0.00830078125, 'loss_3': -15.853141784667969, 'loss_4': 0.9279868006706238, 'epoch': 6.94}
{'loss': 0.0314, 'grad_norm': 10.185439109802246, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.026163840666413307, 'loss_2': 0.0052337646484375, 'loss_3': -15.906543731689453, 'loss_4': 0.9729273915290833, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 15:48:35,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:35,660 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [29:48<1:08:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:42,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023917773738503456, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.58, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01947910524904728, 'eval_loss_2': 0.004438668489456177, 'eval_loss_3': -18.053312301635742, 'eval_loss_4': 0.9196556806564331, 'epoch': 6.95}
{'loss': 0.0199, 'grad_norm': 6.839906215667725, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.016954071819782257, 'loss_2': 0.0029392242431640625, 'loss_3': -15.920292854309082, 'loss_4': 0.9882009625434875, 'epoch': 6.95}
{'loss': 0.0302, 'grad_norm': 9.762925148010254, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.022950340062379837, 'loss_2': 0.007232666015625, 'loss_3': -16.063491821289062, 'loss_4': 0.7019436955451965, 'epoch': 6.96}
{'loss': 0.0276, 'grad_norm': 12.095706939697266, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.018841205164790154, 'loss_2': 0.00876617431640625, 'loss_3': -15.770156860351562, 'loss_4': 1.076871633529663, 'epoch': 6.97}
{'loss': 0.0322, 'grad_norm': 11.490553855895996, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.030292417854070663, 'loss_2': 0.001956939697265625, 'loss_3': -16.180904388427734, 'loss_4': 0.8850442171096802, 'epoch': 6.97}
{'loss': 0.0262, 'grad_norm': 9.852673530578613, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.021842598915100098, 'loss_2': 0.00437164306640625, 'loss_3': -15.893871307373047, 'loss_4': 0.6586604714393616, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 15:48:42,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:42,994 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [29:55<1:04:20,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 15:48:50,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01575333997607231, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011993002146482468, 'eval_loss_2': 0.0037603378295898438, 'eval_loss_3': -18.11223602294922, 'eval_loss_4': 0.7732089757919312, 'epoch': 6.98}
{'loss': 0.068, 'grad_norm': 27.80318260192871, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.06243262439966202, 'loss_2': 0.00553131103515625, 'loss_3': -15.909461975097656, 'loss_4': 0.6775810122489929, 'epoch': 6.98}
{'loss': 0.0244, 'grad_norm': 9.514739036560059, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.021962273865938187, 'loss_2': 0.002452850341796875, 'loss_3': -16.02675437927246, 'loss_4': 1.4908742904663086, 'epoch': 6.99}
{'loss': 0.0263, 'grad_norm': 10.733687400817871, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.023745523765683174, 'loss_2': 0.0025634765625, 'loss_3': -16.148422241210938, 'loss_4': 1.1553350687026978, 'epoch': 6.99}
{'loss': 0.0098, 'grad_norm': 8.559308052062988, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.008122004568576813, 'loss_2': 0.0016851425170898438, 'loss_3': -15.877042770385742, 'loss_4': 0.7296991348266602, 'epoch': 7.0}
{'loss': 0.027, 'grad_norm': 9.166749954223633, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.023626651614904404, 'loss_2': 0.003353118896484375, 'loss_3': -16.011093139648438, 'loss_4': 1.0829005241394043, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 15:48:50,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:50,019 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:02<1:07:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:48:57,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01809348165988922, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013985707424581051, 'eval_loss_2': 0.004107773303985596, 'eval_loss_3': -18.19683837890625, 'eval_loss_4': 0.8905158638954163, 'epoch': 7.01}
{'loss': 0.0559, 'grad_norm': 14.942194938659668, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.05248519405722618, 'loss_2': 0.0034465789794921875, 'loss_3': -16.098827362060547, 'loss_4': 1.056780219078064, 'epoch': 7.01}
{'loss': 0.0179, 'grad_norm': 6.132245063781738, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.017274491488933563, 'loss_2': 0.0006570816040039062, 'loss_3': -15.978293418884277, 'loss_4': 1.2452630996704102, 'epoch': 7.02}
{'loss': 0.0159, 'grad_norm': 5.882717132568359, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.011064743623137474, 'loss_2': 0.004852294921875, 'loss_3': -15.976480484008789, 'loss_4': 0.8971787691116333, 'epoch': 7.02}
{'loss': 0.0296, 'grad_norm': 8.145237922668457, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.023746401071548462, 'loss_2': 0.00589752197265625, 'loss_3': -16.04197120666504, 'loss_4': 1.1873869895935059, 'epoch': 7.03}
{'loss': 0.0375, 'grad_norm': 16.3186092376709, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.03686803579330444, 'loss_2': 0.0006694793701171875, 'loss_3': -15.90921401977539, 'loss_4': 0.8949238061904907, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 15:48:57,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:57,359 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:10<1:08:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:04,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018543614074587822, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014429500326514244, 'eval_loss_2': 0.004114113748073578, 'eval_loss_3': -18.191858291625977, 'eval_loss_4': 1.0529367923736572, 'epoch': 7.03}
{'loss': 0.0258, 'grad_norm': 10.60428237915039, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.0255474504083395, 'loss_2': 0.00023221969604492188, 'loss_3': -16.051387786865234, 'loss_4': 1.1375895738601685, 'epoch': 7.04}
{'loss': 0.0381, 'grad_norm': 11.921801567077637, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.03726734220981598, 'loss_2': 0.0008716583251953125, 'loss_3': -16.111459732055664, 'loss_4': 1.1830852031707764, 'epoch': 7.05}
{'loss': 0.0535, 'grad_norm': 13.635966300964355, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.046037718653678894, 'loss_2': 0.00746917724609375, 'loss_3': -16.120105743408203, 'loss_4': 1.4790903329849243, 'epoch': 7.05}
{'loss': 0.0257, 'grad_norm': 6.401856899261475, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.01827313005924225, 'loss_2': 0.0074005126953125, 'loss_3': -15.903680801391602, 'loss_4': 1.3108454942703247, 'epoch': 7.06}
{'loss': 0.0392, 'grad_norm': 12.38784408569336, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.03724130243062973, 'loss_2': 0.001953125, 'loss_3': -16.203161239624023, 'loss_4': 1.3435533046722412, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 15:49:04,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:04,698 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:17<1:08:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:12,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018662679940462112, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014923682436347008, 'eval_loss_2': 0.003738999366760254, 'eval_loss_3': -18.156911849975586, 'eval_loss_4': 1.2256669998168945, 'epoch': 7.06}
{'loss': 0.0448, 'grad_norm': 8.555488586425781, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.04448236897587776, 'loss_2': 0.0003037452697753906, 'loss_3': -16.055492401123047, 'loss_4': 1.7816200256347656, 'epoch': 7.07}
{'loss': 0.0449, 'grad_norm': 22.935224533081055, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.04211115837097168, 'loss_2': 0.002838134765625, 'loss_3': -15.883423805236816, 'loss_4': 1.7451815605163574, 'epoch': 7.08}
{'loss': 0.0211, 'grad_norm': 6.6876749992370605, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.01668683998286724, 'loss_2': 0.00445556640625, 'loss_3': -16.0413818359375, 'loss_4': 1.304631233215332, 'epoch': 7.08}
{'loss': 0.0277, 'grad_norm': 10.01722526550293, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.019035108387470245, 'loss_2': 0.0086822509765625, 'loss_3': -16.048633575439453, 'loss_4': 1.1366591453552246, 'epoch': 7.09}
{'loss': 0.0189, 'grad_norm': 6.5079216957092285, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.012354000471532345, 'loss_2': 0.006565093994140625, 'loss_3': -15.907438278198242, 'loss_4': 1.6802613735198975, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 15:49:12,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:12,040 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:24<1:08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:19,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022669468075037003, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.811, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017564984038472176, 'eval_loss_2': 0.005104482173919678, 'eval_loss_3': -18.105947494506836, 'eval_loss_4': 1.2225432395935059, 'epoch': 7.09}
{'loss': 0.0195, 'grad_norm': 6.893027305603027, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.01432798057794571, 'loss_2': 0.0052032470703125, 'loss_3': -16.280317306518555, 'loss_4': 1.3192884922027588, 'epoch': 7.1}
{'loss': 0.0423, 'grad_norm': 19.69480323791504, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.034054744988679886, 'loss_2': 0.0082855224609375, 'loss_3': -16.040979385375977, 'loss_4': 1.1858900785446167, 'epoch': 7.1}
{'loss': 0.018, 'grad_norm': 7.003460884094238, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.017079418525099754, 'loss_2': 0.00091552734375, 'loss_3': -16.100013732910156, 'loss_4': 1.1337244510650635, 'epoch': 7.11}
{'loss': 0.1522, 'grad_norm': 31.701190948486328, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.15161606669425964, 'loss_2': 0.0005817413330078125, 'loss_3': -15.91514778137207, 'loss_4': 1.2813255786895752, 'epoch': 7.12}
{'loss': 0.0342, 'grad_norm': 11.369476318359375, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.029908647760748863, 'loss_2': 0.004241943359375, 'loss_3': -15.83418083190918, 'loss_4': 1.3256757259368896, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 15:49:19,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:19,391 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:32<1:07:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:26,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030576203018426895, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.953, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.026917995885014534, 'eval_loss_2': 0.003658205270767212, 'eval_loss_3': -18.041397094726562, 'eval_loss_4': 1.2746251821517944, 'epoch': 7.12}
{'loss': 0.0508, 'grad_norm': 15.683659553527832, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.04373377561569214, 'loss_2': 0.007110595703125, 'loss_3': -16.01540756225586, 'loss_4': 1.281129240989685, 'epoch': 7.13}
{'loss': 0.0591, 'grad_norm': 20.992502212524414, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.05245228111743927, 'loss_2': 0.006649017333984375, 'loss_3': -15.88132381439209, 'loss_4': 1.0432512760162354, 'epoch': 7.13}
{'loss': 0.0206, 'grad_norm': 6.479775428771973, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.01993197202682495, 'loss_2': 0.0006799697875976562, 'loss_3': -16.011211395263672, 'loss_4': 1.1274219751358032, 'epoch': 7.14}
{'loss': 0.0286, 'grad_norm': 12.638707160949707, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.026503540575504303, 'loss_2': 0.002079010009765625, 'loss_3': -15.963363647460938, 'loss_4': 1.2464115619659424, 'epoch': 7.15}
{'loss': 0.0312, 'grad_norm': 9.613271713256836, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.027951087802648544, 'loss_2': 0.0032501220703125, 'loss_3': -16.00408172607422, 'loss_4': 1.0409547090530396, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 15:49:26,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:26,722 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:39<1:07:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:34,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032450102269649506, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02931041829288006, 'eval_loss_2': 0.003139682114124298, 'eval_loss_3': -18.02262306213379, 'eval_loss_4': 1.5015767812728882, 'epoch': 7.15}
{'loss': 0.0359, 'grad_norm': 10.248163223266602, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.035046689212322235, 'loss_2': 0.0008258819580078125, 'loss_3': -15.958948135375977, 'loss_4': 0.9893165826797485, 'epoch': 7.16}
{'loss': 0.088, 'grad_norm': 29.30693244934082, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.08571019023656845, 'loss_2': 0.002262115478515625, 'loss_3': -15.79574203491211, 'loss_4': 1.6100499629974365, 'epoch': 7.16}
{'loss': 0.0243, 'grad_norm': 7.953956127166748, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.019299780949950218, 'loss_2': 0.00498199462890625, 'loss_3': -16.080760955810547, 'loss_4': 1.3671035766601562, 'epoch': 7.17}
{'loss': 0.0316, 'grad_norm': 9.583939552307129, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.029952887445688248, 'loss_2': 0.001617431640625, 'loss_3': -15.884430885314941, 'loss_4': 1.3318133354187012, 'epoch': 7.17}
{'loss': 0.0283, 'grad_norm': 9.383576393127441, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.028274379670619965, 'loss_2': 6.9141387939453125e-06, 'loss_3': -16.039369583129883, 'loss_4': 1.4492374658584595, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 15:49:34,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:34,061 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:46<1:07:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:41,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03724832460284233, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.03204060718417168, 'eval_loss_2': 0.005207717418670654, 'eval_loss_3': -18.02754783630371, 'eval_loss_4': 1.43497896194458, 'epoch': 7.18}
{'loss': 0.0387, 'grad_norm': 9.90096378326416, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.03601127117872238, 'loss_2': 0.002696990966796875, 'loss_3': -16.020902633666992, 'loss_4': 1.3785912990570068, 'epoch': 7.19}
{'loss': 0.1155, 'grad_norm': 24.837127685546875, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.11235180497169495, 'loss_2': 0.0031833648681640625, 'loss_3': -16.048185348510742, 'loss_4': 1.1117914915084839, 'epoch': 7.19}
{'loss': 0.0227, 'grad_norm': 6.778093338012695, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.018847184255719185, 'loss_2': 0.003814697265625, 'loss_3': -16.168949127197266, 'loss_4': 1.5296924114227295, 'epoch': 7.2}
{'loss': 0.0264, 'grad_norm': 9.53631591796875, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.025405654683709145, 'loss_2': 0.0010242462158203125, 'loss_3': -16.13355255126953, 'loss_4': 1.0756607055664062, 'epoch': 7.2}
{'loss': 0.0246, 'grad_norm': 7.6374287605285645, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.021244993433356285, 'loss_2': 0.0033206939697265625, 'loss_3': -16.041181564331055, 'loss_4': 1.0185619592666626, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 15:49:41,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:41,401 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [30:54<1:07:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:48,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03178708255290985, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.027287766337394714, 'eval_loss_2': 0.004499316215515137, 'eval_loss_3': -18.071449279785156, 'eval_loss_4': 1.481238603591919, 'epoch': 7.21}
{'loss': 0.0215, 'grad_norm': 9.039899826049805, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.02069617249071598, 'loss_2': 0.0007767677307128906, 'loss_3': -16.078763961791992, 'loss_4': 1.5583454370498657, 'epoch': 7.22}
{'loss': 0.0604, 'grad_norm': 20.6856632232666, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.05341294780373573, 'loss_2': 0.00702667236328125, 'loss_3': -16.224822998046875, 'loss_4': 1.7995836734771729, 'epoch': 7.22}
{'loss': 0.0299, 'grad_norm': 10.176204681396484, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.024835916236042976, 'loss_2': 0.005077362060546875, 'loss_3': -16.066057205200195, 'loss_4': 1.4769651889801025, 'epoch': 7.23}
{'loss': 0.0321, 'grad_norm': 8.505254745483398, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.02822917327284813, 'loss_2': 0.00385284423828125, 'loss_3': -16.162717819213867, 'loss_4': 1.3390958309173584, 'epoch': 7.23}
{'loss': 0.063, 'grad_norm': 22.464900970458984, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.058522023260593414, 'loss_2': 0.00444793701171875, 'loss_3': -15.83521842956543, 'loss_4': 1.0568995475769043, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 15:49:48,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:48,743 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:01<1:07:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:56,085 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03534229099750519, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02949000895023346, 'eval_loss_2': 0.0058522820472717285, 'eval_loss_3': -18.065746307373047, 'eval_loss_4': 1.5298954248428345, 'epoch': 7.24}
{'loss': 0.0313, 'grad_norm': 13.284242630004883, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.025818943977355957, 'loss_2': 0.005451202392578125, 'loss_3': -16.052459716796875, 'loss_4': 1.450223445892334, 'epoch': 7.24}
{'loss': 0.0475, 'grad_norm': 14.480437278747559, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.042515240609645844, 'loss_2': 0.00498199462890625, 'loss_3': -16.015146255493164, 'loss_4': 1.6021764278411865, 'epoch': 7.25}
{'loss': 0.018, 'grad_norm': 8.226543426513672, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.01496281661093235, 'loss_2': 0.0030059814453125, 'loss_3': -16.184988021850586, 'loss_4': 1.0562341213226318, 'epoch': 7.26}
{'loss': 0.0202, 'grad_norm': 6.816494464874268, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.012774677947163582, 'loss_2': 0.007434844970703125, 'loss_3': -15.987741470336914, 'loss_4': 1.3452084064483643, 'epoch': 7.26}
{'loss': 0.0286, 'grad_norm': 11.054222106933594, 'learning_rate': 2.275e-05, 'loss_1': 0.021886002272367477, 'loss_2': 0.006763458251953125, 'loss_3': -15.986100196838379, 'loss_4': 1.3264256715774536, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 15:49:56,085 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:56,085 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:08<1:07:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:03,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037921931594610214, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03293635696172714, 'eval_loss_2': 0.00498557835817337, 'eval_loss_3': -18.033987045288086, 'eval_loss_4': 1.4437028169631958, 'epoch': 7.27}
{'loss': 0.0191, 'grad_norm': 7.246025085449219, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.01561378687620163, 'loss_2': 0.0035305023193359375, 'loss_3': -15.844975471496582, 'loss_4': 1.6561378240585327, 'epoch': 7.27}
{'loss': 0.0193, 'grad_norm': 6.920389652252197, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.017072122544050217, 'loss_2': 0.002197265625, 'loss_3': -15.874208450317383, 'loss_4': 1.025606393814087, 'epoch': 7.28}
{'loss': 0.0216, 'grad_norm': 7.494193077087402, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.011619358323514462, 'loss_2': 0.0099334716796875, 'loss_3': -15.818353652954102, 'loss_4': 0.9041373133659363, 'epoch': 7.28}
{'loss': 0.061, 'grad_norm': 21.279525756835938, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.05845214053988457, 'loss_2': 0.0025615692138671875, 'loss_3': -15.765504837036133, 'loss_4': 0.9303774833679199, 'epoch': 7.29}
{'loss': 0.0252, 'grad_norm': 12.795066833496094, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.02164301648736, 'loss_2': 0.00357818603515625, 'loss_3': -15.781959533691406, 'loss_4': 0.8316200375556946, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 15:50:03,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:03,427 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:16<1:07:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:10,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025440763682127, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01924319379031658, 'eval_loss_2': 0.006197571754455566, 'eval_loss_3': -18.0789852142334, 'eval_loss_4': 1.1397441625595093, 'epoch': 7.3}
{'loss': 0.0205, 'grad_norm': 5.255897521972656, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.010374387726187706, 'loss_2': 0.01016998291015625, 'loss_3': -16.007837295532227, 'loss_4': 1.056689739227295, 'epoch': 7.3}
{'loss': 0.0242, 'grad_norm': 8.466485023498535, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.02146516926586628, 'loss_2': 0.0026950836181640625, 'loss_3': -15.884410858154297, 'loss_4': 1.017996907234192, 'epoch': 7.31}
{'loss': 0.0833, 'grad_norm': 14.743209838867188, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.07155608385801315, 'loss_2': 0.01175689697265625, 'loss_3': -15.744187355041504, 'loss_4': 1.158495306968689, 'epoch': 7.31}
{'loss': 0.0485, 'grad_norm': 25.71495246887207, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.046585336327552795, 'loss_2': 0.001865386962890625, 'loss_3': -15.844809532165527, 'loss_4': 1.5791091918945312, 'epoch': 7.32}
{'loss': 0.0244, 'grad_norm': 9.771515846252441, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.01945030316710472, 'loss_2': 0.004962921142578125, 'loss_3': -15.847253799438477, 'loss_4': 0.5023359060287476, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 15:50:10,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:10,768 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:23<1:07:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:18,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01624063402414322, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.638, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012640891596674919, 'eval_loss_2': 0.0035997405648231506, 'eval_loss_3': -18.123167037963867, 'eval_loss_4': 1.1285414695739746, 'epoch': 7.33}
{'loss': 0.0862, 'grad_norm': 16.444116592407227, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.08366422355175018, 'loss_2': 0.002536773681640625, 'loss_3': -16.062889099121094, 'loss_4': 1.7633085250854492, 'epoch': 7.33}
{'loss': 0.1136, 'grad_norm': 34.65845489501953, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.10749788582324982, 'loss_2': 0.006076812744140625, 'loss_3': -15.990362167358398, 'loss_4': 0.8098225593566895, 'epoch': 7.34}
{'loss': 0.0184, 'grad_norm': 6.694243907928467, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.01754629611968994, 'loss_2': 0.0008306503295898438, 'loss_3': -16.02984619140625, 'loss_4': 0.8586474657058716, 'epoch': 7.34}
{'loss': 0.021, 'grad_norm': 16.58086395263672, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.018901947885751724, 'loss_2': 0.0021381378173828125, 'loss_3': -15.87582015991211, 'loss_4': 1.1454033851623535, 'epoch': 7.35}
{'loss': 0.0287, 'grad_norm': 9.234506607055664, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.023922907188534737, 'loss_2': 0.004749298095703125, 'loss_3': -15.897401809692383, 'loss_4': 1.4320244789123535, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 15:50:18,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:18,109 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:30<1:07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:25,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01771075651049614, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.901, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014375777915120125, 'eval_loss_2': 0.0033349767327308655, 'eval_loss_3': -18.11625862121582, 'eval_loss_4': 1.2118756771087646, 'epoch': 7.35}
{'loss': 0.1062, 'grad_norm': 27.57763671875, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.10583163797855377, 'loss_2': 0.0003941059112548828, 'loss_3': -15.907819747924805, 'loss_4': 1.3496947288513184, 'epoch': 7.36}
{'loss': 0.0304, 'grad_norm': 8.274031639099121, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.02683495171368122, 'loss_2': 0.0035800933837890625, 'loss_3': -15.906451225280762, 'loss_4': 0.9581704139709473, 'epoch': 7.37}
{'loss': 0.0182, 'grad_norm': 7.373147010803223, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.01762457564473152, 'loss_2': 0.0006074905395507812, 'loss_3': -16.03278350830078, 'loss_4': 0.929187536239624, 'epoch': 7.37}
{'loss': 0.0225, 'grad_norm': 7.423951148986816, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.020047616213560104, 'loss_2': 0.0025005340576171875, 'loss_3': -15.928321838378906, 'loss_4': 1.2106618881225586, 'epoch': 7.38}
{'loss': 0.0461, 'grad_norm': 9.372570037841797, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.03974531218409538, 'loss_2': 0.0063934326171875, 'loss_3': -16.07624053955078, 'loss_4': 1.649003028869629, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 15:50:25,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:25,441 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:38<1:07:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:32,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019027838483452797, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.483, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01511953305453062, 'eval_loss_2': 0.003908306360244751, 'eval_loss_3': -18.13021469116211, 'eval_loss_4': 1.0442569255828857, 'epoch': 7.38}
{'loss': 0.0317, 'grad_norm': 9.409071922302246, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.030552413314580917, 'loss_2': 0.001178741455078125, 'loss_3': -16.183300018310547, 'loss_4': 1.4463095664978027, 'epoch': 7.39}
{'loss': 0.0252, 'grad_norm': 6.159543991088867, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.01658475771546364, 'loss_2': 0.0086517333984375, 'loss_3': -15.85183048248291, 'loss_4': 1.0485658645629883, 'epoch': 7.4}
{'loss': 0.0327, 'grad_norm': 9.645095825195312, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.02377248741686344, 'loss_2': 0.00897216796875, 'loss_3': -16.010601043701172, 'loss_4': 0.7788454294204712, 'epoch': 7.4}
{'loss': 0.0171, 'grad_norm': 5.929615020751953, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.014548721723258495, 'loss_2': 0.00255584716796875, 'loss_3': -16.115978240966797, 'loss_4': 1.1998525857925415, 'epoch': 7.41}
{'loss': 0.0518, 'grad_norm': 16.092845916748047, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.049358710646629333, 'loss_2': 0.002391815185546875, 'loss_3': -15.844136238098145, 'loss_4': 1.1617456674575806, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 15:50:32,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:32,783 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:45<1:06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:40,113 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020737573504447937, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.944, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01726381480693817, 'eval_loss_2': 0.0034737586975097656, 'eval_loss_3': -18.113754272460938, 'eval_loss_4': 1.067350149154663, 'epoch': 7.41}
{'loss': 0.0399, 'grad_norm': 12.428008079528809, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.03368515148758888, 'loss_2': 0.00621795654296875, 'loss_3': -15.737113952636719, 'loss_4': 1.1359390020370483, 'epoch': 7.42}
{'loss': 0.0406, 'grad_norm': 12.11950397491455, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.035002700984478, 'loss_2': 0.005645751953125, 'loss_3': -15.921822547912598, 'loss_4': 1.4489192962646484, 'epoch': 7.42}
{'loss': 0.034, 'grad_norm': 12.851273536682129, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.027390001341700554, 'loss_2': 0.006561279296875, 'loss_3': -15.8700590133667, 'loss_4': 1.4541206359863281, 'epoch': 7.43}
{'loss': 0.027, 'grad_norm': 7.794866561889648, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.024607159197330475, 'loss_2': 0.002399444580078125, 'loss_3': -16.10761070251465, 'loss_4': 1.2911113500595093, 'epoch': 7.44}
{'loss': 0.0221, 'grad_norm': 8.904912948608398, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.020586829632520676, 'loss_2': 0.0014820098876953125, 'loss_3': -15.792454719543457, 'loss_4': 1.00994074344635, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 15:50:40,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:40,114 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [31:52<1:06:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:47,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02588759735226631, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.967, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01984630897641182, 'eval_loss_2': 0.006041288375854492, 'eval_loss_3': -18.162090301513672, 'eval_loss_4': 1.2780884504318237, 'epoch': 7.44}
{'loss': 0.0456, 'grad_norm': 9.56286907196045, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.04130048677325249, 'loss_2': 0.0043182373046875, 'loss_3': -15.540064811706543, 'loss_4': 1.3389025926589966, 'epoch': 7.45}
{'loss': 0.0322, 'grad_norm': 9.519787788391113, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.02416534535586834, 'loss_2': 0.00799560546875, 'loss_3': -15.962191581726074, 'loss_4': 1.2435483932495117, 'epoch': 7.45}
{'loss': 0.0195, 'grad_norm': 7.798935890197754, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.018717722967267036, 'loss_2': 0.0007581710815429688, 'loss_3': -16.072444915771484, 'loss_4': 1.4629998207092285, 'epoch': 7.46}
{'loss': 0.0322, 'grad_norm': 11.351333618164062, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.030759405344724655, 'loss_2': 0.0014514923095703125, 'loss_3': -16.10147476196289, 'loss_4': 1.3817594051361084, 'epoch': 7.47}
{'loss': 0.037, 'grad_norm': 10.078831672668457, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.031510330736637115, 'loss_2': 0.00543975830078125, 'loss_3': -15.823515892028809, 'loss_4': 1.126524567604065, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 15:50:47,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:47,446 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:00<1:06:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:54,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021707683801651, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0180960763245821, 'eval_loss_2': 0.0036116093397140503, 'eval_loss_3': -18.15915298461914, 'eval_loss_4': 1.3225263357162476, 'epoch': 7.47}
{'loss': 0.0441, 'grad_norm': 10.4190092086792, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.04327554255723953, 'loss_2': 0.0008645057678222656, 'loss_3': -15.867953300476074, 'loss_4': 1.18739914894104, 'epoch': 7.48}
{'loss': 0.016, 'grad_norm': 8.306085586547852, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.015431294217705727, 'loss_2': 0.0005769729614257812, 'loss_3': -16.168373107910156, 'loss_4': 1.535813331604004, 'epoch': 7.48}
{'loss': 0.0107, 'grad_norm': 4.574849605560303, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.007936952635645866, 'loss_2': 0.0027923583984375, 'loss_3': -16.316177368164062, 'loss_4': 1.4665755033493042, 'epoch': 7.49}
{'loss': 0.0205, 'grad_norm': 8.352072715759277, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.01806885562837124, 'loss_2': 0.00241851806640625, 'loss_3': -15.886054992675781, 'loss_4': 1.1704866886138916, 'epoch': 7.49}
{'loss': 0.0221, 'grad_norm': 7.051785945892334, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.015779348090291023, 'loss_2': 0.00635528564453125, 'loss_3': -15.982287406921387, 'loss_4': 1.1435887813568115, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 15:50:54,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:54,785 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:07<1:06:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:02,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027211960405111313, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.018233412876725197, 'eval_loss_2': 0.008978545665740967, 'eval_loss_3': -18.1524715423584, 'eval_loss_4': 1.2393248081207275, 'epoch': 7.5}
{'loss': 0.036, 'grad_norm': 8.6348237991333, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.025578953325748444, 'loss_2': 0.0103912353515625, 'loss_3': -16.08824920654297, 'loss_4': 1.1104705333709717, 'epoch': 7.51}
{'loss': 0.0581, 'grad_norm': 18.115968704223633, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.04240666329860687, 'loss_2': 0.0156707763671875, 'loss_3': -15.924899101257324, 'loss_4': 1.1423671245574951, 'epoch': 7.51}
{'loss': 0.0289, 'grad_norm': 7.505941390991211, 'learning_rate': 2.25e-05, 'loss_1': 0.017766879871487617, 'loss_2': 0.01110076904296875, 'loss_3': -15.919136047363281, 'loss_4': 1.4391124248504639, 'epoch': 7.52}
{'loss': 0.0365, 'grad_norm': 10.039752960205078, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.026118526235222816, 'loss_2': 0.0103759765625, 'loss_3': -16.011768341064453, 'loss_4': 1.1361901760101318, 'epoch': 7.52}
{'loss': 0.0181, 'grad_norm': 6.419393539428711, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.015578057616949081, 'loss_2': 0.002536773681640625, 'loss_3': -15.96506118774414, 'loss_4': 1.1607437133789062, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 15:51:02,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:02,130 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:14<1:06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:09,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02251327782869339, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.44, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01803082972764969, 'eval_loss_2': 0.004482448101043701, 'eval_loss_3': -18.11605453491211, 'eval_loss_4': 1.209601640701294, 'epoch': 7.53}
{'loss': 0.0277, 'grad_norm': 6.820322513580322, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.016116779297590256, 'loss_2': 0.0116119384765625, 'loss_3': -15.85173511505127, 'loss_4': 1.1715178489685059, 'epoch': 7.53}
{'loss': 0.0267, 'grad_norm': 7.857832908630371, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.022864384576678276, 'loss_2': 0.0038051605224609375, 'loss_3': -15.850335121154785, 'loss_4': 0.8106579184532166, 'epoch': 7.54}
{'loss': 0.0403, 'grad_norm': 13.523761749267578, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.037758760154247284, 'loss_2': 0.00249481201171875, 'loss_3': -15.921998023986816, 'loss_4': 1.6516938209533691, 'epoch': 7.55}
{'loss': 0.0582, 'grad_norm': 15.047988891601562, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.05486985296010971, 'loss_2': 0.0033321380615234375, 'loss_3': -15.805926322937012, 'loss_4': 1.3372581005096436, 'epoch': 7.55}
{'loss': 0.0464, 'grad_norm': 18.0361270904541, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.044324424117803574, 'loss_2': 0.002063751220703125, 'loss_3': -15.73741340637207, 'loss_4': 1.2185155153274536, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 15:51:09,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:09,473 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:22<1:06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:16,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03217656910419464, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01941998302936554, 'eval_loss_2': 0.012756586074829102, 'eval_loss_3': -18.072092056274414, 'eval_loss_4': 1.269339680671692, 'epoch': 7.56}
{'loss': 0.0292, 'grad_norm': 6.558427333831787, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.016245713457465172, 'loss_2': 0.0129241943359375, 'loss_3': -16.06536293029785, 'loss_4': 1.3599084615707397, 'epoch': 7.56}
{'loss': 0.0326, 'grad_norm': 10.484655380249023, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.022146806120872498, 'loss_2': 0.010467529296875, 'loss_3': -15.891812324523926, 'loss_4': 1.2244592905044556, 'epoch': 7.57}
{'loss': 0.0472, 'grad_norm': 13.70248794555664, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.031770579516887665, 'loss_2': 0.0154571533203125, 'loss_3': -15.93799877166748, 'loss_4': 1.195605754852295, 'epoch': 7.58}
{'loss': 0.0218, 'grad_norm': 7.39139986038208, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.014575629495084286, 'loss_2': 0.0071868896484375, 'loss_3': -15.863943099975586, 'loss_4': 0.9629123210906982, 'epoch': 7.58}
{'loss': 0.0372, 'grad_norm': 12.64201545715332, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.025762848556041718, 'loss_2': 0.01139068603515625, 'loss_3': -15.879180908203125, 'loss_4': 1.111703634262085, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 15:51:16,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:16,811 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:29<1:06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:24,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0330943800508976, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.012, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020039532333612442, 'eval_loss_2': 0.013054847717285156, 'eval_loss_3': -18.059066772460938, 'eval_loss_4': 1.0069482326507568, 'epoch': 7.59}
{'loss': 0.0544, 'grad_norm': 11.170880317687988, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.03848215937614441, 'loss_2': 0.0159149169921875, 'loss_3': -15.934333801269531, 'loss_4': 1.058989405632019, 'epoch': 7.59}
{'loss': 0.0302, 'grad_norm': 6.51435661315918, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.02060636319220066, 'loss_2': 0.00960540771484375, 'loss_3': -15.82079029083252, 'loss_4': 0.6800287961959839, 'epoch': 7.6}
{'loss': 0.0375, 'grad_norm': 11.442276000976562, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.027269169688224792, 'loss_2': 0.010223388671875, 'loss_3': -16.066255569458008, 'loss_4': 0.45904579758644104, 'epoch': 7.6}
{'loss': 0.0208, 'grad_norm': 8.678380966186523, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.01994413137435913, 'loss_2': 0.0009036064147949219, 'loss_3': -15.955747604370117, 'loss_4': 0.7280222773551941, 'epoch': 7.61}
{'loss': 0.0316, 'grad_norm': 8.446998596191406, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.022183731198310852, 'loss_2': 0.00939178466796875, 'loss_3': -15.904101371765137, 'loss_4': 0.8414239883422852, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 15:51:24,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:24,140 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:36<1:06:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:31,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023468926548957825, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.864, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019687430933117867, 'eval_loss_2': 0.0037814974784851074, 'eval_loss_3': -18.03059959411621, 'eval_loss_4': 0.9200311899185181, 'epoch': 7.62}
{'loss': 0.0307, 'grad_norm': 11.384775161743164, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.02971591055393219, 'loss_2': 0.0009756088256835938, 'loss_3': -15.778297424316406, 'loss_4': 0.7784961462020874, 'epoch': 7.62}
{'loss': 0.0202, 'grad_norm': 5.906309604644775, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.017726603895425797, 'loss_2': 0.0024871826171875, 'loss_3': -15.87590217590332, 'loss_4': 0.5975059270858765, 'epoch': 7.63}
{'loss': 0.0201, 'grad_norm': 9.827617645263672, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.01930435188114643, 'loss_2': 0.0007810592651367188, 'loss_3': -16.02279281616211, 'loss_4': 0.49028855562210083, 'epoch': 7.63}
{'loss': 0.0238, 'grad_norm': 28.585933685302734, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.022671403363347054, 'loss_2': 0.0011425018310546875, 'loss_3': -15.771354675292969, 'loss_4': 0.8792089223861694, 'epoch': 7.64}
{'loss': 0.0678, 'grad_norm': 21.275630950927734, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.06375887989997864, 'loss_2': 0.00408172607421875, 'loss_3': -15.725927352905273, 'loss_4': 0.6923084855079651, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 15:51:31,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:31,473 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:44<1:06:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:38,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024665316566824913, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.51, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020052755251526833, 'eval_loss_2': 0.004612565040588379, 'eval_loss_3': -18.04644203186035, 'eval_loss_4': 0.8891962766647339, 'epoch': 7.65}
{'loss': 0.0204, 'grad_norm': 27.222246170043945, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.01984340511262417, 'loss_2': 0.0005674362182617188, 'loss_3': -15.626689910888672, 'loss_4': 0.6672798991203308, 'epoch': 7.65}
{'loss': 0.0197, 'grad_norm': 5.367558002471924, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.015392902307212353, 'loss_2': 0.004314422607421875, 'loss_3': -16.079368591308594, 'loss_4': 0.499409019947052, 'epoch': 7.66}
{'loss': 0.0158, 'grad_norm': 7.356064319610596, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.012307998724281788, 'loss_2': 0.00347900390625, 'loss_3': -16.059167861938477, 'loss_4': 0.9228657484054565, 'epoch': 7.66}
{'loss': 0.0296, 'grad_norm': 12.345731735229492, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.026658963412046432, 'loss_2': 0.0029354095458984375, 'loss_3': -16.127500534057617, 'loss_4': 1.053572177886963, 'epoch': 7.67}
{'loss': 0.0227, 'grad_norm': 10.80528736114502, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.01949811540544033, 'loss_2': 0.003223419189453125, 'loss_3': -15.89975357055664, 'loss_4': 1.0627834796905518, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 15:51:38,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:38,819 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [32:51<1:06:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:46,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02668312005698681, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.895, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.02045954205095768, 'eval_loss_2': 0.006223578006029129, 'eval_loss_3': -18.050033569335938, 'eval_loss_4': 1.0201809406280518, 'epoch': 7.67}
{'loss': 0.029, 'grad_norm': 9.040071487426758, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.026966338977217674, 'loss_2': 0.00200653076171875, 'loss_3': -15.610597610473633, 'loss_4': 0.4835593104362488, 'epoch': 7.68}
{'loss': 0.0306, 'grad_norm': 10.089028358459473, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.022011032328009605, 'loss_2': 0.00859832763671875, 'loss_3': -15.946073532104492, 'loss_4': 0.8201212286949158, 'epoch': 7.69}
{'loss': 0.0475, 'grad_norm': 13.272915840148926, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.04172417148947716, 'loss_2': 0.00579071044921875, 'loss_3': -15.881759643554688, 'loss_4': 1.6254031658172607, 'epoch': 7.69}
{'loss': 0.0243, 'grad_norm': 7.5275163650512695, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.02378195710480213, 'loss_2': 0.0005474090576171875, 'loss_3': -15.953563690185547, 'loss_4': 1.184375524520874, 'epoch': 7.7}
{'loss': 0.0278, 'grad_norm': 11.386636734008789, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.02398616261780262, 'loss_2': 0.0037994384765625, 'loss_3': -15.96629810333252, 'loss_4': 1.5572468042373657, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 15:51:46,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:46,155 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [32:58<1:06:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:53,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024104377254843712, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.016921065747737885, 'eval_loss_2': 0.0071833133697509766, 'eval_loss_3': -18.056020736694336, 'eval_loss_4': 1.203492522239685, 'epoch': 7.7}
{'loss': 0.0204, 'grad_norm': 6.664111614227295, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.017778243869543076, 'loss_2': 0.0026397705078125, 'loss_3': -15.93874740600586, 'loss_4': 1.6135798692703247, 'epoch': 7.71}
{'loss': 0.0596, 'grad_norm': 26.389404296875, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.057440102100372314, 'loss_2': 0.00220489501953125, 'loss_3': -15.850725173950195, 'loss_4': 1.0384328365325928, 'epoch': 7.72}
{'loss': 0.0226, 'grad_norm': 8.083732604980469, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.021257322281599045, 'loss_2': 0.0013294219970703125, 'loss_3': -16.117637634277344, 'loss_4': 1.481785774230957, 'epoch': 7.72}
{'loss': 0.0196, 'grad_norm': 6.62548828125, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.01421477273106575, 'loss_2': 0.00536346435546875, 'loss_3': -15.812952041625977, 'loss_4': 1.0993037223815918, 'epoch': 7.73}
{'loss': 0.0138, 'grad_norm': 5.016332626342773, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.00525458250194788, 'loss_2': 0.008544921875, 'loss_3': -15.950387954711914, 'loss_4': 1.2665445804595947, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 15:51:53,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:53,514 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:06<1:07:03,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:52:01,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021514486521482468, 'eval_runtime': 3.992, 'eval_samples_per_second': 256.512, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.016955938190221786, 'eval_loss_2': 0.004558548331260681, 'eval_loss_3': -18.073015213012695, 'eval_loss_4': 1.4820072650909424, 'epoch': 7.73}
{'loss': 0.0199, 'grad_norm': 7.919758319854736, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.017449360340833664, 'loss_2': 0.00246429443359375, 'loss_3': -15.845221519470215, 'loss_4': 1.5529053211212158, 'epoch': 7.74}
{'loss': 0.0325, 'grad_norm': 8.838726997375488, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.03163262456655502, 'loss_2': 0.0008320808410644531, 'loss_3': -16.03253173828125, 'loss_4': 1.694688320159912, 'epoch': 7.74}
{'loss': 0.0246, 'grad_norm': 8.40608024597168, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.02036239393055439, 'loss_2': 0.0042266845703125, 'loss_3': -15.66871452331543, 'loss_4': 1.1747143268585205, 'epoch': 7.75}
{'loss': 0.0315, 'grad_norm': 9.594756126403809, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.02931005135178566, 'loss_2': 0.0022144317626953125, 'loss_3': -15.804128646850586, 'loss_4': 1.4595311880111694, 'epoch': 7.76}
{'loss': 0.0337, 'grad_norm': 6.991974830627441, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.017910828813910484, 'loss_2': 0.0157623291015625, 'loss_3': -15.929147720336914, 'loss_4': 2.0469281673431396, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 15:52:01,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:01,048 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:13<1:06:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:08,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030094316229224205, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018723657354712486, 'eval_loss_2': 0.011370658874511719, 'eval_loss_3': -18.076881408691406, 'eval_loss_4': 1.8051115274429321, 'epoch': 7.76}
{'loss': 0.0416, 'grad_norm': 10.536635398864746, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.03328479081392288, 'loss_2': 0.00836181640625, 'loss_3': -15.85073184967041, 'loss_4': 1.7378222942352295, 'epoch': 7.77}
{'loss': 0.0407, 'grad_norm': 6.908852577209473, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.024532262235879898, 'loss_2': 0.016204833984375, 'loss_3': -15.83604621887207, 'loss_4': 2.2988672256469727, 'epoch': 7.77}
{'loss': 0.0418, 'grad_norm': 9.435051918029785, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.025471046566963196, 'loss_2': 0.0162811279296875, 'loss_3': -15.951715469360352, 'loss_4': 1.8087491989135742, 'epoch': 7.78}
{'loss': 0.0722, 'grad_norm': 29.739749908447266, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.057466428726911545, 'loss_2': 0.014739990234375, 'loss_3': -15.656895637512207, 'loss_4': 2.200364589691162, 'epoch': 7.78}
{'loss': 0.0246, 'grad_norm': 5.914450168609619, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.019692087545990944, 'loss_2': 0.004924774169921875, 'loss_3': -15.93005657196045, 'loss_4': 1.9196062088012695, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 15:52:08,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:08,396 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:21<1:06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:15,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03108992800116539, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021772410720586777, 'eval_loss_2': 0.009317517280578613, 'eval_loss_3': -18.049959182739258, 'eval_loss_4': 1.9759299755096436, 'epoch': 7.79}
{'loss': 0.0277, 'grad_norm': 6.847930908203125, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.015559514053165913, 'loss_2': 0.01216888427734375, 'loss_3': -15.75126838684082, 'loss_4': 1.5272483825683594, 'epoch': 7.8}
{'loss': 0.0402, 'grad_norm': 22.566377639770508, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.03762326389551163, 'loss_2': 0.00261688232421875, 'loss_3': -15.850724220275879, 'loss_4': 2.0800888538360596, 'epoch': 7.8}
{'loss': 0.1176, 'grad_norm': 13.330697059631348, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.1169317364692688, 'loss_2': 0.0006608963012695312, 'loss_3': -15.488187789916992, 'loss_4': 1.5852036476135254, 'epoch': 7.81}
{'loss': 0.0158, 'grad_norm': 5.690786361694336, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.01156127080321312, 'loss_2': 0.004192352294921875, 'loss_3': -15.834175109863281, 'loss_4': 1.855061411857605, 'epoch': 7.81}
{'loss': 0.0208, 'grad_norm': 6.856158256530762, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.017723066732287407, 'loss_2': 0.0030517578125, 'loss_3': -15.832106590270996, 'loss_4': 1.3906803131103516, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 15:52:15,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:15,743 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:28<1:05:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:23,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03916165232658386, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.817, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.03373667597770691, 'eval_loss_2': 0.005424976348876953, 'eval_loss_3': -17.999055862426758, 'eval_loss_4': 2.000479221343994, 'epoch': 7.82}
{'loss': 0.0192, 'grad_norm': 8.019255638122559, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.018713176250457764, 'loss_2': 0.0005054473876953125, 'loss_3': -15.991938591003418, 'loss_4': 1.6154296398162842, 'epoch': 7.83}
{'loss': 0.0223, 'grad_norm': 7.194009780883789, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.01616489514708519, 'loss_2': 0.006103515625, 'loss_3': -15.894124984741211, 'loss_4': 1.556721568107605, 'epoch': 7.83}
{'loss': 0.0618, 'grad_norm': 20.31298828125, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.04707592353224754, 'loss_2': 0.014739990234375, 'loss_3': -15.635316848754883, 'loss_4': 1.6512932777404785, 'epoch': 7.84}
{'loss': 0.0284, 'grad_norm': 8.670394897460938, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.022796079516410828, 'loss_2': 0.005615234375, 'loss_3': -15.857852935791016, 'loss_4': 1.4943914413452148, 'epoch': 7.84}
{'loss': 0.0653, 'grad_norm': 22.29050636291504, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.06268280744552612, 'loss_2': 0.002643585205078125, 'loss_3': -15.734454154968262, 'loss_4': 2.079251289367676, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 15:52:23,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:23,089 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:35<1:05:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:30,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05039960891008377, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.046814993023872375, 'eval_loss_2': 0.003584623336791992, 'eval_loss_3': -17.956485748291016, 'eval_loss_4': 2.2748990058898926, 'epoch': 7.85}
{'loss': 0.0652, 'grad_norm': 18.35798454284668, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.06402673572301865, 'loss_2': 0.001220703125, 'loss_3': -15.888230323791504, 'loss_4': 2.1647591590881348, 'epoch': 7.85}
{'loss': 0.0334, 'grad_norm': 9.889963150024414, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.029247280210256577, 'loss_2': 0.00412750244140625, 'loss_3': -15.752506256103516, 'loss_4': 1.7200005054473877, 'epoch': 7.86}
{'loss': 0.0171, 'grad_norm': 5.791409492492676, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.015065058134496212, 'loss_2': 0.002017974853515625, 'loss_3': -15.84950065612793, 'loss_4': 1.912556767463684, 'epoch': 7.87}
{'loss': 0.0184, 'grad_norm': 6.485111713409424, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.015007097274065018, 'loss_2': 0.003414154052734375, 'loss_3': -15.933963775634766, 'loss_4': 2.1434404850006104, 'epoch': 7.87}
{'loss': 0.1242, 'grad_norm': 39.75174331665039, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.12417562305927277, 'loss_2': 3.9458274841308594e-05, 'loss_3': -15.669032096862793, 'loss_4': 1.8542826175689697, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 15:52:30,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:30,442 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:43<1:05:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:37,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03697257861495018, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03164178133010864, 'eval_loss_2': 0.005330801010131836, 'eval_loss_3': -17.98550796508789, 'eval_loss_4': 2.3102822303771973, 'epoch': 7.88}
{'loss': 0.0208, 'grad_norm': 4.809178352355957, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.009603402577340603, 'loss_2': 0.01123809814453125, 'loss_3': -15.935798645019531, 'loss_4': 2.4504032135009766, 'epoch': 7.88}
{'loss': 0.0346, 'grad_norm': 8.430529594421387, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.02056656777858734, 'loss_2': 0.0140380859375, 'loss_3': -15.957762718200684, 'loss_4': 2.4959616661071777, 'epoch': 7.89}
{'loss': 0.0236, 'grad_norm': 6.144732475280762, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.017133070155978203, 'loss_2': 0.00646209716796875, 'loss_3': -15.79292106628418, 'loss_4': 1.7114264965057373, 'epoch': 7.9}
{'loss': 0.0115, 'grad_norm': 5.638300895690918, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.01100216992199421, 'loss_2': 0.0005388259887695312, 'loss_3': -15.83765983581543, 'loss_4': 2.077638626098633, 'epoch': 7.9}
{'loss': 0.0178, 'grad_norm': 11.932418823242188, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.017645614221692085, 'loss_2': 0.00013637542724609375, 'loss_3': -15.764162063598633, 'loss_4': 1.9905102252960205, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 15:52:37,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:37,791 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:47<1:05:47,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:52:41,592 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360
[INFO|configuration_utils.py:420] 2025-01-21 15:52:41,593 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360/config.json                                                                            
{'eval_loss': 0.014856802299618721, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011273541487753391, 'eval_loss_2': 0.003583259880542755, 'eval_loss_3': -18.09876251220703, 'eval_loss_4': 2.4233975410461426, 'epoch': 7.91}
[INFO|modeling_utils.py:2988] 2025-01-21 15:52:42,072 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:52:42,074 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:52:42,074 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:52:42,895 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-645] due to args.save_total_limit
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [33:51<1:11:58,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:52:46,531 >>
{'loss': 0.0208, 'grad_norm': 6.314789295196533, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.014295516535639763, 'loss_2': 0.006500244140625, 'loss_3': -15.76004695892334, 'loss_4': 2.00441837310791, 'epoch': 7.91}
{'loss': 0.0295, 'grad_norm': 11.745610237121582, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.025816606357693672, 'loss_2': 0.00363922119140625, 'loss_3': -15.765380859375, 'loss_4': 2.333132266998291, 'epoch': 7.92}
{'loss': 0.0636, 'grad_norm': 19.538372039794922, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.0532437339425087, 'loss_2': 0.01031494140625, 'loss_3': -15.83755111694336, 'loss_4': 2.858473777770996, 'epoch': 7.92}
{'loss': 0.0314, 'grad_norm': 9.329928398132324, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.025010989978909492, 'loss_2': 0.00637054443359375, 'loss_3': -15.965063095092773, 'loss_4': 2.3016011714935303, 'epoch': 7.93}
{'loss': 0.0282, 'grad_norm': 10.563870429992676, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.02223566174507141, 'loss_2': 0.0059967041015625, 'loss_3': -15.567586898803711, 'loss_4': 2.779702663421631, 'epoch': 7.94}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:52:46,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:46,531 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [33:59<1:06:38,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:52:53,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022791758179664612, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011114493012428284, 'eval_loss_2': 0.011677265167236328, 'eval_loss_3': -18.12437629699707, 'eval_loss_4': 2.533477306365967, 'epoch': 7.94}
{'loss': 0.0365, 'grad_norm': 12.221634864807129, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.031111953780055046, 'loss_2': 0.00534820556640625, 'loss_3': -15.844189643859863, 'loss_4': 2.8190269470214844, 'epoch': 7.94}
{'loss': 0.0225, 'grad_norm': 7.31989049911499, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.019475314766168594, 'loss_2': 0.003032684326171875, 'loss_3': -15.643660545349121, 'loss_4': 2.7418267726898193, 'epoch': 7.95}
{'loss': 0.0345, 'grad_norm': 9.520922660827637, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.021862046793103218, 'loss_2': 0.0126800537109375, 'loss_3': -15.794818878173828, 'loss_4': 2.808408260345459, 'epoch': 7.95}
{'loss': 0.0367, 'grad_norm': 16.807531356811523, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.03652137145400047, 'loss_2': 0.0001913309097290039, 'loss_3': -15.911253929138184, 'loss_4': 2.9180221557617188, 'epoch': 7.96}
{'loss': 0.0222, 'grad_norm': 6.340178966522217, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.013532597571611404, 'loss_2': 0.00862884521484375, 'loss_3': -15.896805763244629, 'loss_4': 2.544362783432007, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 15:52:53,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:53,877 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:06<1:05:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:01,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01817747950553894, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012567593716084957, 'eval_loss_2': 0.005609884858131409, 'eval_loss_3': -18.101646423339844, 'eval_loss_4': 2.3852059841156006, 'epoch': 7.97}
{'loss': 0.0181, 'grad_norm': 5.496821403503418, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.0123995840549469, 'loss_2': 0.005687713623046875, 'loss_3': -15.71807861328125, 'loss_4': 2.179579734802246, 'epoch': 7.97}
{'loss': 0.0298, 'grad_norm': 8.348301887512207, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.020356902852654457, 'loss_2': 0.0094757080078125, 'loss_3': -15.81374740600586, 'loss_4': 2.5378451347351074, 'epoch': 7.98}
{'loss': 0.0179, 'grad_norm': 7.338255882263184, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.01568964496254921, 'loss_2': 0.0022258758544921875, 'loss_3': -15.592143058776855, 'loss_4': 2.8599472045898438, 'epoch': 7.98}
{'loss': 0.0343, 'grad_norm': 8.34761905670166, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.024812355637550354, 'loss_2': 0.0094451904296875, 'loss_3': -15.711074829101562, 'loss_4': 2.120687484741211, 'epoch': 7.99}
{'loss': 0.0517, 'grad_norm': 18.288930892944336, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.04828033968806267, 'loss_2': 0.0033931732177734375, 'loss_3': -15.895797729492188, 'loss_4': 2.3826475143432617, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 15:53:01,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:01,199 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:13<1:04:14,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:53:08,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018268989399075508, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.035, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01479222159832716, 'eval_loss_2': 0.003476768732070923, 'eval_loss_3': -18.083763122558594, 'eval_loss_4': 2.287682056427002, 'epoch': 7.99}
{'loss': 0.0218, 'grad_norm': 8.891992568969727, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.014615696854889393, 'loss_2': 0.007221221923828125, 'loss_3': -15.466438293457031, 'loss_4': 1.4189709424972534, 'epoch': 8.0}
{'loss': 0.0143, 'grad_norm': 5.695798397064209, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.013776524923741817, 'loss_2': 0.0005211830139160156, 'loss_3': -15.895025253295898, 'loss_4': 2.6809632778167725, 'epoch': 8.01}
{'loss': 0.0196, 'grad_norm': 6.417776584625244, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.013655264861881733, 'loss_2': 0.005901336669921875, 'loss_3': -15.71398639678955, 'loss_4': 2.2398064136505127, 'epoch': 8.01}
{'loss': 0.0173, 'grad_norm': 8.876388549804688, 'learning_rate': 2.2e-05, 'loss_1': 0.015993498265743256, 'loss_2': 0.0013446807861328125, 'loss_3': -15.940787315368652, 'loss_4': 2.0818769931793213, 'epoch': 8.02}
{'loss': 0.0238, 'grad_norm': 10.714842796325684, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.020794561132788658, 'loss_2': 0.00298309326171875, 'loss_3': -15.761943817138672, 'loss_4': 2.0979671478271484, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 15:53:08,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:08,267 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:21<1:05:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:15,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02374301850795746, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.017109930515289307, 'eval_loss_2': 0.006633087992668152, 'eval_loss_3': -18.06613540649414, 'eval_loss_4': 2.3028039932250977, 'epoch': 8.02}
{'loss': 0.0214, 'grad_norm': 7.405932903289795, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.01964230090379715, 'loss_2': 0.00171661376953125, 'loss_3': -15.722421646118164, 'loss_4': 2.394052267074585, 'epoch': 8.03}
{'loss': 0.0642, 'grad_norm': 14.361992835998535, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.06384456157684326, 'loss_2': 0.0003681182861328125, 'loss_3': -15.637474060058594, 'loss_4': 2.266010284423828, 'epoch': 8.03}
{'loss': 0.0394, 'grad_norm': 10.57740306854248, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.034787386655807495, 'loss_2': 0.00461578369140625, 'loss_3': -15.652435302734375, 'loss_4': 1.7335894107818604, 'epoch': 8.04}
{'loss': 0.02, 'grad_norm': 6.158220291137695, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.014129570685327053, 'loss_2': 0.00585174560546875, 'loss_3': -15.785032272338867, 'loss_4': 2.21348237991333, 'epoch': 8.05}
{'loss': 0.0211, 'grad_norm': 6.5927958488464355, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.015297162346541882, 'loss_2': 0.005771636962890625, 'loss_3': -15.855668067932129, 'loss_4': 2.3150997161865234, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 15:53:15,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:15,613 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:28<1:05:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:22,951 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021310895681381226, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.017975063994526863, 'eval_loss_2': 0.0033358335494995117, 'eval_loss_3': -18.070680618286133, 'eval_loss_4': 2.1958131790161133, 'epoch': 8.05}
{'loss': 0.0144, 'grad_norm': 6.4266157150268555, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.012994236312806606, 'loss_2': 0.0013780593872070312, 'loss_3': -16.03618621826172, 'loss_4': 1.7809922695159912, 'epoch': 8.06}
{'loss': 0.0203, 'grad_norm': 7.444899559020996, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.01800484210252762, 'loss_2': 0.0023193359375, 'loss_3': -15.886333465576172, 'loss_4': 1.7669923305511475, 'epoch': 8.06}
{'loss': 0.099, 'grad_norm': 20.1190185546875, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.0946834534406662, 'loss_2': 0.0043487548828125, 'loss_3': -15.756044387817383, 'loss_4': 2.3076460361480713, 'epoch': 8.07}
{'loss': 0.0226, 'grad_norm': 8.290215492248535, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.020236646756529808, 'loss_2': 0.0023136138916015625, 'loss_3': -16.027908325195312, 'loss_4': 1.9388350248336792, 'epoch': 8.08}
{'loss': 0.0334, 'grad_norm': 10.18718433380127, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.026062430813908577, 'loss_2': 0.0073699951171875, 'loss_3': -15.905977249145508, 'loss_4': 2.8347725868225098, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 15:53:22,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:22,951 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:35<1:05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:30,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023809855803847313, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.599, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017574280500411987, 'eval_loss_2': 0.006235577166080475, 'eval_loss_3': -18.08022689819336, 'eval_loss_4': 2.4268887042999268, 'epoch': 8.08}
{'loss': 0.0243, 'grad_norm': 6.466904640197754, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.014964866451919079, 'loss_2': 0.00930023193359375, 'loss_3': -15.624038696289062, 'loss_4': 1.8269562721252441, 'epoch': 8.09}
{'loss': 0.0713, 'grad_norm': 19.759756088256836, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.0644133910536766, 'loss_2': 0.00693511962890625, 'loss_3': -15.928215026855469, 'loss_4': 2.189971446990967, 'epoch': 8.09}
{'loss': 0.0216, 'grad_norm': 6.37173318862915, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.01611940562725067, 'loss_2': 0.00551605224609375, 'loss_3': -16.083141326904297, 'loss_4': 2.5701537132263184, 'epoch': 8.1}
{'loss': 0.0192, 'grad_norm': 6.620795249938965, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.015101841650903225, 'loss_2': 0.00408172607421875, 'loss_3': -16.128870010375977, 'loss_4': 2.9361395835876465, 'epoch': 8.1}
{'loss': 0.0295, 'grad_norm': 7.515565395355225, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.022003158926963806, 'loss_2': 0.007541656494140625, 'loss_3': -15.843862533569336, 'loss_4': 2.547126293182373, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 15:53:30,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:30,295 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:43<1:05:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:37,641 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019160715863108635, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.016408171504735947, 'eval_loss_2': 0.002752542495727539, 'eval_loss_3': -18.09231185913086, 'eval_loss_4': 2.754368782043457, 'epoch': 8.11}
{'loss': 0.0166, 'grad_norm': 4.946502685546875, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.01130753941833973, 'loss_2': 0.00527191162109375, 'loss_3': -16.20513916015625, 'loss_4': 2.417685031890869, 'epoch': 8.12}
{'loss': 0.026, 'grad_norm': 12.59468936920166, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.02500702627003193, 'loss_2': 0.000995635986328125, 'loss_3': -15.748913764953613, 'loss_4': 2.822265148162842, 'epoch': 8.12}
{'loss': 0.0215, 'grad_norm': 5.017735481262207, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.012105676345527172, 'loss_2': 0.00939178466796875, 'loss_3': -16.062328338623047, 'loss_4': 2.2889444828033447, 'epoch': 8.13}
{'loss': 0.0202, 'grad_norm': 6.779708385467529, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.014832554385066032, 'loss_2': 0.00539398193359375, 'loss_3': -16.01718521118164, 'loss_4': 2.5345253944396973, 'epoch': 8.13}
{'loss': 0.0175, 'grad_norm': 7.283528804779053, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.015958569943904877, 'loss_2': 0.001499176025390625, 'loss_3': -15.97464370727539, 'loss_4': 2.707885503768921, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 15:53:37,641 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:37,641 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [34:50<1:05:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:44,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018010154366493225, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014748492278158665, 'eval_loss_2': 0.003261663019657135, 'eval_loss_3': -18.162628173828125, 'eval_loss_4': 2.772934913635254, 'epoch': 8.14}
{'loss': 0.0271, 'grad_norm': 10.619197845458984, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.023025162518024445, 'loss_2': 0.0040740966796875, 'loss_3': -16.031291961669922, 'loss_4': 2.5732078552246094, 'epoch': 8.15}
{'loss': 0.0249, 'grad_norm': 10.113694190979004, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.022548215463757515, 'loss_2': 0.002391815185546875, 'loss_3': -15.997588157653809, 'loss_4': 2.5697104930877686, 'epoch': 8.15}
{'loss': 0.0355, 'grad_norm': 14.679239273071289, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.03529364988207817, 'loss_2': 0.00021696090698242188, 'loss_3': -15.979822158813477, 'loss_4': 2.5784401893615723, 'epoch': 8.16}
{'loss': 0.018, 'grad_norm': 5.872612476348877, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.016156764701008797, 'loss_2': 0.0018329620361328125, 'loss_3': -16.197898864746094, 'loss_4': 2.5654525756835938, 'epoch': 8.16}
{'loss': 0.0203, 'grad_norm': 5.667387962341309, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.010768508538603783, 'loss_2': 0.0095367431640625, 'loss_3': -16.18262481689453, 'loss_4': 2.569115161895752, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 15:53:44,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:44,994 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [34:57<1:05:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:52,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015864063054323196, 'eval_runtime': 3.8271, 'eval_samples_per_second': 267.563, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.01242327131330967, 'eval_loss_2': 0.0034407898783683777, 'eval_loss_3': -18.180435180664062, 'eval_loss_4': 2.432835817337036, 'epoch': 8.17}
{'loss': 0.0165, 'grad_norm': 9.236977577209473, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.016042694449424744, 'loss_2': 0.00043463706970214844, 'loss_3': -16.060916900634766, 'loss_4': 2.5130505561828613, 'epoch': 8.17}
{'loss': 0.0363, 'grad_norm': 18.97972297668457, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.031666114926338196, 'loss_2': 0.0046234130859375, 'loss_3': -15.859009742736816, 'loss_4': 2.513765335083008, 'epoch': 8.18}
{'loss': 0.0267, 'grad_norm': 7.920193672180176, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.0260416641831398, 'loss_2': 0.0006809234619140625, 'loss_3': -15.974952697753906, 'loss_4': 2.219606876373291, 'epoch': 8.19}
{'loss': 0.0241, 'grad_norm': 8.450104713439941, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.019806988537311554, 'loss_2': 0.00428009033203125, 'loss_3': -16.07791519165039, 'loss_4': 2.4425365924835205, 'epoch': 8.19}
{'loss': 0.0129, 'grad_norm': 5.944403171539307, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.01215430535376072, 'loss_2': 0.0007867813110351562, 'loss_3': -16.145139694213867, 'loss_4': 2.3733251094818115, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 15:53:52,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:52,369 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:05<1:04:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:59,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015399996191263199, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.274, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01220100186765194, 'eval_loss_2': 0.0031989961862564087, 'eval_loss_3': -18.177228927612305, 'eval_loss_4': 2.0306708812713623, 'epoch': 8.2}
{'loss': 0.0146, 'grad_norm': 7.708044528961182, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.014237822964787483, 'loss_2': 0.0003643035888671875, 'loss_3': -15.892450332641602, 'loss_4': 1.6762639284133911, 'epoch': 8.2}
{'loss': 0.0193, 'grad_norm': 6.829317092895508, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.016473641619086266, 'loss_2': 0.00279998779296875, 'loss_3': -15.91986083984375, 'loss_4': 1.6252765655517578, 'epoch': 8.21}
{'loss': 0.0188, 'grad_norm': 6.410006046295166, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.01851191185414791, 'loss_2': 0.0002689361572265625, 'loss_3': -15.954017639160156, 'loss_4': 1.5220556259155273, 'epoch': 8.22}
{'loss': 0.0174, 'grad_norm': 6.666898727416992, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.015020215883851051, 'loss_2': 0.0023651123046875, 'loss_3': -15.897019386291504, 'loss_4': 1.1479483842849731, 'epoch': 8.22}
{'loss': 0.0193, 'grad_norm': 6.937206745147705, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.013630337081849575, 'loss_2': 0.005710601806640625, 'loss_3': -15.959064483642578, 'loss_4': 1.362808346748352, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 15:53:59,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:59,715 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:12<1:04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:07,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015510099940001965, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.438, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01195116713643074, 'eval_loss_2': 0.003558933734893799, 'eval_loss_3': -18.161231994628906, 'eval_loss_4': 1.3795177936553955, 'epoch': 8.23}
{'loss': 0.0356, 'grad_norm': 8.39538288116455, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.018912101164460182, 'loss_2': 0.016693115234375, 'loss_3': -16.082992553710938, 'loss_4': 1.509340524673462, 'epoch': 8.23}
{'loss': 0.0197, 'grad_norm': 7.9982991218566895, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.01509152539074421, 'loss_2': 0.00464630126953125, 'loss_3': -15.96908950805664, 'loss_4': 1.2671115398406982, 'epoch': 8.24}
{'loss': 0.0162, 'grad_norm': 6.063951015472412, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.012775754556059837, 'loss_2': 0.003459930419921875, 'loss_3': -15.926042556762695, 'loss_4': 1.2230643033981323, 'epoch': 8.24}
{'loss': 0.0179, 'grad_norm': 7.332769393920898, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.014069348573684692, 'loss_2': 0.003871917724609375, 'loss_3': -15.929758071899414, 'loss_4': 0.883173406124115, 'epoch': 8.25}
{'loss': 0.0182, 'grad_norm': 4.98596715927124, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.010323318652808666, 'loss_2': 0.0078277587890625, 'loss_3': -16.029312133789062, 'loss_4': 1.1962549686431885, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 15:54:07,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:07,061 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:16<1:04:40,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:54:10,863 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420
[INFO|configuration_utils.py:420] 2025-01-21 15:54:10,865 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420/config.json                                                                            
{'eval_loss': 0.014487143605947495, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.47, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010648963041603565, 'eval_loss_2': 0.003838181495666504, 'eval_loss_3': -18.157230377197266, 'eval_loss_4': 0.947690486907959, 'epoch': 8.26}
[INFO|modeling_utils.py:2988] 2025-01-21 15:54:11,336 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:54:11,337 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:54:11,337 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:54:12,164 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1360] due to args.save_total_limit
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:21<1:10:49,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:54:15,798 >>
{'loss': 0.0361, 'grad_norm': 12.622273445129395, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.03559883311390877, 'loss_2': 0.0004520416259765625, 'loss_3': -15.71567153930664, 'loss_4': 0.772186279296875, 'epoch': 8.26}
{'loss': 0.0468, 'grad_norm': 14.173638343811035, 'learning_rate': 2.175e-05, 'loss_1': 0.045103274285793304, 'loss_2': 0.0016803741455078125, 'loss_3': -15.977221488952637, 'loss_4': 1.2437978982925415, 'epoch': 8.27}
{'loss': 0.0401, 'grad_norm': 14.594565391540527, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.03737775981426239, 'loss_2': 0.002758026123046875, 'loss_3': -16.169857025146484, 'loss_4': 0.5981687307357788, 'epoch': 8.27}
{'loss': 0.0195, 'grad_norm': 7.502720832824707, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.01871257647871971, 'loss_2': 0.0007505416870117188, 'loss_3': -16.135540008544922, 'loss_4': 0.7372826337814331, 'epoch': 8.28}
{'loss': 0.0154, 'grad_norm': 6.9321136474609375, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.014259979128837585, 'loss_2': 0.0011043548583984375, 'loss_3': -15.985879898071289, 'loss_4': 0.5590658783912659, 'epoch': 8.28}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:54:15,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:15,799 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:25<1:10:49,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 15:54:19,593 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425
[INFO|configuration_utils.py:420] 2025-01-21 15:54:19,594 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425/config.json                                                                            
{'eval_loss': 0.013063788414001465, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.954, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010434028692543507, 'eval_loss_2': 0.002629760652780533, 'eval_loss_3': -18.179494857788086, 'eval_loss_4': 0.49267473816871643, 'epoch': 8.28}
[INFO|modeling_utils.py:2988] 2025-01-21 15:54:20,070 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:54:20,071 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:54:20,071 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:54:20,902 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1420] due to args.save_total_limit
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:29<1:11:44,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:54:24,535 >>
{'loss': 0.0412, 'grad_norm': 16.27045249938965, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.039896029978990555, 'loss_2': 0.00130462646484375, 'loss_3': -16.028167724609375, 'loss_4': 0.05272667109966278, 'epoch': 8.29}
{'loss': 0.0112, 'grad_norm': 5.971189022064209, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.007806605659425259, 'loss_2': 0.003398895263671875, 'loss_3': -16.07866859436035, 'loss_4': 0.1865324079990387, 'epoch': 8.3}
{'loss': 0.0195, 'grad_norm': 5.966244220733643, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.012069492600858212, 'loss_2': 0.0074462890625, 'loss_3': -16.001333236694336, 'loss_4': 0.6609983444213867, 'epoch': 8.3}
{'loss': 0.0581, 'grad_norm': 20.525875091552734, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.05472724139690399, 'loss_2': 0.0034198760986328125, 'loss_3': -15.603614807128906, 'loss_4': 0.8966773748397827, 'epoch': 8.31}
{'loss': 0.0331, 'grad_norm': 8.860051155090332, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.025188524276018143, 'loss_2': 0.00794219970703125, 'loss_3': -15.738905906677246, 'loss_4': 0.5082085132598877, 'epoch': 8.31}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:54:24,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:24,535 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:37<1:05:33,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:54:31,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016105789691209793, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.707, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01170813012868166, 'eval_loss_2': 0.004397660493850708, 'eval_loss_3': -18.18292236328125, 'eval_loss_4': 0.3907140791416168, 'epoch': 8.31}
{'loss': 0.0134, 'grad_norm': 5.383891582489014, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.01067529059946537, 'loss_2': 0.00275421142578125, 'loss_3': -16.054840087890625, 'loss_4': 0.7905228137969971, 'epoch': 8.32}
{'loss': 0.0109, 'grad_norm': 5.065618991851807, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.00737827830016613, 'loss_2': 0.003551483154296875, 'loss_3': -15.966621398925781, 'loss_4': 0.39292076230049133, 'epoch': 8.33}
{'loss': 0.0167, 'grad_norm': 7.8919453620910645, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.015034168027341366, 'loss_2': 0.0016613006591796875, 'loss_3': -15.915009498596191, 'loss_4': 0.1936902105808258, 'epoch': 8.33}
{'loss': 0.0275, 'grad_norm': 7.073726177215576, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.019353272393345833, 'loss_2': 0.00811767578125, 'loss_3': -15.952058792114258, 'loss_4': 0.4704805910587311, 'epoch': 8.34}
{'loss': 0.0201, 'grad_norm': 6.573635101318359, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.013624997809529305, 'loss_2': 0.006439208984375, 'loss_3': -15.936100959777832, 'loss_4': 0.6541283130645752, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 15:54:31,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:31,871 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:44<1:04:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:39,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0223211832344532, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.401, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014695006422698498, 'eval_loss_2': 0.007626175880432129, 'eval_loss_3': -18.189668655395508, 'eval_loss_4': 0.4240962862968445, 'epoch': 8.34}
{'loss': 0.0279, 'grad_norm': 6.232071876525879, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.013165316544473171, 'loss_2': 0.01470947265625, 'loss_3': -16.205827713012695, 'loss_4': 0.27171796560287476, 'epoch': 8.35}
{'loss': 0.0314, 'grad_norm': 10.241079330444336, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.018572499975562096, 'loss_2': 0.01279449462890625, 'loss_3': -16.165794372558594, 'loss_4': 0.5109824538230896, 'epoch': 8.35}
{'loss': 0.0325, 'grad_norm': 8.49394702911377, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.018371276557445526, 'loss_2': 0.0141754150390625, 'loss_3': -15.798168182373047, 'loss_4': 0.44055214524269104, 'epoch': 8.36}
{'loss': 0.0534, 'grad_norm': 17.856510162353516, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.04693323373794556, 'loss_2': 0.006465911865234375, 'loss_3': -15.991840362548828, 'loss_4': 0.9580909609794617, 'epoch': 8.37}
{'loss': 0.019, 'grad_norm': 4.925334930419922, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.009378411807119846, 'loss_2': 0.0096435546875, 'loss_3': -16.065683364868164, 'loss_4': 0.25583207607269287, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 15:54:39,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:39,207 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [35:51<1:04:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:46,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03180751949548721, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.66, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021287890151143074, 'eval_loss_2': 0.010519623756408691, 'eval_loss_3': -18.180360794067383, 'eval_loss_4': 0.5210329294204712, 'epoch': 8.37}
{'loss': 0.0321, 'grad_norm': 8.1907958984375, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.020713895559310913, 'loss_2': 0.0113677978515625, 'loss_3': -15.818092346191406, 'loss_4': 0.12495338916778564, 'epoch': 8.38}
{'loss': 0.0178, 'grad_norm': 7.830981254577637, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.012091468088328838, 'loss_2': 0.0057525634765625, 'loss_3': -15.807202339172363, 'loss_4': 0.6104092597961426, 'epoch': 8.38}
{'loss': 0.0115, 'grad_norm': 5.327051639556885, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.009889356791973114, 'loss_2': 0.0016393661499023438, 'loss_3': -15.929936408996582, 'loss_4': 0.6080572605133057, 'epoch': 8.39}
{'loss': 0.0305, 'grad_norm': 6.514959812164307, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.017512327060103416, 'loss_2': 0.01302337646484375, 'loss_3': -16.114904403686523, 'loss_4': -0.10433794558048248, 'epoch': 8.4}
{'loss': 0.0187, 'grad_norm': 6.065464019775391, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.013601490296423435, 'loss_2': 0.005115509033203125, 'loss_3': -16.25116539001465, 'loss_4': 0.33177000284194946, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 15:54:46,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:46,544 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [35:59<1:04:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:53,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023738069459795952, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.786, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.019714130088686943, 'eval_loss_2': 0.004023939371109009, 'eval_loss_3': -18.20043182373047, 'eval_loss_4': 0.49485090374946594, 'epoch': 8.4}
{'loss': 0.021, 'grad_norm': 8.000916481018066, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.017260825261473656, 'loss_2': 0.003749847412109375, 'loss_3': -16.18222427368164, 'loss_4': 0.8896400928497314, 'epoch': 8.41}
{'loss': 0.0141, 'grad_norm': 6.333855152130127, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.011434684507548809, 'loss_2': 0.002696990966796875, 'loss_3': -16.14910888671875, 'loss_4': 0.8257081508636475, 'epoch': 8.41}
{'loss': 0.019, 'grad_norm': 6.900500297546387, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.01821497268974781, 'loss_2': 0.0007634162902832031, 'loss_3': -16.107341766357422, 'loss_4': 0.6906286478042603, 'epoch': 8.42}
{'loss': 0.0306, 'grad_norm': 6.218695640563965, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.015532400459051132, 'loss_2': 0.0150909423828125, 'loss_3': -16.03533363342285, 'loss_4': 0.2724533975124359, 'epoch': 8.42}
{'loss': 0.0287, 'grad_norm': 7.282963275909424, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.020356427878141403, 'loss_2': 0.00830078125, 'loss_3': -16.181364059448242, 'loss_4': 0.3924306631088257, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 15:54:53,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:53,878 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:06<1:03:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:55:01,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022803280502557755, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.798, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.017600001767277718, 'eval_loss_2': 0.005203276872634888, 'eval_loss_3': -18.22900390625, 'eval_loss_4': 0.3331812024116516, 'epoch': 8.43}
{'loss': 0.0324, 'grad_norm': 9.97746467590332, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.02350594289600849, 'loss_2': 0.008880615234375, 'loss_3': -16.053863525390625, 'loss_4': 0.5427411794662476, 'epoch': 8.44}
{'loss': 0.0203, 'grad_norm': 5.449357986450195, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.01426771841943264, 'loss_2': 0.00603485107421875, 'loss_3': -15.982980728149414, 'loss_4': 0.20929156243801117, 'epoch': 8.44}
{'loss': 0.0453, 'grad_norm': 23.01340103149414, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.03871973976492882, 'loss_2': 0.00653076171875, 'loss_3': -15.975776672363281, 'loss_4': 0.33036893606185913, 'epoch': 8.45}
{'loss': 0.0244, 'grad_norm': 8.073270797729492, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.02277214638888836, 'loss_2': 0.0016450881958007812, 'loss_3': -16.303443908691406, 'loss_4': 0.7400486469268799, 'epoch': 8.45}
{'loss': 0.0178, 'grad_norm': 7.264580726623535, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.014490891247987747, 'loss_2': 0.003307342529296875, 'loss_3': -16.181053161621094, 'loss_4': 0.4369175434112549, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 15:55:01,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:01,206 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:13<1:04:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:08,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02078375220298767, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01696057617664337, 'eval_loss_2': 0.0038231760263442993, 'eval_loss_3': -18.233867645263672, 'eval_loss_4': 0.25552263855934143, 'epoch': 8.46}
{'loss': 0.0178, 'grad_norm': 5.960031032562256, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.013498803600668907, 'loss_2': 0.0042724609375, 'loss_3': -16.09326934814453, 'loss_4': 0.1649773269891739, 'epoch': 8.47}
{'loss': 0.0257, 'grad_norm': 8.880417823791504, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.022847793996334076, 'loss_2': 0.00289154052734375, 'loss_3': -15.981861114501953, 'loss_4': 0.648362398147583, 'epoch': 8.47}
{'loss': 0.0307, 'grad_norm': 7.864597797393799, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.019558431580662727, 'loss_2': 0.01116943359375, 'loss_3': -16.126882553100586, 'loss_4': 0.24896405637264252, 'epoch': 8.48}
{'loss': 0.0157, 'grad_norm': 5.949865341186523, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.015182552859187126, 'loss_2': 0.0004687309265136719, 'loss_3': -15.88063907623291, 'loss_4': 0.26060348749160767, 'epoch': 8.48}
{'loss': 0.0139, 'grad_norm': 6.042922019958496, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.012579540722072124, 'loss_2': 0.0013027191162109375, 'loss_3': -16.317710876464844, 'loss_4': 0.08533287793397903, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 15:55:08,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:08,562 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:21<1:03:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:15,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024440109729766846, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.017943603917956352, 'eval_loss_2': 0.006496503949165344, 'eval_loss_3': -18.211833953857422, 'eval_loss_4': 0.20074428617954254, 'epoch': 8.49}
{'loss': 0.0348, 'grad_norm': 12.59511947631836, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.02355016954243183, 'loss_2': 0.0112762451171875, 'loss_3': -16.074485778808594, 'loss_4': 0.6676516532897949, 'epoch': 8.49}
{'loss': 0.0404, 'grad_norm': 9.958479881286621, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.034620027989149094, 'loss_2': 0.00576019287109375, 'loss_3': -15.916017532348633, 'loss_4': 0.3746677339076996, 'epoch': 8.5}
{'loss': 0.0449, 'grad_norm': 7.109064102172852, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.040125858038663864, 'loss_2': 0.0047607421875, 'loss_3': -15.849159240722656, 'loss_4': 0.05036482214927673, 'epoch': 8.51}
{'loss': 0.0408, 'grad_norm': 11.853271484375, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.03822417929768562, 'loss_2': 0.002620697021484375, 'loss_3': -16.203441619873047, 'loss_4': 0.48267513513565063, 'epoch': 8.51}
{'loss': 0.027, 'grad_norm': 9.030181884765625, 'learning_rate': 2.15e-05, 'loss_1': 0.023420121520757675, 'loss_2': 0.00356292724609375, 'loss_3': -15.889500617980957, 'loss_4': 0.4952694773674011, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 15:55:15,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:15,910 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:28<1:03:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:23,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022649232298135757, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.238, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01900467462837696, 'eval_loss_2': 0.0036445558071136475, 'eval_loss_3': -18.226530075073242, 'eval_loss_4': 0.2478400617837906, 'epoch': 8.52}
{'loss': 0.0232, 'grad_norm': 8.241830825805664, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.017233753576874733, 'loss_2': 0.00595855712890625, 'loss_3': -15.949616432189941, 'loss_4': 0.46425989270210266, 'epoch': 8.52}
{'loss': 0.0252, 'grad_norm': 6.457409858703613, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.020565830171108246, 'loss_2': 0.0046234130859375, 'loss_3': -16.02833366394043, 'loss_4': 0.5424903631210327, 'epoch': 8.53}
{'loss': 0.022, 'grad_norm': 6.800302028656006, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.017226317897439003, 'loss_2': 0.0047607421875, 'loss_3': -15.890193939208984, 'loss_4': 0.20500807464122772, 'epoch': 8.53}
{'loss': 0.0214, 'grad_norm': 6.431467056274414, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.012853688560426235, 'loss_2': 0.00852203369140625, 'loss_3': -16.073951721191406, 'loss_4': 0.28904688358306885, 'epoch': 8.54}
{'loss': 0.0241, 'grad_norm': 12.518651008605957, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.02306683361530304, 'loss_2': 0.0009899139404296875, 'loss_3': -16.18743896484375, 'loss_4': 0.19043411314487457, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 15:55:23,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:23,254 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:36<1:03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:30,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01923362910747528, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01614333689212799, 'eval_loss_2': 0.00309029221534729, 'eval_loss_3': -18.277158737182617, 'eval_loss_4': 0.3704547584056854, 'epoch': 8.55}
{'loss': 0.0175, 'grad_norm': 5.375710964202881, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.01459508016705513, 'loss_2': 0.002895355224609375, 'loss_3': -16.141944885253906, 'loss_4': 0.2853211760520935, 'epoch': 8.55}
{'loss': 0.0628, 'grad_norm': 23.41893196105957, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.06163879856467247, 'loss_2': 0.0011615753173828125, 'loss_3': -16.014820098876953, 'loss_4': 0.3828308582305908, 'epoch': 8.56}
{'loss': 0.0485, 'grad_norm': 12.675695419311523, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.04456646740436554, 'loss_2': 0.00395965576171875, 'loss_3': -15.739225387573242, 'loss_4': 0.4699847996234894, 'epoch': 8.56}
{'loss': 0.0213, 'grad_norm': 6.787499904632568, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.020071329548954964, 'loss_2': 0.0012493133544921875, 'loss_3': -16.240346908569336, 'loss_4': 0.5105640888214111, 'epoch': 8.57}
{'loss': 0.0738, 'grad_norm': 20.506511688232422, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.06942123174667358, 'loss_2': 0.00437164306640625, 'loss_3': -15.917838096618652, 'loss_4': 1.5469167232513428, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 15:55:30,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:30,595 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:43<1:03:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:37,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02301902510225773, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.87, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01913483999669552, 'eval_loss_2': 0.00388418510556221, 'eval_loss_3': -18.352136611938477, 'eval_loss_4': 0.6796919703483582, 'epoch': 8.58}
{'loss': 0.0512, 'grad_norm': 12.911681175231934, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.03781352937221527, 'loss_2': 0.01336669921875, 'loss_3': -15.879772186279297, 'loss_4': 0.6364160180091858, 'epoch': 8.58}
{'loss': 0.0386, 'grad_norm': 8.871960639953613, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.03659677505493164, 'loss_2': 0.0019817352294921875, 'loss_3': -15.930269241333008, 'loss_4': 0.7571141719818115, 'epoch': 8.59}
{'loss': 0.0641, 'grad_norm': 15.088747024536133, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.062253955751657486, 'loss_2': 0.0018177032470703125, 'loss_3': -16.101821899414062, 'loss_4': 1.0087352991104126, 'epoch': 8.59}
{'loss': 0.1006, 'grad_norm': 23.419788360595703, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.09570787101984024, 'loss_2': 0.004863739013671875, 'loss_3': -16.097549438476562, 'loss_4': 0.9878082871437073, 'epoch': 8.6}
{'loss': 0.0312, 'grad_norm': 10.866353034973145, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.027983753010630608, 'loss_2': 0.003208160400390625, 'loss_3': -16.115428924560547, 'loss_4': 0.809516966342926, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 15:55:37,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:37,950 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [36:50<1:03:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:45,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02438792772591114, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.021225357428193092, 'eval_loss_2': 0.003162570297718048, 'eval_loss_3': -18.369409561157227, 'eval_loss_4': 0.8555265665054321, 'epoch': 8.6}
{'loss': 0.0553, 'grad_norm': 18.488027572631836, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.05116453394293785, 'loss_2': 0.004180908203125, 'loss_3': -15.77767562866211, 'loss_4': 0.8958881497383118, 'epoch': 8.61}
{'loss': 0.0373, 'grad_norm': 9.571683883666992, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.035051193088293076, 'loss_2': 0.00222015380859375, 'loss_3': -16.203094482421875, 'loss_4': 0.9963769316673279, 'epoch': 8.62}
{'loss': 0.1266, 'grad_norm': 29.2514591217041, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.1254637986421585, 'loss_2': 0.00110626220703125, 'loss_3': -15.888838768005371, 'loss_4': 1.6092565059661865, 'epoch': 8.62}
{'loss': 0.0882, 'grad_norm': 21.691356658935547, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.08231517672538757, 'loss_2': 0.00585174560546875, 'loss_3': -16.176368713378906, 'loss_4': 1.154801845550537, 'epoch': 8.63}
{'loss': 0.0205, 'grad_norm': 6.476040840148926, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.019892483949661255, 'loss_2': 0.0006046295166015625, 'loss_3': -16.09786033630371, 'loss_4': 1.0575896501541138, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 15:55:45,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:45,296 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [36:58<1:03:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:52,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026514336466789246, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01986749656498432, 'eval_loss_2': 0.006646841764450073, 'eval_loss_3': -18.331514358520508, 'eval_loss_4': 0.8023084402084351, 'epoch': 8.63}
{'loss': 0.0386, 'grad_norm': 11.435969352722168, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.0367882177233696, 'loss_2': 0.0018596649169921875, 'loss_3': -16.123048782348633, 'loss_4': 1.2647123336791992, 'epoch': 8.64}
{'loss': 0.0337, 'grad_norm': 9.562980651855469, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.029984446242451668, 'loss_2': 0.00368499755859375, 'loss_3': -16.187644958496094, 'loss_4': 1.0328292846679688, 'epoch': 8.65}
{'loss': 0.0292, 'grad_norm': 7.190654277801514, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.021952327340841293, 'loss_2': 0.00724029541015625, 'loss_3': -16.037731170654297, 'loss_4': 0.8956754207611084, 'epoch': 8.65}
{'loss': 0.0117, 'grad_norm': 5.597558975219727, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.011361678130924702, 'loss_2': 0.0003066062927246094, 'loss_3': -16.320133209228516, 'loss_4': 0.6189789175987244, 'epoch': 8.66}
{'loss': 0.0975, 'grad_norm': 16.170738220214844, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.08807311207056046, 'loss_2': 0.00939178466796875, 'loss_3': -16.088123321533203, 'loss_4': 1.1846816539764404, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 15:55:52,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:52,651 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:05<1:03:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:00,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023884490132331848, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01578982174396515, 'eval_loss_2': 0.0080946683883667, 'eval_loss_3': -18.26326560974121, 'eval_loss_4': 0.6563796401023865, 'epoch': 8.66}
{'loss': 0.0214, 'grad_norm': 8.161358833312988, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.014295787550508976, 'loss_2': 0.0070648193359375, 'loss_3': -16.192890167236328, 'loss_4': 1.075096845626831, 'epoch': 8.67}
{'loss': 0.0374, 'grad_norm': 18.395591735839844, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.033808108419179916, 'loss_2': 0.0035495758056640625, 'loss_3': -16.015539169311523, 'loss_4': 0.5823919773101807, 'epoch': 8.67}
{'loss': 0.0408, 'grad_norm': 19.359479904174805, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.037283338606357574, 'loss_2': 0.00351715087890625, 'loss_3': -15.794351577758789, 'loss_4': 0.5237956643104553, 'epoch': 8.68}
{'loss': 0.0199, 'grad_norm': 5.489469528198242, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.01732448861002922, 'loss_2': 0.0026149749755859375, 'loss_3': -16.065046310424805, 'loss_4': 0.5982595682144165, 'epoch': 8.69}
{'loss': 0.0099, 'grad_norm': 5.121459484100342, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.007887784391641617, 'loss_2': 0.0019683837890625, 'loss_3': -15.91073989868164, 'loss_4': 0.7792389392852783, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 15:56:00,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:00,002 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:12<1:03:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:07,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01907053217291832, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.348, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015288125723600388, 'eval_loss_2': 0.003782406449317932, 'eval_loss_3': -18.205808639526367, 'eval_loss_4': 0.6041707396507263, 'epoch': 8.69}
{'loss': 0.0176, 'grad_norm': 7.150874137878418, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.011390677653253078, 'loss_2': 0.0062255859375, 'loss_3': -15.925969123840332, 'loss_4': 0.7737805843353271, 'epoch': 8.7}
{'loss': 0.0577, 'grad_norm': 18.875181198120117, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.05055210739374161, 'loss_2': 0.00717926025390625, 'loss_3': -16.024192810058594, 'loss_4': 0.24413466453552246, 'epoch': 8.7}
{'loss': 0.0329, 'grad_norm': 8.171871185302734, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.02133941277861595, 'loss_2': 0.0115203857421875, 'loss_3': -15.613200187683105, 'loss_4': 0.5111000537872314, 'epoch': 8.71}
{'loss': 0.0333, 'grad_norm': 7.460546970367432, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.015215497463941574, 'loss_2': 0.018096923828125, 'loss_3': -16.023357391357422, 'loss_4': 0.13935212790966034, 'epoch': 8.72}
{'loss': 0.0426, 'grad_norm': 13.60171127319336, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.03837263211607933, 'loss_2': 0.004184722900390625, 'loss_3': -15.837020874023438, 'loss_4': 0.7523456811904907, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 15:56:07,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:07,349 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:20<1:03:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:14,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024130288511514664, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.618, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01566428132355213, 'eval_loss_2': 0.008466005325317383, 'eval_loss_3': -18.17647933959961, 'eval_loss_4': 0.6186626553535461, 'epoch': 8.72}
{'loss': 0.0335, 'grad_norm': 7.480952262878418, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.021941015496850014, 'loss_2': 0.01154327392578125, 'loss_3': -15.901473045349121, 'loss_4': 0.36845821142196655, 'epoch': 8.73}
{'loss': 0.0482, 'grad_norm': 9.759786605834961, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.04492668807506561, 'loss_2': 0.00324249267578125, 'loss_3': -15.86560344696045, 'loss_4': 1.0347871780395508, 'epoch': 8.73}
{'loss': 0.0271, 'grad_norm': 8.950194358825684, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.018855318427085876, 'loss_2': 0.00829315185546875, 'loss_3': -16.123550415039062, 'loss_4': 0.5154979825019836, 'epoch': 8.74}
{'loss': 0.0241, 'grad_norm': 8.440754890441895, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.015122324228286743, 'loss_2': 0.009002685546875, 'loss_3': -16.023311614990234, 'loss_4': 0.8184102773666382, 'epoch': 8.74}
{'loss': 0.0592, 'grad_norm': 18.466875076293945, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.057513605803251266, 'loss_2': 0.0016717910766601562, 'loss_3': -15.994157791137695, 'loss_4': 1.19539213180542, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 15:56:14,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:14,686 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:27<1:03:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:22,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024970853701233864, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.759, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.020940804854035378, 'eval_loss_2': 0.004030048847198486, 'eval_loss_3': -18.14813804626465, 'eval_loss_4': 0.9161850214004517, 'epoch': 8.75}
{'loss': 0.0189, 'grad_norm': 7.5043230056762695, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.016545545309782028, 'loss_2': 0.002349853515625, 'loss_3': -15.917724609375, 'loss_4': 1.1761474609375, 'epoch': 8.76}
{'loss': 0.0158, 'grad_norm': 6.19424295425415, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.015255105681717396, 'loss_2': 0.0005106925964355469, 'loss_3': -16.1207332611084, 'loss_4': 1.2861682176589966, 'epoch': 8.76}
{'loss': 0.0147, 'grad_norm': 5.945674896240234, 'learning_rate': 2.125e-05, 'loss_1': 0.00734869996085763, 'loss_2': 0.0073699951171875, 'loss_3': -16.16702651977539, 'loss_4': 0.8360703587532043, 'epoch': 8.77}
{'loss': 0.0238, 'grad_norm': 6.551950454711914, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.014164693653583527, 'loss_2': 0.009674072265625, 'loss_3': -15.713237762451172, 'loss_4': 0.2958020567893982, 'epoch': 8.77}
{'loss': 0.0227, 'grad_norm': 7.2819647789001465, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.02243921346962452, 'loss_2': 0.00024271011352539062, 'loss_3': -16.06644630432129, 'loss_4': 0.6077971458435059, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 15:56:22,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:22,024 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:34<1:02:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:29,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027811631560325623, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.021530194208025932, 'eval_loss_2': 0.006281435489654541, 'eval_loss_3': -18.15812110900879, 'eval_loss_4': 0.9094871282577515, 'epoch': 8.78}
{'loss': 0.0179, 'grad_norm': 7.25111722946167, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.012812241911888123, 'loss_2': 0.0050506591796875, 'loss_3': -15.9390869140625, 'loss_4': 0.8411435484886169, 'epoch': 8.78}
{'loss': 0.0142, 'grad_norm': 5.837362766265869, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.013781030662357807, 'loss_2': 0.0004439353942871094, 'loss_3': -16.03884506225586, 'loss_4': 0.6724547147750854, 'epoch': 8.79}
{'loss': 0.0177, 'grad_norm': 6.635302543640137, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.013085665181279182, 'loss_2': 0.0045928955078125, 'loss_3': -15.819351196289062, 'loss_4': 1.0741589069366455, 'epoch': 8.8}
{'loss': 0.0327, 'grad_norm': 8.645389556884766, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.02429591678082943, 'loss_2': 0.00836181640625, 'loss_3': -15.894237518310547, 'loss_4': 0.8580409288406372, 'epoch': 8.8}
{'loss': 0.0348, 'grad_norm': 9.559423446655273, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.02993575483560562, 'loss_2': 0.004825592041015625, 'loss_3': -15.828847885131836, 'loss_4': 0.8788427114486694, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 15:56:29,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:29,367 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:42<1:02:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:36,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026966534554958344, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.652, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.024728767573833466, 'eval_loss_2': 0.002237766981124878, 'eval_loss_3': -18.161014556884766, 'eval_loss_4': 1.071791172027588, 'epoch': 8.81}
{'loss': 0.0859, 'grad_norm': 15.847079277038574, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.08389383554458618, 'loss_2': 0.002040863037109375, 'loss_3': -15.932517051696777, 'loss_4': 0.7756982445716858, 'epoch': 8.81}
{'loss': 0.0136, 'grad_norm': 5.111569881439209, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.00773984519764781, 'loss_2': 0.00588226318359375, 'loss_3': -15.807894706726074, 'loss_4': 0.7662961483001709, 'epoch': 8.82}
{'loss': 0.0186, 'grad_norm': 5.664394378662109, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.014186453074216843, 'loss_2': 0.004375457763671875, 'loss_3': -16.05010223388672, 'loss_4': 1.284668207168579, 'epoch': 8.83}
{'loss': 0.0224, 'grad_norm': 6.023157596588135, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.01566944271326065, 'loss_2': 0.00675201416015625, 'loss_3': -16.25971794128418, 'loss_4': 1.3149775266647339, 'epoch': 8.83}
{'loss': 0.0306, 'grad_norm': 9.668974876403809, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.025492919608950615, 'loss_2': 0.00513458251953125, 'loss_3': -15.75498104095459, 'loss_4': 0.7702932357788086, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 15:56:36,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:36,707 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [37:49<1:02:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:44,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027922283858060837, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.692, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02387143298983574, 'eval_loss_2': 0.004050850868225098, 'eval_loss_3': -18.227680206298828, 'eval_loss_4': 1.2247669696807861, 'epoch': 8.84}
{'loss': 0.02, 'grad_norm': 5.356483459472656, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.010740981437265873, 'loss_2': 0.00921630859375, 'loss_3': -16.05582618713379, 'loss_4': 1.2751470804214478, 'epoch': 8.84}
{'loss': 0.0306, 'grad_norm': 7.258366584777832, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.02304478920996189, 'loss_2': 0.0075531005859375, 'loss_3': -15.867449760437012, 'loss_4': 1.1661514043807983, 'epoch': 8.85}
{'loss': 0.0775, 'grad_norm': 15.553686141967773, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.07116971909999847, 'loss_2': 0.00634765625, 'loss_3': -15.974349975585938, 'loss_4': 1.4193551540374756, 'epoch': 8.85}
{'loss': 0.0257, 'grad_norm': 8.167140007019043, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.02316637896001339, 'loss_2': 0.002490997314453125, 'loss_3': -16.047693252563477, 'loss_4': 1.4439268112182617, 'epoch': 8.86}
{'loss': 0.0267, 'grad_norm': 10.340246200561523, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.024420160800218582, 'loss_2': 0.0022792816162109375, 'loss_3': -15.829507827758789, 'loss_4': 1.3149998188018799, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 15:56:44,046 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:44,046 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [37:56<1:02:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:51,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035770244896411896, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.03262622654438019, 'eval_loss_2': 0.0031440183520317078, 'eval_loss_3': -18.156166076660156, 'eval_loss_4': 1.3853530883789062, 'epoch': 8.87}
{'loss': 0.0128, 'grad_norm': 4.934054851531982, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.010172632522881031, 'loss_2': 0.002620697021484375, 'loss_3': -16.095890045166016, 'loss_4': 1.3647080659866333, 'epoch': 8.87}
{'loss': 0.0192, 'grad_norm': 6.925053596496582, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.0158513356000185, 'loss_2': 0.003326416015625, 'loss_3': -15.707647323608398, 'loss_4': 1.0632399320602417, 'epoch': 8.88}
{'loss': 0.1019, 'grad_norm': 15.057195663452148, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.09533590078353882, 'loss_2': 0.00655364990234375, 'loss_3': -16.201807022094727, 'loss_4': 1.7564078569412231, 'epoch': 8.88}
{'loss': 0.0139, 'grad_norm': 5.0516276359558105, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.01212960947304964, 'loss_2': 0.0018024444580078125, 'loss_3': -15.691924095153809, 'loss_4': 1.0938758850097656, 'epoch': 8.89}
{'loss': 0.0131, 'grad_norm': 5.034365653991699, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.010492256842553616, 'loss_2': 0.0025787353515625, 'loss_3': -15.883308410644531, 'loss_4': 1.233456015586853, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 15:56:51,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:51,391 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:04<1:02:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:58,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.049077585339546204, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.736, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.045273374766111374, 'eval_loss_2': 0.0038042068481445312, 'eval_loss_3': -18.090415954589844, 'eval_loss_4': 1.4385898113250732, 'epoch': 8.9}
{'loss': 0.0235, 'grad_norm': 8.88943099975586, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.01679282821714878, 'loss_2': 0.006683349609375, 'loss_3': -15.91296100616455, 'loss_4': 1.3632111549377441, 'epoch': 8.9}
{'loss': 0.0284, 'grad_norm': 5.356436729431152, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.01263228990137577, 'loss_2': 0.015777587890625, 'loss_3': -16.145103454589844, 'loss_4': 1.3436250686645508, 'epoch': 8.91}
{'loss': 0.0319, 'grad_norm': 9.691915512084961, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.028406376019120216, 'loss_2': 0.0034618377685546875, 'loss_3': -15.799947738647461, 'loss_4': 1.017350435256958, 'epoch': 8.91}
{'loss': 0.0283, 'grad_norm': 10.145624160766602, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.019761476665735245, 'loss_2': 0.008575439453125, 'loss_3': -15.759127616882324, 'loss_4': 1.0694793462753296, 'epoch': 8.92}
{'loss': 0.0319, 'grad_norm': 6.758859634399414, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.017419012263417244, 'loss_2': 0.0144805908203125, 'loss_3': -15.66726016998291, 'loss_4': 1.0384730100631714, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 15:56:58,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:58,728 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:11<1:02:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:06,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0545387789607048, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.591, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.049360983073711395, 'eval_loss_2': 0.005177795886993408, 'eval_loss_3': -18.08477783203125, 'eval_loss_4': 1.3228119611740112, 'epoch': 8.92}
{'loss': 0.0366, 'grad_norm': 9.779667854309082, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.02929425798356533, 'loss_2': 0.0073394775390625, 'loss_3': -15.98027515411377, 'loss_4': 1.3006260395050049, 'epoch': 8.93}
{'loss': 0.0227, 'grad_norm': 10.976512908935547, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.020955929532647133, 'loss_2': 0.0017375946044921875, 'loss_3': -15.878307342529297, 'loss_4': 1.3497329950332642, 'epoch': 8.94}
{'loss': 0.0252, 'grad_norm': 9.255660057067871, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.02344680204987526, 'loss_2': 0.001773834228515625, 'loss_3': -16.071786880493164, 'loss_4': 1.0089209079742432, 'epoch': 8.94}
{'loss': 0.012, 'grad_norm': 5.107515811920166, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.009177499450743198, 'loss_2': 0.002780914306640625, 'loss_3': -15.954708099365234, 'loss_4': 1.3914289474487305, 'epoch': 8.95}
{'loss': 0.024, 'grad_norm': 8.059989929199219, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.02349196933209896, 'loss_2': 0.0004978179931640625, 'loss_3': -16.020679473876953, 'loss_4': 1.2970826625823975, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 15:57:06,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:06,075 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:18<1:02:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:13,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053285207599401474, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.129, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.04985804855823517, 'eval_loss_2': 0.003427162766456604, 'eval_loss_3': -18.066444396972656, 'eval_loss_4': 1.0790338516235352, 'epoch': 8.95}
{'loss': 0.0214, 'grad_norm': 9.825721740722656, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.019610555842518806, 'loss_2': 0.0018291473388671875, 'loss_3': -15.709094047546387, 'loss_4': 0.7858940362930298, 'epoch': 8.96}
{'loss': 0.1196, 'grad_norm': 18.69819450378418, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.11421112716197968, 'loss_2': 0.005340576171875, 'loss_3': -15.622380256652832, 'loss_4': 0.7309171557426453, 'epoch': 8.97}
{'loss': 0.0313, 'grad_norm': 8.047789573669434, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.02980760671198368, 'loss_2': 0.001483917236328125, 'loss_3': -15.903656959533691, 'loss_4': 1.3211864233016968, 'epoch': 8.97}
{'loss': 0.0333, 'grad_norm': 12.024205207824707, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.03080819547176361, 'loss_2': 0.0024776458740234375, 'loss_3': -15.856441497802734, 'loss_4': 0.9563228487968445, 'epoch': 8.98}
{'loss': 0.0142, 'grad_norm': 5.691793441772461, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.011466173455119133, 'loss_2': 0.002780914306640625, 'loss_3': -15.860373497009277, 'loss_4': 0.7060867547988892, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 15:57:13,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:13,423 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:25<59:44,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 15:57:20,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04149207845330238, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.859, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.03779963403940201, 'eval_loss_2': 0.003692448139190674, 'eval_loss_3': -18.101869583129883, 'eval_loss_4': 0.8067876100540161, 'epoch': 8.98}
{'loss': 0.0268, 'grad_norm': 8.034919738769531, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.02169787324965, 'loss_2': 0.005100250244140625, 'loss_3': -15.833992958068848, 'loss_4': 0.7265706062316895, 'epoch': 8.99}
{'loss': 0.0241, 'grad_norm': 9.21764087677002, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.018686287105083466, 'loss_2': 0.005397796630859375, 'loss_3': -15.733179092407227, 'loss_4': 0.470598042011261, 'epoch': 8.99}
{'loss': 0.0146, 'grad_norm': 6.060043811798096, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.0032091836910694838, 'loss_2': 0.0113677978515625, 'loss_3': -16.011510848999023, 'loss_4': 0.4065369963645935, 'epoch': 9.0}
{'loss': 0.0207, 'grad_norm': 5.067032814025879, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.018975555896759033, 'loss_2': 0.0017242431640625, 'loss_3': -15.933223724365234, 'loss_4': 0.9547988772392273, 'epoch': 9.01}
{'loss': 0.0139, 'grad_norm': 5.7110676765441895, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.010990330949425697, 'loss_2': 0.002925872802734375, 'loss_3': -15.950690269470215, 'loss_4': 0.3837825655937195, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 15:57:20,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:20,440 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:33<1:01:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:57:27,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03552420809864998, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.751, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.03258299082517624, 'eval_loss_2': 0.002941220998764038, 'eval_loss_3': -18.068729400634766, 'eval_loss_4': 0.5577132105827332, 'epoch': 9.01}
{'loss': 0.0173, 'grad_norm': 5.868772983551025, 'learning_rate': 2.1e-05, 'loss_1': 0.013066064566373825, 'loss_2': 0.004230499267578125, 'loss_3': -16.016538619995117, 'loss_4': 0.6977007389068604, 'epoch': 9.02}
{'loss': 0.0174, 'grad_norm': 7.5893096923828125, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.016543656587600708, 'loss_2': 0.0008816719055175781, 'loss_3': -15.806336402893066, 'loss_4': 0.35540536046028137, 'epoch': 9.02}
{'loss': 0.0174, 'grad_norm': 5.734630107879639, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.009283686988055706, 'loss_2': 0.00807952880859375, 'loss_3': -15.815948486328125, 'loss_4': 0.28382354974746704, 'epoch': 9.03}
{'loss': 0.0117, 'grad_norm': 4.455015659332275, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.00844479538500309, 'loss_2': 0.003223419189453125, 'loss_3': -15.767563819885254, 'loss_4': 0.38308990001678467, 'epoch': 9.03}
{'loss': 0.0332, 'grad_norm': 11.74187183380127, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.031031403690576553, 'loss_2': 0.0022068023681640625, 'loss_3': -15.818307876586914, 'loss_4': 1.0303130149841309, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 15:57:27,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:27,779 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:40<1:02:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:35,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03460553660988808, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.653, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.028141887858510017, 'eval_loss_2': 0.00646364688873291, 'eval_loss_3': -18.043230056762695, 'eval_loss_4': 0.6800916790962219, 'epoch': 9.04}
{'loss': 0.0266, 'grad_norm': 13.117871284484863, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.02476537972688675, 'loss_2': 0.0018434524536132812, 'loss_3': -15.94284725189209, 'loss_4': 0.8754557967185974, 'epoch': 9.05}
{'loss': 0.0222, 'grad_norm': 14.658863067626953, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.017624665051698685, 'loss_2': 0.00460052490234375, 'loss_3': -15.809141159057617, 'loss_4': 0.5303724408149719, 'epoch': 9.05}
{'loss': 0.0084, 'grad_norm': 5.769434928894043, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.007248376030474901, 'loss_2': 0.0011920928955078125, 'loss_3': -15.895099639892578, 'loss_4': 0.626272976398468, 'epoch': 9.06}
{'loss': 0.0083, 'grad_norm': 4.734612464904785, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.00815624836832285, 'loss_2': 9.632110595703125e-05, 'loss_3': -15.942106246948242, 'loss_4': 0.5682656764984131, 'epoch': 9.06}
{'loss': 0.0118, 'grad_norm': 4.559063911437988, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.006196172442287207, 'loss_2': 0.005645751953125, 'loss_3': -16.257068634033203, 'loss_4': 1.020961046218872, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 15:57:35,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:35,122 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [38:47<1:02:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:42,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031879156827926636, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02924204058945179, 'eval_loss_2': 0.002637118101119995, 'eval_loss_3': -18.032312393188477, 'eval_loss_4': 0.6628561615943909, 'epoch': 9.07}
{'loss': 0.022, 'grad_norm': 12.563814163208008, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.02197353169322014, 'loss_2': 5.3822994232177734e-05, 'loss_3': -15.795766830444336, 'loss_4': 0.5821722745895386, 'epoch': 9.08}
{'loss': 0.0144, 'grad_norm': 5.780943393707275, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.008260269649326801, 'loss_2': 0.006175994873046875, 'loss_3': -16.128952026367188, 'loss_4': 0.6442394256591797, 'epoch': 9.08}
{'loss': 0.0153, 'grad_norm': 6.976834774017334, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.011990870349109173, 'loss_2': 0.0032596588134765625, 'loss_3': -16.019851684570312, 'loss_4': 0.37266749143600464, 'epoch': 9.09}
{'loss': 0.0155, 'grad_norm': 6.558446884155273, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.015427025966346264, 'loss_2': 4.696846008300781e-05, 'loss_3': -15.851872444152832, 'loss_4': 0.9226157665252686, 'epoch': 9.09}
{'loss': 0.0101, 'grad_norm': 4.790376663208008, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.0063108354806900024, 'loss_2': 0.0037441253662109375, 'loss_3': -16.0592041015625, 'loss_4': 1.157456398010254, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 15:57:42,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:42,460 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [38:55<1:02:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:49,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02184775099158287, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.608, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01695265993475914, 'eval_loss_2': 0.0048950910568237305, 'eval_loss_3': -18.094362258911133, 'eval_loss_4': 0.6601178050041199, 'epoch': 9.1}
{'loss': 0.0168, 'grad_norm': 6.717415809631348, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.01603531837463379, 'loss_2': 0.0007252693176269531, 'loss_3': -16.04205322265625, 'loss_4': 0.8316286206245422, 'epoch': 9.1}
{'loss': 0.0134, 'grad_norm': 5.541249752044678, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.011363993398845196, 'loss_2': 0.0020465850830078125, 'loss_3': -15.999178886413574, 'loss_4': 0.9480834603309631, 'epoch': 9.11}
{'loss': 0.0158, 'grad_norm': 6.938218593597412, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.015611140057444572, 'loss_2': 0.00014328956604003906, 'loss_3': -15.919624328613281, 'loss_4': 0.5978895425796509, 'epoch': 9.12}
{'loss': 0.0193, 'grad_norm': 8.54107666015625, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.018552228808403015, 'loss_2': 0.0007848739624023438, 'loss_3': -15.871537208557129, 'loss_4': 1.1438263654708862, 'epoch': 9.12}
{'loss': 0.0153, 'grad_norm': 5.442216873168945, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.009770923294126987, 'loss_2': 0.00550079345703125, 'loss_3': -15.992025375366211, 'loss_4': 0.3862762451171875, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 15:57:49,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:49,807 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:02<1:01:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:57,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018528340384364128, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.807, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015030412934720516, 'eval_loss_2': 0.0034979283809661865, 'eval_loss_3': -18.10788917541504, 'eval_loss_4': 0.5674688816070557, 'epoch': 9.13}
{'loss': 0.0186, 'grad_norm': 6.616340637207031, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.010659812018275261, 'loss_2': 0.0079193115234375, 'loss_3': -16.05817413330078, 'loss_4': 0.5859609842300415, 'epoch': 9.13}
{'loss': 0.0343, 'grad_norm': 9.471280097961426, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.022835317999124527, 'loss_2': 0.011505126953125, 'loss_3': -15.828364372253418, 'loss_4': 0.4712385833263397, 'epoch': 9.14}
{'loss': 0.0275, 'grad_norm': 10.03880500793457, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.025516169145703316, 'loss_2': 0.0019664764404296875, 'loss_3': -16.0195369720459, 'loss_4': 0.38790053129196167, 'epoch': 9.15}
{'loss': 0.0178, 'grad_norm': 9.14654541015625, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.01691173017024994, 'loss_2': 0.000881195068359375, 'loss_3': -15.880990028381348, 'loss_4': 0.6633381843566895, 'epoch': 9.15}
{'loss': 0.0315, 'grad_norm': 18.206832885742188, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.031079832464456558, 'loss_2': 0.0003910064697265625, 'loss_3': -15.889352798461914, 'loss_4': 0.3433665633201599, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 15:57:57,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:57,139 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:09<1:01:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:04,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01632663421332836, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.695, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013099430128932, 'eval_loss_2': 0.0032272040843963623, 'eval_loss_3': -18.12285614013672, 'eval_loss_4': 0.6408650279045105, 'epoch': 9.16}
{'loss': 0.0129, 'grad_norm': 5.043839931488037, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.01173377875238657, 'loss_2': 0.0011262893676757812, 'loss_3': -15.958541870117188, 'loss_4': 0.5103815793991089, 'epoch': 9.16}
{'loss': 0.0492, 'grad_norm': 22.589401245117188, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.046826861798763275, 'loss_2': 0.002349853515625, 'loss_3': -15.945165634155273, 'loss_4': 0.6597244739532471, 'epoch': 9.17}
{'loss': 0.04, 'grad_norm': 9.632817268371582, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.03651111572980881, 'loss_2': 0.00347137451171875, 'loss_3': -16.006942749023438, 'loss_4': 0.7303966283798218, 'epoch': 9.17}
{'loss': 0.0138, 'grad_norm': 5.511718273162842, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.010213764384388924, 'loss_2': 0.00357818603515625, 'loss_3': -16.061473846435547, 'loss_4': 1.1901166439056396, 'epoch': 9.18}
{'loss': 0.0893, 'grad_norm': 10.932910919189453, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.08683422952890396, 'loss_2': 0.00249481201171875, 'loss_3': -16.05640411376953, 'loss_4': 1.4537794589996338, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 15:58:04,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:04,478 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:17<1:01:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:11,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017623890191316605, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.855, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012577492743730545, 'eval_loss_2': 0.005046401172876358, 'eval_loss_3': -18.142650604248047, 'eval_loss_4': 1.0748265981674194, 'epoch': 9.19}
{'loss': 0.0715, 'grad_norm': 22.59332847595215, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.06787069141864777, 'loss_2': 0.0036716461181640625, 'loss_3': -15.67148208618164, 'loss_4': 1.5533382892608643, 'epoch': 9.19}
{'loss': 0.0205, 'grad_norm': 8.023519515991211, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.018666917458176613, 'loss_2': 0.00183868408203125, 'loss_3': -15.875070571899414, 'loss_4': 1.0652415752410889, 'epoch': 9.2}
{'loss': 0.0492, 'grad_norm': 14.612848281860352, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.04310933127999306, 'loss_2': 0.006134033203125, 'loss_3': -15.851072311401367, 'loss_4': 1.538924217224121, 'epoch': 9.2}
{'loss': 0.0354, 'grad_norm': 12.11619758605957, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.03340578451752663, 'loss_2': 0.002002716064453125, 'loss_3': -16.177597045898438, 'loss_4': 1.4578704833984375, 'epoch': 9.21}
{'loss': 0.026, 'grad_norm': 6.611920356750488, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.019430138170719147, 'loss_2': 0.00653076171875, 'loss_3': -16.01372528076172, 'loss_4': 1.4919418096542358, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 15:58:11,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:11,809 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:24<1:01:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:19,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01696832850575447, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.733, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012716743163764477, 'eval_loss_2': 0.004251584410667419, 'eval_loss_3': -18.132038116455078, 'eval_loss_4': 1.498287558555603, 'epoch': 9.22}
{'loss': 0.0198, 'grad_norm': 5.201909065246582, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.015557433478534222, 'loss_2': 0.0041961669921875, 'loss_3': -16.150161743164062, 'loss_4': 1.8320307731628418, 'epoch': 9.22}
{'loss': 0.0422, 'grad_norm': 9.062737464904785, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.03364866226911545, 'loss_2': 0.008514404296875, 'loss_3': -16.19741439819336, 'loss_4': 2.19008731842041, 'epoch': 9.23}
{'loss': 0.0194, 'grad_norm': 6.7316508293151855, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.017077762633562088, 'loss_2': 0.002361297607421875, 'loss_3': -16.07345199584961, 'loss_4': 1.3653316497802734, 'epoch': 9.23}
{'loss': 0.0285, 'grad_norm': 8.846512794494629, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.023454764857888222, 'loss_2': 0.005035400390625, 'loss_3': -15.959208488464355, 'loss_4': 1.5941890478134155, 'epoch': 9.24}
{'loss': 0.0272, 'grad_norm': 7.758948802947998, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.026600152254104614, 'loss_2': 0.000629425048828125, 'loss_3': -15.868293762207031, 'loss_4': 2.178051471710205, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 15:58:19,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:19,144 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:31<1:01:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:26,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017813872545957565, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01389981247484684, 'eval_loss_2': 0.003914058208465576, 'eval_loss_3': -18.098751068115234, 'eval_loss_4': 1.6661773920059204, 'epoch': 9.24}
{'loss': 0.0959, 'grad_norm': 36.58317184448242, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.0922376960515976, 'loss_2': 0.003643035888671875, 'loss_3': -16.001338958740234, 'loss_4': 2.2142956256866455, 'epoch': 9.25}
{'loss': 0.0271, 'grad_norm': 8.139154434204102, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.024204423651099205, 'loss_2': 0.0029449462890625, 'loss_3': -16.092716217041016, 'loss_4': 1.4350388050079346, 'epoch': 9.26}
{'loss': 0.0512, 'grad_norm': 14.006047248840332, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.05043812096118927, 'loss_2': 0.000766754150390625, 'loss_3': -15.937019348144531, 'loss_4': 1.9544622898101807, 'epoch': 9.26}
{'loss': 0.0276, 'grad_norm': 6.637139320373535, 'learning_rate': 2.075e-05, 'loss_1': 0.023307252675294876, 'loss_2': 0.004302978515625, 'loss_3': -15.906532287597656, 'loss_4': 1.989766001701355, 'epoch': 9.27}
{'loss': 0.0271, 'grad_norm': 8.040871620178223, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.02118716947734356, 'loss_2': 0.00592041015625, 'loss_3': -16.033056259155273, 'loss_4': 1.7883062362670898, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 15:58:26,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:26,492 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:39<1:01:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:33,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574729010462761, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.422, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012548606842756271, 'eval_loss_2': 0.003198683261871338, 'eval_loss_3': -18.095420837402344, 'eval_loss_4': 1.689929485321045, 'epoch': 9.27}
{'loss': 0.0359, 'grad_norm': 14.00793170928955, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.03576473891735077, 'loss_2': 0.00018417835235595703, 'loss_3': -16.11461067199707, 'loss_4': 1.5889374017715454, 'epoch': 9.28}
{'loss': 0.0294, 'grad_norm': 6.712397575378418, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.028580376878380775, 'loss_2': 0.0008287429809570312, 'loss_3': -16.198135375976562, 'loss_4': 1.7227094173431396, 'epoch': 9.28}
{'loss': 0.0162, 'grad_norm': 5.7470574378967285, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.013435237109661102, 'loss_2': 0.002750396728515625, 'loss_3': -15.997520446777344, 'loss_4': 2.093259811401367, 'epoch': 9.29}
{'loss': 0.0215, 'grad_norm': 8.530098915100098, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.021478811278939247, 'loss_2': 6.532669067382812e-05, 'loss_3': -16.06097412109375, 'loss_4': 1.3582392930984497, 'epoch': 9.3}
{'loss': 0.0126, 'grad_norm': 5.367908477783203, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.010046347975730896, 'loss_2': 0.002536773681640625, 'loss_3': -15.909154891967773, 'loss_4': 1.363081932067871, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 15:58:33,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:33,833 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:46<1:01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:41,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014956438913941383, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010998796671628952, 'eval_loss_2': 0.003957644104957581, 'eval_loss_3': -18.146202087402344, 'eval_loss_4': 1.4566317796707153, 'epoch': 9.3}
{'loss': 0.0284, 'grad_norm': 11.580204010009766, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.02597280591726303, 'loss_2': 0.002422332763671875, 'loss_3': -16.11328125, 'loss_4': 1.7427828311920166, 'epoch': 9.31}
{'loss': 0.0489, 'grad_norm': 14.248414039611816, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.044301412999629974, 'loss_2': 0.0046234130859375, 'loss_3': -16.07732391357422, 'loss_4': 1.8403419256210327, 'epoch': 9.31}
{'loss': 0.0244, 'grad_norm': 8.802443504333496, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.021751904860138893, 'loss_2': 0.002655029296875, 'loss_3': -15.872453689575195, 'loss_4': 1.426891565322876, 'epoch': 9.32}
{'loss': 0.0117, 'grad_norm': 6.215237140655518, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.01116951648145914, 'loss_2': 0.0005621910095214844, 'loss_3': -16.241046905517578, 'loss_4': 1.3544931411743164, 'epoch': 9.33}
{'loss': 0.0144, 'grad_norm': 5.185093402862549, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.008873732760548592, 'loss_2': 0.00553131103515625, 'loss_3': -15.966401100158691, 'loss_4': 1.4565520286560059, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 15:58:41,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:41,178 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [39:50<1:01:28,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:58:44,972 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605
[INFO|configuration_utils.py:420] 2025-01-21 15:58:44,974 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605/config.json                                                                            
{'eval_loss': 0.01274043694138527, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009303619153797626, 'eval_loss_2': 0.0034368187189102173, 'eval_loss_3': -18.148771286010742, 'eval_loss_4': 1.270930290222168, 'epoch': 9.33}
[INFO|modeling_utils.py:2988] 2025-01-21 15:58:45,442 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:58:45,444 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:58:45,444 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:58:46,273 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1425] due to args.save_total_limit
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [39:55<1:07:17,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:58:49,901 >>
{'loss': 0.0173, 'grad_norm': 5.873899936676025, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.011648950167000294, 'loss_2': 0.00567626953125, 'loss_3': -15.941106796264648, 'loss_4': 1.1173603534698486, 'epoch': 9.34}
{'loss': 0.0573, 'grad_norm': 33.205265045166016, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.05340239405632019, 'loss_2': 0.0038547515869140625, 'loss_3': -15.890632629394531, 'loss_4': 1.4966120719909668, 'epoch': 9.34}
{'loss': 0.0151, 'grad_norm': 5.384354591369629, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.01230594515800476, 'loss_2': 0.0027561187744140625, 'loss_3': -16.124042510986328, 'loss_4': 1.6677600145339966, 'epoch': 9.35}
{'loss': 0.0435, 'grad_norm': 13.544270515441895, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.0383194275200367, 'loss_2': 0.005146026611328125, 'loss_3': -15.621599197387695, 'loss_4': 1.2617061138153076, 'epoch': 9.35}
{'loss': 0.0119, 'grad_norm': 4.811568737030029, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.0075364019721746445, 'loss_2': 0.00434112548828125, 'loss_3': -15.962024688720703, 'loss_4': 1.236649751663208, 'epoch': 9.36}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:58:49,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:49,901 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:02<1:02:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:58:57,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01419495977461338, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009486014023423195, 'eval_loss_2': 0.0047089457511901855, 'eval_loss_3': -18.16795539855957, 'eval_loss_4': 1.0790268182754517, 'epoch': 9.36}
{'loss': 0.0198, 'grad_norm': 5.976630687713623, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.013025090098381042, 'loss_2': 0.00676727294921875, 'loss_3': -16.129459381103516, 'loss_4': 0.7871925830841064, 'epoch': 9.37}
{'loss': 0.0249, 'grad_norm': 9.357597351074219, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.022254709154367447, 'loss_2': 0.002628326416015625, 'loss_3': -15.959173202514648, 'loss_4': 1.3456404209136963, 'epoch': 9.37}
{'loss': 0.0308, 'grad_norm': 6.370028972625732, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.016865843906998634, 'loss_2': 0.01397705078125, 'loss_3': -16.1991024017334, 'loss_4': 1.4254200458526611, 'epoch': 9.38}
{'loss': 0.0392, 'grad_norm': 10.9824800491333, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.03712218999862671, 'loss_2': 0.00209808349609375, 'loss_3': -15.931652069091797, 'loss_4': 1.2368687391281128, 'epoch': 9.38}
{'loss': 0.0241, 'grad_norm': 5.822247505187988, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.01084811519831419, 'loss_2': 0.01324462890625, 'loss_3': -16.026845932006836, 'loss_4': 1.2772555351257324, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 15:58:57,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:57,231 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:09<1:01:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:04,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01701943762600422, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00982670672237873, 'eval_loss_2': 0.007192730903625488, 'eval_loss_3': -18.205514907836914, 'eval_loss_4': 1.076213002204895, 'epoch': 9.39}
{'loss': 0.0253, 'grad_norm': 7.084706783294678, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.02029179036617279, 'loss_2': 0.00496673583984375, 'loss_3': -15.905531883239746, 'loss_4': 1.1521472930908203, 'epoch': 9.4}
{'loss': 0.0158, 'grad_norm': 6.468362808227539, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.01314486376941204, 'loss_2': 0.002689361572265625, 'loss_3': -16.007299423217773, 'loss_4': 1.4446167945861816, 'epoch': 9.4}
{'loss': 0.036, 'grad_norm': 16.118473052978516, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.029926639050245285, 'loss_2': 0.006084442138671875, 'loss_3': -16.033828735351562, 'loss_4': 1.1772927045822144, 'epoch': 9.41}
{'loss': 0.0255, 'grad_norm': 5.502432823181152, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.0117906229570508, 'loss_2': 0.0137176513671875, 'loss_3': -16.20284080505371, 'loss_4': 1.0455315113067627, 'epoch': 9.41}
{'loss': 0.0232, 'grad_norm': 6.8679022789001465, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.015111463144421577, 'loss_2': 0.00811767578125, 'loss_3': -15.9998197555542, 'loss_4': 1.29041588306427, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 15:59:04,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:04,568 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:17<1:01:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:11,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015303893946111202, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.415, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01054595410823822, 'eval_loss_2': 0.004757940769195557, 'eval_loss_3': -18.204933166503906, 'eval_loss_4': 0.9145168662071228, 'epoch': 9.42}
{'loss': 0.0197, 'grad_norm': 7.109686374664307, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.013521872460842133, 'loss_2': 0.00618743896484375, 'loss_3': -16.051799774169922, 'loss_4': 0.5475870966911316, 'epoch': 9.42}
{'loss': 0.0104, 'grad_norm': 6.077266693115234, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.00937140453606844, 'loss_2': 0.0010013580322265625, 'loss_3': -15.940200805664062, 'loss_4': 0.7476763725280762, 'epoch': 9.43}
{'loss': 0.0181, 'grad_norm': 7.985600471496582, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.014090651646256447, 'loss_2': 0.00399017333984375, 'loss_3': -16.152952194213867, 'loss_4': 0.7560933828353882, 'epoch': 9.44}
{'loss': 0.0106, 'grad_norm': 5.829636096954346, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.00987706333398819, 'loss_2': 0.0006771087646484375, 'loss_3': -15.752511978149414, 'loss_4': 0.7690824270248413, 'epoch': 9.44}
{'loss': 0.0184, 'grad_norm': 5.77152156829834, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.013387656770646572, 'loss_2': 0.005023956298828125, 'loss_3': -16.12899398803711, 'loss_4': 0.7951996326446533, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 15:59:11,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:11,916 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:24<1:00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:19,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017099672928452492, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.795, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012388970702886581, 'eval_loss_2': 0.00471070408821106, 'eval_loss_3': -18.192703247070312, 'eval_loss_4': 0.5795273780822754, 'epoch': 9.45}
{'loss': 0.0165, 'grad_norm': 5.65313196182251, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.013913657516241074, 'loss_2': 0.0025424957275390625, 'loss_3': -15.974126815795898, 'loss_4': 0.37933778762817383, 'epoch': 9.45}
{'loss': 0.0197, 'grad_norm': 6.172056198120117, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.014602258801460266, 'loss_2': 0.005146026611328125, 'loss_3': -15.932056427001953, 'loss_4': 0.44403505325317383, 'epoch': 9.46}
{'loss': 0.0563, 'grad_norm': 18.683921813964844, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.05390927568078041, 'loss_2': 0.002437591552734375, 'loss_3': -15.798885345458984, 'loss_4': 0.24099920690059662, 'epoch': 9.47}
{'loss': 0.0308, 'grad_norm': 10.738749504089355, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.023528484627604485, 'loss_2': 0.00730133056640625, 'loss_3': -15.973320007324219, 'loss_4': 0.6002998352050781, 'epoch': 9.47}
{'loss': 0.0357, 'grad_norm': 15.051952362060547, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.03164146840572357, 'loss_2': 0.004024505615234375, 'loss_3': -16.198719024658203, 'loss_4': 0.3663296103477478, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 15:59:19,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:19,250 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:32<1:00:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:26,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01692749373614788, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.754, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014100994914770126, 'eval_loss_2': 0.002826496958732605, 'eval_loss_3': -18.15424919128418, 'eval_loss_4': 0.3493114709854126, 'epoch': 9.48}
{'loss': 0.0238, 'grad_norm': 9.373724937438965, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.022079357877373695, 'loss_2': 0.0016870498657226562, 'loss_3': -15.996269226074219, 'loss_4': 0.5427380204200745, 'epoch': 9.48}
{'loss': 0.0153, 'grad_norm': 5.062491416931152, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.007450376637279987, 'loss_2': 0.00789642333984375, 'loss_3': -15.97024917602539, 'loss_4': -0.00618550181388855, 'epoch': 9.49}
{'loss': 0.0171, 'grad_norm': 4.737728118896484, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.0080042015761137, 'loss_2': 0.009124755859375, 'loss_3': -15.966763496398926, 'loss_4': 0.7004615664482117, 'epoch': 9.49}
{'loss': 0.0244, 'grad_norm': 8.30579948425293, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.01966250315308571, 'loss_2': 0.004703521728515625, 'loss_3': -15.827317237854004, 'loss_4': 0.2879217863082886, 'epoch': 9.5}
{'loss': 0.0185, 'grad_norm': 6.684210300445557, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.01407337561249733, 'loss_2': 0.00444793701171875, 'loss_3': -15.812220573425293, 'loss_4': 0.32871049642562866, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 15:59:26,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:26,589 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:39<1:00:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:33,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022620350122451782, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.712, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0157471913844347, 'eval_loss_2': 0.0068731606006622314, 'eval_loss_3': -18.132110595703125, 'eval_loss_4': 0.16753123700618744, 'epoch': 9.51}
{'loss': 0.0137, 'grad_norm': 5.6009521484375, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.010084852576255798, 'loss_2': 0.0035877227783203125, 'loss_3': -15.868142127990723, 'loss_4': 0.3658696413040161, 'epoch': 9.51}
{'loss': 0.0299, 'grad_norm': 6.057348251342773, 'learning_rate': 2.05e-05, 'loss_1': 0.014739937148988247, 'loss_2': 0.01514434814453125, 'loss_3': -15.845142364501953, 'loss_4': 0.32029762864112854, 'epoch': 9.52}
{'loss': 0.0251, 'grad_norm': 7.466437816619873, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.017069194465875626, 'loss_2': 0.0080718994140625, 'loss_3': -16.061227798461914, 'loss_4': 0.0579715371131897, 'epoch': 9.52}
{'loss': 0.0112, 'grad_norm': 5.284412384033203, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.008730698376893997, 'loss_2': 0.002506256103515625, 'loss_3': -16.036401748657227, 'loss_4': -0.03359109163284302, 'epoch': 9.53}
{'loss': 0.0086, 'grad_norm': 5.286905288696289, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.007708157878369093, 'loss_2': 0.0009198188781738281, 'loss_3': -16.055837631225586, 'loss_4': 0.1608479619026184, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 15:59:33,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:33,917 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [40:46<1:00:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:41,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020465632900595665, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.761, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01722065359354019, 'eval_loss_2': 0.0032449811697006226, 'eval_loss_3': -18.0977725982666, 'eval_loss_4': -0.16867519915103912, 'epoch': 9.53}
{'loss': 0.0117, 'grad_norm': 5.414021968841553, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.011018767952919006, 'loss_2': 0.00064849853515625, 'loss_3': -16.040050506591797, 'loss_4': -0.49958735704421997, 'epoch': 9.54}
{'loss': 0.0912, 'grad_norm': 14.570788383483887, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.08441297709941864, 'loss_2': 0.00679779052734375, 'loss_3': -16.165945053100586, 'loss_4': 0.25792670249938965, 'epoch': 9.55}
{'loss': 0.0188, 'grad_norm': 6.958655834197998, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.0144639378413558, 'loss_2': 0.00429534912109375, 'loss_3': -15.82742691040039, 'loss_4': -0.5179868936538696, 'epoch': 9.55}
{'loss': 0.0156, 'grad_norm': 6.122456073760986, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.012968789786100388, 'loss_2': 0.00262451171875, 'loss_3': -15.837196350097656, 'loss_4': -0.23301459848880768, 'epoch': 9.56}
{'loss': 0.0172, 'grad_norm': 5.153083324432373, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.015119178220629692, 'loss_2': 0.002124786376953125, 'loss_3': -16.036731719970703, 'loss_4': -0.10718513280153275, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 15:59:41,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:41,254 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [40:54<1:00:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:48,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021470334380865097, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.291, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01867949403822422, 'eval_loss_2': 0.0027908384799957275, 'eval_loss_3': -18.093624114990234, 'eval_loss_4': -0.4527655243873596, 'epoch': 9.56}
{'loss': 0.0231, 'grad_norm': 7.71013879776001, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.019858622923493385, 'loss_2': 0.00319671630859375, 'loss_3': -16.034053802490234, 'loss_4': 0.021751701831817627, 'epoch': 9.57}
{'loss': 0.007, 'grad_norm': 4.820932865142822, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.00649656355381012, 'loss_2': 0.00048828125, 'loss_3': -16.04689598083496, 'loss_4': -0.6798794269561768, 'epoch': 9.58}
{'loss': 0.0264, 'grad_norm': 10.5554780960083, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.021529313176870346, 'loss_2': 0.004886627197265625, 'loss_3': -16.064292907714844, 'loss_4': -0.43901097774505615, 'epoch': 9.58}
{'loss': 0.031, 'grad_norm': 19.87761116027832, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.030691374093294144, 'loss_2': 0.00033092498779296875, 'loss_3': -16.081998825073242, 'loss_4': -0.5376527309417725, 'epoch': 9.59}
{'loss': 0.0244, 'grad_norm': 5.1025004386901855, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.0070395865477621555, 'loss_2': 0.017364501953125, 'loss_3': -16.047433853149414, 'loss_4': -0.7174592018127441, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 15:59:48,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:48,595 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:01<1:00:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:55,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03622664883732796, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02930622361600399, 'eval_loss_2': 0.006920427083969116, 'eval_loss_3': -18.07320785522461, 'eval_loss_4': -0.7811073064804077, 'epoch': 9.59}
{'loss': 0.0257, 'grad_norm': 7.687488079071045, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.019469156861305237, 'loss_2': 0.00618743896484375, 'loss_3': -16.061586380004883, 'loss_4': -0.8549830913543701, 'epoch': 9.6}
{'loss': 0.0641, 'grad_norm': 19.405689239501953, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.058057256042957306, 'loss_2': 0.006072998046875, 'loss_3': -16.113910675048828, 'loss_4': -0.5634439587593079, 'epoch': 9.6}
{'loss': 0.0328, 'grad_norm': 8.999667167663574, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.021958937868475914, 'loss_2': 0.010833740234375, 'loss_3': -16.0585994720459, 'loss_4': -1.1805548667907715, 'epoch': 9.61}
{'loss': 0.0213, 'grad_norm': 10.015512466430664, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.020790409296751022, 'loss_2': 0.0005340576171875, 'loss_3': -16.05715560913086, 'loss_4': -1.0493606328964233, 'epoch': 9.62}
{'loss': 0.0127, 'grad_norm': 5.151648998260498, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.008486468344926834, 'loss_2': 0.0042572021484375, 'loss_3': -16.032955169677734, 'loss_4': -1.0786526203155518, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 15:59:55,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:55,942 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:08<1:00:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:00:03,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04511650651693344, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.041373953223228455, 'eval_loss_2': 0.0037425458431243896, 'eval_loss_3': -17.999286651611328, 'eval_loss_4': -0.8356918692588806, 'epoch': 9.62}
{'loss': 0.013, 'grad_norm': 5.256529331207275, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.010172444395720959, 'loss_2': 0.00278472900390625, 'loss_3': -16.10013198852539, 'loss_4': -1.0757461786270142, 'epoch': 9.63}
{'loss': 0.0141, 'grad_norm': 5.9419121742248535, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.010430235415697098, 'loss_2': 0.003673553466796875, 'loss_3': -16.04785919189453, 'loss_4': -0.9522680044174194, 'epoch': 9.63}
{'loss': 0.0224, 'grad_norm': 13.753256797790527, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.02160060591995716, 'loss_2': 0.0007495880126953125, 'loss_3': -15.895915985107422, 'loss_4': -0.9181288480758667, 'epoch': 9.64}
{'loss': 0.0079, 'grad_norm': 4.9108357429504395, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.0055253393948078156, 'loss_2': 0.002407073974609375, 'loss_3': -16.04789924621582, 'loss_4': -0.5365563631057739, 'epoch': 9.65}
{'loss': 0.0126, 'grad_norm': 5.2109293937683105, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.00837531965225935, 'loss_2': 0.0042572021484375, 'loss_3': -15.941117286682129, 'loss_4': -0.8289753198623657, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 16:00:03,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:03,270 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:16<1:00:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:10,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05590140074491501, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.679, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.05218929052352905, 'eval_loss_2': 0.0037121139466762543, 'eval_loss_3': -17.922706604003906, 'eval_loss_4': -0.8348480463027954, 'epoch': 9.65}
{'loss': 0.0251, 'grad_norm': 10.951865196228027, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.024752862751483917, 'loss_2': 0.0003063678741455078, 'loss_3': -16.000835418701172, 'loss_4': -1.0310159921646118, 'epoch': 9.66}
{'loss': 0.0413, 'grad_norm': 15.168249130249023, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.03758636489510536, 'loss_2': 0.0036792755126953125, 'loss_3': -15.825496673583984, 'loss_4': -0.9476218223571777, 'epoch': 9.66}
{'loss': 0.0275, 'grad_norm': 10.382753372192383, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.019969506189227104, 'loss_2': 0.00754547119140625, 'loss_3': -15.99132251739502, 'loss_4': -0.7464542388916016, 'epoch': 9.67}
{'loss': 0.0141, 'grad_norm': 6.182492256164551, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.012052146717905998, 'loss_2': 0.0020923614501953125, 'loss_3': -15.837844848632812, 'loss_4': -0.6583201885223389, 'epoch': 9.67}
{'loss': 0.0416, 'grad_norm': 15.730931282043457, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.037748824805021286, 'loss_2': 0.003875732421875, 'loss_3': -15.820455551147461, 'loss_4': -0.8350577354431152, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 16:00:10,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:10,608 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:23<1:00:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:17,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08265537023544312, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.07716315984725952, 'eval_loss_2': 0.005492210388183594, 'eval_loss_3': -17.846574783325195, 'eval_loss_4': -0.6608682870864868, 'epoch': 9.68}
{'loss': 0.021, 'grad_norm': 6.260912895202637, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.017033882439136505, 'loss_2': 0.003997802734375, 'loss_3': -15.962021827697754, 'loss_4': -1.1848317384719849, 'epoch': 9.69}
{'loss': 0.0215, 'grad_norm': 5.6511993408203125, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.0168682262301445, 'loss_2': 0.00466156005859375, 'loss_3': -16.004236221313477, 'loss_4': -0.4795697033405304, 'epoch': 9.69}
{'loss': 0.0118, 'grad_norm': 6.934606552124023, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.011119235306978226, 'loss_2': 0.0006384849548339844, 'loss_3': -15.888107299804688, 'loss_4': -0.3983134627342224, 'epoch': 9.7}
{'loss': 0.0256, 'grad_norm': 8.884461402893066, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.020692406222224236, 'loss_2': 0.00487518310546875, 'loss_3': -15.582419395446777, 'loss_4': -0.7430295348167419, 'epoch': 9.7}
{'loss': 0.0239, 'grad_norm': 7.20464563369751, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.021452078595757484, 'loss_2': 0.0024929046630859375, 'loss_3': -15.746618270874023, 'loss_4': -0.43816643953323364, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 16:00:17,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:17,947 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:30<1:01:00,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:00:25,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08768168091773987, 'eval_runtime': 3.9906, 'eval_samples_per_second': 256.601, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.08385198563337326, 'eval_loss_2': 0.0038296878337860107, 'eval_loss_3': -17.836734771728516, 'eval_loss_4': -0.27546632289886475, 'epoch': 9.71}
{'loss': 0.0222, 'grad_norm': 11.631628036499023, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.021210791543126106, 'loss_2': 0.0009717941284179688, 'loss_3': -15.945680618286133, 'loss_4': -0.19318249821662903, 'epoch': 9.72}
{'loss': 0.0157, 'grad_norm': 9.423380851745605, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.012769156135618687, 'loss_2': 0.00290679931640625, 'loss_3': -15.864487648010254, 'loss_4': -0.006846368312835693, 'epoch': 9.72}
{'loss': 0.0447, 'grad_norm': 17.527502059936523, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.03878111019730568, 'loss_2': 0.005893707275390625, 'loss_3': -15.748628616333008, 'loss_4': -0.4150918126106262, 'epoch': 9.73}
{'loss': 0.0344, 'grad_norm': 8.700088500976562, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.03188899904489517, 'loss_2': 0.002544403076171875, 'loss_3': -16.044218063354492, 'loss_4': 0.05093768984079361, 'epoch': 9.73}
{'loss': 0.0131, 'grad_norm': 5.1837687492370605, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.009422330185770988, 'loss_2': 0.003719329833984375, 'loss_3': -16.142398834228516, 'loss_4': 0.20629623532295227, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 16:00:25,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:25,477 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:38<1:00:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:32,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07569855451583862, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.209, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.07181504368782043, 'eval_loss_2': 0.0038835033774375916, 'eval_loss_3': -17.877971649169922, 'eval_loss_4': -0.08208224922418594, 'epoch': 9.74}
{'loss': 0.0183, 'grad_norm': 8.168143272399902, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.015736516565084457, 'loss_2': 0.00257110595703125, 'loss_3': -15.834753036499023, 'loss_4': -0.055840909481048584, 'epoch': 9.74}
{'loss': 0.0154, 'grad_norm': 7.34029483795166, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.014254601672291756, 'loss_2': 0.001171112060546875, 'loss_3': -15.91859245300293, 'loss_4': -0.42417484521865845, 'epoch': 9.75}
{'loss': 0.0359, 'grad_norm': 9.254487037658691, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.02610764093697071, 'loss_2': 0.0097503662109375, 'loss_3': -16.06726837158203, 'loss_4': 0.15222059190273285, 'epoch': 9.76}
{'loss': 0.0139, 'grad_norm': 5.876062393188477, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.01043077651411295, 'loss_2': 0.00350189208984375, 'loss_3': -15.903849601745605, 'loss_4': -0.37701910734176636, 'epoch': 9.76}
{'loss': 0.0138, 'grad_norm': 6.747912406921387, 'learning_rate': 2.025e-05, 'loss_1': 0.011694290675222874, 'loss_2': 0.0020771026611328125, 'loss_3': -15.905632972717285, 'loss_4': -0.2890234887599945, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 16:00:32,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:32,822 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:45<1:00:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:40,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04767706245183945, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.04406755417585373, 'eval_loss_2': 0.0036095082759857178, 'eval_loss_3': -17.99003028869629, 'eval_loss_4': 0.0669393539428711, 'epoch': 9.77}
{'loss': 0.0224, 'grad_norm': 10.642951965332031, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.022227611392736435, 'loss_2': 0.0001983642578125, 'loss_3': -16.094207763671875, 'loss_4': -0.17520007491111755, 'epoch': 9.77}
{'loss': 0.0461, 'grad_norm': 9.985030174255371, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.03796085715293884, 'loss_2': 0.00818634033203125, 'loss_3': -15.955492973327637, 'loss_4': -0.04702430218458176, 'epoch': 9.78}
{'loss': 0.036, 'grad_norm': 13.924186706542969, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.02655966766178608, 'loss_2': 0.0094146728515625, 'loss_3': -15.918283462524414, 'loss_4': -0.009469889104366302, 'epoch': 9.78}
{'loss': 0.0298, 'grad_norm': 14.439359664916992, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.027485372498631477, 'loss_2': 0.0023136138916015625, 'loss_3': -15.977386474609375, 'loss_4': 0.5316910743713379, 'epoch': 9.79}
{'loss': 0.0304, 'grad_norm': 8.831254959106445, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.022979680448770523, 'loss_2': 0.00746917724609375, 'loss_3': -16.088518142700195, 'loss_4': 0.27536994218826294, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 16:00:40,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:40,164 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1690/5160 [41:52<59:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:47,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029164478182792664, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0249945018440485, 'eval_loss_2': 0.004169974476099014, 'eval_loss_3': -18.032123565673828, 'eval_loss_4': 0.13191883265972137, 'epoch': 9.8}
{'loss': 0.0201, 'grad_norm': 7.328647136688232, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.018834395334124565, 'loss_2': 0.001308441162109375, 'loss_3': -16.07544708251953, 'loss_4': 0.3319293260574341, 'epoch': 9.8}
{'loss': 0.029, 'grad_norm': 8.284544944763184, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.027820846065878868, 'loss_2': 0.0011911392211914062, 'loss_3': -16.090648651123047, 'loss_4': 0.39505770802497864, 'epoch': 9.81}
{'loss': 0.0149, 'grad_norm': 6.439077377319336, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.01053476519882679, 'loss_2': 0.0044097900390625, 'loss_3': -16.061946868896484, 'loss_4': 0.1709005981683731, 'epoch': 9.81}
{'loss': 0.0134, 'grad_norm': 5.6014604568481445, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.009667842648923397, 'loss_2': 0.00373077392578125, 'loss_3': -16.103553771972656, 'loss_4': 0.3035687506198883, 'epoch': 9.82}
{'loss': 0.0185, 'grad_norm': 8.42331314086914, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.018313249573111534, 'loss_2': 0.00022983551025390625, 'loss_3': -16.064552307128906, 'loss_4': 0.47651398181915283, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 16:00:47,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:47,501 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [42:00<59:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:54,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022552723065018654, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.876, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01838357374072075, 'eval_loss_2': 0.004169151186943054, 'eval_loss_3': -18.05299186706543, 'eval_loss_4': 0.17025375366210938, 'epoch': 9.83}
{'loss': 0.0147, 'grad_norm': 6.240669250488281, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.009549823589622974, 'loss_2': 0.0051116943359375, 'loss_3': -15.76186752319336, 'loss_4': 0.5824001431465149, 'epoch': 9.83}
{'loss': 0.0307, 'grad_norm': 12.668100357055664, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.028605425730347633, 'loss_2': 0.0020732879638671875, 'loss_3': -16.170320510864258, 'loss_4': 0.5317739248275757, 'epoch': 9.84}
{'loss': 0.0233, 'grad_norm': 8.842000007629395, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.02213650941848755, 'loss_2': 0.0011796951293945312, 'loss_3': -15.932331085205078, 'loss_4': 0.03608979284763336, 'epoch': 9.84}
{'loss': 0.0128, 'grad_norm': 5.509971618652344, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.009822815656661987, 'loss_2': 0.002933502197265625, 'loss_3': -15.96609115600586, 'loss_4': 0.0020808465778827667, 'epoch': 9.85}
{'loss': 0.0123, 'grad_norm': 6.195712089538574, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.011475720442831516, 'loss_2': 0.0008587837219238281, 'loss_3': -16.004066467285156, 'loss_4': 0.3479890823364258, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 16:00:54,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:54,834 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:07<59:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:02,176 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023373007774353027, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016338109970092773, 'eval_loss_2': 0.007034897804260254, 'eval_loss_3': -18.047908782958984, 'eval_loss_4': 0.14247651398181915, 'epoch': 9.85}
{'loss': 0.0386, 'grad_norm': 12.87403678894043, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.036157578229904175, 'loss_2': 0.002422332763671875, 'loss_3': -16.105051040649414, 'loss_4': 0.1428806185722351, 'epoch': 9.86}
{'loss': 0.0313, 'grad_norm': 11.614361763000488, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.030962491407990456, 'loss_2': 0.0002942085266113281, 'loss_3': -16.174644470214844, 'loss_4': 0.360939621925354, 'epoch': 9.87}
{'loss': 0.0412, 'grad_norm': 20.29111099243164, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.02973836101591587, 'loss_2': 0.01146697998046875, 'loss_3': -15.866750717163086, 'loss_4': 0.3504400849342346, 'epoch': 9.87}
{'loss': 0.0207, 'grad_norm': 4.779483318328857, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.004538890440016985, 'loss_2': 0.0161590576171875, 'loss_3': -15.882673263549805, 'loss_4': 0.25733262300491333, 'epoch': 9.88}
{'loss': 0.0298, 'grad_norm': 6.078619480133057, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.019500015303492546, 'loss_2': 0.01025390625, 'loss_3': -15.67098617553711, 'loss_4': 0.036430723965168, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 16:01:02,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:02,177 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:14<59:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:09,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027026375755667686, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0153781957924366, 'eval_loss_2': 0.011648178100585938, 'eval_loss_3': -18.047698974609375, 'eval_loss_4': 0.4363381266593933, 'epoch': 9.88}
{'loss': 0.0326, 'grad_norm': 10.154106140136719, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.017964012920856476, 'loss_2': 0.01465606689453125, 'loss_3': -15.814287185668945, 'loss_4': 0.06195087730884552, 'epoch': 9.89}
{'loss': 0.0227, 'grad_norm': 5.4934797286987305, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.009954380802810192, 'loss_2': 0.012786865234375, 'loss_3': -15.974723815917969, 'loss_4': 0.39973339438438416, 'epoch': 9.9}
{'loss': 0.0285, 'grad_norm': 7.761425495147705, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.015155150555074215, 'loss_2': 0.013336181640625, 'loss_3': -15.968058586120605, 'loss_4': 0.22303463518619537, 'epoch': 9.9}
{'loss': 0.0213, 'grad_norm': 6.360682964324951, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.019093381240963936, 'loss_2': 0.002231597900390625, 'loss_3': -15.87328052520752, 'loss_4': 0.5435384511947632, 'epoch': 9.91}
{'loss': 0.062, 'grad_norm': 18.42340850830078, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.05250582844018936, 'loss_2': 0.0095367431640625, 'loss_3': -15.981278419494629, 'loss_4': 0.6123546361923218, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 16:01:09,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:09,515 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:22<59:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:16,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019508685916662216, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.848, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013302209787070751, 'eval_loss_2': 0.00620647519826889, 'eval_loss_3': -18.078723907470703, 'eval_loss_4': 0.6217490434646606, 'epoch': 9.91}
{'loss': 0.0181, 'grad_norm': 9.9425687789917, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.016742238774895668, 'loss_2': 0.0014028549194335938, 'loss_3': -16.094146728515625, 'loss_4': 0.8849550485610962, 'epoch': 9.92}
{'loss': 0.0179, 'grad_norm': 5.604239463806152, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.007203953340649605, 'loss_2': 0.010650634765625, 'loss_3': -16.22896957397461, 'loss_4': 0.5553088188171387, 'epoch': 9.92}
{'loss': 0.0161, 'grad_norm': 5.312983989715576, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.011897407472133636, 'loss_2': 0.00421905517578125, 'loss_3': -15.932247161865234, 'loss_4': 0.6524222493171692, 'epoch': 9.93}
{'loss': 0.09, 'grad_norm': 16.949966430664062, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.0887133777141571, 'loss_2': 0.0013170242309570312, 'loss_3': -16.205413818359375, 'loss_4': 0.5779294967651367, 'epoch': 9.94}
{'loss': 0.0267, 'grad_norm': 6.52567720413208, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.01911862939596176, 'loss_2': 0.00756072998046875, 'loss_3': -15.869661331176758, 'loss_4': 0.9372351169586182, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 16:01:16,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:16,848 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:29<59:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:24,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016733229160308838, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0133607666939497, 'eval_loss_2': 0.0033724606037139893, 'eval_loss_3': -18.043384552001953, 'eval_loss_4': 0.6837419867515564, 'epoch': 9.94}
{'loss': 0.0122, 'grad_norm': 7.148545742034912, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.011010618880391121, 'loss_2': 0.0012226104736328125, 'loss_3': -16.1334285736084, 'loss_4': 0.5582073926925659, 'epoch': 9.95}
{'loss': 0.0255, 'grad_norm': 7.432267189025879, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.024846205487847328, 'loss_2': 0.0006833076477050781, 'loss_3': -16.07872200012207, 'loss_4': 0.792121171951294, 'epoch': 9.95}
{'loss': 0.0134, 'grad_norm': 8.695794105529785, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.013243342749774456, 'loss_2': 0.00011682510375976562, 'loss_3': -15.660322189331055, 'loss_4': 0.32126113772392273, 'epoch': 9.96}
{'loss': 0.0172, 'grad_norm': 5.147747993469238, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.010625813156366348, 'loss_2': 0.006565093994140625, 'loss_3': -15.805989265441895, 'loss_4': 0.44935619831085205, 'epoch': 9.97}
{'loss': 0.0077, 'grad_norm': 4.875113487243652, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.005271628964692354, 'loss_2': 0.00241851806640625, 'loss_3': -16.139259338378906, 'loss_4': 0.28954577445983887, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 16:01:24,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:24,190 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:36<53:29,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:01:31,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0176268108189106, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.146, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014165693894028664, 'eval_loss_2': 0.003461115062236786, 'eval_loss_3': -18.0604190826416, 'eval_loss_4': 0.6485543251037598, 'epoch': 9.97}
{'loss': 0.0264, 'grad_norm': 13.539335250854492, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.02559497021138668, 'loss_2': 0.0007734298706054688, 'loss_3': -16.194833755493164, 'loss_4': 0.9762732982635498, 'epoch': 9.98}
{'loss': 0.0083, 'grad_norm': 4.605430603027344, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.005750859621912241, 'loss_2': 0.0025577545166015625, 'loss_3': -15.977880477905273, 'loss_4': 0.29923009872436523, 'epoch': 9.98}
{'loss': 0.0072, 'grad_norm': 4.519468784332275, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.004886037670075893, 'loss_2': 0.00235748291015625, 'loss_3': -16.14332389831543, 'loss_4': 0.9055211544036865, 'epoch': 9.99}
{'loss': 0.0158, 'grad_norm': 5.824855327606201, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.009676966816186905, 'loss_2': 0.00608062744140625, 'loss_3': -16.104869842529297, 'loss_4': 0.6064376831054688, 'epoch': 9.99}
{'loss': 0.0033, 'grad_norm': 5.9428935050964355, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.002500826260074973, 'loss_2': 0.0007805824279785156, 'loss_3': -16.140642166137695, 'loss_4': 0.8071776628494263, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 16:01:31,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:31,185 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:43<58:33,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:01:38,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017153121531009674, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013494987972080708, 'eval_loss_2': 0.003658134490251541, 'eval_loss_3': -18.076135635375977, 'eval_loss_4': 0.7055476903915405, 'epoch': 10.0}
{'loss': 0.0115, 'grad_norm': 5.050654411315918, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.010499884374439716, 'loss_2': 0.0010194778442382812, 'loss_3': -16.02564239501953, 'loss_4': 0.3939097225666046, 'epoch': 10.01}
{'loss': 0.0455, 'grad_norm': 17.04439926147461, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.04407188668847084, 'loss_2': 0.0013790130615234375, 'loss_3': -15.904300689697266, 'loss_4': 0.5332769751548767, 'epoch': 10.01}
{'loss': 0.0159, 'grad_norm': 5.709038734436035, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.014786267653107643, 'loss_2': 0.001140594482421875, 'loss_3': -16.063148498535156, 'loss_4': 0.7894124984741211, 'epoch': 10.02}
{'loss': 0.0136, 'grad_norm': 5.769471645355225, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.011174367740750313, 'loss_2': 0.0024566650390625, 'loss_3': -15.97977066040039, 'loss_4': 0.726940393447876, 'epoch': 10.02}
{'loss': 0.0139, 'grad_norm': 10.557929992675781, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.013274465687572956, 'loss_2': 0.0005979537963867188, 'loss_3': -16.21163558959961, 'loss_4': 0.46515411138534546, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 16:01:38,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:38,572 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [42:51<59:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:45,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01700301095843315, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013290715403854847, 'eval_loss_2': 0.003712296485900879, 'eval_loss_3': -18.107393264770508, 'eval_loss_4': 0.660353422164917, 'epoch': 10.03}
{'loss': 0.0173, 'grad_norm': 6.582996368408203, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.013013672083616257, 'loss_2': 0.004276275634765625, 'loss_3': -16.10164451599121, 'loss_4': 0.39686551690101624, 'epoch': 10.03}
{'loss': 0.022, 'grad_norm': 7.237179279327393, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.018919017165899277, 'loss_2': 0.00311279296875, 'loss_3': -15.95435619354248, 'loss_4': 1.3748739957809448, 'epoch': 10.04}
{'loss': 0.0301, 'grad_norm': 15.250898361206055, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.02282298170030117, 'loss_2': 0.007293701171875, 'loss_3': -15.723522186279297, 'loss_4': 0.9118400812149048, 'epoch': 10.05}
{'loss': 0.0286, 'grad_norm': 9.91932487487793, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.0214017815887928, 'loss_2': 0.0071563720703125, 'loss_3': -16.20963478088379, 'loss_4': 0.529442548751831, 'epoch': 10.05}
{'loss': 0.0212, 'grad_norm': 5.611578941345215, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.011335290037095547, 'loss_2': 0.0098876953125, 'loss_3': -16.16689682006836, 'loss_4': 0.5559883713722229, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 16:01:45,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:45,918 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [42:58<59:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:53,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01864621788263321, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.353, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.013632446527481079, 'eval_loss_2': 0.00501377135515213, 'eval_loss_3': -18.163604736328125, 'eval_loss_4': 0.6919041275978088, 'epoch': 10.06}
{'loss': 0.0145, 'grad_norm': 5.927586078643799, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.011777205392718315, 'loss_2': 0.0027313232421875, 'loss_3': -16.193078994750977, 'loss_4': 0.6095073223114014, 'epoch': 10.06}
{'loss': 0.0366, 'grad_norm': 14.227860450744629, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.027616843581199646, 'loss_2': 0.00894927978515625, 'loss_3': -15.986857414245605, 'loss_4': 0.3778919577598572, 'epoch': 10.07}
{'loss': 0.0231, 'grad_norm': 12.585098266601562, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.022700639441609383, 'loss_2': 0.00034999847412109375, 'loss_3': -16.34048843383789, 'loss_4': 0.6279563903808594, 'epoch': 10.08}
{'loss': 0.0579, 'grad_norm': 24.906768798828125, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.05315614119172096, 'loss_2': 0.004730224609375, 'loss_3': -16.02927017211914, 'loss_4': 0.995568037033081, 'epoch': 10.08}
{'loss': 0.0148, 'grad_norm': 6.374131679534912, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.014228200539946556, 'loss_2': 0.0006194114685058594, 'loss_3': -16.123126983642578, 'loss_4': 0.38029080629348755, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 16:01:53,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:53,287 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:06<59:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:00,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020075567066669464, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016137292608618736, 'eval_loss_2': 0.003938272595405579, 'eval_loss_3': -18.18547821044922, 'eval_loss_4': 0.4704642593860626, 'epoch': 10.09}
{'loss': 0.013, 'grad_norm': 5.9623918533325195, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.010147701017558575, 'loss_2': 0.002803802490234375, 'loss_3': -16.034351348876953, 'loss_4': 0.3385516405105591, 'epoch': 10.09}
{'loss': 0.025, 'grad_norm': 8.439069747924805, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.01950972154736519, 'loss_2': 0.00550079345703125, 'loss_3': -15.96794319152832, 'loss_4': 0.6165292263031006, 'epoch': 10.1}
{'loss': 0.0169, 'grad_norm': 5.966907024383545, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.012153476476669312, 'loss_2': 0.004730224609375, 'loss_3': -16.16347885131836, 'loss_4': -0.026970218867063522, 'epoch': 10.1}
{'loss': 0.0303, 'grad_norm': 6.708466529846191, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.018629370257258415, 'loss_2': 0.0117034912109375, 'loss_3': -16.144428253173828, 'loss_4': 0.2204662710428238, 'epoch': 10.11}
{'loss': 0.016, 'grad_norm': 6.36038064956665, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.015326815657317638, 'loss_2': 0.0007190704345703125, 'loss_3': -16.082361221313477, 'loss_4': 0.35263657569885254, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 16:02:00,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:00,629 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:13<59:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:07,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023804355412721634, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.858, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016729164868593216, 'eval_loss_2': 0.007075190544128418, 'eval_loss_3': -18.18924331665039, 'eval_loss_4': 0.21701210737228394, 'epoch': 10.12}
{'loss': 0.0171, 'grad_norm': 5.741753101348877, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.011740787886083126, 'loss_2': 0.00536346435546875, 'loss_3': -16.32036018371582, 'loss_4': 0.5021300315856934, 'epoch': 10.12}
{'loss': 0.0177, 'grad_norm': 6.960360050201416, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.01656441204249859, 'loss_2': 0.001125335693359375, 'loss_3': -15.852116584777832, 'loss_4': 0.3693190813064575, 'epoch': 10.13}
{'loss': 0.0187, 'grad_norm': 8.814738273620605, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.018239658325910568, 'loss_2': 0.0005006790161132812, 'loss_3': -16.079843521118164, 'loss_4': -0.02497367560863495, 'epoch': 10.13}
{'loss': 0.0144, 'grad_norm': 6.220790386199951, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.012900409288704395, 'loss_2': 0.00154876708984375, 'loss_3': -15.982803344726562, 'loss_4': 0.07993300259113312, 'epoch': 10.14}
{'loss': 0.0259, 'grad_norm': 7.4800496101379395, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.01763635128736496, 'loss_2': 0.0082855224609375, 'loss_3': -15.904496192932129, 'loss_4': 0.18717747926712036, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 16:02:07,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:07,962 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:20<58:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:15,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024214042350649834, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.656, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.020569905638694763, 'eval_loss_2': 0.0036441385746002197, 'eval_loss_3': -18.164939880371094, 'eval_loss_4': -0.0682104304432869, 'epoch': 10.15}
{'loss': 0.03, 'grad_norm': 12.075041770935059, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.026915427297353745, 'loss_2': 0.0030345916748046875, 'loss_3': -16.02010154724121, 'loss_4': -0.15893319249153137, 'epoch': 10.15}
{'loss': 0.0189, 'grad_norm': 5.061675071716309, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.012410316616296768, 'loss_2': 0.00647735595703125, 'loss_3': -16.01109504699707, 'loss_4': -0.1024632602930069, 'epoch': 10.16}
{'loss': 0.0227, 'grad_norm': 6.47805643081665, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.016342323273420334, 'loss_2': 0.00638580322265625, 'loss_3': -16.104717254638672, 'loss_4': -0.3335670232772827, 'epoch': 10.16}
{'loss': 0.0305, 'grad_norm': 8.422109603881836, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.02532927319407463, 'loss_2': 0.005138397216796875, 'loss_3': -16.030799865722656, 'loss_4': -0.26270580291748047, 'epoch': 10.17}
{'loss': 0.0642, 'grad_norm': 21.677810668945312, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.05852646753191948, 'loss_2': 0.00563812255859375, 'loss_3': -16.201309204101562, 'loss_4': 0.2539929449558258, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 16:02:15,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:15,304 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:28<58:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:22,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03482732176780701, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02962198667228222, 'eval_loss_2': 0.005205333232879639, 'eval_loss_3': -18.123746871948242, 'eval_loss_4': -0.26178881525993347, 'epoch': 10.17}
{'loss': 0.0326, 'grad_norm': 9.170533180236816, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.025764528661966324, 'loss_2': 0.00679779052734375, 'loss_3': -16.206275939941406, 'loss_4': -0.5911447405815125, 'epoch': 10.18}
{'loss': 0.0091, 'grad_norm': 4.72560977935791, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.007159631699323654, 'loss_2': 0.00197601318359375, 'loss_3': -15.969270706176758, 'loss_4': 0.008504003286361694, 'epoch': 10.19}
{'loss': 0.0394, 'grad_norm': 12.672550201416016, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.03548787534236908, 'loss_2': 0.003955841064453125, 'loss_3': -15.891796112060547, 'loss_4': -0.44112417101860046, 'epoch': 10.19}
{'loss': 0.0233, 'grad_norm': 7.800995826721191, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.01844884268939495, 'loss_2': 0.004810333251953125, 'loss_3': -16.023897171020508, 'loss_4': -0.5289265513420105, 'epoch': 10.2}
{'loss': 0.0218, 'grad_norm': 6.583800792694092, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.019276270642876625, 'loss_2': 0.002536773681640625, 'loss_3': -15.99055004119873, 'loss_4': -0.30935990810394287, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 16:02:22,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:22,638 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:35<58:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:29,983 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04282074049115181, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.039864037185907364, 'eval_loss_2': 0.0029567107558250427, 'eval_loss_3': -18.056745529174805, 'eval_loss_4': -0.38718128204345703, 'epoch': 10.2}
{'loss': 0.0229, 'grad_norm': 7.171073913574219, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.020610593259334564, 'loss_2': 0.0023345947265625, 'loss_3': -15.911903381347656, 'loss_4': -0.3881954252719879, 'epoch': 10.21}
{'loss': 0.0137, 'grad_norm': 5.230739116668701, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.009799252264201641, 'loss_2': 0.00389862060546875, 'loss_3': -16.112586975097656, 'loss_4': -0.06716486066579819, 'epoch': 10.22}
{'loss': 0.0158, 'grad_norm': 6.470874786376953, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.014366857707500458, 'loss_2': 0.00145721435546875, 'loss_3': -16.014738082885742, 'loss_4': -0.290795236825943, 'epoch': 10.22}
{'loss': 0.0355, 'grad_norm': 19.264236450195312, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.03106699511408806, 'loss_2': 0.004451751708984375, 'loss_3': -15.998269081115723, 'loss_4': -0.23824012279510498, 'epoch': 10.23}
{'loss': 0.0258, 'grad_norm': 7.4600067138671875, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.016197271645069122, 'loss_2': 0.009613037109375, 'loss_3': -16.074031829833984, 'loss_4': -0.6346226930618286, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 16:02:29,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:29,983 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:42<58:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:37,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06525413691997528, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.05600444972515106, 'eval_loss_2': 0.009249687194824219, 'eval_loss_3': -18.01714515686035, 'eval_loss_4': -0.3195834159851074, 'epoch': 10.23}
{'loss': 0.0879, 'grad_norm': 18.442384719848633, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.08058082312345505, 'loss_2': 0.007293701171875, 'loss_3': -15.924542427062988, 'loss_4': -0.17865918576717377, 'epoch': 10.24}
{'loss': 0.0247, 'grad_norm': 5.226795673370361, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.008169172331690788, 'loss_2': 0.016510009765625, 'loss_3': -16.085800170898438, 'loss_4': -0.25044307112693787, 'epoch': 10.24}
{'loss': 0.02, 'grad_norm': 7.2838568687438965, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.014289284124970436, 'loss_2': 0.00574493408203125, 'loss_3': -16.07413101196289, 'loss_4': -0.35253793001174927, 'epoch': 10.25}
{'loss': 0.0293, 'grad_norm': 7.291037559509277, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.017272785305976868, 'loss_2': 0.01201629638671875, 'loss_3': -16.02577781677246, 'loss_4': -0.41405653953552246, 'epoch': 10.26}
{'loss': 0.0305, 'grad_norm': 12.834756851196289, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.03049246035516262, 'loss_2': 3.4689903259277344e-05, 'loss_3': -15.96061897277832, 'loss_4': 0.041067250072956085, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 16:02:37,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:37,325 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [43:50<58:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:44,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.052496425807476044, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.04832708463072777, 'eval_loss_2': 0.004169344902038574, 'eval_loss_3': -18.01131248474121, 'eval_loss_4': -0.3222386837005615, 'epoch': 10.26}
{'loss': 0.0148, 'grad_norm': 6.506532192230225, 'learning_rate': 1.975e-05, 'loss_1': 0.011343110352754593, 'loss_2': 0.00341033935546875, 'loss_3': -16.138961791992188, 'loss_4': -0.47850069403648376, 'epoch': 10.27}
{'loss': 0.0144, 'grad_norm': 5.429684162139893, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.009734019637107849, 'loss_2': 0.004711151123046875, 'loss_3': -15.98112678527832, 'loss_4': -0.16293446719646454, 'epoch': 10.27}
{'loss': 0.0093, 'grad_norm': 5.309232234954834, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.009100295603275299, 'loss_2': 0.00020587444305419922, 'loss_3': -16.07569122314453, 'loss_4': -0.5483816862106323, 'epoch': 10.28}
{'loss': 0.0265, 'grad_norm': 8.918594360351562, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.023110056295990944, 'loss_2': 0.0034351348876953125, 'loss_3': -15.95068073272705, 'loss_4': -0.7132964134216309, 'epoch': 10.28}
{'loss': 0.0413, 'grad_norm': 10.84953498840332, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.035395629703998566, 'loss_2': 0.005950927734375, 'loss_3': -16.05923080444336, 'loss_4': -0.07794047892093658, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 16:02:44,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:44,667 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [43:57<58:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:52,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031379979103803635, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0247801560908556, 'eval_loss_2': 0.006599828600883484, 'eval_loss_3': -18.107013702392578, 'eval_loss_4': -0.3948223888874054, 'epoch': 10.29}
{'loss': 0.0141, 'grad_norm': 5.0622639656066895, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.012182993814349174, 'loss_2': 0.001941680908203125, 'loss_3': -15.868145942687988, 'loss_4': -0.6276273131370544, 'epoch': 10.3}
{'loss': 0.0156, 'grad_norm': 5.6694722175598145, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.008195735514163971, 'loss_2': 0.00745391845703125, 'loss_3': -15.984253883361816, 'loss_4': -0.24153348803520203, 'epoch': 10.3}
{'loss': 0.0256, 'grad_norm': 10.900081634521484, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.01979232020676136, 'loss_2': 0.00579071044921875, 'loss_3': -16.019046783447266, 'loss_4': 0.055239856243133545, 'epoch': 10.31}
{'loss': 0.021, 'grad_norm': 6.731463432312012, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.016956673935055733, 'loss_2': 0.00408172607421875, 'loss_3': -15.905905723571777, 'loss_4': -0.2430523931980133, 'epoch': 10.31}
{'loss': 0.0236, 'grad_norm': 5.9677300453186035, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.014118451625108719, 'loss_2': 0.009521484375, 'loss_3': -15.883011817932129, 'loss_4': -0.6044647693634033, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 16:02:52,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:52,012 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:04<58:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:59,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022640420123934746, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016139205545186996, 'eval_loss_2': 0.0065012127161026, 'eval_loss_3': -18.17438507080078, 'eval_loss_4': -0.3145626187324524, 'epoch': 10.32}
{'loss': 0.017, 'grad_norm': 6.433867931365967, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.011638528667390347, 'loss_2': 0.005401611328125, 'loss_3': -16.049585342407227, 'loss_4': -0.5284820795059204, 'epoch': 10.33}
{'loss': 0.0254, 'grad_norm': 11.199386596679688, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.024036645889282227, 'loss_2': 0.001377105712890625, 'loss_3': -15.928640365600586, 'loss_4': -0.5993427038192749, 'epoch': 10.33}
{'loss': 0.0108, 'grad_norm': 6.403573036193848, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.010448132641613483, 'loss_2': 0.0003764629364013672, 'loss_3': -16.14449691772461, 'loss_4': -0.5674967169761658, 'epoch': 10.34}
{'loss': 0.0208, 'grad_norm': 6.891273021697998, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.013595455326139927, 'loss_2': 0.00716400146484375, 'loss_3': -15.926861763000488, 'loss_4': -0.06271493434906006, 'epoch': 10.34}
{'loss': 0.0073, 'grad_norm': 5.117480278015137, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.00689741363748908, 'loss_2': 0.0004467964172363281, 'loss_3': -16.162250518798828, 'loss_4': -0.36128681898117065, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 16:02:59,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:59,349 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:12<58:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:06,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021663375198841095, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01607889123260975, 'eval_loss_2': 0.005584482103586197, 'eval_loss_3': -18.23451042175293, 'eval_loss_4': -0.3604883849620819, 'epoch': 10.35}
{'loss': 0.0396, 'grad_norm': 8.454634666442871, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.021213071420788765, 'loss_2': 0.0183563232421875, 'loss_3': -15.802755355834961, 'loss_4': -0.23214304447174072, 'epoch': 10.35}
{'loss': 0.0521, 'grad_norm': 18.354246139526367, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.045157015323638916, 'loss_2': 0.006988525390625, 'loss_3': -16.013700485229492, 'loss_4': 0.031263526529073715, 'epoch': 10.36}
{'loss': 0.0212, 'grad_norm': 5.532536029815674, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.010814623907208443, 'loss_2': 0.010406494140625, 'loss_3': -16.054197311401367, 'loss_4': 0.2739700376987457, 'epoch': 10.37}
{'loss': 0.0358, 'grad_norm': 13.107515335083008, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.029632538557052612, 'loss_2': 0.006122589111328125, 'loss_3': -16.170825958251953, 'loss_4': -0.2458309531211853, 'epoch': 10.37}
{'loss': 0.0276, 'grad_norm': 6.002509117126465, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.01215063314884901, 'loss_2': 0.0154876708984375, 'loss_3': -16.216636657714844, 'loss_4': 0.054717496037483215, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 16:03:06,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:06,696 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:19<58:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:14,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025515586137771606, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015988260507583618, 'eval_loss_2': 0.009527325630187988, 'eval_loss_3': -18.229063034057617, 'eval_loss_4': -0.19796966016292572, 'epoch': 10.38}
{'loss': 0.0428, 'grad_norm': 14.068346977233887, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.03805001080036163, 'loss_2': 0.004711151123046875, 'loss_3': -16.038375854492188, 'loss_4': -0.3046627640724182, 'epoch': 10.38}
{'loss': 0.0128, 'grad_norm': 5.362626552581787, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.00949717964977026, 'loss_2': 0.00334930419921875, 'loss_3': -16.071922302246094, 'loss_4': 0.18343521654605865, 'epoch': 10.39}
{'loss': 0.0273, 'grad_norm': 8.566688537597656, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.01713877171278, 'loss_2': 0.0101318359375, 'loss_3': -16.0163516998291, 'loss_4': 0.006948068737983704, 'epoch': 10.4}
{'loss': 0.0265, 'grad_norm': 9.622268676757812, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.02558950148522854, 'loss_2': 0.0009369850158691406, 'loss_3': -16.087682723999023, 'loss_4': -0.20593205094337463, 'epoch': 10.4}
{'loss': 0.019, 'grad_norm': 8.270684242248535, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.018746165558695793, 'loss_2': 0.000263214111328125, 'loss_3': -16.157669067382812, 'loss_4': 0.18213443458080292, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 16:03:14,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:14,051 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:26<58:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:21,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019511744379997253, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014960631728172302, 'eval_loss_2': 0.004551112651824951, 'eval_loss_3': -18.217609405517578, 'eval_loss_4': 0.07552170753479004, 'epoch': 10.41}
{'loss': 0.0138, 'grad_norm': 6.717442989349365, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.013721790164709091, 'loss_2': 0.0001138448715209961, 'loss_3': -16.231857299804688, 'loss_4': 0.20952942967414856, 'epoch': 10.41}
{'loss': 0.0203, 'grad_norm': 6.62957239151001, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.01432139053940773, 'loss_2': 0.0059356689453125, 'loss_3': -16.101743698120117, 'loss_4': -0.4101404845714569, 'epoch': 10.42}
{'loss': 0.0171, 'grad_norm': 6.927975177764893, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.014255061745643616, 'loss_2': 0.0028934478759765625, 'loss_3': -16.014862060546875, 'loss_4': 0.38401371240615845, 'epoch': 10.42}
{'loss': 0.0257, 'grad_norm': 7.438562870025635, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.017094062641263008, 'loss_2': 0.00858306884765625, 'loss_3': -15.98221206665039, 'loss_4': 0.21196813881397247, 'epoch': 10.43}
{'loss': 0.0401, 'grad_norm': 14.273036003112793, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.028181789442896843, 'loss_2': 0.01190185546875, 'loss_3': -15.984195709228516, 'loss_4': 0.3904775083065033, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 16:03:21,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:21,393 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:34<58:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:28,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020910806953907013, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016027817502617836, 'eval_loss_2': 0.004882991313934326, 'eval_loss_3': -18.219444274902344, 'eval_loss_4': 0.32301682233810425, 'epoch': 10.44}
{'loss': 0.0246, 'grad_norm': 8.165432929992676, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.017377231270074844, 'loss_2': 0.00725555419921875, 'loss_3': -16.129924774169922, 'loss_4': 0.3134625554084778, 'epoch': 10.44}
{'loss': 0.0502, 'grad_norm': 12.697628021240234, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.03682564198970795, 'loss_2': 0.013336181640625, 'loss_3': -16.00604248046875, 'loss_4': 0.09334301948547363, 'epoch': 10.45}
{'loss': 0.0255, 'grad_norm': 12.114984512329102, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.02538798563182354, 'loss_2': 9.775161743164062e-05, 'loss_3': -16.074644088745117, 'loss_4': 0.25920718908309937, 'epoch': 10.45}
{'loss': 0.0265, 'grad_norm': 6.069173336029053, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.01471824198961258, 'loss_2': 0.011810302734375, 'loss_3': -15.962064743041992, 'loss_4': 0.5912845730781555, 'epoch': 10.46}
{'loss': 0.0813, 'grad_norm': 11.942952156066895, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.07341771572828293, 'loss_2': 0.00789642333984375, 'loss_3': -16.046960830688477, 'loss_4': 1.0939756631851196, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 16:03:28,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:28,734 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:41<57:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:36,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026964221149683, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.022517073899507523, 'eval_loss_2': 0.004447147250175476, 'eval_loss_3': -18.128686904907227, 'eval_loss_4': 0.38010719418525696, 'epoch': 10.47}
{'loss': 0.014, 'grad_norm': 5.12506628036499, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.013602624647319317, 'loss_2': 0.00039315223693847656, 'loss_3': -15.959228515625, 'loss_4': 0.2816385328769684, 'epoch': 10.47}
{'loss': 0.0213, 'grad_norm': 5.2242207527160645, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.014828421175479889, 'loss_2': 0.006496429443359375, 'loss_3': -16.00661849975586, 'loss_4': 0.7236022353172302, 'epoch': 10.48}
{'loss': 0.0167, 'grad_norm': 5.248795509338379, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.013997860252857208, 'loss_2': 0.00274658203125, 'loss_3': -15.945089340209961, 'loss_4': 0.17277884483337402, 'epoch': 10.48}
{'loss': 0.0284, 'grad_norm': 7.011333465576172, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.02735055238008499, 'loss_2': 0.0010118484497070312, 'loss_3': -16.1085147857666, 'loss_4': 0.6543292999267578, 'epoch': 10.49}
{'loss': 0.0124, 'grad_norm': 5.492076396942139, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.0065498026087880135, 'loss_2': 0.0058746337890625, 'loss_3': -16.023700714111328, 'loss_4': -0.1428617686033249, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 16:03:36,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:36,073 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [44:48<57:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:43,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033666837960481644, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.028344858437776566, 'eval_loss_2': 0.005321979522705078, 'eval_loss_3': -18.034814834594727, 'eval_loss_4': 0.4250292479991913, 'epoch': 10.49}
{'loss': 0.0706, 'grad_norm': 18.07662010192871, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.06457782536745071, 'loss_2': 0.005977630615234375, 'loss_3': -15.773233413696289, 'loss_4': 0.23366689682006836, 'epoch': 10.5}
{'loss': 0.0117, 'grad_norm': 5.2142558097839355, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.01003323681652546, 'loss_2': 0.0016994476318359375, 'loss_3': -15.879511833190918, 'loss_4': 0.04529312998056412, 'epoch': 10.51}
{'loss': 0.0388, 'grad_norm': 17.142236709594727, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.0357576347887516, 'loss_2': 0.0030841827392578125, 'loss_3': -15.731254577636719, 'loss_4': 0.23794549703598022, 'epoch': 10.51}
{'loss': 0.0184, 'grad_norm': 6.391157150268555, 'learning_rate': 1.95e-05, 'loss_1': 0.011776560917496681, 'loss_2': 0.006610870361328125, 'loss_3': -16.187076568603516, 'loss_4': 0.2842043340206146, 'epoch': 10.52}
{'loss': 0.0081, 'grad_norm': 5.149101734161377, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.007512108888477087, 'loss_2': 0.0006346702575683594, 'loss_3': -15.745488166809082, 'loss_4': 0.3815854787826538, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 16:03:43,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:43,416 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [44:56<57:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:50,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03617272898554802, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.031359996646642685, 'eval_loss_2': 0.0048127323389053345, 'eval_loss_3': -18.019390106201172, 'eval_loss_4': 0.3612893223762512, 'epoch': 10.52}
{'loss': 0.0253, 'grad_norm': 6.906118392944336, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.013085856102406979, 'loss_2': 0.012176513671875, 'loss_3': -16.045969009399414, 'loss_4': -0.02002788335084915, 'epoch': 10.53}
{'loss': 0.0132, 'grad_norm': 5.595761299133301, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.012157340534031391, 'loss_2': 0.0010499954223632812, 'loss_3': -15.995307922363281, 'loss_4': 0.43140435218811035, 'epoch': 10.53}
{'loss': 0.0151, 'grad_norm': 5.755061626434326, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.010906883515417576, 'loss_2': 0.00421905517578125, 'loss_3': -15.97414779663086, 'loss_4': 0.25983673334121704, 'epoch': 10.54}
{'loss': 0.0336, 'grad_norm': 11.290349006652832, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.029854731634259224, 'loss_2': 0.0037822723388671875, 'loss_3': -16.037334442138672, 'loss_4': 0.09097768366336823, 'epoch': 10.55}
{'loss': 0.0144, 'grad_norm': 9.96661376953125, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.013562946580350399, 'loss_2': 0.0008182525634765625, 'loss_3': -15.841588020324707, 'loss_4': 0.32735171914100647, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 16:03:50,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:50,758 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:03<57:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:58,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026640284806489944, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.792, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021784042939543724, 'eval_loss_2': 0.004856247454881668, 'eval_loss_3': -18.023193359375, 'eval_loss_4': 0.24687109887599945, 'epoch': 10.55}
{'loss': 0.0093, 'grad_norm': 4.989448547363281, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.0081400815397501, 'loss_2': 0.0011196136474609375, 'loss_3': -15.809334754943848, 'loss_4': 0.1460169404745102, 'epoch': 10.56}
{'loss': 0.0313, 'grad_norm': 10.496208190917969, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.023598745465278625, 'loss_2': 0.007724761962890625, 'loss_3': -15.877630233764648, 'loss_4': 0.7580821514129639, 'epoch': 10.56}
{'loss': 0.033, 'grad_norm': 18.09590721130371, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.029361983761191368, 'loss_2': 0.003631591796875, 'loss_3': -16.12506675720215, 'loss_4': 0.28164026141166687, 'epoch': 10.57}
{'loss': 0.0337, 'grad_norm': 11.700085639953613, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.023002158850431442, 'loss_2': 0.0107421875, 'loss_3': -15.890328407287598, 'loss_4': 0.16652339696884155, 'epoch': 10.58}
{'loss': 0.0083, 'grad_norm': 4.5906877517700195, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.0058847637847065926, 'loss_2': 0.00244903564453125, 'loss_3': -15.972868919372559, 'loss_4': 0.07037908583879471, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 16:03:58,094 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:58,094 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:10<57:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:05,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0251105185598135, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.02057722769677639, 'eval_loss_2': 0.004533290863037109, 'eval_loss_3': -18.03131866455078, 'eval_loss_4': 0.19841712713241577, 'epoch': 10.58}
{'loss': 0.0161, 'grad_norm': 5.755341053009033, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.009610949084162712, 'loss_2': 0.006504058837890625, 'loss_3': -16.14626693725586, 'loss_4': 0.08494473248720169, 'epoch': 10.59}
{'loss': 0.0119, 'grad_norm': 4.794707298278809, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.007029224652796984, 'loss_2': 0.00484466552734375, 'loss_3': -16.159687042236328, 'loss_4': 0.07289163768291473, 'epoch': 10.59}
{'loss': 0.0124, 'grad_norm': 5.2167558670043945, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.009743157774209976, 'loss_2': 0.0026416778564453125, 'loss_3': -15.79609489440918, 'loss_4': 0.46119534969329834, 'epoch': 10.6}
{'loss': 0.0166, 'grad_norm': 6.356990337371826, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.015598083846271038, 'loss_2': 0.0010433197021484375, 'loss_3': -16.02376365661621, 'loss_4': -0.2031770646572113, 'epoch': 10.6}
{'loss': 0.0299, 'grad_norm': 9.321314811706543, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.02576352097094059, 'loss_2': 0.00411224365234375, 'loss_3': -15.853267669677734, 'loss_4': 0.04234471172094345, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 16:04:05,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:05,436 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:18<57:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:12,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02616562508046627, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02239377796649933, 'eval_loss_2': 0.003771848976612091, 'eval_loss_3': -18.04486656188965, 'eval_loss_4': 0.25097915530204773, 'epoch': 10.61}
{'loss': 0.0181, 'grad_norm': 5.0271430015563965, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.009841764345765114, 'loss_2': 0.008209228515625, 'loss_3': -16.18844985961914, 'loss_4': 0.6524580717086792, 'epoch': 10.62}
{'loss': 0.0252, 'grad_norm': 8.274768829345703, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.01535662729293108, 'loss_2': 0.00980377197265625, 'loss_3': -15.915634155273438, 'loss_4': 0.1149810180068016, 'epoch': 10.62}
{'loss': 0.0146, 'grad_norm': 7.638990879058838, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.01309709157794714, 'loss_2': 0.001476287841796875, 'loss_3': -16.22579574584961, 'loss_4': 0.0038330107927322388, 'epoch': 10.63}
{'loss': 0.0203, 'grad_norm': 5.743778228759766, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.012964501976966858, 'loss_2': 0.00731658935546875, 'loss_3': -16.009435653686523, 'loss_4': 0.47119325399398804, 'epoch': 10.63}
{'loss': 0.0207, 'grad_norm': 6.130071640014648, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.015240803360939026, 'loss_2': 0.0054168701171875, 'loss_3': -15.828873634338379, 'loss_4': 0.29423820972442627, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 16:04:12,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:12,774 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:25<57:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:20,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02613610029220581, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.022214964032173157, 'eval_loss_2': 0.003921136260032654, 'eval_loss_3': -18.070852279663086, 'eval_loss_4': 0.31450051069259644, 'epoch': 10.64}
{'loss': 0.0557, 'grad_norm': 14.546326637268066, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.055448953062295914, 'loss_2': 0.0002815723419189453, 'loss_3': -16.005910873413086, 'loss_4': 0.3584447503089905, 'epoch': 10.65}
{'loss': 0.0175, 'grad_norm': 6.259669780731201, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.015293250791728497, 'loss_2': 0.002178192138671875, 'loss_3': -15.81932544708252, 'loss_4': 0.09371361136436462, 'epoch': 10.65}
{'loss': 0.1385, 'grad_norm': 16.880388259887695, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.12683728337287903, 'loss_2': 0.0117034912109375, 'loss_3': -15.917149543762207, 'loss_4': 0.22892221808433533, 'epoch': 10.66}
{'loss': 0.0268, 'grad_norm': 9.35248851776123, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.017851579934358597, 'loss_2': 0.00891876220703125, 'loss_3': -15.759058952331543, 'loss_4': 0.22539067268371582, 'epoch': 10.66}
{'loss': 0.0107, 'grad_norm': 4.296051979064941, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.009450595825910568, 'loss_2': 0.0012407302856445312, 'loss_3': -16.105863571166992, 'loss_4': 0.3882295489311218, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 16:04:20,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:20,113 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:32<57:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:27,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025651760399341583, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.022129788994789124, 'eval_loss_2': 0.0035219714045524597, 'eval_loss_3': -18.061126708984375, 'eval_loss_4': 0.31595608592033386, 'epoch': 10.67}
{'loss': 0.0165, 'grad_norm': 6.405238151550293, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.0136741753667593, 'loss_2': 0.0028018951416015625, 'loss_3': -16.064971923828125, 'loss_4': -0.19346289336681366, 'epoch': 10.67}
{'loss': 0.0276, 'grad_norm': 13.673567771911621, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.024694515392184258, 'loss_2': 0.00286865234375, 'loss_3': -15.717138290405273, 'loss_4': 0.5925192832946777, 'epoch': 10.68}
{'loss': 0.0176, 'grad_norm': 6.539736270904541, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.014899453148245811, 'loss_2': 0.002750396728515625, 'loss_3': -15.829004287719727, 'loss_4': 0.29585105180740356, 'epoch': 10.69}
{'loss': 0.0191, 'grad_norm': 8.484435081481934, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.01549206767231226, 'loss_2': 0.003566741943359375, 'loss_3': -15.722516059875488, 'loss_4': 0.36165711283683777, 'epoch': 10.69}
{'loss': 0.0293, 'grad_norm': 16.806005477905273, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.021590564399957657, 'loss_2': 0.007740020751953125, 'loss_3': -16.00674057006836, 'loss_4': 0.5501986145973206, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 16:04:27,452 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:27,452 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:40<57:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:34,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025544220581650734, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.020958058536052704, 'eval_loss_2': 0.004586160182952881, 'eval_loss_3': -18.03820037841797, 'eval_loss_4': 0.15521596372127533, 'epoch': 10.7}
{'loss': 0.0179, 'grad_norm': 7.115772724151611, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.009837259538471699, 'loss_2': 0.0080413818359375, 'loss_3': -16.131134033203125, 'loss_4': -0.012809298932552338, 'epoch': 10.7}
{'loss': 0.0269, 'grad_norm': 10.219223022460938, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.024590779095888138, 'loss_2': 0.002315521240234375, 'loss_3': -16.035512924194336, 'loss_4': 0.5288994312286377, 'epoch': 10.71}
{'loss': 0.015, 'grad_norm': 7.164445400238037, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.014673843048512936, 'loss_2': 0.0003681182861328125, 'loss_3': -16.05333137512207, 'loss_4': -0.28336894512176514, 'epoch': 10.72}
{'loss': 0.0213, 'grad_norm': 8.739157676696777, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.018513083457946777, 'loss_2': 0.0027561187744140625, 'loss_3': -15.829120635986328, 'loss_4': -0.18880178034305573, 'epoch': 10.72}
{'loss': 0.0202, 'grad_norm': 10.344371795654297, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.0195813849568367, 'loss_2': 0.000576019287109375, 'loss_3': -15.827136039733887, 'loss_4': 0.19914287328720093, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 16:04:34,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:34,795 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [45:47<57:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:42,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028374237939715385, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.023411734029650688, 'eval_loss_2': 0.004962503910064697, 'eval_loss_3': -18.02873992919922, 'eval_loss_4': -0.06343380361795425, 'epoch': 10.73}
{'loss': 0.0136, 'grad_norm': 5.527531623840332, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.0134922806173563, 'loss_2': 9.620189666748047e-05, 'loss_3': -15.74822998046875, 'loss_4': 0.3779132664203644, 'epoch': 10.73}
{'loss': 0.0191, 'grad_norm': 5.617045879364014, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.010638860985636711, 'loss_2': 0.0084381103515625, 'loss_3': -16.127256393432617, 'loss_4': -0.24523288011550903, 'epoch': 10.74}
{'loss': 0.0159, 'grad_norm': 6.942539691925049, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.01442650705575943, 'loss_2': 0.0014495849609375, 'loss_3': -15.862112045288086, 'loss_4': -0.4454621374607086, 'epoch': 10.74}
{'loss': 0.0361, 'grad_norm': 7.735495090484619, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.024073751643300056, 'loss_2': 0.012054443359375, 'loss_3': -16.106243133544922, 'loss_4': 0.25692760944366455, 'epoch': 10.75}
{'loss': 0.0577, 'grad_norm': 14.674118041992188, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.04826251417398453, 'loss_2': 0.00940704345703125, 'loss_3': -15.983572959899902, 'loss_4': -0.1724652647972107, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 16:04:42,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:42,131 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [45:54<57:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:49,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.043340276926755905, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.742, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.031216928735375404, 'eval_loss_2': 0.012123346328735352, 'eval_loss_3': -17.961172103881836, 'eval_loss_4': -0.26488742232322693, 'epoch': 10.76}
{'loss': 0.0234, 'grad_norm': 9.82239055633545, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.014288106001913548, 'loss_2': 0.00911712646484375, 'loss_3': -15.896520614624023, 'loss_4': -0.6124523878097534, 'epoch': 10.76}
{'loss': 0.0512, 'grad_norm': 17.486997604370117, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.042499735951423645, 'loss_2': 0.00873565673828125, 'loss_3': -16.037212371826172, 'loss_4': -0.39509347081184387, 'epoch': 10.77}
{'loss': 0.038, 'grad_norm': 14.471529006958008, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.03201460465788841, 'loss_2': 0.006000518798828125, 'loss_3': -15.970270156860352, 'loss_4': -0.6025639772415161, 'epoch': 10.77}
{'loss': 0.019, 'grad_norm': 5.849020004272461, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.014763378538191319, 'loss_2': 0.00420379638671875, 'loss_3': -15.846043586730957, 'loss_4': -0.42502614855766296, 'epoch': 10.78}
{'loss': 0.0254, 'grad_norm': 5.030261039733887, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.010605341754853725, 'loss_2': 0.0147552490234375, 'loss_3': -16.067481994628906, 'loss_4': -0.5181683897972107, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 16:04:49,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:49,462 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:02<57:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:56,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06036585569381714, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.665, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.051940739154815674, 'eval_loss_2': 0.008425116539001465, 'eval_loss_3': -17.901355743408203, 'eval_loss_4': -0.5401755571365356, 'epoch': 10.78}
{'loss': 0.0378, 'grad_norm': 11.98160171508789, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.026467973366379738, 'loss_2': 0.011322021484375, 'loss_3': -15.959542274475098, 'loss_4': -0.8184598088264465, 'epoch': 10.79}
{'loss': 0.0177, 'grad_norm': 12.080206871032715, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.016356637701392174, 'loss_2': 0.0013027191162109375, 'loss_3': -16.11430549621582, 'loss_4': -0.6879345774650574, 'epoch': 10.8}
{'loss': 0.0215, 'grad_norm': 7.220185279846191, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.014882218092679977, 'loss_2': 0.0066375732421875, 'loss_3': -16.07697105407715, 'loss_4': -0.8144819736480713, 'epoch': 10.8}
{'loss': 0.0521, 'grad_norm': 19.305150985717773, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.04448718577623367, 'loss_2': 0.00759124755859375, 'loss_3': -15.838455200195312, 'loss_4': -0.6176212430000305, 'epoch': 10.81}
{'loss': 0.0203, 'grad_norm': 7.404001712799072, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.012954393401741982, 'loss_2': 0.0073699951171875, 'loss_3': -16.11916732788086, 'loss_4': -0.9536570310592651, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 16:04:56,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:56,802 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:09<57:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:04,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08708815276622772, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.7, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.08332215994596481, 'eval_loss_2': 0.003765985369682312, 'eval_loss_3': -17.818336486816406, 'eval_loss_4': -0.7962905764579773, 'epoch': 10.81}
{'loss': 0.0255, 'grad_norm': 9.913495063781738, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.02307007648050785, 'loss_2': 0.002414703369140625, 'loss_3': -15.939035415649414, 'loss_4': -0.9135873317718506, 'epoch': 10.82}
{'loss': 0.0209, 'grad_norm': 5.402578830718994, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.00684636365622282, 'loss_2': 0.01403045654296875, 'loss_3': -16.17658805847168, 'loss_4': -0.8659248352050781, 'epoch': 10.83}
{'loss': 0.0319, 'grad_norm': 14.587817192077637, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.02535950392484665, 'loss_2': 0.006561279296875, 'loss_3': -15.880722045898438, 'loss_4': -1.3293644189834595, 'epoch': 10.83}
{'loss': 0.0153, 'grad_norm': 4.875869274139404, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.006052230019122362, 'loss_2': 0.0092010498046875, 'loss_3': -16.078609466552734, 'loss_4': -1.2190871238708496, 'epoch': 10.84}
{'loss': 0.0218, 'grad_norm': 9.815313339233398, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.012842654250562191, 'loss_2': 0.00891876220703125, 'loss_3': -15.979408264160156, 'loss_4': -1.1698702573776245, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 16:05:04,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:04,149 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:16<56:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:11,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.12153185904026031, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.11733005195856094, 'eval_loss_2': 0.004201814532279968, 'eval_loss_3': -17.733911514282227, 'eval_loss_4': -0.8420995473861694, 'epoch': 10.84}
{'loss': 0.04, 'grad_norm': 9.686055183410645, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.037608519196510315, 'loss_2': 0.002376556396484375, 'loss_3': -15.900007247924805, 'loss_4': -0.9470060467720032, 'epoch': 10.85}
{'loss': 0.0698, 'grad_norm': 26.351987838745117, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.06525302678346634, 'loss_2': 0.00450897216796875, 'loss_3': -15.888720512390137, 'loss_4': -1.0584884881973267, 'epoch': 10.85}
{'loss': 0.0215, 'grad_norm': 10.898419380187988, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.01969960331916809, 'loss_2': 0.0018253326416015625, 'loss_3': -15.901418685913086, 'loss_4': -1.4431772232055664, 'epoch': 10.86}
{'loss': 0.0128, 'grad_norm': 6.1772541999816895, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.012605487369000912, 'loss_2': 0.00018227100372314453, 'loss_3': -16.02513313293457, 'loss_4': -1.0512969493865967, 'epoch': 10.87}
{'loss': 0.0133, 'grad_norm': 5.811003684997559, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.008496127091348171, 'loss_2': 0.00484466552734375, 'loss_3': -16.281909942626953, 'loss_4': -0.7702672481536865, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 16:05:11,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:11,495 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:24<56:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:18,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08650623261928558, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.08258246630430222, 'eval_loss_2': 0.003923773765563965, 'eval_loss_3': -17.850452423095703, 'eval_loss_4': -0.7989547252655029, 'epoch': 10.87}
{'loss': 0.0179, 'grad_norm': 8.622485160827637, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.01397014781832695, 'loss_2': 0.0038909912109375, 'loss_3': -16.04802894592285, 'loss_4': -1.3754756450653076, 'epoch': 10.88}
{'loss': 0.0189, 'grad_norm': 8.167852401733398, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.018151795491576195, 'loss_2': 0.0007414817810058594, 'loss_3': -15.837982177734375, 'loss_4': -0.9517257213592529, 'epoch': 10.88}
{'loss': 0.059, 'grad_norm': 15.437237739562988, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.04936836659908295, 'loss_2': 0.00959014892578125, 'loss_3': -16.156211853027344, 'loss_4': -0.8123871088027954, 'epoch': 10.89}
{'loss': 0.0231, 'grad_norm': 7.232284069061279, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.017290949821472168, 'loss_2': 0.00583648681640625, 'loss_3': -16.123266220092773, 'loss_4': -0.8652623891830444, 'epoch': 10.9}
{'loss': 0.008, 'grad_norm': 4.94169807434082, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.005454696249216795, 'loss_2': 0.0025787353515625, 'loss_3': -16.030698776245117, 'loss_4': -0.9647481441497803, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 16:05:18,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:18,836 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:31<56:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:26,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.062256913632154465, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.789, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.05743665620684624, 'eval_loss_2': 0.0048202574253082275, 'eval_loss_3': -17.96733856201172, 'eval_loss_4': -0.7402849793434143, 'epoch': 10.9}
{'loss': 0.0211, 'grad_norm': 9.127543449401855, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.02031608670949936, 'loss_2': 0.00075531005859375, 'loss_3': -16.06756591796875, 'loss_4': -0.7717768549919128, 'epoch': 10.91}
{'loss': 0.0198, 'grad_norm': 7.059532165527344, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.01672399789094925, 'loss_2': 0.003082275390625, 'loss_3': -16.132869720458984, 'loss_4': -0.8702626824378967, 'epoch': 10.91}
{'loss': 0.0208, 'grad_norm': 5.917684555053711, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.011849340051412582, 'loss_2': 0.0089874267578125, 'loss_3': -16.307209014892578, 'loss_4': -0.7187234163284302, 'epoch': 10.92}
{'loss': 0.0231, 'grad_norm': 8.4136381149292, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.019339945167303085, 'loss_2': 0.00371551513671875, 'loss_3': -16.168277740478516, 'loss_4': -1.0695691108703613, 'epoch': 10.92}
{'loss': 0.0106, 'grad_norm': 6.697227954864502, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.007482429035007954, 'loss_2': 0.003162384033203125, 'loss_3': -16.173126220703125, 'loss_4': -0.42170578241348267, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 16:05:26,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:26,169 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:38<56:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:33,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.047274962067604065, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.044033315032720566, 'eval_loss_2': 0.0032416433095932007, 'eval_loss_3': -18.035751342773438, 'eval_loss_4': -0.5916410088539124, 'epoch': 10.93}
{'loss': 0.0275, 'grad_norm': 7.10733699798584, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.016447575762867928, 'loss_2': 0.0110626220703125, 'loss_3': -16.38656234741211, 'loss_4': -0.7967114448547363, 'epoch': 10.94}
{'loss': 0.0846, 'grad_norm': 15.86275863647461, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.08289666473865509, 'loss_2': 0.0017251968383789062, 'loss_3': -16.25786590576172, 'loss_4': -0.36937403678894043, 'epoch': 10.94}
{'loss': 0.0436, 'grad_norm': 11.867050170898438, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.04061609134078026, 'loss_2': 0.002964019775390625, 'loss_3': -16.169193267822266, 'loss_4': -0.22836552560329437, 'epoch': 10.95}
{'loss': 0.0172, 'grad_norm': 6.566805362701416, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.0167248398065567, 'loss_2': 0.0004405975341796875, 'loss_3': -16.06845474243164, 'loss_4': -0.39674264192581177, 'epoch': 10.95}
{'loss': 0.0224, 'grad_norm': 5.444952964782715, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.009746229276061058, 'loss_2': 0.0126190185546875, 'loss_3': -16.23733139038086, 'loss_4': -0.612884521484375, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 16:05:33,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:33,505 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [46:46<56:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:40,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03609476238489151, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.76, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0303446426987648, 'eval_loss_2': 0.005750119686126709, 'eval_loss_3': -18.111310958862305, 'eval_loss_4': -0.4537371098995209, 'epoch': 10.96}
{'loss': 0.0291, 'grad_norm': 10.93909740447998, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.027796171605587006, 'loss_2': 0.0012874603271484375, 'loss_3': -16.260944366455078, 'loss_4': -0.7650939226150513, 'epoch': 10.97}
{'loss': 0.0424, 'grad_norm': 13.143739700317383, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.04051034525036812, 'loss_2': 0.00191497802734375, 'loss_3': -16.126354217529297, 'loss_4': -0.36168843507766724, 'epoch': 10.97}
{'loss': 0.0984, 'grad_norm': 32.86294937133789, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.09162422269582748, 'loss_2': 0.006805419921875, 'loss_3': -16.103591918945312, 'loss_4': -0.16256558895111084, 'epoch': 10.98}
{'loss': 0.0405, 'grad_norm': 9.17106819152832, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.027481449767947197, 'loss_2': 0.0129852294921875, 'loss_3': -16.100215911865234, 'loss_4': -0.4896862506866455, 'epoch': 10.98}
{'loss': 0.0206, 'grad_norm': 7.400912284851074, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.0168001726269722, 'loss_2': 0.003765106201171875, 'loss_3': -16.098709106445312, 'loss_4': -0.43651801347732544, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 16:05:40,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:40,843 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [46:53<54:43,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:05:47,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026511386036872864, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.324, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.021745696663856506, 'eval_loss_2': 0.004765689373016357, 'eval_loss_3': -18.15360450744629, 'eval_loss_4': -0.17703425884246826, 'epoch': 10.99}
{'loss': 0.0375, 'grad_norm': 20.533119201660156, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.03352672979235649, 'loss_2': 0.0039825439453125, 'loss_3': -16.267288208007812, 'loss_4': -0.28272107243537903, 'epoch': 10.99}
{'loss': 0.0104, 'grad_norm': 9.135486602783203, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.006323127541691065, 'loss_2': 0.0040740966796875, 'loss_3': -16.361886978149414, 'loss_4': -0.22590920329093933, 'epoch': 11.0}
{'loss': 0.0289, 'grad_norm': 9.074850082397461, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.025055374950170517, 'loss_2': 0.0038909912109375, 'loss_3': -16.14129638671875, 'loss_4': 0.36839914321899414, 'epoch': 11.01}
{'loss': 0.0331, 'grad_norm': 22.877714157104492, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.02654307335615158, 'loss_2': 0.006561279296875, 'loss_3': -16.169340133666992, 'loss_4': -0.04266516864299774, 'epoch': 11.01}
{'loss': 0.02, 'grad_norm': 7.3872270584106445, 'learning_rate': 1.9e-05, 'loss_1': 0.015206919983029366, 'loss_2': 0.004749298095703125, 'loss_3': -16.11187171936035, 'loss_4': -0.02825099229812622, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 16:05:47,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:47,867 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:00<55:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:05:55,196 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02249755524098873, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.779, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01801462657749653, 'eval_loss_2': 0.004482924938201904, 'eval_loss_3': -18.207576751708984, 'eval_loss_4': -0.1033860296010971, 'epoch': 11.02}
{'loss': 0.015, 'grad_norm': 6.812342166900635, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.014266044832766056, 'loss_2': 0.00070953369140625, 'loss_3': -16.27875518798828, 'loss_4': 0.08926023542881012, 'epoch': 11.02}
{'loss': 0.0217, 'grad_norm': 7.911276817321777, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.019806021824479103, 'loss_2': 0.001918792724609375, 'loss_3': -16.25392723083496, 'loss_4': -0.0014996863901615143, 'epoch': 11.03}
{'loss': 0.0128, 'grad_norm': 5.388843059539795, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.012028767727315426, 'loss_2': 0.0007867813110351562, 'loss_3': -16.103742599487305, 'loss_4': -0.09622329473495483, 'epoch': 11.03}
{'loss': 0.0195, 'grad_norm': 5.880233287811279, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.015104417689144611, 'loss_2': 0.004390716552734375, 'loss_3': -16.032257080078125, 'loss_4': -0.055716365575790405, 'epoch': 11.04}
{'loss': 0.0125, 'grad_norm': 4.804126739501953, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.008050750941038132, 'loss_2': 0.0044403076171875, 'loss_3': -16.397132873535156, 'loss_4': 0.03413894772529602, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 16:05:55,196 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:55,196 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:07<56:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:02,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020350079983472824, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.907, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016906682401895523, 'eval_loss_2': 0.003443397581577301, 'eval_loss_3': -18.22080421447754, 'eval_loss_4': -0.10622124373912811, 'epoch': 11.05}
{'loss': 0.0217, 'grad_norm': 9.158504486083984, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.02168433554470539, 'loss_2': 5.3882598876953125e-05, 'loss_3': -16.233524322509766, 'loss_4': 0.4911637306213379, 'epoch': 11.05}
{'loss': 0.014, 'grad_norm': 5.919906139373779, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.012894079089164734, 'loss_2': 0.001102447509765625, 'loss_3': -16.3709716796875, 'loss_4': 0.5071016550064087, 'epoch': 11.06}
{'loss': 0.0234, 'grad_norm': 13.39559268951416, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.017307426780462265, 'loss_2': 0.006137847900390625, 'loss_3': -16.159141540527344, 'loss_4': 0.13184796273708344, 'epoch': 11.06}
{'loss': 0.0615, 'grad_norm': 14.9766845703125, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.056185752153396606, 'loss_2': 0.0053558349609375, 'loss_3': -16.07077980041504, 'loss_4': 0.3426263630390167, 'epoch': 11.07}
{'loss': 0.0239, 'grad_norm': 8.196805953979492, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.021787505596876144, 'loss_2': 0.002105712890625, 'loss_3': -16.47749900817871, 'loss_4': -0.3326517939567566, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 16:06:02,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:02,528 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:15<56:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:09,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022816121578216553, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.896, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018764451146125793, 'eval_loss_2': 0.004051670432090759, 'eval_loss_3': -18.19878578186035, 'eval_loss_4': -0.21707729995250702, 'epoch': 11.08}
{'loss': 0.0214, 'grad_norm': 8.089038848876953, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.020262423902750015, 'loss_2': 0.0011844635009765625, 'loss_3': -16.33013153076172, 'loss_4': -0.08513032644987106, 'epoch': 11.08}
{'loss': 0.0328, 'grad_norm': 10.118117332458496, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.03095906786620617, 'loss_2': 0.001861572265625, 'loss_3': -16.04991912841797, 'loss_4': 0.05997762084007263, 'epoch': 11.09}
{'loss': 0.0259, 'grad_norm': 9.850508689880371, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.025488656014204025, 'loss_2': 0.0004222393035888672, 'loss_3': -16.166189193725586, 'loss_4': 0.11666818708181381, 'epoch': 11.09}
{'loss': 0.0407, 'grad_norm': 15.939077377319336, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.03396659344434738, 'loss_2': 0.00678253173828125, 'loss_3': -16.39508628845215, 'loss_4': 0.011976607143878937, 'epoch': 11.1}
{'loss': 0.0368, 'grad_norm': 10.617218017578125, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.03270210325717926, 'loss_2': 0.00411224365234375, 'loss_3': -16.158214569091797, 'loss_4': -0.022482864558696747, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 16:06:09,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:09,861 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:22<55:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:06:17,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023436542600393295, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.757, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.020220618695020676, 'eval_loss_2': 0.0032159239053726196, 'eval_loss_3': -18.15829849243164, 'eval_loss_4': -0.32775822281837463, 'epoch': 11.1}
{'loss': 0.0314, 'grad_norm': 7.052646636962891, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.02055354416370392, 'loss_2': 0.01087188720703125, 'loss_3': -16.10696029663086, 'loss_4': -0.4391058087348938, 'epoch': 11.11}
{'loss': 0.0166, 'grad_norm': 5.872966766357422, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.015439464710652828, 'loss_2': 0.0011568069458007812, 'loss_3': -16.320165634155273, 'loss_4': -0.11315537244081497, 'epoch': 11.12}
{'loss': 0.0236, 'grad_norm': 7.594259738922119, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.023046404123306274, 'loss_2': 0.0005521774291992188, 'loss_3': -16.239782333374023, 'loss_4': 0.11788725852966309, 'epoch': 11.12}
{'loss': 0.0454, 'grad_norm': 15.224793434143066, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.038894664496183395, 'loss_2': 0.0064849853515625, 'loss_3': -16.258380889892578, 'loss_4': -0.13261032104492188, 'epoch': 11.13}
{'loss': 0.0181, 'grad_norm': 6.509914875030518, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.017326561734080315, 'loss_2': 0.0008082389831542969, 'loss_3': -16.24962615966797, 'loss_4': -0.7333390116691589, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 16:06:17,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:17,192 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:29<55:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:24,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027588598430156708, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.824, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.022214671596884727, 'eval_loss_2': 0.005373924970626831, 'eval_loss_3': -18.13313102722168, 'eval_loss_4': -0.30778422951698303, 'epoch': 11.13}
{'loss': 0.0255, 'grad_norm': 8.72756576538086, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.019738446921110153, 'loss_2': 0.005756378173828125, 'loss_3': -16.263376235961914, 'loss_4': 0.2255258858203888, 'epoch': 11.14}
{'loss': 0.0736, 'grad_norm': 17.34081268310547, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.061581846326589584, 'loss_2': 0.01200103759765625, 'loss_3': -16.034469604492188, 'loss_4': -0.09827135503292084, 'epoch': 11.15}
{'loss': 0.0207, 'grad_norm': 6.903987884521484, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.01983608305454254, 'loss_2': 0.000835418701171875, 'loss_3': -16.23937225341797, 'loss_4': 0.08672842383384705, 'epoch': 11.15}
{'loss': 0.034, 'grad_norm': 9.61950969696045, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.024646377190947533, 'loss_2': 0.00939178466796875, 'loss_3': -16.071924209594727, 'loss_4': -0.08867838978767395, 'epoch': 11.16}
{'loss': 0.0279, 'grad_norm': 6.603583335876465, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.018768545240163803, 'loss_2': 0.00917816162109375, 'loss_3': -15.874147415161133, 'loss_4': -0.5079567432403564, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 16:06:24,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:24,524 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:37<55:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:31,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02579524554312229, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.385, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0223136767745018, 'eval_loss_2': 0.003481566905975342, 'eval_loss_3': -18.116268157958984, 'eval_loss_4': -0.2129969298839569, 'epoch': 11.16}
{'loss': 0.0158, 'grad_norm': 5.749547958374023, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.011272752657532692, 'loss_2': 0.0045318603515625, 'loss_3': -16.261085510253906, 'loss_4': -0.42920202016830444, 'epoch': 11.17}
{'loss': 0.0269, 'grad_norm': 12.133371353149414, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.025047168135643005, 'loss_2': 0.0018138885498046875, 'loss_3': -16.19061851501465, 'loss_4': -0.003761976957321167, 'epoch': 11.17}
{'loss': 0.0273, 'grad_norm': 8.732951164245605, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.023280713707208633, 'loss_2': 0.00397491455078125, 'loss_3': -16.158187866210938, 'loss_4': 0.2516162097454071, 'epoch': 11.18}
{'loss': 0.02, 'grad_norm': 7.225453853607178, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.015011360868811607, 'loss_2': 0.00495147705078125, 'loss_3': -16.182849884033203, 'loss_4': -0.09302915632724762, 'epoch': 11.19}
{'loss': 0.0379, 'grad_norm': 10.140623092651367, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.03663153201341629, 'loss_2': 0.0013036727905273438, 'loss_3': -16.117923736572266, 'loss_4': 0.049418628215789795, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 16:06:31,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:31,862 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:44<55:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:39,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027889443561434746, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02453530952334404, 'eval_loss_2': 0.0033541321754455566, 'eval_loss_3': -18.107284545898438, 'eval_loss_4': 0.12169227749109268, 'epoch': 11.19}
{'loss': 0.0371, 'grad_norm': 10.747476577758789, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.03522338345646858, 'loss_2': 0.001850128173828125, 'loss_3': -15.98276138305664, 'loss_4': 0.04763465002179146, 'epoch': 11.2}
{'loss': 0.0122, 'grad_norm': 4.989015102386475, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.00917486660182476, 'loss_2': 0.00307464599609375, 'loss_3': -15.967536926269531, 'loss_4': 0.28981614112854004, 'epoch': 11.2}
{'loss': 0.0315, 'grad_norm': 19.757675170898438, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.030505871400237083, 'loss_2': 0.0010251998901367188, 'loss_3': -16.22525405883789, 'loss_4': 0.972300112247467, 'epoch': 11.21}
{'loss': 0.043, 'grad_norm': 28.488468170166016, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.034697651863098145, 'loss_2': 0.00826263427734375, 'loss_3': -16.270557403564453, 'loss_4': 0.5767433643341064, 'epoch': 11.22}
{'loss': 0.0138, 'grad_norm': 5.3011298179626465, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.012507726438343525, 'loss_2': 0.0012683868408203125, 'loss_3': -16.10253143310547, 'loss_4': 0.30606237053871155, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 16:06:39,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:39,197 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [47:51<55:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:46,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030754219740629196, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.025407088920474052, 'eval_loss_2': 0.005347132682800293, 'eval_loss_3': -18.11469268798828, 'eval_loss_4': 0.197494238615036, 'epoch': 11.22}
{'loss': 0.0064, 'grad_norm': 4.56298303604126, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.005913643166422844, 'loss_2': 0.00046539306640625, 'loss_3': -16.358821868896484, 'loss_4': 0.3126069903373718, 'epoch': 11.23}
{'loss': 0.0264, 'grad_norm': 13.694121360778809, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.024533016607165337, 'loss_2': 0.0018939971923828125, 'loss_3': -16.274137496948242, 'loss_4': 0.14642423391342163, 'epoch': 11.23}
{'loss': 0.0276, 'grad_norm': 9.479171752929688, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.020662812516093254, 'loss_2': 0.00688934326171875, 'loss_3': -16.176990509033203, 'loss_4': 0.045995742082595825, 'epoch': 11.24}
{'loss': 0.0177, 'grad_norm': 7.193207263946533, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.01432634424418211, 'loss_2': 0.003398895263671875, 'loss_3': -16.204261779785156, 'loss_4': 0.25879767537117004, 'epoch': 11.24}
{'loss': 0.0221, 'grad_norm': 8.597845077514648, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.019429843872785568, 'loss_2': 0.0026645660400390625, 'loss_3': -16.24359893798828, 'loss_4': 0.22725680470466614, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 16:06:46,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:46,535 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [47:59<55:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:53,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0289662703871727, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.945, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02402837574481964, 'eval_loss_2': 0.004937894642353058, 'eval_loss_3': -18.159454345703125, 'eval_loss_4': 0.12961594760417938, 'epoch': 11.25}
{'loss': 0.0342, 'grad_norm': 16.726848602294922, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.028549904003739357, 'loss_2': 0.0056304931640625, 'loss_3': -16.1475830078125, 'loss_4': 0.07101006805896759, 'epoch': 11.26}
{'loss': 0.0189, 'grad_norm': 7.123395919799805, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.013692698441445827, 'loss_2': 0.00525665283203125, 'loss_3': -16.374021530151367, 'loss_4': 0.2139507234096527, 'epoch': 11.26}
{'loss': 0.0192, 'grad_norm': 7.5098161697387695, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.013303475454449654, 'loss_2': 0.00592803955078125, 'loss_3': -16.208820343017578, 'loss_4': 0.006336867809295654, 'epoch': 11.27}
{'loss': 0.022, 'grad_norm': 7.375545501708984, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.018499188125133514, 'loss_2': 0.00351715087890625, 'loss_3': -16.022563934326172, 'loss_4': -0.23099565505981445, 'epoch': 11.27}
{'loss': 0.0508, 'grad_norm': 11.050668716430664, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.05061936751008034, 'loss_2': 0.00015616416931152344, 'loss_3': -16.254446029663086, 'loss_4': 0.38313034176826477, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 16:06:53,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:53,864 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:06<55:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:01,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026615027338266373, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.851, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.022938527166843414, 'eval_loss_2': 0.003676503896713257, 'eval_loss_3': -18.180774688720703, 'eval_loss_4': -0.13667544722557068, 'epoch': 11.28}
{'loss': 0.0176, 'grad_norm': 4.97595739364624, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.01610657013952732, 'loss_2': 0.0014801025390625, 'loss_3': -16.23387908935547, 'loss_4': -0.2433626800775528, 'epoch': 11.28}
{'loss': 0.0237, 'grad_norm': 7.752364158630371, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.022754192352294922, 'loss_2': 0.0009479522705078125, 'loss_3': -16.173725128173828, 'loss_4': -0.188086599111557, 'epoch': 11.29}
{'loss': 0.0847, 'grad_norm': 30.284412384033203, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.08435177803039551, 'loss_2': 0.00039076805114746094, 'loss_3': -16.043930053710938, 'loss_4': 0.18923382461071014, 'epoch': 11.3}
{'loss': 0.0259, 'grad_norm': 6.986033916473389, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.019525282084941864, 'loss_2': 0.006351470947265625, 'loss_3': -16.168807983398438, 'loss_4': -0.2160128504037857, 'epoch': 11.3}
{'loss': 0.0375, 'grad_norm': 15.35604190826416, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.029984911903738976, 'loss_2': 0.0074920654296875, 'loss_3': -16.2377872467041, 'loss_4': -0.11890186369419098, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 16:07:01,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:01,200 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:13<55:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:08,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030524160712957382, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02322843298316002, 'eval_loss_2': 0.007295727729797363, 'eval_loss_3': -18.159423828125, 'eval_loss_4': -0.29619333148002625, 'epoch': 11.31}
{'loss': 0.0569, 'grad_norm': 21.284658432006836, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.048336680978536606, 'loss_2': 0.008575439453125, 'loss_3': -16.037071228027344, 'loss_4': -0.3869704604148865, 'epoch': 11.31}
{'loss': 0.0311, 'grad_norm': 8.388611793518066, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.02544519491493702, 'loss_2': 0.0056304931640625, 'loss_3': -16.084239959716797, 'loss_4': -0.4327540397644043, 'epoch': 11.32}
{'loss': 0.0263, 'grad_norm': 9.46513557434082, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.01940234564244747, 'loss_2': 0.006946563720703125, 'loss_3': -16.300853729248047, 'loss_4': -0.29014477133750916, 'epoch': 11.33}
{'loss': 0.0294, 'grad_norm': 7.7000861167907715, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.025690700858831406, 'loss_2': 0.003719329833984375, 'loss_3': -16.18459701538086, 'loss_4': -0.2849430739879608, 'epoch': 11.33}
{'loss': 0.0226, 'grad_norm': 7.499233245849609, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.018336234614253044, 'loss_2': 0.004276275634765625, 'loss_3': -16.182634353637695, 'loss_4': -0.7707971930503845, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 16:07:08,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:08,539 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:21<55:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:15,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03008304163813591, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.026121236383914948, 'eval_loss_2': 0.003961801528930664, 'eval_loss_3': -18.1207275390625, 'eval_loss_4': -0.411726176738739, 'epoch': 11.34}
{'loss': 0.0907, 'grad_norm': 13.866219520568848, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.0853431224822998, 'loss_2': 0.00534820556640625, 'loss_3': -16.209068298339844, 'loss_4': -0.0944068655371666, 'epoch': 11.34}
{'loss': 0.0164, 'grad_norm': 5.662259578704834, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.012525971978902817, 'loss_2': 0.003887176513671875, 'loss_3': -16.12889862060547, 'loss_4': -0.3468117415904999, 'epoch': 11.35}
{'loss': 0.0124, 'grad_norm': 4.578849792480469, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.007846212945878506, 'loss_2': 0.004547119140625, 'loss_3': -16.126041412353516, 'loss_4': -0.057368919253349304, 'epoch': 11.35}
{'loss': 0.0151, 'grad_norm': 5.726158142089844, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.012363328598439693, 'loss_2': 0.00273895263671875, 'loss_3': -16.192874908447266, 'loss_4': -0.4470006823539734, 'epoch': 11.36}
{'loss': 0.0143, 'grad_norm': 8.429466247558594, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.012471752241253853, 'loss_2': 0.0017795562744140625, 'loss_3': -15.988515853881836, 'loss_4': -0.20784446597099304, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 16:07:15,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:15,870 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:28<55:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:07:23,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03493610769510269, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.030775735154747963, 'eval_loss_2': 0.004160374402999878, 'eval_loss_3': -18.06476402282715, 'eval_loss_4': -0.27225396037101746, 'epoch': 11.37}
{'loss': 0.0186, 'grad_norm': 5.908996105194092, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.014465794898569584, 'loss_2': 0.00409698486328125, 'loss_3': -16.11601448059082, 'loss_4': -0.24130450189113617, 'epoch': 11.37}
{'loss': 0.0193, 'grad_norm': 9.814796447753906, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.018092244863510132, 'loss_2': 0.001216888427734375, 'loss_3': -16.243776321411133, 'loss_4': -0.2053324580192566, 'epoch': 11.38}
{'loss': 0.0091, 'grad_norm': 4.8785247802734375, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.006122851278632879, 'loss_2': 0.0029296875, 'loss_3': -16.306758880615234, 'loss_4': -0.4279390573501587, 'epoch': 11.38}
{'loss': 0.011, 'grad_norm': 4.634602069854736, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.00840718112885952, 'loss_2': 0.002635955810546875, 'loss_3': -16.127485275268555, 'loss_4': -0.14565475285053253, 'epoch': 11.39}
{'loss': 0.0184, 'grad_norm': 5.390608310699463, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.007865066640079021, 'loss_2': 0.0105743408203125, 'loss_3': -15.841875076293945, 'loss_4': -0.35145097970962524, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 16:07:23,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:23,202 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:35<55:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:30,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03508933633565903, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.02845584601163864, 'eval_loss_2': 0.006633490324020386, 'eval_loss_3': -18.04461669921875, 'eval_loss_4': -0.09890373051166534, 'epoch': 11.4}
{'loss': 0.008, 'grad_norm': 5.035520076751709, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.00740198977291584, 'loss_2': 0.0006418228149414062, 'loss_3': -16.14516830444336, 'loss_4': 0.013500906527042389, 'epoch': 11.4}
{'loss': 0.0218, 'grad_norm': 13.503456115722656, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.019816098734736443, 'loss_2': 0.0019702911376953125, 'loss_3': -16.272781372070312, 'loss_4': 0.4175867438316345, 'epoch': 11.41}
{'loss': 0.0461, 'grad_norm': 13.641018867492676, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.04476326331496239, 'loss_2': 0.00135040283203125, 'loss_3': -16.047636032104492, 'loss_4': -0.19266489148139954, 'epoch': 11.41}
{'loss': 0.0173, 'grad_norm': 7.120334148406982, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.014474955387413502, 'loss_2': 0.002849578857421875, 'loss_3': -16.39668083190918, 'loss_4': -0.004969179630279541, 'epoch': 11.42}
{'loss': 0.0119, 'grad_norm': 5.803394317626953, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.008368266746401787, 'loss_2': 0.0034942626953125, 'loss_3': -16.04012680053711, 'loss_4': -0.09766083210706711, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 16:07:30,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:30,541 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:43<55:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:37,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028759852051734924, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.724, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02378167025744915, 'eval_loss_2': 0.004978179931640625, 'eval_loss_3': -18.080121994018555, 'eval_loss_4': 0.1336650252342224, 'epoch': 11.42}
{'loss': 0.0099, 'grad_norm': 5.144611358642578, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.009027536027133465, 'loss_2': 0.0009093284606933594, 'loss_3': -16.26264190673828, 'loss_4': 0.3109469413757324, 'epoch': 11.43}
{'loss': 0.0096, 'grad_norm': 6.285392761230469, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.008952136151492596, 'loss_2': 0.0006227493286132812, 'loss_3': -16.129138946533203, 'loss_4': -0.007203243672847748, 'epoch': 11.44}
{'loss': 0.0142, 'grad_norm': 4.99694299697876, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.008486492559313774, 'loss_2': 0.00576019287109375, 'loss_3': -16.13958740234375, 'loss_4': 0.20593582093715668, 'epoch': 11.44}
{'loss': 0.0213, 'grad_norm': 7.080156326293945, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.014113398268818855, 'loss_2': 0.007137298583984375, 'loss_3': -16.090248107910156, 'loss_4': 0.30225974321365356, 'epoch': 11.45}
{'loss': 0.0276, 'grad_norm': 11.227781295776367, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.02627047523856163, 'loss_2': 0.0013027191162109375, 'loss_3': -16.091270446777344, 'loss_4': 0.2965591847896576, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 16:07:37,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:37,883 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [48:50<55:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:45,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024172767996788025, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.879, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021007470786571503, 'eval_loss_2': 0.003165297210216522, 'eval_loss_3': -18.121234893798828, 'eval_loss_4': 0.16606135666370392, 'epoch': 11.45}
{'loss': 0.0248, 'grad_norm': 8.470690727233887, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.023917578160762787, 'loss_2': 0.0009207725524902344, 'loss_3': -16.06693458557129, 'loss_4': 0.2179807722568512, 'epoch': 11.46}
{'loss': 0.0092, 'grad_norm': 4.550682544708252, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.00742134265601635, 'loss_2': 0.001758575439453125, 'loss_3': -16.248289108276367, 'loss_4': -0.13789436221122742, 'epoch': 11.47}
{'loss': 0.012, 'grad_norm': 5.506258487701416, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.007411487866193056, 'loss_2': 0.00460052490234375, 'loss_3': -16.00460433959961, 'loss_4': 0.09629207849502563, 'epoch': 11.47}
{'loss': 0.0474, 'grad_norm': 14.53758716583252, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.040864698588848114, 'loss_2': 0.00652313232421875, 'loss_3': -16.105953216552734, 'loss_4': 0.7124028205871582, 'epoch': 11.48}
{'loss': 0.0121, 'grad_norm': 5.2723774909973145, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.0066184597089886665, 'loss_2': 0.00547027587890625, 'loss_3': -16.057979583740234, 'loss_4': 0.3474159836769104, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 16:07:45,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:45,224 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [48:57<54:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:52,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02945421263575554, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.058, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.022937819361686707, 'eval_loss_2': 0.006516396999359131, 'eval_loss_3': -18.060028076171875, 'eval_loss_4': 0.1638650894165039, 'epoch': 11.48}
{'loss': 0.0111, 'grad_norm': 4.640439987182617, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.008752851746976376, 'loss_2': 0.002391815185546875, 'loss_3': -16.1759033203125, 'loss_4': -0.07682648301124573, 'epoch': 11.49}
{'loss': 0.0131, 'grad_norm': 7.207991123199463, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.010923998430371284, 'loss_2': 0.002166748046875, 'loss_3': -15.912397384643555, 'loss_4': 0.1672712117433548, 'epoch': 11.49}
{'loss': 0.009, 'grad_norm': 5.534405708312988, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.00900011695921421, 'loss_2': 3.314018249511719e-05, 'loss_3': -16.104400634765625, 'loss_4': -0.03289591521024704, 'epoch': 11.5}
{'loss': 0.02, 'grad_norm': 10.005091667175293, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.017268462106585503, 'loss_2': 0.0026912689208984375, 'loss_3': -16.10916519165039, 'loss_4': 0.04499877244234085, 'epoch': 11.51}
{'loss': 0.0253, 'grad_norm': 7.563626289367676, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.01355916541069746, 'loss_2': 0.01178741455078125, 'loss_3': -15.987578392028809, 'loss_4': 0.176315575838089, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 16:07:52,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:52,568 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:05<54:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:59,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033513009548187256, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.753, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.025344550609588623, 'eval_loss_2': 0.008168458938598633, 'eval_loss_3': -18.053678512573242, 'eval_loss_4': 0.2025662511587143, 'epoch': 11.51}
{'loss': 0.0438, 'grad_norm': 17.92389678955078, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.0371168851852417, 'loss_2': 0.00666046142578125, 'loss_3': -15.922426223754883, 'loss_4': 0.5197092890739441, 'epoch': 11.52}
{'loss': 0.031, 'grad_norm': 7.613214015960693, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.019433336332440376, 'loss_2': 0.01157379150390625, 'loss_3': -15.89211368560791, 'loss_4': -0.02839694917201996, 'epoch': 11.52}
{'loss': 0.0301, 'grad_norm': 11.689245223999023, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.018987510353326797, 'loss_2': 0.01108551025390625, 'loss_3': -16.23767852783203, 'loss_4': 0.20368963479995728, 'epoch': 11.53}
{'loss': 0.018, 'grad_norm': 5.784150123596191, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.010710668750107288, 'loss_2': 0.007259368896484375, 'loss_3': -16.093948364257812, 'loss_4': 0.2736383378505707, 'epoch': 11.53}
{'loss': 0.0269, 'grad_norm': 17.514604568481445, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.022579802200198174, 'loss_2': 0.0042877197265625, 'loss_3': -15.930940628051758, 'loss_4': 0.3718486428260803, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 16:07:59,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:59,899 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:12<54:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:07,234 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0254641305655241, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021924689412117004, 'eval_loss_2': 0.003539443016052246, 'eval_loss_3': -18.085830688476562, 'eval_loss_4': 0.2892204523086548, 'epoch': 11.54}
{'loss': 0.0213, 'grad_norm': 5.772505283355713, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.017511090263724327, 'loss_2': 0.003742218017578125, 'loss_3': -15.845322608947754, 'loss_4': 0.2756159007549286, 'epoch': 11.55}
{'loss': 0.0141, 'grad_norm': 5.874538898468018, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.014011041261255741, 'loss_2': 0.0001347064971923828, 'loss_3': -16.136096954345703, 'loss_4': 0.13680604100227356, 'epoch': 11.55}
{'loss': 0.0162, 'grad_norm': 6.103495121002197, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.011001410894095898, 'loss_2': 0.005176544189453125, 'loss_3': -16.17476463317871, 'loss_4': 0.4151727557182312, 'epoch': 11.56}
{'loss': 0.0093, 'grad_norm': 5.415417671203613, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.009031112305819988, 'loss_2': 0.00021958351135253906, 'loss_3': -16.078887939453125, 'loss_4': -0.11679790914058685, 'epoch': 11.56}
{'loss': 0.0268, 'grad_norm': 13.015303611755371, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.02071399614214897, 'loss_2': 0.00606536865234375, 'loss_3': -16.078540802001953, 'loss_4': 0.35035786032676697, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 16:08:07,234 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:07,234 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:19<54:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:14,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02257457748055458, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.018604815006256104, 'eval_loss_2': 0.003969758749008179, 'eval_loss_3': -18.11216926574707, 'eval_loss_4': 0.3285019099712372, 'epoch': 11.57}
{'loss': 0.0113, 'grad_norm': 5.3545145988464355, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.011192470788955688, 'loss_2': 0.00015485286712646484, 'loss_3': -15.98543930053711, 'loss_4': 0.34633633494377136, 'epoch': 11.58}
{'loss': 0.0155, 'grad_norm': 6.121934413909912, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.010799411684274673, 'loss_2': 0.004730224609375, 'loss_3': -15.948708534240723, 'loss_4': 0.7450004816055298, 'epoch': 11.58}
{'loss': 0.0161, 'grad_norm': 8.370771408081055, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.012511756271123886, 'loss_2': 0.003566741943359375, 'loss_3': -16.264663696289062, 'loss_4': 0.027702055871486664, 'epoch': 11.59}
{'loss': 0.0321, 'grad_norm': 9.157550811767578, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.017807966098189354, 'loss_2': 0.01427459716796875, 'loss_3': -16.125076293945312, 'loss_4': 0.1997898519039154, 'epoch': 11.59}
{'loss': 0.0061, 'grad_norm': 4.858877182006836, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.005455570761114359, 'loss_2': 0.0006542205810546875, 'loss_3': -15.71773910522461, 'loss_4': 0.46699196100234985, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 16:08:14,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:14,576 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:27<54:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:21,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020369822159409523, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016718875616788864, 'eval_loss_2': 0.003650948405265808, 'eval_loss_3': -18.125125885009766, 'eval_loss_4': 0.536941409111023, 'epoch': 11.6}
{'loss': 0.0227, 'grad_norm': 9.558403968811035, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.016874758526682854, 'loss_2': 0.005832672119140625, 'loss_3': -15.725191116333008, 'loss_4': 0.7557421326637268, 'epoch': 11.6}
{'loss': 0.0138, 'grad_norm': 5.138393402099609, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.007020696997642517, 'loss_2': 0.00673675537109375, 'loss_3': -16.052871704101562, 'loss_4': 0.3883439600467682, 'epoch': 11.61}
{'loss': 0.0203, 'grad_norm': 7.136875152587891, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.016408659517765045, 'loss_2': 0.0038909912109375, 'loss_3': -15.916601181030273, 'loss_4': 0.5866064429283142, 'epoch': 11.62}
{'loss': 0.017, 'grad_norm': 5.27850341796875, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.007708834018558264, 'loss_2': 0.00925445556640625, 'loss_3': -15.99813461303711, 'loss_4': 0.6831461191177368, 'epoch': 11.62}
{'loss': 0.008, 'grad_norm': 4.912322998046875, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.00642132293432951, 'loss_2': 0.0015287399291992188, 'loss_3': -16.00682258605957, 'loss_4': 0.9486844539642334, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 16:08:21,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:21,911 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:34<54:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:29,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02107054926455021, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.563, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01578822173178196, 'eval_loss_2': 0.0052823275327682495, 'eval_loss_3': -18.130544662475586, 'eval_loss_4': 0.7888985276222229, 'epoch': 11.63}
{'loss': 0.0153, 'grad_norm': 7.082236289978027, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.01383301429450512, 'loss_2': 0.0014820098876953125, 'loss_3': -15.948269844055176, 'loss_4': 0.9945856332778931, 'epoch': 11.63}
{'loss': 0.0151, 'grad_norm': 8.776277542114258, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.01505823154002428, 'loss_2': 9.02414321899414e-05, 'loss_3': -16.1116886138916, 'loss_4': 0.6518857479095459, 'epoch': 11.64}
{'loss': 0.0119, 'grad_norm': 5.309328556060791, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.009397990070283413, 'loss_2': 0.002506256103515625, 'loss_3': -15.90429401397705, 'loss_4': 1.2092031240463257, 'epoch': 11.65}
{'loss': 0.0288, 'grad_norm': 14.760682106018066, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.026377059519290924, 'loss_2': 0.00244140625, 'loss_3': -15.693580627441406, 'loss_4': 1.033799409866333, 'epoch': 11.65}
{'loss': 0.0219, 'grad_norm': 5.958887100219727, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.010975333862006664, 'loss_2': 0.01093292236328125, 'loss_3': -15.932743072509766, 'loss_4': 1.1137049198150635, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 16:08:29,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:29,254 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:42<54:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:36,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021683305501937866, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014796584844589233, 'eval_loss_2': 0.006886720657348633, 'eval_loss_3': -18.144407272338867, 'eval_loss_4': 1.0148441791534424, 'epoch': 11.66}
{'loss': 0.0165, 'grad_norm': 7.626697063446045, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.01586827076971531, 'loss_2': 0.0006542205810546875, 'loss_3': -16.078638076782227, 'loss_4': 1.1903645992279053, 'epoch': 11.66}
{'loss': 0.0466, 'grad_norm': 12.238852500915527, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.039301369339227676, 'loss_2': 0.00731658935546875, 'loss_3': -16.17584991455078, 'loss_4': 1.2881741523742676, 'epoch': 11.67}
{'loss': 0.0126, 'grad_norm': 7.207858562469482, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.010428889654576778, 'loss_2': 0.0021305084228515625, 'loss_3': -15.846000671386719, 'loss_4': 1.116448163986206, 'epoch': 11.67}
{'loss': 0.0325, 'grad_norm': 13.719521522521973, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.02881375513970852, 'loss_2': 0.00363922119140625, 'loss_3': -16.02328872680664, 'loss_4': 1.255952000617981, 'epoch': 11.68}
{'loss': 0.0095, 'grad_norm': 5.73189640045166, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.008492336608469486, 'loss_2': 0.0010204315185546875, 'loss_3': -15.978765487670898, 'loss_4': 1.1962494850158691, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 16:08:36,594 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:36,594 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [49:49<54:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:43,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019670914858579636, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014531265012919903, 'eval_loss_2': 0.005139648914337158, 'eval_loss_3': -18.159032821655273, 'eval_loss_4': 1.254779577255249, 'epoch': 11.69}
{'loss': 0.0145, 'grad_norm': 7.269014835357666, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.013342607766389847, 'loss_2': 0.0011444091796875, 'loss_3': -15.913589477539062, 'loss_4': 1.646902084350586, 'epoch': 11.69}
{'loss': 0.0226, 'grad_norm': 8.600749015808105, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.018860843032598495, 'loss_2': 0.003757476806640625, 'loss_3': -15.73361873626709, 'loss_4': 1.4046270847320557, 'epoch': 11.7}
{'loss': 0.0219, 'grad_norm': 14.986296653747559, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.017579350620508194, 'loss_2': 0.0042877197265625, 'loss_3': -15.956025123596191, 'loss_4': 1.6035512685775757, 'epoch': 11.7}
{'loss': 0.0069, 'grad_norm': 4.903024673461914, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.0063470155000686646, 'loss_2': 0.00054168701171875, 'loss_3': -15.86984634399414, 'loss_4': 1.2844319343566895, 'epoch': 11.71}
{'loss': 0.0311, 'grad_norm': 13.338089942932129, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.02546180970966816, 'loss_2': 0.00567626953125, 'loss_3': -16.036699295043945, 'loss_4': 1.4985251426696777, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 16:08:43,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:43,932 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [49:56<54:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:51,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01905926875770092, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.574, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014757360331714153, 'eval_loss_2': 0.004301905632019043, 'eval_loss_3': -18.140361785888672, 'eval_loss_4': 1.288365125656128, 'epoch': 11.72}
{'loss': 0.0141, 'grad_norm': 6.3834075927734375, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.012511609122157097, 'loss_2': 0.001598358154296875, 'loss_3': -15.807178497314453, 'loss_4': 1.593820333480835, 'epoch': 11.72}
{'loss': 0.0183, 'grad_norm': 7.17423152923584, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.015371945686638355, 'loss_2': 0.0029430389404296875, 'loss_3': -16.15825080871582, 'loss_4': 1.159977674484253, 'epoch': 11.73}
{'loss': 0.0149, 'grad_norm': 5.157345294952393, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.008285141550004482, 'loss_2': 0.00658416748046875, 'loss_3': -15.83212661743164, 'loss_4': 1.3107812404632568, 'epoch': 11.73}
{'loss': 0.0178, 'grad_norm': 4.855899810791016, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.006120820064097643, 'loss_2': 0.01163482666015625, 'loss_3': -15.797457695007324, 'loss_4': 1.4169611930847168, 'epoch': 11.74}
{'loss': 0.0191, 'grad_norm': 6.092061996459961, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.013543824665248394, 'loss_2': 0.005584716796875, 'loss_3': -15.703716278076172, 'loss_4': 1.4851396083831787, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 16:08:51,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:51,271 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:04<54:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:58,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022336263209581375, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01783587597310543, 'eval_loss_2': 0.004500389099121094, 'eval_loss_3': -18.100053787231445, 'eval_loss_4': 1.1848889589309692, 'epoch': 11.74}
{'loss': 0.0232, 'grad_norm': 9.37684154510498, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.01620377041399479, 'loss_2': 0.0070037841796875, 'loss_3': -16.021757125854492, 'loss_4': 0.7290832996368408, 'epoch': 11.75}
{'loss': 0.025, 'grad_norm': 10.65498161315918, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.02269461192190647, 'loss_2': 0.0022792816162109375, 'loss_3': -15.800884246826172, 'loss_4': 1.118152141571045, 'epoch': 11.76}
{'loss': 0.0192, 'grad_norm': 8.292563438415527, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.016153477132320404, 'loss_2': 0.0030517578125, 'loss_3': -15.986971855163574, 'loss_4': 1.01504385471344, 'epoch': 11.76}
{'loss': 0.0191, 'grad_norm': 9.735201835632324, 'learning_rate': 1.825e-05, 'loss_1': 0.016944175586104393, 'loss_2': 0.002178192138671875, 'loss_3': -15.774211883544922, 'loss_4': 1.1714190244674683, 'epoch': 11.77}
{'loss': 0.0204, 'grad_norm': 5.784500598907471, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.010736070573329926, 'loss_2': 0.00968170166015625, 'loss_3': -15.92619800567627, 'loss_4': 0.658577024936676, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 16:08:58,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:58,614 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:11<54:53,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:09:06,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030325714498758316, 'eval_runtime': 3.9877, 'eval_samples_per_second': 256.787, 'eval_steps_per_second': 4.012, 'eval_loss_1': 0.024171534925699234, 'eval_loss_2': 0.006154179573059082, 'eval_loss_3': -18.055845260620117, 'eval_loss_4': 0.9553071856498718, 'epoch': 11.77}
{'loss': 0.019, 'grad_norm': 5.320788860321045, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.009572076611220837, 'loss_2': 0.00939178466796875, 'loss_3': -15.971992492675781, 'loss_4': 0.8789559602737427, 'epoch': 11.78}
{'loss': 0.039, 'grad_norm': 17.84276580810547, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.030925406143069267, 'loss_2': 0.00803375244140625, 'loss_3': -16.087003707885742, 'loss_4': 1.2460476160049438, 'epoch': 11.78}
{'loss': 0.0116, 'grad_norm': 8.921228408813477, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.010414418764412403, 'loss_2': 0.001155853271484375, 'loss_3': -15.996716499328613, 'loss_4': 0.6234062910079956, 'epoch': 11.79}
{'loss': 0.0165, 'grad_norm': 9.34566593170166, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.01585790142416954, 'loss_2': 0.0006222724914550781, 'loss_3': -16.098892211914062, 'loss_4': 0.7501035928726196, 'epoch': 11.8}
{'loss': 0.0186, 'grad_norm': 7.138310432434082, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.0158025324344635, 'loss_2': 0.002750396728515625, 'loss_3': -15.9898681640625, 'loss_4': 1.2159557342529297, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 16:09:06,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:06,152 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:18<54:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:13,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03216828405857086, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.027888821437954903, 'eval_loss_2': 0.004279464483261108, 'eval_loss_3': -18.00874900817871, 'eval_loss_4': 0.7701604962348938, 'epoch': 11.8}
{'loss': 0.0304, 'grad_norm': 21.126882553100586, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.027716869488358498, 'loss_2': 0.0026397705078125, 'loss_3': -15.859134674072266, 'loss_4': 0.7858281135559082, 'epoch': 11.81}
{'loss': 0.0126, 'grad_norm': 6.229031085968018, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.00959790963679552, 'loss_2': 0.0030269622802734375, 'loss_3': -16.063335418701172, 'loss_4': 0.37732353806495667, 'epoch': 11.81}
{'loss': 0.0731, 'grad_norm': 18.317142486572266, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.07205093652009964, 'loss_2': 0.0010833740234375, 'loss_3': -15.792769432067871, 'loss_4': 1.1656866073608398, 'epoch': 11.82}
{'loss': 0.0182, 'grad_norm': 7.685384750366211, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.016483457759022713, 'loss_2': 0.00167083740234375, 'loss_3': -15.924270629882812, 'loss_4': 0.9181074500083923, 'epoch': 11.83}
{'loss': 0.0156, 'grad_norm': 5.788201332092285, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.010792034678161144, 'loss_2': 0.00479888916015625, 'loss_3': -15.824409484863281, 'loss_4': 0.6964303255081177, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 16:09:13,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:13,506 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:26<53:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:20,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02758757211267948, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.024834943935275078, 'eval_loss_2': 0.0027526281774044037, 'eval_loss_3': -18.004568099975586, 'eval_loss_4': 0.6506249904632568, 'epoch': 11.83}
{'loss': 0.0242, 'grad_norm': 7.648484230041504, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.018972575664520264, 'loss_2': 0.0052032470703125, 'loss_3': -15.882367134094238, 'loss_4': 0.7203201651573181, 'epoch': 11.84}
{'loss': 0.0462, 'grad_norm': 11.604376792907715, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.03931951895356178, 'loss_2': 0.00691986083984375, 'loss_3': -15.811052322387695, 'loss_4': 0.7034382820129395, 'epoch': 11.84}
{'loss': 0.0088, 'grad_norm': 5.1560282707214355, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.006960050668567419, 'loss_2': 0.0018634796142578125, 'loss_3': -15.999225616455078, 'loss_4': 0.6638690233230591, 'epoch': 11.85}
{'loss': 0.0429, 'grad_norm': 14.044334411621094, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.0392354391515255, 'loss_2': 0.0036792755126953125, 'loss_3': -15.980537414550781, 'loss_4': 0.7717273235321045, 'epoch': 11.85}
{'loss': 0.0214, 'grad_norm': 7.600560665130615, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.014367441646754742, 'loss_2': 0.00704193115234375, 'loss_3': -15.860665321350098, 'loss_4': 0.8930346369743347, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 16:09:20,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:20,849 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:33<53:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:28,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024819277226924896, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.022741369903087616, 'eval_loss_2': 0.0020779073238372803, 'eval_loss_3': -18.00699806213379, 'eval_loss_4': 0.5288820266723633, 'epoch': 11.86}
{'loss': 0.023, 'grad_norm': 7.932291030883789, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.020265577360987663, 'loss_2': 0.002742767333984375, 'loss_3': -15.807842254638672, 'loss_4': 0.5563869476318359, 'epoch': 11.87}
{'loss': 0.0266, 'grad_norm': 14.219411849975586, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.025825878605246544, 'loss_2': 0.0007839202880859375, 'loss_3': -15.931671142578125, 'loss_4': 0.6036085486412048, 'epoch': 11.87}
{'loss': 0.0156, 'grad_norm': 6.452018737792969, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.010140063241124153, 'loss_2': 0.00543212890625, 'loss_3': -16.0339298248291, 'loss_4': 0.36047205328941345, 'epoch': 11.88}
{'loss': 0.0148, 'grad_norm': 6.885424613952637, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.011815731413662434, 'loss_2': 0.00302886962890625, 'loss_3': -15.915018081665039, 'loss_4': 0.3067512512207031, 'epoch': 11.88}
{'loss': 0.0164, 'grad_norm': 4.903318405151367, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.009271579794585705, 'loss_2': 0.00711822509765625, 'loss_3': -16.079498291015625, 'loss_4': 0.5110184550285339, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 16:09:28,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:28,188 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:40<53:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:35,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026745403185486794, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.019875356927514076, 'eval_loss_2': 0.006870046257972717, 'eval_loss_3': -18.055200576782227, 'eval_loss_4': 0.4156111478805542, 'epoch': 11.89}
{'loss': 0.0326, 'grad_norm': 7.811835765838623, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.019892441108822823, 'loss_2': 0.0127105712890625, 'loss_3': -15.981681823730469, 'loss_4': 0.4485509395599365, 'epoch': 11.9}
{'loss': 0.0524, 'grad_norm': 20.38321304321289, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.05073072388768196, 'loss_2': 0.0016851425170898438, 'loss_3': -15.943930625915527, 'loss_4': 0.7889073491096497, 'epoch': 11.9}
{'loss': 0.0125, 'grad_norm': 5.834094047546387, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.009070429019629955, 'loss_2': 0.003459930419921875, 'loss_3': -16.101621627807617, 'loss_4': 0.42402851581573486, 'epoch': 11.91}
{'loss': 0.0232, 'grad_norm': 9.12612247467041, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.020910993218421936, 'loss_2': 0.00232696533203125, 'loss_3': -16.2560977935791, 'loss_4': 0.3386440873146057, 'epoch': 11.91}
{'loss': 0.0268, 'grad_norm': 7.544681072235107, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.019399510696530342, 'loss_2': 0.00743865966796875, 'loss_3': -16.089757919311523, 'loss_4': 0.5625905990600586, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 16:09:35,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:35,532 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [50:48<53:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:42,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01797766610980034, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01386255957186222, 'eval_loss_2': 0.004115104675292969, 'eval_loss_3': -18.134300231933594, 'eval_loss_4': 0.43645310401916504, 'epoch': 11.92}
{'loss': 0.0136, 'grad_norm': 5.672520160675049, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.013078291900455952, 'loss_2': 0.0005102157592773438, 'loss_3': -16.185819625854492, 'loss_4': 0.611301064491272, 'epoch': 11.92}
{'loss': 0.0208, 'grad_norm': 7.479193687438965, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.016038738191127777, 'loss_2': 0.00479888916015625, 'loss_3': -15.944501876831055, 'loss_4': 0.3179721534252167, 'epoch': 11.93}
{'loss': 0.0287, 'grad_norm': 8.538002967834473, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.022982707247138023, 'loss_2': 0.00574493408203125, 'loss_3': -16.13382339477539, 'loss_4': 0.2852334976196289, 'epoch': 11.94}
{'loss': 0.0313, 'grad_norm': 13.81082534790039, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.030731799080967903, 'loss_2': 0.0005216598510742188, 'loss_3': -16.184406280517578, 'loss_4': 1.0304359197616577, 'epoch': 11.94}
{'loss': 0.0204, 'grad_norm': 7.644654273986816, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.01871221512556076, 'loss_2': 0.0016450881958007812, 'loss_3': -16.012510299682617, 'loss_4': 1.1702473163604736, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 16:09:42,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:42,877 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [50:55<53:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:50,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014731023460626602, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012376092374324799, 'eval_loss_2': 0.0023549310863018036, 'eval_loss_3': -18.172883987426758, 'eval_loss_4': 0.6434723138809204, 'epoch': 11.95}
{'loss': 0.0131, 'grad_norm': 5.326456546783447, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.010307024233043194, 'loss_2': 0.0028076171875, 'loss_3': -15.910261154174805, 'loss_4': 0.7877161502838135, 'epoch': 11.95}
{'loss': 0.0255, 'grad_norm': 7.523043632507324, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.022617259994149208, 'loss_2': 0.0028743743896484375, 'loss_3': -15.940617561340332, 'loss_4': 0.9566078186035156, 'epoch': 11.96}
{'loss': 0.1145, 'grad_norm': 30.33656883239746, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.10034440457820892, 'loss_2': 0.0141754150390625, 'loss_3': -16.01770782470703, 'loss_4': 1.3221700191497803, 'epoch': 11.97}
{'loss': 0.0137, 'grad_norm': 5.674135208129883, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.011530714109539986, 'loss_2': 0.0021514892578125, 'loss_3': -16.003469467163086, 'loss_4': 0.23770222067832947, 'epoch': 11.97}
{'loss': 0.0305, 'grad_norm': 9.629947662353516, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.016493508592247963, 'loss_2': 0.01401519775390625, 'loss_3': -16.029857635498047, 'loss_4': 0.8074116110801697, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 16:09:50,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:50,227 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:02<50:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:09:57,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0220302976667881, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013403357937932014, 'eval_loss_2': 0.008626937866210938, 'eval_loss_3': -18.15803337097168, 'eval_loss_4': 0.6148172616958618, 'epoch': 11.98}
{'loss': 0.0615, 'grad_norm': 23.75151824951172, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.04907670617103577, 'loss_2': 0.0124359130859375, 'loss_3': -15.983717918395996, 'loss_4': 1.2898935079574585, 'epoch': 11.98}
{'loss': 0.0343, 'grad_norm': 8.083830833435059, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.02515050582587719, 'loss_2': 0.00914764404296875, 'loss_3': -16.015186309814453, 'loss_4': 0.7610786557197571, 'epoch': 11.99}
{'loss': 0.0271, 'grad_norm': 8.176772117614746, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.016449447721242905, 'loss_2': 0.0106964111328125, 'loss_3': -16.19527816772461, 'loss_4': 1.0832602977752686, 'epoch': 11.99}
{'loss': 0.0204, 'grad_norm': 6.5778045654296875, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.006833773106336594, 'loss_2': 0.013580322265625, 'loss_3': -16.14229393005371, 'loss_4': 0.6239039897918701, 'epoch': 12.0}
{'loss': 0.1102, 'grad_norm': 17.49269676208496, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.1010722815990448, 'loss_2': 0.00909423828125, 'loss_3': -15.978572845458984, 'loss_4': 1.2389860153198242, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 16:09:57,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:57,260 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:10<52:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:10:04,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020302480086684227, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.746, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012915556319057941, 'eval_loss_2': 0.007386922836303711, 'eval_loss_3': -18.134729385375977, 'eval_loss_4': 0.4636133015155792, 'epoch': 12.01}
{'loss': 0.0265, 'grad_norm': 8.280712127685547, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.024388540536165237, 'loss_2': 0.00209808349609375, 'loss_3': -16.000675201416016, 'loss_4': 0.6676759719848633, 'epoch': 12.01}
{'loss': 0.0161, 'grad_norm': 5.493773460388184, 'learning_rate': 1.8e-05, 'loss_1': 0.009440491907298565, 'loss_2': 0.00665283203125, 'loss_3': -16.065990447998047, 'loss_4': 0.8093090057373047, 'epoch': 12.02}
{'loss': 0.0078, 'grad_norm': 4.983150959014893, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.00588371092453599, 'loss_2': 0.001888275146484375, 'loss_3': -15.860586166381836, 'loss_4': 0.5171236395835876, 'epoch': 12.02}
{'loss': 0.0305, 'grad_norm': 12.954085350036621, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.024183358997106552, 'loss_2': 0.006313323974609375, 'loss_3': -16.10050392150879, 'loss_4': 0.3524639308452606, 'epoch': 12.03}
{'loss': 0.0177, 'grad_norm': 5.1889328956604, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.013560442253947258, 'loss_2': 0.00414276123046875, 'loss_3': -15.943008422851562, 'loss_4': 0.7717057466506958, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 16:10:04,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:04,597 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:17<53:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:11,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0148223377764225, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.853, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011819993145763874, 'eval_loss_2': 0.003002345561981201, 'eval_loss_3': -18.114330291748047, 'eval_loss_4': 0.2841201424598694, 'epoch': 12.03}
{'loss': 0.0107, 'grad_norm': 5.211305141448975, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.008543946780264378, 'loss_2': 0.0021820068359375, 'loss_3': -16.049665451049805, 'loss_4': 0.6236886978149414, 'epoch': 12.04}
{'loss': 0.0128, 'grad_norm': 5.9316205978393555, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.011574376374483109, 'loss_2': 0.0012722015380859375, 'loss_3': -15.969547271728516, 'loss_4': 0.490555077791214, 'epoch': 12.05}
{'loss': 0.0239, 'grad_norm': 14.898770332336426, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.01994158700108528, 'loss_2': 0.003963470458984375, 'loss_3': -16.124248504638672, 'loss_4': 0.6877607107162476, 'epoch': 12.05}
{'loss': 0.0185, 'grad_norm': 8.537897109985352, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.016445651650428772, 'loss_2': 0.002056121826171875, 'loss_3': -16.011394500732422, 'loss_4': 0.5720911026000977, 'epoch': 12.06}
{'loss': 0.0146, 'grad_norm': 7.08465576171875, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.010782180353999138, 'loss_2': 0.00384521484375, 'loss_3': -16.12024688720703, 'loss_4': 0.6220585703849792, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 16:10:11,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:11,938 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:24<53:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:19,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020654119551181793, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.756, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013573504984378815, 'eval_loss_2': 0.0070806145668029785, 'eval_loss_3': -18.10256004333496, 'eval_loss_4': 0.0326261967420578, 'epoch': 12.06}
{'loss': 0.0276, 'grad_norm': 8.469039916992188, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.019359484314918518, 'loss_2': 0.0082550048828125, 'loss_3': -16.06035614013672, 'loss_4': 0.20799404382705688, 'epoch': 12.07}
{'loss': 0.0136, 'grad_norm': 7.472890853881836, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.011432239785790443, 'loss_2': 0.0021381378173828125, 'loss_3': -16.112060546875, 'loss_4': -0.012461062520742416, 'epoch': 12.08}
{'loss': 0.039, 'grad_norm': 13.563288688659668, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.034734465181827545, 'loss_2': 0.004302978515625, 'loss_3': -16.251365661621094, 'loss_4': 0.3620031774044037, 'epoch': 12.08}
{'loss': 0.0548, 'grad_norm': 13.622346878051758, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.04532599449157715, 'loss_2': 0.00945281982421875, 'loss_3': -15.962759971618652, 'loss_4': 0.5233687162399292, 'epoch': 12.09}
{'loss': 0.0274, 'grad_norm': 12.66946792602539, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.02723659574985504, 'loss_2': 0.00019359588623046875, 'loss_3': -16.11723518371582, 'loss_4': 0.4043571949005127, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 16:10:19,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:19,273 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:32<53:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:26,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020881306380033493, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.752, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017015714198350906, 'eval_loss_2': 0.0038655921816825867, 'eval_loss_3': -18.063875198364258, 'eval_loss_4': -0.2079675942659378, 'epoch': 12.09}
{'loss': 0.0223, 'grad_norm': 9.618748664855957, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.020728452131152153, 'loss_2': 0.001590728759765625, 'loss_3': -16.042940139770508, 'loss_4': -0.021673083305358887, 'epoch': 12.1}
{'loss': 0.0181, 'grad_norm': 9.731667518615723, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.01676567830145359, 'loss_2': 0.0012998580932617188, 'loss_3': -15.927329063415527, 'loss_4': 0.19056002795696259, 'epoch': 12.1}
{'loss': 0.0124, 'grad_norm': 5.350615978240967, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.009053234942257404, 'loss_2': 0.00339508056640625, 'loss_3': -16.02549171447754, 'loss_4': 0.004907272756099701, 'epoch': 12.11}
{'loss': 0.02, 'grad_norm': 9.316783905029297, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.017205359414219856, 'loss_2': 0.0028400421142578125, 'loss_3': -16.14288330078125, 'loss_4': -0.4611055254936218, 'epoch': 12.12}
{'loss': 0.0236, 'grad_norm': 10.556987762451172, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.021473800763487816, 'loss_2': 0.00211334228515625, 'loss_3': -15.787474632263184, 'loss_4': 0.30892878770828247, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 16:10:26,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:26,609 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:39<53:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:33,957 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021531682461500168, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017558258026838303, 'eval_loss_2': 0.003973424434661865, 'eval_loss_3': -18.065677642822266, 'eval_loss_4': -0.2764211893081665, 'epoch': 12.12}
{'loss': 0.0216, 'grad_norm': 9.19953727722168, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.019494730979204178, 'loss_2': 0.0020885467529296875, 'loss_3': -15.820276260375977, 'loss_4': -0.5033369064331055, 'epoch': 12.13}
{'loss': 0.0093, 'grad_norm': 5.293595314025879, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.007323786150664091, 'loss_2': 0.0019435882568359375, 'loss_3': -16.219690322875977, 'loss_4': -0.10886521637439728, 'epoch': 12.13}
{'loss': 0.0177, 'grad_norm': 5.323729038238525, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.008044994436204433, 'loss_2': 0.0096282958984375, 'loss_3': -16.192392349243164, 'loss_4': -0.3680575489997864, 'epoch': 12.14}
{'loss': 0.02, 'grad_norm': 6.814139366149902, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.014807012863457203, 'loss_2': 0.00514984130859375, 'loss_3': -15.97544002532959, 'loss_4': -0.1558198779821396, 'epoch': 12.15}
{'loss': 0.0259, 'grad_norm': 8.043359756469727, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.019046999514102936, 'loss_2': 0.006866455078125, 'loss_3': -16.04629135131836, 'loss_4': -0.19002395868301392, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 16:10:33,957 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:33,957 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [51:46<53:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:41,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018933113664388657, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015814676880836487, 'eval_loss_2': 0.00311843678355217, 'eval_loss_3': -18.068702697753906, 'eval_loss_4': -0.28727442026138306, 'epoch': 12.15}
{'loss': 0.0276, 'grad_norm': 14.804550170898438, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.02628236822783947, 'loss_2': 0.0013484954833984375, 'loss_3': -15.943458557128906, 'loss_4': -0.28849154710769653, 'epoch': 12.16}
{'loss': 0.0258, 'grad_norm': 22.204622268676758, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.024384714663028717, 'loss_2': 0.001415252685546875, 'loss_3': -15.934049606323242, 'loss_4': -0.23487859964370728, 'epoch': 12.16}
{'loss': 0.0163, 'grad_norm': 7.202488422393799, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.01584966480731964, 'loss_2': 0.000499725341796875, 'loss_3': -15.92219352722168, 'loss_4': 0.06111644580960274, 'epoch': 12.17}
{'loss': 0.0151, 'grad_norm': 7.514458656311035, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.013191829435527325, 'loss_2': 0.001861572265625, 'loss_3': -15.940271377563477, 'loss_4': -0.03305927291512489, 'epoch': 12.17}
{'loss': 0.022, 'grad_norm': 6.708962440490723, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.017495039850473404, 'loss_2': 0.0044708251953125, 'loss_3': -15.893413543701172, 'loss_4': 0.03681352362036705, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 16:10:41,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:41,299 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [51:54<52:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:48,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0235087089240551, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014875809662044048, 'eval_loss_2': 0.008632898330688477, 'eval_loss_3': -18.0533504486084, 'eval_loss_4': -0.2559935450553894, 'epoch': 12.18}
{'loss': 0.0222, 'grad_norm': 5.708931922912598, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.009547942318022251, 'loss_2': 0.01263427734375, 'loss_3': -16.31675910949707, 'loss_4': 0.13097627460956573, 'epoch': 12.19}
{'loss': 0.0315, 'grad_norm': 13.229981422424316, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.02466748282313347, 'loss_2': 0.006866455078125, 'loss_3': -15.923955917358398, 'loss_4': -0.12259037792682648, 'epoch': 12.19}
{'loss': 0.0288, 'grad_norm': 11.830754280090332, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.021036554127931595, 'loss_2': 0.007781982421875, 'loss_3': -15.891931533813477, 'loss_4': -0.09773509204387665, 'epoch': 12.2}
{'loss': 0.0139, 'grad_norm': 5.693922996520996, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.011738634668290615, 'loss_2': 0.0021820068359375, 'loss_3': -16.046545028686523, 'loss_4': 0.07976388931274414, 'epoch': 12.2}
{'loss': 0.0168, 'grad_norm': 6.667601108551025, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.013152600266039371, 'loss_2': 0.003612518310546875, 'loss_3': -16.012874603271484, 'loss_4': -0.7834079265594482, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 16:10:48,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:48,642 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:01<52:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:55,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019718822091817856, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01570960320532322, 'eval_loss_2': 0.004009220749139786, 'eval_loss_3': -18.087783813476562, 'eval_loss_4': -0.34626591205596924, 'epoch': 12.21}
{'loss': 0.0213, 'grad_norm': 9.873205184936523, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.018573563545942307, 'loss_2': 0.0027027130126953125, 'loss_3': -16.228103637695312, 'loss_4': -0.052778393030166626, 'epoch': 12.22}
{'loss': 0.0112, 'grad_norm': 5.505738258361816, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.010516519658267498, 'loss_2': 0.000637054443359375, 'loss_3': -15.989174842834473, 'loss_4': -0.5840641260147095, 'epoch': 12.22}
{'loss': 0.0117, 'grad_norm': 5.748988628387451, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.008252388797700405, 'loss_2': 0.0034961700439453125, 'loss_3': -15.880036354064941, 'loss_4': -0.3638497591018677, 'epoch': 12.23}
{'loss': 0.0159, 'grad_norm': 6.173418998718262, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.01399318315088749, 'loss_2': 0.0019474029541015625, 'loss_3': -15.915939331054688, 'loss_4': -0.3741993010044098, 'epoch': 12.23}
{'loss': 0.0248, 'grad_norm': 8.52639389038086, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.022669874131679535, 'loss_2': 0.002124786376953125, 'loss_3': -15.998326301574707, 'loss_4': 0.16463999450206757, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 16:10:55,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:55,980 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:08<52:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:03,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019807890057563782, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.015295161865651608, 'eval_loss_2': 0.0045127272605896, 'eval_loss_3': -18.106800079345703, 'eval_loss_4': -0.34132155776023865, 'epoch': 12.24}
{'loss': 0.0089, 'grad_norm': 4.514716148376465, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.008037944324314594, 'loss_2': 0.0008287429809570312, 'loss_3': -16.057567596435547, 'loss_4': -0.5052933096885681, 'epoch': 12.24}
{'loss': 0.0066, 'grad_norm': 4.773540019989014, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.006253856234252453, 'loss_2': 0.00035190582275390625, 'loss_3': -16.204875946044922, 'loss_4': -0.14493542909622192, 'epoch': 12.25}
{'loss': 0.0344, 'grad_norm': 12.343934059143066, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.029740404337644577, 'loss_2': 0.004642486572265625, 'loss_3': -15.998428344726562, 'loss_4': -0.2970506548881531, 'epoch': 12.26}
{'loss': 0.0228, 'grad_norm': 10.213569641113281, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.01822698302567005, 'loss_2': 0.00460052490234375, 'loss_3': -16.03960609436035, 'loss_4': 0.3252646327018738, 'epoch': 12.26}
{'loss': 0.0123, 'grad_norm': 6.260313034057617, 'learning_rate': 1.775e-05, 'loss_1': 0.010394539684057236, 'loss_2': 0.001926422119140625, 'loss_3': -16.118770599365234, 'loss_4': 0.02693331241607666, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 16:11:03,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:03,323 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:16<52:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:10,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019806038588285446, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01617066189646721, 'eval_loss_2': 0.0036353766918182373, 'eval_loss_3': -18.102901458740234, 'eval_loss_4': -0.20538784563541412, 'epoch': 12.27}
{'loss': 0.0119, 'grad_norm': 5.409435749053955, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.00827120803296566, 'loss_2': 0.0035991668701171875, 'loss_3': -16.29478645324707, 'loss_4': -0.3837941884994507, 'epoch': 12.27}
{'loss': 0.0146, 'grad_norm': 5.217811107635498, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.012044711969792843, 'loss_2': 0.002506256103515625, 'loss_3': -16.130430221557617, 'loss_4': -0.6190127730369568, 'epoch': 12.28}
{'loss': 0.0505, 'grad_norm': 28.044525146484375, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.04162986949086189, 'loss_2': 0.008880615234375, 'loss_3': -15.945262908935547, 'loss_4': -0.3290259838104248, 'epoch': 12.28}
{'loss': 0.0254, 'grad_norm': 8.910319328308105, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.02011951059103012, 'loss_2': 0.005279541015625, 'loss_3': -16.16708755493164, 'loss_4': -0.44428110122680664, 'epoch': 12.29}
{'loss': 0.0158, 'grad_norm': 5.969791889190674, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.010164991952478886, 'loss_2': 0.0055999755859375, 'loss_3': -15.967554092407227, 'loss_4': -0.1801617592573166, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 16:11:10,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:10,661 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:23<52:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:18,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021491501480340958, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013605570420622826, 'eval_loss_2': 0.007885932922363281, 'eval_loss_3': -18.107866287231445, 'eval_loss_4': -0.040200114250183105, 'epoch': 12.3}
{'loss': 0.0199, 'grad_norm': 7.62974739074707, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.012197071686387062, 'loss_2': 0.0077362060546875, 'loss_3': -16.079065322875977, 'loss_4': 0.29404503107070923, 'epoch': 12.3}
{'loss': 0.015, 'grad_norm': 7.4012064933776855, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.010858144611120224, 'loss_2': 0.00409698486328125, 'loss_3': -15.96642017364502, 'loss_4': 0.046579182147979736, 'epoch': 12.31}
{'loss': 0.0227, 'grad_norm': 7.187617778778076, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.015559942461550236, 'loss_2': 0.00710296630859375, 'loss_3': -15.897680282592773, 'loss_4': 0.06147247552871704, 'epoch': 12.31}
{'loss': 0.0219, 'grad_norm': 7.911198139190674, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.015363235957920551, 'loss_2': 0.00655364990234375, 'loss_3': -15.878325462341309, 'loss_4': -0.015834607183933258, 'epoch': 12.32}
{'loss': 0.0116, 'grad_norm': 6.911129951477051, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.010085804387927055, 'loss_2': 0.0015439987182617188, 'loss_3': -16.242908477783203, 'loss_4': 0.12286397069692612, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 16:11:18,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:18,002 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:30<52:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:25,345 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0167390163987875, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.752, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012596283107995987, 'eval_loss_2': 0.004142731428146362, 'eval_loss_3': -18.109500885009766, 'eval_loss_4': 0.24099715054035187, 'epoch': 12.33}
{'loss': 0.0174, 'grad_norm': 6.2022318840026855, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.010699577629566193, 'loss_2': 0.00665283203125, 'loss_3': -15.847625732421875, 'loss_4': 0.4464725852012634, 'epoch': 12.33}
{'loss': 0.012, 'grad_norm': 6.731620788574219, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.010252095758914948, 'loss_2': 0.0017786026000976562, 'loss_3': -16.118776321411133, 'loss_4': 0.18061813712120056, 'epoch': 12.34}
{'loss': 0.0151, 'grad_norm': 6.924844741821289, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.008332261815667152, 'loss_2': 0.00675201416015625, 'loss_3': -16.017379760742188, 'loss_4': 0.44318246841430664, 'epoch': 12.34}
{'loss': 0.0403, 'grad_norm': 19.51581573486328, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.03390564024448395, 'loss_2': 0.0063629150390625, 'loss_3': -16.087383270263672, 'loss_4': 0.29543644189834595, 'epoch': 12.35}
{'loss': 0.0126, 'grad_norm': 5.448646068572998, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.006322242319583893, 'loss_2': 0.00626373291015625, 'loss_3': -16.0863037109375, 'loss_4': 0.5189767479896545, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 16:11:25,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:25,345 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:38<52:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:32,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01599506288766861, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012333972379565239, 'eval_loss_2': 0.0036610886454582214, 'eval_loss_3': -18.099411010742188, 'eval_loss_4': 0.2802608013153076, 'epoch': 12.35}
{'loss': 0.065, 'grad_norm': 24.000829696655273, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.05743588134646416, 'loss_2': 0.007572174072265625, 'loss_3': -15.729299545288086, 'loss_4': 0.3464614152908325, 'epoch': 12.36}
{'loss': 0.0191, 'grad_norm': 5.976665496826172, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.008810317143797874, 'loss_2': 0.01025390625, 'loss_3': -15.857588768005371, 'loss_4': -0.22016550600528717, 'epoch': 12.37}
{'loss': 0.0127, 'grad_norm': 6.464428901672363, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.008872877806425095, 'loss_2': 0.0038604736328125, 'loss_3': -16.015777587890625, 'loss_4': 0.3119279146194458, 'epoch': 12.37}
{'loss': 0.0136, 'grad_norm': 6.398122310638428, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.010126819834113121, 'loss_2': 0.0034275054931640625, 'loss_3': -15.928276062011719, 'loss_4': 0.24301986396312714, 'epoch': 12.38}
{'loss': 0.0137, 'grad_norm': 4.728443145751953, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.009194171987473965, 'loss_2': 0.0044708251953125, 'loss_3': -16.098491668701172, 'loss_4': 0.24647673964500427, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 16:11:32,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:32,696 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [52:45<52:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:40,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01513153500854969, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011780653148889542, 'eval_loss_2': 0.003350883722305298, 'eval_loss_3': -18.096837997436523, 'eval_loss_4': 0.21793672442436218, 'epoch': 12.38}
{'loss': 0.0214, 'grad_norm': 10.228838920593262, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.0185703095048666, 'loss_2': 0.00283050537109375, 'loss_3': -15.859643936157227, 'loss_4': 0.4160160422325134, 'epoch': 12.39}
{'loss': 0.0063, 'grad_norm': 4.60553503036499, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.00349562824703753, 'loss_2': 0.002803802490234375, 'loss_3': -15.97023868560791, 'loss_4': 0.12314820289611816, 'epoch': 12.4}
{'loss': 0.0105, 'grad_norm': 5.504690647125244, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.008526213467121124, 'loss_2': 0.0020160675048828125, 'loss_3': -15.901759147644043, 'loss_4': 0.17266124486923218, 'epoch': 12.4}
{'loss': 0.0564, 'grad_norm': 22.763246536254883, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.05521012842655182, 'loss_2': 0.001140594482421875, 'loss_3': -15.957228660583496, 'loss_4': 0.34367379546165466, 'epoch': 12.41}
{'loss': 0.0074, 'grad_norm': 5.215724945068359, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.006852097809314728, 'loss_2': 0.0005197525024414062, 'loss_3': -16.15817642211914, 'loss_4': 0.1800856739282608, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 16:11:40,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:40,041 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [52:52<52:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:47,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016021788120269775, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.65, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01214030385017395, 'eval_loss_2': 0.003881484270095825, 'eval_loss_3': -18.087343215942383, 'eval_loss_4': 0.34915804862976074, 'epoch': 12.41}
{'loss': 0.0104, 'grad_norm': 5.566078186035156, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.008806968107819557, 'loss_2': 0.001617431640625, 'loss_3': -16.029468536376953, 'loss_4': 0.45472854375839233, 'epoch': 12.42}
{'loss': 0.0116, 'grad_norm': 5.041396141052246, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.009008724242448807, 'loss_2': 0.002582550048828125, 'loss_3': -15.885163307189941, 'loss_4': 0.038867831230163574, 'epoch': 12.42}
{'loss': 0.0346, 'grad_norm': 14.56029987335205, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.027262505143880844, 'loss_2': 0.00738525390625, 'loss_3': -15.877800941467285, 'loss_4': 0.8173093795776367, 'epoch': 12.43}
{'loss': 0.0264, 'grad_norm': 11.90939712524414, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.01923827826976776, 'loss_2': 0.007171630859375, 'loss_3': -15.924503326416016, 'loss_4': 0.3274115025997162, 'epoch': 12.44}
{'loss': 0.0124, 'grad_norm': 6.040456295013428, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.01219964399933815, 'loss_2': 0.0002205371856689453, 'loss_3': -15.763980865478516, 'loss_4': 0.41821005940437317, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 16:11:47,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:47,376 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:00<52:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:54,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01824955642223358, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012880966067314148, 'eval_loss_2': 0.005368590354919434, 'eval_loss_3': -18.085384368896484, 'eval_loss_4': 0.4018905460834503, 'epoch': 12.44}
{'loss': 0.019, 'grad_norm': 5.027559757232666, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.008194115944206715, 'loss_2': 0.0107879638671875, 'loss_3': -15.900978088378906, 'loss_4': 0.02100757695734501, 'epoch': 12.45}
{'loss': 0.0163, 'grad_norm': 4.560359477996826, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.006673324387520552, 'loss_2': 0.00965118408203125, 'loss_3': -16.084121704101562, 'loss_4': 0.4151548743247986, 'epoch': 12.45}
{'loss': 0.0145, 'grad_norm': 5.301275730133057, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.009699312038719654, 'loss_2': 0.0048370361328125, 'loss_3': -15.86677074432373, 'loss_4': 0.26411616802215576, 'epoch': 12.46}
{'loss': 0.0094, 'grad_norm': 5.47191858291626, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.008049830794334412, 'loss_2': 0.0013790130615234375, 'loss_3': -15.974559783935547, 'loss_4': 0.4888114929199219, 'epoch': 12.47}
{'loss': 0.013, 'grad_norm': 5.162775039672852, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.007804654538631439, 'loss_2': 0.005229949951171875, 'loss_3': -16.15194320678711, 'loss_4': 0.04393533244729042, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 16:11:54,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:54,716 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:07<52:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:02,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017476407811045647, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.615, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01339007169008255, 'eval_loss_2': 0.004086337983608246, 'eval_loss_3': -18.08370590209961, 'eval_loss_4': 0.34616976976394653, 'epoch': 12.47}
{'loss': 0.013, 'grad_norm': 6.289846420288086, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.011372605338692665, 'loss_2': 0.0015878677368164062, 'loss_3': -15.767492294311523, 'loss_4': 0.5076166391372681, 'epoch': 12.48}
{'loss': 0.0101, 'grad_norm': 5.0995707511901855, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.009336834773421288, 'loss_2': 0.0007505416870117188, 'loss_3': -16.047229766845703, 'loss_4': 0.32235223054885864, 'epoch': 12.48}
{'loss': 0.0167, 'grad_norm': 6.5581464767456055, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.012401477433741093, 'loss_2': 0.00433349609375, 'loss_3': -15.845413208007812, 'loss_4': 0.2810300588607788, 'epoch': 12.49}
{'loss': 0.0172, 'grad_norm': 6.7697577476501465, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.011115639470517635, 'loss_2': 0.006061553955078125, 'loss_3': -15.807805061340332, 'loss_4': 0.17534102499485016, 'epoch': 12.49}
{'loss': 0.0145, 'grad_norm': 7.125385284423828, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.010671225376427174, 'loss_2': 0.00380706787109375, 'loss_3': -15.822760581970215, 'loss_4': -0.20758569240570068, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 16:12:02,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:02,058 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:14<51:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:09,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018356749787926674, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01386526320129633, 'eval_loss_2': 0.00449148565530777, 'eval_loss_3': -18.045696258544922, 'eval_loss_4': 0.1485321968793869, 'epoch': 12.5}
{'loss': 0.014, 'grad_norm': 5.526390552520752, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.011002400889992714, 'loss_2': 0.002956390380859375, 'loss_3': -15.762945175170898, 'loss_4': 0.21576163172721863, 'epoch': 12.51}
{'loss': 0.0155, 'grad_norm': 6.456777572631836, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.012192758731544018, 'loss_2': 0.003337860107421875, 'loss_3': -16.01401138305664, 'loss_4': 0.18146908283233643, 'epoch': 12.51}
{'loss': 0.0089, 'grad_norm': 5.129329204559326, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.008522596210241318, 'loss_2': 0.00041937828063964844, 'loss_3': -16.05897331237793, 'loss_4': 0.03001391887664795, 'epoch': 12.52}
{'loss': 0.0162, 'grad_norm': 5.58021879196167, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.007878242060542107, 'loss_2': 0.00830841064453125, 'loss_3': -15.925217628479004, 'loss_4': -0.003771662712097168, 'epoch': 12.52}
{'loss': 0.0195, 'grad_norm': 7.786123752593994, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.019220633432269096, 'loss_2': 0.0002601146697998047, 'loss_3': -15.907295227050781, 'loss_4': -0.30247530341148376, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 16:12:09,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:09,400 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:22<51:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:16,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019232943654060364, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.015305533073842525, 'eval_loss_2': 0.003927409648895264, 'eval_loss_3': -18.04914093017578, 'eval_loss_4': -0.09977104514837265, 'epoch': 12.53}
{'loss': 0.0317, 'grad_norm': 32.77684783935547, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.03129526972770691, 'loss_2': 0.00045013427734375, 'loss_3': -15.723846435546875, 'loss_4': 0.15090669691562653, 'epoch': 12.53}
{'loss': 0.0136, 'grad_norm': 11.319549560546875, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.01152098085731268, 'loss_2': 0.0020427703857421875, 'loss_3': -16.239967346191406, 'loss_4': -0.024384908378124237, 'epoch': 12.54}
{'loss': 0.0109, 'grad_norm': 5.495093822479248, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.009838336147367954, 'loss_2': 0.0010509490966796875, 'loss_3': -16.012882232666016, 'loss_4': -0.08039075881242752, 'epoch': 12.55}
{'loss': 0.0183, 'grad_norm': 4.667754650115967, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.005977731663733721, 'loss_2': 0.0123443603515625, 'loss_3': -16.093177795410156, 'loss_4': -0.18959319591522217, 'epoch': 12.55}
{'loss': 0.0143, 'grad_norm': 6.568260192871094, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.009982194751501083, 'loss_2': 0.004276275634765625, 'loss_3': -16.13904571533203, 'loss_4': -0.34335529804229736, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 16:12:16,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:16,739 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:29<51:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:24,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021505121141672134, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016963040456175804, 'eval_loss_2': 0.0045420825481414795, 'eval_loss_3': -18.050214767456055, 'eval_loss_4': -0.1489202082157135, 'epoch': 12.56}
{'loss': 0.0239, 'grad_norm': 11.982964515686035, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.018216008320450783, 'loss_2': 0.005725860595703125, 'loss_3': -15.982912063598633, 'loss_4': -0.14552530646324158, 'epoch': 12.56}
{'loss': 0.0078, 'grad_norm': 4.912888526916504, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.00718529662117362, 'loss_2': 0.0005855560302734375, 'loss_3': -15.823858261108398, 'loss_4': -0.24846991896629333, 'epoch': 12.57}
{'loss': 0.0156, 'grad_norm': 8.639533996582031, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.011752594262361526, 'loss_2': 0.0038738250732421875, 'loss_3': -16.04671287536621, 'loss_4': -0.5117892026901245, 'epoch': 12.58}
{'loss': 0.022, 'grad_norm': 9.76961612701416, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.019413115456700325, 'loss_2': 0.002628326416015625, 'loss_3': -16.125699996948242, 'loss_4': -0.29613032937049866, 'epoch': 12.58}
{'loss': 0.0666, 'grad_norm': 21.081222534179688, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.06433869898319244, 'loss_2': 0.00225830078125, 'loss_3': -15.961109161376953, 'loss_4': 0.04501023143529892, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 16:12:24,078 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:24,078 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:36<51:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:31,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02336868830025196, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.238, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018076831474900246, 'eval_loss_2': 0.005291856825351715, 'eval_loss_3': -18.041440963745117, 'eval_loss_4': -0.0826607421040535, 'epoch': 12.59}
{'loss': 0.0225, 'grad_norm': 11.794264793395996, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.01766127161681652, 'loss_2': 0.00482177734375, 'loss_3': -15.97442626953125, 'loss_4': -0.043100543320178986, 'epoch': 12.59}
{'loss': 0.025, 'grad_norm': 7.807493686676025, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.016097450628876686, 'loss_2': 0.008880615234375, 'loss_3': -16.00041961669922, 'loss_4': 0.1899561882019043, 'epoch': 12.6}
{'loss': 0.0093, 'grad_norm': 4.9989094734191895, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.005308979190886021, 'loss_2': 0.00396728515625, 'loss_3': -15.981380462646484, 'loss_4': -0.12616132199764252, 'epoch': 12.6}
{'loss': 0.0234, 'grad_norm': 5.830223083496094, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.014758752658963203, 'loss_2': 0.00868988037109375, 'loss_3': -15.891249656677246, 'loss_4': -0.26657381653785706, 'epoch': 12.61}
{'loss': 0.0139, 'grad_norm': 5.707932472229004, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.008298635482788086, 'loss_2': 0.005615234375, 'loss_3': -16.019289016723633, 'loss_4': -0.3417541980743408, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 16:12:31,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:31,426 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:44<51:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:38,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02555639110505581, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.586, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01936311088502407, 'eval_loss_2': 0.006193280220031738, 'eval_loss_3': -18.077943801879883, 'eval_loss_4': -0.16227377951145172, 'epoch': 12.62}
{'loss': 0.0294, 'grad_norm': 8.403186798095703, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.02475782111287117, 'loss_2': 0.00469207763671875, 'loss_3': -15.997457504272461, 'loss_4': 0.0226663276553154, 'epoch': 12.62}
{'loss': 0.0265, 'grad_norm': 8.04704475402832, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.01823602430522442, 'loss_2': 0.00830078125, 'loss_3': -15.951295852661133, 'loss_4': 0.20088256895542145, 'epoch': 12.63}
{'loss': 0.0157, 'grad_norm': 6.1014485359191895, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.010967114940285683, 'loss_2': 0.0046844482421875, 'loss_3': -16.030630111694336, 'loss_4': -0.3907940685749054, 'epoch': 12.63}
{'loss': 0.0185, 'grad_norm': 6.156560897827148, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.012331011705100536, 'loss_2': 0.00621795654296875, 'loss_3': -15.86756420135498, 'loss_4': 0.10329180955886841, 'epoch': 12.64}
{'loss': 0.0158, 'grad_norm': 5.810293197631836, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.009098510257899761, 'loss_2': 0.00672149658203125, 'loss_3': -15.984167098999023, 'loss_4': -0.14740872383117676, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 16:12:38,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:38,763 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [53:51<51:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:46,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023666923865675926, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019542761147022247, 'eval_loss_2': 0.004124164581298828, 'eval_loss_3': -18.067569732666016, 'eval_loss_4': -0.25335797667503357, 'epoch': 12.65}
{'loss': 0.0091, 'grad_norm': 5.383454322814941, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.006956349592655897, 'loss_2': 0.002185821533203125, 'loss_3': -15.986440658569336, 'loss_4': -0.1029844731092453, 'epoch': 12.65}
{'loss': 0.0117, 'grad_norm': 4.578147888183594, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.008055269718170166, 'loss_2': 0.003604888916015625, 'loss_3': -16.14291763305664, 'loss_4': -0.6582419872283936, 'epoch': 12.66}
{'loss': 0.0165, 'grad_norm': 7.72735071182251, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.01047119777649641, 'loss_2': 0.006046295166015625, 'loss_3': -15.901710510253906, 'loss_4': -0.5555435419082642, 'epoch': 12.66}
{'loss': 0.0141, 'grad_norm': 5.719658374786377, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.012826756574213505, 'loss_2': 0.0012569427490234375, 'loss_3': -15.799575805664062, 'loss_4': -0.25716421008110046, 'epoch': 12.67}
{'loss': 0.024, 'grad_norm': 24.45528221130371, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.023289114236831665, 'loss_2': 0.0007371902465820312, 'loss_3': -16.03018569946289, 'loss_4': -0.22941696643829346, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 16:12:46,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:46,099 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [53:58<51:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:53,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025009114295244217, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.749, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018873590975999832, 'eval_loss_2': 0.006135523319244385, 'eval_loss_3': -18.0589599609375, 'eval_loss_4': -0.06971868127584457, 'epoch': 12.67}
{'loss': 0.057, 'grad_norm': 38.427040100097656, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.04955027997493744, 'loss_2': 0.007480621337890625, 'loss_3': -15.858275413513184, 'loss_4': -0.06481871753931046, 'epoch': 12.68}
{'loss': 0.0156, 'grad_norm': 5.942725658416748, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.009412199258804321, 'loss_2': 0.006198883056640625, 'loss_3': -15.899314880371094, 'loss_4': -0.2848622798919678, 'epoch': 12.69}
{'loss': 0.0164, 'grad_norm': 6.464975833892822, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.014010579325258732, 'loss_2': 0.00241851806640625, 'loss_3': -16.18747329711914, 'loss_4': -0.0491643100976944, 'epoch': 12.69}
{'loss': 0.0117, 'grad_norm': 6.484963893890381, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.010421615093946457, 'loss_2': 0.0013074874877929688, 'loss_3': -15.827116966247559, 'loss_4': 0.21780791878700256, 'epoch': 12.7}
{'loss': 0.0222, 'grad_norm': 7.29071044921875, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.009879969991743565, 'loss_2': 0.01230621337890625, 'loss_3': -15.930910110473633, 'loss_4': -0.20374301075935364, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 16:12:53,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:53,432 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:06<51:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:00,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026551425457000732, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.734, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021215857937932014, 'eval_loss_2': 0.005335569381713867, 'eval_loss_3': -18.04483413696289, 'eval_loss_4': 0.10948693752288818, 'epoch': 12.7}
{'loss': 0.017, 'grad_norm': 5.049865245819092, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.007956829853355885, 'loss_2': 0.00901031494140625, 'loss_3': -16.054780960083008, 'loss_4': 0.22314776480197906, 'epoch': 12.71}
{'loss': 0.0234, 'grad_norm': 8.878281593322754, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.017491567879915237, 'loss_2': 0.0059356689453125, 'loss_3': -15.843077659606934, 'loss_4': 0.1642743945121765, 'epoch': 12.72}
{'loss': 0.0187, 'grad_norm': 5.436305046081543, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.016608987003564835, 'loss_2': 0.002105712890625, 'loss_3': -16.11112403869629, 'loss_4': 0.04069174826145172, 'epoch': 12.72}
{'loss': 0.0141, 'grad_norm': 6.162337779998779, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.011046401225030422, 'loss_2': 0.003047943115234375, 'loss_3': -16.05127716064453, 'loss_4': 0.28377312421798706, 'epoch': 12.73}
{'loss': 0.0164, 'grad_norm': 6.921222686767578, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.014979442581534386, 'loss_2': 0.0014553070068359375, 'loss_3': -15.763163566589355, 'loss_4': 0.034395016729831696, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 16:13:00,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:00,765 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:13<51:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:08,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024874284863471985, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.768, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.020315036177635193, 'eval_loss_2': 0.004559248685836792, 'eval_loss_3': -18.01934242248535, 'eval_loss_4': 0.45811307430267334, 'epoch': 12.73}
{'loss': 0.0673, 'grad_norm': 15.99344539642334, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.06544286012649536, 'loss_2': 0.0019016265869140625, 'loss_3': -15.874356269836426, 'loss_4': 0.9792284965515137, 'epoch': 12.74}
{'loss': 0.0355, 'grad_norm': 9.592497825622559, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.031307708472013474, 'loss_2': 0.00420379638671875, 'loss_3': -15.957006454467773, 'loss_4': 0.5862929821014404, 'epoch': 12.74}
{'loss': 0.0084, 'grad_norm': 4.690924644470215, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.0047914450988173485, 'loss_2': 0.0035915374755859375, 'loss_3': -16.076974868774414, 'loss_4': 0.30920910835266113, 'epoch': 12.75}
{'loss': 0.0479, 'grad_norm': 7.258594512939453, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.04539945721626282, 'loss_2': 0.002490997314453125, 'loss_3': -16.001544952392578, 'loss_4': 0.2986988425254822, 'epoch': 12.76}
{'loss': 0.0145, 'grad_norm': 6.706132411956787, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.012613004073500633, 'loss_2': 0.001903533935546875, 'loss_3': -15.98263168334961, 'loss_4': 1.0081984996795654, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 16:13:08,098 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:08,098 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:20<51:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:15,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02386232279241085, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01934872753918171, 'eval_loss_2': 0.004513591527938843, 'eval_loss_3': -17.987564086914062, 'eval_loss_4': 0.6520764827728271, 'epoch': 12.76}
{'loss': 0.0242, 'grad_norm': 8.139496803283691, 'learning_rate': 1.725e-05, 'loss_1': 0.015767458826303482, 'loss_2': 0.008453369140625, 'loss_3': -16.089282989501953, 'loss_4': 0.6203145980834961, 'epoch': 12.77}
{'loss': 0.0125, 'grad_norm': 6.841559886932373, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.010487087070941925, 'loss_2': 0.00205230712890625, 'loss_3': -15.749631881713867, 'loss_4': 0.7459631562232971, 'epoch': 12.77}
{'loss': 0.0241, 'grad_norm': 9.590577125549316, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.014174260199069977, 'loss_2': 0.0099029541015625, 'loss_3': -16.176380157470703, 'loss_4': 0.9183018803596497, 'epoch': 12.78}
{'loss': 0.0757, 'grad_norm': 21.129243850708008, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.07192816585302353, 'loss_2': 0.003772735595703125, 'loss_3': -15.923507690429688, 'loss_4': 0.7106618881225586, 'epoch': 12.78}
{'loss': 0.0198, 'grad_norm': 7.300106048583984, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.013388367369771004, 'loss_2': 0.006439208984375, 'loss_3': -15.94277572631836, 'loss_4': 0.6997998952865601, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 16:13:15,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:15,441 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:28<51:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:22,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023386675864458084, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.794, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018901845440268517, 'eval_loss_2': 0.004484832286834717, 'eval_loss_3': -18.009639739990234, 'eval_loss_4': 0.7082376480102539, 'epoch': 12.79}
{'loss': 0.0146, 'grad_norm': 8.039544105529785, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.011953654699027538, 'loss_2': 0.002635955810546875, 'loss_3': -15.932573318481445, 'loss_4': 0.6828837394714355, 'epoch': 12.8}
{'loss': 0.0173, 'grad_norm': 6.905407428741455, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.011806564405560493, 'loss_2': 0.00551605224609375, 'loss_3': -15.965145111083984, 'loss_4': 0.8689165115356445, 'epoch': 12.8}
{'loss': 0.0157, 'grad_norm': 6.147314548492432, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.010809073224663734, 'loss_2': 0.0048675537109375, 'loss_3': -16.08401107788086, 'loss_4': 0.790553092956543, 'epoch': 12.81}
{'loss': 0.0097, 'grad_norm': 6.1730546951293945, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.009676555171608925, 'loss_2': 2.5033950805664062e-05, 'loss_3': -15.941692352294922, 'loss_4': 0.6723882555961609, 'epoch': 12.81}
{'loss': 0.0128, 'grad_norm': 5.60254430770874, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.009715608321130276, 'loss_2': 0.003070831298828125, 'loss_3': -15.930776596069336, 'loss_4': 0.7822349667549133, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 16:13:22,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:22,781 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:35<50:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:30,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02260594815015793, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01822265237569809, 'eval_loss_2': 0.004383295774459839, 'eval_loss_3': -18.019386291503906, 'eval_loss_4': 0.8435264825820923, 'epoch': 12.82}
{'loss': 0.0081, 'grad_norm': 5.073461055755615, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.005769285839051008, 'loss_2': 0.002285003662109375, 'loss_3': -15.738690376281738, 'loss_4': 0.7806743383407593, 'epoch': 12.83}
{'loss': 0.0193, 'grad_norm': 7.179666996002197, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.016316736117005348, 'loss_2': 0.003032684326171875, 'loss_3': -16.04535484313965, 'loss_4': 0.9980473518371582, 'epoch': 12.83}
{'loss': 0.0099, 'grad_norm': 5.4136552810668945, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.00797251146286726, 'loss_2': 0.001903533935546875, 'loss_3': -16.200668334960938, 'loss_4': 0.9442625641822815, 'epoch': 12.84}
{'loss': 0.0104, 'grad_norm': 5.107698440551758, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.004860648885369301, 'loss_2': 0.0054931640625, 'loss_3': -15.948419570922852, 'loss_4': 0.555874228477478, 'epoch': 12.84}
{'loss': 0.0086, 'grad_norm': 5.680031776428223, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.008092056959867477, 'loss_2': 0.0005078315734863281, 'loss_3': -16.03525161743164, 'loss_4': 0.6976598501205444, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 16:13:30,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:30,121 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:42<50:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:37,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02155490219593048, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.833, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01753733679652214, 'eval_loss_2': 0.004017561674118042, 'eval_loss_3': -18.004779815673828, 'eval_loss_4': 0.8060982823371887, 'epoch': 12.85}
{'loss': 0.009, 'grad_norm': 5.280638694763184, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.008804363198578358, 'loss_2': 0.00018024444580078125, 'loss_3': -16.058696746826172, 'loss_4': 0.9087715148925781, 'epoch': 12.85}
{'loss': 0.0162, 'grad_norm': 7.5670084953308105, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.012264843098819256, 'loss_2': 0.0038967132568359375, 'loss_3': -15.792154312133789, 'loss_4': 0.9558818340301514, 'epoch': 12.86}
{'loss': 0.0144, 'grad_norm': 6.759661674499512, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.012558192946016788, 'loss_2': 0.00186920166015625, 'loss_3': -15.870065689086914, 'loss_4': 0.7441139817237854, 'epoch': 12.87}
{'loss': 0.0109, 'grad_norm': 5.446780681610107, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.008193149231374264, 'loss_2': 0.0027065277099609375, 'loss_3': -16.074222564697266, 'loss_4': 0.458183616399765, 'epoch': 12.87}
{'loss': 0.0156, 'grad_norm': 5.3691511154174805, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.0068092648871243, 'loss_2': 0.0087432861328125, 'loss_3': -16.127676010131836, 'loss_4': 0.38463979959487915, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 16:13:37,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:37,459 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [54:50<50:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:44,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020840082317590714, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.017133865505456924, 'eval_loss_2': 0.003706216812133789, 'eval_loss_3': -17.999544143676758, 'eval_loss_4': 0.780019998550415, 'epoch': 12.88}
{'loss': 0.021, 'grad_norm': 10.334738731384277, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.02039746195077896, 'loss_2': 0.0006060600280761719, 'loss_3': -15.988359451293945, 'loss_4': 0.6820353269577026, 'epoch': 12.88}
{'loss': 0.0373, 'grad_norm': 22.59559440612793, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.03713159263134003, 'loss_2': 0.00015604496002197266, 'loss_3': -15.687870979309082, 'loss_4': 0.7618211507797241, 'epoch': 12.89}
{'loss': 0.021, 'grad_norm': 6.069033622741699, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.013863304629921913, 'loss_2': 0.007171630859375, 'loss_3': -15.805381774902344, 'loss_4': 0.6863497495651245, 'epoch': 12.9}
{'loss': 0.0204, 'grad_norm': 6.159707546234131, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.008182617835700512, 'loss_2': 0.012237548828125, 'loss_3': -15.804352760314941, 'loss_4': 0.6884758472442627, 'epoch': 12.9}
{'loss': 0.0409, 'grad_norm': 14.300379753112793, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.03588612750172615, 'loss_2': 0.00496673583984375, 'loss_3': -15.740798950195312, 'loss_4': 0.7049738168716431, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 16:13:44,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:44,798 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [54:57<50:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:52,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019206557422876358, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015246185474097729, 'eval_loss_2': 0.003960371017456055, 'eval_loss_3': -17.989818572998047, 'eval_loss_4': 0.7721086740493774, 'epoch': 12.91}
{'loss': 0.012, 'grad_norm': 7.648539066314697, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.010841564275324345, 'loss_2': 0.0011892318725585938, 'loss_3': -15.703960418701172, 'loss_4': 0.5207716822624207, 'epoch': 12.91}
{'loss': 0.0099, 'grad_norm': 5.628737926483154, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.0066162641160190105, 'loss_2': 0.0032978057861328125, 'loss_3': -15.995763778686523, 'loss_4': 0.6953985691070557, 'epoch': 12.92}
{'loss': 0.0086, 'grad_norm': 5.276566505432129, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.006239552050828934, 'loss_2': 0.0023822784423828125, 'loss_3': -15.849688529968262, 'loss_4': 0.44901734590530396, 'epoch': 12.92}
{'loss': 0.032, 'grad_norm': 17.039749145507812, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.026109348982572556, 'loss_2': 0.005870819091796875, 'loss_3': -15.878667831420898, 'loss_4': 0.5441569089889526, 'epoch': 12.93}
{'loss': 0.0093, 'grad_norm': 5.337219715118408, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.007545407861471176, 'loss_2': 0.0017099380493164062, 'loss_3': -15.810120582580566, 'loss_4': 0.6768025755882263, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 16:13:52,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:52,137 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:04<50:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:59,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021519724279642105, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.846, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01726943626999855, 'eval_loss_2': 0.004250288009643555, 'eval_loss_3': -17.978473663330078, 'eval_loss_4': 0.7838195562362671, 'epoch': 12.94}
{'loss': 0.0393, 'grad_norm': 11.167878150939941, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.033741019666194916, 'loss_2': 0.005588531494140625, 'loss_3': -15.943389892578125, 'loss_4': 0.7662824392318726, 'epoch': 12.94}
{'loss': 0.0177, 'grad_norm': 5.4279069900512695, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.010892552323639393, 'loss_2': 0.006839752197265625, 'loss_3': -15.849403381347656, 'loss_4': 0.5513080954551697, 'epoch': 12.95}
{'loss': 0.0182, 'grad_norm': 6.698185920715332, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.01156102865934372, 'loss_2': 0.006603240966796875, 'loss_3': -15.800333023071289, 'loss_4': 0.7682843804359436, 'epoch': 12.95}
{'loss': 0.0175, 'grad_norm': 7.755651950836182, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.013287554495036602, 'loss_2': 0.004180908203125, 'loss_3': -15.854385375976562, 'loss_4': 0.5771142244338989, 'epoch': 12.96}
{'loss': 0.0228, 'grad_norm': 15.096590995788574, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.022095629945397377, 'loss_2': 0.00066375732421875, 'loss_3': -15.7611665725708, 'loss_4': 0.29268133640289307, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 16:13:59,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:59,473 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:12<50:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:14:06,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020525123924016953, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.86, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017490912228822708, 'eval_loss_2': 0.0030342116951942444, 'eval_loss_3': -17.984012603759766, 'eval_loss_4': 0.7929966449737549, 'epoch': 12.97}
{'loss': 0.01, 'grad_norm': 6.188849925994873, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.009126521646976471, 'loss_2': 0.0008497238159179688, 'loss_3': -16.05436897277832, 'loss_4': 0.9719473123550415, 'epoch': 12.97}
{'loss': 0.0191, 'grad_norm': 11.106047630310059, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.01362692378461361, 'loss_2': 0.005512237548828125, 'loss_3': -15.708829879760742, 'loss_4': 0.9832388162612915, 'epoch': 12.98}
{'loss': 0.0144, 'grad_norm': 8.280475616455078, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.014275146648287773, 'loss_2': 0.00016868114471435547, 'loss_3': -15.838605880737305, 'loss_4': 0.8587392568588257, 'epoch': 12.98}
{'loss': 0.01, 'grad_norm': 5.403774738311768, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.007035798393189907, 'loss_2': 0.002933502197265625, 'loss_3': -15.819267272949219, 'loss_4': 0.8619954586029053, 'epoch': 12.99}
{'loss': 0.0121, 'grad_norm': 5.93215799331665, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.010046648792922497, 'loss_2': 0.0020294189453125, 'loss_3': -15.813716888427734, 'loss_4': 0.7079876661300659, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 16:14:06,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:06,786 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:19<49:25,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:14:13,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021325193345546722, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01728024147450924, 'eval_loss_2': 0.004044950008392334, 'eval_loss_3': -18.007225036621094, 'eval_loss_4': 0.7100551724433899, 'epoch': 12.99}
{'loss': 0.0047, 'grad_norm': 6.953395843505859, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.0042509534396231174, 'loss_2': 0.00044083595275878906, 'loss_3': -15.867183685302734, 'loss_4': 0.16558516025543213, 'epoch': 13.0}
{'loss': 0.013, 'grad_norm': 6.184171199798584, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.011008834466338158, 'loss_2': 0.0019474029541015625, 'loss_3': -15.812005043029785, 'loss_4': 0.6375987529754639, 'epoch': 13.01}
{'loss': 0.0156, 'grad_norm': 6.495484352111816, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.012435412965714931, 'loss_2': 0.003204345703125, 'loss_3': -15.89411449432373, 'loss_4': 0.5180931687355042, 'epoch': 13.01}
{'loss': 0.0247, 'grad_norm': 6.814857006072998, 'learning_rate': 1.7e-05, 'loss_1': 0.010643456131219864, 'loss_2': 0.01409912109375, 'loss_3': -15.89208984375, 'loss_4': 0.418260395526886, 'epoch': 13.02}
{'loss': 0.02, 'grad_norm': 8.606318473815918, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.0148309962823987, 'loss_2': 0.005126953125, 'loss_3': -16.012554168701172, 'loss_4': 0.5709751844406128, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 16:14:13,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:13,830 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:26<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:14:21,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02149886265397072, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.825, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015109721571207047, 'eval_loss_2': 0.006389141082763672, 'eval_loss_3': -18.00712776184082, 'eval_loss_4': 0.3663242757320404, 'epoch': 13.02}
{'loss': 0.0149, 'grad_norm': 4.5574870109558105, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.005000729113817215, 'loss_2': 0.00994110107421875, 'loss_3': -15.982492446899414, 'loss_4': 0.4781370162963867, 'epoch': 13.03}
{'loss': 0.0107, 'grad_norm': 4.5231733322143555, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.00670837564393878, 'loss_2': 0.0039520263671875, 'loss_3': -15.845085144042969, 'loss_4': 0.2717045545578003, 'epoch': 13.03}
{'loss': 0.0104, 'grad_norm': 5.189947605133057, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.00690470589324832, 'loss_2': 0.00350189208984375, 'loss_3': -15.73259449005127, 'loss_4': 0.08057784289121628, 'epoch': 13.04}
{'loss': 0.0066, 'grad_norm': 5.389833927154541, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.006074863485991955, 'loss_2': 0.00049591064453125, 'loss_3': -16.05769920349121, 'loss_4': 0.2984328866004944, 'epoch': 13.05}
{'loss': 0.015, 'grad_norm': 7.118544578552246, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.014917531050741673, 'loss_2': 7.796287536621094e-05, 'loss_3': -15.867189407348633, 'loss_4': 0.22315064072608948, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 16:14:21,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:21,168 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:33<50:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:14:28,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01884567365050316, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.182, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015833696350455284, 'eval_loss_2': 0.0030119791626930237, 'eval_loss_3': -18.031538009643555, 'eval_loss_4': 0.0950317308306694, 'epoch': 13.05}
{'loss': 0.01, 'grad_norm': 5.690074920654297, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.007029786705970764, 'loss_2': 0.0029468536376953125, 'loss_3': -15.989374160766602, 'loss_4': 0.17096483707427979, 'epoch': 13.06}
{'loss': 0.0079, 'grad_norm': 4.937428951263428, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.005781203042715788, 'loss_2': 0.00214385986328125, 'loss_3': -16.077098846435547, 'loss_4': -0.19134150445461273, 'epoch': 13.06}
{'loss': 0.0079, 'grad_norm': 5.481888294219971, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.006320091895759106, 'loss_2': 0.0015392303466796875, 'loss_3': -15.826273918151855, 'loss_4': -0.14937543869018555, 'epoch': 13.07}
{'loss': 0.027, 'grad_norm': 5.313855171203613, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.011503852903842926, 'loss_2': 0.015472412109375, 'loss_3': -16.162416458129883, 'loss_4': 0.21401254832744598, 'epoch': 13.08}
{'loss': 0.0136, 'grad_norm': 5.286374092102051, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.005954605061560869, 'loss_2': 0.007598876953125, 'loss_3': -15.937618255615234, 'loss_4': 0.23398731648921967, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 16:14:28,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:28,493 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:41<50:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:35,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0239255428314209, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.525, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015449212864041328, 'eval_loss_2': 0.00847633183002472, 'eval_loss_3': -18.03416633605957, 'eval_loss_4': -0.009811237454414368, 'epoch': 13.08}
{'loss': 0.0144, 'grad_norm': 5.23184871673584, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.006770229898393154, 'loss_2': 0.007671356201171875, 'loss_3': -15.95113754272461, 'loss_4': 0.08394506573677063, 'epoch': 13.09}
{'loss': 0.0214, 'grad_norm': 4.725967884063721, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.005930121522396803, 'loss_2': 0.01546478271484375, 'loss_3': -16.13373374938965, 'loss_4': 0.39112064242362976, 'epoch': 13.09}
{'loss': 0.0135, 'grad_norm': 4.7318315505981445, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.0055459230206906796, 'loss_2': 0.007965087890625, 'loss_3': -15.95935344696045, 'loss_4': -0.2186531126499176, 'epoch': 13.1}
{'loss': 0.0224, 'grad_norm': 9.77202320098877, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.020659808069467545, 'loss_2': 0.0017261505126953125, 'loss_3': -16.05169105529785, 'loss_4': -0.22610364854335785, 'epoch': 13.1}
{'loss': 0.0191, 'grad_norm': 5.642656326293945, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.008840112015604973, 'loss_2': 0.010223388671875, 'loss_3': -16.03778839111328, 'loss_4': -0.23582889139652252, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 16:14:35,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:35,830 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [55:48<50:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:43,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01943700760602951, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.813, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015178493224084377, 'eval_loss_2': 0.004258513450622559, 'eval_loss_3': -18.05880355834961, 'eval_loss_4': 8.058827370405197e-05, 'epoch': 13.11}
{'loss': 0.0281, 'grad_norm': 11.011000633239746, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.019238358363509178, 'loss_2': 0.00881195068359375, 'loss_3': -16.14893341064453, 'loss_4': -0.31315532326698303, 'epoch': 13.12}
{'loss': 0.0304, 'grad_norm': 12.973183631896973, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.024262050166726112, 'loss_2': 0.006145477294921875, 'loss_3': -16.158199310302734, 'loss_4': 0.3354555368423462, 'epoch': 13.12}
{'loss': 0.0175, 'grad_norm': 7.394423484802246, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.015128443017601967, 'loss_2': 0.00238037109375, 'loss_3': -16.112815856933594, 'loss_4': -0.26587986946105957, 'epoch': 13.13}
{'loss': 0.0397, 'grad_norm': 18.64876937866211, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.036154888570308685, 'loss_2': 0.003551483154296875, 'loss_3': -16.063642501831055, 'loss_4': -0.16387581825256348, 'epoch': 13.13}
{'loss': 0.0166, 'grad_norm': 7.20729398727417, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.016062773764133453, 'loss_2': 0.00051116943359375, 'loss_3': -16.076860427856445, 'loss_4': 0.16242989897727966, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 16:14:43,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:43,172 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [55:55<50:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:50,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018732937052845955, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.627, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014965415932238102, 'eval_loss_2': 0.0037675201892852783, 'eval_loss_3': -18.072534561157227, 'eval_loss_4': 0.1074296161532402, 'epoch': 13.14}
{'loss': 0.0145, 'grad_norm': 5.314903736114502, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.007189077325165272, 'loss_2': 0.00732421875, 'loss_3': -16.055349349975586, 'loss_4': -0.08816211670637131, 'epoch': 13.15}
{'loss': 0.0245, 'grad_norm': 7.251594543457031, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.019956447184085846, 'loss_2': 0.0045166015625, 'loss_3': -16.10483741760254, 'loss_4': 0.22812622785568237, 'epoch': 13.15}
{'loss': 0.016, 'grad_norm': 8.224408149719238, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.013662975281476974, 'loss_2': 0.002315521240234375, 'loss_3': -16.062740325927734, 'loss_4': 0.26593196392059326, 'epoch': 13.16}
{'loss': 0.0071, 'grad_norm': 5.2886433601379395, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.006121515296399593, 'loss_2': 0.0010013580322265625, 'loss_3': -16.265506744384766, 'loss_4': 0.10576199740171432, 'epoch': 13.16}
{'loss': 0.0133, 'grad_norm': 4.523906707763672, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.005496785510331392, 'loss_2': 0.00785064697265625, 'loss_3': -16.146379470825195, 'loss_4': -0.01616901159286499, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 16:14:50,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:50,510 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:03<49:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:57,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019192148000001907, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.755, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0157149750739336, 'eval_loss_2': 0.0034771710634231567, 'eval_loss_3': -18.083410263061523, 'eval_loss_4': 0.2692202925682068, 'epoch': 13.17}
{'loss': 0.0341, 'grad_norm': 13.30252742767334, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.03229314833879471, 'loss_2': 0.0018405914306640625, 'loss_3': -16.158727645874023, 'loss_4': 0.02801169455051422, 'epoch': 13.17}
{'loss': 0.0151, 'grad_norm': 5.020483493804932, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.006477548275142908, 'loss_2': 0.00860595703125, 'loss_3': -15.912097930908203, 'loss_4': -0.0587041974067688, 'epoch': 13.18}
{'loss': 0.026, 'grad_norm': 13.26461410522461, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.019169438630342484, 'loss_2': 0.006832122802734375, 'loss_3': -16.231693267822266, 'loss_4': 0.3055422008037567, 'epoch': 13.19}
{'loss': 0.0061, 'grad_norm': 4.648370265960693, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.004955913871526718, 'loss_2': 0.0011844635009765625, 'loss_3': -16.11480712890625, 'loss_4': 0.4732125997543335, 'epoch': 13.19}
{'loss': 0.0207, 'grad_norm': 5.960394382476807, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.01228813175112009, 'loss_2': 0.00843048095703125, 'loss_3': -16.187030792236328, 'loss_4': 0.8836076259613037, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 16:14:57,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:57,849 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:10<49:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:05,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020883508026599884, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.759, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.016632549464702606, 'eval_loss_2': 0.004250958561897278, 'eval_loss_3': -18.106063842773438, 'eval_loss_4': 0.5057944059371948, 'epoch': 13.2}
{'loss': 0.0157, 'grad_norm': 5.865714073181152, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.010306295938789845, 'loss_2': 0.005390167236328125, 'loss_3': -16.07930564880371, 'loss_4': 0.30472779273986816, 'epoch': 13.2}
{'loss': 0.0304, 'grad_norm': 9.800188064575195, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.028988216072320938, 'loss_2': 0.00138092041015625, 'loss_3': -16.04725456237793, 'loss_4': 0.7892951965332031, 'epoch': 13.21}
{'loss': 0.0166, 'grad_norm': 6.255987167358398, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.009815176948904991, 'loss_2': 0.0067901611328125, 'loss_3': -15.959813117980957, 'loss_4': 0.1367131769657135, 'epoch': 13.22}
{'loss': 0.0083, 'grad_norm': 5.069822311401367, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.008196529000997543, 'loss_2': 0.0001138448715209961, 'loss_3': -16.05056381225586, 'loss_4': 0.2465251386165619, 'epoch': 13.22}
{'loss': 0.0131, 'grad_norm': 5.739617347717285, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.013044392690062523, 'loss_2': 4.410743713378906e-05, 'loss_3': -16.02302360534668, 'loss_4': 0.5755723118782043, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 16:15:05,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:05,185 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:17<49:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:12,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021089842543005943, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.759, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015100114047527313, 'eval_loss_2': 0.005989730358123779, 'eval_loss_3': -18.0877742767334, 'eval_loss_4': 0.5996192693710327, 'epoch': 13.23}
{'loss': 0.0244, 'grad_norm': 11.882433891296387, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.017621684819459915, 'loss_2': 0.00677490234375, 'loss_3': -15.982922554016113, 'loss_4': 0.7121270895004272, 'epoch': 13.23}
{'loss': 0.0132, 'grad_norm': 7.637299537658691, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.012791275978088379, 'loss_2': 0.00039958953857421875, 'loss_3': -15.96533203125, 'loss_4': 0.2659871578216553, 'epoch': 13.24}
{'loss': 0.0169, 'grad_norm': 7.434885501861572, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.013593651354312897, 'loss_2': 0.003284454345703125, 'loss_3': -16.092164993286133, 'loss_4': 0.715766191482544, 'epoch': 13.24}
{'loss': 0.0121, 'grad_norm': 5.267116069793701, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.005912382155656815, 'loss_2': 0.006229400634765625, 'loss_3': -16.187034606933594, 'loss_4': 0.5009691715240479, 'epoch': 13.25}
{'loss': 0.0123, 'grad_norm': 6.838003635406494, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.011114499531686306, 'loss_2': 0.001186370849609375, 'loss_3': -16.12639045715332, 'loss_4': 0.9455437660217285, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 16:15:12,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:12,534 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:25<49:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:19,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019561070948839188, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015381593257188797, 'eval_loss_2': 0.004179477691650391, 'eval_loss_3': -18.06856346130371, 'eval_loss_4': 0.8309145569801331, 'epoch': 13.26}
{'loss': 0.0174, 'grad_norm': 6.121667861938477, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.012853446416556835, 'loss_2': 0.0045318603515625, 'loss_3': -16.04237174987793, 'loss_4': 0.872346818447113, 'epoch': 13.26}
{'loss': 0.0094, 'grad_norm': 5.3526434898376465, 'learning_rate': 1.675e-05, 'loss_1': 0.0050310660153627396, 'loss_2': 0.0043487548828125, 'loss_3': -16.074031829833984, 'loss_4': 0.49503093957901, 'epoch': 13.27}
{'loss': 0.0256, 'grad_norm': 9.798314094543457, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.021926524117588997, 'loss_2': 0.003662109375, 'loss_3': -15.938640594482422, 'loss_4': 0.6907542943954468, 'epoch': 13.27}
{'loss': 0.0087, 'grad_norm': 5.338858127593994, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.008315972983837128, 'loss_2': 0.0004239082336425781, 'loss_3': -16.136329650878906, 'loss_4': 0.8511763215065002, 'epoch': 13.28}
{'loss': 0.0872, 'grad_norm': 21.216753005981445, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.08152475953102112, 'loss_2': 0.0056610107421875, 'loss_3': -16.191329956054688, 'loss_4': 1.6509325504302979, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 16:15:19,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:19,872 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:32<49:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:27,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02400757372379303, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.831, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016932740807533264, 'eval_loss_2': 0.007074832916259766, 'eval_loss_3': -18.051305770874023, 'eval_loss_4': 1.0077433586120605, 'epoch': 13.28}
{'loss': 0.0137, 'grad_norm': 5.766229152679443, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.00908564031124115, 'loss_2': 0.00457763671875, 'loss_3': -16.010522842407227, 'loss_4': 0.9689458608627319, 'epoch': 13.29}
{'loss': 0.0089, 'grad_norm': 5.37758207321167, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.005885159131139517, 'loss_2': 0.0030117034912109375, 'loss_3': -16.015701293945312, 'loss_4': 0.6371557712554932, 'epoch': 13.3}
{'loss': 0.0202, 'grad_norm': 5.712952136993408, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.01213415339589119, 'loss_2': 0.00806427001953125, 'loss_3': -15.903888702392578, 'loss_4': 0.9761508107185364, 'epoch': 13.3}
{'loss': 0.0199, 'grad_norm': 5.458822250366211, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.007616295013576746, 'loss_2': 0.0122528076171875, 'loss_3': -16.26154136657715, 'loss_4': 1.0409919023513794, 'epoch': 13.31}
{'loss': 0.0091, 'grad_norm': 4.782182216644287, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.005036329384893179, 'loss_2': 0.00408935546875, 'loss_3': -16.0555419921875, 'loss_4': 1.0513755083084106, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 16:15:27,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:27,212 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:39<49:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:34,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02268649823963642, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018459932878613472, 'eval_loss_2': 0.004226565361022949, 'eval_loss_3': -18.03082847595215, 'eval_loss_4': 0.9904695749282837, 'epoch': 13.31}
{'loss': 0.0173, 'grad_norm': 7.581695079803467, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.010894321836531162, 'loss_2': 0.006443023681640625, 'loss_3': -16.0634765625, 'loss_4': 0.9724712371826172, 'epoch': 13.32}
{'loss': 0.0094, 'grad_norm': 5.1109209060668945, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.005203368607908487, 'loss_2': 0.00420379638671875, 'loss_3': -16.059633255004883, 'loss_4': 0.7463741302490234, 'epoch': 13.33}
{'loss': 0.0117, 'grad_norm': 6.662496566772461, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.008714054711163044, 'loss_2': 0.0030155181884765625, 'loss_3': -15.855029106140137, 'loss_4': 0.5857656002044678, 'epoch': 13.33}
{'loss': 0.0081, 'grad_norm': 4.994746208190918, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.006132947281002998, 'loss_2': 0.00201416015625, 'loss_3': -16.086078643798828, 'loss_4': 0.9227125644683838, 'epoch': 13.34}
{'loss': 0.0195, 'grad_norm': 5.967210292816162, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.01149804424494505, 'loss_2': 0.00799560546875, 'loss_3': -15.978721618652344, 'loss_4': 0.7470430731773376, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 16:15:34,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:34,555 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [56:47<49:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:41,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02249852567911148, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.88, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017631521448493004, 'eval_loss_2': 0.004867002367973328, 'eval_loss_3': -17.998008728027344, 'eval_loss_4': 0.8053080439567566, 'epoch': 13.34}
{'loss': 0.018, 'grad_norm': 8.560297012329102, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.01755097694694996, 'loss_2': 0.000484466552734375, 'loss_3': -16.073211669921875, 'loss_4': 0.9918853044509888, 'epoch': 13.35}
{'loss': 0.0124, 'grad_norm': 4.997934341430664, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.007171924225986004, 'loss_2': 0.00527191162109375, 'loss_3': -15.845799446105957, 'loss_4': 0.9849680662155151, 'epoch': 13.35}
{'loss': 0.0079, 'grad_norm': 5.185398101806641, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.006791709456592798, 'loss_2': 0.0011444091796875, 'loss_3': -16.027549743652344, 'loss_4': 0.7435150146484375, 'epoch': 13.36}
{'loss': 0.0131, 'grad_norm': 5.657660484313965, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.007558006327599287, 'loss_2': 0.0055694580078125, 'loss_3': -16.022674560546875, 'loss_4': 0.49390867352485657, 'epoch': 13.37}
{'loss': 0.0362, 'grad_norm': 6.950727939605713, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.020737063139677048, 'loss_2': 0.01543426513671875, 'loss_3': -16.08959197998047, 'loss_4': 1.079782485961914, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 16:15:41,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:41,890 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [56:54<49:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:49,225 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022056475281715393, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.809, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01829032599925995, 'eval_loss_2': 0.0037661492824554443, 'eval_loss_3': -17.988798141479492, 'eval_loss_4': 0.7934433221817017, 'epoch': 13.37}
{'loss': 0.0093, 'grad_norm': 4.622340679168701, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.007822547107934952, 'loss_2': 0.0015201568603515625, 'loss_3': -15.842823028564453, 'loss_4': 0.6450185775756836, 'epoch': 13.38}
{'loss': 0.0289, 'grad_norm': 12.3750638961792, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.02631322667002678, 'loss_2': 0.0025577545166015625, 'loss_3': -16.035411834716797, 'loss_4': 0.6927610039710999, 'epoch': 13.38}
{'loss': 0.0158, 'grad_norm': 5.940391540527344, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.011447339318692684, 'loss_2': 0.004364013671875, 'loss_3': -16.18892478942871, 'loss_4': 0.6699111461639404, 'epoch': 13.39}
{'loss': 0.017, 'grad_norm': 6.330977916717529, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.016273977234959602, 'loss_2': 0.0007266998291015625, 'loss_3': -15.991375923156738, 'loss_4': 0.5904288291931152, 'epoch': 13.4}
{'loss': 0.0082, 'grad_norm': 5.809434413909912, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.007808218244463205, 'loss_2': 0.000438690185546875, 'loss_3': -15.962955474853516, 'loss_4': 0.6832902431488037, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 16:15:49,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:49,225 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:01<49:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:56,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026433352380990982, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01961435377597809, 'eval_loss_2': 0.006818994879722595, 'eval_loss_3': -17.98845863342285, 'eval_loss_4': 0.8765419721603394, 'epoch': 13.4}
{'loss': 0.0127, 'grad_norm': 5.597837924957275, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.009905111975967884, 'loss_2': 0.002750396728515625, 'loss_3': -16.18678092956543, 'loss_4': 1.1106244325637817, 'epoch': 13.41}
{'loss': 0.0145, 'grad_norm': 5.153608798980713, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.006490056402981281, 'loss_2': 0.0080413818359375, 'loss_3': -15.994457244873047, 'loss_4': 0.8529543876647949, 'epoch': 13.41}
{'loss': 0.0228, 'grad_norm': 6.1116533279418945, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.012781494297087193, 'loss_2': 0.00998687744140625, 'loss_3': -15.850624084472656, 'loss_4': 0.6715090274810791, 'epoch': 13.42}
{'loss': 0.0309, 'grad_norm': 7.257368564605713, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.01705191843211651, 'loss_2': 0.013885498046875, 'loss_3': -15.844001770019531, 'loss_4': 0.4982016682624817, 'epoch': 13.42}
{'loss': 0.0502, 'grad_norm': 15.574881553649902, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.03513114154338837, 'loss_2': 0.01509857177734375, 'loss_3': -16.0037899017334, 'loss_4': 0.6717938780784607, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 16:15:56,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:56,570 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:09<49:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:03,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028409332036972046, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.020612331107258797, 'eval_loss_2': 0.0077970027923583984, 'eval_loss_3': -17.983102798461914, 'eval_loss_4': 0.5903908610343933, 'epoch': 13.43}
{'loss': 0.0186, 'grad_norm': 5.574455261230469, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.007963551208376884, 'loss_2': 0.01067352294921875, 'loss_3': -15.833745002746582, 'loss_4': 0.5801434516906738, 'epoch': 13.44}
{'loss': 0.0162, 'grad_norm': 5.147378921508789, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.007663043215870857, 'loss_2': 0.008575439453125, 'loss_3': -16.044017791748047, 'loss_4': 0.6418641805648804, 'epoch': 13.44}
{'loss': 0.0251, 'grad_norm': 6.145763874053955, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.013439731672406197, 'loss_2': 0.011688232421875, 'loss_3': -16.039775848388672, 'loss_4': 0.7184722423553467, 'epoch': 13.45}
{'loss': 0.0856, 'grad_norm': 17.963621139526367, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.08472862839698792, 'loss_2': 0.0008273124694824219, 'loss_3': -15.995118141174316, 'loss_4': 0.6789427995681763, 'epoch': 13.45}
{'loss': 0.018, 'grad_norm': 6.439766883850098, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.012435395270586014, 'loss_2': 0.00554656982421875, 'loss_3': -15.980283737182617, 'loss_4': 0.39089494943618774, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 16:16:03,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:03,903 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:16<49:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:11,237 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022980090230703354, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019452698528766632, 'eval_loss_2': 0.003527391701936722, 'eval_loss_3': -17.996959686279297, 'eval_loss_4': 0.2592541575431824, 'epoch': 13.46}
{'loss': 0.0152, 'grad_norm': 6.336106300354004, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.012646825052797794, 'loss_2': 0.0025463104248046875, 'loss_3': -15.99761962890625, 'loss_4': 0.5607725977897644, 'epoch': 13.47}
{'loss': 0.02, 'grad_norm': 8.202166557312012, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.014998247846961021, 'loss_2': 0.00496673583984375, 'loss_3': -15.960609436035156, 'loss_4': 0.4681215286254883, 'epoch': 13.47}
{'loss': 0.0122, 'grad_norm': 5.7161173820495605, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.00829394068568945, 'loss_2': 0.003864288330078125, 'loss_3': -15.820724487304688, 'loss_4': 0.47706514596939087, 'epoch': 13.48}
{'loss': 0.0176, 'grad_norm': 6.4093427658081055, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.009097889997065067, 'loss_2': 0.0084991455078125, 'loss_3': -16.277652740478516, 'loss_4': 0.3892320394515991, 'epoch': 13.48}
{'loss': 0.0155, 'grad_norm': 7.576799392700195, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.014926819130778313, 'loss_2': 0.0005574226379394531, 'loss_3': -16.20651626586914, 'loss_4': 0.3792366683483124, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 16:16:11,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:11,237 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:23<48:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:18,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022106479853391647, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.936, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01669910177588463, 'eval_loss_2': 0.005407378077507019, 'eval_loss_3': -17.992197036743164, 'eval_loss_4': 0.10101468861103058, 'epoch': 13.49}
{'loss': 0.0229, 'grad_norm': 7.633788108825684, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.016221879050135612, 'loss_2': 0.006679534912109375, 'loss_3': -15.842037200927734, 'loss_4': -0.1222480982542038, 'epoch': 13.49}
{'loss': 0.0127, 'grad_norm': 5.58234977722168, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.010859837755560875, 'loss_2': 0.0018329620361328125, 'loss_3': -15.87686538696289, 'loss_4': 0.45853856205940247, 'epoch': 13.5}
{'loss': 0.0078, 'grad_norm': 4.6111063957214355, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.006145308259874582, 'loss_2': 0.0016918182373046875, 'loss_3': -15.790996551513672, 'loss_4': -0.10004080832004547, 'epoch': 13.51}
{'loss': 0.0084, 'grad_norm': 5.248103141784668, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.00719556026160717, 'loss_2': 0.001155853271484375, 'loss_3': -16.028400421142578, 'loss_4': 0.0901518315076828, 'epoch': 13.51}
{'loss': 0.0159, 'grad_norm': 6.617354393005371, 'learning_rate': 1.65e-05, 'loss_1': 0.012490899302065372, 'loss_2': 0.0034046173095703125, 'loss_3': -16.001094818115234, 'loss_4': 0.36864081025123596, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 16:16:18,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:18,568 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:31<48:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:25,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01710834726691246, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014135565608739853, 'eval_loss_2': 0.0029727816581726074, 'eval_loss_3': -18.02130126953125, 'eval_loss_4': 0.036912932991981506, 'epoch': 13.52}
{'loss': 0.0096, 'grad_norm': 5.514089107513428, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.006520546972751617, 'loss_2': 0.003093719482421875, 'loss_3': -15.846219062805176, 'loss_4': 0.44952863454818726, 'epoch': 13.52}
{'loss': 0.0271, 'grad_norm': 9.089489936828613, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.01894824206829071, 'loss_2': 0.00815582275390625, 'loss_3': -15.85499382019043, 'loss_4': -0.19120396673679352, 'epoch': 13.53}
{'loss': 0.0199, 'grad_norm': 13.937585830688477, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.01687736250460148, 'loss_2': 0.0029926300048828125, 'loss_3': -16.033565521240234, 'loss_4': 0.19344013929367065, 'epoch': 13.53}
{'loss': 0.0363, 'grad_norm': 7.596169471740723, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.024470392614603043, 'loss_2': 0.0117950439453125, 'loss_3': -16.01256561279297, 'loss_4': 0.30404624342918396, 'epoch': 13.54}
{'loss': 0.041, 'grad_norm': 12.436120986938477, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.02987169474363327, 'loss_2': 0.01111602783203125, 'loss_3': -16.04765510559082, 'loss_4': 0.0005874484777450562, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 16:16:25,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:25,901 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:38<48:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:33,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019319841638207436, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.364, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014516199007630348, 'eval_loss_2': 0.004803642630577087, 'eval_loss_3': -18.016721725463867, 'eval_loss_4': 0.021755902096629143, 'epoch': 13.55}
{'loss': 0.0171, 'grad_norm': 6.506109237670898, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.008091268129646778, 'loss_2': 0.00905609130859375, 'loss_3': -15.936833381652832, 'loss_4': -0.13981308043003082, 'epoch': 13.55}
{'loss': 0.0249, 'grad_norm': 13.041138648986816, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.01820380985736847, 'loss_2': 0.00667572021484375, 'loss_3': -15.828960418701172, 'loss_4': 0.22417500615119934, 'epoch': 13.56}
{'loss': 0.0204, 'grad_norm': 8.870504379272461, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.016852833330631256, 'loss_2': 0.0035552978515625, 'loss_3': -15.932368278503418, 'loss_4': -0.14118421077728271, 'epoch': 13.56}
{'loss': 0.0265, 'grad_norm': 6.772068977355957, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.018329361453652382, 'loss_2': 0.0081939697265625, 'loss_3': -15.848560333251953, 'loss_4': 0.13036319613456726, 'epoch': 13.57}
{'loss': 0.0091, 'grad_norm': 6.685928821563721, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.0085794972255826, 'loss_2': 0.0005621910095214844, 'loss_3': -15.9869384765625, 'loss_4': -0.22880032658576965, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 16:16:33,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:33,243 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [57:45<48:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:40,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018529072403907776, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.832, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015108225867152214, 'eval_loss_2': 0.0034208446741104126, 'eval_loss_3': -18.051151275634766, 'eval_loss_4': -0.17084026336669922, 'epoch': 13.58}
{'loss': 0.0154, 'grad_norm': 5.9626569747924805, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.013895474374294281, 'loss_2': 0.0014944076538085938, 'loss_3': -16.111801147460938, 'loss_4': -0.04646909981966019, 'epoch': 13.58}
{'loss': 0.0085, 'grad_norm': 4.99795389175415, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.008226786740124226, 'loss_2': 0.0003209114074707031, 'loss_3': -16.124736785888672, 'loss_4': -0.08967067301273346, 'epoch': 13.59}
{'loss': 0.028, 'grad_norm': 12.517438888549805, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.027405966073274612, 'loss_2': 0.000545501708984375, 'loss_3': -15.96949291229248, 'loss_4': -0.5457857251167297, 'epoch': 13.59}
{'loss': 0.0207, 'grad_norm': 6.142583847045898, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.014937889762222767, 'loss_2': 0.0057220458984375, 'loss_3': -15.778815269470215, 'loss_4': -0.22574180364608765, 'epoch': 13.6}
{'loss': 0.0252, 'grad_norm': 7.753067970275879, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.019872456789016724, 'loss_2': 0.00533294677734375, 'loss_3': -16.050731658935547, 'loss_4': -0.5192570686340332, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 16:16:40,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:40,577 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [57:53<48:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:47,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020151697099208832, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015286885201931, 'eval_loss_2': 0.004864811897277832, 'eval_loss_3': -18.054523468017578, 'eval_loss_4': -0.3463124930858612, 'epoch': 13.6}
{'loss': 0.0174, 'grad_norm': 7.456849575042725, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.014014753513038158, 'loss_2': 0.003376007080078125, 'loss_3': -16.066179275512695, 'loss_4': -0.300437331199646, 'epoch': 13.61}
{'loss': 0.0176, 'grad_norm': 6.378867149353027, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.014001777395606041, 'loss_2': 0.003597259521484375, 'loss_3': -16.153549194335938, 'loss_4': 0.2650223970413208, 'epoch': 13.62}
{'loss': 0.045, 'grad_norm': 18.67562484741211, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.043107785284519196, 'loss_2': 0.0019102096557617188, 'loss_3': -15.92335319519043, 'loss_4': -0.18563643097877502, 'epoch': 13.62}
{'loss': 0.013, 'grad_norm': 5.129345417022705, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.012143593281507492, 'loss_2': 0.0008597373962402344, 'loss_3': -16.288009643554688, 'loss_4': -0.45867255330085754, 'epoch': 13.63}
{'loss': 0.0364, 'grad_norm': 17.104860305786133, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.029552968218922615, 'loss_2': 0.00681304931640625, 'loss_3': -15.945478439331055, 'loss_4': -0.2518889605998993, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 16:16:47,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:47,909 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:00<48:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:55,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016554169356822968, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.92, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013331941328942776, 'eval_loss_2': 0.003222227096557617, 'eval_loss_3': -18.101951599121094, 'eval_loss_4': -0.3687065839767456, 'epoch': 13.63}
{'loss': 0.0118, 'grad_norm': 5.385375022888184, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.005277625750750303, 'loss_2': 0.0065155029296875, 'loss_3': -16.038238525390625, 'loss_4': -0.04792231321334839, 'epoch': 13.64}
{'loss': 0.0232, 'grad_norm': 11.14810848236084, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.02093731053173542, 'loss_2': 0.0022411346435546875, 'loss_3': -15.895830154418945, 'loss_4': -0.40096497535705566, 'epoch': 13.65}
{'loss': 0.0166, 'grad_norm': 6.629270553588867, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.010386607609689236, 'loss_2': 0.006237030029296875, 'loss_3': -15.960418701171875, 'loss_4': 0.22144602239131927, 'epoch': 13.65}
{'loss': 0.0142, 'grad_norm': 5.959634304046631, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.011165649630129337, 'loss_2': 0.00302886962890625, 'loss_3': -16.230337142944336, 'loss_4': -0.2809525728225708, 'epoch': 13.66}
{'loss': 0.0327, 'grad_norm': 15.831432342529297, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.027177564799785614, 'loss_2': 0.0054931640625, 'loss_3': -16.076934814453125, 'loss_4': -0.41023582220077515, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 16:16:55,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:55,243 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:07<48:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:02,579 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017422273755073547, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.832, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014152511954307556, 'eval_loss_2': 0.003269761800765991, 'eval_loss_3': -18.081478118896484, 'eval_loss_4': -0.24075226485729218, 'epoch': 13.66}
{'loss': 0.018, 'grad_norm': 6.509657382965088, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.011555595323443413, 'loss_2': 0.0064697265625, 'loss_3': -16.10255241394043, 'loss_4': -0.2416510432958603, 'epoch': 13.67}
{'loss': 0.0164, 'grad_norm': 5.805641174316406, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.00876869261264801, 'loss_2': 0.007587432861328125, 'loss_3': -16.07657814025879, 'loss_4': -0.4390260875225067, 'epoch': 13.67}
{'loss': 0.0213, 'grad_norm': 7.960528373718262, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.014181583188474178, 'loss_2': 0.007110595703125, 'loss_3': -15.856189727783203, 'loss_4': -0.05605614557862282, 'epoch': 13.68}
{'loss': 0.0173, 'grad_norm': 7.362940788269043, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.015563682653009892, 'loss_2': 0.0017385482788085938, 'loss_3': -16.11410140991211, 'loss_4': -0.08735394477844238, 'epoch': 13.69}
{'loss': 0.0144, 'grad_norm': 6.812689781188965, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.013477243483066559, 'loss_2': 0.000957489013671875, 'loss_3': -15.845869064331055, 'loss_4': -0.0226307213306427, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 16:17:02,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:02,579 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:15<48:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:09,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017998898401856422, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.214, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01527010090649128, 'eval_loss_2': 0.002728797495365143, 'eval_loss_3': -18.09688949584961, 'eval_loss_4': -0.0794614851474762, 'epoch': 13.69}
{'loss': 0.052, 'grad_norm': 26.456043243408203, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.05113762244582176, 'loss_2': 0.0009002685546875, 'loss_3': -15.996137619018555, 'loss_4': 0.3257293403148651, 'epoch': 13.7}
{'loss': 0.0166, 'grad_norm': 8.108214378356934, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.01651844196021557, 'loss_2': 3.647804260253906e-05, 'loss_3': -15.81953239440918, 'loss_4': -0.18437322974205017, 'epoch': 13.7}
{'loss': 0.0112, 'grad_norm': 5.465729236602783, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.008641395717859268, 'loss_2': 0.002529144287109375, 'loss_3': -16.174915313720703, 'loss_4': -0.20012424886226654, 'epoch': 13.71}
{'loss': 0.0298, 'grad_norm': 8.171630859375, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.02319628745317459, 'loss_2': 0.006622314453125, 'loss_3': -16.220766067504883, 'loss_4': 0.0748363733291626, 'epoch': 13.72}
{'loss': 0.0166, 'grad_norm': 6.231635093688965, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.013545266352593899, 'loss_2': 0.0030117034912109375, 'loss_3': -16.31311798095703, 'loss_4': 0.16770799458026886, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 16:17:09,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:09,927 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:22<48:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:17,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02044060453772545, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017008954659104347, 'eval_loss_2': 0.003431648015975952, 'eval_loss_3': -18.08197593688965, 'eval_loss_4': -0.11601854860782623, 'epoch': 13.72}
{'loss': 0.0151, 'grad_norm': 8.362184524536133, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.013628280721604824, 'loss_2': 0.0014972686767578125, 'loss_3': -15.998871803283691, 'loss_4': -0.2515281140804291, 'epoch': 13.73}
{'loss': 0.019, 'grad_norm': 4.824928283691406, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.005882635712623596, 'loss_2': 0.013092041015625, 'loss_3': -16.112199783325195, 'loss_4': -0.04627057909965515, 'epoch': 13.73}
{'loss': 0.2313, 'grad_norm': 19.529775619506836, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.23119619488716125, 'loss_2': 0.00015103816986083984, 'loss_3': -16.231937408447266, 'loss_4': 0.2947796881198883, 'epoch': 13.74}
{'loss': 0.0186, 'grad_norm': 9.86320686340332, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.014918769709765911, 'loss_2': 0.0036468505859375, 'loss_3': -16.054664611816406, 'loss_4': -0.11339925974607468, 'epoch': 13.74}
{'loss': 0.0301, 'grad_norm': 24.724031448364258, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.02793274261057377, 'loss_2': 0.002178192138671875, 'loss_3': -16.003833770751953, 'loss_4': 0.08508557826280594, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 16:17:17,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:17,277 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:30<48:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:24,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02003699168562889, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.968, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016084013506770134, 'eval_loss_2': 0.003952976316213608, 'eval_loss_3': -18.129140853881836, 'eval_loss_4': -0.0780441090464592, 'epoch': 13.75}
{'loss': 0.0113, 'grad_norm': 6.012276649475098, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.009129131212830544, 'loss_2': 0.0021762847900390625, 'loss_3': -16.116634368896484, 'loss_4': -0.30070626735687256, 'epoch': 13.76}
{'loss': 0.046, 'grad_norm': 21.855010986328125, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.04572201892733574, 'loss_2': 0.00023066997528076172, 'loss_3': -16.019380569458008, 'loss_4': -0.048700764775276184, 'epoch': 13.76}
{'loss': 0.0099, 'grad_norm': 6.049498558044434, 'learning_rate': 1.625e-05, 'loss_1': 0.00861852616071701, 'loss_2': 0.0012607574462890625, 'loss_3': -16.028249740600586, 'loss_4': 0.3296296000480652, 'epoch': 13.77}
{'loss': 0.08, 'grad_norm': 17.484636306762695, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.07397374510765076, 'loss_2': 0.0060577392578125, 'loss_3': -16.094600677490234, 'loss_4': 0.46253252029418945, 'epoch': 13.77}
{'loss': 0.0194, 'grad_norm': 6.980600833892822, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.014003905467689037, 'loss_2': 0.00537109375, 'loss_3': -16.27170181274414, 'loss_4': -0.04377985745668411, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 16:17:24,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:24,618 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:37<48:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:31,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015453575178980827, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.83, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012093604542315006, 'eval_loss_2': 0.003359973430633545, 'eval_loss_3': -18.180784225463867, 'eval_loss_4': 0.29940539598464966, 'epoch': 13.78}
{'loss': 0.0285, 'grad_norm': 7.728475093841553, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.021498829126358032, 'loss_2': 0.00696563720703125, 'loss_3': -16.162893295288086, 'loss_4': 0.15356852114200592, 'epoch': 13.78}
{'loss': 0.0203, 'grad_norm': 7.426629543304443, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.01663907617330551, 'loss_2': 0.0036468505859375, 'loss_3': -15.969053268432617, 'loss_4': 0.6223371028900146, 'epoch': 13.79}
{'loss': 0.0088, 'grad_norm': 5.345712184906006, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.008685260079801083, 'loss_2': 0.00013196468353271484, 'loss_3': -16.120309829711914, 'loss_4': 0.36534059047698975, 'epoch': 13.8}
{'loss': 0.0109, 'grad_norm': 5.289335250854492, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.0076700481586158276, 'loss_2': 0.003276824951171875, 'loss_3': -16.10508155822754, 'loss_4': 0.4701102674007416, 'epoch': 13.8}
{'loss': 0.01, 'grad_norm': 4.782940864562988, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.007934260182082653, 'loss_2': 0.0021038055419921875, 'loss_3': -16.312660217285156, 'loss_4': 0.32717782258987427, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 16:17:31,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:31,955 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [58:44<48:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:39,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013559684157371521, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.859, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011049403809010983, 'eval_loss_2': 0.002510279417037964, 'eval_loss_3': -18.164413452148438, 'eval_loss_4': 0.6324471235275269, 'epoch': 13.81}
{'loss': 0.0196, 'grad_norm': 7.455689907073975, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.017460765317082405, 'loss_2': 0.002147674560546875, 'loss_3': -16.019481658935547, 'loss_4': 0.7483456134796143, 'epoch': 13.81}
{'loss': 0.0236, 'grad_norm': 6.646409034729004, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.01882980577647686, 'loss_2': 0.004756927490234375, 'loss_3': -16.313568115234375, 'loss_4': 0.9361951947212219, 'epoch': 13.82}
{'loss': 0.0235, 'grad_norm': 6.8046345710754395, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.016383031383156776, 'loss_2': 0.007129669189453125, 'loss_3': -16.022491455078125, 'loss_4': 0.5983339548110962, 'epoch': 13.83}
{'loss': 0.0281, 'grad_norm': 9.431084632873535, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.020949436351656914, 'loss_2': 0.00713348388671875, 'loss_3': -15.89254379272461, 'loss_4': 0.5572715997695923, 'epoch': 13.83}
{'loss': 0.0281, 'grad_norm': 8.593506813049316, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.015722980722784996, 'loss_2': 0.01233673095703125, 'loss_3': -16.000452041625977, 'loss_4': 0.9522815346717834, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 16:17:39,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:39,298 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [58:52<48:41,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:17:46,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014200491830706596, 'eval_runtime': 3.9943, 'eval_samples_per_second': 256.364, 'eval_steps_per_second': 4.006, 'eval_loss_1': 0.010723976418375969, 'eval_loss_2': 0.0034765154123306274, 'eval_loss_3': -18.153234481811523, 'eval_loss_4': 0.8684643507003784, 'epoch': 13.84}
{'loss': 0.0121, 'grad_norm': 4.765066146850586, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.009580378420650959, 'loss_2': 0.00254058837890625, 'loss_3': -16.080312728881836, 'loss_4': 0.6811400651931763, 'epoch': 13.84}
{'loss': 0.014, 'grad_norm': 7.604002475738525, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.011305342428386211, 'loss_2': 0.002696990966796875, 'loss_3': -16.187366485595703, 'loss_4': 1.1529502868652344, 'epoch': 13.85}
{'loss': 0.0217, 'grad_norm': 8.574216842651367, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.02065069042146206, 'loss_2': 0.00102996826171875, 'loss_3': -16.043498992919922, 'loss_4': 0.7460505962371826, 'epoch': 13.85}
{'loss': 0.0194, 'grad_norm': 8.255875587463379, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.018222637474536896, 'loss_2': 0.001209259033203125, 'loss_3': -16.01046371459961, 'loss_4': 1.51517653465271, 'epoch': 13.86}
{'loss': 0.0206, 'grad_norm': 6.46405553817749, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.0162228774279356, 'loss_2': 0.004383087158203125, 'loss_3': -15.997367858886719, 'loss_4': 0.9803369045257568, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 16:17:46,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:46,843 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [58:59<48:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:54,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01645520329475403, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.258, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011031003668904305, 'eval_loss_2': 0.005424201488494873, 'eval_loss_3': -18.1645565032959, 'eval_loss_4': 0.9668078422546387, 'epoch': 13.87}
{'loss': 0.0264, 'grad_norm': 7.937733173370361, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.019902128726243973, 'loss_2': 0.006458282470703125, 'loss_3': -16.071046829223633, 'loss_4': 0.7338630557060242, 'epoch': 13.87}
{'loss': 0.0606, 'grad_norm': 21.162494659423828, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.05083188787102699, 'loss_2': 0.0097503662109375, 'loss_3': -16.124164581298828, 'loss_4': 1.0268135070800781, 'epoch': 13.88}
{'loss': 0.012, 'grad_norm': 6.393991470336914, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.009303185157477856, 'loss_2': 0.00274658203125, 'loss_3': -16.129262924194336, 'loss_4': 1.3366849422454834, 'epoch': 13.88}
{'loss': 0.0067, 'grad_norm': 4.678887367248535, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.006167102139443159, 'loss_2': 0.0005440711975097656, 'loss_3': -16.250999450683594, 'loss_4': 0.907371997833252, 'epoch': 13.89}
{'loss': 0.0154, 'grad_norm': 7.158745288848877, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.011217198334634304, 'loss_2': 0.0041656494140625, 'loss_3': -16.155704498291016, 'loss_4': 1.353479266166687, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 16:17:54,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:54,186 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:06<47:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:01,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014002474024891853, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011247188784182072, 'eval_loss_2': 0.002755284309387207, 'eval_loss_3': -18.156639099121094, 'eval_loss_4': 0.9205908179283142, 'epoch': 13.9}
{'loss': 0.0214, 'grad_norm': 8.655936241149902, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.017897168174386024, 'loss_2': 0.0034942626953125, 'loss_3': -15.82359504699707, 'loss_4': 0.8673170804977417, 'epoch': 13.9}
{'loss': 0.0154, 'grad_norm': 5.133492469787598, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.010740794241428375, 'loss_2': 0.0046539306640625, 'loss_3': -16.290075302124023, 'loss_4': 1.1545650959014893, 'epoch': 13.91}
{'loss': 0.0072, 'grad_norm': 4.6905107498168945, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.006339984945952892, 'loss_2': 0.0009050369262695312, 'loss_3': -16.115421295166016, 'loss_4': 0.9663047790527344, 'epoch': 13.91}
{'loss': 0.0431, 'grad_norm': 17.022327423095703, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.0395657904446125, 'loss_2': 0.00354766845703125, 'loss_3': -16.097333908081055, 'loss_4': 1.122196912765503, 'epoch': 13.92}
{'loss': 0.0236, 'grad_norm': 6.186427593231201, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.014242352917790413, 'loss_2': 0.00933074951171875, 'loss_3': -15.973724365234375, 'loss_4': 0.7626377940177917, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 16:18:01,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:01,527 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:14<47:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:08,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014813742600381374, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011624409817159176, 'eval_loss_2': 0.0031893327832221985, 'eval_loss_3': -18.134830474853516, 'eval_loss_4': 0.8601281642913818, 'epoch': 13.92}
{'loss': 0.0145, 'grad_norm': 6.267877101898193, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.011561516672372818, 'loss_2': 0.0029468536376953125, 'loss_3': -16.121845245361328, 'loss_4': 0.8007333278656006, 'epoch': 13.93}
{'loss': 0.0139, 'grad_norm': 4.767637252807617, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.01097461674362421, 'loss_2': 0.002902984619140625, 'loss_3': -16.12621307373047, 'loss_4': 0.8461354970932007, 'epoch': 13.94}
{'loss': 0.0197, 'grad_norm': 6.1293134689331055, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.01715567521750927, 'loss_2': 0.00252532958984375, 'loss_3': -15.982261657714844, 'loss_4': 0.527632474899292, 'epoch': 13.94}
{'loss': 0.0078, 'grad_norm': 4.464937686920166, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.005363974254578352, 'loss_2': 0.002460479736328125, 'loss_3': -16.178173065185547, 'loss_4': 0.969666063785553, 'epoch': 13.95}
{'loss': 0.0117, 'grad_norm': 5.59777307510376, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.009861770085990429, 'loss_2': 0.0017986297607421875, 'loss_3': -16.29497528076172, 'loss_4': 0.9670005440711975, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 16:18:08,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:08,873 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:21<47:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:16,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013764800503849983, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.83, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01143651269376278, 'eval_loss_2': 0.002328287810087204, 'eval_loss_3': -18.095483779907227, 'eval_loss_4': 0.7496505975723267, 'epoch': 13.95}
{'loss': 0.0141, 'grad_norm': 6.594494819641113, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.013599648140370846, 'loss_2': 0.00047206878662109375, 'loss_3': -16.048418045043945, 'loss_4': 0.6644233465194702, 'epoch': 13.96}
{'loss': 0.0136, 'grad_norm': 4.921153545379639, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.005019811447709799, 'loss_2': 0.00853729248046875, 'loss_3': -16.15018081665039, 'loss_4': 0.7196967601776123, 'epoch': 13.97}
{'loss': 0.0172, 'grad_norm': 6.693923473358154, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.012798694893717766, 'loss_2': 0.00438690185546875, 'loss_3': -15.89072322845459, 'loss_4': 0.27421045303344727, 'epoch': 13.97}
{'loss': 0.0305, 'grad_norm': 17.189369201660156, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.02855999954044819, 'loss_2': 0.0019092559814453125, 'loss_3': -16.184619903564453, 'loss_4': 0.7622186541557312, 'epoch': 13.98}
{'loss': 0.0207, 'grad_norm': 8.888140678405762, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.018132397904992104, 'loss_2': 0.002521514892578125, 'loss_3': -16.09952163696289, 'loss_4': 0.4576481282711029, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 16:18:16,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:16,214 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:28<45:37,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 16:18:23,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01452413760125637, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.899, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011546499095857143, 'eval_loss_2': 0.0029776394367218018, 'eval_loss_3': -18.083208084106445, 'eval_loss_4': 0.6060025095939636, 'epoch': 13.98}
{'loss': 0.022, 'grad_norm': 6.546063423156738, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.01330149918794632, 'loss_2': 0.008697509765625, 'loss_3': -15.902451515197754, 'loss_4': 0.27399447560310364, 'epoch': 13.99}
{'loss': 0.0201, 'grad_norm': 7.037632942199707, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.01846589893102646, 'loss_2': 0.0016345977783203125, 'loss_3': -16.245769500732422, 'loss_4': 1.045615315437317, 'epoch': 13.99}
{'loss': 0.0062, 'grad_norm': 6.1640849113464355, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.0046886722557246685, 'loss_2': 0.0014848709106445312, 'loss_3': -16.065046310424805, 'loss_4': 0.6015878915786743, 'epoch': 14.0}
{'loss': 0.0099, 'grad_norm': 5.325961112976074, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.008578953333199024, 'loss_2': 0.0013484954833984375, 'loss_3': -16.092876434326172, 'loss_4': 0.7893858551979065, 'epoch': 14.01}
{'loss': 0.0225, 'grad_norm': 9.337038040161133, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.020546240732073784, 'loss_2': 0.001964569091796875, 'loss_3': -16.259119033813477, 'loss_4': 0.9103479385375977, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 16:18:23,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:23,245 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:36<47:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:18:30,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015455818735063076, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.501, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012420451268553734, 'eval_loss_2': 0.0030353665351867676, 'eval_loss_3': -18.103904724121094, 'eval_loss_4': 0.6076540946960449, 'epoch': 14.01}
{'loss': 0.015, 'grad_norm': 7.158557415008545, 'learning_rate': 1.6e-05, 'loss_1': 0.012182319536805153, 'loss_2': 0.00279998779296875, 'loss_3': -15.884318351745605, 'loss_4': 0.5861319899559021, 'epoch': 14.02}
{'loss': 0.0109, 'grad_norm': 5.579606056213379, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.01023110095411539, 'loss_2': 0.0006818771362304688, 'loss_3': -16.072126388549805, 'loss_4': 1.059529423713684, 'epoch': 14.02}
{'loss': 0.0104, 'grad_norm': 5.806006908416748, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.009763908572494984, 'loss_2': 0.0006275177001953125, 'loss_3': -16.086084365844727, 'loss_4': 0.7848595380783081, 'epoch': 14.03}
{'loss': 0.0306, 'grad_norm': 16.766706466674805, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.024954695254564285, 'loss_2': 0.0056610107421875, 'loss_3': -16.074295043945312, 'loss_4': 0.6959736943244934, 'epoch': 14.03}
{'loss': 0.0245, 'grad_norm': 11.473153114318848, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.02309429459273815, 'loss_2': 0.00138092041015625, 'loss_3': -16.047470092773438, 'loss_4': 0.7370752096176147, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 16:18:30,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:30,586 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:43<47:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:37,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01727638579905033, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01353482436388731, 'eval_loss_2': 0.0037415623664855957, 'eval_loss_3': -18.137676239013672, 'eval_loss_4': 0.5645143389701843, 'epoch': 14.04}
{'loss': 0.018, 'grad_norm': 6.605551719665527, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.011458792723715305, 'loss_2': 0.006565093994140625, 'loss_3': -16.106290817260742, 'loss_4': 0.48345738649368286, 'epoch': 14.05}
{'loss': 0.0254, 'grad_norm': 6.046892166137695, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.01714092679321766, 'loss_2': 0.00823974609375, 'loss_3': -16.3575382232666, 'loss_4': 0.25898420810699463, 'epoch': 14.05}
{'loss': 0.013, 'grad_norm': 6.780148029327393, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.011682840995490551, 'loss_2': 0.0012969970703125, 'loss_3': -16.11264419555664, 'loss_4': 0.6845214366912842, 'epoch': 14.06}
{'loss': 0.0106, 'grad_norm': 5.426539421081543, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.009635563008487225, 'loss_2': 0.0009183883666992188, 'loss_3': -16.049776077270508, 'loss_4': 0.43940794467926025, 'epoch': 14.06}
{'loss': 0.0152, 'grad_norm': 6.162564277648926, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.013222252950072289, 'loss_2': 0.001953125, 'loss_3': -16.051769256591797, 'loss_4': 0.5637972354888916, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 16:18:37,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:37,923 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 2425/5160 [59:50<47:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:45,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018577564507722855, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015587386675179005, 'eval_loss_2': 0.0029901787638664246, 'eval_loss_3': -18.141386032104492, 'eval_loss_4': 0.508168637752533, 'epoch': 14.07}
{'loss': 0.017, 'grad_norm': 5.810696601867676, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.016288645565509796, 'loss_2': 0.000705718994140625, 'loss_3': -16.055404663085938, 'loss_4': 0.03946777433156967, 'epoch': 14.08}
{'loss': 0.0196, 'grad_norm': 6.406870365142822, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.016044506803154945, 'loss_2': 0.003566741943359375, 'loss_3': -16.237424850463867, 'loss_4': 0.576317548751831, 'epoch': 14.08}
{'loss': 0.0231, 'grad_norm': 9.7886962890625, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.01901989057660103, 'loss_2': 0.0040740966796875, 'loss_3': -15.93592643737793, 'loss_4': 0.4195256233215332, 'epoch': 14.09}
{'loss': 0.0292, 'grad_norm': 8.486334800720215, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.02213480696082115, 'loss_2': 0.007049560546875, 'loss_3': -16.163732528686523, 'loss_4': 0.41442930698394775, 'epoch': 14.09}
{'loss': 0.0109, 'grad_norm': 4.881743431091309, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.006414772477000952, 'loss_2': 0.00452423095703125, 'loss_3': -16.22927474975586, 'loss_4': 0.3027048707008362, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 16:18:45,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:45,270 >>   Batch size = 64
 47%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                     | 2430/5160 [59:58<47:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:52,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02187640778720379, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.913, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017367612570524216, 'eval_loss_2': 0.004508793354034424, 'eval_loss_3': -18.14346694946289, 'eval_loss_4': 0.4128338098526001, 'epoch': 14.1}
{'loss': 0.0543, 'grad_norm': 14.570043563842773, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.05027109012007713, 'loss_2': 0.004016876220703125, 'loss_3': -16.26969337463379, 'loss_4': 0.06592674553394318, 'epoch': 14.1}
{'loss': 0.0277, 'grad_norm': 9.957338333129883, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.023323411121964455, 'loss_2': 0.00440216064453125, 'loss_3': -16.125343322753906, 'loss_4': 0.19332078099250793, 'epoch': 14.11}
{'loss': 0.0107, 'grad_norm': 5.83134651184082, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.009384118020534515, 'loss_2': 0.0013179779052734375, 'loss_3': -16.28964614868164, 'loss_4': 0.6823310256004333, 'epoch': 14.12}
{'loss': 0.0186, 'grad_norm': 9.430916786193848, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.017373010516166687, 'loss_2': 0.0012378692626953125, 'loss_3': -16.18565559387207, 'loss_4': 0.2529386878013611, 'epoch': 14.12}
{'loss': 0.0214, 'grad_norm': 6.971468448638916, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.019566375762224197, 'loss_2': 0.0017871856689453125, 'loss_3': -16.247804641723633, 'loss_4': 0.4315059781074524, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 16:18:52,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:52,601 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:05<47:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:59,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021347874775528908, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.673, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.018467510119080544, 'eval_loss_2': 0.0028803646564483643, 'eval_loss_3': -18.13224983215332, 'eval_loss_4': 0.25329533219337463, 'epoch': 14.13}
{'loss': 0.026, 'grad_norm': 9.69177532196045, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.017435651272535324, 'loss_2': 0.00856781005859375, 'loss_3': -16.15146255493164, 'loss_4': 0.10660050809383392, 'epoch': 14.13}
{'loss': 0.0133, 'grad_norm': 6.620501518249512, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.012787429615855217, 'loss_2': 0.00054931640625, 'loss_3': -16.291807174682617, 'loss_4': 0.16385303437709808, 'epoch': 14.14}
{'loss': 0.0171, 'grad_norm': 6.784374713897705, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.0166468545794487, 'loss_2': 0.0004329681396484375, 'loss_3': -16.126840591430664, 'loss_4': 0.38773179054260254, 'epoch': 14.15}
{'loss': 0.0294, 'grad_norm': 8.081354141235352, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.022970162332057953, 'loss_2': 0.0064544677734375, 'loss_3': -16.11238670349121, 'loss_4': 0.4768041968345642, 'epoch': 14.15}
{'loss': 0.0116, 'grad_norm': 4.856348514556885, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.009311847388744354, 'loss_2': 0.002262115478515625, 'loss_3': -16.163911819458008, 'loss_4': 0.04864565283060074, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 16:18:59,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:59,934 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:12<47:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:07,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021037515252828598, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.69, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01841655559837818, 'eval_loss_2': 0.0026209577918052673, 'eval_loss_3': -18.109006881713867, 'eval_loss_4': 0.0024394914507865906, 'epoch': 14.16}
{'loss': 0.0105, 'grad_norm': 5.55018424987793, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.009755769744515419, 'loss_2': 0.0007805824279785156, 'loss_3': -16.15951919555664, 'loss_4': -0.10939168930053711, 'epoch': 14.16}
{'loss': 0.0281, 'grad_norm': 10.333303451538086, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.027246709913015366, 'loss_2': 0.0008363723754882812, 'loss_3': -16.249984741210938, 'loss_4': -0.058273836970329285, 'epoch': 14.17}
{'loss': 0.0324, 'grad_norm': 14.348185539245605, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.02901318483054638, 'loss_2': 0.003345489501953125, 'loss_3': -16.32767105102539, 'loss_4': -0.422837495803833, 'epoch': 14.17}
{'loss': 0.0119, 'grad_norm': 5.362023830413818, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.011015468277037144, 'loss_2': 0.0009164810180664062, 'loss_3': -16.111663818359375, 'loss_4': -0.06453333795070648, 'epoch': 14.18}
{'loss': 0.0152, 'grad_norm': 5.542792797088623, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.010122374631464481, 'loss_2': 0.005092620849609375, 'loss_3': -15.987642288208008, 'loss_4': -0.18442751467227936, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 16:19:07,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:07,276 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:20<46:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:14,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022827571257948875, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.020000144839286804, 'eval_loss_2': 0.0028274282813072205, 'eval_loss_3': -18.065753936767578, 'eval_loss_4': -0.2029634416103363, 'epoch': 14.19}
{'loss': 0.0212, 'grad_norm': 5.849790573120117, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.017706600949168205, 'loss_2': 0.0034637451171875, 'loss_3': -16.278057098388672, 'loss_4': -0.15640267729759216, 'epoch': 14.19}
{'loss': 0.0152, 'grad_norm': 7.636838436126709, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.014088858850300312, 'loss_2': 0.0011043548583984375, 'loss_3': -16.207195281982422, 'loss_4': -0.3868906795978546, 'epoch': 14.2}
{'loss': 0.0103, 'grad_norm': 5.551015377044678, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.009605531580746174, 'loss_2': 0.0006952285766601562, 'loss_3': -16.22240447998047, 'loss_4': 0.37077197432518005, 'epoch': 14.2}
{'loss': 0.0171, 'grad_norm': 7.783056735992432, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.016929566860198975, 'loss_2': 0.00012612342834472656, 'loss_3': -16.108978271484375, 'loss_4': -0.5545815229415894, 'epoch': 14.21}
{'loss': 0.0161, 'grad_norm': 6.341125011444092, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.011938083916902542, 'loss_2': 0.0041961669921875, 'loss_3': -16.03356170654297, 'loss_4': -0.14906743168830872, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 16:19:14,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:14,620 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:27<46:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:21,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024893492460250854, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.856, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019059985876083374, 'eval_loss_2': 0.0058335065841674805, 'eval_loss_3': -18.106830596923828, 'eval_loss_4': -0.2939208149909973, 'epoch': 14.22}
{'loss': 0.023, 'grad_norm': 6.268103122711182, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.014127157628536224, 'loss_2': 0.00887298583984375, 'loss_3': -16.253459930419922, 'loss_4': -0.32033491134643555, 'epoch': 14.22}
{'loss': 0.027, 'grad_norm': 10.322887420654297, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.021410055458545685, 'loss_2': 0.0056304931640625, 'loss_3': -16.229543685913086, 'loss_4': -0.039043132215738297, 'epoch': 14.23}
{'loss': 0.0682, 'grad_norm': 31.126720428466797, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.06306593120098114, 'loss_2': 0.005146026611328125, 'loss_3': -16.086488723754883, 'loss_4': -0.41799768805503845, 'epoch': 14.23}
{'loss': 0.0198, 'grad_norm': 8.195874214172363, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.01714576780796051, 'loss_2': 0.0026397705078125, 'loss_3': -16.195446014404297, 'loss_4': 0.07276488840579987, 'epoch': 14.24}
{'loss': 0.0893, 'grad_norm': 18.62244987487793, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.08220183849334717, 'loss_2': 0.00707244873046875, 'loss_3': -16.536291122436523, 'loss_4': 0.27039143443107605, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 16:19:21,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:21,956 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:34<46:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:29,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023387007415294647, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.872, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018020421266555786, 'eval_loss_2': 0.0053665898740291595, 'eval_loss_3': -18.096494674682617, 'eval_loss_4': -0.32343414425849915, 'epoch': 14.24}
{'loss': 0.0207, 'grad_norm': 9.549534797668457, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.01746337115764618, 'loss_2': 0.003269195556640625, 'loss_3': -16.11909294128418, 'loss_4': -0.3887232542037964, 'epoch': 14.25}
{'loss': 0.0113, 'grad_norm': 6.044152736663818, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.009922024793922901, 'loss_2': 0.0013294219970703125, 'loss_3': -16.197265625, 'loss_4': -0.1332208812236786, 'epoch': 14.26}
{'loss': 0.0231, 'grad_norm': 8.214807510375977, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.02172131836414337, 'loss_2': 0.0013322830200195312, 'loss_3': -16.172555923461914, 'loss_4': 0.15206782519817352, 'epoch': 14.26}
{'loss': 0.0134, 'grad_norm': 5.026345252990723, 'learning_rate': 1.575e-05, 'loss_1': 0.007937046699225903, 'loss_2': 0.00542449951171875, 'loss_3': -16.05653953552246, 'loss_4': -0.2096981704235077, 'epoch': 14.27}
{'loss': 0.0097, 'grad_norm': 5.950761795043945, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.007225979585200548, 'loss_2': 0.0024280548095703125, 'loss_3': -16.14261817932129, 'loss_4': -0.017424121499061584, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 16:19:29,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:29,289 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:42<46:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:36,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021448783576488495, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.796, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019149670377373695, 'eval_loss_2': 0.0022991113364696503, 'eval_loss_3': -18.090229034423828, 'eval_loss_4': -0.25747692584991455, 'epoch': 14.27}
{'loss': 0.0185, 'grad_norm': 5.428981304168701, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.007594388443976641, 'loss_2': 0.01092529296875, 'loss_3': -16.19780158996582, 'loss_4': -0.2991885542869568, 'epoch': 14.28}
{'loss': 0.0311, 'grad_norm': 7.211319446563721, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.021550150588154793, 'loss_2': 0.009521484375, 'loss_3': -16.350784301757812, 'loss_4': -0.2685900032520294, 'epoch': 14.28}
{'loss': 0.0079, 'grad_norm': 4.97255277633667, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.007348215207457542, 'loss_2': 0.00054931640625, 'loss_3': -16.103620529174805, 'loss_4': 0.009306788444519043, 'epoch': 14.29}
{'loss': 0.0199, 'grad_norm': 7.1871771812438965, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.014581154100596905, 'loss_2': 0.00534820556640625, 'loss_3': -16.055328369140625, 'loss_4': -0.1675848364830017, 'epoch': 14.3}
{'loss': 0.0291, 'grad_norm': 9.904486656188965, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.018472468480467796, 'loss_2': 0.01067352294921875, 'loss_3': -16.196582794189453, 'loss_4': -0.3148248493671417, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 16:19:36,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:36,626 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:00:49<46:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:43,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024513373151421547, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.751, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018426427617669106, 'eval_loss_2': 0.006086945533752441, 'eval_loss_3': -18.115930557250977, 'eval_loss_4': -0.11436179280281067, 'epoch': 14.3}
{'loss': 0.0526, 'grad_norm': 10.6312255859375, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.04491007700562477, 'loss_2': 0.007663726806640625, 'loss_3': -16.282203674316406, 'loss_4': 0.05440276861190796, 'epoch': 14.31}
{'loss': 0.0187, 'grad_norm': 5.738931655883789, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.013951952569186687, 'loss_2': 0.00472259521484375, 'loss_3': -16.38511085510254, 'loss_4': 0.2167736142873764, 'epoch': 14.31}
{'loss': 0.0102, 'grad_norm': 5.548842430114746, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.006170301698148251, 'loss_2': 0.0039825439453125, 'loss_3': -16.369298934936523, 'loss_4': -0.014307834208011627, 'epoch': 14.32}
{'loss': 0.0223, 'grad_norm': 7.126171112060547, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.014957933686673641, 'loss_2': 0.00736236572265625, 'loss_3': -16.228607177734375, 'loss_4': -0.22320689260959625, 'epoch': 14.33}
{'loss': 0.0193, 'grad_norm': 6.8168840408325195, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.01639297790825367, 'loss_2': 0.00295257568359375, 'loss_3': -15.941102981567383, 'loss_4': -0.11041799932718277, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 16:19:43,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:43,964 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:00:56<46:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:51,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0201166570186615, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.209, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016566606238484383, 'eval_loss_2': 0.0035500526428222656, 'eval_loss_3': -18.1480770111084, 'eval_loss_4': 0.0120669174939394, 'epoch': 14.33}
{'loss': 0.0116, 'grad_norm': 5.471829891204834, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.008723204024136066, 'loss_2': 0.002918243408203125, 'loss_3': -16.193859100341797, 'loss_4': -0.05090134218335152, 'epoch': 14.34}
{'loss': 0.0215, 'grad_norm': 6.320110321044922, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.014147085137665272, 'loss_2': 0.00737762451171875, 'loss_3': -16.222667694091797, 'loss_4': 0.09853088855743408, 'epoch': 14.34}
{'loss': 0.0159, 'grad_norm': 6.3135223388671875, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.0148153156042099, 'loss_2': 0.001129150390625, 'loss_3': -16.195972442626953, 'loss_4': 0.22951914370059967, 'epoch': 14.35}
{'loss': 0.0102, 'grad_norm': 6.388473987579346, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.007628253661096096, 'loss_2': 0.0025482177734375, 'loss_3': -15.85104751586914, 'loss_4': -0.1924215853214264, 'epoch': 14.35}
{'loss': 0.0099, 'grad_norm': 5.775668144226074, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.009260023944079876, 'loss_2': 0.0006413459777832031, 'loss_3': -16.08487319946289, 'loss_4': 0.1516943871974945, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 16:19:51,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:51,310 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:04<46:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:58,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0218349602073431, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.906, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016716187819838524, 'eval_loss_2': 0.005118772387504578, 'eval_loss_3': -18.134798049926758, 'eval_loss_4': 0.04153028130531311, 'epoch': 14.36}
{'loss': 0.0218, 'grad_norm': 5.961891174316406, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.009720254689455032, 'loss_2': 0.0120391845703125, 'loss_3': -16.082548141479492, 'loss_4': 0.21335886418819427, 'epoch': 14.37}
{'loss': 0.0091, 'grad_norm': 5.118155002593994, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.006411376409232616, 'loss_2': 0.002735137939453125, 'loss_3': -16.04047966003418, 'loss_4': 0.05543452501296997, 'epoch': 14.37}
{'loss': 0.0131, 'grad_norm': 6.498630046844482, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.010708875954151154, 'loss_2': 0.002368927001953125, 'loss_3': -16.12923812866211, 'loss_4': 0.026477500796318054, 'epoch': 14.38}
{'loss': 0.0147, 'grad_norm': 5.647703170776367, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.007962723262608051, 'loss_2': 0.0067138671875, 'loss_3': -15.995079040527344, 'loss_4': 0.2848738431930542, 'epoch': 14.38}
{'loss': 0.0152, 'grad_norm': 5.090465545654297, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.007587755098938942, 'loss_2': 0.00763702392578125, 'loss_3': -16.25888442993164, 'loss_4': 0.45152217149734497, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 16:19:58,644 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:58,644 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:11<46:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:05,978 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020680859684944153, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.879, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016548343002796173, 'eval_loss_2': 0.00413251668214798, 'eval_loss_3': -18.137083053588867, 'eval_loss_4': 0.19249023497104645, 'epoch': 14.39}
{'loss': 0.0126, 'grad_norm': 5.063274383544922, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.009142654947936535, 'loss_2': 0.0034847259521484375, 'loss_3': -16.110164642333984, 'loss_4': 0.04148487001657486, 'epoch': 14.4}
{'loss': 0.0126, 'grad_norm': 5.082512378692627, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.006913053337484598, 'loss_2': 0.005645751953125, 'loss_3': -16.15972900390625, 'loss_4': 0.4821607172489166, 'epoch': 14.4}
{'loss': 0.0085, 'grad_norm': 5.28180456161499, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.007580794394016266, 'loss_2': 0.0009260177612304688, 'loss_3': -16.143381118774414, 'loss_4': 0.26457780599594116, 'epoch': 14.41}
{'loss': 0.0094, 'grad_norm': 5.48844575881958, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.009216701611876488, 'loss_2': 0.0001685619354248047, 'loss_3': -16.146888732910156, 'loss_4': 0.3971864581108093, 'epoch': 14.41}
{'loss': 0.0176, 'grad_norm': 5.1705193519592285, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.009617633186280727, 'loss_2': 0.008026123046875, 'loss_3': -16.053403854370117, 'loss_4': -0.006618976593017578, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 16:20:05,978 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:05,978 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:18<46:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:13,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02076123282313347, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.952, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016401242464780807, 'eval_loss_2': 0.004359990358352661, 'eval_loss_3': -18.14030647277832, 'eval_loss_4': 0.3019275665283203, 'epoch': 14.42}
{'loss': 0.019, 'grad_norm': 7.539348602294922, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.01777089387178421, 'loss_2': 0.001220703125, 'loss_3': -16.24413299560547, 'loss_4': 0.5583987832069397, 'epoch': 14.42}
{'loss': 0.0258, 'grad_norm': 7.258279800415039, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.015864113345742226, 'loss_2': 0.00989532470703125, 'loss_3': -16.19332504272461, 'loss_4': 0.10796479135751724, 'epoch': 14.43}
{'loss': 0.0121, 'grad_norm': 5.680828094482422, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.009516664780676365, 'loss_2': 0.0025787353515625, 'loss_3': -16.115249633789062, 'loss_4': 0.282203733921051, 'epoch': 14.44}
{'loss': 0.0238, 'grad_norm': 12.846382141113281, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.01807379350066185, 'loss_2': 0.005710601806640625, 'loss_3': -16.135021209716797, 'loss_4': 0.3658049702644348, 'epoch': 14.44}
{'loss': 0.0134, 'grad_norm': 6.502979278564453, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.009730682708323002, 'loss_2': 0.0037078857421875, 'loss_3': -16.28565216064453, 'loss_4': 0.7914584279060364, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 16:20:13,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:13,316 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:26<46:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:20,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01949377730488777, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.862, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01583026722073555, 'eval_loss_2': 0.0036635100841522217, 'eval_loss_3': -18.116046905517578, 'eval_loss_4': 0.2915072441101074, 'epoch': 14.45}
{'loss': 0.0137, 'grad_norm': 6.697117805480957, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.00984132383018732, 'loss_2': 0.0039043426513671875, 'loss_3': -16.038503646850586, 'loss_4': 0.6477674245834351, 'epoch': 14.45}
{'loss': 0.0105, 'grad_norm': 6.3920817375183105, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.010334795340895653, 'loss_2': 0.0001850128173828125, 'loss_3': -16.05487823486328, 'loss_4': 0.38284099102020264, 'epoch': 14.46}
{'loss': 0.0362, 'grad_norm': 16.881410598754883, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.033260244876146317, 'loss_2': 0.002979278564453125, 'loss_3': -15.984296798706055, 'loss_4': 0.1280713677406311, 'epoch': 14.47}
{'loss': 0.0139, 'grad_norm': 8.4833345413208, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.009846636094152927, 'loss_2': 0.004058837890625, 'loss_3': -15.966726303100586, 'loss_4': 0.3165217638015747, 'epoch': 14.47}
{'loss': 0.0113, 'grad_norm': 5.871706008911133, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.00825495645403862, 'loss_2': 0.003063201904296875, 'loss_3': -16.252161026000977, 'loss_4': 0.3808876574039459, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 16:20:20,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:20,655 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:33<46:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:27,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021012328565120697, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016180971637368202, 'eval_loss_2': 0.004831355065107346, 'eval_loss_3': -18.118471145629883, 'eval_loss_4': 0.13246789574623108, 'epoch': 14.48}
{'loss': 0.0082, 'grad_norm': 4.76146125793457, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.004554412327706814, 'loss_2': 0.003673553466796875, 'loss_3': -16.194780349731445, 'loss_4': -0.08653904497623444, 'epoch': 14.48}
{'loss': 0.038, 'grad_norm': 20.79074478149414, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.03032807447016239, 'loss_2': 0.00768280029296875, 'loss_3': -15.940677642822266, 'loss_4': 0.3604198098182678, 'epoch': 14.49}
{'loss': 0.0239, 'grad_norm': 6.0195441246032715, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.013861936517059803, 'loss_2': 0.0100860595703125, 'loss_3': -15.974994659423828, 'loss_4': 0.5081077218055725, 'epoch': 14.49}
{'loss': 0.0116, 'grad_norm': 4.692469120025635, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.0064282105304300785, 'loss_2': 0.00519561767578125, 'loss_3': -15.884820938110352, 'loss_4': -0.0826750323176384, 'epoch': 14.5}
{'loss': 0.0175, 'grad_norm': 4.801136493682861, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.0056335353292524815, 'loss_2': 0.0118255615234375, 'loss_3': -16.309839248657227, 'loss_4': 0.2751578092575073, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 16:20:27,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:27,996 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:40<45:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:35,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021581916138529778, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01790868677198887, 'eval_loss_2': 0.003673229366540909, 'eval_loss_3': -18.121240615844727, 'eval_loss_4': 0.0890139788389206, 'epoch': 14.51}
{'loss': 0.0121, 'grad_norm': 4.806751728057861, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.006583919283002615, 'loss_2': 0.00548553466796875, 'loss_3': -16.224308013916016, 'loss_4': 0.4096507430076599, 'epoch': 14.51}
{'loss': 0.0096, 'grad_norm': 5.532423496246338, 'learning_rate': 1.55e-05, 'loss_1': 0.008270502090454102, 'loss_2': 0.0012960433959960938, 'loss_3': -16.115222930908203, 'loss_4': 0.13311335444450378, 'epoch': 14.52}
{'loss': 0.0073, 'grad_norm': 4.933772563934326, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.006927335634827614, 'loss_2': 0.00034356117248535156, 'loss_3': -15.972110748291016, 'loss_4': -0.1508948802947998, 'epoch': 14.52}
{'loss': 0.0142, 'grad_norm': 5.969352722167969, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.011650330387055874, 'loss_2': 0.002506256103515625, 'loss_3': -16.142555236816406, 'loss_4': -0.14964179694652557, 'epoch': 14.53}
{'loss': 0.0137, 'grad_norm': 5.722869396209717, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.009518511593341827, 'loss_2': 0.004184722900390625, 'loss_3': -16.1907958984375, 'loss_4': 0.013028163462877274, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 16:20:35,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:35,341 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:01:48<45:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:42,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022047918289899826, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.058, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01802402175962925, 'eval_loss_2': 0.004023894667625427, 'eval_loss_3': -18.09739875793457, 'eval_loss_4': 0.043645188212394714, 'epoch': 14.53}
{'loss': 0.0107, 'grad_norm': 5.401095390319824, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.009691627696156502, 'loss_2': 0.0010576248168945312, 'loss_3': -16.16672134399414, 'loss_4': -0.0769827663898468, 'epoch': 14.54}
{'loss': 0.0137, 'grad_norm': 4.931644916534424, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.009693996049463749, 'loss_2': 0.00403594970703125, 'loss_3': -16.011924743652344, 'loss_4': 0.12187479436397552, 'epoch': 14.55}
{'loss': 0.0093, 'grad_norm': 5.319824695587158, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.007791584357619286, 'loss_2': 0.0014591217041015625, 'loss_3': -16.196338653564453, 'loss_4': 0.17398637533187866, 'epoch': 14.55}
{'loss': 0.0094, 'grad_norm': 5.389394283294678, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.006788941100239754, 'loss_2': 0.002574920654296875, 'loss_3': -15.966940879821777, 'loss_4': -0.08931808173656464, 'epoch': 14.56}
{'loss': 0.0178, 'grad_norm': 5.309996128082275, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.009976521134376526, 'loss_2': 0.00785064697265625, 'loss_3': -16.010456085205078, 'loss_4': -0.04582538455724716, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 16:20:42,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:42,671 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:01:55<45:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:50,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021578442305326462, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.886, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016465242952108383, 'eval_loss_2': 0.005113199353218079, 'eval_loss_3': -18.08697509765625, 'eval_loss_4': 0.023815136402845383, 'epoch': 14.56}
{'loss': 0.0083, 'grad_norm': 4.735970497131348, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.004709939938038588, 'loss_2': 0.0036067962646484375, 'loss_3': -16.337528228759766, 'loss_4': -0.16119620203971863, 'epoch': 14.57}
{'loss': 0.0233, 'grad_norm': 7.2431416511535645, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.019331909716129303, 'loss_2': 0.00397491455078125, 'loss_3': -16.079896926879883, 'loss_4': 0.2771350145339966, 'epoch': 14.58}
{'loss': 0.0203, 'grad_norm': 8.686269760131836, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.018578147515654564, 'loss_2': 0.0017108917236328125, 'loss_3': -16.0234317779541, 'loss_4': 0.25104841589927673, 'epoch': 14.58}
{'loss': 0.0236, 'grad_norm': 19.428987503051758, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.021574795246124268, 'loss_2': 0.0020542144775390625, 'loss_3': -16.056781768798828, 'loss_4': 0.02098764479160309, 'epoch': 14.59}
{'loss': 0.0149, 'grad_norm': 6.137033939361572, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.010310964658856392, 'loss_2': 0.004638671875, 'loss_3': -16.088916778564453, 'loss_4': -0.018420442938804626, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 16:20:50,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:50,004 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:02<45:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:57,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020927859470248222, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.623, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.018003176897764206, 'eval_loss_2': 0.002924680709838867, 'eval_loss_3': -18.03798484802246, 'eval_loss_4': -0.0004590936005115509, 'epoch': 14.59}
{'loss': 0.0073, 'grad_norm': 4.9420247077941895, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.006334324367344379, 'loss_2': 0.001003265380859375, 'loss_3': -16.174896240234375, 'loss_4': 0.1656612902879715, 'epoch': 14.6}
{'loss': 0.0141, 'grad_norm': 5.230830669403076, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.011951292864978313, 'loss_2': 0.0021877288818359375, 'loss_3': -16.142953872680664, 'loss_4': -0.09121720492839813, 'epoch': 14.6}
{'loss': 0.0236, 'grad_norm': 9.490601539611816, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.0188676156103611, 'loss_2': 0.00473785400390625, 'loss_3': -16.017925262451172, 'loss_4': 0.11409544944763184, 'epoch': 14.61}
{'loss': 0.0115, 'grad_norm': 5.372410774230957, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.009261549450457096, 'loss_2': 0.00228118896484375, 'loss_3': -16.096572875976562, 'loss_4': -0.11974690109491348, 'epoch': 14.62}
{'loss': 0.0149, 'grad_norm': 6.397095680236816, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.01237280573695898, 'loss_2': 0.002567291259765625, 'loss_3': -16.041404724121094, 'loss_4': -0.3271920084953308, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 16:20:57,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:57,347 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:10<45:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:04,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020392276346683502, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017712842673063278, 'eval_loss_2': 0.002679433673620224, 'eval_loss_3': -18.046039581298828, 'eval_loss_4': 0.053423043340444565, 'epoch': 14.62}
{'loss': 0.0297, 'grad_norm': 10.431556701660156, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.020325643941760063, 'loss_2': 0.00942230224609375, 'loss_3': -16.020248413085938, 'loss_4': 0.17313992977142334, 'epoch': 14.63}
{'loss': 0.0117, 'grad_norm': 6.432621002197266, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.01058928668498993, 'loss_2': 0.0011463165283203125, 'loss_3': -16.051055908203125, 'loss_4': 0.2323196679353714, 'epoch': 14.63}
{'loss': 0.0109, 'grad_norm': 6.1349005699157715, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.010831030085682869, 'loss_2': 3.3736228942871094e-05, 'loss_3': -16.144277572631836, 'loss_4': 0.03592996299266815, 'epoch': 14.64}
{'loss': 0.0111, 'grad_norm': 5.566783905029297, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.007907290011644363, 'loss_2': 0.003147125244140625, 'loss_3': -16.104408264160156, 'loss_4': 0.190621018409729, 'epoch': 14.65}
{'loss': 0.0154, 'grad_norm': 7.0949201583862305, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.014181690290570259, 'loss_2': 0.0012226104736328125, 'loss_3': -16.087310791015625, 'loss_4': 0.10985934734344482, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 16:21:04,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:04,687 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:17<45:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:12,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021110136061906815, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015802761539816856, 'eval_loss_2': 0.005307376384735107, 'eval_loss_3': -18.08977699279785, 'eval_loss_4': 0.2565648555755615, 'epoch': 14.65}
{'loss': 0.0085, 'grad_norm': 4.78590202331543, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.007399773225188255, 'loss_2': 0.0010843276977539062, 'loss_3': -16.0057430267334, 'loss_4': 0.265272319316864, 'epoch': 14.66}
{'loss': 0.0273, 'grad_norm': 10.919078826904297, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.02621944434940815, 'loss_2': 0.0010623931884765625, 'loss_3': -16.322494506835938, 'loss_4': 0.2668720483779907, 'epoch': 14.66}
{'loss': 0.028, 'grad_norm': 10.89603042602539, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.023984437808394432, 'loss_2': 0.004058837890625, 'loss_3': -16.01033592224121, 'loss_4': 0.4680440425872803, 'epoch': 14.67}
{'loss': 0.0199, 'grad_norm': 9.525352478027344, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.015638651326298714, 'loss_2': 0.00431060791015625, 'loss_3': -16.121294021606445, 'loss_4': 0.32625073194503784, 'epoch': 14.67}
{'loss': 0.0085, 'grad_norm': 5.2567973136901855, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.005952449981123209, 'loss_2': 0.0025787353515625, 'loss_3': -16.218687057495117, 'loss_4': 0.5285258293151855, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 16:21:12,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:12,033 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:24<45:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:19,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018219774588942528, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01491746585816145, 'eval_loss_2': 0.003302309662103653, 'eval_loss_3': -18.09605598449707, 'eval_loss_4': 0.31672534346580505, 'epoch': 14.68}
{'loss': 0.0127, 'grad_norm': 5.030842304229736, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.006248958874493837, 'loss_2': 0.00641632080078125, 'loss_3': -16.1179141998291, 'loss_4': 0.620890736579895, 'epoch': 14.69}
{'loss': 0.0116, 'grad_norm': 5.496626853942871, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.007515573874115944, 'loss_2': 0.00411224365234375, 'loss_3': -16.1041316986084, 'loss_4': 0.17986060678958893, 'epoch': 14.69}
{'loss': 0.0192, 'grad_norm': 7.168902397155762, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.01246575079858303, 'loss_2': 0.0067138671875, 'loss_3': -16.027034759521484, 'loss_4': 0.059919655323028564, 'epoch': 14.7}
{'loss': 0.0364, 'grad_norm': 14.648560523986816, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.03189326822757721, 'loss_2': 0.004486083984375, 'loss_3': -16.23604393005371, 'loss_4': 0.6879122257232666, 'epoch': 14.7}
{'loss': 0.0207, 'grad_norm': 7.7170281410217285, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.01101409737020731, 'loss_2': 0.009674072265625, 'loss_3': -16.202281951904297, 'loss_4': 0.34110862016677856, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 16:21:19,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:19,377 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:32<45:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:26,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018333308398723602, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.113, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01334952563047409, 'eval_loss_2': 0.004983782768249512, 'eval_loss_3': -18.068492889404297, 'eval_loss_4': 0.22510726749897003, 'epoch': 14.71}
{'loss': 0.0088, 'grad_norm': 6.482350826263428, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.008594166487455368, 'loss_2': 0.0002512931823730469, 'loss_3': -16.10084342956543, 'loss_4': 0.4831026494503021, 'epoch': 14.72}
{'loss': 0.0094, 'grad_norm': 4.397438049316406, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.004814087878912687, 'loss_2': 0.00463104248046875, 'loss_3': -16.066246032714844, 'loss_4': 0.322753369808197, 'epoch': 14.72}
{'loss': 0.0237, 'grad_norm': 7.783139228820801, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.01767526939511299, 'loss_2': 0.00605010986328125, 'loss_3': -16.028390884399414, 'loss_4': 0.01432870328426361, 'epoch': 14.73}
{'loss': 0.0173, 'grad_norm': 8.636083602905273, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.010188690386712551, 'loss_2': 0.0071258544921875, 'loss_3': -16.300912857055664, 'loss_4': -0.06802936643362045, 'epoch': 14.73}
{'loss': 0.0131, 'grad_norm': 4.7061309814453125, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.0059998962096869946, 'loss_2': 0.007080078125, 'loss_3': -15.90788459777832, 'loss_4': 0.5633242726325989, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 16:21:26,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:26,706 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:39<45:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:34,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01839490234851837, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.96, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011969640851020813, 'eval_loss_2': 0.006425261497497559, 'eval_loss_3': -18.05257225036621, 'eval_loss_4': 0.12429948896169662, 'epoch': 14.74}
{'loss': 0.0206, 'grad_norm': 7.063494682312012, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.013725677505135536, 'loss_2': 0.00687408447265625, 'loss_3': -16.050065994262695, 'loss_4': 0.31107717752456665, 'epoch': 14.74}
{'loss': 0.0105, 'grad_norm': 4.904780387878418, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.004862705245614052, 'loss_2': 0.0056304931640625, 'loss_3': -16.34783363342285, 'loss_4': 0.010211873799562454, 'epoch': 14.75}
{'loss': 0.0162, 'grad_norm': 7.152298927307129, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.01114773191511631, 'loss_2': 0.0050506591796875, 'loss_3': -15.718354225158691, 'loss_4': 0.4384947121143341, 'epoch': 14.76}
{'loss': 0.0153, 'grad_norm': 8.099044799804688, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.011859502643346786, 'loss_2': 0.003475189208984375, 'loss_3': -16.00484848022461, 'loss_4': 0.5635796785354614, 'epoch': 14.76}
{'loss': 0.023, 'grad_norm': 7.425659656524658, 'learning_rate': 1.525e-05, 'loss_1': 0.012005575932562351, 'loss_2': 0.01103973388671875, 'loss_3': -16.284934997558594, 'loss_4': 0.27264106273651123, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 16:21:34,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:34,041 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:02:46<45:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:41,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017496120184659958, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.744, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013894031755626202, 'eval_loss_2': 0.0036020874977111816, 'eval_loss_3': -18.029333114624023, 'eval_loss_4': 0.1276869773864746, 'epoch': 14.77}
{'loss': 0.0678, 'grad_norm': 15.911360740661621, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.06169942393898964, 'loss_2': 0.00611114501953125, 'loss_3': -16.002140045166016, 'loss_4': 0.7403393387794495, 'epoch': 14.77}
{'loss': 0.016, 'grad_norm': 5.15460729598999, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.005834054667502642, 'loss_2': 0.01012420654296875, 'loss_3': -16.15801429748535, 'loss_4': 0.10988114774227142, 'epoch': 14.78}
{'loss': 0.0262, 'grad_norm': 9.321995735168457, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.019949741661548615, 'loss_2': 0.006267547607421875, 'loss_3': -15.927061080932617, 'loss_4': -0.028981000185012817, 'epoch': 14.78}
{'loss': 0.0254, 'grad_norm': 13.619979858398438, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.020843954756855965, 'loss_2': 0.004573822021484375, 'loss_3': -15.87098217010498, 'loss_4': 0.6091543436050415, 'epoch': 14.79}
{'loss': 0.0131, 'grad_norm': 10.315457344055176, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.010930991731584072, 'loss_2': 0.002155303955078125, 'loss_3': -16.01217269897461, 'loss_4': 0.40760084986686707, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 16:21:41,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:41,381 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:02:54<45:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:48,720 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019874323159456253, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014089991338551044, 'eval_loss_2': 0.005784332752227783, 'eval_loss_3': -18.009765625, 'eval_loss_4': 0.1939329206943512, 'epoch': 14.8}
{'loss': 0.0153, 'grad_norm': 5.0220417976379395, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.007130579557269812, 'loss_2': 0.00812530517578125, 'loss_3': -16.12518310546875, 'loss_4': 0.14325642585754395, 'epoch': 14.8}
{'loss': 0.0098, 'grad_norm': 4.7487053871154785, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.005323221441358328, 'loss_2': 0.0045013427734375, 'loss_3': -16.197322845458984, 'loss_4': 0.16433624923229218, 'epoch': 14.81}
{'loss': 0.0216, 'grad_norm': 6.243142127990723, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.010039905086159706, 'loss_2': 0.011566162109375, 'loss_3': -16.155275344848633, 'loss_4': 0.27676331996917725, 'epoch': 14.81}
{'loss': 0.0075, 'grad_norm': 5.430375099182129, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.005971094593405724, 'loss_2': 0.0015773773193359375, 'loss_3': -16.179019927978516, 'loss_4': 0.5447627305984497, 'epoch': 14.82}
{'loss': 0.0078, 'grad_norm': 4.840742111206055, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.006599999498575926, 'loss_2': 0.00121307373046875, 'loss_3': -16.002965927124023, 'loss_4': 0.23254407942295074, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 16:21:48,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:48,720 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:01<45:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:56,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02015267312526703, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01617578975856304, 'eval_loss_2': 0.003976881504058838, 'eval_loss_3': -17.98613929748535, 'eval_loss_4': 0.2761486768722534, 'epoch': 14.83}
{'loss': 0.01, 'grad_norm': 5.061067581176758, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.00736320810392499, 'loss_2': 0.00263214111328125, 'loss_3': -16.123897552490234, 'loss_4': 0.12272728979587555, 'epoch': 14.83}
{'loss': 0.018, 'grad_norm': 6.692649841308594, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.016676951199769974, 'loss_2': 0.00136566162109375, 'loss_3': -16.174522399902344, 'loss_4': 0.3671422004699707, 'epoch': 14.84}
{'loss': 0.0069, 'grad_norm': 5.195640563964844, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.005085153039544821, 'loss_2': 0.001789093017578125, 'loss_3': -15.853218078613281, 'loss_4': -0.00879107415676117, 'epoch': 14.84}
{'loss': 0.0087, 'grad_norm': 4.911319255828857, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.006279890891164541, 'loss_2': 0.0024471282958984375, 'loss_3': -16.147212982177734, 'loss_4': 0.05370359122753143, 'epoch': 14.85}
{'loss': 0.0106, 'grad_norm': 6.169122219085693, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.010094630531966686, 'loss_2': 0.00046443939208984375, 'loss_3': -15.9239501953125, 'loss_4': 0.34378400444984436, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 16:21:56,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:56,056 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:08<44:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:03,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021226800978183746, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.913, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0164627805352211, 'eval_loss_2': 0.0047640204429626465, 'eval_loss_3': -17.978715896606445, 'eval_loss_4': 0.35676851868629456, 'epoch': 14.85}
{'loss': 0.0162, 'grad_norm': 5.901479721069336, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.008940967731177807, 'loss_2': 0.007289886474609375, 'loss_3': -16.033336639404297, 'loss_4': 0.48008227348327637, 'epoch': 14.86}
{'loss': 0.0091, 'grad_norm': 5.499490261077881, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.006801658309996128, 'loss_2': 0.00232696533203125, 'loss_3': -16.0961971282959, 'loss_4': 0.47864145040512085, 'epoch': 14.87}
{'loss': 0.0051, 'grad_norm': 4.4684247970581055, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.004446020815521479, 'loss_2': 0.0006189346313476562, 'loss_3': -16.155582427978516, 'loss_4': 0.18039679527282715, 'epoch': 14.87}
{'loss': 0.0138, 'grad_norm': 8.798008918762207, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.012978598475456238, 'loss_2': 0.0008020401000976562, 'loss_3': -16.103609085083008, 'loss_4': 0.3130055367946625, 'epoch': 14.88}
{'loss': 0.0061, 'grad_norm': 5.185956954956055, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.005750374402850866, 'loss_2': 0.00032329559326171875, 'loss_3': -16.08746337890625, 'loss_4': 0.48464518785476685, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 16:22:03,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:03,386 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:16<44:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:10,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020027732476592064, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.023, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.015828851610422134, 'eval_loss_2': 0.00419887900352478, 'eval_loss_3': -18.005077362060547, 'eval_loss_4': 0.2981683015823364, 'epoch': 14.88}
{'loss': 0.0146, 'grad_norm': 5.7779860496521, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.012053878046572208, 'loss_2': 0.002536773681640625, 'loss_3': -16.202957153320312, 'loss_4': 0.4161764979362488, 'epoch': 14.89}
{'loss': 0.015, 'grad_norm': 11.695940971374512, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.011801802553236485, 'loss_2': 0.0032196044921875, 'loss_3': -16.142515182495117, 'loss_4': 0.41913020610809326, 'epoch': 14.9}
{'loss': 0.0223, 'grad_norm': 21.54483413696289, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.018117157742381096, 'loss_2': 0.004150390625, 'loss_3': -16.105573654174805, 'loss_4': 0.01911168172955513, 'epoch': 14.9}
{'loss': 0.0185, 'grad_norm': 6.2941999435424805, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.013934985734522343, 'loss_2': 0.00452423095703125, 'loss_3': -16.001550674438477, 'loss_4': 0.19667896628379822, 'epoch': 14.91}
{'loss': 0.0266, 'grad_norm': 7.480443954467773, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.013686147518455982, 'loss_2': 0.01290130615234375, 'loss_3': -16.241573333740234, 'loss_4': 0.0018887892365455627, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 16:22:10,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:10,722 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:23<44:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:18,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02004099264740944, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.079, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.016878576949238777, 'eval_loss_2': 0.0031624138355255127, 'eval_loss_3': -17.998592376708984, 'eval_loss_4': 0.2569015622138977, 'epoch': 14.91}
{'loss': 0.011, 'grad_norm': 4.800724983215332, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.00475710304453969, 'loss_2': 0.006221771240234375, 'loss_3': -16.04116439819336, 'loss_4': 0.09242989122867584, 'epoch': 14.92}
{'loss': 0.0078, 'grad_norm': 4.852489948272705, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.006905130110681057, 'loss_2': 0.0009031295776367188, 'loss_3': -16.05204200744629, 'loss_4': 0.3986929655075073, 'epoch': 14.92}
{'loss': 0.0089, 'grad_norm': 6.251087665557861, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.00825387705117464, 'loss_2': 0.0006136894226074219, 'loss_3': -16.130355834960938, 'loss_4': 0.08802242577075958, 'epoch': 14.93}
{'loss': 0.022, 'grad_norm': 10.12937068939209, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.014929774217307568, 'loss_2': 0.00704193115234375, 'loss_3': -16.04470443725586, 'loss_4': 0.08918951451778412, 'epoch': 14.94}
{'loss': 0.0097, 'grad_norm': 5.6039605140686035, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.007926360704004765, 'loss_2': 0.00182342529296875, 'loss_3': -16.0590763092041, 'loss_4': 0.10550744086503983, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 16:22:18,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:18,048 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:30<44:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:25,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021163105964660645, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01729661040008068, 'eval_loss_2': 0.0038664937019348145, 'eval_loss_3': -17.98337745666504, 'eval_loss_4': 0.3715512156486511, 'epoch': 14.94}
{'loss': 0.0149, 'grad_norm': 6.041805267333984, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.008731297217309475, 'loss_2': 0.0062103271484375, 'loss_3': -15.949447631835938, 'loss_4': 0.08249355852603912, 'epoch': 14.95}
{'loss': 0.024, 'grad_norm': 7.084870338439941, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.015455974265933037, 'loss_2': 0.0084991455078125, 'loss_3': -15.95060920715332, 'loss_4': 0.3150448203086853, 'epoch': 14.95}
{'loss': 0.0082, 'grad_norm': 5.457366466522217, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.006732243113219738, 'loss_2': 0.0014944076538085938, 'loss_3': -15.980865478515625, 'loss_4': 0.23579251766204834, 'epoch': 14.96}
{'loss': 0.0107, 'grad_norm': 5.001805305480957, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.0058981506153941154, 'loss_2': 0.0048065185546875, 'loss_3': -16.18291473388672, 'loss_4': 0.07746897637844086, 'epoch': 14.97}
{'loss': 0.01, 'grad_norm': 5.736614227294922, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.009593808092176914, 'loss_2': 0.000392913818359375, 'loss_3': -16.05641746520996, 'loss_4': 0.17217999696731567, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 16:22:25,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:25,383 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:37<40:06,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:22:32,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02224924974143505, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.761, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01764529198408127, 'eval_loss_2': 0.004603959619998932, 'eval_loss_3': -17.954654693603516, 'eval_loss_4': 0.4235307574272156, 'epoch': 14.97}
{'loss': 0.0086, 'grad_norm': 6.325654983520508, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.006515604443848133, 'loss_2': 0.002117156982421875, 'loss_3': -15.994132041931152, 'loss_4': 0.6465235948562622, 'epoch': 14.98}
{'loss': 0.0267, 'grad_norm': 14.646916389465332, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.02517043426632881, 'loss_2': 0.00157928466796875, 'loss_3': -16.07646942138672, 'loss_4': 0.31998419761657715, 'epoch': 14.98}
{'loss': 0.019, 'grad_norm': 11.60073471069336, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.014724244363605976, 'loss_2': 0.00428009033203125, 'loss_3': -16.134166717529297, 'loss_4': 0.41843605041503906, 'epoch': 14.99}
{'loss': 0.0173, 'grad_norm': 5.374924182891846, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.009779849089682102, 'loss_2': 0.00751495361328125, 'loss_3': -15.937952041625977, 'loss_4': 0.6555923223495483, 'epoch': 14.99}
{'loss': 0.0159, 'grad_norm': 11.163139343261719, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.014248734340071678, 'loss_2': 0.001644134521484375, 'loss_3': -15.708829879760742, 'loss_4': 0.2895806133747101, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 16:22:32,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:32,373 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:03:45<43:51,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:22:39,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02174994722008705, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.648, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01876574568450451, 'eval_loss_2': 0.0029842033982276917, 'eval_loss_3': -17.942636489868164, 'eval_loss_4': 0.4301912188529968, 'epoch': 15.0}
{'loss': 0.0099, 'grad_norm': 6.100677013397217, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.009171298705041409, 'loss_2': 0.000736236572265625, 'loss_3': -15.82278060913086, 'loss_4': -0.09445005655288696, 'epoch': 15.01}
{'loss': 0.0149, 'grad_norm': 7.216975212097168, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.010534055531024933, 'loss_2': 0.00433349609375, 'loss_3': -15.940088272094727, 'loss_4': 0.3292692303657532, 'epoch': 15.01}
{'loss': 0.0095, 'grad_norm': 5.480530261993408, 'learning_rate': 1.5e-05, 'loss_1': 0.007294869981706142, 'loss_2': 0.00215911865234375, 'loss_3': -16.114452362060547, 'loss_4': 0.44096097350120544, 'epoch': 15.02}
{'loss': 0.0167, 'grad_norm': 7.2903828620910645, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.014454979449510574, 'loss_2': 0.0022678375244140625, 'loss_3': -15.969520568847656, 'loss_4': 0.002001538872718811, 'epoch': 15.02}
{'loss': 0.0751, 'grad_norm': 26.684614181518555, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.0692732185125351, 'loss_2': 0.005870819091796875, 'loss_3': -16.050735473632812, 'loss_4': 0.5023218393325806, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 16:22:39,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:39,750 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:03:52<44:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:22:47,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02304498478770256, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.019997579976916313, 'eval_loss_2': 0.0030474066734313965, 'eval_loss_3': -17.976388931274414, 'eval_loss_4': 0.5159757733345032, 'epoch': 15.03}
{'loss': 0.012, 'grad_norm': 5.459511756896973, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.00524369440972805, 'loss_2': 0.0067596435546875, 'loss_3': -16.044689178466797, 'loss_4': 0.13063178956508636, 'epoch': 15.03}
{'loss': 0.0054, 'grad_norm': 5.486062049865723, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.004938966128975153, 'loss_2': 0.0004935264587402344, 'loss_3': -15.995574951171875, 'loss_4': 0.5791850090026855, 'epoch': 15.04}
{'loss': 0.0172, 'grad_norm': 7.817046165466309, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.013616139069199562, 'loss_2': 0.003574371337890625, 'loss_3': -16.047908782958984, 'loss_4': 0.7500312328338623, 'epoch': 15.05}
{'loss': 0.0142, 'grad_norm': 6.076000690460205, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.007295310031622648, 'loss_2': 0.006870269775390625, 'loss_3': -15.972395896911621, 'loss_4': 0.30136531591415405, 'epoch': 15.05}
{'loss': 0.0089, 'grad_norm': 5.7255659103393555, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.008651336655020714, 'loss_2': 0.0002760887145996094, 'loss_3': -15.994367599487305, 'loss_4': 0.3726348876953125, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 16:22:47,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:47,077 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:03:59<44:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:54,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02111918106675148, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.921, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018358130007982254, 'eval_loss_2': 0.002761051058769226, 'eval_loss_3': -18.00651741027832, 'eval_loss_4': 0.5593307018280029, 'epoch': 15.06}
{'loss': 0.0064, 'grad_norm': 5.418373107910156, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.005499041639268398, 'loss_2': 0.000904083251953125, 'loss_3': -16.077198028564453, 'loss_4': 0.12751075625419617, 'epoch': 15.06}
{'loss': 0.0219, 'grad_norm': 9.547562599182129, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.018204903230071068, 'loss_2': 0.0037384033203125, 'loss_3': -15.917983055114746, 'loss_4': 0.2897230386734009, 'epoch': 15.07}
{'loss': 0.0117, 'grad_norm': 7.987299919128418, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.009067696519196033, 'loss_2': 0.002613067626953125, 'loss_3': -16.085458755493164, 'loss_4': 0.08843261003494263, 'epoch': 15.08}
{'loss': 0.0201, 'grad_norm': 8.377668380737305, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.018738145008683205, 'loss_2': 0.0013332366943359375, 'loss_3': -16.15523910522461, 'loss_4': 0.452497661113739, 'epoch': 15.08}
{'loss': 0.0089, 'grad_norm': 5.241547584533691, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.00594581663608551, 'loss_2': 0.00292205810546875, 'loss_3': -16.226451873779297, 'loss_4': 0.8447294235229492, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 16:22:54,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:54,418 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:07<44:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:01,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023165900260210037, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.117, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01687188819050789, 'eval_loss_2': 0.0062940120697021484, 'eval_loss_3': -18.028310775756836, 'eval_loss_4': 0.5469411015510559, 'epoch': 15.09}
{'loss': 0.018, 'grad_norm': 6.380393028259277, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.015165050514042377, 'loss_2': 0.002811431884765625, 'loss_3': -16.162796020507812, 'loss_4': 0.3964720368385315, 'epoch': 15.09}
{'loss': 0.025, 'grad_norm': 8.711438179016113, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.011462587863206863, 'loss_2': 0.0135345458984375, 'loss_3': -16.130773544311523, 'loss_4': 0.6497609615325928, 'epoch': 15.1}
{'loss': 0.017, 'grad_norm': 9.936857223510742, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.016694679856300354, 'loss_2': 0.00033092498779296875, 'loss_3': -16.06890869140625, 'loss_4': 0.6102636456489563, 'epoch': 15.1}
{'loss': 0.0053, 'grad_norm': 5.1444597244262695, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.005077590700238943, 'loss_2': 0.0002644062042236328, 'loss_3': -16.247661590576172, 'loss_4': 0.2056988626718521, 'epoch': 15.11}
{'loss': 0.0073, 'grad_norm': 5.858333110809326, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.0070693339221179485, 'loss_2': 0.00020956993103027344, 'loss_3': -15.873307228088379, 'loss_4': 0.5939813852310181, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 16:23:01,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:01,754 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:14<44:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:09,091 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02543129399418831, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018935415893793106, 'eval_loss_2': 0.006495878100395203, 'eval_loss_3': -18.023664474487305, 'eval_loss_4': 0.45606786012649536, 'epoch': 15.12}
{'loss': 0.0189, 'grad_norm': 8.854405403137207, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.01111612468957901, 'loss_2': 0.0077667236328125, 'loss_3': -16.1051082611084, 'loss_4': 0.14270898699760437, 'epoch': 15.12}
{'loss': 0.014, 'grad_norm': 6.818634986877441, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.01020977646112442, 'loss_2': 0.0037708282470703125, 'loss_3': -16.022214889526367, 'loss_4': 0.13125310838222504, 'epoch': 15.13}
{'loss': 0.0095, 'grad_norm': 5.470636367797852, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.005996748339384794, 'loss_2': 0.0034770965576171875, 'loss_3': -16.301759719848633, 'loss_4': 0.6057246327400208, 'epoch': 15.13}
{'loss': 0.0158, 'grad_norm': 8.894164085388184, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.011692378669977188, 'loss_2': 0.00408935546875, 'loss_3': -16.156749725341797, 'loss_4': 0.26396888494491577, 'epoch': 15.14}
{'loss': 0.0077, 'grad_norm': 4.590737819671631, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.004841178189963102, 'loss_2': 0.0028781890869140625, 'loss_3': -16.161361694335938, 'loss_4': 0.3360707759857178, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 16:23:09,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:09,092 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:21<44:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:16,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021320201456546783, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.095, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01759037934243679, 'eval_loss_2': 0.0037298202514648438, 'eval_loss_3': -18.00502586364746, 'eval_loss_4': 0.38219019770622253, 'epoch': 15.15}
{'loss': 0.0091, 'grad_norm': 4.684144973754883, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.006643755827099085, 'loss_2': 0.0024509429931640625, 'loss_3': -15.983844757080078, 'loss_4': 0.29073816537857056, 'epoch': 15.15}
{'loss': 0.0218, 'grad_norm': 7.518321990966797, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.016611846163868904, 'loss_2': 0.005237579345703125, 'loss_3': -16.008934020996094, 'loss_4': 0.16535085439682007, 'epoch': 15.16}
{'loss': 0.0149, 'grad_norm': 6.444500923156738, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.011394782923161983, 'loss_2': 0.0035247802734375, 'loss_3': -16.065597534179688, 'loss_4': 0.3932468891143799, 'epoch': 15.16}
{'loss': 0.0883, 'grad_norm': 18.081798553466797, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.08290305733680725, 'loss_2': 0.00534820556640625, 'loss_3': -15.860250473022461, 'loss_4': -0.0011532008647918701, 'epoch': 15.17}
{'loss': 0.0139, 'grad_norm': 5.213911533355713, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.008172420784831047, 'loss_2': 0.00571441650390625, 'loss_3': -16.177047729492188, 'loss_4': 0.3116704225540161, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 16:23:16,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:16,424 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:29<43:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:23,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020879916846752167, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.191, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018213903531432152, 'eval_loss_2': 0.0026660114526748657, 'eval_loss_3': -18.011980056762695, 'eval_loss_4': 0.30181804299354553, 'epoch': 15.17}
{'loss': 0.0119, 'grad_norm': 5.517012596130371, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.01023662555962801, 'loss_2': 0.0016155242919921875, 'loss_3': -16.075992584228516, 'loss_4': 0.18596111238002777, 'epoch': 15.18}
{'loss': 0.0128, 'grad_norm': 5.665380477905273, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.010993142612278461, 'loss_2': 0.0017910003662109375, 'loss_3': -15.991008758544922, 'loss_4': 0.006883271038532257, 'epoch': 15.19}
{'loss': 0.0066, 'grad_norm': 5.077467441558838, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.005604894831776619, 'loss_2': 0.0009889602661132812, 'loss_3': -15.889677047729492, 'loss_4': 0.13423490524291992, 'epoch': 15.19}
{'loss': 0.0144, 'grad_norm': 5.156194686889648, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.007208310067653656, 'loss_2': 0.00716400146484375, 'loss_3': -16.191490173339844, 'loss_4': 0.1249496340751648, 'epoch': 15.2}
{'loss': 0.0192, 'grad_norm': 5.985362529754639, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.01095214020460844, 'loss_2': 0.00829315185546875, 'loss_3': -15.990574836730957, 'loss_4': 0.2808188498020172, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 16:23:23,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:23,755 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:36<43:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:31,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01977451890707016, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.878, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017535677179694176, 'eval_loss_2': 0.002238839864730835, 'eval_loss_3': -18.02676010131836, 'eval_loss_4': 0.2583160400390625, 'epoch': 15.2}
{'loss': 0.0111, 'grad_norm': 5.3992719650268555, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.00786462053656578, 'loss_2': 0.0031890869140625, 'loss_3': -16.18782615661621, 'loss_4': 0.08131273090839386, 'epoch': 15.21}
{'loss': 0.0137, 'grad_norm': 5.554477214813232, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.006558416411280632, 'loss_2': 0.0071258544921875, 'loss_3': -16.06248664855957, 'loss_4': 0.1586945652961731, 'epoch': 15.22}
{'loss': 0.0275, 'grad_norm': 16.869232177734375, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.02642842009663582, 'loss_2': 0.0011119842529296875, 'loss_3': -16.101696014404297, 'loss_4': -0.10918513685464859, 'epoch': 15.22}
{'loss': 0.0214, 'grad_norm': 6.8244733810424805, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.013075429946184158, 'loss_2': 0.0083465576171875, 'loss_3': -16.11479949951172, 'loss_4': 0.31047752499580383, 'epoch': 15.23}
{'loss': 0.0102, 'grad_norm': 4.652900218963623, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.006924794055521488, 'loss_2': 0.0033092498779296875, 'loss_3': -15.991987228393555, 'loss_4': 0.29113516211509705, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 16:23:31,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:31,095 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:43<43:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:38,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02104146219789982, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.886, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01582232117652893, 'eval_loss_2': 0.0052191391587257385, 'eval_loss_3': -18.047208786010742, 'eval_loss_4': 0.2545193135738373, 'epoch': 15.23}
{'loss': 0.0807, 'grad_norm': 18.784055709838867, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.07164747267961502, 'loss_2': 0.009063720703125, 'loss_3': -16.196170806884766, 'loss_4': 0.9661475419998169, 'epoch': 15.24}
{'loss': 0.0169, 'grad_norm': 5.550018310546875, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.012895675376057625, 'loss_2': 0.0039825439453125, 'loss_3': -16.323556900024414, 'loss_4': 0.3363885283470154, 'epoch': 15.24}
{'loss': 0.0159, 'grad_norm': 8.32966423034668, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.00828891433775425, 'loss_2': 0.007656097412109375, 'loss_3': -16.058156967163086, 'loss_4': 0.37947002053260803, 'epoch': 15.25}
{'loss': 0.0076, 'grad_norm': 5.079675197601318, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.0030960841104388237, 'loss_2': 0.0045166015625, 'loss_3': -16.169233322143555, 'loss_4': 0.1665487289428711, 'epoch': 15.26}
{'loss': 0.0145, 'grad_norm': 5.517069339752197, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.009652582928538322, 'loss_2': 0.00481414794921875, 'loss_3': -16.036691665649414, 'loss_4': 0.013455566018819809, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 16:23:38,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:38,432 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:04:51<43:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:45,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019339246675372124, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01447717472910881, 'eval_loss_2': 0.004862070083618164, 'eval_loss_3': -18.052032470703125, 'eval_loss_4': 0.2553195655345917, 'epoch': 15.26}
{'loss': 0.0158, 'grad_norm': 7.212793350219727, 'learning_rate': 1.475e-05, 'loss_1': 0.013309532776474953, 'loss_2': 0.00247955322265625, 'loss_3': -16.185169219970703, 'loss_4': -0.07944367080926895, 'epoch': 15.27}
{'loss': 0.0104, 'grad_norm': 4.822257995605469, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.004434175789356232, 'loss_2': 0.006015777587890625, 'loss_3': -16.118711471557617, 'loss_4': 0.19467756152153015, 'epoch': 15.27}
{'loss': 0.0106, 'grad_norm': 5.395743370056152, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.010471890680491924, 'loss_2': 8.273124694824219e-05, 'loss_3': -15.909501075744629, 'loss_4': -0.036775246262550354, 'epoch': 15.28}
{'loss': 0.0157, 'grad_norm': 6.676316738128662, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.013482866808772087, 'loss_2': 0.002254486083984375, 'loss_3': -16.043819427490234, 'loss_4': 0.29763415455818176, 'epoch': 15.28}
{'loss': 0.0133, 'grad_norm': 6.040818691253662, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.012254753150045872, 'loss_2': 0.001026153564453125, 'loss_3': -16.042757034301758, 'loss_4': -0.03368040919303894, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 16:23:45,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:45,766 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:04:58<43:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:53,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017093781381845474, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.074, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014455743134021759, 'eval_loss_2': 0.002638038247823715, 'eval_loss_3': -18.034101486206055, 'eval_loss_4': 0.2214997261762619, 'epoch': 15.29}
{'loss': 0.0183, 'grad_norm': 8.761497497558594, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.011770518496632576, 'loss_2': 0.006500244140625, 'loss_3': -16.237030029296875, 'loss_4': -0.42333173751831055, 'epoch': 15.3}
{'loss': 0.0218, 'grad_norm': 10.656842231750488, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.019861364737153053, 'loss_2': 0.0019855499267578125, 'loss_3': -16.108808517456055, 'loss_4': 0.29674744606018066, 'epoch': 15.3}
{'loss': 0.0483, 'grad_norm': 19.01692008972168, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.0477101095020771, 'loss_2': 0.0005693435668945312, 'loss_3': -16.107223510742188, 'loss_4': -0.004640765488147736, 'epoch': 15.31}
{'loss': 0.0169, 'grad_norm': 6.155171871185303, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.012926006689667702, 'loss_2': 0.003936767578125, 'loss_3': -16.051374435424805, 'loss_4': 0.23433777689933777, 'epoch': 15.31}
{'loss': 0.0079, 'grad_norm': 4.533664226531982, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.005372048821300268, 'loss_2': 0.00247955322265625, 'loss_3': -16.098922729492188, 'loss_4': 0.3834250569343567, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 16:23:53,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:53,097 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:05<43:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:00,428 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016143545508384705, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.88, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013528273440897465, 'eval_loss_2': 0.0026152729988098145, 'eval_loss_3': -18.030929565429688, 'eval_loss_4': 0.096671923995018, 'epoch': 15.32}
{'loss': 0.0111, 'grad_norm': 4.968990325927734, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.007712366059422493, 'loss_2': 0.0033702850341796875, 'loss_3': -16.058929443359375, 'loss_4': 0.08035966753959656, 'epoch': 15.33}
{'loss': 0.0186, 'grad_norm': 6.187310218811035, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.0134657621383667, 'loss_2': 0.00514984130859375, 'loss_3': -16.317546844482422, 'loss_4': 0.14246252179145813, 'epoch': 15.33}
{'loss': 0.0202, 'grad_norm': 5.303869247436523, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.008915942162275314, 'loss_2': 0.011322021484375, 'loss_3': -15.764176368713379, 'loss_4': -0.20258121192455292, 'epoch': 15.34}
{'loss': 0.0124, 'grad_norm': 6.072983741760254, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.006573264021426439, 'loss_2': 0.005863189697265625, 'loss_3': -15.974246978759766, 'loss_4': 0.11195274442434311, 'epoch': 15.34}
{'loss': 0.021, 'grad_norm': 5.6831488609313965, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.008746097795665264, 'loss_2': 0.01226043701171875, 'loss_3': -16.10862159729004, 'loss_4': -0.10631158202886581, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 16:24:00,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:00,428 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:13<43:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:07,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020029325038194656, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.815, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0158245749771595, 'eval_loss_2': 0.004204750061035156, 'eval_loss_3': -18.045625686645508, 'eval_loss_4': 0.009609848260879517, 'epoch': 15.35}
{'loss': 0.0174, 'grad_norm': 6.777437686920166, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.011690682731568813, 'loss_2': 0.00571441650390625, 'loss_3': -16.2799072265625, 'loss_4': 0.08719649910926819, 'epoch': 15.35}
{'loss': 0.0232, 'grad_norm': 8.492955207824707, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.01553533785045147, 'loss_2': 0.00763702392578125, 'loss_3': -15.947025299072266, 'loss_4': -0.24407453835010529, 'epoch': 15.36}
{'loss': 0.0116, 'grad_norm': 4.665276527404785, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.0056882454082369804, 'loss_2': 0.00586700439453125, 'loss_3': -16.033117294311523, 'loss_4': -0.16120144724845886, 'epoch': 15.37}
{'loss': 0.0155, 'grad_norm': 7.156879901885986, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.012782621197402477, 'loss_2': 0.0026760101318359375, 'loss_3': -15.9427490234375, 'loss_4': 0.1221085712313652, 'epoch': 15.37}
{'loss': 0.01, 'grad_norm': 4.8461833000183105, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.007173464633524418, 'loss_2': 0.002819061279296875, 'loss_3': -16.027786254882812, 'loss_4': -0.039351899176836014, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 16:24:07,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:07,760 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:20<43:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:15,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021068556234240532, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.018, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01716744527220726, 'eval_loss_2': 0.0039011090993881226, 'eval_loss_3': -18.031089782714844, 'eval_loss_4': -0.10125840455293655, 'epoch': 15.38}
{'loss': 0.02, 'grad_norm': 7.448888301849365, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.017546549439430237, 'loss_2': 0.00246429443359375, 'loss_3': -16.039947509765625, 'loss_4': -0.03238648921251297, 'epoch': 15.38}
{'loss': 0.0208, 'grad_norm': 14.498454093933105, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.018160779029130936, 'loss_2': 0.002666473388671875, 'loss_3': -16.095062255859375, 'loss_4': 0.13587547838687897, 'epoch': 15.39}
{'loss': 0.0408, 'grad_norm': 15.124199867248535, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.038908667862415314, 'loss_2': 0.00193023681640625, 'loss_3': -16.2355899810791, 'loss_4': 0.1339576691389084, 'epoch': 15.4}
{'loss': 0.0122, 'grad_norm': 6.494082927703857, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.010016117244958878, 'loss_2': 0.0021724700927734375, 'loss_3': -16.232669830322266, 'loss_4': -0.055997177958488464, 'epoch': 15.4}
{'loss': 0.026, 'grad_norm': 8.089422225952148, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.01634208671748638, 'loss_2': 0.00970458984375, 'loss_3': -16.066818237304688, 'loss_4': -0.4719913601875305, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 16:24:15,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:15,096 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:27<43:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:22,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02146111987531185, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.157, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.017719779163599014, 'eval_loss_2': 0.003741338849067688, 'eval_loss_3': -18.059371948242188, 'eval_loss_4': -0.14330412447452545, 'epoch': 15.41}
{'loss': 0.0145, 'grad_norm': 5.294992446899414, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.006011201534420252, 'loss_2': 0.008453369140625, 'loss_3': -16.206087112426758, 'loss_4': -0.29617416858673096, 'epoch': 15.41}
{'loss': 0.0248, 'grad_norm': 10.81727123260498, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.02242765948176384, 'loss_2': 0.00240325927734375, 'loss_3': -15.97732925415039, 'loss_4': -0.44077759981155396, 'epoch': 15.42}
{'loss': 0.0121, 'grad_norm': 5.594942092895508, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.003421481465920806, 'loss_2': 0.00864410400390625, 'loss_3': -16.131502151489258, 'loss_4': 0.01902671530842781, 'epoch': 15.42}
{'loss': 0.0103, 'grad_norm': 5.507696151733398, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.00843753945082426, 'loss_2': 0.0018215179443359375, 'loss_3': -15.965534210205078, 'loss_4': -0.4585224688053131, 'epoch': 15.43}
{'loss': 0.0303, 'grad_norm': 18.097993850708008, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.029405010864138603, 'loss_2': 0.000885009765625, 'loss_3': -16.079322814941406, 'loss_4': -0.6219636797904968, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 16:24:22,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:22,427 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:35<43:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:29,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022718951106071472, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.534, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01885773427784443, 'eval_loss_2': 0.0038612186908721924, 'eval_loss_3': -18.090749740600586, 'eval_loss_4': -0.0772382915019989, 'epoch': 15.44}
{'loss': 0.0101, 'grad_norm': 5.49919319152832, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.007763170637190342, 'loss_2': 0.00234222412109375, 'loss_3': -16.1726131439209, 'loss_4': -0.13598068058490753, 'epoch': 15.44}
{'loss': 0.01, 'grad_norm': 4.952794075012207, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.007522869389504194, 'loss_2': 0.002445220947265625, 'loss_3': -16.096532821655273, 'loss_4': -0.041819021105766296, 'epoch': 15.45}
{'loss': 0.0195, 'grad_norm': 10.144779205322266, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.013990988954901695, 'loss_2': 0.005523681640625, 'loss_3': -16.014511108398438, 'loss_4': -0.28874480724334717, 'epoch': 15.45}
{'loss': 0.0189, 'grad_norm': 8.670891761779785, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.01624910719692707, 'loss_2': 0.0026397705078125, 'loss_3': -16.37693214416504, 'loss_4': -0.1847277730703354, 'epoch': 15.46}
{'loss': 0.0691, 'grad_norm': 24.78620719909668, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.06840074062347412, 'loss_2': 0.0007085800170898438, 'loss_3': -16.22277069091797, 'loss_4': 0.18719185888767242, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 16:24:29,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:29,766 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:42<43:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:37,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021935369819402695, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.143, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0187275018543005, 'eval_loss_2': 0.003207869827747345, 'eval_loss_3': -18.084177017211914, 'eval_loss_4': 0.09543702006340027, 'epoch': 15.47}
{'loss': 0.0174, 'grad_norm': 7.649080753326416, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.014288779348134995, 'loss_2': 0.0031032562255859375, 'loss_3': -16.12542724609375, 'loss_4': 0.12192869186401367, 'epoch': 15.47}
{'loss': 0.0209, 'grad_norm': 12.152852058410645, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.017771773040294647, 'loss_2': 0.003154754638671875, 'loss_3': -15.93787956237793, 'loss_4': -0.07309466600418091, 'epoch': 15.48}
{'loss': 0.0182, 'grad_norm': 8.771295547485352, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.015403681434690952, 'loss_2': 0.002788543701171875, 'loss_3': -15.980466842651367, 'loss_4': 0.26550114154815674, 'epoch': 15.48}
{'loss': 0.0154, 'grad_norm': 6.309683322906494, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.011627628467977047, 'loss_2': 0.003818511962890625, 'loss_3': -15.970352172851562, 'loss_4': 0.17711281776428223, 'epoch': 15.49}
{'loss': 0.0827, 'grad_norm': 29.932065963745117, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.07998676598072052, 'loss_2': 0.002716064453125, 'loss_3': -16.28506088256836, 'loss_4': 0.08501291275024414, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 16:24:37,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:37,097 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:05:49<43:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:44,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023782599717378616, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.207, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019346047192811966, 'eval_loss_2': 0.00443655252456665, 'eval_loss_3': -18.0889949798584, 'eval_loss_4': 0.2514638304710388, 'epoch': 15.49}
{'loss': 0.0287, 'grad_norm': 28.080299377441406, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.027545804157853127, 'loss_2': 0.0011577606201171875, 'loss_3': -16.059001922607422, 'loss_4': 0.24993383884429932, 'epoch': 15.5}
{'loss': 0.0089, 'grad_norm': 5.8105926513671875, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.008506097830832005, 'loss_2': 0.0003647804260253906, 'loss_3': -15.660137176513672, 'loss_4': 0.5829946398735046, 'epoch': 15.51}
{'loss': 0.0141, 'grad_norm': 6.56908655166626, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.013060923665761948, 'loss_2': 0.0010814666748046875, 'loss_3': -16.185718536376953, 'loss_4': 0.4720270037651062, 'epoch': 15.51}
{'loss': 0.0168, 'grad_norm': 6.021709442138672, 'learning_rate': 1.45e-05, 'loss_1': 0.014916721731424332, 'loss_2': 0.00189208984375, 'loss_3': -16.20594024658203, 'loss_4': 0.28508925437927246, 'epoch': 15.52}
{'loss': 0.0083, 'grad_norm': 4.986517429351807, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.006245442200452089, 'loss_2': 0.00208282470703125, 'loss_3': -16.188899993896484, 'loss_4': 0.28838253021240234, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 16:24:44,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:44,430 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:05:57<42:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:51,773 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022636234760284424, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.949, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018933681771159172, 'eval_loss_2': 0.0037025511264801025, 'eval_loss_3': -18.108871459960938, 'eval_loss_4': 0.3924694359302521, 'epoch': 15.52}
{'loss': 0.0081, 'grad_norm': 5.3354811668396, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.005627840757369995, 'loss_2': 0.0024871826171875, 'loss_3': -16.330808639526367, 'loss_4': 0.030200466513633728, 'epoch': 15.53}
{'loss': 0.0083, 'grad_norm': 4.83615779876709, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.00526079535484314, 'loss_2': 0.003017425537109375, 'loss_3': -16.319746017456055, 'loss_4': 0.24148942530155182, 'epoch': 15.53}
{'loss': 0.0084, 'grad_norm': 5.287516117095947, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.007376103196293116, 'loss_2': 0.0010652542114257812, 'loss_3': -16.227985382080078, 'loss_4': 0.7196458578109741, 'epoch': 15.54}
{'loss': 0.0296, 'grad_norm': 10.679670333862305, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.027995232492685318, 'loss_2': 0.0016164779663085938, 'loss_3': -15.95569896697998, 'loss_4': 0.29065507650375366, 'epoch': 15.55}
{'loss': 0.0515, 'grad_norm': 26.889629364013672, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.050786372274160385, 'loss_2': 0.0007181167602539062, 'loss_3': -16.078088760375977, 'loss_4': 0.23325207829475403, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 16:24:51,773 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:51,773 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:04<42:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:59,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02329961396753788, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019281940534710884, 'eval_loss_2': 0.004017673432826996, 'eval_loss_3': -18.127683639526367, 'eval_loss_4': 0.4044044613838196, 'epoch': 15.55}
{'loss': 0.0107, 'grad_norm': 4.850882530212402, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.006751974578946829, 'loss_2': 0.003948211669921875, 'loss_3': -15.969365119934082, 'loss_4': -0.01475352793931961, 'epoch': 15.56}
{'loss': 0.019, 'grad_norm': 10.436473846435547, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.01563699170947075, 'loss_2': 0.003398895263671875, 'loss_3': -16.028995513916016, 'loss_4': 0.8692183494567871, 'epoch': 15.56}
{'loss': 0.0176, 'grad_norm': 5.679418087005615, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.009008469991385937, 'loss_2': 0.008575439453125, 'loss_3': -16.07948112487793, 'loss_4': 0.27985870838165283, 'epoch': 15.57}
{'loss': 0.0097, 'grad_norm': 4.6100568771362305, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.004169808235019445, 'loss_2': 0.0055694580078125, 'loss_3': -16.38161277770996, 'loss_4': 0.2915281355381012, 'epoch': 15.58}
{'loss': 0.0255, 'grad_norm': 7.563169479370117, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.01619657129049301, 'loss_2': 0.00927734375, 'loss_3': -16.136592864990234, 'loss_4': 0.39190250635147095, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 16:24:59,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:59,112 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:11<42:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:06,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02383612096309662, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.609, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.020679809153079987, 'eval_loss_2': 0.003156311810016632, 'eval_loss_3': -18.14531898498535, 'eval_loss_4': 0.2908920645713806, 'epoch': 15.58}
{'loss': 0.0086, 'grad_norm': 5.555976867675781, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.008009328506886959, 'loss_2': 0.0006351470947265625, 'loss_3': -16.1871395111084, 'loss_4': 0.045655686408281326, 'epoch': 15.59}
{'loss': 0.0123, 'grad_norm': 5.338296413421631, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.009586505591869354, 'loss_2': 0.00270843505859375, 'loss_3': -16.044958114624023, 'loss_4': 0.15376321971416473, 'epoch': 15.59}
{'loss': 0.0073, 'grad_norm': 5.264533996582031, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.006995079107582569, 'loss_2': 0.00033593177795410156, 'loss_3': -16.129310607910156, 'loss_4': 0.17976103723049164, 'epoch': 15.6}
{'loss': 0.0143, 'grad_norm': 4.942204475402832, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.007645281031727791, 'loss_2': 0.006618499755859375, 'loss_3': -16.08406639099121, 'loss_4': 0.09390323609113693, 'epoch': 15.6}
{'loss': 0.0258, 'grad_norm': 9.874446868896484, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.020060056820511818, 'loss_2': 0.005779266357421875, 'loss_3': -16.112377166748047, 'loss_4': 0.00435754656791687, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 16:25:06,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:06,457 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:19<42:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:13,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02907646633684635, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.926, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.020359765738248825, 'eval_loss_2': 0.008716702461242676, 'eval_loss_3': -18.16363525390625, 'eval_loss_4': 0.1659976691007614, 'epoch': 15.61}
{'loss': 0.0141, 'grad_norm': 5.866241931915283, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.010171730071306229, 'loss_2': 0.00394439697265625, 'loss_3': -16.096515655517578, 'loss_4': -0.09802745282649994, 'epoch': 15.62}
{'loss': 0.0199, 'grad_norm': 6.403625965118408, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.010032068938016891, 'loss_2': 0.00989532470703125, 'loss_3': -16.132707595825195, 'loss_4': 0.3175044059753418, 'epoch': 15.62}
{'loss': 0.0131, 'grad_norm': 4.424612045288086, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.004326715134084225, 'loss_2': 0.0087738037109375, 'loss_3': -16.22863006591797, 'loss_4': -0.10805775225162506, 'epoch': 15.63}
{'loss': 0.0196, 'grad_norm': 5.975839614868164, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.013146799057722092, 'loss_2': 0.0064697265625, 'loss_3': -15.955799102783203, 'loss_4': 0.4687894582748413, 'epoch': 15.63}
{'loss': 0.0152, 'grad_norm': 5.309192657470703, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.010496818460524082, 'loss_2': 0.0046539306640625, 'loss_3': -16.30738067626953, 'loss_4': 0.3395342230796814, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 16:25:13,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:13,789 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:26<42:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:21,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02508895844221115, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.894, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018601812422275543, 'eval_loss_2': 0.006487146019935608, 'eval_loss_3': -18.17620277404785, 'eval_loss_4': 0.25692611932754517, 'epoch': 15.64}
{'loss': 0.0272, 'grad_norm': 7.826234340667725, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.01837247796356678, 'loss_2': 0.00879669189453125, 'loss_3': -16.20792007446289, 'loss_4': 0.03307810053229332, 'epoch': 15.65}
{'loss': 0.0129, 'grad_norm': 6.029383182525635, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.007371603511273861, 'loss_2': 0.005542755126953125, 'loss_3': -16.153324127197266, 'loss_4': 0.6009194850921631, 'epoch': 15.65}
{'loss': 0.011, 'grad_norm': 4.919212341308594, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.005181363318115473, 'loss_2': 0.00580596923828125, 'loss_3': -16.2508602142334, 'loss_4': 0.4900307059288025, 'epoch': 15.66}
{'loss': 0.005, 'grad_norm': 4.63642692565918, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.003613054985180497, 'loss_2': 0.0013637542724609375, 'loss_3': -16.300796508789062, 'loss_4': 0.11776761710643768, 'epoch': 15.66}
{'loss': 0.0154, 'grad_norm': 5.641694068908691, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.009331385605037212, 'loss_2': 0.00606536865234375, 'loss_3': -16.167705535888672, 'loss_4': 0.29991260170936584, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 16:25:21,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:21,122 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:33<42:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:28,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021764017641544342, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.954, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.0176604762673378, 'eval_loss_2': 0.004103541374206543, 'eval_loss_3': -18.195703506469727, 'eval_loss_4': 0.25197890400886536, 'epoch': 15.67}
{'loss': 0.0135, 'grad_norm': 7.520174026489258, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.01256386749446392, 'loss_2': 0.0009465217590332031, 'loss_3': -16.39296531677246, 'loss_4': 0.25439518690109253, 'epoch': 15.67}
{'loss': 0.0134, 'grad_norm': 4.457690715789795, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.005704990588128567, 'loss_2': 0.007663726806640625, 'loss_3': -16.296072006225586, 'loss_4': 0.36900797486305237, 'epoch': 15.68}
{'loss': 0.0131, 'grad_norm': 5.180301189422607, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.005933425389230251, 'loss_2': 0.0071868896484375, 'loss_3': -16.327125549316406, 'loss_4': 0.1360253393650055, 'epoch': 15.69}
{'loss': 0.0126, 'grad_norm': 5.208430290222168, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.005628076381981373, 'loss_2': 0.006988525390625, 'loss_3': -16.313804626464844, 'loss_4': -0.1830923855304718, 'epoch': 15.69}
{'loss': 0.0321, 'grad_norm': 10.719818115234375, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.03089469112455845, 'loss_2': 0.0011835098266601562, 'loss_3': -16.36788558959961, 'loss_4': 0.4407450556755066, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 16:25:28,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:28,461 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:41<42:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:35,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02231419086456299, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01879654824733734, 'eval_loss_2': 0.003517642617225647, 'eval_loss_3': -18.193525314331055, 'eval_loss_4': 0.3456180989742279, 'epoch': 15.7}
{'loss': 0.0041, 'grad_norm': 4.571831226348877, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.0036997117567807436, 'loss_2': 0.0004487037658691406, 'loss_3': -16.178178787231445, 'loss_4': 0.22467802464962006, 'epoch': 15.7}
{'loss': 0.0098, 'grad_norm': 5.745857238769531, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.009087776765227318, 'loss_2': 0.0007309913635253906, 'loss_3': -16.209468841552734, 'loss_4': 0.506273627281189, 'epoch': 15.71}
{'loss': 0.0164, 'grad_norm': 5.800230026245117, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.007182485889643431, 'loss_2': 0.00919342041015625, 'loss_3': -16.253480911254883, 'loss_4': 0.40600669384002686, 'epoch': 15.72}
{'loss': 0.0164, 'grad_norm': 8.172014236450195, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.014469203539192677, 'loss_2': 0.0018930435180664062, 'loss_3': -16.304241180419922, 'loss_4': 0.44171467423439026, 'epoch': 15.72}
{'loss': 0.0081, 'grad_norm': 5.882145404815674, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.0077191125601530075, 'loss_2': 0.00041484832763671875, 'loss_3': -16.381101608276367, 'loss_4': 0.5565402507781982, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 16:25:35,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:35,802 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:06:48<42:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:43,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022027675062417984, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01871127262711525, 'eval_loss_2': 0.0033164024353027344, 'eval_loss_3': -18.186086654663086, 'eval_loss_4': 0.31315356492996216, 'epoch': 15.73}
{'loss': 0.0214, 'grad_norm': 12.049966812133789, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.01994350180029869, 'loss_2': 0.0014085769653320312, 'loss_3': -16.22225570678711, 'loss_4': 0.16991859674453735, 'epoch': 15.73}
{'loss': 0.0095, 'grad_norm': 5.519628524780273, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.007461664266884327, 'loss_2': 0.002048492431640625, 'loss_3': -16.105487823486328, 'loss_4': 0.5636066198348999, 'epoch': 15.74}
{'loss': 0.0191, 'grad_norm': 8.297572135925293, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.01773877628147602, 'loss_2': 0.0013704299926757812, 'loss_3': -16.26013946533203, 'loss_4': 0.10528996586799622, 'epoch': 15.74}
{'loss': 0.01, 'grad_norm': 6.100853443145752, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.009236722253262997, 'loss_2': 0.000751495361328125, 'loss_3': -16.13037109375, 'loss_4': 0.14652760326862335, 'epoch': 15.75}
{'loss': 0.01, 'grad_norm': 5.351013660430908, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.008708830922842026, 'loss_2': 0.0013256072998046875, 'loss_3': -16.175458908081055, 'loss_4': 0.3107609748840332, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 16:25:43,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:43,146 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:06:55<42:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:50,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022785475477576256, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.527, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01882123202085495, 'eval_loss_2': 0.003964245319366455, 'eval_loss_3': -18.199562072753906, 'eval_loss_4': 0.2184070497751236, 'epoch': 15.76}
{'loss': 0.012, 'grad_norm': 5.103357315063477, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.008945648558437824, 'loss_2': 0.0030059814453125, 'loss_3': -16.379253387451172, 'loss_4': 0.36845719814300537, 'epoch': 15.76}
{'loss': 0.0187, 'grad_norm': 8.818964004516602, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.0185206588357687, 'loss_2': 0.0001590251922607422, 'loss_3': -16.095523834228516, 'loss_4': 0.4712335467338562, 'epoch': 15.77}
{'loss': 0.0087, 'grad_norm': 4.85579252243042, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.004244986921548843, 'loss_2': 0.0044708251953125, 'loss_3': -16.307626724243164, 'loss_4': 0.34012433886528015, 'epoch': 15.77}
{'loss': 0.0088, 'grad_norm': 5.280574798583984, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.008674546144902706, 'loss_2': 7.975101470947266e-05, 'loss_3': -16.318599700927734, 'loss_4': 0.09503838419914246, 'epoch': 15.78}
{'loss': 0.0081, 'grad_norm': 5.695892333984375, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.007744383066892624, 'loss_2': 0.00035953521728515625, 'loss_3': -16.398468017578125, 'loss_4': 0.35561317205429077, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 16:25:50,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:50,486 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:03<42:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:57,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02273947186768055, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.983, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.019327450543642044, 'eval_loss_2': 0.003412023186683655, 'eval_loss_3': -18.194379806518555, 'eval_loss_4': 0.19876733422279358, 'epoch': 15.78}
{'loss': 0.0077, 'grad_norm': 5.213804244995117, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.007613317109644413, 'loss_2': 0.00012540817260742188, 'loss_3': -16.233905792236328, 'loss_4': 0.12575934827327728, 'epoch': 15.79}
{'loss': 0.0453, 'grad_norm': 15.021464347839355, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.03643345460295677, 'loss_2': 0.0088653564453125, 'loss_3': -16.229249954223633, 'loss_4': 0.18679675459861755, 'epoch': 15.8}
{'loss': 0.0097, 'grad_norm': 5.446176052093506, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.007583276368677616, 'loss_2': 0.0021419525146484375, 'loss_3': -16.2864933013916, 'loss_4': 0.35908985137939453, 'epoch': 15.8}
{'loss': 0.0136, 'grad_norm': 5.943905353546143, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.009214690886437893, 'loss_2': 0.00435638427734375, 'loss_3': -16.261049270629883, 'loss_4': 0.31454259157180786, 'epoch': 15.81}
{'loss': 0.0064, 'grad_norm': 5.157626152038574, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.005994858685880899, 'loss_2': 0.0004496574401855469, 'loss_3': -16.42848014831543, 'loss_4': 0.16959087550640106, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 16:25:57,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:57,820 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:10<42:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:05,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024063225835561752, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.873, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.020437756553292274, 'eval_loss_2': 0.0036254674196243286, 'eval_loss_3': -18.19275665283203, 'eval_loss_4': 0.18975050747394562, 'epoch': 15.81}
{'loss': 0.0118, 'grad_norm': 6.524453163146973, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.008073736913502216, 'loss_2': 0.003704071044921875, 'loss_3': -16.306690216064453, 'loss_4': 0.1214575320482254, 'epoch': 15.82}
{'loss': 0.0084, 'grad_norm': 4.610841751098633, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.007323867175728083, 'loss_2': 0.0011243820190429688, 'loss_3': -16.48733139038086, 'loss_4': 0.25785118341445923, 'epoch': 15.83}
{'loss': 0.0118, 'grad_norm': 5.077111721038818, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.005839083343744278, 'loss_2': 0.00595855712890625, 'loss_3': -16.137964248657227, 'loss_4': 0.16762083768844604, 'epoch': 15.83}
{'loss': 0.0131, 'grad_norm': 4.62088680267334, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.005772939883172512, 'loss_2': 0.00731658935546875, 'loss_3': -16.112457275390625, 'loss_4': 0.28272032737731934, 'epoch': 15.84}
{'loss': 0.0122, 'grad_norm': 5.418802738189697, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.00984064768999815, 'loss_2': 0.00237274169921875, 'loss_3': -16.23297882080078, 'loss_4': -0.01929766684770584, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 16:26:05,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:05,156 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:17<41:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:12,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025029562413692474, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.020787417888641357, 'eval_loss_2': 0.004242144525051117, 'eval_loss_3': -18.19877815246582, 'eval_loss_4': 0.13238763809204102, 'epoch': 15.84}
{'loss': 0.0073, 'grad_norm': 4.36979866027832, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.003990056458860636, 'loss_2': 0.0033397674560546875, 'loss_3': -16.30306625366211, 'loss_4': 0.27663454413414, 'epoch': 15.85}
{'loss': 0.006, 'grad_norm': 5.347218036651611, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.005037982016801834, 'loss_2': 0.0009427070617675781, 'loss_3': -16.197154998779297, 'loss_4': 0.05860179290175438, 'epoch': 15.85}
{'loss': 0.0294, 'grad_norm': 7.710791110992432, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.018052255734801292, 'loss_2': 0.01137542724609375, 'loss_3': -16.269540786743164, 'loss_4': -0.03870505094528198, 'epoch': 15.86}
{'loss': 0.0186, 'grad_norm': 5.676060676574707, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.006764333229511976, 'loss_2': 0.011810302734375, 'loss_3': -16.409652709960938, 'loss_4': 0.10393507778644562, 'epoch': 15.87}
{'loss': 0.0092, 'grad_norm': 6.082924842834473, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.009092217311263084, 'loss_2': 6.073713302612305e-05, 'loss_3': -16.13692855834961, 'loss_4': -0.2085881382226944, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 16:26:12,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:12,484 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:25<41:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:19,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027692275121808052, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.821, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021243935450911522, 'eval_loss_2': 0.006448343396186829, 'eval_loss_3': -18.176855087280273, 'eval_loss_4': -0.05649002268910408, 'epoch': 15.87}
{'loss': 0.0664, 'grad_norm': 13.816995620727539, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.06072111427783966, 'loss_2': 0.00566864013671875, 'loss_3': -16.32280731201172, 'loss_4': 0.2157159447669983, 'epoch': 15.88}
{'loss': 0.0273, 'grad_norm': 11.755608558654785, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.020998505875468254, 'loss_2': 0.0063323974609375, 'loss_3': -16.35184669494629, 'loss_4': 0.12082864344120026, 'epoch': 15.88}
{'loss': 0.0768, 'grad_norm': 12.219017028808594, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.06762886792421341, 'loss_2': 0.009124755859375, 'loss_3': -16.18665313720703, 'loss_4': 0.43482619524002075, 'epoch': 15.89}
{'loss': 0.0228, 'grad_norm': 6.120978355407715, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.01203330047428608, 'loss_2': 0.01080322265625, 'loss_3': -16.210205078125, 'loss_4': -0.02286948636174202, 'epoch': 15.9}
{'loss': 0.0074, 'grad_norm': 4.763759613037109, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.0073426770977675915, 'loss_2': 3.463029861450195e-05, 'loss_3': -16.2642822265625, 'loss_4': -0.7087410688400269, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 16:26:19,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:19,818 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:32<42:33,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:26:27,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02675868570804596, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.618, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02203441970050335, 'eval_loss_2': 0.004724264144897461, 'eval_loss_3': -18.160945892333984, 'eval_loss_4': -0.2136555016040802, 'epoch': 15.9}
{'loss': 0.0169, 'grad_norm': 6.025171756744385, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.01165541261434555, 'loss_2': 0.005218505859375, 'loss_3': -16.108400344848633, 'loss_4': -0.3862384557723999, 'epoch': 15.91}
{'loss': 0.0171, 'grad_norm': 7.629732608795166, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.011660201475024223, 'loss_2': 0.00548553466796875, 'loss_3': -16.277650833129883, 'loss_4': -0.0967019647359848, 'epoch': 15.91}
{'loss': 0.022, 'grad_norm': 7.190231800079346, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.011766749434173107, 'loss_2': 0.01020050048828125, 'loss_3': -16.212583541870117, 'loss_4': -0.155519038438797, 'epoch': 15.92}
{'loss': 0.0106, 'grad_norm': 5.425271511077881, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.009065261110663414, 'loss_2': 0.0015125274658203125, 'loss_3': -16.163009643554688, 'loss_4': -0.9860592484474182, 'epoch': 15.92}
{'loss': 0.0129, 'grad_norm': 5.229885101318359, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.009361441247165203, 'loss_2': 0.003505706787109375, 'loss_3': -16.416954040527344, 'loss_4': -0.4410226345062256, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 16:26:27,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:27,344 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:40<41:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:34,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026327896863222122, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.808, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.020825034007430077, 'eval_loss_2': 0.005502864718437195, 'eval_loss_3': -18.136014938354492, 'eval_loss_4': -0.25572827458381653, 'epoch': 15.93}
{'loss': 0.011, 'grad_norm': 5.178197383880615, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.006404159590601921, 'loss_2': 0.004566192626953125, 'loss_3': -16.131729125976562, 'loss_4': -0.12901419401168823, 'epoch': 15.94}
{'loss': 0.0123, 'grad_norm': 5.048823833465576, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.009447145275771618, 'loss_2': 0.00281524658203125, 'loss_3': -16.272733688354492, 'loss_4': -0.336238294839859, 'epoch': 15.94}
{'loss': 0.0187, 'grad_norm': 4.960488319396973, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.007121693808585405, 'loss_2': 0.0115966796875, 'loss_3': -16.181053161621094, 'loss_4': 0.062424153089523315, 'epoch': 15.95}
{'loss': 0.0089, 'grad_norm': 4.798678874969482, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.006910603027790785, 'loss_2': 0.00196075439453125, 'loss_3': -16.029964447021484, 'loss_4': -0.1915387511253357, 'epoch': 15.95}
{'loss': 0.0087, 'grad_norm': 4.236949443817139, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.006335393525660038, 'loss_2': 0.002376556396484375, 'loss_3': -16.32927894592285, 'loss_4': -0.38471025228500366, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 16:26:34,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:34,676 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:07:47<41:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:42,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024152465164661407, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.689, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01978893019258976, 'eval_loss_2': 0.004363536834716797, 'eval_loss_3': -18.111600875854492, 'eval_loss_4': -0.23134364187717438, 'epoch': 15.96}
{'loss': 0.0145, 'grad_norm': 5.093283653259277, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.009786980226635933, 'loss_2': 0.00469207763671875, 'loss_3': -16.263202667236328, 'loss_4': -0.5059257745742798, 'epoch': 15.97}
{'loss': 0.0144, 'grad_norm': 7.256038188934326, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.012847050093114376, 'loss_2': 0.0015544891357421875, 'loss_3': -16.22314453125, 'loss_4': 0.30636531114578247, 'epoch': 15.97}
{'loss': 0.0116, 'grad_norm': 5.000443458557129, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.007450711447745562, 'loss_2': 0.00417327880859375, 'loss_3': -16.40091323852539, 'loss_4': -0.029920078814029694, 'epoch': 15.98}
{'loss': 0.0061, 'grad_norm': 4.740968704223633, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.005128484219312668, 'loss_2': 0.0010204315185546875, 'loss_3': -16.14437484741211, 'loss_4': -0.24640710651874542, 'epoch': 15.98}
{'loss': 0.0171, 'grad_norm': 6.0333404541015625, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.010891374200582504, 'loss_2': 0.0062103271484375, 'loss_3': -16.156330108642578, 'loss_4': 0.11105319112539291, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 16:26:42,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:42,015 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:07:54<40:21,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:26:49,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02763550542294979, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02155560627579689, 'eval_loss_2': 0.0060798972845077515, 'eval_loss_3': -18.092668533325195, 'eval_loss_4': -0.009836209937930107, 'epoch': 15.99}
{'loss': 0.0195, 'grad_norm': 6.844662189483643, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.010433634743094444, 'loss_2': 0.009033203125, 'loss_3': -16.195938110351562, 'loss_4': -0.08007536828517914, 'epoch': 15.99}
{'loss': 0.0087, 'grad_norm': 6.115316390991211, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.0018139096209779382, 'loss_2': 0.0069122314453125, 'loss_3': -16.234066009521484, 'loss_4': -0.20810578763484955, 'epoch': 16.0}
{'loss': 0.0131, 'grad_norm': 5.315604209899902, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.00638556806370616, 'loss_2': 0.00673675537109375, 'loss_3': -16.262306213378906, 'loss_4': 0.45740431547164917, 'epoch': 16.01}
{'loss': 0.0289, 'grad_norm': 10.456520080566406, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.02024611458182335, 'loss_2': 0.008636474609375, 'loss_3': -16.26041030883789, 'loss_4': 0.32229751348495483, 'epoch': 16.01}
{'loss': 0.0091, 'grad_norm': 4.423137187957764, 'learning_rate': 1.4e-05, 'loss_1': 0.005776848178356886, 'loss_2': 0.003368377685546875, 'loss_3': -16.434158325195312, 'loss_4': -0.2242087870836258, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 16:26:49,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:49,040 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:01<41:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:26:56,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027028558775782585, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.86, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021918978542089462, 'eval_loss_2': 0.005109578371047974, 'eval_loss_3': -18.08595848083496, 'eval_loss_4': 0.10925985872745514, 'epoch': 16.02}
{'loss': 0.0184, 'grad_norm': 9.777000427246094, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.01752404123544693, 'loss_2': 0.0008630752563476562, 'loss_3': -16.17945098876953, 'loss_4': -0.07325948029756546, 'epoch': 16.02}
{'loss': 0.016, 'grad_norm': 6.860093593597412, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.011575606651604176, 'loss_2': 0.004425048828125, 'loss_3': -16.238744735717773, 'loss_4': 0.3229784667491913, 'epoch': 16.03}
{'loss': 0.0139, 'grad_norm': 5.750235080718994, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.0095239682123065, 'loss_2': 0.0043792724609375, 'loss_3': -16.11722183227539, 'loss_4': 0.41743022203445435, 'epoch': 16.03}
{'loss': 0.0163, 'grad_norm': 6.9438629150390625, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.01147970650345087, 'loss_2': 0.00481414794921875, 'loss_3': -16.170127868652344, 'loss_4': 0.4880894720554352, 'epoch': 16.04}
{'loss': 0.0819, 'grad_norm': 19.12418556213379, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.08162170648574829, 'loss_2': 0.00024175643920898438, 'loss_3': -16.32171630859375, 'loss_4': 0.12540066242218018, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 16:26:56,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:56,369 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:09<41:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:03,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025363856926560402, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.733, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02124963141977787, 'eval_loss_2': 0.004114225506782532, 'eval_loss_3': -18.08490753173828, 'eval_loss_4': 0.18569315969944, 'epoch': 16.05}
{'loss': 0.0135, 'grad_norm': 8.231456756591797, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.012511441484093666, 'loss_2': 0.001033782958984375, 'loss_3': -16.134645462036133, 'loss_4': 0.6956261992454529, 'epoch': 16.05}
{'loss': 0.0119, 'grad_norm': 5.372586250305176, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.008058380335569382, 'loss_2': 0.0038356781005859375, 'loss_3': -16.189430236816406, 'loss_4': 0.18674728274345398, 'epoch': 16.06}
{'loss': 0.0115, 'grad_norm': 4.907805442810059, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.005757218226790428, 'loss_2': 0.005718231201171875, 'loss_3': -16.303009033203125, 'loss_4': -0.017792224884033203, 'epoch': 16.06}
{'loss': 0.025, 'grad_norm': 10.981783866882324, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.021703850477933884, 'loss_2': 0.003284454345703125, 'loss_3': -16.051509857177734, 'loss_4': 0.23213036358356476, 'epoch': 16.07}
{'loss': 0.0195, 'grad_norm': 11.443782806396484, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.019327588379383087, 'loss_2': 0.00018513202667236328, 'loss_3': -16.354398727416992, 'loss_4': 0.2220696210861206, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 16:27:03,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:03,706 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:16<41:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:11,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025448303669691086, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.605, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.020983371883630753, 'eval_loss_2': 0.004464931786060333, 'eval_loss_3': -18.085704803466797, 'eval_loss_4': 0.210200235247612, 'epoch': 16.08}
{'loss': 0.008, 'grad_norm': 5.008153915405273, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.007525437045842409, 'loss_2': 0.00043582916259765625, 'loss_3': -16.22030258178711, 'loss_4': 0.3662857115268707, 'epoch': 16.08}
{'loss': 0.0206, 'grad_norm': 6.4240875244140625, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.013562441803514957, 'loss_2': 0.00704193115234375, 'loss_3': -16.439247131347656, 'loss_4': 0.37152257561683655, 'epoch': 16.09}
{'loss': 0.0156, 'grad_norm': 5.490179061889648, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.010118061676621437, 'loss_2': 0.00547027587890625, 'loss_3': -16.120878219604492, 'loss_4': 0.11183484643697739, 'epoch': 16.09}
{'loss': 0.0088, 'grad_norm': 5.0893754959106445, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.006351433228701353, 'loss_2': 0.002460479736328125, 'loss_3': -16.098047256469727, 'loss_4': 0.1358294039964676, 'epoch': 16.1}
{'loss': 0.0074, 'grad_norm': 5.7427287101745605, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.006004053633660078, 'loss_2': 0.0013475418090820312, 'loss_3': -16.313962936401367, 'loss_4': -0.1294717788696289, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 16:27:11,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:11,049 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:23<41:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:18,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02538115158677101, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021108269691467285, 'eval_loss_2': 0.004272878170013428, 'eval_loss_3': -18.089746475219727, 'eval_loss_4': 0.24242620170116425, 'epoch': 16.1}
{'loss': 0.0199, 'grad_norm': 6.4944634437561035, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.01214614324271679, 'loss_2': 0.007755279541015625, 'loss_3': -16.4166202545166, 'loss_4': -0.10593723505735397, 'epoch': 16.11}
{'loss': 0.0148, 'grad_norm': 5.77080774307251, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.00900039728730917, 'loss_2': 0.0058441162109375, 'loss_3': -16.091522216796875, 'loss_4': 0.047824688255786896, 'epoch': 16.12}
{'loss': 0.0176, 'grad_norm': 6.24049711227417, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.013662943616509438, 'loss_2': 0.00394439697265625, 'loss_3': -16.07111358642578, 'loss_4': 0.3309868574142456, 'epoch': 16.12}
{'loss': 0.0055, 'grad_norm': 5.072879791259766, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.0039940085262060165, 'loss_2': 0.0015020370483398438, 'loss_3': -16.27440643310547, 'loss_4': 0.3457387089729309, 'epoch': 16.13}
{'loss': 0.0157, 'grad_norm': 6.1365485191345215, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.008270522579550743, 'loss_2': 0.00739288330078125, 'loss_3': -16.30899429321289, 'loss_4': -0.05750398337841034, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 16:27:18,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:18,377 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:31<41:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:25,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024381471797823906, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.829, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01996440999209881, 'eval_loss_2': 0.004417061805725098, 'eval_loss_3': -18.138505935668945, 'eval_loss_4': 0.21110548079013824, 'epoch': 16.13}
{'loss': 0.0141, 'grad_norm': 7.511993408203125, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.011645551770925522, 'loss_2': 0.00241851806640625, 'loss_3': -16.138389587402344, 'loss_4': 0.14613685011863708, 'epoch': 16.14}
{'loss': 0.0325, 'grad_norm': 12.900769233703613, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.030471133068203926, 'loss_2': 0.002048492431640625, 'loss_3': -16.108421325683594, 'loss_4': 0.09619565308094025, 'epoch': 16.15}
{'loss': 0.0065, 'grad_norm': 4.711023330688477, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.004881802015006542, 'loss_2': 0.0015897750854492188, 'loss_3': -16.37161636352539, 'loss_4': 0.08083763718605042, 'epoch': 16.15}
{'loss': 0.0224, 'grad_norm': 10.362536430358887, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.021897684782743454, 'loss_2': 0.0004634857177734375, 'loss_3': -16.141340255737305, 'loss_4': 0.06531789898872375, 'epoch': 16.16}
{'loss': 0.0145, 'grad_norm': 4.881317138671875, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.003939910791814327, 'loss_2': 0.01053619384765625, 'loss_3': -16.237401962280273, 'loss_4': 0.17609673738479614, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 16:27:25,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:25,719 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:38<41:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:33,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02508000284433365, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02057339996099472, 'eval_loss_2': 0.004506602883338928, 'eval_loss_3': -18.14335823059082, 'eval_loss_4': 0.1610085666179657, 'epoch': 16.16}
{'loss': 0.0093, 'grad_norm': 5.1529436111450195, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.005049847532063723, 'loss_2': 0.004291534423828125, 'loss_3': -16.272043228149414, 'loss_4': -0.27759116888046265, 'epoch': 16.17}
{'loss': 0.017, 'grad_norm': 10.521203994750977, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.016578158363699913, 'loss_2': 0.00045871734619140625, 'loss_3': -16.354698181152344, 'loss_4': 0.17325332760810852, 'epoch': 16.17}
{'loss': 0.0135, 'grad_norm': 6.494261264801025, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.012433655560016632, 'loss_2': 0.0011129379272460938, 'loss_3': -16.033781051635742, 'loss_4': 0.4235261380672455, 'epoch': 16.18}
{'loss': 0.015, 'grad_norm': 13.162344932556152, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.01315357442945242, 'loss_2': 0.0018777847290039062, 'loss_3': -16.115127563476562, 'loss_4': 0.33866995573043823, 'epoch': 16.19}
{'loss': 0.0133, 'grad_norm': 8.583640098571777, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.010727791115641594, 'loss_2': 0.0025787353515625, 'loss_3': -16.251388549804688, 'loss_4': 0.06704594939947128, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 16:27:33,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:33,056 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:08:45<41:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:40,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024331239983439445, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.489, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.019929884001612663, 'eval_loss_2': 0.004401355981826782, 'eval_loss_3': -18.138341903686523, 'eval_loss_4': 0.14042651653289795, 'epoch': 16.19}
{'loss': 0.0111, 'grad_norm': 5.03790807723999, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.007759504020214081, 'loss_2': 0.003387451171875, 'loss_3': -16.308443069458008, 'loss_4': -0.048976972699165344, 'epoch': 16.2}
{'loss': 0.0144, 'grad_norm': 7.14628267288208, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.011838536709547043, 'loss_2': 0.002574920654296875, 'loss_3': -16.03773307800293, 'loss_4': 0.11284508556127548, 'epoch': 16.2}
{'loss': 0.0145, 'grad_norm': 6.999091148376465, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.011535258032381535, 'loss_2': 0.0029201507568359375, 'loss_3': -16.3570556640625, 'loss_4': -0.07885421812534332, 'epoch': 16.21}
{'loss': 0.0128, 'grad_norm': 5.124416828155518, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.006734941154718399, 'loss_2': 0.00608062744140625, 'loss_3': -16.294883728027344, 'loss_4': -0.0006250180304050446, 'epoch': 16.22}
{'loss': 0.0122, 'grad_norm': 6.194590091705322, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.008852086029946804, 'loss_2': 0.003330230712890625, 'loss_3': -16.16407012939453, 'loss_4': -0.05090290307998657, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 16:27:40,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:40,403 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:08:53<40:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:47,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02473391592502594, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019716575741767883, 'eval_loss_2': 0.005017340183258057, 'eval_loss_3': -18.12684440612793, 'eval_loss_4': 0.14263203740119934, 'epoch': 16.22}
{'loss': 0.0276, 'grad_norm': 9.048175811767578, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.02610204927623272, 'loss_2': 0.0015115737915039062, 'loss_3': -16.229217529296875, 'loss_4': 0.32775068283081055, 'epoch': 16.23}
{'loss': 0.0171, 'grad_norm': 4.754846572875977, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.008665477856993675, 'loss_2': 0.0084381103515625, 'loss_3': -16.202754974365234, 'loss_4': 0.33227241039276123, 'epoch': 16.23}
{'loss': 0.0136, 'grad_norm': 5.410109519958496, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.011718623340129852, 'loss_2': 0.001842498779296875, 'loss_3': -16.26475715637207, 'loss_4': 0.2112967073917389, 'epoch': 16.24}
{'loss': 0.0123, 'grad_norm': 4.6142449378967285, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.007043591700494289, 'loss_2': 0.00524139404296875, 'loss_3': -16.153160095214844, 'loss_4': -0.29189902544021606, 'epoch': 16.24}
{'loss': 0.0112, 'grad_norm': 5.062502861022949, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.005728241056203842, 'loss_2': 0.0054779052734375, 'loss_3': -16.3032169342041, 'loss_4': 0.1670593023300171, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 16:27:47,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:47,739 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:00<40:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:55,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025336958467960358, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.955, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.021010616794228554, 'eval_loss_2': 0.004326343536376953, 'eval_loss_3': -18.12569808959961, 'eval_loss_4': 0.14836189150810242, 'epoch': 16.25}
{'loss': 0.0173, 'grad_norm': 7.2537970542907715, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.011195087805390358, 'loss_2': 0.00612640380859375, 'loss_3': -16.082136154174805, 'loss_4': 0.030804336071014404, 'epoch': 16.26}
{'loss': 0.0168, 'grad_norm': 8.967085838317871, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.015231925062835217, 'loss_2': 0.0015697479248046875, 'loss_3': -16.182146072387695, 'loss_4': 0.2756413221359253, 'epoch': 16.26}
{'loss': 0.0092, 'grad_norm': 5.829061031341553, 'learning_rate': 1.375e-05, 'loss_1': 0.007349787745624781, 'loss_2': 0.0018138885498046875, 'loss_3': -16.258480072021484, 'loss_4': 0.4094245135784149, 'epoch': 16.27}
{'loss': 0.016, 'grad_norm': 7.1956939697265625, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.011898146010935307, 'loss_2': 0.0041351318359375, 'loss_3': -16.17593002319336, 'loss_4': 0.05447184294462204, 'epoch': 16.27}
{'loss': 0.0089, 'grad_norm': 5.154912948608398, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.007497277110815048, 'loss_2': 0.00138092041015625, 'loss_3': -16.192134857177734, 'loss_4': 0.3429529070854187, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 16:27:55,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:55,071 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:07<40:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:02,412 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025916606187820435, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.835, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021936390548944473, 'eval_loss_2': 0.00398021936416626, 'eval_loss_3': -18.118011474609375, 'eval_loss_4': 0.1458061784505844, 'epoch': 16.28}
{'loss': 0.01, 'grad_norm': 7.267586708068848, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.009098375216126442, 'loss_2': 0.0009016990661621094, 'loss_3': -16.073814392089844, 'loss_4': -0.28520432114601135, 'epoch': 16.28}
{'loss': 0.0111, 'grad_norm': 7.287327289581299, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.008880805224180222, 'loss_2': 0.00217437744140625, 'loss_3': -16.333171844482422, 'loss_4': -0.009950220584869385, 'epoch': 16.29}
{'loss': 0.0257, 'grad_norm': 6.093552589416504, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.013606159016489983, 'loss_2': 0.0120849609375, 'loss_3': -16.148366928100586, 'loss_4': 0.0359460711479187, 'epoch': 16.3}
{'loss': 0.0175, 'grad_norm': 5.274052619934082, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.008779182098805904, 'loss_2': 0.00875091552734375, 'loss_3': -16.46497344970703, 'loss_4': 0.03917348012328148, 'epoch': 16.3}
{'loss': 0.0279, 'grad_norm': 16.02800941467285, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.021903283894062042, 'loss_2': 0.005950927734375, 'loss_3': -16.07522201538086, 'loss_4': 0.13093098998069763, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 16:28:02,412 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:02,412 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:15<40:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:09,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028029775246977806, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.856, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.02153569832444191, 'eval_loss_2': 0.006494075059890747, 'eval_loss_3': -18.120315551757812, 'eval_loss_4': 0.13428956270217896, 'epoch': 16.31}
{'loss': 0.0156, 'grad_norm': 5.078352928161621, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.008368901908397675, 'loss_2': 0.00719451904296875, 'loss_3': -16.288650512695312, 'loss_4': -0.09659678488969803, 'epoch': 16.31}
{'loss': 0.0211, 'grad_norm': 5.774413108825684, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.014079801738262177, 'loss_2': 0.00701904296875, 'loss_3': -16.309268951416016, 'loss_4': 0.5556643009185791, 'epoch': 16.32}
{'loss': 0.0142, 'grad_norm': 5.867401599884033, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.01362900622189045, 'loss_2': 0.0005245208740234375, 'loss_3': -16.300270080566406, 'loss_4': 0.14750678837299347, 'epoch': 16.33}
{'loss': 0.0169, 'grad_norm': 6.097907066345215, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.0167668666690588, 'loss_2': 0.00014078617095947266, 'loss_3': -16.074172973632812, 'loss_4': -0.3649723529815674, 'epoch': 16.33}
{'loss': 0.0141, 'grad_norm': 6.155980110168457, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.012876822613179684, 'loss_2': 0.0012226104736328125, 'loss_3': -16.230724334716797, 'loss_4': -0.14656245708465576, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 16:28:09,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:09,745 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:22<40:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:17,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02751709707081318, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.93, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.022902412340044975, 'eval_loss_2': 0.004614684730768204, 'eval_loss_3': -18.125694274902344, 'eval_loss_4': 0.0611724928021431, 'epoch': 16.34}
{'loss': 0.0103, 'grad_norm': 4.425526142120361, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.006888695061206818, 'loss_2': 0.0033702850341796875, 'loss_3': -16.3609676361084, 'loss_4': 0.04785504192113876, 'epoch': 16.34}
{'loss': 0.0085, 'grad_norm': 5.0926690101623535, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.007728967349976301, 'loss_2': 0.00080108642578125, 'loss_3': -16.154460906982422, 'loss_4': 0.5459851026535034, 'epoch': 16.35}
{'loss': 0.0216, 'grad_norm': 14.423028945922852, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.0163380466401577, 'loss_2': 0.00527191162109375, 'loss_3': -16.133413314819336, 'loss_4': -0.011464744806289673, 'epoch': 16.35}
{'loss': 0.0186, 'grad_norm': 7.583089351654053, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.014055133797228336, 'loss_2': 0.0045013427734375, 'loss_3': -16.278345108032227, 'loss_4': 0.15383103489875793, 'epoch': 16.36}
{'loss': 0.0099, 'grad_norm': 5.263413906097412, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.006231280509382486, 'loss_2': 0.003696441650390625, 'loss_3': -16.407480239868164, 'loss_4': -0.005612224340438843, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 16:28:17,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:17,082 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:29<40:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:24,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026260383427143097, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.021939733996987343, 'eval_loss_2': 0.004320651292800903, 'eval_loss_3': -18.13252067565918, 'eval_loss_4': 0.019914213567972183, 'epoch': 16.37}
{'loss': 0.0192, 'grad_norm': 8.526082038879395, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.018186943605542183, 'loss_2': 0.0010480880737304688, 'loss_3': -16.15532684326172, 'loss_4': -0.07706712931394577, 'epoch': 16.37}
{'loss': 0.0177, 'grad_norm': 5.823362827301025, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.013298384845256805, 'loss_2': 0.00438690185546875, 'loss_3': -16.323162078857422, 'loss_4': 0.008122742176055908, 'epoch': 16.38}
{'loss': 0.0137, 'grad_norm': 7.388204574584961, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.01120145432651043, 'loss_2': 0.002513885498046875, 'loss_3': -16.26639175415039, 'loss_4': 0.21254432201385498, 'epoch': 16.38}
{'loss': 0.0124, 'grad_norm': 4.821498870849609, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.006118972785770893, 'loss_2': 0.00629425048828125, 'loss_3': -16.05567741394043, 'loss_4': -0.10047471523284912, 'epoch': 16.39}
{'loss': 0.0138, 'grad_norm': 5.750057697296143, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.012345129624009132, 'loss_2': 0.001491546630859375, 'loss_3': -16.177906036376953, 'loss_4': 0.2611619830131531, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 16:28:24,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:24,430 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:37<40:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:31,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027648165822029114, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.807, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02229943871498108, 'eval_loss_2': 0.005348727107048035, 'eval_loss_3': -18.155540466308594, 'eval_loss_4': 0.07345715910196304, 'epoch': 16.4}
{'loss': 0.0185, 'grad_norm': 8.493791580200195, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.011715959757566452, 'loss_2': 0.00681304931640625, 'loss_3': -16.054304122924805, 'loss_4': 0.1498618721961975, 'epoch': 16.4}
{'loss': 0.0144, 'grad_norm': 4.9410271644592285, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.008983360603451729, 'loss_2': 0.00543212890625, 'loss_3': -16.32370376586914, 'loss_4': 0.17942501604557037, 'epoch': 16.41}
{'loss': 0.0154, 'grad_norm': 5.454463958740234, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.010180069133639336, 'loss_2': 0.005268096923828125, 'loss_3': -16.114139556884766, 'loss_4': -0.2431621551513672, 'epoch': 16.41}
{'loss': 0.0153, 'grad_norm': 4.967524528503418, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.007207159418612719, 'loss_2': 0.00807952880859375, 'loss_3': -16.369766235351562, 'loss_4': 0.1534268707036972, 'epoch': 16.42}
{'loss': 0.0224, 'grad_norm': 13.946435928344727, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.021339526399970055, 'loss_2': 0.0010223388671875, 'loss_3': -16.04738998413086, 'loss_4': -0.35760802030563354, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 16:28:31,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:31,769 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:09:44<40:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:39,101 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02753630466759205, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.023223523050546646, 'eval_loss_2': 0.004312783479690552, 'eval_loss_3': -18.11179542541504, 'eval_loss_4': 0.15561068058013916, 'epoch': 16.42}
{'loss': 0.0073, 'grad_norm': 4.5738019943237305, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.005941330920904875, 'loss_2': 0.0013446807861328125, 'loss_3': -16.158592224121094, 'loss_4': 0.18160831928253174, 'epoch': 16.43}
{'loss': 0.0071, 'grad_norm': 4.654820919036865, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.0065828245133161545, 'loss_2': 0.0004825592041015625, 'loss_3': -16.11830711364746, 'loss_4': 0.0014171376824378967, 'epoch': 16.44}
{'loss': 0.0098, 'grad_norm': 4.663363456726074, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.005292787682265043, 'loss_2': 0.004528045654296875, 'loss_3': -16.01396369934082, 'loss_4': 0.3305169343948364, 'epoch': 16.44}
{'loss': 0.0169, 'grad_norm': 5.570150852203369, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.008806218393146992, 'loss_2': 0.0081024169921875, 'loss_3': -16.08686065673828, 'loss_4': -0.032713040709495544, 'epoch': 16.45}
{'loss': 0.0158, 'grad_norm': 7.324251174926758, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.011214537546038628, 'loss_2': 0.004581451416015625, 'loss_3': -16.195873260498047, 'loss_4': 0.4346311092376709, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 16:28:39,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:39,101 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:09:51<40:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:46,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.044323842972517014, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.907, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.04042743146419525, 'eval_loss_2': 0.0038964152336120605, 'eval_loss_3': -18.00417709350586, 'eval_loss_4': 0.3411214053630829, 'epoch': 16.45}
{'loss': 0.0088, 'grad_norm': 6.124179840087891, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.007944882847368717, 'loss_2': 0.0008115768432617188, 'loss_3': -16.090038299560547, 'loss_4': 0.02506422996520996, 'epoch': 16.46}
{'loss': 0.0379, 'grad_norm': 16.42436408996582, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.036878131330013275, 'loss_2': 0.0010137557983398438, 'loss_3': -16.259626388549805, 'loss_4': 0.0669739842414856, 'epoch': 16.47}
{'loss': 0.0077, 'grad_norm': 4.850247383117676, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.0074118152260780334, 'loss_2': 0.0002741813659667969, 'loss_3': -16.1129150390625, 'loss_4': 0.25200507044792175, 'epoch': 16.47}
{'loss': 0.0991, 'grad_norm': 21.38286018371582, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.09820803999900818, 'loss_2': 0.0009007453918457031, 'loss_3': -15.850667953491211, 'loss_4': 0.3805862367153168, 'epoch': 16.48}
{'loss': 0.0183, 'grad_norm': 7.245558261871338, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.015725143253803253, 'loss_2': 0.0026092529296875, 'loss_3': -16.218299865722656, 'loss_4': 0.17531746625900269, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 16:28:46,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:46,431 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:09:59<40:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:53,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06513211876153946, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.913, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0617913082242012, 'eval_loss_2': 0.003340810537338257, 'eval_loss_3': -17.878215789794922, 'eval_loss_4': 0.46035292744636536, 'epoch': 16.48}
{'loss': 0.0304, 'grad_norm': 14.698871612548828, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.027559630572795868, 'loss_2': 0.002864837646484375, 'loss_3': -15.734162330627441, 'loss_4': 0.2870689332485199, 'epoch': 16.49}
{'loss': 0.0217, 'grad_norm': 5.533774375915527, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.020938286557793617, 'loss_2': 0.00078582763671875, 'loss_3': -16.094409942626953, 'loss_4': 0.5443331003189087, 'epoch': 16.49}
{'loss': 0.0357, 'grad_norm': 7.055023193359375, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.020948776975274086, 'loss_2': 0.0147857666015625, 'loss_3': -15.853675842285156, 'loss_4': 0.4536312222480774, 'epoch': 16.5}
{'loss': 0.0318, 'grad_norm': 10.69443130493164, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.022478865459561348, 'loss_2': 0.009368896484375, 'loss_3': -15.982681274414062, 'loss_4': 0.35113194584846497, 'epoch': 16.51}
{'loss': 0.0092, 'grad_norm': 4.797990798950195, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.007500908337533474, 'loss_2': 0.0016927719116210938, 'loss_3': -16.05103874206543, 'loss_4': 0.5660207867622375, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 16:28:53,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:53,770 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:06<39:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:01,104 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0772009789943695, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.536, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.07432939857244492, 'eval_loss_2': 0.002871587872505188, 'eval_loss_3': -17.83683204650879, 'eval_loss_4': 0.5341612100601196, 'epoch': 16.51}
{'loss': 0.042, 'grad_norm': inf, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.0370023287832737, 'loss_2': 0.004955291748046875, 'loss_3': -16.045204162597656, 'loss_4': 0.17227739095687866, 'epoch': 16.52}
{'loss': 0.0598, 'grad_norm': 22.402509689331055, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.05713867396116257, 'loss_2': 0.0026493072509765625, 'loss_3': -16.02406883239746, 'loss_4': 0.9280954003334045, 'epoch': 16.52}
{'loss': 0.0164, 'grad_norm': 8.280990600585938, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.012126105837523937, 'loss_2': 0.004241943359375, 'loss_3': -16.023990631103516, 'loss_4': 0.37450650334358215, 'epoch': 16.53}
{'loss': 0.0153, 'grad_norm': 6.440679550170898, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.014405022375285625, 'loss_2': 0.0009107589721679688, 'loss_3': -16.055068969726562, 'loss_4': 0.6267118453979492, 'epoch': 16.53}
{'loss': 0.0665, 'grad_norm': 24.1285343170166, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.06509336829185486, 'loss_2': 0.001434326171875, 'loss_3': -16.178804397583008, 'loss_4': 0.6942479610443115, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 16:29:01,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:01,105 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:13<39:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:08,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07369603216648102, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.06957414001226425, 'eval_loss_2': 0.004121899604797363, 'eval_loss_3': -17.859071731567383, 'eval_loss_4': 0.5922483205795288, 'epoch': 16.54}
{'loss': 0.0098, 'grad_norm': 5.018616199493408, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.0054156724363565445, 'loss_2': 0.00434112548828125, 'loss_3': -16.1954402923584, 'loss_4': 0.6707804799079895, 'epoch': 16.55}
{'loss': 0.0167, 'grad_norm': 4.658058166503906, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.007409224286675453, 'loss_2': 0.0092620849609375, 'loss_3': -15.983577728271484, 'loss_4': -0.03876388072967529, 'epoch': 16.55}
{'loss': 0.0214, 'grad_norm': 9.349040031433105, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.016287285834550858, 'loss_2': 0.005092620849609375, 'loss_3': -16.068767547607422, 'loss_4': 0.5670027732849121, 'epoch': 16.56}
{'loss': 0.0146, 'grad_norm': 5.341909408569336, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.01115829311311245, 'loss_2': 0.003482818603515625, 'loss_3': -16.24933433532715, 'loss_4': 0.6338335871696472, 'epoch': 16.56}
{'loss': 0.0075, 'grad_norm': 5.45347261428833, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.007094568107277155, 'loss_2': 0.0003743171691894531, 'loss_3': -15.953666687011719, 'loss_4': 0.5131740570068359, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 16:29:08,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:08,435 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:21<39:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:15,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09273897856473923, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.714, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.08775459229946136, 'eval_loss_2': 0.004984378814697266, 'eval_loss_3': -17.788354873657227, 'eval_loss_4': 0.7119939923286438, 'epoch': 16.57}
{'loss': 0.0423, 'grad_norm': 46.340763092041016, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.038744501769542694, 'loss_2': 0.003559112548828125, 'loss_3': -15.9169921875, 'loss_4': 0.20341390371322632, 'epoch': 16.58}
{'loss': 0.0225, 'grad_norm': 11.825857162475586, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.0192733071744442, 'loss_2': 0.0032024383544921875, 'loss_3': -15.96845817565918, 'loss_4': 0.774714469909668, 'epoch': 16.58}
{'loss': 0.0319, 'grad_norm': 11.66423511505127, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.0313589982688427, 'loss_2': 0.0005426406860351562, 'loss_3': -15.837079048156738, 'loss_4': 1.0700021982192993, 'epoch': 16.59}
{'loss': 0.0097, 'grad_norm': 6.5234456062316895, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.008798041380941868, 'loss_2': 0.000858306884765625, 'loss_3': -15.971977233886719, 'loss_4': 0.5519979596138, 'epoch': 16.59}
{'loss': 0.0094, 'grad_norm': 6.6504316329956055, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.006642408203333616, 'loss_2': 0.0027866363525390625, 'loss_3': -16.234088897705078, 'loss_4': 0.7172425985336304, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 16:29:15,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:15,775 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:28<39:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:23,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030275410041213036, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.91, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.026065541431307793, 'eval_loss_2': 0.004209868609905243, 'eval_loss_3': -18.056114196777344, 'eval_loss_4': 0.5751802325248718, 'epoch': 16.6}
{'loss': 0.0088, 'grad_norm': 5.488251209259033, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.008313474245369434, 'loss_2': 0.0004749298095703125, 'loss_3': -16.222564697265625, 'loss_4': 0.5785560607910156, 'epoch': 16.6}
{'loss': 0.02, 'grad_norm': 8.62558650970459, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.012090829201042652, 'loss_2': 0.0078887939453125, 'loss_3': -16.131669998168945, 'loss_4': 0.3783484101295471, 'epoch': 16.61}
{'loss': 0.0082, 'grad_norm': 5.68841028213501, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.006548147648572922, 'loss_2': 0.001636505126953125, 'loss_3': -16.153766632080078, 'loss_4': 0.6606242060661316, 'epoch': 16.62}
{'loss': 0.0278, 'grad_norm': 12.286784172058105, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.026889558881521225, 'loss_2': 0.0009565353393554688, 'loss_3': -15.96832275390625, 'loss_4': 0.6394087076187134, 'epoch': 16.62}
{'loss': 0.0098, 'grad_norm': 5.0886383056640625, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.006846987176686525, 'loss_2': 0.0029468536376953125, 'loss_3': -16.23180389404297, 'loss_4': 0.9699360728263855, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 16:29:23,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:23,111 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:35<39:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:30,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02210213616490364, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.77, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017058415338397026, 'eval_loss_2': 0.005043722689151764, 'eval_loss_3': -18.15959930419922, 'eval_loss_4': 0.7094124555587769, 'epoch': 16.63}
{'loss': 0.0377, 'grad_norm': 11.98124885559082, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.026178579777479172, 'loss_2': 0.011505126953125, 'loss_3': -15.981971740722656, 'loss_4': 0.929324209690094, 'epoch': 16.63}
{'loss': 0.017, 'grad_norm': 9.372154235839844, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.011588196270167828, 'loss_2': 0.005401611328125, 'loss_3': -16.314672470092773, 'loss_4': 1.2286065816879272, 'epoch': 16.64}
{'loss': 0.0128, 'grad_norm': 5.332683086395264, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.007405661512166262, 'loss_2': 0.005401611328125, 'loss_3': -16.31151008605957, 'loss_4': 0.9328938722610474, 'epoch': 16.65}
{'loss': 0.0095, 'grad_norm': 4.43625020980835, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.0037944773212075233, 'loss_2': 0.0057373046875, 'loss_3': -16.116491317749023, 'loss_4': 0.963096022605896, 'epoch': 16.65}
{'loss': 0.0051, 'grad_norm': 5.240485668182373, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.004731802735477686, 'loss_2': 0.0003914833068847656, 'loss_3': -16.09394645690918, 'loss_4': 1.0324978828430176, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 16:29:30,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:30,449 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:43<39:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:37,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022085387259721756, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.979, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.015880128368735313, 'eval_loss_2': 0.006205260753631592, 'eval_loss_3': -18.199443817138672, 'eval_loss_4': 0.9421655535697937, 'epoch': 16.66}
{'loss': 0.0157, 'grad_norm': 6.209053993225098, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.013005116954445839, 'loss_2': 0.002735137939453125, 'loss_3': -16.157230377197266, 'loss_4': 0.9664422869682312, 'epoch': 16.66}
{'loss': 0.0164, 'grad_norm': 5.284154891967773, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.011187932454049587, 'loss_2': 0.0052032470703125, 'loss_3': -16.198915481567383, 'loss_4': 1.4880170822143555, 'epoch': 16.67}
{'loss': 0.0162, 'grad_norm': 5.532314300537109, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.00925432052463293, 'loss_2': 0.0069427490234375, 'loss_3': -16.34661102294922, 'loss_4': 0.7649273872375488, 'epoch': 16.67}
{'loss': 0.0361, 'grad_norm': 12.63499641418457, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.028167279437184334, 'loss_2': 0.0079193115234375, 'loss_3': -16.055479049682617, 'loss_4': 1.508500337600708, 'epoch': 16.68}
{'loss': 0.0207, 'grad_norm': 8.492189407348633, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.01802120730280876, 'loss_2': 0.0026416778564453125, 'loss_3': -16.08511734008789, 'loss_4': 1.142695665359497, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 16:29:37,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:37,790 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:10:50<39:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:45,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018792256712913513, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014554143883287907, 'eval_loss_2': 0.004238113760948181, 'eval_loss_3': -18.20964813232422, 'eval_loss_4': 1.067295789718628, 'epoch': 16.69}
{'loss': 0.0123, 'grad_norm': 5.541228771209717, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.009090841747820377, 'loss_2': 0.0032024383544921875, 'loss_3': -16.399076461791992, 'loss_4': 1.1703795194625854, 'epoch': 16.69}
{'loss': 0.0285, 'grad_norm': 12.756646156311035, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.02440909668803215, 'loss_2': 0.00411224365234375, 'loss_3': -16.055950164794922, 'loss_4': 1.344797968864441, 'epoch': 16.7}
{'loss': 0.0154, 'grad_norm': 5.113608360290527, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.005643559619784355, 'loss_2': 0.00975799560546875, 'loss_3': -16.211265563964844, 'loss_4': 1.3701543807983398, 'epoch': 16.7}
{'loss': 0.0271, 'grad_norm': 11.839105606079102, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.020567461848258972, 'loss_2': 0.006526947021484375, 'loss_3': -16.227569580078125, 'loss_4': 1.084479808807373, 'epoch': 16.71}
{'loss': 0.0129, 'grad_norm': 5.308232307434082, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.0109653789550066, 'loss_2': 0.0019092559814453125, 'loss_3': -16.15580177307129, 'loss_4': 0.7303736209869385, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 16:29:45,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:45,134 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:10:57<39:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:52,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020984768867492676, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.864, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016721108928322792, 'eval_loss_2': 0.0042636580765247345, 'eval_loss_3': -18.227205276489258, 'eval_loss_4': 1.3188763856887817, 'epoch': 16.72}
{'loss': 0.0148, 'grad_norm': 8.185044288635254, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.009731312282383442, 'loss_2': 0.005100250244140625, 'loss_3': -16.431520462036133, 'loss_4': 1.4342416524887085, 'epoch': 16.72}
{'loss': 0.0298, 'grad_norm': 8.900660514831543, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.02004142291843891, 'loss_2': 0.009765625, 'loss_3': -16.41167640686035, 'loss_4': 1.2723524570465088, 'epoch': 16.73}
{'loss': 0.0293, 'grad_norm': 9.21338939666748, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.02089053764939308, 'loss_2': 0.0084075927734375, 'loss_3': -16.363059997558594, 'loss_4': 1.5424096584320068, 'epoch': 16.73}
{'loss': 0.0438, 'grad_norm': 32.461692810058594, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.03597242385149002, 'loss_2': 0.00785064697265625, 'loss_3': -16.222789764404297, 'loss_4': 2.189833641052246, 'epoch': 16.74}
{'loss': 0.0066, 'grad_norm': 4.861378192901611, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.0053915539756417274, 'loss_2': 0.0011749267578125, 'loss_3': -16.149368286132812, 'loss_4': 0.9398126602172852, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 16:29:52,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:52,474 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:05<39:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:59,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01867600530385971, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.985, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014269612729549408, 'eval_loss_2': 0.004406392574310303, 'eval_loss_3': -18.221420288085938, 'eval_loss_4': 1.2101123332977295, 'epoch': 16.74}
{'loss': 0.0181, 'grad_norm': 11.067728996276855, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.015910958871245384, 'loss_2': 0.002155303955078125, 'loss_3': -16.42742919921875, 'loss_4': 1.5932137966156006, 'epoch': 16.75}
{'loss': 0.0281, 'grad_norm': 14.674759864807129, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.021285496652126312, 'loss_2': 0.00685882568359375, 'loss_3': -16.219783782958984, 'loss_4': 1.3997212648391724, 'epoch': 16.76}
{'loss': 0.019, 'grad_norm': 5.6384992599487305, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.012314967811107635, 'loss_2': 0.006717681884765625, 'loss_3': -16.20041847229004, 'loss_4': 1.4669748544692993, 'epoch': 16.76}
{'loss': 0.0101, 'grad_norm': 4.933906078338623, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.0065956637263298035, 'loss_2': 0.0035247802734375, 'loss_3': -16.270122528076172, 'loss_4': 1.3342244625091553, 'epoch': 16.77}
{'loss': 0.0142, 'grad_norm': 4.992412567138672, 'learning_rate': 1.325e-05, 'loss_1': 0.012212196364998817, 'loss_2': 0.0019464492797851562, 'loss_3': -16.33815574645996, 'loss_4': 1.24211585521698, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 16:29:59,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:59,805 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:12<39:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:07,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016769250854849815, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.047, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013766244053840637, 'eval_loss_2': 0.0030030086636543274, 'eval_loss_3': -18.22854232788086, 'eval_loss_4': 1.0561639070510864, 'epoch': 16.77}
{'loss': 0.0144, 'grad_norm': 7.070417404174805, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.013534016907215118, 'loss_2': 0.0008802413940429688, 'loss_3': -16.103071212768555, 'loss_4': 0.8986120223999023, 'epoch': 16.78}
{'loss': 0.0217, 'grad_norm': 8.381839752197266, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.019224783405661583, 'loss_2': 0.0025177001953125, 'loss_3': -16.17904281616211, 'loss_4': 1.0465734004974365, 'epoch': 16.78}
{'loss': 0.0119, 'grad_norm': 6.04385232925415, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.01005546748638153, 'loss_2': 0.001811981201171875, 'loss_3': -16.151676177978516, 'loss_4': 1.137030839920044, 'epoch': 16.79}
{'loss': 0.0133, 'grad_norm': 5.392253875732422, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.010098889470100403, 'loss_2': 0.0031871795654296875, 'loss_3': -16.214086532592773, 'loss_4': 1.170972228050232, 'epoch': 16.8}
{'loss': 0.0112, 'grad_norm': 4.6868696212768555, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.006474816706031561, 'loss_2': 0.004680633544921875, 'loss_3': -16.4384765625, 'loss_4': 0.7466702461242676, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 16:30:07,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:07,138 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:19<39:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:14,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02022481895983219, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.776, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01599116623401642, 'eval_loss_2': 0.004233650863170624, 'eval_loss_3': -18.218637466430664, 'eval_loss_4': 0.9307531714439392, 'epoch': 16.8}
{'loss': 0.013, 'grad_norm': 5.191872596740723, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.008214435540139675, 'loss_2': 0.00473785400390625, 'loss_3': -16.151906967163086, 'loss_4': 1.0797412395477295, 'epoch': 16.81}
{'loss': 0.013, 'grad_norm': 5.146373748779297, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.010456835851073265, 'loss_2': 0.00250244140625, 'loss_3': -16.281251907348633, 'loss_4': 1.253813624382019, 'epoch': 16.81}
{'loss': 0.011, 'grad_norm': 4.895185470581055, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.006082192528992891, 'loss_2': 0.0048980712890625, 'loss_3': -16.20022964477539, 'loss_4': 0.8712925910949707, 'epoch': 16.82}
{'loss': 0.0104, 'grad_norm': 5.254944324493408, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.008096212521195412, 'loss_2': 0.0022602081298828125, 'loss_3': -16.103984832763672, 'loss_4': 0.951170802116394, 'epoch': 16.83}
{'loss': 0.0217, 'grad_norm': 7.249142646789551, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.014286158606410027, 'loss_2': 0.007396697998046875, 'loss_3': -16.207355499267578, 'loss_4': 0.8778347969055176, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 16:30:14,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:14,476 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:27<38:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:30:21,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02136813849210739, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.707, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01760498434305191, 'eval_loss_2': 0.003763154149055481, 'eval_loss_3': -18.21040153503418, 'eval_loss_4': 0.8615443110466003, 'epoch': 16.83}
{'loss': 0.013, 'grad_norm': 5.149916172027588, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.007928051054477692, 'loss_2': 0.00507354736328125, 'loss_3': -16.186786651611328, 'loss_4': 0.8900870680809021, 'epoch': 16.84}
{'loss': 0.0119, 'grad_norm': 5.8668904304504395, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.010429373942315578, 'loss_2': 0.0014791488647460938, 'loss_3': -16.17230796813965, 'loss_4': 0.6003949642181396, 'epoch': 16.84}
{'loss': 0.0077, 'grad_norm': 5.329829692840576, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.007327262312173843, 'loss_2': 0.0003597736358642578, 'loss_3': -15.942361831665039, 'loss_4': 0.7145353555679321, 'epoch': 16.85}
{'loss': 0.0059, 'grad_norm': 4.774243354797363, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.005696754902601242, 'loss_2': 0.00023365020751953125, 'loss_3': -16.20948600769043, 'loss_4': 1.0138059854507446, 'epoch': 16.85}
{'loss': 0.0959, 'grad_norm': 23.374601364135742, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.08942859619855881, 'loss_2': 0.00649261474609375, 'loss_3': -16.112035751342773, 'loss_4': 1.0510348081588745, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 16:30:21,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:21,805 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:34<38:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:29,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022831011563539505, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.79, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017775163054466248, 'eval_loss_2': 0.005055852234363556, 'eval_loss_3': -18.19338607788086, 'eval_loss_4': 0.7392107248306274, 'epoch': 16.86}
{'loss': 0.0278, 'grad_norm': 19.17331886291504, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.02699587680399418, 'loss_2': 0.0008258819580078125, 'loss_3': -16.222248077392578, 'loss_4': 0.7356279492378235, 'epoch': 16.87}
{'loss': 0.026, 'grad_norm': 7.990181922912598, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.018508000299334526, 'loss_2': 0.0074920654296875, 'loss_3': -16.11419105529785, 'loss_4': 1.0872066020965576, 'epoch': 16.87}
{'loss': 0.0519, 'grad_norm': 14.634450912475586, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.044871289283037186, 'loss_2': 0.00702667236328125, 'loss_3': -16.305828094482422, 'loss_4': 0.7695878744125366, 'epoch': 16.88}
{'loss': 0.0185, 'grad_norm': 5.753861427307129, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.011152253486216068, 'loss_2': 0.00736236572265625, 'loss_3': -16.183265686035156, 'loss_4': 0.9721260666847229, 'epoch': 16.88}
{'loss': 0.0169, 'grad_norm': 4.988844394683838, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.010139108635485172, 'loss_2': 0.006744384765625, 'loss_3': -16.2508487701416, 'loss_4': 0.6292740106582642, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 16:30:29,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:29,137 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:41<38:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:36,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02271772176027298, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.935, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01673085428774357, 'eval_loss_2': 0.0059868693351745605, 'eval_loss_3': -18.188400268554688, 'eval_loss_4': 0.6735249161720276, 'epoch': 16.89}
{'loss': 0.024, 'grad_norm': 5.561071872711182, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.012430783361196518, 'loss_2': 0.01157379150390625, 'loss_3': -16.180208206176758, 'loss_4': 0.7339006662368774, 'epoch': 16.9}
{'loss': 0.0217, 'grad_norm': 8.037673950195312, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.010348306968808174, 'loss_2': 0.0113983154296875, 'loss_3': -16.155548095703125, 'loss_4': 1.1074457168579102, 'epoch': 16.9}
{'loss': 0.0248, 'grad_norm': 5.740501880645752, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.010021072812378407, 'loss_2': 0.0147857666015625, 'loss_3': -16.11752700805664, 'loss_4': 0.25827115774154663, 'epoch': 16.91}
{'loss': 0.0236, 'grad_norm': 10.513669967651367, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.02105950564146042, 'loss_2': 0.00250244140625, 'loss_3': -16.24915313720703, 'loss_4': 1.0232629776000977, 'epoch': 16.91}
{'loss': 0.0085, 'grad_norm': 4.676488399505615, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.005477316211909056, 'loss_2': 0.0030670166015625, 'loss_3': -16.19985580444336, 'loss_4': 1.1374661922454834, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 16:30:36,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:36,472 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:11:49<38:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:43,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018747596070170403, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.911, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.015482889488339424, 'eval_loss_2': 0.0032647065818309784, 'eval_loss_3': -18.22122573852539, 'eval_loss_4': 0.7724844217300415, 'epoch': 16.92}
{'loss': 0.0243, 'grad_norm': 8.24360179901123, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.020031727850437164, 'loss_2': 0.0042266845703125, 'loss_3': -16.475032806396484, 'loss_4': 1.299425482749939, 'epoch': 16.92}
{'loss': 0.013, 'grad_norm': 6.019115447998047, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.006578680593520403, 'loss_2': 0.0064697265625, 'loss_3': -16.269756317138672, 'loss_4': 0.6320263743400574, 'epoch': 16.93}
{'loss': 0.0126, 'grad_norm': 5.314500331878662, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.012016125954687595, 'loss_2': 0.0005660057067871094, 'loss_3': -16.066211700439453, 'loss_4': 1.1067975759506226, 'epoch': 16.94}
{'loss': 0.0295, 'grad_norm': 20.381725311279297, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.026457244530320168, 'loss_2': 0.003078460693359375, 'loss_3': -16.20656394958496, 'loss_4': 0.7473268508911133, 'epoch': 16.94}
{'loss': 0.0184, 'grad_norm': 6.268843650817871, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.013151844963431358, 'loss_2': 0.00527191162109375, 'loss_3': -16.10680389404297, 'loss_4': 0.9644681215286255, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 16:30:43,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:43,808 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:11:56<38:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:51,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01917058788239956, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015042229555547237, 'eval_loss_2': 0.004128355532884598, 'eval_loss_3': -18.23013687133789, 'eval_loss_4': 0.9168559908866882, 'epoch': 16.95}
{'loss': 0.0246, 'grad_norm': 6.803840160369873, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.016568170860409737, 'loss_2': 0.00800323486328125, 'loss_3': -16.236488342285156, 'loss_4': 0.3448222875595093, 'epoch': 16.95}
{'loss': 0.0254, 'grad_norm': 7.745387554168701, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.016723640263080597, 'loss_2': 0.0087127685546875, 'loss_3': -16.267398834228516, 'loss_4': 1.0036289691925049, 'epoch': 16.96}
{'loss': 0.017, 'grad_norm': 6.924570083618164, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.013733234256505966, 'loss_2': 0.003284454345703125, 'loss_3': -16.28702163696289, 'loss_4': 1.2124881744384766, 'epoch': 16.97}
{'loss': 0.0447, 'grad_norm': 9.605642318725586, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.028001494705677032, 'loss_2': 0.016693115234375, 'loss_3': -16.366161346435547, 'loss_4': 1.0994477272033691, 'epoch': 16.97}
{'loss': 0.0211, 'grad_norm': 5.519503593444824, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.012082628905773163, 'loss_2': 0.00901031494140625, 'loss_3': -16.11025047302246, 'loss_4': 0.8171391487121582, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 16:30:51,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:51,142 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:03<36:20,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:30:58,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01750403270125389, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.697, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01469779945909977, 'eval_loss_2': 0.002806231379508972, 'eval_loss_3': -18.21750259399414, 'eval_loss_4': 0.957098662853241, 'epoch': 16.98}
{'loss': 0.0212, 'grad_norm': 7.053088188171387, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.014380896463990211, 'loss_2': 0.00679779052734375, 'loss_3': -16.21370506286621, 'loss_4': 0.848540723323822, 'epoch': 16.98}
{'loss': 0.0157, 'grad_norm': 6.380999565124512, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.010212627239525318, 'loss_2': 0.00543975830078125, 'loss_3': -16.272499084472656, 'loss_4': 0.7413249015808105, 'epoch': 16.99}
{'loss': 0.0087, 'grad_norm': 5.3529791831970215, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.005426563322544098, 'loss_2': 0.0032291412353515625, 'loss_3': -16.331924438476562, 'loss_4': 0.7943464517593384, 'epoch': 16.99}
{'loss': 0.0044, 'grad_norm': 6.024144649505615, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.0031221278477460146, 'loss_2': 0.0012598037719726562, 'loss_3': -16.53186798095703, 'loss_4': 1.1313940286636353, 'epoch': 17.0}
{'loss': 0.0083, 'grad_norm': 4.8607659339904785, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.0068090069107711315, 'loss_2': 0.0014619827270507812, 'loss_3': -16.36060905456543, 'loss_4': 0.9367690086364746, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 16:30:58,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:58,169 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:10<38:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:31:05,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018769964575767517, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01552425418049097, 'eval_loss_2': 0.003245711326599121, 'eval_loss_3': -18.229679107666016, 'eval_loss_4': 0.9096170663833618, 'epoch': 17.01}
{'loss': 0.016, 'grad_norm': 5.607328414916992, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.009546054527163506, 'loss_2': 0.00641632080078125, 'loss_3': -16.291093826293945, 'loss_4': 1.1123090982437134, 'epoch': 17.01}
{'loss': 0.0112, 'grad_norm': 4.949873924255371, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.00921045895665884, 'loss_2': 0.001979827880859375, 'loss_3': -16.343368530273438, 'loss_4': 0.6042656302452087, 'epoch': 17.02}
{'loss': 0.0221, 'grad_norm': 6.491678237915039, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.018188491463661194, 'loss_2': 0.00394439697265625, 'loss_3': -16.16800308227539, 'loss_4': 0.9122107028961182, 'epoch': 17.02}
{'loss': 0.0383, 'grad_norm': 10.495052337646484, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.031026436015963554, 'loss_2': 0.007232666015625, 'loss_3': -16.227750778198242, 'loss_4': 1.2772319316864014, 'epoch': 17.03}
{'loss': 0.0301, 'grad_norm': 11.393684387207031, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.023922502994537354, 'loss_2': 0.00616455078125, 'loss_3': -16.32756996154785, 'loss_4': 0.9402256011962891, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 16:31:05,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:05,505 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:18<38:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:31:12,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017880700528621674, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013929597102105618, 'eval_loss_2': 0.0039511024951934814, 'eval_loss_3': -18.245920181274414, 'eval_loss_4': 0.9685536026954651, 'epoch': 17.03}
{'loss': 0.0153, 'grad_norm': 5.055150508880615, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.01094464398920536, 'loss_2': 0.00440216064453125, 'loss_3': -16.257610321044922, 'loss_4': 0.7842223048210144, 'epoch': 17.04}
{'loss': 0.0201, 'grad_norm': 7.820413589477539, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.018735961988568306, 'loss_2': 0.0013532638549804688, 'loss_3': -16.347017288208008, 'loss_4': 0.7497290372848511, 'epoch': 17.05}
{'loss': 0.0241, 'grad_norm': 7.993170261383057, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.01610572636127472, 'loss_2': 0.007965087890625, 'loss_3': -16.103893280029297, 'loss_4': 1.0715492963790894, 'epoch': 17.05}
{'loss': 0.0205, 'grad_norm': 10.766979217529297, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.017850589007139206, 'loss_2': 0.002620697021484375, 'loss_3': -16.188987731933594, 'loss_4': 1.6068954467773438, 'epoch': 17.06}
{'loss': 0.0289, 'grad_norm': 9.2481050491333, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.0231541208922863, 'loss_2': 0.005767822265625, 'loss_3': -16.1837215423584, 'loss_4': 1.3145345449447632, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 16:31:12,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:12,840 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:25<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:20,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016803815960884094, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.501, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.012753099203109741, 'eval_loss_2': 0.004050716757774353, 'eval_loss_3': -18.246397018432617, 'eval_loss_4': 0.9711307287216187, 'epoch': 17.06}
{'loss': 0.0116, 'grad_norm': 4.6865434646606445, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.007897348143160343, 'loss_2': 0.00365447998046875, 'loss_3': -16.186031341552734, 'loss_4': 0.9361348748207092, 'epoch': 17.07}
{'loss': 0.0144, 'grad_norm': 6.325507164001465, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.012232951819896698, 'loss_2': 0.00218963623046875, 'loss_3': -16.38023567199707, 'loss_4': 1.0229637622833252, 'epoch': 17.08}
{'loss': 0.0185, 'grad_norm': 8.308453559875488, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.01785706728696823, 'loss_2': 0.0006089210510253906, 'loss_3': -16.40654945373535, 'loss_4': 1.1533658504486084, 'epoch': 17.08}
{'loss': 0.0148, 'grad_norm': 6.929630279541016, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.014726218767464161, 'loss_2': 8.52346420288086e-05, 'loss_3': -16.431209564208984, 'loss_4': 0.49121177196502686, 'epoch': 17.09}
{'loss': 0.0197, 'grad_norm': 10.749978065490723, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.018101368099451065, 'loss_2': 0.001575469970703125, 'loss_3': -16.30826759338379, 'loss_4': 0.5893651247024536, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 16:31:20,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:20,161 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:32<38:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:27,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017289528623223305, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.602, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.013854571618139744, 'eval_loss_2': 0.0034349560737609863, 'eval_loss_3': -18.227554321289062, 'eval_loss_4': 0.7197556495666504, 'epoch': 17.09}
{'loss': 0.0235, 'grad_norm': 9.196050643920898, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.017818927764892578, 'loss_2': 0.005725860595703125, 'loss_3': -16.340856552124023, 'loss_4': 0.6235314607620239, 'epoch': 17.1}
{'loss': 0.0082, 'grad_norm': 5.371210098266602, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.007359437644481659, 'loss_2': 0.000858306884765625, 'loss_3': -16.23233985900879, 'loss_4': 0.49961310625076294, 'epoch': 17.1}
{'loss': 0.0148, 'grad_norm': 6.529805660247803, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.013185637071728706, 'loss_2': 0.0016202926635742188, 'loss_3': -16.41384506225586, 'loss_4': 1.1190448999404907, 'epoch': 17.11}
{'loss': 0.0291, 'grad_norm': 7.771575450897217, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.0167374350130558, 'loss_2': 0.01239013671875, 'loss_3': -16.098047256469727, 'loss_4': -0.003900490701198578, 'epoch': 17.12}
{'loss': 0.0115, 'grad_norm': 5.854300022125244, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.01122751273214817, 'loss_2': 0.0003151893615722656, 'loss_3': -16.34588623046875, 'loss_4': 0.6737750768661499, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 16:31:27,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:27,492 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:40<38:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:34,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02154996618628502, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.384, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013705635443329811, 'eval_loss_2': 0.007844328880310059, 'eval_loss_3': -18.21077537536621, 'eval_loss_4': 0.5261419415473938, 'epoch': 17.12}
{'loss': 0.0229, 'grad_norm': 9.393231391906738, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.0187432412058115, 'loss_2': 0.00420379638671875, 'loss_3': -16.490493774414062, 'loss_4': 0.24302564561367035, 'epoch': 17.13}
{'loss': 0.0228, 'grad_norm': 5.904016017913818, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.014494561590254307, 'loss_2': 0.0083465576171875, 'loss_3': -16.375900268554688, 'loss_4': -0.0914878100156784, 'epoch': 17.13}
{'loss': 0.0177, 'grad_norm': 4.575329780578613, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.007388397119939327, 'loss_2': 0.01027679443359375, 'loss_3': -16.252168655395508, 'loss_4': 0.813140869140625, 'epoch': 17.14}
{'loss': 0.0623, 'grad_norm': 14.628299713134766, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.05408213287591934, 'loss_2': 0.008209228515625, 'loss_3': -16.448673248291016, 'loss_4': 0.5629076957702637, 'epoch': 17.15}
{'loss': 0.018, 'grad_norm': 5.2603325843811035, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.010302050970494747, 'loss_2': 0.00769805908203125, 'loss_3': -16.375728607177734, 'loss_4': 0.5285173654556274, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 16:31:34,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:34,826 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:12:47<38:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:42,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020995091646909714, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.153, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.015250097028911114, 'eval_loss_2': 0.005744993686676025, 'eval_loss_3': -18.191205978393555, 'eval_loss_4': 0.43547070026397705, 'epoch': 17.15}
{'loss': 0.021, 'grad_norm': 5.568713665008545, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.01053361315280199, 'loss_2': 0.01043701171875, 'loss_3': -16.19353485107422, 'loss_4': 0.3871586322784424, 'epoch': 17.16}
{'loss': 0.0101, 'grad_norm': 5.111843585968018, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.007854397408664227, 'loss_2': 0.0022220611572265625, 'loss_3': -16.28492546081543, 'loss_4': 0.5401080846786499, 'epoch': 17.16}
{'loss': 0.0441, 'grad_norm': 16.647932052612305, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.04082681983709335, 'loss_2': 0.0032901763916015625, 'loss_3': -16.335445404052734, 'loss_4': -0.020098183304071426, 'epoch': 17.17}
{'loss': 0.0116, 'grad_norm': 5.3338727951049805, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.004907361231744289, 'loss_2': 0.0067291259765625, 'loss_3': -16.313678741455078, 'loss_4': 0.24077752232551575, 'epoch': 17.17}
{'loss': 0.0093, 'grad_norm': 4.769593238830566, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.006208584178239107, 'loss_2': 0.003078460693359375, 'loss_3': -16.240432739257812, 'loss_4': 0.19286710023880005, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 16:31:42,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:42,160 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:12:54<37:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:49,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018453698605298996, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.436, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015095691196620464, 'eval_loss_2': 0.003358006477355957, 'eval_loss_3': -18.165102005004883, 'eval_loss_4': 0.48823121190071106, 'epoch': 17.18}
{'loss': 0.0128, 'grad_norm': 4.673812389373779, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.005900159943848848, 'loss_2': 0.0069427490234375, 'loss_3': -16.336898803710938, 'loss_4': 0.3655017912387848, 'epoch': 17.19}
{'loss': 0.0174, 'grad_norm': 5.882911205291748, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.01386240217834711, 'loss_2': 0.003551483154296875, 'loss_3': -16.199663162231445, 'loss_4': 0.1309470236301422, 'epoch': 17.19}
{'loss': 0.0167, 'grad_norm': 4.845552921295166, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.008229306899011135, 'loss_2': 0.00846099853515625, 'loss_3': -16.343385696411133, 'loss_4': 0.8252459764480591, 'epoch': 17.2}
{'loss': 0.0136, 'grad_norm': 6.092241287231445, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.011283960193395615, 'loss_2': 0.0022716522216796875, 'loss_3': -16.26000213623047, 'loss_4': 0.8157901763916016, 'epoch': 17.2}
{'loss': 0.0068, 'grad_norm': 4.50137996673584, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.0038872328586876392, 'loss_2': 0.002941131591796875, 'loss_3': -16.156200408935547, 'loss_4': 0.14354217052459717, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 16:31:49,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:49,486 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:02<37:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:56,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020077470690011978, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.601, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01695689931511879, 'eval_loss_2': 0.0031205713748931885, 'eval_loss_3': -18.150455474853516, 'eval_loss_4': 0.5538933277130127, 'epoch': 17.21}
{'loss': 0.0085, 'grad_norm': 4.584674835205078, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.003885150421410799, 'loss_2': 0.00461578369140625, 'loss_3': -16.174421310424805, 'loss_4': 0.6575582027435303, 'epoch': 17.22}
{'loss': 0.0978, 'grad_norm': 18.645790100097656, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.09350286424160004, 'loss_2': 0.00433349609375, 'loss_3': -16.091033935546875, 'loss_4': 0.5442171692848206, 'epoch': 17.22}
{'loss': 0.0098, 'grad_norm': 5.19511079788208, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.0055557978339493275, 'loss_2': 0.0042572021484375, 'loss_3': -16.04686164855957, 'loss_4': 0.5908021926879883, 'epoch': 17.23}
{'loss': 0.0092, 'grad_norm': 4.825313568115234, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.007412313483655453, 'loss_2': 0.001827239990234375, 'loss_3': -16.12765121459961, 'loss_4': 0.29540807008743286, 'epoch': 17.23}
{'loss': 0.0149, 'grad_norm': 6.209420204162598, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.012806037440896034, 'loss_2': 0.00206756591796875, 'loss_3': -16.44966697692871, 'loss_4': 0.6567709445953369, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 16:31:56,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:56,809 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:09<37:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:04,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019566308706998825, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.663, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.016435427591204643, 'eval_loss_2': 0.003130882978439331, 'eval_loss_3': -18.155458450317383, 'eval_loss_4': 0.6328669786453247, 'epoch': 17.24}
{'loss': 0.0248, 'grad_norm': 7.16257905960083, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.019929734990000725, 'loss_2': 0.004913330078125, 'loss_3': -16.28993034362793, 'loss_4': 0.12739092111587524, 'epoch': 17.24}
{'loss': 0.0219, 'grad_norm': 6.880613327026367, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.012668079696595669, 'loss_2': 0.00925445556640625, 'loss_3': -16.022178649902344, 'loss_4': 0.47135716676712036, 'epoch': 17.25}
{'loss': 0.0122, 'grad_norm': 7.742593765258789, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.01162432599812746, 'loss_2': 0.0005712509155273438, 'loss_3': -16.373567581176758, 'loss_4': 0.8369724750518799, 'epoch': 17.26}
{'loss': 0.0185, 'grad_norm': 5.6927809715271, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.00958690233528614, 'loss_2': 0.0088653564453125, 'loss_3': -16.204530715942383, 'loss_4': 0.005253173410892487, 'epoch': 17.26}
{'loss': 0.0172, 'grad_norm': 5.320067882537842, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.006142792757600546, 'loss_2': 0.01100921630859375, 'loss_3': -16.310405731201172, 'loss_4': 0.49012941122055054, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 16:32:04,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:04,138 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:16<37:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:11,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01906462386250496, 'eval_runtime': 3.7825, 'eval_samples_per_second': 270.721, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.016261057928204536, 'eval_loss_2': 0.0028035640716552734, 'eval_loss_3': -18.166139602661133, 'eval_loss_4': 0.7060343027114868, 'epoch': 17.27}
{'loss': 0.0117, 'grad_norm': 5.453372001647949, 'learning_rate': 1.275e-05, 'loss_1': 0.008883536793291569, 'loss_2': 0.0028171539306640625, 'loss_3': -16.19278335571289, 'loss_4': 0.8279387354850769, 'epoch': 17.27}
{'loss': 0.0408, 'grad_norm': 12.260128021240234, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.03136957809329033, 'loss_2': 0.0093841552734375, 'loss_3': -16.239063262939453, 'loss_4': 0.4507620930671692, 'epoch': 17.28}
{'loss': 0.0205, 'grad_norm': 6.665945529937744, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.016555180773139, 'loss_2': 0.003902435302734375, 'loss_3': -16.44860076904297, 'loss_4': 0.6972341537475586, 'epoch': 17.28}
{'loss': 0.0428, 'grad_norm': 15.037385940551758, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.03309481963515282, 'loss_2': 0.0096893310546875, 'loss_3': -16.043052673339844, 'loss_4': 0.3453378975391388, 'epoch': 17.29}
{'loss': 0.0135, 'grad_norm': 5.3198394775390625, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.006827015895396471, 'loss_2': 0.00666046142578125, 'loss_3': -16.236276626586914, 'loss_4': 0.7319141626358032, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 16:32:11,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:11,463 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:24<37:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:18,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018541447818279266, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.302, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01578507386147976, 'eval_loss_2': 0.002756372094154358, 'eval_loss_3': -18.18590545654297, 'eval_loss_4': 0.6689152121543884, 'epoch': 17.3}
{'loss': 0.0067, 'grad_norm': 4.996638774871826, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.006468778010457754, 'loss_2': 0.00023186206817626953, 'loss_3': -15.94327449798584, 'loss_4': 0.05221192538738251, 'epoch': 17.3}
{'loss': 0.0142, 'grad_norm': 7.011891841888428, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.011443067342042923, 'loss_2': 0.00270843505859375, 'loss_3': -16.3422794342041, 'loss_4': 0.6392228603363037, 'epoch': 17.31}
{'loss': 0.0163, 'grad_norm': 8.544392585754395, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.014934388920664787, 'loss_2': 0.0013523101806640625, 'loss_3': -16.189537048339844, 'loss_4': 0.43396666646003723, 'epoch': 17.31}
{'loss': 0.0209, 'grad_norm': 7.3921332359313965, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.015289442613720894, 'loss_2': 0.00563812255859375, 'loss_3': -16.236305236816406, 'loss_4': 0.3115326166152954, 'epoch': 17.32}
{'loss': 0.0276, 'grad_norm': 7.713406085968018, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.019563807174563408, 'loss_2': 0.00799560546875, 'loss_3': -16.14006805419922, 'loss_4': -0.014004044234752655, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 16:32:18,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:18,789 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:31<37:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:26,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01746942847967148, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01414920948445797, 'eval_loss_2': 0.0033202171325683594, 'eval_loss_3': -18.20836639404297, 'eval_loss_4': 0.5769429206848145, 'epoch': 17.33}
{'loss': 0.0261, 'grad_norm': 7.839788913726807, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.01610432378947735, 'loss_2': 0.0099639892578125, 'loss_3': -16.0394287109375, 'loss_4': 0.30609944462776184, 'epoch': 17.33}
{'loss': 0.0085, 'grad_norm': 5.236128330230713, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.007801740895956755, 'loss_2': 0.0006489753723144531, 'loss_3': -16.36211395263672, 'loss_4': 0.5341861248016357, 'epoch': 17.34}
{'loss': 0.0133, 'grad_norm': 5.695839881896973, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.008533544838428497, 'loss_2': 0.004810333251953125, 'loss_3': -16.20147132873535, 'loss_4': 0.3854086399078369, 'epoch': 17.34}
{'loss': 0.0318, 'grad_norm': 12.82514476776123, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.024421848356723785, 'loss_2': 0.007358551025390625, 'loss_3': -16.280643463134766, 'loss_4': 0.3728684186935425, 'epoch': 17.35}
{'loss': 0.0156, 'grad_norm': 5.380212783813477, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.007985670119524002, 'loss_2': 0.0076446533203125, 'loss_3': -16.207324981689453, 'loss_4': 0.2504122257232666, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 16:32:26,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:26,117 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:38<37:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:32:33,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01732504740357399, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.37, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013280863873660564, 'eval_loss_2': 0.004044182598590851, 'eval_loss_3': -18.198301315307617, 'eval_loss_4': 0.5054929852485657, 'epoch': 17.35}
{'loss': 0.0155, 'grad_norm': 5.687934875488281, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.008985212072730064, 'loss_2': 0.006500244140625, 'loss_3': -16.216299057006836, 'loss_4': 0.5648092031478882, 'epoch': 17.36}
{'loss': 0.0075, 'grad_norm': 4.907759666442871, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.006833561230450869, 'loss_2': 0.0006198883056640625, 'loss_3': -16.266542434692383, 'loss_4': 0.21430176496505737, 'epoch': 17.37}
{'loss': 0.0095, 'grad_norm': 6.355384349822998, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.008255716413259506, 'loss_2': 0.0012264251708984375, 'loss_3': -16.128385543823242, 'loss_4': 0.7782692909240723, 'epoch': 17.37}
{'loss': 0.0096, 'grad_norm': 5.1021833419799805, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.006573081482201815, 'loss_2': 0.002979278564453125, 'loss_3': -16.37708282470703, 'loss_4': -0.03167302906513214, 'epoch': 17.38}
{'loss': 0.0095, 'grad_norm': 5.013871192932129, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.006435733754187822, 'loss_2': 0.0030517578125, 'loss_3': -16.202150344848633, 'loss_4': 0.06053594499826431, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 16:32:33,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:33,441 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:13:46<37:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:40,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016370130702853203, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.602, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.013373805209994316, 'eval_loss_2': 0.0029963254928588867, 'eval_loss_3': -18.214975357055664, 'eval_loss_4': 0.4619150757789612, 'epoch': 17.38}
{'loss': 0.0073, 'grad_norm': 4.716040134429932, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.005928910803049803, 'loss_2': 0.001338958740234375, 'loss_3': -16.449459075927734, 'loss_4': 9.000301361083984e-05, 'epoch': 17.39}
{'loss': 0.0218, 'grad_norm': 16.094945907592773, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.019718077033758163, 'loss_2': 0.0020465850830078125, 'loss_3': -16.151113510131836, 'loss_4': 0.33740943670272827, 'epoch': 17.4}
{'loss': 0.0165, 'grad_norm': 5.207362174987793, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.006357824895530939, 'loss_2': 0.010101318359375, 'loss_3': -16.305477142333984, 'loss_4': 0.19178512692451477, 'epoch': 17.4}
{'loss': 0.0313, 'grad_norm': 11.740978240966797, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.025979313999414444, 'loss_2': 0.00534820556640625, 'loss_3': -16.266155242919922, 'loss_4': 0.5983507037162781, 'epoch': 17.41}
{'loss': 0.0055, 'grad_norm': 5.115098476409912, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.004976079799234867, 'loss_2': 0.0005025863647460938, 'loss_3': -16.252059936523438, 'loss_4': 0.34751492738723755, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 16:32:40,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:40,766 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:13:53<37:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:32:48,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016128510236740112, 'eval_runtime': 3.7823, 'eval_samples_per_second': 270.733, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.013073991984128952, 'eval_loss_2': 0.0030545219779014587, 'eval_loss_3': -18.229602813720703, 'eval_loss_4': 0.4788818359375, 'epoch': 17.41}
{'loss': 0.006, 'grad_norm': 4.448404788970947, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.005132271442562342, 'loss_2': 0.0008854866027832031, 'loss_3': -16.45697784423828, 'loss_4': 0.2640831470489502, 'epoch': 17.42}
{'loss': 0.0095, 'grad_norm': 6.32501745223999, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.007343498524278402, 'loss_2': 0.0021343231201171875, 'loss_3': -16.178565979003906, 'loss_4': 0.1810876429080963, 'epoch': 17.42}
{'loss': 0.0117, 'grad_norm': 6.607614517211914, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.009030712768435478, 'loss_2': 0.00263214111328125, 'loss_3': -16.292709350585938, 'loss_4': 0.05871628224849701, 'epoch': 17.43}
{'loss': 0.0092, 'grad_norm': 4.799917221069336, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.006848411168903112, 'loss_2': 0.0023288726806640625, 'loss_3': -16.353679656982422, 'loss_4': 0.4493849575519562, 'epoch': 17.44}
{'loss': 0.0124, 'grad_norm': 5.978124618530273, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.010112585499882698, 'loss_2': 0.002292633056640625, 'loss_3': -16.24071502685547, 'loss_4': 0.4470937252044678, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 16:32:48,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:48,083 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:00<37:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:32:55,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015020577237010002, 'eval_runtime': 3.7818, 'eval_samples_per_second': 270.768, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.011802837252616882, 'eval_loss_2': 0.0032177381217479706, 'eval_loss_3': -18.220531463623047, 'eval_loss_4': 0.44103533029556274, 'epoch': 17.44}
{'loss': 0.0107, 'grad_norm': 4.828795909881592, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.006904535461217165, 'loss_2': 0.003772735595703125, 'loss_3': -16.266033172607422, 'loss_4': 0.3800819516181946, 'epoch': 17.45}
{'loss': 0.0385, 'grad_norm': 26.882028579711914, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.03840494528412819, 'loss_2': 0.0001361370086669922, 'loss_3': -16.218219757080078, 'loss_4': 0.05210769176483154, 'epoch': 17.45}
{'loss': 0.0118, 'grad_norm': 4.839357852935791, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.006857267115265131, 'loss_2': 0.004917144775390625, 'loss_3': -16.193708419799805, 'loss_4': -0.08337339013814926, 'epoch': 17.46}
{'loss': 0.0133, 'grad_norm': 4.880584239959717, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.006024403963238001, 'loss_2': 0.0073089599609375, 'loss_3': -16.289884567260742, 'loss_4': 0.5486901998519897, 'epoch': 17.47}
{'loss': 0.017, 'grad_norm': 8.418807983398438, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.014129333198070526, 'loss_2': 0.0028324127197265625, 'loss_3': -16.387161254882812, 'loss_4': 0.6722390651702881, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 16:32:55,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:55,402 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:08<37:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:33:02,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016433879733085632, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.182, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011777358129620552, 'eval_loss_2': 0.0046565234661102295, 'eval_loss_3': -18.227123260498047, 'eval_loss_4': 0.3873361349105835, 'epoch': 17.47}
{'loss': 0.0117, 'grad_norm': 5.691718578338623, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.011135553009808064, 'loss_2': 0.0005445480346679688, 'loss_3': -16.33646583557129, 'loss_4': 0.6417348384857178, 'epoch': 17.48}
{'loss': 0.0137, 'grad_norm': 6.209737777709961, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.008039134554564953, 'loss_2': 0.005687713623046875, 'loss_3': -16.197282791137695, 'loss_4': 0.30793511867523193, 'epoch': 17.48}
{'loss': 0.0139, 'grad_norm': 5.887053966522217, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.008898620493710041, 'loss_2': 0.004974365234375, 'loss_3': -16.204845428466797, 'loss_4': 0.5833430886268616, 'epoch': 17.49}
{'loss': 0.0122, 'grad_norm': 5.184559345245361, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.006425690837204456, 'loss_2': 0.00580596923828125, 'loss_3': -16.295894622802734, 'loss_4': 0.19272847473621368, 'epoch': 17.49}
{'loss': 0.0175, 'grad_norm': 5.9600138664245605, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.00783395953476429, 'loss_2': 0.00970458984375, 'loss_3': -16.280029296875, 'loss_4': -0.5034783482551575, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 16:33:02,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:02,729 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:15<36:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:33:10,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0166020430624485, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.173, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01211429014801979, 'eval_loss_2': 0.004487752914428711, 'eval_loss_3': -18.220731735229492, 'eval_loss_4': 0.32241708040237427, 'epoch': 17.5}
{'loss': 0.02, 'grad_norm': 6.609034061431885, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.010022304020822048, 'loss_2': 0.0099945068359375, 'loss_3': -16.136276245117188, 'loss_4': 0.08829056471586227, 'epoch': 17.51}
{'loss': 0.0092, 'grad_norm': 4.406111240386963, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.005213107913732529, 'loss_2': 0.003997802734375, 'loss_3': -16.248023986816406, 'loss_4': 0.26740872859954834, 'epoch': 17.51}
{'loss': 0.0986, 'grad_norm': 10.806178092956543, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.09374113380908966, 'loss_2': 0.004878997802734375, 'loss_3': -16.21529769897461, 'loss_4': 0.9773575067520142, 'epoch': 17.52}
{'loss': 0.0107, 'grad_norm': 5.752763748168945, 'learning_rate': 1.25e-05, 'loss_1': 0.009915036149322987, 'loss_2': 0.0007967948913574219, 'loss_3': -16.253559112548828, 'loss_4': -0.07903864979743958, 'epoch': 17.52}
{'loss': 0.01, 'grad_norm': 4.669870853424072, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.008815919980406761, 'loss_2': 0.0012102127075195312, 'loss_3': -16.32888412475586, 'loss_4': 0.22796837985515594, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 16:33:10,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:10,052 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:22<36:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:33:17,378 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01531450729817152, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.314, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012173788622021675, 'eval_loss_2': 0.0031407177448272705, 'eval_loss_3': -18.216405868530273, 'eval_loss_4': 0.2342032939195633, 'epoch': 17.53}
{'loss': 0.0093, 'grad_norm': 5.139655590057373, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.007776961661875248, 'loss_2': 0.0015087127685546875, 'loss_3': -16.10148048400879, 'loss_4': 0.2560378313064575, 'epoch': 17.53}
{'loss': 0.0097, 'grad_norm': 5.227234840393066, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.007152167614549398, 'loss_2': 0.00254058837890625, 'loss_3': -16.42669677734375, 'loss_4': 0.49708688259124756, 'epoch': 17.54}
{'loss': 0.0113, 'grad_norm': 4.9031805992126465, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.00550139369443059, 'loss_2': 0.005828857421875, 'loss_3': -16.359411239624023, 'loss_4': -0.09599503874778748, 'epoch': 17.55}
{'loss': 0.022, 'grad_norm': 7.660260200500488, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.014683717861771584, 'loss_2': 0.00730133056640625, 'loss_3': -16.387258529663086, 'loss_4': 0.18068787455558777, 'epoch': 17.55}
{'loss': 0.0088, 'grad_norm': 5.345910549163818, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.006594645790755749, 'loss_2': 0.0022068023681640625, 'loss_3': -16.199848175048828, 'loss_4': 0.10616891086101532, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 16:33:17,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:17,379 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:30<36:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:24,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01669877953827381, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.466, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01202088501304388, 'eval_loss_2': 0.004677891731262207, 'eval_loss_3': -18.205909729003906, 'eval_loss_4': 0.16926799714565277, 'epoch': 17.56}
{'loss': 0.0172, 'grad_norm': 5.288155555725098, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.0057245176285505295, 'loss_2': 0.011474609375, 'loss_3': -16.36617660522461, 'loss_4': -0.16819065809249878, 'epoch': 17.56}
{'loss': 0.0165, 'grad_norm': 5.828494071960449, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.00789815466850996, 'loss_2': 0.0085601806640625, 'loss_3': -16.15378761291504, 'loss_4': 0.1772001087665558, 'epoch': 17.57}
{'loss': 0.0211, 'grad_norm': 10.021743774414062, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.013071469962596893, 'loss_2': 0.008056640625, 'loss_3': -16.306182861328125, 'loss_4': 0.28017210960388184, 'epoch': 17.58}
{'loss': 0.0117, 'grad_norm': 6.074174880981445, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.010513417422771454, 'loss_2': 0.0011730194091796875, 'loss_3': -16.174028396606445, 'loss_4': 0.19908925890922546, 'epoch': 17.58}
{'loss': 0.0163, 'grad_norm': 4.61159086227417, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.009247026406228542, 'loss_2': 0.00707244873046875, 'loss_3': -16.27594757080078, 'loss_4': 0.49384787678718567, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 16:33:24,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:24,711 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:37<36:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:32,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017521603032946587, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.331, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013388707302510738, 'eval_loss_2': 0.004132896661758423, 'eval_loss_3': -18.222414016723633, 'eval_loss_4': 0.18637022376060486, 'epoch': 17.59}
{'loss': 0.0092, 'grad_norm': 4.524965286254883, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.0048813666217029095, 'loss_2': 0.0043182373046875, 'loss_3': -16.37896728515625, 'loss_4': 0.37408244609832764, 'epoch': 17.59}
{'loss': 0.0232, 'grad_norm': 14.417240142822266, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.018795644864439964, 'loss_2': 0.0043792724609375, 'loss_3': -16.241395950317383, 'loss_4': -0.0591299794614315, 'epoch': 17.6}
{'loss': 0.0237, 'grad_norm': 8.554160118103027, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.015955287963151932, 'loss_2': 0.00775146484375, 'loss_3': -16.182525634765625, 'loss_4': -0.08591478317975998, 'epoch': 17.6}
{'loss': 0.0124, 'grad_norm': 8.193166732788086, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.010704278945922852, 'loss_2': 0.0016937255859375, 'loss_3': -16.47509002685547, 'loss_4': 0.07268114387989044, 'epoch': 17.61}
{'loss': 0.0217, 'grad_norm': 11.103249549865723, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.02118084765970707, 'loss_2': 0.0005283355712890625, 'loss_3': -16.33448600769043, 'loss_4': 0.358654648065567, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 16:33:32,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:32,037 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:14:44<36:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:39,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01812993548810482, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.036, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01493321917951107, 'eval_loss_2': 0.00319671630859375, 'eval_loss_3': -18.203317642211914, 'eval_loss_4': 0.15953165292739868, 'epoch': 17.62}
{'loss': 0.0153, 'grad_norm': 9.770145416259766, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.014678562991321087, 'loss_2': 0.0006189346313476562, 'loss_3': -16.310405731201172, 'loss_4': 0.12554927170276642, 'epoch': 17.62}
{'loss': 0.0103, 'grad_norm': 7.590055465698242, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.009448224678635597, 'loss_2': 0.0008411407470703125, 'loss_3': -16.324033737182617, 'loss_4': 0.03454294055700302, 'epoch': 17.63}
{'loss': 0.0064, 'grad_norm': 4.559540271759033, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.005936081986874342, 'loss_2': 0.0004849433898925781, 'loss_3': -16.157108306884766, 'loss_4': 0.19638748466968536, 'epoch': 17.63}
{'loss': 0.0101, 'grad_norm': 4.624507904052734, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.005858559161424637, 'loss_2': 0.00421905517578125, 'loss_3': -16.441465377807617, 'loss_4': -0.13864825665950775, 'epoch': 17.64}
{'loss': 0.0186, 'grad_norm': 10.628507614135742, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.018454521894454956, 'loss_2': 0.0001703500747680664, 'loss_3': -16.40201187133789, 'loss_4': -0.21595978736877441, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 16:33:39,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:39,368 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:14:52<36:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:33:46,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01867140270769596, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015327046625316143, 'eval_loss_2': 0.0033443570137023926, 'eval_loss_3': -18.191856384277344, 'eval_loss_4': 0.13985399901866913, 'epoch': 17.65}
{'loss': 0.0092, 'grad_norm': 5.773899555206299, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.0076195248402655125, 'loss_2': 0.00159454345703125, 'loss_3': -16.389892578125, 'loss_4': 0.3407769203186035, 'epoch': 17.65}
{'loss': 0.0127, 'grad_norm': 4.957844257354736, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.00773183349519968, 'loss_2': 0.00493621826171875, 'loss_3': -16.273284912109375, 'loss_4': -0.25848615169525146, 'epoch': 17.66}
{'loss': 0.0078, 'grad_norm': 5.395263671875, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.00693734735250473, 'loss_2': 0.0008540153503417969, 'loss_3': -16.30068588256836, 'loss_4': -0.15647825598716736, 'epoch': 17.66}
{'loss': 0.0126, 'grad_norm': 6.144693374633789, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.010463844984769821, 'loss_2': 0.0021820068359375, 'loss_3': -16.25595474243164, 'loss_4': -0.00788608193397522, 'epoch': 17.67}
{'loss': 0.0081, 'grad_norm': 4.781744956970215, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.006790350191295147, 'loss_2': 0.0012989044189453125, 'loss_3': -16.384565353393555, 'loss_4': -0.03639513999223709, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 16:33:46,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:46,698 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:14:59<36:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:54,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02039196342229843, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.62, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.0165609959512949, 'eval_loss_2': 0.0038309693336486816, 'eval_loss_3': -18.18805694580078, 'eval_loss_4': 0.1831848919391632, 'epoch': 17.67}
{'loss': 0.0099, 'grad_norm': 5.2706780433654785, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.007400608155876398, 'loss_2': 0.00246429443359375, 'loss_3': -16.339370727539062, 'loss_4': 0.07758738100528717, 'epoch': 17.68}
{'loss': 0.0186, 'grad_norm': 8.649469375610352, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.01038335170596838, 'loss_2': 0.00818634033203125, 'loss_3': -16.237438201904297, 'loss_4': -0.3553723692893982, 'epoch': 17.69}
{'loss': 0.0098, 'grad_norm': 4.333634376525879, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.004480701871216297, 'loss_2': 0.00536346435546875, 'loss_3': -16.296693801879883, 'loss_4': 0.08933284133672714, 'epoch': 17.69}
{'loss': 0.0203, 'grad_norm': 7.189856052398682, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.011272364296019077, 'loss_2': 0.009002685546875, 'loss_3': -16.220855712890625, 'loss_4': 0.07440783083438873, 'epoch': 17.7}
{'loss': 0.0101, 'grad_norm': 7.431534290313721, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.00977866817265749, 'loss_2': 0.00029659271240234375, 'loss_3': -16.27495574951172, 'loss_4': 0.36532992124557495, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 16:33:54,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:54,022 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:06<36:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:01,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01965547353029251, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.697, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.01628219336271286, 'eval_loss_2': 0.003373280167579651, 'eval_loss_3': -18.197010040283203, 'eval_loss_4': 0.226848304271698, 'epoch': 17.7}
{'loss': 0.0068, 'grad_norm': 4.538443088531494, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.005766401067376137, 'loss_2': 0.0010242462158203125, 'loss_3': -16.35688018798828, 'loss_4': -0.010385926812887192, 'epoch': 17.71}
{'loss': 0.0099, 'grad_norm': 4.890439510345459, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.008135671727359295, 'loss_2': 0.0017719268798828125, 'loss_3': -16.247535705566406, 'loss_4': 0.07933561503887177, 'epoch': 17.72}
{'loss': 0.0138, 'grad_norm': 5.187180995941162, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.005124886054545641, 'loss_2': 0.00872039794921875, 'loss_3': -16.34271240234375, 'loss_4': -0.38459622859954834, 'epoch': 17.72}
{'loss': 0.0081, 'grad_norm': 5.182873249053955, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.006993590388447046, 'loss_2': 0.0011386871337890625, 'loss_3': -16.366836547851562, 'loss_4': 0.25100451707839966, 'epoch': 17.73}
{'loss': 0.0089, 'grad_norm': 5.441027641296387, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.00807241816073656, 'loss_2': 0.0008344650268554688, 'loss_3': -16.332561492919922, 'loss_4': 0.1536584496498108, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 16:34:01,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:01,340 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:14<36:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:08,656 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022402841597795486, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.564, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.018434545025229454, 'eval_loss_2': 0.003968298435211182, 'eval_loss_3': -18.187227249145508, 'eval_loss_4': 0.11100449413061142, 'epoch': 17.73}
{'loss': 0.0283, 'grad_norm': 13.641073226928711, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.025236736983060837, 'loss_2': 0.00307464599609375, 'loss_3': -16.438636779785156, 'loss_4': -0.252265989780426, 'epoch': 17.74}
{'loss': 0.0121, 'grad_norm': 4.729413986206055, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.004190353211015463, 'loss_2': 0.0078887939453125, 'loss_3': -16.258758544921875, 'loss_4': 0.07390987873077393, 'epoch': 17.74}
{'loss': 0.0156, 'grad_norm': 5.537628650665283, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.007017422933131456, 'loss_2': 0.008544921875, 'loss_3': -16.229595184326172, 'loss_4': -0.3328656256198883, 'epoch': 17.75}
{'loss': 0.0423, 'grad_norm': 20.3113956451416, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.03883353993296623, 'loss_2': 0.0034618377685546875, 'loss_3': -16.305133819580078, 'loss_4': 0.20016354322433472, 'epoch': 17.76}
{'loss': 0.0097, 'grad_norm': 4.863358497619629, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.007982666604220867, 'loss_2': 0.0017528533935546875, 'loss_3': -16.332721710205078, 'loss_4': 0.03501866012811661, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 16:34:08,657 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:08,657 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:21<36:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:15,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023544196039438248, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.408, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.019947294145822525, 'eval_loss_2': 0.0035969018936157227, 'eval_loss_3': -18.16889190673828, 'eval_loss_4': 0.09617458283901215, 'epoch': 17.76}
{'loss': 0.0106, 'grad_norm': 7.543654918670654, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.010039684362709522, 'loss_2': 0.0005311965942382812, 'loss_3': -16.157028198242188, 'loss_4': 0.22115188837051392, 'epoch': 17.77}
{'loss': 0.0095, 'grad_norm': 4.8310675621032715, 'learning_rate': 1.225e-05, 'loss_1': 0.006759681273251772, 'loss_2': 0.002758026123046875, 'loss_3': -16.309574127197266, 'loss_4': -0.2095421850681305, 'epoch': 17.77}
{'loss': 0.019, 'grad_norm': 7.1115522384643555, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.01675516553223133, 'loss_2': 0.002269744873046875, 'loss_3': -16.195703506469727, 'loss_4': -0.18487271666526794, 'epoch': 17.78}
{'loss': 0.0168, 'grad_norm': 5.766134262084961, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.011167140677571297, 'loss_2': 0.00565338134765625, 'loss_3': -16.263586044311523, 'loss_4': -0.02277486026287079, 'epoch': 17.78}
{'loss': 0.0137, 'grad_norm': 6.079775333404541, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.0114156948402524, 'loss_2': 0.0022907257080078125, 'loss_3': -16.235979080200195, 'loss_4': -0.3219814896583557, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 16:34:15,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:15,984 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:28<36:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:23,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024093393236398697, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.439, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021656323224306107, 'eval_loss_2': 0.0024370700120925903, 'eval_loss_3': -18.12790298461914, 'eval_loss_4': 0.1012602224946022, 'epoch': 17.79}
{'loss': 0.0127, 'grad_norm': 4.856530666351318, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.009268337860703468, 'loss_2': 0.003406524658203125, 'loss_3': -16.164684295654297, 'loss_4': -0.1096879094839096, 'epoch': 17.8}
{'loss': 0.0161, 'grad_norm': 5.377303123474121, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.011578268371522427, 'loss_2': 0.0045166015625, 'loss_3': -16.382463455200195, 'loss_4': -0.13465991616249084, 'epoch': 17.8}
{'loss': 0.0153, 'grad_norm': 6.508031845092773, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.010290293022990227, 'loss_2': 0.005039215087890625, 'loss_3': -16.22364044189453, 'loss_4': -0.02978905662894249, 'epoch': 17.81}
{'loss': 0.0181, 'grad_norm': 7.340712070465088, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.012950928881764412, 'loss_2': 0.005161285400390625, 'loss_3': -16.457229614257812, 'loss_4': -0.08156867325305939, 'epoch': 17.81}
{'loss': 0.0394, 'grad_norm': 7.422914981842041, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.035394683480262756, 'loss_2': 0.0039825439453125, 'loss_3': -16.363784790039062, 'loss_4': -0.47947728633880615, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 16:34:23,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:23,309 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:36<36:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:30,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025799209251999855, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.409, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.022249380126595497, 'eval_loss_2': 0.003549829125404358, 'eval_loss_3': -18.128175735473633, 'eval_loss_4': 0.015716630965471268, 'epoch': 17.82}
{'loss': 0.0187, 'grad_norm': 7.583407878875732, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.012549818493425846, 'loss_2': 0.00611114501953125, 'loss_3': -16.314350128173828, 'loss_4': 0.010948017239570618, 'epoch': 17.83}
{'loss': 0.01, 'grad_norm': 5.024576663970947, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.005484460853040218, 'loss_2': 0.004550933837890625, 'loss_3': -16.186025619506836, 'loss_4': 0.16262535750865936, 'epoch': 17.83}
{'loss': 0.0085, 'grad_norm': 4.965442657470703, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.007345155812799931, 'loss_2': 0.0011796951293945312, 'loss_3': -16.4404239654541, 'loss_4': -0.1294301301240921, 'epoch': 17.84}
{'loss': 0.0174, 'grad_norm': 6.921135902404785, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.01325969398021698, 'loss_2': 0.004161834716796875, 'loss_3': -16.37738037109375, 'loss_4': -0.1342359185218811, 'epoch': 17.84}
{'loss': 0.0123, 'grad_norm': 6.654801845550537, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.011281455866992474, 'loss_2': 0.0009751319885253906, 'loss_3': -16.258214950561523, 'loss_4': -0.4479805827140808, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 16:34:30,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:30,632 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:15:43<35:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:37,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027543360367417336, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.381, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.023019932210445404, 'eval_loss_2': 0.004523426294326782, 'eval_loss_3': -18.12688446044922, 'eval_loss_4': -0.1049172431230545, 'epoch': 17.85}
{'loss': 0.0084, 'grad_norm': 4.90167236328125, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.005805235356092453, 'loss_2': 0.00263214111328125, 'loss_3': -16.36795425415039, 'loss_4': -0.45077675580978394, 'epoch': 17.85}
{'loss': 0.0092, 'grad_norm': 4.935251712799072, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.004826687276363373, 'loss_2': 0.004364013671875, 'loss_3': -16.20356559753418, 'loss_4': -0.27422767877578735, 'epoch': 17.86}
{'loss': 0.0185, 'grad_norm': 4.791271686553955, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.006758102681487799, 'loss_2': 0.01172637939453125, 'loss_3': -16.26657485961914, 'loss_4': -0.34028875827789307, 'epoch': 17.87}
{'loss': 0.0198, 'grad_norm': 5.544460296630859, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.013295420445501804, 'loss_2': 0.006481170654296875, 'loss_3': -16.23769760131836, 'loss_4': -0.20115607976913452, 'epoch': 17.87}
{'loss': 0.0111, 'grad_norm': 4.452163219451904, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.00437453156337142, 'loss_2': 0.006710052490234375, 'loss_3': -16.391048431396484, 'loss_4': -0.04744479060173035, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 16:34:37,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:37,949 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:15:50<35:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:45,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02710697054862976, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.196, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02388802170753479, 'eval_loss_2': 0.0032189488410949707, 'eval_loss_3': -18.122156143188477, 'eval_loss_4': -0.21584509313106537, 'epoch': 17.88}
{'loss': 0.0106, 'grad_norm': 4.917036056518555, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.007411685306578875, 'loss_2': 0.0031604766845703125, 'loss_3': -16.342350006103516, 'loss_4': 0.09609381854534149, 'epoch': 17.88}
{'loss': 0.0095, 'grad_norm': 5.0721306800842285, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.006604322697967291, 'loss_2': 0.00290679931640625, 'loss_3': -16.36484718322754, 'loss_4': -0.3608555197715759, 'epoch': 17.89}
{'loss': 0.005, 'grad_norm': 4.649219512939453, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.0040421150624752045, 'loss_2': 0.0009298324584960938, 'loss_3': -16.37818717956543, 'loss_4': -0.041742995381355286, 'epoch': 17.9}
{'loss': 0.0176, 'grad_norm': 9.783354759216309, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.013786143623292446, 'loss_2': 0.00385284423828125, 'loss_3': -16.177629470825195, 'loss_4': -0.22325995564460754, 'epoch': 17.9}
{'loss': 0.0283, 'grad_norm': 15.385748863220215, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.025590350851416588, 'loss_2': 0.0027008056640625, 'loss_3': -16.268369674682617, 'loss_4': -0.3725805878639221, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 16:34:45,281 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:45,281 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:15:58<35:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:52,600 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029614780098199844, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.685, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.0263205599039793, 'eval_loss_2': 0.003294222056865692, 'eval_loss_3': -18.088001251220703, 'eval_loss_4': -0.14345362782478333, 'epoch': 17.91}
{'loss': 0.0086, 'grad_norm': 4.800839424133301, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.004577145911753178, 'loss_2': 0.00400543212890625, 'loss_3': -16.463037490844727, 'loss_4': -0.4305819272994995, 'epoch': 17.91}
{'loss': 0.0755, 'grad_norm': 17.850250244140625, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.06893935799598694, 'loss_2': 0.0065460205078125, 'loss_3': -16.234668731689453, 'loss_4': 0.1482284516096115, 'epoch': 17.92}
{'loss': 0.0061, 'grad_norm': 5.441655158996582, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.005795943550765514, 'loss_2': 0.00027751922607421875, 'loss_3': -16.30971908569336, 'loss_4': -0.08536643534898758, 'epoch': 17.92}
{'loss': 0.0189, 'grad_norm': 9.401216506958008, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.016706882044672966, 'loss_2': 0.00220489501953125, 'loss_3': -16.55177116394043, 'loss_4': 0.12954223155975342, 'epoch': 17.93}
{'loss': 0.0136, 'grad_norm': 5.682661533355713, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.008581909351050854, 'loss_2': 0.00499725341796875, 'loss_3': -16.27537727355957, 'loss_4': -0.5440264940261841, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 16:34:52,600 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:52,600 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:05<35:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:59,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030926747247576714, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.231, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.027394520118832588, 'eval_loss_2': 0.003532230854034424, 'eval_loss_3': -18.074501037597656, 'eval_loss_4': 0.06127355620265007, 'epoch': 17.94}
{'loss': 0.0134, 'grad_norm': 5.5834245681762695, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.011950680986046791, 'loss_2': 0.0014171600341796875, 'loss_3': -16.16126823425293, 'loss_4': 0.30859601497650146, 'epoch': 17.94}
{'loss': 0.0208, 'grad_norm': 10.775202751159668, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.015647146850824356, 'loss_2': 0.005161285400390625, 'loss_3': -16.258806228637695, 'loss_4': -0.15899668633937836, 'epoch': 17.95}
{'loss': 0.0071, 'grad_norm': 5.952262878417969, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.006713101174682379, 'loss_2': 0.0004200935363769531, 'loss_3': -16.35317611694336, 'loss_4': 0.19377027451992035, 'epoch': 17.95}
{'loss': 0.0148, 'grad_norm': 5.451669216156006, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.008675480261445045, 'loss_2': 0.006168365478515625, 'loss_3': -16.224395751953125, 'loss_4': 0.33004820346832275, 'epoch': 17.96}
{'loss': 0.0141, 'grad_norm': 5.044348239898682, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.008970771916210651, 'loss_2': 0.00514984130859375, 'loss_3': -16.336273193359375, 'loss_4': 0.5328524112701416, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 16:34:59,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:59,929 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:12<35:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:35:07,248 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02890656515955925, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.092, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0248018279671669, 'eval_loss_2': 0.004104733467102051, 'eval_loss_3': -18.085172653198242, 'eval_loss_4': 0.3029628396034241, 'epoch': 17.97}
{'loss': 0.0111, 'grad_norm': 7.460611343383789, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.010017860680818558, 'loss_2': 0.0011272430419921875, 'loss_3': -16.281742095947266, 'loss_4': 0.24791765213012695, 'epoch': 17.97}
{'loss': 0.0067, 'grad_norm': 5.060264587402344, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.003827076405286789, 'loss_2': 0.002857208251953125, 'loss_3': -16.388362884521484, 'loss_4': 0.25313127040863037, 'epoch': 17.98}
{'loss': 0.0167, 'grad_norm': 6.181139945983887, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.012534626759588718, 'loss_2': 0.004123687744140625, 'loss_3': -16.325613021850586, 'loss_4': -0.16587688028812408, 'epoch': 17.98}
{'loss': 0.0129, 'grad_norm': 5.019193172454834, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.007834191434085369, 'loss_2': 0.00502777099609375, 'loss_3': -16.26077651977539, 'loss_4': 0.36042508482933044, 'epoch': 17.99}
{'loss': 0.0103, 'grad_norm': 4.542118072509766, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.0054007638245821, 'loss_2': 0.004913330078125, 'loss_3': -16.386478424072266, 'loss_4': 0.24608229100704193, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 16:35:07,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:07,249 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:19<34:50,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:35:14,285 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024723513051867485, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.057, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.020493460819125175, 'eval_loss_2': 0.00423005223274231, 'eval_loss_3': -18.105514526367188, 'eval_loss_4': 0.34217435121536255, 'epoch': 17.99}
{'loss': 0.0032, 'grad_norm': 6.265619277954102, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.0020599416457116604, 'loss_2': 0.0011463165283203125, 'loss_3': -16.113094329833984, 'loss_4': 0.3901369571685791, 'epoch': 18.0}
{'loss': 0.0122, 'grad_norm': 6.5943498611450195, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.010591743513941765, 'loss_2': 0.001644134521484375, 'loss_3': -16.12102508544922, 'loss_4': 0.7404723167419434, 'epoch': 18.01}
{'loss': 0.0115, 'grad_norm': 5.31699275970459, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.006166920997202396, 'loss_2': 0.0052947998046875, 'loss_3': -16.101728439331055, 'loss_4': 0.41359537839889526, 'epoch': 18.01}
{'loss': 0.0121, 'grad_norm': 4.478928089141846, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.0045211343094706535, 'loss_2': 0.007572174072265625, 'loss_3': -16.17217254638672, 'loss_4': 0.1817058026790619, 'epoch': 18.02}
{'loss': 0.0112, 'grad_norm': 5.0809431076049805, 'learning_rate': 1.2e-05, 'loss_1': 0.006774448789656162, 'loss_2': 0.0044097900390625, 'loss_3': -16.184974670410156, 'loss_4': -0.011515781283378601, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 16:35:14,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:14,285 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:27<35:49,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:35:21,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021496355533599854, 'eval_runtime': 3.9849, 'eval_samples_per_second': 256.97, 'eval_steps_per_second': 4.015, 'eval_loss_1': 0.01828623004257679, 'eval_loss_2': 0.003210127353668213, 'eval_loss_3': -18.118141174316406, 'eval_loss_4': 0.2457478940486908, 'epoch': 18.02}
{'loss': 0.0105, 'grad_norm': 6.701739311218262, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.009203820489346981, 'loss_2': 0.0013179779052734375, 'loss_3': -16.156301498413086, 'loss_4': 0.5443859100341797, 'epoch': 18.03}
{'loss': 0.0091, 'grad_norm': 4.865537166595459, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.0059120566584169865, 'loss_2': 0.0032176971435546875, 'loss_3': -16.09928321838379, 'loss_4': 0.15064167976379395, 'epoch': 18.03}
{'loss': 0.0106, 'grad_norm': 5.560173034667969, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.009489425458014011, 'loss_2': 0.0011463165283203125, 'loss_3': -16.25107192993164, 'loss_4': 0.24651846289634705, 'epoch': 18.04}
{'loss': 0.0085, 'grad_norm': 4.655960559844971, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.005647621583193541, 'loss_2': 0.002841949462890625, 'loss_3': -16.21308135986328, 'loss_4': -0.008107736706733704, 'epoch': 18.05}
{'loss': 0.0205, 'grad_norm': 7.144950866699219, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.01851620152592659, 'loss_2': 0.001972198486328125, 'loss_3': -16.059356689453125, 'loss_4': 0.3762851357460022, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 16:35:21,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:21,811 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:34<35:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:29,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021327920258045197, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.017915137112140656, 'eval_loss_2': 0.003412783145904541, 'eval_loss_3': -18.116992950439453, 'eval_loss_4': 0.18111589550971985, 'epoch': 18.05}
{'loss': 0.0071, 'grad_norm': 4.8720784187316895, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.004407631698995829, 'loss_2': 0.0027179718017578125, 'loss_3': -16.255931854248047, 'loss_4': 0.22018617391586304, 'epoch': 18.06}
{'loss': 0.0139, 'grad_norm': 5.472630500793457, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.008792485110461712, 'loss_2': 0.0050811767578125, 'loss_3': -16.050113677978516, 'loss_4': 0.03450094908475876, 'epoch': 18.06}
{'loss': 0.0157, 'grad_norm': 6.927603721618652, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.011994516476988792, 'loss_2': 0.003662109375, 'loss_3': -16.34723472595215, 'loss_4': 0.01042746938765049, 'epoch': 18.07}
{'loss': 0.0069, 'grad_norm': 4.675073146820068, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.004832001402974129, 'loss_2': 0.0020599365234375, 'loss_3': -16.34653091430664, 'loss_4': 0.07619858533143997, 'epoch': 18.08}
{'loss': 0.0263, 'grad_norm': 7.34348726272583, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.017656739801168442, 'loss_2': 0.00861358642578125, 'loss_3': -16.18328094482422, 'loss_4': 0.26396387815475464, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 16:35:29,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:29,151 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:41<35:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:36,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020865926519036293, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.328, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01762206479907036, 'eval_loss_2': 0.003243863582611084, 'eval_loss_3': -18.12371063232422, 'eval_loss_4': 0.10832275450229645, 'epoch': 18.08}
{'loss': 0.0115, 'grad_norm': 4.939547538757324, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.007401416078209877, 'loss_2': 0.004138946533203125, 'loss_3': -16.250049591064453, 'loss_4': 0.018356025218963623, 'epoch': 18.09}
{'loss': 0.0086, 'grad_norm': 5.659091472625732, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.00673008244484663, 'loss_2': 0.001880645751953125, 'loss_3': -16.40645408630371, 'loss_4': -0.006993144750595093, 'epoch': 18.09}
{'loss': 0.0071, 'grad_norm': 5.298095226287842, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.005615067668259144, 'loss_2': 0.001453399658203125, 'loss_3': -16.33449935913086, 'loss_4': -0.08121833205223083, 'epoch': 18.1}
{'loss': 0.0064, 'grad_norm': 5.206094741821289, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.005506162066012621, 'loss_2': 0.0008459091186523438, 'loss_3': -16.089502334594727, 'loss_4': 0.41385355591773987, 'epoch': 18.1}
{'loss': 0.0596, 'grad_norm': 17.69980239868164, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.053686752915382385, 'loss_2': 0.00594329833984375, 'loss_3': -16.2630615234375, 'loss_4': 0.1023041382431984, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 16:35:36,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:36,487 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:16:49<35:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:35:43,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02080238237977028, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.32, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.017676029354333878, 'eval_loss_2': 0.0031263530254364014, 'eval_loss_3': -18.12442398071289, 'eval_loss_4': 0.05800508335232735, 'epoch': 18.11}
{'loss': 0.0179, 'grad_norm': 12.670177459716797, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.017028819769620895, 'loss_2': 0.0008325576782226562, 'loss_3': -16.142169952392578, 'loss_4': -0.290539026260376, 'epoch': 18.12}
{'loss': 0.0076, 'grad_norm': 4.937202453613281, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.006032078061252832, 'loss_2': 0.0015735626220703125, 'loss_3': -16.273618698120117, 'loss_4': -0.0008747130632400513, 'epoch': 18.12}
{'loss': 0.015, 'grad_norm': 5.17874813079834, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.010157506912946701, 'loss_2': 0.0048828125, 'loss_3': -16.28948402404785, 'loss_4': 0.11807559430599213, 'epoch': 18.13}
{'loss': 0.0183, 'grad_norm': 6.782402992248535, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.014315853826701641, 'loss_2': 0.00400543212890625, 'loss_3': -16.2441349029541, 'loss_4': -0.01540910080075264, 'epoch': 18.13}
{'loss': 0.0118, 'grad_norm': 5.331570625305176, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.007582497783005238, 'loss_2': 0.00418853759765625, 'loss_3': -16.111541748046875, 'loss_4': -0.08160331845283508, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 16:35:43,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:43,809 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:16:56<35:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:51,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02225884422659874, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.018664801493287086, 'eval_loss_2': 0.003594040870666504, 'eval_loss_3': -18.112987518310547, 'eval_loss_4': 0.11026396602392197, 'epoch': 18.14}
{'loss': 0.0121, 'grad_norm': 4.415602207183838, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.005604180973023176, 'loss_2': 0.0064544677734375, 'loss_3': -16.36168670654297, 'loss_4': -0.13849613070487976, 'epoch': 18.15}
{'loss': 0.0118, 'grad_norm': 7.725472927093506, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.010403049178421497, 'loss_2': 0.0014276504516601562, 'loss_3': -16.378250122070312, 'loss_4': -0.1842135637998581, 'epoch': 18.15}
{'loss': 0.0103, 'grad_norm': 4.5990071296691895, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.005136164370924234, 'loss_2': 0.005161285400390625, 'loss_3': -16.013046264648438, 'loss_4': 0.10677751898765564, 'epoch': 18.16}
{'loss': 0.0515, 'grad_norm': 31.97563362121582, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.04533566161990166, 'loss_2': 0.00618743896484375, 'loss_3': -16.21770477294922, 'loss_4': 0.3454417884349823, 'epoch': 18.16}
{'loss': 0.0186, 'grad_norm': 13.39486312866211, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.015889206901192665, 'loss_2': 0.002735137939453125, 'loss_3': -16.380455017089844, 'loss_4': -0.051884278655052185, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 16:35:51,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:51,143 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:03<35:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:58,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02287571132183075, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.379, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.018462244421243668, 'eval_loss_2': 0.004413466900587082, 'eval_loss_3': -18.129968643188477, 'eval_loss_4': 0.10155577212572098, 'epoch': 18.17}
{'loss': 0.01, 'grad_norm': 5.82504415512085, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.0076040178537368774, 'loss_2': 0.002422332763671875, 'loss_3': -16.166940689086914, 'loss_4': 0.43326735496520996, 'epoch': 18.17}
{'loss': 0.0167, 'grad_norm': 5.442390441894531, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.013459015637636185, 'loss_2': 0.0032444000244140625, 'loss_3': -16.16823387145996, 'loss_4': 0.1366955190896988, 'epoch': 18.18}
{'loss': 0.0129, 'grad_norm': 5.727015972137451, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.0073455520905554295, 'loss_2': 0.00559234619140625, 'loss_3': -16.195457458496094, 'loss_4': -0.09192238748073578, 'epoch': 18.19}
{'loss': 0.0165, 'grad_norm': 8.0715970993042, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.014183806255459785, 'loss_2': 0.002292633056640625, 'loss_3': -16.325918197631836, 'loss_4': 0.3043297529220581, 'epoch': 18.19}
{'loss': 0.0176, 'grad_norm': 13.840971946716309, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.015003316104412079, 'loss_2': 0.002613067626953125, 'loss_3': -16.43105697631836, 'loss_4': 0.4303150177001953, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 16:35:58,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:58,467 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:11<34:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:05,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019939417019486427, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.406, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017063627019524574, 'eval_loss_2': 0.002875789999961853, 'eval_loss_3': -18.1503963470459, 'eval_loss_4': 0.2137937843799591, 'epoch': 18.2}
{'loss': 0.0112, 'grad_norm': 5.00303840637207, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.0053530107252299786, 'loss_2': 0.0058746337890625, 'loss_3': -16.361642837524414, 'loss_4': 0.3315085768699646, 'epoch': 18.2}
{'loss': 0.01, 'grad_norm': 7.291624546051025, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.008660417050123215, 'loss_2': 0.001338958740234375, 'loss_3': -16.240692138671875, 'loss_4': 0.3626066744327545, 'epoch': 18.21}
{'loss': 0.0184, 'grad_norm': 8.262816429138184, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.01422274298965931, 'loss_2': 0.00412750244140625, 'loss_3': -16.314008712768555, 'loss_4': -0.03421253710985184, 'epoch': 18.22}
{'loss': 0.0114, 'grad_norm': 5.443856239318848, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.008033063262701035, 'loss_2': 0.00337982177734375, 'loss_3': -16.380739212036133, 'loss_4': 0.26498186588287354, 'epoch': 18.22}
{'loss': 0.0185, 'grad_norm': 5.494760990142822, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.010384125635027885, 'loss_2': 0.00811767578125, 'loss_3': -16.261930465698242, 'loss_4': 0.46676409244537354, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 16:36:05,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:05,798 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:18<34:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:13,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020693335682153702, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.237, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01631736196577549, 'eval_loss_2': 0.004375971853733063, 'eval_loss_3': -18.16212272644043, 'eval_loss_4': 0.3030983507633209, 'epoch': 18.23}
{'loss': 0.0108, 'grad_norm': 4.977119445800781, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.008383176289498806, 'loss_2': 0.00237274169921875, 'loss_3': -16.304889678955078, 'loss_4': 0.42331403493881226, 'epoch': 18.23}
{'loss': 0.0147, 'grad_norm': 5.873904705047607, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.010809605941176414, 'loss_2': 0.00385284423828125, 'loss_3': -16.441463470458984, 'loss_4': 0.011902280151844025, 'epoch': 18.24}
{'loss': 0.0129, 'grad_norm': 4.70483922958374, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.006574083585292101, 'loss_2': 0.0063018798828125, 'loss_3': -16.3817138671875, 'loss_4': 0.046939872205257416, 'epoch': 18.24}
{'loss': 0.0234, 'grad_norm': 6.252986907958984, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.01458341721445322, 'loss_2': 0.00884246826171875, 'loss_3': -16.26059341430664, 'loss_4': 0.1994103640317917, 'epoch': 18.25}
{'loss': 0.0105, 'grad_norm': 5.728532791137695, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.008589490316808224, 'loss_2': 0.0019359588623046875, 'loss_3': -16.42118263244629, 'loss_4': 1.3019979000091553, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 16:36:13,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:13,125 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:25<34:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:20,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01802709884941578, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.35, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014504554681479931, 'eval_loss_2': 0.003522545099258423, 'eval_loss_3': -18.1802921295166, 'eval_loss_4': 0.27985110878944397, 'epoch': 18.26}
{'loss': 0.0498, 'grad_norm': 28.80170440673828, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.04311924800276756, 'loss_2': 0.0066680908203125, 'loss_3': -16.388919830322266, 'loss_4': 0.6977308392524719, 'epoch': 18.26}
{'loss': 0.0141, 'grad_norm': 5.235372066497803, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.011691605672240257, 'loss_2': 0.0024261474609375, 'loss_3': -16.38239288330078, 'loss_4': 0.4377647042274475, 'epoch': 18.27}
{'loss': 0.0924, 'grad_norm': 11.478248596191406, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.08948149532079697, 'loss_2': 0.0028743743896484375, 'loss_3': -16.203392028808594, 'loss_4': 0.47132375836372375, 'epoch': 18.27}
{'loss': 0.0139, 'grad_norm': 6.527899742126465, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.013545027934014797, 'loss_2': 0.0003600120544433594, 'loss_3': -16.28031349182129, 'loss_4': -0.029348373413085938, 'epoch': 18.28}
{'loss': 0.0124, 'grad_norm': 5.400788307189941, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.0070540993474423885, 'loss_2': 0.0053253173828125, 'loss_3': -16.38901138305664, 'loss_4': 0.3503572344779968, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 16:36:20,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:20,458 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:33<34:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:27,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018993327394127846, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.461, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014343679882586002, 'eval_loss_2': 0.004649646580219269, 'eval_loss_3': -18.16854476928711, 'eval_loss_4': 0.2765774428844452, 'epoch': 18.28}
{'loss': 0.0155, 'grad_norm': 6.874942779541016, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.013694385066628456, 'loss_2': 0.00177764892578125, 'loss_3': -16.359432220458984, 'loss_4': 0.21865402162075043, 'epoch': 18.29}
{'loss': 0.0198, 'grad_norm': 14.627908706665039, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.019727306440472603, 'loss_2': 4.470348358154297e-05, 'loss_3': -16.404541015625, 'loss_4': 0.41388005018234253, 'epoch': 18.3}
{'loss': 0.0168, 'grad_norm': 6.649428844451904, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.009035313501954079, 'loss_2': 0.007724761962890625, 'loss_3': -16.445045471191406, 'loss_4': 0.7837802767753601, 'epoch': 18.3}
{'loss': 0.0183, 'grad_norm': 8.451292037963867, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.015661969780921936, 'loss_2': 0.0026302337646484375, 'loss_3': -16.3763370513916, 'loss_4': 0.4819539189338684, 'epoch': 18.31}
{'loss': 0.0112, 'grad_norm': 5.372694969177246, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.009584473446011543, 'loss_2': 0.00160980224609375, 'loss_3': -16.42942237854004, 'loss_4': 0.5807703733444214, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 16:36:27,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:27,785 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:40<34:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:36:35,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019857488572597504, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.44, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013696095906198025, 'eval_loss_2': 0.006161391735076904, 'eval_loss_3': -18.19866943359375, 'eval_loss_4': 0.16630098223686218, 'epoch': 18.31}
{'loss': 0.0061, 'grad_norm': 5.25200891494751, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.00571058876812458, 'loss_2': 0.00037360191345214844, 'loss_3': -16.423240661621094, 'loss_4': 0.21036368608474731, 'epoch': 18.32}
{'loss': 0.0084, 'grad_norm': 6.780426025390625, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.006935529410839081, 'loss_2': 0.0014781951904296875, 'loss_3': -16.251022338867188, 'loss_4': -0.0284205824136734, 'epoch': 18.33}
{'loss': 0.012, 'grad_norm': 4.9682183265686035, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.005831717513501644, 'loss_2': 0.006134033203125, 'loss_3': -16.41779327392578, 'loss_4': 0.25607436895370483, 'epoch': 18.33}
{'loss': 0.0316, 'grad_norm': 9.93140697479248, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.029591728001832962, 'loss_2': 0.0020465850830078125, 'loss_3': -16.403579711914062, 'loss_4': 0.46590301394462585, 'epoch': 18.34}
{'loss': 0.0133, 'grad_norm': 6.79277229309082, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.013332038186490536, 'loss_2': 1.6093254089355469e-06, 'loss_3': -16.378177642822266, 'loss_4': 0.01884552836418152, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 16:36:35,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:35,107 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:17:47<34:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:42,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01666739210486412, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.645, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.012485300190746784, 'eval_loss_2': 0.004182092845439911, 'eval_loss_3': -18.178415298461914, 'eval_loss_4': 0.06834053248167038, 'epoch': 18.34}
{'loss': 0.0154, 'grad_norm': 6.566122055053711, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.014969074167311192, 'loss_2': 0.0004482269287109375, 'loss_3': -16.130857467651367, 'loss_4': -0.15197288990020752, 'epoch': 18.35}
{'loss': 0.0157, 'grad_norm': 4.499615669250488, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.00924557726830244, 'loss_2': 0.006439208984375, 'loss_3': -16.56277847290039, 'loss_4': 0.26639652252197266, 'epoch': 18.35}
{'loss': 0.0083, 'grad_norm': 4.61287260055542, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.006415671668946743, 'loss_2': 0.001895904541015625, 'loss_3': -16.24730682373047, 'loss_4': 0.26678112149238586, 'epoch': 18.36}
{'loss': 0.0136, 'grad_norm': 6.816031455993652, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.011623994447290897, 'loss_2': 0.001972198486328125, 'loss_3': -16.349830627441406, 'loss_4': 0.4336661696434021, 'epoch': 18.37}
{'loss': 0.016, 'grad_norm': 6.564871788024902, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.014271658845245838, 'loss_2': 0.0017499923706054688, 'loss_3': -16.240293502807617, 'loss_4': 0.254303514957428, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 16:36:42,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:42,431 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:17:55<34:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:49,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016671279445290565, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.547, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.012594559229910374, 'eval_loss_2': 0.004076719284057617, 'eval_loss_3': -18.16839027404785, 'eval_loss_4': 0.08927464485168457, 'epoch': 18.37}
{'loss': 0.0098, 'grad_norm': 5.560041427612305, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.009747225791215897, 'loss_2': 3.337860107421875e-05, 'loss_3': -16.305004119873047, 'loss_4': 0.054566048085689545, 'epoch': 18.38}
{'loss': 0.0078, 'grad_norm': 4.870301723480225, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.00513503048568964, 'loss_2': 0.00266265869140625, 'loss_3': -16.360729217529297, 'loss_4': 0.32986176013946533, 'epoch': 18.38}
{'loss': 0.0111, 'grad_norm': 6.4445624351501465, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.01110241562128067, 'loss_2': 1.2993812561035156e-05, 'loss_3': -16.271671295166016, 'loss_4': 0.1830943375825882, 'epoch': 18.39}
{'loss': 0.0111, 'grad_norm': 5.040235996246338, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.007782539818435907, 'loss_2': 0.0032806396484375, 'loss_3': -16.101104736328125, 'loss_4': -0.04394476115703583, 'epoch': 18.4}
{'loss': 0.011, 'grad_norm': 5.131170749664307, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.005192568060010672, 'loss_2': 0.00583648681640625, 'loss_3': -16.3194637298584, 'loss_4': -0.19015301764011383, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 16:36:49,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:49,758 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:02<34:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:57,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01645694300532341, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.378, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012465162202715874, 'eval_loss_2': 0.0039917826652526855, 'eval_loss_3': -18.15680694580078, 'eval_loss_4': 0.15319059789180756, 'epoch': 18.4}
{'loss': 0.0076, 'grad_norm': 5.150000095367432, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.006358811166137457, 'loss_2': 0.001277923583984375, 'loss_3': -16.504562377929688, 'loss_4': 0.21382638812065125, 'epoch': 18.41}
{'loss': 0.0328, 'grad_norm': 13.780384063720703, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.03182898461818695, 'loss_2': 0.0009927749633789062, 'loss_3': -16.140995025634766, 'loss_4': 0.08540557324886322, 'epoch': 18.41}
{'loss': 0.0116, 'grad_norm': 5.921293258666992, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.009520922787487507, 'loss_2': 0.0020599365234375, 'loss_3': -16.205596923828125, 'loss_4': -0.1301075667142868, 'epoch': 18.42}
{'loss': 0.0121, 'grad_norm': 5.827301979064941, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.0073263393715023994, 'loss_2': 0.004749298095703125, 'loss_3': -16.382766723632812, 'loss_4': 0.10542519390583038, 'epoch': 18.42}
{'loss': 0.0122, 'grad_norm': 5.467844486236572, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.00717926025390625, 'loss_2': 0.00502777099609375, 'loss_3': -16.302846908569336, 'loss_4': 0.16139701008796692, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 16:36:57,085 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:57,085 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:09<34:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:04,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018024424090981483, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.074, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012088011018931866, 'eval_loss_2': 0.005936414003372192, 'eval_loss_3': -18.160442352294922, 'eval_loss_4': 0.1996556669473648, 'epoch': 18.43}
{'loss': 0.0133, 'grad_norm': 5.229219913482666, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.006254046689718962, 'loss_2': 0.007080078125, 'loss_3': -16.2447509765625, 'loss_4': -0.03565191477537155, 'epoch': 18.44}
{'loss': 0.0089, 'grad_norm': 5.215832710266113, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.008261149749159813, 'loss_2': 0.000659942626953125, 'loss_3': -16.28704071044922, 'loss_4': 0.14757946133613586, 'epoch': 18.44}
{'loss': 0.0172, 'grad_norm': 6.2722368240356445, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.010253221727907658, 'loss_2': 0.006927490234375, 'loss_3': -16.183860778808594, 'loss_4': -0.18889106810092926, 'epoch': 18.45}
{'loss': 0.0185, 'grad_norm': 6.747028350830078, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.013523192144930363, 'loss_2': 0.004955291748046875, 'loss_3': -16.4271297454834, 'loss_4': 0.8996934294700623, 'epoch': 18.45}
{'loss': 0.0115, 'grad_norm': 6.094423294067383, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.010935820639133453, 'loss_2': 0.0005731582641601562, 'loss_3': -15.980841636657715, 'loss_4': 0.21142667531967163, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 16:37:04,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:04,423 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:17<34:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:11,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01595909520983696, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012890202924609184, 'eval_loss_2': 0.003068894147872925, 'eval_loss_3': -18.14495086669922, 'eval_loss_4': 0.2961995601654053, 'epoch': 18.46}
{'loss': 0.0077, 'grad_norm': 4.861879825592041, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.007059271913021803, 'loss_2': 0.0006160736083984375, 'loss_3': -16.199440002441406, 'loss_4': 0.3855128288269043, 'epoch': 18.47}
{'loss': 0.0071, 'grad_norm': 4.985285758972168, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.0069530499167740345, 'loss_2': 0.00016200542449951172, 'loss_3': -16.18419075012207, 'loss_4': 0.30362629890441895, 'epoch': 18.47}
{'loss': 0.0122, 'grad_norm': 5.387083053588867, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.008712664246559143, 'loss_2': 0.003475189208984375, 'loss_3': -16.272113800048828, 'loss_4': 0.4005594849586487, 'epoch': 18.48}
{'loss': 0.0165, 'grad_norm': 6.883744716644287, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.012419331818819046, 'loss_2': 0.004070281982421875, 'loss_3': -16.38713836669922, 'loss_4': 0.8821614384651184, 'epoch': 18.48}
{'loss': 0.0179, 'grad_norm': 11.754262924194336, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.016881441697478294, 'loss_2': 0.0010347366333007812, 'loss_3': -16.16183090209961, 'loss_4': 0.4224429726600647, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 16:37:11,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:11,750 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:24<34:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:19,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01557592861354351, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.545, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.012551721185445786, 'eval_loss_2': 0.0030242055654525757, 'eval_loss_3': -18.14902114868164, 'eval_loss_4': 0.3782321810722351, 'epoch': 18.49}
{'loss': 0.0097, 'grad_norm': 4.565370082855225, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.005698378663510084, 'loss_2': 0.0039520263671875, 'loss_3': -16.233381271362305, 'loss_4': 0.23533809185028076, 'epoch': 18.49}
{'loss': 0.0288, 'grad_norm': 9.525177001953125, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.02350970171391964, 'loss_2': 0.005279541015625, 'loss_3': -16.18598175048828, 'loss_4': 0.7755385637283325, 'epoch': 18.5}
{'loss': 0.013, 'grad_norm': 5.3030877113342285, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.008428096771240234, 'loss_2': 0.004619598388671875, 'loss_3': -16.453899383544922, 'loss_4': 0.5052316188812256, 'epoch': 18.51}
{'loss': 0.0171, 'grad_norm': 6.8611321449279785, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.010934334248304367, 'loss_2': 0.0061187744140625, 'loss_3': -16.218151092529297, 'loss_4': 0.39367127418518066, 'epoch': 18.51}
{'loss': 0.0179, 'grad_norm': 6.060311317443848, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.0068172262981534, 'loss_2': 0.0110931396484375, 'loss_3': -16.365028381347656, 'loss_4': 0.8315585851669312, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 16:37:19,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:19,072 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:31<34:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:26,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015208209864795208, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.63, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01220025960355997, 'eval_loss_2': 0.003007948398590088, 'eval_loss_3': -18.12579345703125, 'eval_loss_4': 0.43224474787712097, 'epoch': 18.52}
{'loss': 0.0093, 'grad_norm': 5.305455207824707, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.00834070984274149, 'loss_2': 0.0009293556213378906, 'loss_3': -16.158363342285156, 'loss_4': -0.012407161295413971, 'epoch': 18.52}
{'loss': 0.0238, 'grad_norm': 7.48187780380249, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.014953329227864742, 'loss_2': 0.0088348388671875, 'loss_3': -16.250734329223633, 'loss_4': 0.16534051299095154, 'epoch': 18.53}
{'loss': 0.0113, 'grad_norm': 5.363292217254639, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.00617059925571084, 'loss_2': 0.0051422119140625, 'loss_3': -16.207637786865234, 'loss_4': 0.63898766040802, 'epoch': 18.53}
{'loss': 0.0287, 'grad_norm': 15.042010307312012, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.020945847034454346, 'loss_2': 0.00771331787109375, 'loss_3': -16.205577850341797, 'loss_4': 0.5462422966957092, 'epoch': 18.54}
{'loss': 0.0282, 'grad_norm': 10.953805923461914, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.0224553644657135, 'loss_2': 0.0057525634765625, 'loss_3': -16.35472297668457, 'loss_4': 0.6826799511909485, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 16:37:26,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:26,395 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:39<33:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:33,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014763228595256805, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.643, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01166634913533926, 'eval_loss_2': 0.0030968785285949707, 'eval_loss_3': -18.133316040039062, 'eval_loss_4': 0.5486510992050171, 'epoch': 18.55}
{'loss': 0.0121, 'grad_norm': 7.0225830078125, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.011902344413101673, 'loss_2': 0.00015211105346679688, 'loss_3': -16.31929588317871, 'loss_4': 0.6158220767974854, 'epoch': 18.55}
{'loss': 0.0104, 'grad_norm': 4.599118709564209, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.004982153419405222, 'loss_2': 0.00542449951171875, 'loss_3': -16.19734764099121, 'loss_4': 0.7099716663360596, 'epoch': 18.56}
{'loss': 0.0185, 'grad_norm': 6.0568671226501465, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.015871945768594742, 'loss_2': 0.002582550048828125, 'loss_3': -16.222124099731445, 'loss_4': 0.1341523826122284, 'epoch': 18.56}
{'loss': 0.0117, 'grad_norm': 5.027451515197754, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.007960607297718525, 'loss_2': 0.0037689208984375, 'loss_3': -16.353824615478516, 'loss_4': 0.7478911876678467, 'epoch': 18.57}
{'loss': 0.0131, 'grad_norm': 6.117638111114502, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.008504394441843033, 'loss_2': 0.0045623779296875, 'loss_3': -16.172292709350586, 'loss_4': 0.86001056432724, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 16:37:33,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:33,721 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:18:46<33:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:41,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014599466696381569, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.183, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011120805516839027, 'eval_loss_2': 0.0034786611795425415, 'eval_loss_3': -18.117176055908203, 'eval_loss_4': 0.6504027843475342, 'epoch': 18.58}
{'loss': 0.0241, 'grad_norm': 11.59201717376709, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.0220576673746109, 'loss_2': 0.00202178955078125, 'loss_3': -16.340957641601562, 'loss_4': 0.6431790590286255, 'epoch': 18.58}
{'loss': 0.0099, 'grad_norm': 4.44078254699707, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.008525828830897808, 'loss_2': 0.0013332366943359375, 'loss_3': -16.281532287597656, 'loss_4': 0.5763641595840454, 'epoch': 18.59}
{'loss': 0.0088, 'grad_norm': 5.000508785247803, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.005191192030906677, 'loss_2': 0.003604888916015625, 'loss_3': -16.269969940185547, 'loss_4': 0.6516373753547668, 'epoch': 18.59}
{'loss': 0.0127, 'grad_norm': 5.26440954208374, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.009960701689124107, 'loss_2': 0.0026912689208984375, 'loss_3': -16.213830947875977, 'loss_4': 0.3071046769618988, 'epoch': 18.6}
{'loss': 0.0235, 'grad_norm': 6.2934889793396, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.011941290460526943, 'loss_2': 0.011566162109375, 'loss_3': -16.423917770385742, 'loss_4': 0.9953361749649048, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 16:37:41,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:41,052 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:18:53<33:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:48,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014095019549131393, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.608, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.010079990141093731, 'eval_loss_2': 0.004015028476715088, 'eval_loss_3': -18.14352035522461, 'eval_loss_4': 0.8319453001022339, 'epoch': 18.6}
{'loss': 0.0836, 'grad_norm': 18.386098861694336, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.08252562582492828, 'loss_2': 0.00104522705078125, 'loss_3': -16.281164169311523, 'loss_4': 0.8820955157279968, 'epoch': 18.61}
{'loss': 0.0081, 'grad_norm': 4.303888320922852, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.006299662869423628, 'loss_2': 0.00177001953125, 'loss_3': -16.111469268798828, 'loss_4': 0.9191443920135498, 'epoch': 18.62}
{'loss': 0.0121, 'grad_norm': 5.776053428649902, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.01194277498871088, 'loss_2': 0.0001342296600341797, 'loss_3': -16.3035888671875, 'loss_4': 1.0453569889068604, 'epoch': 18.62}
{'loss': 0.0204, 'grad_norm': 7.499340057373047, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.01697450876235962, 'loss_2': 0.003459930419921875, 'loss_3': -16.306228637695312, 'loss_4': 0.7580111622810364, 'epoch': 18.63}
{'loss': 0.0177, 'grad_norm': 6.528343677520752, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.013912215828895569, 'loss_2': 0.003826141357421875, 'loss_3': -16.327510833740234, 'loss_4': 0.09720344096422195, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 16:37:48,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:48,375 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:01<33:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:37:55,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015070291236042976, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.412, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011409551836550236, 'eval_loss_2': 0.003660738468170166, 'eval_loss_3': -18.149826049804688, 'eval_loss_4': 0.8292302489280701, 'epoch': 18.63}
{'loss': 0.0145, 'grad_norm': 6.497964859008789, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.013944721780717373, 'loss_2': 0.0005850791931152344, 'loss_3': -16.078325271606445, 'loss_4': 1.0887047052383423, 'epoch': 18.64}
{'loss': 0.0096, 'grad_norm': 4.380557060241699, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.00509360246360302, 'loss_2': 0.00455474853515625, 'loss_3': -16.438373565673828, 'loss_4': 0.7564183473587036, 'epoch': 18.65}
{'loss': 0.0215, 'grad_norm': 6.0288519859313965, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.01633690856397152, 'loss_2': 0.005161285400390625, 'loss_3': -16.279367446899414, 'loss_4': 0.4660038948059082, 'epoch': 18.65}
{'loss': 0.0086, 'grad_norm': 6.232670307159424, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.008604360744357109, 'loss_2': 2.491474151611328e-05, 'loss_3': -16.122146606445312, 'loss_4': 0.7809395790100098, 'epoch': 18.66}
{'loss': 0.0183, 'grad_norm': 5.946056842803955, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.0141734154894948, 'loss_2': 0.004085540771484375, 'loss_3': -16.139875411987305, 'loss_4': 0.6141705513000488, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 16:37:55,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:55,698 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:08<33:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:03,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013374142348766327, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.358, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.009777061641216278, 'eval_loss_2': 0.003597080707550049, 'eval_loss_3': -18.148263931274414, 'eval_loss_4': 0.781970739364624, 'epoch': 18.66}
{'loss': 0.0139, 'grad_norm': 5.992869853973389, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.010167792439460754, 'loss_2': 0.0037364959716796875, 'loss_3': -15.955710411071777, 'loss_4': 0.8911054134368896, 'epoch': 18.67}
{'loss': 0.0176, 'grad_norm': 7.668060302734375, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.015276460908353329, 'loss_2': 0.0023326873779296875, 'loss_3': -16.140445709228516, 'loss_4': 0.09016038477420807, 'epoch': 18.67}
{'loss': 0.0179, 'grad_norm': 6.859378814697266, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.015907082706689835, 'loss_2': 0.0019893646240234375, 'loss_3': -16.40526008605957, 'loss_4': 0.5387257933616638, 'epoch': 18.68}
{'loss': 0.0138, 'grad_norm': 5.790640354156494, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.01207730546593666, 'loss_2': 0.0017547607421875, 'loss_3': -16.3786563873291, 'loss_4': 0.7644309401512146, 'epoch': 18.69}
{'loss': 0.0128, 'grad_norm': 5.449954986572266, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.00860092043876648, 'loss_2': 0.00418853759765625, 'loss_3': -16.15308952331543, 'loss_4': 0.5914006233215332, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 16:38:03,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:03,026 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:15<33:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:10,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013418521732091904, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.421, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.009000416845083237, 'eval_loss_2': 0.004418104887008667, 'eval_loss_3': -18.149717330932617, 'eval_loss_4': 0.8076741695404053, 'epoch': 18.69}
{'loss': 0.0083, 'grad_norm': 6.501620292663574, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.008095581084489822, 'loss_2': 0.00022101402282714844, 'loss_3': -16.563636779785156, 'loss_4': 0.7040506601333618, 'epoch': 18.7}
{'loss': 0.0169, 'grad_norm': 8.41355037689209, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.013625058345496655, 'loss_2': 0.00325775146484375, 'loss_3': -16.358116149902344, 'loss_4': 0.4126560091972351, 'epoch': 18.7}
{'loss': 0.0171, 'grad_norm': 7.747007369995117, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.012561073526740074, 'loss_2': 0.004489898681640625, 'loss_3': -16.075183868408203, 'loss_4': 0.8079156875610352, 'epoch': 18.71}
{'loss': 0.0313, 'grad_norm': 17.787019729614258, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.019955310970544815, 'loss_2': 0.01137542724609375, 'loss_3': -16.239498138427734, 'loss_4': 0.7033848762512207, 'epoch': 18.72}
{'loss': 0.017, 'grad_norm': 7.476433277130127, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.008697080425918102, 'loss_2': 0.0082855224609375, 'loss_3': -16.04126739501953, 'loss_4': 0.4957367181777954, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 16:38:10,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:10,352 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:23<33:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:17,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015140511095523834, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.271, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.009666658006608486, 'eval_loss_2': 0.0054738521575927734, 'eval_loss_3': -18.125797271728516, 'eval_loss_4': 0.8538827300071716, 'epoch': 18.72}
{'loss': 0.0152, 'grad_norm': 5.376303195953369, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.009578273631632328, 'loss_2': 0.005584716796875, 'loss_3': -16.110136032104492, 'loss_4': 0.5474870204925537, 'epoch': 18.73}
{'loss': 0.0198, 'grad_norm': 5.235386371612549, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.009412165731191635, 'loss_2': 0.01043701171875, 'loss_3': -16.27143669128418, 'loss_4': 0.7717188000679016, 'epoch': 18.73}
{'loss': 0.0146, 'grad_norm': 6.787910461425781, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.010146651417016983, 'loss_2': 0.0044708251953125, 'loss_3': -16.297340393066406, 'loss_4': 0.8537921905517578, 'epoch': 18.74}
{'loss': 0.0111, 'grad_norm': 4.810876846313477, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.006177090108394623, 'loss_2': 0.00487518310546875, 'loss_3': -16.209117889404297, 'loss_4': 0.7863799333572388, 'epoch': 18.74}
{'loss': 0.0075, 'grad_norm': 4.576840877532959, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.004243677947670221, 'loss_2': 0.003223419189453125, 'loss_3': -16.235132217407227, 'loss_4': 0.8075525760650635, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 16:38:17,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:17,679 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:30<33:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:25,014 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014605099335312843, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.732, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010804945603013039, 'eval_loss_2': 0.0038001537322998047, 'eval_loss_3': -18.12506866455078, 'eval_loss_4': 0.8223597407341003, 'epoch': 18.75}
{'loss': 0.0123, 'grad_norm': 4.725874423980713, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.00548162404447794, 'loss_2': 0.006839752197265625, 'loss_3': -16.17765998840332, 'loss_4': 0.6955897808074951, 'epoch': 18.76}
{'loss': 0.0072, 'grad_norm': 4.852456092834473, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.004934299737215042, 'loss_2': 0.00228118896484375, 'loss_3': -16.190099716186523, 'loss_4': 0.7549652457237244, 'epoch': 18.76}
{'loss': 0.0078, 'grad_norm': 4.678166389465332, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.003872192231938243, 'loss_2': 0.0039520263671875, 'loss_3': -16.250991821289062, 'loss_4': 0.7554793357849121, 'epoch': 18.77}
{'loss': 0.016, 'grad_norm': 8.207148551940918, 'learning_rate': 1.125e-05, 'loss_1': 0.015313195064663887, 'loss_2': 0.0006728172302246094, 'loss_3': -16.138967514038086, 'loss_4': 0.9515328407287598, 'epoch': 18.77}
{'loss': 0.009, 'grad_norm': 5.011490345001221, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.007171385455876589, 'loss_2': 0.001796722412109375, 'loss_3': -16.174043655395508, 'loss_4': 0.5389248132705688, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 16:38:25,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:25,015 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:37<33:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:38:32,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015049437060952187, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.508, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.011621172539889812, 'eval_loss_2': 0.0034282654523849487, 'eval_loss_3': -18.110881805419922, 'eval_loss_4': 0.8129153251647949, 'epoch': 18.78}
{'loss': 0.0152, 'grad_norm': 6.921298503875732, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.013172104023396969, 'loss_2': 0.0020122528076171875, 'loss_3': -16.17740249633789, 'loss_4': 1.162583589553833, 'epoch': 18.78}
{'loss': 0.0113, 'grad_norm': 6.053894996643066, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.010181101970374584, 'loss_2': 0.0011453628540039062, 'loss_3': -16.152915954589844, 'loss_4': 1.118459939956665, 'epoch': 18.79}
{'loss': 0.009, 'grad_norm': 5.118558406829834, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.007107187062501907, 'loss_2': 0.0018444061279296875, 'loss_3': -16.10086441040039, 'loss_4': 0.7851793169975281, 'epoch': 18.8}
{'loss': 0.0118, 'grad_norm': 5.9395575523376465, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.008142204023897648, 'loss_2': 0.00360870361328125, 'loss_3': -16.23836326599121, 'loss_4': 0.7239845991134644, 'epoch': 18.8}
{'loss': 0.0099, 'grad_norm': 5.100830554962158, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.005764367524534464, 'loss_2': 0.00411224365234375, 'loss_3': -16.16183853149414, 'loss_4': 0.5722559690475464, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 16:38:32,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:32,335 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:19:45<33:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:38:39,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015421832911670208, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.392, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011302095837891102, 'eval_loss_2': 0.004119738936424255, 'eval_loss_3': -18.109882354736328, 'eval_loss_4': 0.8966516852378845, 'epoch': 18.81}
{'loss': 0.0168, 'grad_norm': 7.788809776306152, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.012001178227365017, 'loss_2': 0.0047607421875, 'loss_3': -16.161571502685547, 'loss_4': 1.4958906173706055, 'epoch': 18.81}
{'loss': 0.0109, 'grad_norm': 5.252834320068359, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.008879930712282658, 'loss_2': 0.002048492431640625, 'loss_3': -16.081148147583008, 'loss_4': 0.8694391250610352, 'epoch': 18.82}
{'loss': 0.0071, 'grad_norm': 4.802591800689697, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.005346553400158882, 'loss_2': 0.001781463623046875, 'loss_3': -16.215259552001953, 'loss_4': 0.9455915689468384, 'epoch': 18.83}
{'loss': 0.0038, 'grad_norm': 4.578098297119141, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.003558253636583686, 'loss_2': 0.00023376941680908203, 'loss_3': -16.17487144470215, 'loss_4': 0.9520586729049683, 'epoch': 18.83}
{'loss': 0.006, 'grad_norm': 4.774250507354736, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.0049831741489470005, 'loss_2': 0.0009975433349609375, 'loss_3': -16.078968048095703, 'loss_4': 1.1531713008880615, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 16:38:39,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:39,658 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:19:52<33:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:46,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013676704838871956, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.066, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011193041689693928, 'eval_loss_2': 0.0024836622178554535, 'eval_loss_3': -18.10869026184082, 'eval_loss_4': 0.8536527156829834, 'epoch': 18.84}
{'loss': 0.0095, 'grad_norm': 4.5768208503723145, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.004163696896284819, 'loss_2': 0.00534820556640625, 'loss_3': -16.264102935791016, 'loss_4': 0.8038537502288818, 'epoch': 18.84}
{'loss': 0.0105, 'grad_norm': 8.699783325195312, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.007880105637013912, 'loss_2': 0.002655029296875, 'loss_3': -16.170448303222656, 'loss_4': 1.229683756828308, 'epoch': 18.85}
{'loss': 0.0141, 'grad_norm': 4.844133377075195, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.007798022590577602, 'loss_2': 0.006317138671875, 'loss_3': -16.114965438842773, 'loss_4': 0.7951892614364624, 'epoch': 18.85}
{'loss': 0.0378, 'grad_norm': 9.822693824768066, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.031937550753355026, 'loss_2': 0.005863189697265625, 'loss_3': -16.30484962463379, 'loss_4': 0.8705990314483643, 'epoch': 18.86}
{'loss': 0.0194, 'grad_norm': 6.971498966217041, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.010275808162987232, 'loss_2': 0.0091094970703125, 'loss_3': -16.260398864746094, 'loss_4': 0.9733083844184875, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 16:38:46,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:46,995 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:19:59<32:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:54,314 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014859678223729134, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.463, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01099115889519453, 'eval_loss_2': 0.0038685202598571777, 'eval_loss_3': -18.102968215942383, 'eval_loss_4': 0.7743875980377197, 'epoch': 18.87}
{'loss': 0.0112, 'grad_norm': 5.380910873413086, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.00756080960854888, 'loss_2': 0.003620147705078125, 'loss_3': -16.169559478759766, 'loss_4': 0.7081063985824585, 'epoch': 18.87}
{'loss': 0.0209, 'grad_norm': 6.43291711807251, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.011553396470844746, 'loss_2': 0.009368896484375, 'loss_3': -16.18727684020996, 'loss_4': 0.6554476022720337, 'epoch': 18.88}
{'loss': 0.0181, 'grad_norm': 7.076531887054443, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.013193361461162567, 'loss_2': 0.0048828125, 'loss_3': -15.864538192749023, 'loss_4': 0.8637065887451172, 'epoch': 18.88}
{'loss': 0.017, 'grad_norm': 5.756954669952393, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.0080497357994318, 'loss_2': 0.00890350341796875, 'loss_3': -16.312341690063477, 'loss_4': 0.7110050916671753, 'epoch': 18.89}
{'loss': 0.0151, 'grad_norm': 4.523834705352783, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.0058632236905395985, 'loss_2': 0.00919342041015625, 'loss_3': -16.264089584350586, 'loss_4': 0.8259804844856262, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 16:38:54,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:54,315 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:07<32:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:01,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013593703508377075, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.323, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01082348171621561, 'eval_loss_2': 0.0027702227234840393, 'eval_loss_3': -18.089942932128906, 'eval_loss_4': 0.7742164731025696, 'epoch': 18.9}
{'loss': 0.0106, 'grad_norm': 5.284529685974121, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.008226427249610424, 'loss_2': 0.002414703369140625, 'loss_3': -16.169692993164062, 'loss_4': 0.730832040309906, 'epoch': 18.9}
{'loss': 0.0123, 'grad_norm': 6.515504837036133, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.009587837383151054, 'loss_2': 0.002681732177734375, 'loss_3': -16.337284088134766, 'loss_4': 0.749014139175415, 'epoch': 18.91}
{'loss': 0.0082, 'grad_norm': 5.035619735717773, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.006768328137695789, 'loss_2': 0.0013904571533203125, 'loss_3': -16.06847381591797, 'loss_4': 0.4847875237464905, 'epoch': 18.91}
{'loss': 0.0092, 'grad_norm': 6.575240135192871, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.00895023811608553, 'loss_2': 0.00029850006103515625, 'loss_3': -16.2514591217041, 'loss_4': 0.9834829568862915, 'epoch': 18.92}
{'loss': 0.0116, 'grad_norm': 5.798782825469971, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.006010831333696842, 'loss_2': 0.00556182861328125, 'loss_3': -16.207256317138672, 'loss_4': 0.745322585105896, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 16:39:01,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:01,643 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:14<32:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:08,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014666514471173286, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.413, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011384616605937481, 'eval_loss_2': 0.00328189879655838, 'eval_loss_3': -18.103227615356445, 'eval_loss_4': 0.8447554111480713, 'epoch': 18.92}
{'loss': 0.0138, 'grad_norm': 5.3769755363464355, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.009954195469617844, 'loss_2': 0.00384521484375, 'loss_3': -16.00718116760254, 'loss_4': 0.4205363392829895, 'epoch': 18.93}
{'loss': 0.0124, 'grad_norm': 6.4834208488464355, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.010302947834134102, 'loss_2': 0.002056121826171875, 'loss_3': -16.18351173400879, 'loss_4': 0.9872415661811829, 'epoch': 18.94}
{'loss': 0.0116, 'grad_norm': 6.11099910736084, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.009932927787303925, 'loss_2': 0.0016345977783203125, 'loss_3': -16.125036239624023, 'loss_4': 0.6063591241836548, 'epoch': 18.94}
{'loss': 0.0075, 'grad_norm': 4.538721084594727, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.00513623608276248, 'loss_2': 0.0023899078369140625, 'loss_3': -16.431846618652344, 'loss_4': 0.1849370002746582, 'epoch': 18.95}
{'loss': 0.0086, 'grad_norm': 4.945049285888672, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.008205018937587738, 'loss_2': 0.0004203319549560547, 'loss_3': -16.09832000732422, 'loss_4': 1.1460041999816895, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 16:39:08,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:08,968 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:21<32:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:39:16,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574704423546791, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.418, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012001384049654007, 'eval_loss_2': 0.003745660185813904, 'eval_loss_3': -18.112619400024414, 'eval_loss_4': 0.7694117426872253, 'epoch': 18.95}
{'loss': 0.0082, 'grad_norm': 5.275995254516602, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.007260517682880163, 'loss_2': 0.000896453857421875, 'loss_3': -16.25963020324707, 'loss_4': 0.6815544962882996, 'epoch': 18.96}
{'loss': 0.0147, 'grad_norm': 6.814011096954346, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.01112974714487791, 'loss_2': 0.003551483154296875, 'loss_3': -16.169662475585938, 'loss_4': 0.7020539045333862, 'epoch': 18.97}
{'loss': 0.0071, 'grad_norm': 4.724037170410156, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.006339712999761105, 'loss_2': 0.0007119178771972656, 'loss_3': -16.2431640625, 'loss_4': 0.9821537733078003, 'epoch': 18.97}
{'loss': 0.01, 'grad_norm': 4.856204032897949, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.006500445306301117, 'loss_2': 0.0035190582275390625, 'loss_3': -16.16034698486328, 'loss_4': 0.2726626396179199, 'epoch': 18.98}
{'loss': 0.0135, 'grad_norm': 4.738455772399902, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.007060208823531866, 'loss_2': 0.00641632080078125, 'loss_3': -16.25182342529297, 'loss_4': 0.7432749271392822, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 16:39:16,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:16,291 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:28<31:16,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 16:39:23,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016021305695176125, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.592, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.012492291629314423, 'eval_loss_2': 0.0035290122032165527, 'eval_loss_3': -18.136913299560547, 'eval_loss_4': 0.6427377462387085, 'epoch': 18.98}
{'loss': 0.005, 'grad_norm': 4.687591552734375, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.0036619743332266808, 'loss_2': 0.0013446807861328125, 'loss_3': -16.147754669189453, 'loss_4': 0.49139174818992615, 'epoch': 18.99}
{'loss': 0.0127, 'grad_norm': 5.137612342834473, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.010177482850849628, 'loss_2': 0.0024890899658203125, 'loss_3': -15.895003318786621, 'loss_4': 0.5361483097076416, 'epoch': 18.99}
{'loss': 0.0092, 'grad_norm': 6.827392578125, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.0037787880282849073, 'loss_2': 0.00542449951171875, 'loss_3': -16.034109115600586, 'loss_4': 0.27303117513656616, 'epoch': 19.0}
{'loss': 0.0151, 'grad_norm': 5.048725605010986, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.007245093584060669, 'loss_2': 0.00788116455078125, 'loss_3': -16.238872528076172, 'loss_4': 0.718687117099762, 'epoch': 19.01}
{'loss': 0.0722, 'grad_norm': 12.582378387451172, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.07014540582895279, 'loss_2': 0.0020694732666015625, 'loss_3': -16.264841079711914, 'loss_4': 0.7869303226470947, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 16:39:23,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:23,302 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:36<32:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:39:30,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017848294228315353, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.591, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014073257334530354, 'eval_loss_2': 0.0037750378251075745, 'eval_loss_3': -18.12287139892578, 'eval_loss_4': 0.5575969219207764, 'epoch': 19.01}
{'loss': 0.0214, 'grad_norm': 10.121862411499023, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.017119187861680984, 'loss_2': 0.0042724609375, 'loss_3': -16.33188247680664, 'loss_4': 0.4547772705554962, 'epoch': 19.02}
{'loss': 0.0163, 'grad_norm': 5.337708950042725, 'learning_rate': 1.1e-05, 'loss_1': 0.008379414677619934, 'loss_2': 0.00792694091796875, 'loss_3': -16.184606552124023, 'loss_4': 0.9493472576141357, 'epoch': 19.02}
{'loss': 0.0183, 'grad_norm': 5.395270347595215, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.009221772663295269, 'loss_2': 0.009033203125, 'loss_3': -16.16024398803711, 'loss_4': 0.975896954536438, 'epoch': 19.03}
{'loss': 0.0165, 'grad_norm': 6.660877227783203, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.007471152115613222, 'loss_2': 0.0090484619140625, 'loss_3': -16.230934143066406, 'loss_4': 0.7350207567214966, 'epoch': 19.03}
{'loss': 0.02, 'grad_norm': 8.212430000305176, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.018524929881095886, 'loss_2': 0.0014629364013671875, 'loss_3': -16.297027587890625, 'loss_4': 0.6122560501098633, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 16:39:30,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:30,628 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:20:43<32:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:39:37,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018555544316768646, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.516, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014705445617437363, 'eval_loss_2': 0.003850102424621582, 'eval_loss_3': -18.12409782409668, 'eval_loss_4': 0.5177860260009766, 'epoch': 19.04}
{'loss': 0.008, 'grad_norm': 5.821046352386475, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.005620955489575863, 'loss_2': 0.00238037109375, 'loss_3': -16.240312576293945, 'loss_4': 0.7545928359031677, 'epoch': 19.05}
{'loss': 0.0101, 'grad_norm': 5.45268440246582, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.008952663280069828, 'loss_2': 0.0011415481567382812, 'loss_3': -16.196640014648438, 'loss_4': 0.9253443479537964, 'epoch': 19.05}
{'loss': 0.0973, 'grad_norm': 19.04123878479004, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.09017632156610489, 'loss_2': 0.0071563720703125, 'loss_3': -16.1136474609375, 'loss_4': 0.857068657875061, 'epoch': 19.06}
{'loss': 0.0068, 'grad_norm': 4.954317569732666, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.006098383106291294, 'loss_2': 0.000736236572265625, 'loss_3': -16.066173553466797, 'loss_4': 1.0392138957977295, 'epoch': 19.06}
{'loss': 0.0135, 'grad_norm': 5.331885814666748, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.007906901650130749, 'loss_2': 0.0055694580078125, 'loss_3': -16.001983642578125, 'loss_4': 0.3770151734352112, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 16:39:37,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:37,949 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:20:50<32:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:45,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01836243085563183, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.937, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01463253702968359, 'eval_loss_2': 0.003729894757270813, 'eval_loss_3': -18.11578941345215, 'eval_loss_4': 0.559022843837738, 'epoch': 19.07}
{'loss': 0.0095, 'grad_norm': 7.962005615234375, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.008509639650583267, 'loss_2': 0.0009784698486328125, 'loss_3': -16.15129280090332, 'loss_4': 0.6248882412910461, 'epoch': 19.08}
{'loss': 0.0056, 'grad_norm': 5.029842376708984, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.004983206745237112, 'loss_2': 0.0006551742553710938, 'loss_3': -16.30400848388672, 'loss_4': 0.27882808446884155, 'epoch': 19.08}
{'loss': 0.0106, 'grad_norm': 5.562081813812256, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.007311869878321886, 'loss_2': 0.0032501220703125, 'loss_3': -16.265779495239258, 'loss_4': 0.8806354403495789, 'epoch': 19.09}
{'loss': 0.0252, 'grad_norm': 8.347184181213379, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.01875421404838562, 'loss_2': 0.0064544677734375, 'loss_3': -16.188440322875977, 'loss_4': 0.6166989207267761, 'epoch': 19.09}
{'loss': 0.0161, 'grad_norm': 4.640646934509277, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.005280692130327225, 'loss_2': 0.0108489990234375, 'loss_3': -16.189632415771484, 'loss_4': 0.38099169731140137, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 16:39:45,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:45,291 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:20:58<32:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:39:52,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018771160393953323, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.616, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014728721231222153, 'eval_loss_2': 0.004042439162731171, 'eval_loss_3': -18.10301399230957, 'eval_loss_4': 0.538850724697113, 'epoch': 19.1}
{'loss': 0.0056, 'grad_norm': 4.563480854034424, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.005316182971000671, 'loss_2': 0.00024402141571044922, 'loss_3': -16.278453826904297, 'loss_4': 0.6653350591659546, 'epoch': 19.1}
{'loss': 0.0049, 'grad_norm': 4.803544998168945, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.0034605369437485933, 'loss_2': 0.00144195556640625, 'loss_3': -16.353328704833984, 'loss_4': 0.6120408773422241, 'epoch': 19.11}
{'loss': 0.0053, 'grad_norm': 4.782556533813477, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.00421055918559432, 'loss_2': 0.001041412353515625, 'loss_3': -16.173831939697266, 'loss_4': 0.38706865906715393, 'epoch': 19.12}
{'loss': 0.0107, 'grad_norm': 4.950320243835449, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.005390222650021315, 'loss_2': 0.005260467529296875, 'loss_3': -16.341854095458984, 'loss_4': 0.9544154405593872, 'epoch': 19.12}
{'loss': 0.0142, 'grad_norm': 5.595407485961914, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.013914470560848713, 'loss_2': 0.00026607513427734375, 'loss_3': -16.37094497680664, 'loss_4': 0.670794665813446, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 16:39:52,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:52,614 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:05<32:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:59,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02162906900048256, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.553, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.016057709231972694, 'eval_loss_2': 0.005571357905864716, 'eval_loss_3': -18.090356826782227, 'eval_loss_4': 0.456209272146225, 'epoch': 19.13}
{'loss': 0.0077, 'grad_norm': 4.7205810546875, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.003334455192089081, 'loss_2': 0.004413604736328125, 'loss_3': -16.207271575927734, 'loss_4': 0.5591813921928406, 'epoch': 19.13}
{'loss': 0.01, 'grad_norm': 5.095004558563232, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.004551745485514402, 'loss_2': 0.005489349365234375, 'loss_3': -16.271713256835938, 'loss_4': 0.6082553863525391, 'epoch': 19.14}
{'loss': 0.0139, 'grad_norm': 8.376999855041504, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.012447536922991276, 'loss_2': 0.00141143798828125, 'loss_3': -16.155170440673828, 'loss_4': 0.6561727523803711, 'epoch': 19.15}
{'loss': 0.0112, 'grad_norm': 5.009313583374023, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.005799934733659029, 'loss_2': 0.005390167236328125, 'loss_3': -16.268354415893555, 'loss_4': 0.673416018486023, 'epoch': 19.15}
{'loss': 0.0256, 'grad_norm': 7.440118789672852, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.016443679109215736, 'loss_2': 0.0091094970703125, 'loss_3': -16.118816375732422, 'loss_4': 0.5326297283172607, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 16:39:59,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:59,939 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:12<32:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:07,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02253171242773533, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.644, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01696612872183323, 'eval_loss_2': 0.0055655837059021, 'eval_loss_3': -18.06125259399414, 'eval_loss_4': 0.3750882148742676, 'epoch': 19.16}
{'loss': 0.014, 'grad_norm': 5.110398292541504, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.008902279660105705, 'loss_2': 0.00507354736328125, 'loss_3': -16.272632598876953, 'loss_4': 0.17896945774555206, 'epoch': 19.16}
{'loss': 0.0277, 'grad_norm': 7.259460926055908, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.018158352002501488, 'loss_2': 0.00958251953125, 'loss_3': -16.326889038085938, 'loss_4': 0.522916853427887, 'epoch': 19.17}
{'loss': 0.0224, 'grad_norm': 5.844233512878418, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.014080880209803581, 'loss_2': 0.0083465576171875, 'loss_3': -16.012643814086914, 'loss_4': 0.6318939924240112, 'epoch': 19.17}
{'loss': 0.0157, 'grad_norm': 4.543768405914307, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.007001407444477081, 'loss_2': 0.00868988037109375, 'loss_3': -16.38858985900879, 'loss_4': 0.025109656155109406, 'epoch': 19.18}
{'loss': 0.0155, 'grad_norm': 5.10890531539917, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.007822026498615742, 'loss_2': 0.007659912109375, 'loss_3': -16.380088806152344, 'loss_4': 0.533883810043335, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 16:40:07,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:07,255 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:19<31:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:14,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02114430069923401, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.664, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.016771402209997177, 'eval_loss_2': 0.004372894763946533, 'eval_loss_3': -18.067928314208984, 'eval_loss_4': 0.3594236373901367, 'epoch': 19.19}
{'loss': 0.0063, 'grad_norm': 4.816778659820557, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.0059502338990569115, 'loss_2': 0.0003399848937988281, 'loss_3': -16.222753524780273, 'loss_4': 0.4107746481895447, 'epoch': 19.19}
{'loss': 0.0081, 'grad_norm': 5.254212856292725, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.007281340658664703, 'loss_2': 0.0007758140563964844, 'loss_3': -16.18034553527832, 'loss_4': 0.760076642036438, 'epoch': 19.2}
{'loss': 0.0227, 'grad_norm': 7.8178863525390625, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.014493530616164207, 'loss_2': 0.0081634521484375, 'loss_3': -15.992756843566895, 'loss_4': 0.16712698340415955, 'epoch': 19.2}
{'loss': 0.0112, 'grad_norm': 5.978316307067871, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.00973951630294323, 'loss_2': 0.0015048980712890625, 'loss_3': -15.988027572631836, 'loss_4': 0.555776834487915, 'epoch': 19.21}
{'loss': 0.0153, 'grad_norm': 6.478514194488525, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.008998221717774868, 'loss_2': 0.00634765625, 'loss_3': -16.264427185058594, 'loss_4': 0.12789767980575562, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 16:40:14,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:14,572 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:27<31:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:21,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02059333398938179, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.227, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.017446355894207954, 'eval_loss_2': 0.0031469762325286865, 'eval_loss_3': -18.07526397705078, 'eval_loss_4': 0.3999650776386261, 'epoch': 19.22}
{'loss': 0.0093, 'grad_norm': 5.167358875274658, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.005442865192890167, 'loss_2': 0.003864288330078125, 'loss_3': -15.967159271240234, 'loss_4': -0.16355395317077637, 'epoch': 19.22}
{'loss': 0.0079, 'grad_norm': 5.0943922996521, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.005626743193715811, 'loss_2': 0.002315521240234375, 'loss_3': -16.04562759399414, 'loss_4': 0.5643733739852905, 'epoch': 19.23}
{'loss': 0.0152, 'grad_norm': 6.501199245452881, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.01267442386597395, 'loss_2': 0.00257110595703125, 'loss_3': -16.076736450195312, 'loss_4': 0.21266555786132812, 'epoch': 19.23}
{'loss': 0.0086, 'grad_norm': 5.67727518081665, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.004701875150203705, 'loss_2': 0.0038623809814453125, 'loss_3': -16.327659606933594, 'loss_4': 0.6145970821380615, 'epoch': 19.24}
{'loss': 0.0107, 'grad_norm': 5.1024065017700195, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.008173900656402111, 'loss_2': 0.002532958984375, 'loss_3': -16.2794132232666, 'loss_4': 0.5205264091491699, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 16:40:21,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:21,899 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:34<31:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:29,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02192249335348606, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.392, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017936939373612404, 'eval_loss_2': 0.003985553979873657, 'eval_loss_3': -18.093242645263672, 'eval_loss_4': 0.3440181016921997, 'epoch': 19.24}
{'loss': 0.0173, 'grad_norm': 6.338870048522949, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.010139279998838902, 'loss_2': 0.007144927978515625, 'loss_3': -16.13182258605957, 'loss_4': 0.38137108087539673, 'epoch': 19.25}
{'loss': 0.0059, 'grad_norm': 5.013365268707275, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.004036137834191322, 'loss_2': 0.001873016357421875, 'loss_3': -16.280235290527344, 'loss_4': 0.548835277557373, 'epoch': 19.26}
{'loss': 0.0086, 'grad_norm': 5.317580699920654, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.007385577540844679, 'loss_2': 0.0012493133544921875, 'loss_3': -16.220178604125977, 'loss_4': 0.35739320516586304, 'epoch': 19.26}
{'loss': 0.0118, 'grad_norm': 5.832838535308838, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.00941894669085741, 'loss_2': 0.0023632049560546875, 'loss_3': -16.177793502807617, 'loss_4': 0.5755009651184082, 'epoch': 19.27}
{'loss': 0.0078, 'grad_norm': 4.394106864929199, 'learning_rate': 1.075e-05, 'loss_1': 0.004022607579827309, 'loss_2': 0.0038242340087890625, 'loss_3': -16.12631607055664, 'loss_4': 0.33877483010292053, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 16:40:29,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:29,222 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:41<31:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:36,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0209430530667305, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.382, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017142390832304955, 'eval_loss_2': 0.0038006603717803955, 'eval_loss_3': -18.091384887695312, 'eval_loss_4': 0.32984352111816406, 'epoch': 19.27}
{'loss': 0.0071, 'grad_norm': 4.867019176483154, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.006195935886353254, 'loss_2': 0.0009098052978515625, 'loss_3': -16.028675079345703, 'loss_4': 0.4785561263561249, 'epoch': 19.28}
{'loss': 0.0276, 'grad_norm': 11.480571746826172, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.019748931750655174, 'loss_2': 0.0078887939453125, 'loss_3': -16.330154418945312, 'loss_4': 0.11312711983919144, 'epoch': 19.28}
{'loss': 0.0153, 'grad_norm': 6.374460697174072, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.009068679064512253, 'loss_2': 0.0062103271484375, 'loss_3': -16.104650497436523, 'loss_4': 0.2227325439453125, 'epoch': 19.29}
{'loss': 0.0149, 'grad_norm': 5.309940338134766, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.012538948096334934, 'loss_2': 0.002346038818359375, 'loss_3': -16.155147552490234, 'loss_4': 0.42137420177459717, 'epoch': 19.3}
{'loss': 0.017, 'grad_norm': 6.337000846862793, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.009492859244346619, 'loss_2': 0.007503509521484375, 'loss_3': -16.043529510498047, 'loss_4': 0.0932898223400116, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 16:40:36,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:36,546 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:21:49<31:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:43,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01900164783000946, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.309, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01614104025065899, 'eval_loss_2': 0.0028606057167053223, 'eval_loss_3': -18.1024112701416, 'eval_loss_4': 0.20724929869174957, 'epoch': 19.3}
{'loss': 0.0155, 'grad_norm': 6.150162696838379, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.013503828085958958, 'loss_2': 0.0019683837890625, 'loss_3': -16.119277954101562, 'loss_4': 0.48836469650268555, 'epoch': 19.31}
{'loss': 0.0111, 'grad_norm': 6.094669342041016, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.009518018923699856, 'loss_2': 0.0016307830810546875, 'loss_3': -16.22695541381836, 'loss_4': -0.05532609671354294, 'epoch': 19.31}
{'loss': 0.0136, 'grad_norm': 5.284450054168701, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.009909981861710548, 'loss_2': 0.003711700439453125, 'loss_3': -16.290279388427734, 'loss_4': 0.05077676475048065, 'epoch': 19.32}
{'loss': 0.0136, 'grad_norm': 6.591140270233154, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.01081806793808937, 'loss_2': 0.0027713775634765625, 'loss_3': -16.204160690307617, 'loss_4': 0.25559085607528687, 'epoch': 19.33}
{'loss': 0.0154, 'grad_norm': 4.8786091804504395, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.007402072194963694, 'loss_2': 0.0080108642578125, 'loss_3': -16.027353286743164, 'loss_4': 0.43367183208465576, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 16:40:43,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:43,878 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:21:56<31:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:51,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020226653665304184, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.643, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.015858113765716553, 'eval_loss_2': 0.00436854362487793, 'eval_loss_3': -18.095020294189453, 'eval_loss_4': 0.17019954323768616, 'epoch': 19.33}
{'loss': 0.0149, 'grad_norm': 5.267631530761719, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.006189990788698196, 'loss_2': 0.00875091552734375, 'loss_3': -16.35748863220215, 'loss_4': -0.44245457649230957, 'epoch': 19.34}
{'loss': 0.0186, 'grad_norm': 4.923511981964111, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.005987976677715778, 'loss_2': 0.0126190185546875, 'loss_3': -16.14440155029297, 'loss_4': -0.0690544992685318, 'epoch': 19.34}
{'loss': 0.0117, 'grad_norm': 5.124267578125, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.007326317019760609, 'loss_2': 0.00440216064453125, 'loss_3': -16.22243309020996, 'loss_4': 0.08091851323843002, 'epoch': 19.35}
{'loss': 0.0147, 'grad_norm': 5.416454792022705, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.006436231546103954, 'loss_2': 0.00823211669921875, 'loss_3': -16.476436614990234, 'loss_4': 0.03436776250600815, 'epoch': 19.35}
{'loss': 0.0099, 'grad_norm': 4.793474197387695, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.006677817553281784, 'loss_2': 0.003253936767578125, 'loss_3': -16.243484497070312, 'loss_4': 0.38930317759513855, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 16:40:51,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:51,200 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:03<31:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:58,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01928429864346981, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.52, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01573820970952511, 'eval_loss_2': 0.003546088933944702, 'eval_loss_3': -18.084789276123047, 'eval_loss_4': 0.1591544896364212, 'epoch': 19.36}
{'loss': 0.0316, 'grad_norm': 20.139671325683594, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.029822608456015587, 'loss_2': 0.00179290771484375, 'loss_3': -16.22458839416504, 'loss_4': -0.023979686200618744, 'epoch': 19.37}
{'loss': 0.0091, 'grad_norm': 4.1301188468933105, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.004266105126589537, 'loss_2': 0.0048675537109375, 'loss_3': -16.230321884155273, 'loss_4': 0.3843628466129303, 'epoch': 19.37}
{'loss': 0.0133, 'grad_norm': 5.553765296936035, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.011068555526435375, 'loss_2': 0.002197265625, 'loss_3': -16.089847564697266, 'loss_4': 0.25107455253601074, 'epoch': 19.38}
{'loss': 0.0368, 'grad_norm': 17.5606689453125, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.03449395298957825, 'loss_2': 0.0022945404052734375, 'loss_3': -16.188434600830078, 'loss_4': 0.6611325740814209, 'epoch': 19.38}
{'loss': 0.0118, 'grad_norm': 6.949726104736328, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.010856963694095612, 'loss_2': 0.0009822845458984375, 'loss_3': -16.111547470092773, 'loss_4': 0.4014066159725189, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 16:40:58,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:58,522 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:11<31:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:05,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018851444125175476, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.242, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014553532004356384, 'eval_loss_2': 0.004297912120819092, 'eval_loss_3': -18.118192672729492, 'eval_loss_4': 0.21186374127864838, 'epoch': 19.39}
{'loss': 0.0178, 'grad_norm': 5.887468338012695, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.010950332507491112, 'loss_2': 0.00681304931640625, 'loss_3': -16.335468292236328, 'loss_4': 0.2893226742744446, 'epoch': 19.4}
{'loss': 0.0137, 'grad_norm': 5.727116584777832, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.013310449197888374, 'loss_2': 0.00035953521728515625, 'loss_3': -16.304046630859375, 'loss_4': 0.12713705003261566, 'epoch': 19.4}
{'loss': 0.0172, 'grad_norm': 4.988168239593506, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.005993062164634466, 'loss_2': 0.011199951171875, 'loss_3': -16.026872634887695, 'loss_4': 0.24837294220924377, 'epoch': 19.41}
{'loss': 0.0107, 'grad_norm': 6.1679816246032715, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.008023167960345745, 'loss_2': 0.002681732177734375, 'loss_3': -16.11774444580078, 'loss_4': -0.1538679301738739, 'epoch': 19.41}
{'loss': 0.0137, 'grad_norm': 4.941312789916992, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.008746664971113205, 'loss_2': 0.00495147705078125, 'loss_3': -16.207639694213867, 'loss_4': 0.4860703945159912, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 16:41:05,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:05,851 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:18<31:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:41:13,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019091036170721054, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.677, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.014017726294696331, 'eval_loss_2': 0.0050733089447021484, 'eval_loss_3': -18.113609313964844, 'eval_loss_4': 0.305966854095459, 'epoch': 19.42}
{'loss': 0.013, 'grad_norm': 8.120680809020996, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.010885613970458508, 'loss_2': 0.0021533966064453125, 'loss_3': -16.13985824584961, 'loss_4': 0.48462480306625366, 'epoch': 19.42}
{'loss': 0.0062, 'grad_norm': 5.090523719787598, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.006002343259751797, 'loss_2': 0.00018644332885742188, 'loss_3': -16.06328773498535, 'loss_4': 0.02306342124938965, 'epoch': 19.43}
{'loss': 0.0166, 'grad_norm': 5.460722923278809, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.00768802547827363, 'loss_2': 0.00890350341796875, 'loss_3': -16.086223602294922, 'loss_4': 0.2832370698451996, 'epoch': 19.44}
{'loss': 0.0061, 'grad_norm': 5.841235160827637, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.005899214651435614, 'loss_2': 0.0002263784408569336, 'loss_3': -16.193302154541016, 'loss_4': 0.17359209060668945, 'epoch': 19.44}
{'loss': 0.0308, 'grad_norm': 11.889985084533691, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.020928138867020607, 'loss_2': 0.0098876953125, 'loss_3': -16.230745315551758, 'loss_4': 0.8379389047622681, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 16:41:13,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:13,171 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:25<31:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:20,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018919480964541435, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.378, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013914688490331173, 'eval_loss_2': 0.005004793405532837, 'eval_loss_3': -18.124561309814453, 'eval_loss_4': 0.4421851634979248, 'epoch': 19.45}
{'loss': 0.0058, 'grad_norm': 4.8702497482299805, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.0056763747707009315, 'loss_2': 0.00015532970428466797, 'loss_3': -16.276592254638672, 'loss_4': 0.9041870832443237, 'epoch': 19.45}
{'loss': 0.0051, 'grad_norm': 4.749143600463867, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.004658541176468134, 'loss_2': 0.0004684925079345703, 'loss_3': -16.07860565185547, 'loss_4': 0.47012484073638916, 'epoch': 19.46}
{'loss': 0.007, 'grad_norm': 5.008034706115723, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.006041221786290407, 'loss_2': 0.000942230224609375, 'loss_3': -16.060958862304688, 'loss_4': -0.02347474917769432, 'epoch': 19.47}
{'loss': 0.0086, 'grad_norm': 4.901081085205078, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.004947965499013662, 'loss_2': 0.003665924072265625, 'loss_3': -16.274696350097656, 'loss_4': 0.11133430898189545, 'epoch': 19.47}
{'loss': 0.0063, 'grad_norm': 5.06095027923584, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.00492475088685751, 'loss_2': 0.0013628005981445312, 'loss_3': -16.191482543945312, 'loss_4': 0.24251902103424072, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 16:41:20,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:20,498 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:33<31:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:41:27,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01884227804839611, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.702, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.013933627866208553, 'eval_loss_2': 0.004908651113510132, 'eval_loss_3': -18.125635147094727, 'eval_loss_4': 0.4476487338542938, 'epoch': 19.48}
{'loss': 0.0178, 'grad_norm': 7.650518417358398, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.013723733834922314, 'loss_2': 0.004119873046875, 'loss_3': -16.162202835083008, 'loss_4': 0.7083290219306946, 'epoch': 19.48}
{'loss': 0.0439, 'grad_norm': 22.498628616333008, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.04254902899265289, 'loss_2': 0.0013113021850585938, 'loss_3': -16.233457565307617, 'loss_4': 0.6406749486923218, 'epoch': 19.49}
{'loss': 0.008, 'grad_norm': 4.790947437286377, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.003928732592612505, 'loss_2': 0.00409698486328125, 'loss_3': -16.226058959960938, 'loss_4': 0.3054679036140442, 'epoch': 19.49}
{'loss': 0.0048, 'grad_norm': 4.614077091217041, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.0037136892788112164, 'loss_2': 0.0011138916015625, 'loss_3': -16.23056411743164, 'loss_4': 0.5608079433441162, 'epoch': 19.5}
{'loss': 0.0125, 'grad_norm': 5.399884223937988, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.009807162918150425, 'loss_2': 0.002689361572265625, 'loss_3': -16.19609832763672, 'loss_4': 0.5949892997741699, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 16:41:27,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:27,814 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:40<31:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:35,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017511429265141487, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013994965702295303, 'eval_loss_2': 0.003516465425491333, 'eval_loss_3': -18.127792358398438, 'eval_loss_4': 0.4556257426738739, 'epoch': 19.51}
{'loss': 0.016, 'grad_norm': 5.723809719085693, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.010293974541127682, 'loss_2': 0.0057525634765625, 'loss_3': -16.107463836669922, 'loss_4': 0.8223147988319397, 'epoch': 19.51}
{'loss': 0.0049, 'grad_norm': 4.4665751457214355, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.003672787919640541, 'loss_2': 0.001247406005859375, 'loss_3': -16.37167739868164, 'loss_4': 0.5675368905067444, 'epoch': 19.52}
{'loss': 0.0087, 'grad_norm': 5.113948345184326, 'learning_rate': 1.05e-05, 'loss_1': 0.004556416068226099, 'loss_2': 0.00415802001953125, 'loss_3': -16.155658721923828, 'loss_4': 0.39528709650039673, 'epoch': 19.52}
{'loss': 0.0299, 'grad_norm': 18.520883560180664, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.025721954181790352, 'loss_2': 0.004215240478515625, 'loss_3': -16.090959548950195, 'loss_4': 0.7367522716522217, 'epoch': 19.53}
{'loss': 0.0078, 'grad_norm': 4.746772289276123, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.004146580118685961, 'loss_2': 0.0036754608154296875, 'loss_3': -16.09610939025879, 'loss_4': 0.35189715027809143, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 16:41:35,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:35,156 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:22:47<31:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:42,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019330386072397232, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.902, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01535309012979269, 'eval_loss_2': 0.003977298736572266, 'eval_loss_3': -18.13953399658203, 'eval_loss_4': 0.3939441442489624, 'epoch': 19.53}
{'loss': 0.005, 'grad_norm': 4.425859451293945, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.0036973434034734964, 'loss_2': 0.0013332366943359375, 'loss_3': -16.204105377197266, 'loss_4': 0.39296311140060425, 'epoch': 19.54}
{'loss': 0.0075, 'grad_norm': 4.383633613586426, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.0029681113082915545, 'loss_2': 0.00452423095703125, 'loss_3': -16.137187957763672, 'loss_4': 0.6134657859802246, 'epoch': 19.55}
{'loss': 0.0243, 'grad_norm': 8.5746488571167, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.018503723666071892, 'loss_2': 0.005767822265625, 'loss_3': -16.22752571105957, 'loss_4': 0.292073130607605, 'epoch': 19.55}
{'loss': 0.0107, 'grad_norm': 5.34344482421875, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.006306278053671122, 'loss_2': 0.0044097900390625, 'loss_3': -16.101428985595703, 'loss_4': 0.2646344304084778, 'epoch': 19.56}
{'loss': 0.0082, 'grad_norm': 4.77471399307251, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.006261342205107212, 'loss_2': 0.0019512176513671875, 'loss_3': -16.33263397216797, 'loss_4': -0.2102828323841095, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 16:41:42,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:42,492 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:22:55<30:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:49,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0186200849711895, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.295, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014962548390030861, 'eval_loss_2': 0.0036575347185134888, 'eval_loss_3': -18.174474716186523, 'eval_loss_4': 0.3171718716621399, 'epoch': 19.56}
{'loss': 0.0167, 'grad_norm': 7.581279754638672, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.010954996570944786, 'loss_2': 0.005794525146484375, 'loss_3': -16.211715698242188, 'loss_4': -0.23827806115150452, 'epoch': 19.57}
{'loss': 0.006, 'grad_norm': 4.996559143066406, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.0031888093799352646, 'loss_2': 0.0028228759765625, 'loss_3': -16.158050537109375, 'loss_4': 0.3279103934764862, 'epoch': 19.58}
{'loss': 0.0097, 'grad_norm': 5.178284645080566, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.006498734466731548, 'loss_2': 0.0031585693359375, 'loss_3': -16.323284149169922, 'loss_4': -0.11554041504859924, 'epoch': 19.58}
{'loss': 0.0177, 'grad_norm': 4.645946025848389, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.007780447136610746, 'loss_2': 0.009918212890625, 'loss_3': -16.417659759521484, 'loss_4': 0.05532551929354668, 'epoch': 19.59}
{'loss': 0.0107, 'grad_norm': 8.033574104309082, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.010417899116873741, 'loss_2': 0.00030517578125, 'loss_3': -16.353368759155273, 'loss_4': 0.5799098014831543, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 16:41:49,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:49,816 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:02<30:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:41:57,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01870615966618061, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.712, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.014322834089398384, 'eval_loss_2': 0.0043833255767822266, 'eval_loss_3': -18.196619033813477, 'eval_loss_4': 0.1441786289215088, 'epoch': 19.59}
{'loss': 0.0063, 'grad_norm': 4.628287315368652, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.0057855211198329926, 'loss_2': 0.0005397796630859375, 'loss_3': -16.117183685302734, 'loss_4': 0.3066009283065796, 'epoch': 19.6}
{'loss': 0.0182, 'grad_norm': 5.94422721862793, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.015034918673336506, 'loss_2': 0.00321197509765625, 'loss_3': -16.491077423095703, 'loss_4': 0.22989243268966675, 'epoch': 19.6}
{'loss': 0.0119, 'grad_norm': 5.329896450042725, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.007096405606716871, 'loss_2': 0.004833221435546875, 'loss_3': -16.240745544433594, 'loss_4': 0.08607861399650574, 'epoch': 19.61}
{'loss': 0.02, 'grad_norm': 7.09982442855835, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.015767564997076988, 'loss_2': 0.004241943359375, 'loss_3': -16.314531326293945, 'loss_4': -0.19637984037399292, 'epoch': 19.62}
{'loss': 0.006, 'grad_norm': 4.376786708831787, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.005816962104290724, 'loss_2': 0.00021016597747802734, 'loss_3': -16.135202407836914, 'loss_4': 0.038015082478523254, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 16:41:57,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:57,137 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:09<30:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:42:04,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01964077167212963, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.61, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01496841013431549, 'eval_loss_2': 0.0046723634004592896, 'eval_loss_3': -18.211318969726562, 'eval_loss_4': -0.016853587701916695, 'epoch': 19.62}
{'loss': 0.0057, 'grad_norm': 4.286876201629639, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.004919065628200769, 'loss_2': 0.0007381439208984375, 'loss_3': -16.410127639770508, 'loss_4': -0.18335776031017303, 'epoch': 19.63}
{'loss': 0.0111, 'grad_norm': 5.867626190185547, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.010384156368672848, 'loss_2': 0.0007638931274414062, 'loss_3': -16.281604766845703, 'loss_4': 0.33997243642807007, 'epoch': 19.63}
{'loss': 0.0164, 'grad_norm': 5.814770221710205, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.01273349393159151, 'loss_2': 0.003635406494140625, 'loss_3': -16.292030334472656, 'loss_4': -0.27893930673599243, 'epoch': 19.64}
{'loss': 0.0122, 'grad_norm': 5.4435648918151855, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.006541787181049585, 'loss_2': 0.005615234375, 'loss_3': -16.339466094970703, 'loss_4': -0.1583024561405182, 'epoch': 19.65}
{'loss': 0.0196, 'grad_norm': 5.8124918937683105, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.01528866495937109, 'loss_2': 0.004306793212890625, 'loss_3': -16.021377563476562, 'loss_4': -0.25347626209259033, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 16:42:04,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:04,448 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:17<30:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:42:11,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0196231622248888, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.617, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.015583331696689129, 'eval_loss_2': 0.004039831459522247, 'eval_loss_3': -18.20392608642578, 'eval_loss_4': -0.13797804713249207, 'epoch': 19.65}
{'loss': 0.0141, 'grad_norm': 6.371426582336426, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.013274176977574825, 'loss_2': 0.00084686279296875, 'loss_3': -16.254470825195312, 'loss_4': -0.3667096495628357, 'epoch': 19.66}
{'loss': 0.011, 'grad_norm': 5.852102756500244, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.008714811876416206, 'loss_2': 0.002288818359375, 'loss_3': -16.45137596130371, 'loss_4': -0.13357767462730408, 'epoch': 19.66}
{'loss': 0.0131, 'grad_norm': 6.363212585449219, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.01226110104471445, 'loss_2': 0.0008182525634765625, 'loss_3': -16.24187469482422, 'loss_4': -0.25505563616752625, 'epoch': 19.67}
{'loss': 0.0157, 'grad_norm': 5.051102638244629, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.007625785656273365, 'loss_2': 0.00811767578125, 'loss_3': -16.264183044433594, 'loss_4': -0.39039847254753113, 'epoch': 19.67}
{'loss': 0.0091, 'grad_norm': 5.422536849975586, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.008858207613229752, 'loss_2': 0.00021028518676757812, 'loss_3': -16.215679168701172, 'loss_4': -0.15127161145210266, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 16:42:11,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:11,770 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:24<30:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:42:19,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019862141460180283, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.383, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.016393277794122696, 'eval_loss_2': 0.0034688636660575867, 'eval_loss_3': -18.221769332885742, 'eval_loss_4': -0.12962615489959717, 'epoch': 19.68}
{'loss': 0.0157, 'grad_norm': 5.112420082092285, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.011655520647764206, 'loss_2': 0.00402069091796875, 'loss_3': -16.179616928100586, 'loss_4': -0.22834332287311554, 'epoch': 19.69}
{'loss': 0.0275, 'grad_norm': 9.001227378845215, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.024258581921458244, 'loss_2': 0.003204345703125, 'loss_3': -16.229312896728516, 'loss_4': 0.2112434357404709, 'epoch': 19.69}
{'loss': 0.0191, 'grad_norm': 4.411796569824219, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.0060622552409768105, 'loss_2': 0.0130462646484375, 'loss_3': -16.305269241333008, 'loss_4': -0.44299235939979553, 'epoch': 19.7}
{'loss': 0.0176, 'grad_norm': 4.894444465637207, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.009695818647742271, 'loss_2': 0.0079345703125, 'loss_3': -16.76225471496582, 'loss_4': 0.3715636134147644, 'epoch': 19.7}
{'loss': 0.0205, 'grad_norm': 6.3407511711120605, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.008153763599693775, 'loss_2': 0.0123443603515625, 'loss_3': -16.341651916503906, 'loss_4': -0.07023362070322037, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 16:42:19,094 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:19,094 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:31<30:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:26,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02150622382760048, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.623, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.017509829252958298, 'eval_loss_2': 0.00399639829993248, 'eval_loss_3': -18.209911346435547, 'eval_loss_4': -0.0034142127260565758, 'epoch': 19.71}
{'loss': 0.01, 'grad_norm': 6.2291717529296875, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.009028402157127857, 'loss_2': 0.0009784698486328125, 'loss_3': -16.319124221801758, 'loss_4': 0.019760191440582275, 'epoch': 19.72}
{'loss': 0.016, 'grad_norm': 5.553409099578857, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.012111335061490536, 'loss_2': 0.003936767578125, 'loss_3': -16.46617889404297, 'loss_4': 0.12051714956760406, 'epoch': 19.72}
{'loss': 0.0135, 'grad_norm': 7.129367351531982, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.011594322510063648, 'loss_2': 0.001922607421875, 'loss_3': -16.364612579345703, 'loss_4': 0.15163588523864746, 'epoch': 19.73}
{'loss': 0.0146, 'grad_norm': 5.177118301391602, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.007394409738481045, 'loss_2': 0.007232666015625, 'loss_3': -16.519088745117188, 'loss_4': -0.0024789422750473022, 'epoch': 19.73}
{'loss': 0.0155, 'grad_norm': 5.239860534667969, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.005798798985779285, 'loss_2': 0.009735107421875, 'loss_3': -16.479045867919922, 'loss_4': 0.07218027114868164, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 16:42:26,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:26,418 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:39<30:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:33,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020084107294678688, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.632, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01635836996138096, 'eval_loss_2': 0.0037257373332977295, 'eval_loss_3': -18.208513259887695, 'eval_loss_4': 0.1485770344734192, 'epoch': 19.74}
{'loss': 0.0146, 'grad_norm': 6.2274956703186035, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.010234557092189789, 'loss_2': 0.0043182373046875, 'loss_3': -16.433162689208984, 'loss_4': 0.012180089950561523, 'epoch': 19.74}
{'loss': 0.0357, 'grad_norm': 10.948269844055176, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.024308910593390465, 'loss_2': 0.01137542724609375, 'loss_3': -16.595596313476562, 'loss_4': -0.013801664113998413, 'epoch': 19.75}
{'loss': 0.0116, 'grad_norm': 5.979520320892334, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.008516534231603146, 'loss_2': 0.0031261444091796875, 'loss_3': -16.520980834960938, 'loss_4': 0.35236620903015137, 'epoch': 19.76}
{'loss': 0.0089, 'grad_norm': 4.518274784088135, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.005746913608163595, 'loss_2': 0.00316619873046875, 'loss_3': -16.32547378540039, 'loss_4': 0.12502233684062958, 'epoch': 19.76}
{'loss': 0.0101, 'grad_norm': 6.695845127105713, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.00967442337423563, 'loss_2': 0.00043892860412597656, 'loss_3': -16.244380950927734, 'loss_4': 0.10035814344882965, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 16:42:33,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:33,747 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:23:46<30:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:41,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020389067009091377, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.66, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.015701385214924812, 'eval_loss_2': 0.004687681794166565, 'eval_loss_3': -18.19305992126465, 'eval_loss_4': 0.3258064389228821, 'epoch': 19.77}
{'loss': 0.0128, 'grad_norm': 5.3245649337768555, 'learning_rate': 1.025e-05, 'loss_1': 0.010283933952450752, 'loss_2': 0.0025463104248046875, 'loss_3': -16.34632110595703, 'loss_4': 0.3615933656692505, 'epoch': 19.77}
{'loss': 0.0114, 'grad_norm': 4.844516754150391, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.007252889685332775, 'loss_2': 0.004116058349609375, 'loss_3': -16.40331268310547, 'loss_4': 0.526402473449707, 'epoch': 19.78}
{'loss': 0.0123, 'grad_norm': 6.179476737976074, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.011442544870078564, 'loss_2': 0.0008821487426757812, 'loss_3': -16.170425415039062, 'loss_4': 0.6563076376914978, 'epoch': 19.78}
{'loss': 0.0133, 'grad_norm': 6.006191253662109, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.011799096129834652, 'loss_2': 0.00147247314453125, 'loss_3': -16.149993896484375, 'loss_4': 0.05918838828802109, 'epoch': 19.79}
{'loss': 0.0094, 'grad_norm': 4.285150527954102, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.004401218146085739, 'loss_2': 0.00498199462890625, 'loss_3': -16.370067596435547, 'loss_4': 0.3728899657726288, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 16:42:41,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:41,070 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:23:53<30:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:48,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020642518997192383, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.58, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.013967393897473812, 'eval_loss_2': 0.006675124168395996, 'eval_loss_3': -18.177024841308594, 'eval_loss_4': 0.5295393466949463, 'epoch': 19.8}
{'loss': 0.006, 'grad_norm': 4.49586296081543, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.003502301871776581, 'loss_2': 0.0025177001953125, 'loss_3': -16.435197830200195, 'loss_4': 0.5148711204528809, 'epoch': 19.8}
{'loss': 0.0167, 'grad_norm': 8.792325973510742, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.007766250986605883, 'loss_2': 0.00890350341796875, 'loss_3': -16.299198150634766, 'loss_4': 0.4910268187522888, 'epoch': 19.81}
{'loss': 0.0154, 'grad_norm': 5.315001010894775, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.007497447542846203, 'loss_2': 0.00787353515625, 'loss_3': -16.421722412109375, 'loss_4': 0.3913963735103607, 'epoch': 19.81}
{'loss': 0.0209, 'grad_norm': 5.372258186340332, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.0069027007557451725, 'loss_2': 0.01395416259765625, 'loss_3': -16.144287109375, 'loss_4': 0.6222811341285706, 'epoch': 19.82}
{'loss': 0.0231, 'grad_norm': 8.967939376831055, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.017101332545280457, 'loss_2': 0.006046295166015625, 'loss_3': -16.133033752441406, 'loss_4': 0.7455724477767944, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 16:42:48,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:48,393 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:01<30:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:55,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01922387070953846, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.422, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015101643279194832, 'eval_loss_2': 0.004122227430343628, 'eval_loss_3': -18.161611557006836, 'eval_loss_4': 0.7025774121284485, 'epoch': 19.83}
{'loss': 0.0109, 'grad_norm': 4.668083667755127, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.00990364607423544, 'loss_2': 0.0009493827819824219, 'loss_3': -16.243785858154297, 'loss_4': 0.7870197892189026, 'epoch': 19.83}
{'loss': 0.0204, 'grad_norm': 5.265349388122559, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.009477511048316956, 'loss_2': 0.01094818115234375, 'loss_3': -16.45147132873535, 'loss_4': 0.6566390991210938, 'epoch': 19.84}
{'loss': 0.008, 'grad_norm': 4.524382591247559, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.006668883841484785, 'loss_2': 0.001338958740234375, 'loss_3': -16.2482967376709, 'loss_4': 0.8283528089523315, 'epoch': 19.84}
{'loss': 0.008, 'grad_norm': 4.467279434204102, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.004095579497516155, 'loss_2': 0.0038547515869140625, 'loss_3': -16.386310577392578, 'loss_4': 0.4510817229747772, 'epoch': 19.85}
{'loss': 0.0042, 'grad_norm': 4.937661647796631, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.003939980641007423, 'loss_2': 0.00028228759765625, 'loss_3': -16.242429733276367, 'loss_4': 0.7460787296295166, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 16:42:55,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:55,722 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:08<30:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:43:03,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01864297315478325, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.628, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01562596671283245, 'eval_loss_2': 0.0030170083045959473, 'eval_loss_3': -18.165639877319336, 'eval_loss_4': 0.7799563407897949, 'epoch': 19.85}
{'loss': 0.0166, 'grad_norm': 11.692931175231934, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.01554149016737938, 'loss_2': 0.001056671142578125, 'loss_3': -16.366321563720703, 'loss_4': 0.7270642518997192, 'epoch': 19.86}
{'loss': 0.0133, 'grad_norm': 4.697175025939941, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.004374540410935879, 'loss_2': 0.0089569091796875, 'loss_3': -16.39668846130371, 'loss_4': 1.101807951927185, 'epoch': 19.87}
{'loss': 0.007, 'grad_norm': 4.6660614013671875, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.004042268730700016, 'loss_2': 0.00299072265625, 'loss_3': -16.429489135742188, 'loss_4': 0.470506876707077, 'epoch': 19.87}
{'loss': 0.0071, 'grad_norm': 4.6688971519470215, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.005726630333811045, 'loss_2': 0.00138092041015625, 'loss_3': -16.52852439880371, 'loss_4': 0.825860857963562, 'epoch': 19.88}
{'loss': 0.0153, 'grad_norm': 6.380484104156494, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.012318741530179977, 'loss_2': 0.002933502197265625, 'loss_3': -16.122631072998047, 'loss_4': 0.947587788105011, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 16:43:03,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:03,043 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:15<29:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:10,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017936773598194122, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.587, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014837716706097126, 'eval_loss_2': 0.0030990540981292725, 'eval_loss_3': -18.160009384155273, 'eval_loss_4': 0.8709491491317749, 'epoch': 19.88}
{'loss': 0.0034, 'grad_norm': 4.865387916564941, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.0032741748727858067, 'loss_2': 0.00010442733764648438, 'loss_3': -16.258853912353516, 'loss_4': 1.0552057027816772, 'epoch': 19.89}
{'loss': 0.0094, 'grad_norm': 4.499436855316162, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.008182301186025143, 'loss_2': 0.0011854171752929688, 'loss_3': -16.118412017822266, 'loss_4': 1.2478846311569214, 'epoch': 19.9}
{'loss': 0.0057, 'grad_norm': 4.454697132110596, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.005293807480484247, 'loss_2': 0.0003948211669921875, 'loss_3': -16.27230453491211, 'loss_4': 0.7576935291290283, 'epoch': 19.9}
{'loss': 0.009, 'grad_norm': 4.763543605804443, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.004956986755132675, 'loss_2': 0.00408935546875, 'loss_3': -16.32474708557129, 'loss_4': 0.32807278633117676, 'epoch': 19.91}
{'loss': 0.0133, 'grad_norm': 5.408140659332275, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.006163113750517368, 'loss_2': 0.00710296630859375, 'loss_3': -16.232057571411133, 'loss_4': 0.5328159332275391, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 16:43:10,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:10,368 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:23<29:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:17,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01956939324736595, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.48, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015925703570246696, 'eval_loss_2': 0.0036436915397644043, 'eval_loss_3': -18.156646728515625, 'eval_loss_4': 0.8348366618156433, 'epoch': 19.91}
{'loss': 0.0116, 'grad_norm': 4.762352466583252, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.006158631760627031, 'loss_2': 0.00539398193359375, 'loss_3': -16.209463119506836, 'loss_4': 0.8869177103042603, 'epoch': 19.92}
{'loss': 0.0102, 'grad_norm': 5.4635210037231445, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.008283878676593304, 'loss_2': 0.0019207000732421875, 'loss_3': -16.20738983154297, 'loss_4': 0.8274253606796265, 'epoch': 19.92}
{'loss': 0.0044, 'grad_norm': 4.752988815307617, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.0042195869609713554, 'loss_2': 0.0001323223114013672, 'loss_3': -16.366497039794922, 'loss_4': 0.625236988067627, 'epoch': 19.93}
{'loss': 0.0223, 'grad_norm': 7.944696426391602, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.016132201999425888, 'loss_2': 0.006191253662109375, 'loss_3': -16.429718017578125, 'loss_4': 0.6141481399536133, 'epoch': 19.94}
{'loss': 0.0157, 'grad_norm': 5.061023712158203, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.007151896599680185, 'loss_2': 0.0084991455078125, 'loss_3': -16.392255783081055, 'loss_4': 0.703208327293396, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 16:43:17,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:17,693 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:30<29:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:25,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019712314009666443, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.511, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.016155198216438293, 'eval_loss_2': 0.0035571157932281494, 'eval_loss_3': -18.157604217529297, 'eval_loss_4': 0.7888742685317993, 'epoch': 19.94}
{'loss': 0.0045, 'grad_norm': 4.830958366394043, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.003399352543056011, 'loss_2': 0.0010738372802734375, 'loss_3': -16.281017303466797, 'loss_4': 0.4391676187515259, 'epoch': 19.95}
{'loss': 0.0137, 'grad_norm': 10.469521522521973, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.012526184320449829, 'loss_2': 0.0011949539184570312, 'loss_3': -16.346216201782227, 'loss_4': 0.9486401677131653, 'epoch': 19.95}
{'loss': 0.0123, 'grad_norm': 9.10794448852539, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.012151993811130524, 'loss_2': 0.0001544952392578125, 'loss_3': -16.03432846069336, 'loss_4': 0.5262905359268188, 'epoch': 19.96}
{'loss': 0.0128, 'grad_norm': 7.161424160003662, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.012702928856015205, 'loss_2': 7.176399230957031e-05, 'loss_3': -16.368183135986328, 'loss_4': 0.5699899196624756, 'epoch': 19.97}
{'loss': 0.0748, 'grad_norm': 21.244916915893555, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.07108541578054428, 'loss_2': 0.003688812255859375, 'loss_3': -16.259227752685547, 'loss_4': 0.8221321105957031, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 16:43:25,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:25,018 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:37<26:41,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:43:31,988 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01888328790664673, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.525, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015604467131197453, 'eval_loss_2': 0.0032788217067718506, 'eval_loss_3': -18.156776428222656, 'eval_loss_4': 0.8318603038787842, 'epoch': 19.97}
{'loss': 0.012, 'grad_norm': 4.437272548675537, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.004825640004128218, 'loss_2': 0.007160186767578125, 'loss_3': -16.236835479736328, 'loss_4': 0.651595950126648, 'epoch': 19.98}
{'loss': 0.0057, 'grad_norm': 4.339102268218994, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.0050592790357768536, 'loss_2': 0.0006213188171386719, 'loss_3': -16.392364501953125, 'loss_4': 0.6255066394805908, 'epoch': 19.98}
{'loss': 0.0132, 'grad_norm': 5.479256629943848, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.00925779715180397, 'loss_2': 0.0039520263671875, 'loss_3': -16.053232192993164, 'loss_4': 0.5867682695388794, 'epoch': 19.99}
{'loss': 0.0119, 'grad_norm': 5.794308662414551, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.008764227852225304, 'loss_2': 0.0031147003173828125, 'loss_3': -16.27484893798828, 'loss_4': 0.8146329522132874, 'epoch': 19.99}
{'loss': 0.0093, 'grad_norm': 6.609981060028076, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.00375149748288095, 'loss_2': 0.005565643310546875, 'loss_3': -16.107515335083008, 'loss_4': 0.6319903135299683, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 16:43:31,989 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:31,989 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:24:44<29:11,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:43:39,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020995082333683968, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01657155528664589, 'eval_loss_2': 0.004423525184392929, 'eval_loss_3': -18.142333984375, 'eval_loss_4': 0.9005086421966553, 'epoch': 20.0}
{'loss': 0.0128, 'grad_norm': 4.281069755554199, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.004058076534420252, 'loss_2': 0.008697509765625, 'loss_3': -16.29683494567871, 'loss_4': 0.7943521738052368, 'epoch': 20.01}
{'loss': 0.0072, 'grad_norm': 3.878502368927002, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.005749444477260113, 'loss_2': 0.0014820098876953125, 'loss_3': -16.235538482666016, 'loss_4': 0.6030354499816895, 'epoch': 20.01}
{'loss': 0.0045, 'grad_norm': 5.014130115509033, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.0039314101450145245, 'loss_2': 0.0005893707275390625, 'loss_3': -16.37303924560547, 'loss_4': 0.8544701337814331, 'epoch': 20.02}
{'loss': 0.0111, 'grad_norm': 6.599791526794434, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.01019974797964096, 'loss_2': 0.0008993148803710938, 'loss_3': -16.084030151367188, 'loss_4': 0.6089866161346436, 'epoch': 20.02}
{'loss': 0.0145, 'grad_norm': 4.665881633758545, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.00546256871894002, 'loss_2': 0.009033203125, 'loss_3': -16.439098358154297, 'loss_4': 0.9261909127235413, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 16:43:39,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:39,363 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:24:52<29:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:43:46,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019175516441464424, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.361, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016242055222392082, 'eval_loss_2': 0.002933461219072342, 'eval_loss_3': -18.13705825805664, 'eval_loss_4': 0.9148246049880981, 'epoch': 20.03}
{'loss': 0.0152, 'grad_norm': 4.493371486663818, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.006265208125114441, 'loss_2': 0.00891876220703125, 'loss_3': -16.543649673461914, 'loss_4': 0.863733172416687, 'epoch': 20.03}
{'loss': 0.0072, 'grad_norm': 5.205517768859863, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.006280406378209591, 'loss_2': 0.0009279251098632812, 'loss_3': -15.972909927368164, 'loss_4': 0.84784334897995, 'epoch': 20.04}
{'loss': 0.0108, 'grad_norm': 6.649248123168945, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.00915586482733488, 'loss_2': 0.0016574859619140625, 'loss_3': -16.25389862060547, 'loss_4': 0.45539772510528564, 'epoch': 20.05}
{'loss': 0.0117, 'grad_norm': 5.902149677276611, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.00959786307066679, 'loss_2': 0.002140045166015625, 'loss_3': -16.363174438476562, 'loss_4': 1.297892689704895, 'epoch': 20.05}
{'loss': 0.019, 'grad_norm': 8.560770034790039, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.014418668113648891, 'loss_2': 0.004608154296875, 'loss_3': -16.134521484375, 'loss_4': 1.1775658130645752, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 16:43:46,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:46,689 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:24:59<29:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:43:54,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01819552108645439, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.662, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01528400182723999, 'eval_loss_2': 0.0029115192592144012, 'eval_loss_3': -18.149749755859375, 'eval_loss_4': 0.9976143836975098, 'epoch': 20.06}
{'loss': 0.0231, 'grad_norm': 11.632901191711426, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.019162187352776527, 'loss_2': 0.00397491455078125, 'loss_3': -16.155643463134766, 'loss_4': 0.9945273995399475, 'epoch': 20.06}
{'loss': 0.0101, 'grad_norm': 4.627598285675049, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.006677776109427214, 'loss_2': 0.003398895263671875, 'loss_3': -16.278337478637695, 'loss_4': 0.9379163384437561, 'epoch': 20.07}
{'loss': 0.008, 'grad_norm': 4.517910957336426, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.007138426881283522, 'loss_2': 0.0008530616760253906, 'loss_3': -16.381328582763672, 'loss_4': 1.5829731225967407, 'epoch': 20.08}
{'loss': 0.0079, 'grad_norm': 6.624399185180664, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.007679983042180538, 'loss_2': 0.0002486705780029297, 'loss_3': -16.395681381225586, 'loss_4': 1.3286640644073486, 'epoch': 20.08}
{'loss': 0.007, 'grad_norm': 4.589632034301758, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.004820014350116253, 'loss_2': 0.00215911865234375, 'loss_3': -16.569076538085938, 'loss_4': 1.1170799732208252, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 16:43:54,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:54,012 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:06<29:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:01,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018216915428638458, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.666, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.014989562332630157, 'eval_loss_2': 0.0032273530960083008, 'eval_loss_3': -18.156940460205078, 'eval_loss_4': 1.0649847984313965, 'epoch': 20.09}
{'loss': 0.0128, 'grad_norm': 4.852643013000488, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.008138217963278294, 'loss_2': 0.00469207763671875, 'loss_3': -16.28491973876953, 'loss_4': 1.1771596670150757, 'epoch': 20.09}
{'loss': 0.0869, 'grad_norm': 11.692866325378418, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.08393102139234543, 'loss_2': 0.002979278564453125, 'loss_3': -16.141132354736328, 'loss_4': 1.4887948036193848, 'epoch': 20.1}
{'loss': 0.0105, 'grad_norm': 4.724553108215332, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.004525572061538696, 'loss_2': 0.0059967041015625, 'loss_3': -16.105636596679688, 'loss_4': 0.9851483702659607, 'epoch': 20.1}
{'loss': 0.0132, 'grad_norm': 5.223625659942627, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.00859373714774847, 'loss_2': 0.004638671875, 'loss_3': -16.158353805541992, 'loss_4': 0.7400826811790466, 'epoch': 20.11}
{'loss': 0.0213, 'grad_norm': 5.828799247741699, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.0185251347720623, 'loss_2': 0.0027484893798828125, 'loss_3': -16.313396453857422, 'loss_4': 0.9699981212615967, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 16:44:01,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:01,333 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:14<29:37,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:44:08,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017673887312412262, 'eval_runtime': 3.9826, 'eval_samples_per_second': 257.116, 'eval_steps_per_second': 4.017, 'eval_loss_1': 0.014978586696088314, 'eval_loss_2': 0.0026952996850013733, 'eval_loss_3': -18.158536911010742, 'eval_loss_4': 1.1703410148620605, 'epoch': 20.12}
{'loss': 0.0086, 'grad_norm': 4.345744609832764, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.005332001950591803, 'loss_2': 0.0032901763916015625, 'loss_3': -16.399770736694336, 'loss_4': 1.3130838871002197, 'epoch': 20.12}
{'loss': 0.0086, 'grad_norm': 4.559924125671387, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.005480471067130566, 'loss_2': 0.003086090087890625, 'loss_3': -16.179370880126953, 'loss_4': 1.0819528102874756, 'epoch': 20.13}
{'loss': 0.0117, 'grad_norm': 4.388357162475586, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.004182267934083939, 'loss_2': 0.0075531005859375, 'loss_3': -16.237045288085938, 'loss_4': 1.1949317455291748, 'epoch': 20.13}
{'loss': 0.0135, 'grad_norm': 6.033110618591309, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.00958811491727829, 'loss_2': 0.003955841064453125, 'loss_3': -16.059389114379883, 'loss_4': 1.1553874015808105, 'epoch': 20.14}
{'loss': 0.0144, 'grad_norm': 6.142959117889404, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.009892166592180729, 'loss_2': 0.00452423095703125, 'loss_3': -16.161298751831055, 'loss_4': 1.069661021232605, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 16:44:08,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:08,847 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:21<29:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:16,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01853562518954277, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01594008132815361, 'eval_loss_2': 0.00259554386138916, 'eval_loss_3': -18.164846420288086, 'eval_loss_4': 1.173880934715271, 'epoch': 20.15}
{'loss': 0.01, 'grad_norm': 3.9096481800079346, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.0031092434655874968, 'loss_2': 0.0069122314453125, 'loss_3': -16.44358253479004, 'loss_4': 0.952415406703949, 'epoch': 20.15}
{'loss': 0.0115, 'grad_norm': 4.580349445343018, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.005048155784606934, 'loss_2': 0.006458282470703125, 'loss_3': -16.296382904052734, 'loss_4': 0.899171769618988, 'epoch': 20.16}
{'loss': 0.0077, 'grad_norm': 4.568242073059082, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.005035412032157183, 'loss_2': 0.0026569366455078125, 'loss_3': -16.45214080810547, 'loss_4': 1.2679452896118164, 'epoch': 20.16}
{'loss': 0.0078, 'grad_norm': 4.825891494750977, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.0037957634776830673, 'loss_2': 0.00399017333984375, 'loss_3': -16.308815002441406, 'loss_4': 1.0056875944137573, 'epoch': 20.17}
{'loss': 0.0381, 'grad_norm': 11.790538787841797, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.03590868413448334, 'loss_2': 0.002223968505859375, 'loss_3': -16.195886611938477, 'loss_4': 1.006589651107788, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 16:44:16,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:16,180 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:28<29:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:23,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020047523081302643, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.447, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01723996363580227, 'eval_loss_2': 0.0028075575828552246, 'eval_loss_3': -18.15213966369629, 'eval_loss_4': 1.0922021865844727, 'epoch': 20.17}
{'loss': 0.0127, 'grad_norm': 4.962213039398193, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.01072987075895071, 'loss_2': 0.001949310302734375, 'loss_3': -16.165834426879883, 'loss_4': 1.2309441566467285, 'epoch': 20.18}
{'loss': 0.0083, 'grad_norm': 4.779336452484131, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.00669899582862854, 'loss_2': 0.0016193389892578125, 'loss_3': -16.042821884155273, 'loss_4': 0.9966890811920166, 'epoch': 20.19}
{'loss': 0.0131, 'grad_norm': 8.068624496459961, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.012876110151410103, 'loss_2': 0.0002446174621582031, 'loss_3': -16.226587295532227, 'loss_4': 1.1885982751846313, 'epoch': 20.19}
{'loss': 0.0232, 'grad_norm': 12.945106506347656, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.02287278324365616, 'loss_2': 0.00036716461181640625, 'loss_3': -15.772512435913086, 'loss_4': 0.44874417781829834, 'epoch': 20.2}
{'loss': 0.0049, 'grad_norm': 4.641213893890381, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.004304728005081415, 'loss_2': 0.0005626678466796875, 'loss_3': -16.198089599609375, 'loss_4': 1.1584404706954956, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 16:44:23,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:23,518 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:36<28:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:30,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020794784650206566, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.579, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.017531966790556908, 'eval_loss_2': 0.003262817859649658, 'eval_loss_3': -18.13797378540039, 'eval_loss_4': 0.9523606300354004, 'epoch': 20.2}
{'loss': 0.0146, 'grad_norm': 4.936675071716309, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.00665642973035574, 'loss_2': 0.00789642333984375, 'loss_3': -16.402652740478516, 'loss_4': 0.8118100762367249, 'epoch': 20.21}
{'loss': 0.0091, 'grad_norm': 5.944095611572266, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.007840422913432121, 'loss_2': 0.00128173828125, 'loss_3': -16.372220993041992, 'loss_4': 0.6360651254653931, 'epoch': 20.22}
{'loss': 0.0112, 'grad_norm': 5.322062969207764, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.007871517911553383, 'loss_2': 0.0033111572265625, 'loss_3': -16.200599670410156, 'loss_4': 0.8866403102874756, 'epoch': 20.22}
{'loss': 0.0094, 'grad_norm': 4.474311351776123, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.005859550088644028, 'loss_2': 0.0035400390625, 'loss_3': -16.250322341918945, 'loss_4': 0.5716779232025146, 'epoch': 20.23}
{'loss': 0.0046, 'grad_norm': 4.477032661437988, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.0035307432990521193, 'loss_2': 0.0010995864868164062, 'loss_3': -16.229305267333984, 'loss_4': 0.5484607219696045, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 16:44:30,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:30,841 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:25:43<28:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:44:38,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022062653675675392, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.338, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.018181074410676956, 'eval_loss_2': 0.003881581127643585, 'eval_loss_3': -18.134000778198242, 'eval_loss_4': 0.8773698210716248, 'epoch': 20.23}
{'loss': 0.023, 'grad_norm': 6.633419036865234, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.012176011689007282, 'loss_2': 0.010833740234375, 'loss_3': -16.277652740478516, 'loss_4': 0.4940738081932068, 'epoch': 20.24}
{'loss': 0.0125, 'grad_norm': 5.29995059967041, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.007923140190541744, 'loss_2': 0.0045623779296875, 'loss_3': -16.079383850097656, 'loss_4': 0.595230221748352, 'epoch': 20.24}
{'loss': 0.0168, 'grad_norm': 10.296836853027344, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.013288905844092369, 'loss_2': 0.0034942626953125, 'loss_3': -16.198856353759766, 'loss_4': 0.8833501935005188, 'epoch': 20.25}
{'loss': 0.0135, 'grad_norm': 4.764689922332764, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.006310496013611555, 'loss_2': 0.007160186767578125, 'loss_3': -16.18140411376953, 'loss_4': 0.6233898401260376, 'epoch': 20.26}
{'loss': 0.0094, 'grad_norm': 5.954557418823242, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.007570204325020313, 'loss_2': 0.00183868408203125, 'loss_3': -16.374942779541016, 'loss_4': 1.1936981678009033, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 16:44:38,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:38,165 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:25:50<28:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:44:45,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022449076175689697, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.568, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.018284866586327553, 'eval_loss_2': 0.004164207726716995, 'eval_loss_3': -18.11268424987793, 'eval_loss_4': 0.8423418402671814, 'epoch': 20.26}
{'loss': 0.0163, 'grad_norm': 5.401381492614746, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.008215143345296383, 'loss_2': 0.008087158203125, 'loss_3': -16.32518768310547, 'loss_4': 0.3576838970184326, 'epoch': 20.27}
{'loss': 0.0122, 'grad_norm': 5.862454414367676, 'learning_rate': 9.75e-06, 'loss_1': 0.0049767084419727325, 'loss_2': 0.007232666015625, 'loss_3': -16.045095443725586, 'loss_4': 0.2726224660873413, 'epoch': 20.27}
{'loss': 0.0069, 'grad_norm': 4.80214262008667, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.005467548500746489, 'loss_2': 0.0014553070068359375, 'loss_3': -16.325620651245117, 'loss_4': 0.9045710563659668, 'epoch': 20.28}
{'loss': 0.0111, 'grad_norm': 5.380953788757324, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.004960154183208942, 'loss_2': 0.00618743896484375, 'loss_3': -16.20928955078125, 'loss_4': 0.4034806191921234, 'epoch': 20.28}
{'loss': 0.0097, 'grad_norm': 4.1181416511535645, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.004627302289009094, 'loss_2': 0.00511932373046875, 'loss_3': -16.057119369506836, 'loss_4': 0.9387762546539307, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 16:44:45,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:45,491 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:25:58<28:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:52,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022773899137973785, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.243, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.019035356119275093, 'eval_loss_2': 0.0037385448813438416, 'eval_loss_3': -18.093263626098633, 'eval_loss_4': 0.8114054799079895, 'epoch': 20.29}
{'loss': 0.0075, 'grad_norm': 4.336237907409668, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.005094802472740412, 'loss_2': 0.0024127960205078125, 'loss_3': -16.140798568725586, 'loss_4': 1.153286337852478, 'epoch': 20.3}
{'loss': 0.0197, 'grad_norm': 7.17029333114624, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.0177054051309824, 'loss_2': 0.00202178955078125, 'loss_3': -15.979530334472656, 'loss_4': 0.6628725528717041, 'epoch': 20.3}
{'loss': 0.0038, 'grad_norm': 4.505002975463867, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.003509707050397992, 'loss_2': 0.0002980232238769531, 'loss_3': -16.3526611328125, 'loss_4': 0.9098081588745117, 'epoch': 20.31}
{'loss': 0.0135, 'grad_norm': 5.131837844848633, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.007761896122246981, 'loss_2': 0.00571441650390625, 'loss_3': -16.08932876586914, 'loss_4': 0.29182130098342896, 'epoch': 20.31}
{'loss': 0.0037, 'grad_norm': 4.516618251800537, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.003443177090957761, 'loss_2': 0.0003044605255126953, 'loss_3': -16.17906951904297, 'loss_4': 0.4838261008262634, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 16:44:52,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:52,822 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:05<28:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:00,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023373717442154884, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.515, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.020040657371282578, 'eval_loss_2': 0.003333061933517456, 'eval_loss_3': -18.067951202392578, 'eval_loss_4': 0.7683650255203247, 'epoch': 20.32}
{'loss': 0.01, 'grad_norm': 5.154256820678711, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.005681046284735203, 'loss_2': 0.00429534912109375, 'loss_3': -16.32736587524414, 'loss_4': 0.5005193948745728, 'epoch': 20.33}
{'loss': 0.0121, 'grad_norm': 7.280374050140381, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.008207078091800213, 'loss_2': 0.003910064697265625, 'loss_3': -16.289201736450195, 'loss_4': 1.1260311603546143, 'epoch': 20.33}
{'loss': 0.0101, 'grad_norm': 5.12408447265625, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.005679171998053789, 'loss_2': 0.004398345947265625, 'loss_3': -16.282672882080078, 'loss_4': 0.548312783241272, 'epoch': 20.34}
{'loss': 0.0176, 'grad_norm': 7.820140838623047, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.01265997439622879, 'loss_2': 0.00490570068359375, 'loss_3': -16.207176208496094, 'loss_4': 1.0565361976623535, 'epoch': 20.34}
{'loss': 0.0187, 'grad_norm': 10.269245147705078, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.015855416655540466, 'loss_2': 0.002849578857421875, 'loss_3': -16.029388427734375, 'loss_4': 0.6062593460083008, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 16:45:00,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:00,150 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:12<28:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:07,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024125874042510986, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.563, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.020767273381352425, 'eval_loss_2': 0.003358602523803711, 'eval_loss_3': -18.06564712524414, 'eval_loss_4': 0.6520002484321594, 'epoch': 20.35}
{'loss': 0.0284, 'grad_norm': 11.643549919128418, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.02507280744612217, 'loss_2': 0.0032787322998046875, 'loss_3': -16.22016716003418, 'loss_4': 0.8740731477737427, 'epoch': 20.35}
{'loss': 0.0356, 'grad_norm': 14.354758262634277, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.024718457832932472, 'loss_2': 0.010894775390625, 'loss_3': -16.151874542236328, 'loss_4': 0.4077325463294983, 'epoch': 20.36}
{'loss': 0.0107, 'grad_norm': 5.565192222595215, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.008168190717697144, 'loss_2': 0.00255584716796875, 'loss_3': -16.30977439880371, 'loss_4': 0.7515673637390137, 'epoch': 20.37}
{'loss': 0.0094, 'grad_norm': 4.582058429718018, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.00670662010088563, 'loss_2': 0.00269317626953125, 'loss_3': -16.174179077148438, 'loss_4': 0.3739684820175171, 'epoch': 20.37}
{'loss': 0.0125, 'grad_norm': 6.125595569610596, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.007508893497288227, 'loss_2': 0.0050048828125, 'loss_3': -16.09253692626953, 'loss_4': 0.43170884251594543, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 16:45:07,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:07,481 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:20<28:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:14,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023399319499731064, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.584, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02009355090558529, 'eval_loss_2': 0.003305770456790924, 'eval_loss_3': -18.055294036865234, 'eval_loss_4': 0.560390055179596, 'epoch': 20.38}
{'loss': 0.0152, 'grad_norm': 5.377694606781006, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.008145068772137165, 'loss_2': 0.0070953369140625, 'loss_3': -16.272518157958984, 'loss_4': 0.41158437728881836, 'epoch': 20.38}
{'loss': 0.0061, 'grad_norm': 4.969176769256592, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.004279641900211573, 'loss_2': 0.00180816650390625, 'loss_3': -16.168249130249023, 'loss_4': 0.3661969304084778, 'epoch': 20.39}
{'loss': 0.0153, 'grad_norm': 5.221019744873047, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.006167151033878326, 'loss_2': 0.0091094970703125, 'loss_3': -16.458471298217773, 'loss_4': 0.2258753776550293, 'epoch': 20.4}
{'loss': 0.0064, 'grad_norm': 5.274562835693359, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.0060637108981609344, 'loss_2': 0.00034308433532714844, 'loss_3': -16.284442901611328, 'loss_4': 0.6581450700759888, 'epoch': 20.4}
{'loss': 0.007, 'grad_norm': 4.500927925109863, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.003990711644291878, 'loss_2': 0.003009796142578125, 'loss_3': -16.413419723510742, 'loss_4': 0.47163182497024536, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 16:45:14,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:14,803 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:27<28:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:45:22,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02214881405234337, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.692, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.019081365317106247, 'eval_loss_2': 0.0030674487352371216, 'eval_loss_3': -18.0566463470459, 'eval_loss_4': 0.5131009817123413, 'epoch': 20.41}
{'loss': 0.0104, 'grad_norm': 6.77227258682251, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.0072156949900090694, 'loss_2': 0.0031566619873046875, 'loss_3': -16.22641944885254, 'loss_4': 0.4040102958679199, 'epoch': 20.41}
{'loss': 0.007, 'grad_norm': 4.53588342666626, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.005018908530473709, 'loss_2': 0.002017974853515625, 'loss_3': -16.182100296020508, 'loss_4': 0.21689771115779877, 'epoch': 20.42}
{'loss': 0.0195, 'grad_norm': 7.211100101470947, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.011750731617212296, 'loss_2': 0.007701873779296875, 'loss_3': -16.36155128479004, 'loss_4': 0.6635688543319702, 'epoch': 20.42}
{'loss': 0.0107, 'grad_norm': 5.552125930786133, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.008624125272035599, 'loss_2': 0.002048492431640625, 'loss_3': -16.13837432861328, 'loss_4': 0.5068969130516052, 'epoch': 20.43}
{'loss': 0.0099, 'grad_norm': 5.942970275878906, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.008863945491611958, 'loss_2': 0.0010051727294921875, 'loss_3': -16.347732543945312, 'loss_4': 0.3548000454902649, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 16:45:22,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:22,123 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:34<28:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:29,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02231583744287491, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.687, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01925889030098915, 'eval_loss_2': 0.003056943416595459, 'eval_loss_3': -18.07052993774414, 'eval_loss_4': 0.5076967477798462, 'epoch': 20.44}
{'loss': 0.0105, 'grad_norm': 5.324479579925537, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.004454588983207941, 'loss_2': 0.0060272216796875, 'loss_3': -16.28514862060547, 'loss_4': 0.5884840488433838, 'epoch': 20.44}
{'loss': 0.0096, 'grad_norm': 5.319820880889893, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.0066493502818048, 'loss_2': 0.0029315948486328125, 'loss_3': -16.199771881103516, 'loss_4': 0.030398782342672348, 'epoch': 20.45}
{'loss': 0.0074, 'grad_norm': 4.735093116760254, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.0035867635160684586, 'loss_2': 0.003780364990234375, 'loss_3': -16.18157196044922, 'loss_4': 0.1889033019542694, 'epoch': 20.45}
{'loss': 0.0106, 'grad_norm': 5.953412055969238, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.00986479315906763, 'loss_2': 0.0007181167602539062, 'loss_3': -16.26382827758789, 'loss_4': 0.12272290885448456, 'epoch': 20.46}
{'loss': 0.025, 'grad_norm': 8.286581993103027, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.015880092978477478, 'loss_2': 0.0091400146484375, 'loss_3': -16.199649810791016, 'loss_4': 0.09493626654148102, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 16:45:29,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:29,448 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:26:42<28:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:36,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02324248105287552, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.286, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.021111074835062027, 'eval_loss_2': 0.002131406217813492, 'eval_loss_3': -18.05229949951172, 'eval_loss_4': 0.4946810305118561, 'epoch': 20.47}
{'loss': 0.0105, 'grad_norm': 4.847158908843994, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.00925334170460701, 'loss_2': 0.00128936767578125, 'loss_3': -15.999120712280273, 'loss_4': 0.6663118004798889, 'epoch': 20.47}
{'loss': 0.0193, 'grad_norm': 8.891937255859375, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.017644057050347328, 'loss_2': 0.0016765594482421875, 'loss_3': -16.03598403930664, 'loss_4': 0.6974838972091675, 'epoch': 20.48}
{'loss': 0.0796, 'grad_norm': 10.758696556091309, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.07939698547124863, 'loss_2': 0.00017547607421875, 'loss_3': -16.26833152770996, 'loss_4': 0.5351375341415405, 'epoch': 20.48}
{'loss': 0.0082, 'grad_norm': 4.768463611602783, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.007911168038845062, 'loss_2': 0.0003132820129394531, 'loss_3': -16.207237243652344, 'loss_4': 0.5339761972427368, 'epoch': 20.49}
{'loss': 0.0152, 'grad_norm': 5.359222888946533, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.006237248424440622, 'loss_2': 0.00899505615234375, 'loss_3': -16.304349899291992, 'loss_4': 0.5107299089431763, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 16:45:36,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:36,779 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:26:49<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:44,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02299659326672554, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.221, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019685642793774605, 'eval_loss_2': 0.003310948610305786, 'eval_loss_3': -18.074596405029297, 'eval_loss_4': 0.5122745037078857, 'epoch': 20.49}
{'loss': 0.0076, 'grad_norm': 4.871659755706787, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.005827849265187979, 'loss_2': 0.001739501953125, 'loss_3': -16.122419357299805, 'loss_4': 0.38133224844932556, 'epoch': 20.5}
{'loss': 0.0098, 'grad_norm': 4.982160568237305, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.00703014712780714, 'loss_2': 0.0027618408203125, 'loss_3': -16.244674682617188, 'loss_4': 0.33868101239204407, 'epoch': 20.51}
{'loss': 0.0136, 'grad_norm': 5.2046966552734375, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.006638696882873774, 'loss_2': 0.00693511962890625, 'loss_3': -16.082916259765625, 'loss_4': 0.6661597490310669, 'epoch': 20.51}
{'loss': 0.0095, 'grad_norm': 6.427997589111328, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.007752433884888887, 'loss_2': 0.001728057861328125, 'loss_3': -16.265703201293945, 'loss_4': 0.2601645588874817, 'epoch': 20.52}
{'loss': 0.0303, 'grad_norm': 10.541364669799805, 'learning_rate': 9.5e-06, 'loss_1': 0.025653688237071037, 'loss_2': 0.00469207763671875, 'loss_3': -16.164901733398438, 'loss_4': 0.7213941812515259, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 16:45:44,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:44,108 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:26:56<27:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:45:51,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022657625377178192, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.338, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019206538796424866, 'eval_loss_2': 0.0034510865807533264, 'eval_loss_3': -18.083290100097656, 'eval_loss_4': 0.5043485164642334, 'epoch': 20.52}
{'loss': 0.0059, 'grad_norm': 4.527300834655762, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.0035939167719334364, 'loss_2': 0.002277374267578125, 'loss_3': -16.43764877319336, 'loss_4': 0.3968459665775299, 'epoch': 20.53}
{'loss': 0.0053, 'grad_norm': 4.5007476806640625, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.0046701026149094105, 'loss_2': 0.0006628036499023438, 'loss_3': -16.18484878540039, 'loss_4': 0.8747557401657104, 'epoch': 20.53}
{'loss': 0.0084, 'grad_norm': 5.303404808044434, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.006661789026111364, 'loss_2': 0.0017747879028320312, 'loss_3': -16.427356719970703, 'loss_4': 0.8344379663467407, 'epoch': 20.54}
{'loss': 0.0232, 'grad_norm': 9.46237564086914, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.018488241359591484, 'loss_2': 0.0047454833984375, 'loss_3': -16.143104553222656, 'loss_4': 0.7737170457839966, 'epoch': 20.55}
{'loss': 0.0097, 'grad_norm': 4.914712905883789, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.0060829888097941875, 'loss_2': 0.00363922119140625, 'loss_3': -16.274147033691406, 'loss_4': 0.24502885341644287, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 16:45:51,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:51,427 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:04<27:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:58,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023813307285308838, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.22, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01902690716087818, 'eval_loss_2': 0.004786401987075806, 'eval_loss_3': -18.090167999267578, 'eval_loss_4': 0.5440850853919983, 'epoch': 20.55}
{'loss': 0.0212, 'grad_norm': 6.260042667388916, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.014714328572154045, 'loss_2': 0.006481170654296875, 'loss_3': -16.179656982421875, 'loss_4': 0.9400488138198853, 'epoch': 20.56}
{'loss': 0.0103, 'grad_norm': 6.3834309577941895, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.007021267432719469, 'loss_2': 0.003269195556640625, 'loss_3': -16.264631271362305, 'loss_4': 0.30559223890304565, 'epoch': 20.56}
{'loss': 0.0186, 'grad_norm': 9.159677505493164, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.01629733107984066, 'loss_2': 0.00232696533203125, 'loss_3': -16.228939056396484, 'loss_4': 0.47810670733451843, 'epoch': 20.57}
{'loss': 0.015, 'grad_norm': 5.0301513671875, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.007098115514963865, 'loss_2': 0.0079193115234375, 'loss_3': -16.312986373901367, 'loss_4': 0.6089451313018799, 'epoch': 20.58}
{'loss': 0.0079, 'grad_norm': 4.620437145233154, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.00648131500929594, 'loss_2': 0.0014019012451171875, 'loss_3': -16.42276382446289, 'loss_4': 0.6602239608764648, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 16:45:58,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:58,761 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:11<27:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:06,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02357809618115425, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.319, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019408291205763817, 'eval_loss_2': 0.0041698068380355835, 'eval_loss_3': -18.0748233795166, 'eval_loss_4': 0.6261222958564758, 'epoch': 20.58}
{'loss': 0.0221, 'grad_norm': 7.340967655181885, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.012184308841824532, 'loss_2': 0.0099029541015625, 'loss_3': -16.227191925048828, 'loss_4': 0.6487547159194946, 'epoch': 20.59}
{'loss': 0.0078, 'grad_norm': 5.612512111663818, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.007525723427534103, 'loss_2': 0.0002319812774658203, 'loss_3': -16.13620948791504, 'loss_4': 0.8328015804290771, 'epoch': 20.59}
{'loss': 0.0195, 'grad_norm': 10.326147079467773, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.014373854734003544, 'loss_2': 0.005092620849609375, 'loss_3': -16.21576690673828, 'loss_4': 0.6716433763504028, 'epoch': 20.6}
{'loss': 0.0089, 'grad_norm': 6.024586200714111, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.006748323794454336, 'loss_2': 0.00217437744140625, 'loss_3': -16.318208694458008, 'loss_4': 0.7267690896987915, 'epoch': 20.6}
{'loss': 0.0795, 'grad_norm': 10.48652172088623, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.07890739291906357, 'loss_2': 0.0005817413330078125, 'loss_3': -16.255870819091797, 'loss_4': 0.7265070080757141, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 16:46:06,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:06,092 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:18<27:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:13,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02418009750545025, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.020740071311593056, 'eval_loss_2': 0.003440026193857193, 'eval_loss_3': -18.07257843017578, 'eval_loss_4': 0.6573023796081543, 'epoch': 20.61}
{'loss': 0.0073, 'grad_norm': 5.5806498527526855, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.006712775211781263, 'loss_2': 0.0006203651428222656, 'loss_3': -16.44107437133789, 'loss_4': 1.0695805549621582, 'epoch': 20.62}
{'loss': 0.009, 'grad_norm': 4.976170063018799, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.00725072855129838, 'loss_2': 0.0017194747924804688, 'loss_3': -16.174606323242188, 'loss_4': 0.800356388092041, 'epoch': 20.62}
{'loss': 0.0077, 'grad_norm': 5.015856742858887, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.005702146794646978, 'loss_2': 0.002025604248046875, 'loss_3': -16.280437469482422, 'loss_4': 0.45922213792800903, 'epoch': 20.63}
{'loss': 0.0105, 'grad_norm': 7.624022960662842, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.010186641477048397, 'loss_2': 0.0003294944763183594, 'loss_3': -16.37239646911621, 'loss_4': 0.48483559489250183, 'epoch': 20.63}
{'loss': 0.0091, 'grad_norm': 4.857439994812012, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.004711912013590336, 'loss_2': 0.004421234130859375, 'loss_3': -16.172283172607422, 'loss_4': 0.6641136407852173, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 16:46:13,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:13,416 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:26<27:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:20,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024422546848654747, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.501, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.021675515919923782, 'eval_loss_2': 0.0027470290660858154, 'eval_loss_3': -18.058679580688477, 'eval_loss_4': 0.6803223490715027, 'epoch': 20.64}
{'loss': 0.01, 'grad_norm': 5.528604030609131, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.007670155260711908, 'loss_2': 0.0022945404052734375, 'loss_3': -16.128997802734375, 'loss_4': 0.795943558216095, 'epoch': 20.65}
{'loss': 0.0137, 'grad_norm': 5.330234050750732, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.00694612693041563, 'loss_2': 0.0067596435546875, 'loss_3': -16.299095153808594, 'loss_4': 1.053877592086792, 'epoch': 20.65}
{'loss': 0.023, 'grad_norm': 13.350637435913086, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.022241249680519104, 'loss_2': 0.0007810592651367188, 'loss_3': -16.263601303100586, 'loss_4': 0.8970327377319336, 'epoch': 20.66}
{'loss': 0.0141, 'grad_norm': 4.998563766479492, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.007360377348959446, 'loss_2': 0.006744384765625, 'loss_3': -16.208009719848633, 'loss_4': 0.43093621730804443, 'epoch': 20.66}
{'loss': 0.0076, 'grad_norm': 5.707151412963867, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.006910736672580242, 'loss_2': 0.0006613731384277344, 'loss_3': -16.430015563964844, 'loss_4': 0.7610628604888916, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 16:46:20,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:20,739 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:33<27:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:46:28,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02474226802587509, 'eval_runtime': 3.7823, 'eval_samples_per_second': 270.736, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.020727243274450302, 'eval_loss_2': 0.004015028476715088, 'eval_loss_3': -18.059371948242188, 'eval_loss_4': 0.7702201008796692, 'epoch': 20.67}
{'loss': 0.0062, 'grad_norm': 4.767739295959473, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.005644844379276037, 'loss_2': 0.0005130767822265625, 'loss_3': -16.257755279541016, 'loss_4': 0.44875818490982056, 'epoch': 20.67}
{'loss': 0.013, 'grad_norm': 4.589282989501953, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.005143388640135527, 'loss_2': 0.0078277587890625, 'loss_3': -16.40064239501953, 'loss_4': 0.5285928249359131, 'epoch': 20.68}
{'loss': 0.0155, 'grad_norm': 6.763200283050537, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.010055270045995712, 'loss_2': 0.00543975830078125, 'loss_3': -16.32575225830078, 'loss_4': 0.7929167747497559, 'epoch': 20.69}
{'loss': 0.0178, 'grad_norm': 12.258591651916504, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.016910426318645477, 'loss_2': 0.0008783340454101562, 'loss_3': -16.230411529541016, 'loss_4': 0.778212308883667, 'epoch': 20.69}
{'loss': 0.0159, 'grad_norm': 4.71517276763916, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.004858361091464758, 'loss_2': 0.011077880859375, 'loss_3': -16.346126556396484, 'loss_4': 0.8897632956504822, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 16:46:28,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:28,061 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:40<27:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:35,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026602167636156082, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.443, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021083446219563484, 'eval_loss_2': 0.005518719553947449, 'eval_loss_3': -18.063547134399414, 'eval_loss_4': 0.7743446826934814, 'epoch': 20.7}
{'loss': 0.0139, 'grad_norm': 5.927441120147705, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.008588802069425583, 'loss_2': 0.0053558349609375, 'loss_3': -16.195533752441406, 'loss_4': 0.0774652510881424, 'epoch': 20.7}
{'loss': 0.0142, 'grad_norm': 5.498435974121094, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.007030364125967026, 'loss_2': 0.0071868896484375, 'loss_3': -16.50279426574707, 'loss_4': 0.8959699869155884, 'epoch': 20.71}
{'loss': 0.0149, 'grad_norm': 6.943743705749512, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.00989396683871746, 'loss_2': 0.0050201416015625, 'loss_3': -16.419553756713867, 'loss_4': 0.8680882453918457, 'epoch': 20.72}
{'loss': 0.0114, 'grad_norm': 6.875802040100098, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.007576946634799242, 'loss_2': 0.003818511962890625, 'loss_3': -16.301048278808594, 'loss_4': 0.692734956741333, 'epoch': 20.72}
{'loss': 0.0101, 'grad_norm': 4.927944660186768, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.007234505377709866, 'loss_2': 0.002841949462890625, 'loss_3': -16.201923370361328, 'loss_4': 0.8057297468185425, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 16:46:35,387 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:35,387 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:27:48<27:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:42,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02517194114625454, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.515, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.02190818451344967, 'eval_loss_2': 0.0032637566328048706, 'eval_loss_3': -18.061100006103516, 'eval_loss_4': 0.7196028828620911, 'epoch': 20.73}
{'loss': 0.0139, 'grad_norm': 5.003607749938965, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.006591885816305876, 'loss_2': 0.007312774658203125, 'loss_3': -16.394149780273438, 'loss_4': 0.8543511629104614, 'epoch': 20.73}
{'loss': 0.0049, 'grad_norm': 4.623851299285889, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.0037644682452082634, 'loss_2': 0.0011110305786132812, 'loss_3': -16.41279411315918, 'loss_4': 0.5280227661132812, 'epoch': 20.74}
{'loss': 0.0223, 'grad_norm': 7.301672458648682, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.01165823545306921, 'loss_2': 0.0106201171875, 'loss_3': -16.05340576171875, 'loss_4': 0.445732444524765, 'epoch': 20.74}
{'loss': 0.0169, 'grad_norm': 7.035484313964844, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.011914677917957306, 'loss_2': 0.0050048828125, 'loss_3': -16.327299118041992, 'loss_4': 1.0140297412872314, 'epoch': 20.75}
{'loss': 0.0246, 'grad_norm': 11.940377235412598, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.019963743165135384, 'loss_2': 0.0046234130859375, 'loss_3': -16.406400680541992, 'loss_4': 0.4607031047344208, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 16:46:42,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:42,716 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:27:55<27:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:50,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024670688435435295, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.039, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.022362735122442245, 'eval_loss_2': 0.0023079514503479004, 'eval_loss_3': -18.044883728027344, 'eval_loss_4': 0.6445556879043579, 'epoch': 20.76}
{'loss': 0.0135, 'grad_norm': 7.678527355194092, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.01013740710914135, 'loss_2': 0.0033721923828125, 'loss_3': -16.370586395263672, 'loss_4': 0.506682813167572, 'epoch': 20.76}
{'loss': 0.0079, 'grad_norm': 5.539459705352783, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.0069751618430018425, 'loss_2': 0.0008869171142578125, 'loss_3': -16.208812713623047, 'loss_4': 0.6596928238868713, 'epoch': 20.77}
{'loss': 0.0118, 'grad_norm': 6.735714435577393, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.008590496145188808, 'loss_2': 0.003170013427734375, 'loss_3': -16.442590713500977, 'loss_4': 0.5460904836654663, 'epoch': 20.77}
{'loss': 0.0188, 'grad_norm': 5.837723731994629, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.01312060933560133, 'loss_2': 0.0056915283203125, 'loss_3': -16.3066463470459, 'loss_4': 0.4412587881088257, 'epoch': 20.78}
{'loss': 0.0222, 'grad_norm': 9.369864463806152, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.020316248759627342, 'loss_2': 0.001918792724609375, 'loss_3': -16.32492446899414, 'loss_4': 1.191194772720337, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 16:46:50,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:50,053 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:02<27:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:57,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025714561343193054, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.873, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.022406933829188347, 'eval_loss_2': 0.003307625651359558, 'eval_loss_3': -18.045639038085938, 'eval_loss_4': 0.6469391584396362, 'epoch': 20.78}
{'loss': 0.0067, 'grad_norm': 4.814915657043457, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.0051376293413341045, 'loss_2': 0.001544952392578125, 'loss_3': -16.142480850219727, 'loss_4': 0.6858665943145752, 'epoch': 20.79}
{'loss': 0.0122, 'grad_norm': 5.0595831871032715, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.005552233196794987, 'loss_2': 0.00664520263671875, 'loss_3': -16.24981117248535, 'loss_4': 0.4042249023914337, 'epoch': 20.8}
{'loss': 0.0105, 'grad_norm': 5.6724371910095215, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.006916931830346584, 'loss_2': 0.00357818603515625, 'loss_3': -16.296804428100586, 'loss_4': 0.33146992325782776, 'epoch': 20.8}
{'loss': 0.008, 'grad_norm': 5.154529094696045, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.005862180143594742, 'loss_2': 0.0021381378173828125, 'loss_3': -16.144012451171875, 'loss_4': 0.11974991858005524, 'epoch': 20.81}
{'loss': 0.0128, 'grad_norm': 5.194815635681152, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.008476443588733673, 'loss_2': 0.004306793212890625, 'loss_3': -16.344738006591797, 'loss_4': 0.7496380805969238, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 16:46:57,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:57,382 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:10<27:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:47:04,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025874406099319458, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02298686094582081, 'eval_loss_2': 0.002887547016143799, 'eval_loss_3': -18.030115127563477, 'eval_loss_4': 0.6243370771408081, 'epoch': 20.81}
{'loss': 0.0124, 'grad_norm': 5.44408655166626, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.009994564577937126, 'loss_2': 0.002407073974609375, 'loss_3': -16.123823165893555, 'loss_4': 1.002504825592041, 'epoch': 20.82}
{'loss': 0.0084, 'grad_norm': 5.753446578979492, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.007360968738794327, 'loss_2': 0.0010223388671875, 'loss_3': -16.175933837890625, 'loss_4': 0.1544388234615326, 'epoch': 20.83}
{'loss': 0.0233, 'grad_norm': 8.72432804107666, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.014312327839434147, 'loss_2': 0.00901031494140625, 'loss_3': -16.403682708740234, 'loss_4': 0.41944819688796997, 'epoch': 20.83}
{'loss': 0.0064, 'grad_norm': 5.092086315155029, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.005367218516767025, 'loss_2': 0.0010271072387695312, 'loss_3': -16.179523468017578, 'loss_4': 0.422946035861969, 'epoch': 20.84}
{'loss': 0.0144, 'grad_norm': 7.147604942321777, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.013639056123793125, 'loss_2': 0.0007562637329101562, 'loss_3': -16.105661392211914, 'loss_4': 0.5218660831451416, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 16:47:04,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:04,703 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:17<27:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:12,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024195268750190735, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.503, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.020709015429019928, 'eval_loss_2': 0.003486253321170807, 'eval_loss_3': -18.031539916992188, 'eval_loss_4': 0.5824227929115295, 'epoch': 20.84}
{'loss': 0.011, 'grad_norm': 5.191038608551025, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.007687920238822699, 'loss_2': 0.003314971923828125, 'loss_3': -16.29922103881836, 'loss_4': 0.7332427501678467, 'epoch': 20.85}
{'loss': 0.0085, 'grad_norm': 6.3580403327941895, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.007947866804897785, 'loss_2': 0.0005254745483398438, 'loss_3': -16.095739364624023, 'loss_4': 0.4432745575904846, 'epoch': 20.85}
{'loss': 0.0168, 'grad_norm': 6.66691255569458, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.012312836945056915, 'loss_2': 0.0045013427734375, 'loss_3': -16.27745246887207, 'loss_4': 0.6397565603256226, 'epoch': 20.86}
{'loss': 0.0133, 'grad_norm': 6.158311367034912, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.009513755328953266, 'loss_2': 0.0037746429443359375, 'loss_3': -16.12481689453125, 'loss_4': 0.5742521286010742, 'epoch': 20.87}
{'loss': 0.017, 'grad_norm': 6.565804958343506, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.010723065584897995, 'loss_2': 0.00623321533203125, 'loss_3': -16.175182342529297, 'loss_4': 0.6381081342697144, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 16:47:12,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:12,027 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:24<26:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:47:19,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023615380749106407, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.418, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.020204583182930946, 'eval_loss_2': 0.0034108012914657593, 'eval_loss_3': -18.040170669555664, 'eval_loss_4': 0.509752094745636, 'epoch': 20.87}
{'loss': 0.0116, 'grad_norm': 5.553554534912109, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.008462594822049141, 'loss_2': 0.003162384033203125, 'loss_3': -16.040393829345703, 'loss_4': 0.41946518421173096, 'epoch': 20.88}
{'loss': 0.0059, 'grad_norm': 4.983200550079346, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.005876234732568264, 'loss_2': 2.9087066650390625e-05, 'loss_3': -16.262876510620117, 'loss_4': 0.17393536865711212, 'epoch': 20.88}
{'loss': 0.011, 'grad_norm': 5.736391544342041, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.00917155109345913, 'loss_2': 0.0018062591552734375, 'loss_3': -16.32574462890625, 'loss_4': 0.7028475999832153, 'epoch': 20.89}
{'loss': 0.0301, 'grad_norm': 16.5771484375, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.028537001460790634, 'loss_2': 0.0015420913696289062, 'loss_3': -16.077899932861328, 'loss_4': 0.408389687538147, 'epoch': 20.9}
{'loss': 0.0055, 'grad_norm': 4.550439834594727, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.0042589507065713406, 'loss_2': 0.0012035369873046875, 'loss_3': -16.27281951904297, 'loss_4': 0.5543658137321472, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 16:47:19,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:19,348 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:32<26:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:47:26,669 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020682403817772865, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.635, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.018404044210910797, 'eval_loss_2': 0.002278357744216919, 'eval_loss_3': -18.058290481567383, 'eval_loss_4': 0.44762280583381653, 'epoch': 20.9}
{'loss': 0.0095, 'grad_norm': 5.368980407714844, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.007221270352602005, 'loss_2': 0.0023212432861328125, 'loss_3': -16.346702575683594, 'loss_4': 0.3729395270347595, 'epoch': 20.91}
{'loss': 0.0082, 'grad_norm': 5.46937370300293, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.006272619124501944, 'loss_2': 0.00197601318359375, 'loss_3': -16.28038787841797, 'loss_4': 0.1685941368341446, 'epoch': 20.91}
{'loss': 0.0122, 'grad_norm': 4.6873698234558105, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.005421709269285202, 'loss_2': 0.00673675537109375, 'loss_3': -16.265480041503906, 'loss_4': 0.44866836071014404, 'epoch': 20.92}
{'loss': 0.01, 'grad_norm': 4.692079544067383, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.007500268053263426, 'loss_2': 0.002483367919921875, 'loss_3': -16.227914810180664, 'loss_4': 0.23908467590808868, 'epoch': 20.92}
{'loss': 0.0295, 'grad_norm': 12.34205150604248, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.02487052232027054, 'loss_2': 0.00464630126953125, 'loss_3': -16.207826614379883, 'loss_4': 0.6976439952850342, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 16:47:26,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:26,669 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:39<26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:34,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026099303737282753, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.942, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018309812992811203, 'eval_loss_2': 0.007789492607116699, 'eval_loss_3': -18.068500518798828, 'eval_loss_4': 0.3975795805454254, 'epoch': 20.93}
{'loss': 0.0244, 'grad_norm': 4.449499130249023, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.0047986614517867565, 'loss_2': 0.01959228515625, 'loss_3': -16.293275833129883, 'loss_4': 0.09016095846891403, 'epoch': 20.94}
{'loss': 0.0102, 'grad_norm': 6.101228713989258, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.006453679874539375, 'loss_2': 0.003765106201171875, 'loss_3': -16.475221633911133, 'loss_4': 0.542985737323761, 'epoch': 20.94}
{'loss': 0.0136, 'grad_norm': 4.803783416748047, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.007281152065843344, 'loss_2': 0.006336212158203125, 'loss_3': -16.314910888671875, 'loss_4': 0.4236322045326233, 'epoch': 20.95}
{'loss': 0.0108, 'grad_norm': 4.882750988006592, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.00490361824631691, 'loss_2': 0.005855560302734375, 'loss_3': -16.359722137451172, 'loss_4': 0.3664676547050476, 'epoch': 20.95}
{'loss': 0.023, 'grad_norm': 4.65485954284668, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.00573071138933301, 'loss_2': 0.0172882080078125, 'loss_3': -16.19769859313965, 'loss_4': 0.16341795027256012, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 16:47:34,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:34,002 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:28:46<26:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:47:41,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02587677165865898, 'eval_runtime': 3.7824, 'eval_samples_per_second': 270.726, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.01787186786532402, 'eval_loss_2': 0.008004903793334961, 'eval_loss_3': -18.093839645385742, 'eval_loss_4': 0.32730650901794434, 'epoch': 20.96}
{'loss': 0.0086, 'grad_norm': 5.141160011291504, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.005822556093335152, 'loss_2': 0.0027751922607421875, 'loss_3': -16.256832122802734, 'loss_4': 0.3515385389328003, 'epoch': 20.97}
{'loss': 0.0245, 'grad_norm': 10.859278678894043, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.01931343600153923, 'loss_2': 0.005157470703125, 'loss_3': -16.45692253112793, 'loss_4': 0.35287487506866455, 'epoch': 20.97}
{'loss': 0.0233, 'grad_norm': 10.576605796813965, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.01734689436852932, 'loss_2': 0.0059814453125, 'loss_3': -16.32213592529297, 'loss_4': 0.10370524227619171, 'epoch': 20.98}
{'loss': 0.0214, 'grad_norm': 5.821412563323975, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.008104629814624786, 'loss_2': 0.01332855224609375, 'loss_3': -16.300636291503906, 'loss_4': 0.18974624574184418, 'epoch': 20.98}
{'loss': 0.0205, 'grad_norm': 6.005496025085449, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.012493887916207314, 'loss_2': 0.0080108642578125, 'loss_3': -16.32822036743164, 'loss_4': 0.09914424270391464, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 16:47:41,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:41,321 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:28:53<25:52,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 16:47:48,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02173522487282753, 'eval_runtime': 3.782, 'eval_samples_per_second': 270.756, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.017702853307127953, 'eval_loss_2': 0.0040323734283447266, 'eval_loss_3': -18.09752655029297, 'eval_loss_4': 0.3149641454219818, 'epoch': 20.99}
{'loss': 0.0066, 'grad_norm': 5.2323079109191895, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.004217030480504036, 'loss_2': 0.002422332763671875, 'loss_3': -16.237302780151367, 'loss_4': 0.17969535291194916, 'epoch': 20.99}
{'loss': 0.0111, 'grad_norm': 7.156876564025879, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.004596475511789322, 'loss_2': 0.00647735595703125, 'loss_3': -16.229236602783203, 'loss_4': 0.001030809711664915, 'epoch': 21.0}
{'loss': 0.0088, 'grad_norm': 5.255671501159668, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.006616729311645031, 'loss_2': 0.002147674560546875, 'loss_3': -16.268827438354492, 'loss_4': 0.31923937797546387, 'epoch': 21.01}
{'loss': 0.0108, 'grad_norm': 6.22049617767334, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.010041478089988232, 'loss_2': 0.0007658004760742188, 'loss_3': -16.216293334960938, 'loss_4': -0.10610674321651459, 'epoch': 21.01}
{'loss': 0.0053, 'grad_norm': 4.748549461364746, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.0036566026974469423, 'loss_2': 0.001682281494140625, 'loss_3': -16.239952087402344, 'loss_4': 0.13778366148471832, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 16:47:48,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:48,327 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:01<26:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:47:55,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01969374530017376, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.399, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01742890290915966, 'eval_loss_2': 0.002264842391014099, 'eval_loss_3': -18.08064842224121, 'eval_loss_4': 0.2506890892982483, 'epoch': 21.02}
{'loss': 0.0154, 'grad_norm': 4.806551933288574, 'learning_rate': 9e-06, 'loss_1': 0.005314260255545378, 'loss_2': 0.01009368896484375, 'loss_3': -16.347030639648438, 'loss_4': -0.07626239955425262, 'epoch': 21.02}
{'loss': 0.0167, 'grad_norm': 7.945086479187012, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.015966227278113365, 'loss_2': 0.0006918907165527344, 'loss_3': -16.309816360473633, 'loss_4': 0.2940940260887146, 'epoch': 21.03}
{'loss': 0.0089, 'grad_norm': 5.1791672706604, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.004888066556304693, 'loss_2': 0.00400543212890625, 'loss_3': -16.19485855102539, 'loss_4': 0.26731109619140625, 'epoch': 21.03}
{'loss': 0.0102, 'grad_norm': 5.237722873687744, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.008736591786146164, 'loss_2': 0.0015001296997070312, 'loss_3': -16.424657821655273, 'loss_4': 0.5308628678321838, 'epoch': 21.04}
{'loss': 0.0162, 'grad_norm': 5.0917067527771, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.009066564030945301, 'loss_2': 0.0070953369140625, 'loss_3': -16.250036239624023, 'loss_4': 0.346304714679718, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 16:47:55,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:55,651 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:08<26:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:48:02,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01953347586095333, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.253, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01738564670085907, 'eval_loss_2': 0.002147827297449112, 'eval_loss_3': -18.07464599609375, 'eval_loss_4': 0.14899685978889465, 'epoch': 21.05}
{'loss': 0.0164, 'grad_norm': 8.420909881591797, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.014137866906821728, 'loss_2': 0.002269744873046875, 'loss_3': -16.3675479888916, 'loss_4': 0.12287469953298569, 'epoch': 21.05}
{'loss': 0.0158, 'grad_norm': 6.63242769241333, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.012766307219862938, 'loss_2': 0.0030364990234375, 'loss_3': -16.295181274414062, 'loss_4': 0.022895455360412598, 'epoch': 21.06}
{'loss': 0.0165, 'grad_norm': 9.480841636657715, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.015231232158839703, 'loss_2': 0.0012264251708984375, 'loss_3': -16.2739315032959, 'loss_4': 0.3084968328475952, 'epoch': 21.06}
{'loss': 0.0045, 'grad_norm': 4.657949924468994, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.0037480820901691914, 'loss_2': 0.0007219314575195312, 'loss_3': -16.205223083496094, 'loss_4': 0.0021235011518001556, 'epoch': 21.07}
{'loss': 0.0085, 'grad_norm': 4.709563732147217, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.00486903777346015, 'loss_2': 0.00360107421875, 'loss_3': -16.447799682617188, 'loss_4': -0.027623668313026428, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 16:48:02,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:02,975 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:15<26:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:48:10,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019145004451274872, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.461, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.016820034012198448, 'eval_loss_2': 0.0023249685764312744, 'eval_loss_3': -18.077348709106445, 'eval_loss_4': 0.11691732704639435, 'epoch': 21.08}
{'loss': 0.0158, 'grad_norm': 7.676302433013916, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.015167555771768093, 'loss_2': 0.0006356239318847656, 'loss_3': -16.112823486328125, 'loss_4': 0.04178151488304138, 'epoch': 21.08}
{'loss': 0.0089, 'grad_norm': 5.145687103271484, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.005209519527852535, 'loss_2': 0.003711700439453125, 'loss_3': -16.32752227783203, 'loss_4': 0.012874094769358635, 'epoch': 21.09}
{'loss': 0.0097, 'grad_norm': 4.766882419586182, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.0066804438829422, 'loss_2': 0.003009796142578125, 'loss_3': -16.262069702148438, 'loss_4': -0.028363443911075592, 'epoch': 21.09}
{'loss': 0.0109, 'grad_norm': 5.772698879241943, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.009078290313482285, 'loss_2': 0.0018682479858398438, 'loss_3': -16.343265533447266, 'loss_4': -0.2629758417606354, 'epoch': 21.1}
{'loss': 0.016, 'grad_norm': 5.273969650268555, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.007386835757642984, 'loss_2': 0.0086212158203125, 'loss_3': -16.164499282836914, 'loss_4': 0.02930833399295807, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 16:48:10,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:10,292 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:23<26:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:17,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01876138150691986, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0163294468075037, 'eval_loss_2': 0.00243193656206131, 'eval_loss_3': -18.08448600769043, 'eval_loss_4': 0.027403518557548523, 'epoch': 21.1}
{'loss': 0.0521, 'grad_norm': 20.799955368041992, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.05187160521745682, 'loss_2': 0.0002129077911376953, 'loss_3': -16.16757583618164, 'loss_4': 0.029861658811569214, 'epoch': 21.11}
{'loss': 0.0132, 'grad_norm': 4.730926036834717, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.009440995752811432, 'loss_2': 0.0037689208984375, 'loss_3': -16.465740203857422, 'loss_4': -0.07205985486507416, 'epoch': 21.12}
{'loss': 0.0156, 'grad_norm': 5.994328498840332, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.009272659197449684, 'loss_2': 0.0063323974609375, 'loss_3': -16.25870132446289, 'loss_4': -0.0481225848197937, 'epoch': 21.12}
{'loss': 0.0088, 'grad_norm': 4.667018413543701, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.005723708309233189, 'loss_2': 0.00304412841796875, 'loss_3': -16.522085189819336, 'loss_4': 0.19678395986557007, 'epoch': 21.13}
{'loss': 0.0115, 'grad_norm': 6.037407398223877, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.007944890297949314, 'loss_2': 0.003520965576171875, 'loss_3': -16.353561401367188, 'loss_4': -0.1078641340136528, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 16:48:17,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:17,623 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:30<26:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:48:24,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019163720309734344, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.546, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.016337521374225616, 'eval_loss_2': 0.002826198935508728, 'eval_loss_3': -18.09390640258789, 'eval_loss_4': -0.042584192007780075, 'epoch': 21.13}
{'loss': 0.0103, 'grad_norm': 5.488627910614014, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.0076881651766598225, 'loss_2': 0.002628326416015625, 'loss_3': -16.329730987548828, 'loss_4': -0.10977402329444885, 'epoch': 21.14}
{'loss': 0.0115, 'grad_norm': 5.744450569152832, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.010063300840556622, 'loss_2': 0.0014781951904296875, 'loss_3': -16.249269485473633, 'loss_4': 0.10891413688659668, 'epoch': 21.15}
{'loss': 0.0097, 'grad_norm': 5.0420942306518555, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.0061795637011528015, 'loss_2': 0.003551483154296875, 'loss_3': -16.072317123413086, 'loss_4': -0.26393115520477295, 'epoch': 21.15}
{'loss': 0.0131, 'grad_norm': 4.441651344299316, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.004403778351843357, 'loss_2': 0.0086822509765625, 'loss_3': -16.263051986694336, 'loss_4': -0.19292119145393372, 'epoch': 21.16}
{'loss': 0.0278, 'grad_norm': 17.09234619140625, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.022421272471547127, 'loss_2': 0.00533294677734375, 'loss_3': -16.444238662719727, 'loss_4': -0.0626971572637558, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 16:48:24,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:24,940 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:37<26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:32,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020055124536156654, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.611, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01640082336962223, 'eval_loss_2': 0.003654301166534424, 'eval_loss_3': -18.091503143310547, 'eval_loss_4': -0.06619691848754883, 'epoch': 21.16}
{'loss': 0.007, 'grad_norm': 5.1800217628479, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.0060311476700007915, 'loss_2': 0.0009965896606445312, 'loss_3': -16.1225643157959, 'loss_4': -0.1833290159702301, 'epoch': 21.17}
{'loss': 0.0084, 'grad_norm': 4.501731872558594, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.00521807000041008, 'loss_2': 0.00313568115234375, 'loss_3': -16.241682052612305, 'loss_4': -0.38358020782470703, 'epoch': 21.17}
{'loss': 0.0062, 'grad_norm': 4.768157005310059, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.005456640385091305, 'loss_2': 0.0007624626159667969, 'loss_3': -16.463592529296875, 'loss_4': -0.009269878268241882, 'epoch': 21.18}
{'loss': 0.0088, 'grad_norm': 4.853228569030762, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.0033305708784610033, 'loss_2': 0.005435943603515625, 'loss_3': -16.236610412597656, 'loss_4': -0.36727261543273926, 'epoch': 21.19}
{'loss': 0.0122, 'grad_norm': 4.9676194190979, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.00639651995152235, 'loss_2': 0.005767822265625, 'loss_3': -16.35996437072754, 'loss_4': 0.003119051456451416, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 16:48:32,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:32,264 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:29:45<26:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:48:39,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02036735787987709, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.327, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016533223912119865, 'eval_loss_2': 0.0038341358304023743, 'eval_loss_3': -18.08841896057129, 'eval_loss_4': -0.04064968228340149, 'epoch': 21.19}
{'loss': 0.0266, 'grad_norm': 11.07714557647705, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.01860992982983589, 'loss_2': 0.0079498291015625, 'loss_3': -16.396560668945312, 'loss_4': 0.14878103137016296, 'epoch': 21.2}
{'loss': 0.0159, 'grad_norm': 13.008489608764648, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.015434234403073788, 'loss_2': 0.00051116943359375, 'loss_3': -16.199081420898438, 'loss_4': -0.027300037443637848, 'epoch': 21.2}
{'loss': 0.037, 'grad_norm': 15.779891014099121, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.03143805265426636, 'loss_2': 0.00557708740234375, 'loss_3': -16.191740036010742, 'loss_4': 0.3550425171852112, 'epoch': 21.21}
{'loss': 0.0052, 'grad_norm': 4.5474700927734375, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.0036796322092413902, 'loss_2': 0.001514434814453125, 'loss_3': -16.297752380371094, 'loss_4': 0.0018026530742645264, 'epoch': 21.22}
{'loss': 0.0095, 'grad_norm': 5.170749187469482, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.007483291439712048, 'loss_2': 0.0019989013671875, 'loss_3': -16.28556251525879, 'loss_4': 0.0895988792181015, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 16:48:39,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:39,586 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:29:52<25:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:46,912 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021148044615983963, 'eval_runtime': 3.7822, 'eval_samples_per_second': 270.741, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.017224615439772606, 'eval_loss_2': 0.003923431038856506, 'eval_loss_3': -18.078876495361328, 'eval_loss_4': 0.03785417228937149, 'epoch': 21.22}
{'loss': 0.0119, 'grad_norm': 6.126919269561768, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.009071901440620422, 'loss_2': 0.0028514862060546875, 'loss_3': -16.303325653076172, 'loss_4': -0.3243631422519684, 'epoch': 21.23}
{'loss': 0.0108, 'grad_norm': 5.092434883117676, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.006777629721909761, 'loss_2': 0.004032135009765625, 'loss_3': -16.362152099609375, 'loss_4': -0.224766343832016, 'epoch': 21.23}
{'loss': 0.0123, 'grad_norm': 6.815504550933838, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.008072239346802235, 'loss_2': 0.00424957275390625, 'loss_3': -16.397668838500977, 'loss_4': -0.29151415824890137, 'epoch': 21.24}
{'loss': 0.0092, 'grad_norm': 4.598298072814941, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.004790611565113068, 'loss_2': 0.004413604736328125, 'loss_3': -16.299386978149414, 'loss_4': -0.14523589611053467, 'epoch': 21.24}
{'loss': 0.0102, 'grad_norm': 5.376684665679932, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.009282363578677177, 'loss_2': 0.0009636878967285156, 'loss_3': -16.1684513092041, 'loss_4': -0.07083483040332794, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 16:48:46,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:46,912 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:29:59<25:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:48:54,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020786577835679054, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.503, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01681634411215782, 'eval_loss_2': 0.003970235586166382, 'eval_loss_3': -18.07440757751465, 'eval_loss_4': 0.09904693812131882, 'epoch': 21.25}
{'loss': 0.0169, 'grad_norm': 4.650909900665283, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.006268930155783892, 'loss_2': 0.01065826416015625, 'loss_3': -16.335224151611328, 'loss_4': 0.18392808735370636, 'epoch': 21.26}
{'loss': 0.006, 'grad_norm': 4.742959022521973, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.002777756191790104, 'loss_2': 0.003246307373046875, 'loss_3': -16.2005558013916, 'loss_4': -0.208469420671463, 'epoch': 21.26}
{'loss': 0.0066, 'grad_norm': 4.025958061218262, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.0019491231068968773, 'loss_2': 0.00469970703125, 'loss_3': -16.529048919677734, 'loss_4': 0.4992666244506836, 'epoch': 21.27}
{'loss': 0.0138, 'grad_norm': 5.325801849365234, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.006333220284432173, 'loss_2': 0.007476806640625, 'loss_3': -16.162429809570312, 'loss_4': -0.06298869848251343, 'epoch': 21.27}
{'loss': 0.0108, 'grad_norm': 5.448899745941162, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.010413708165287971, 'loss_2': 0.0003523826599121094, 'loss_3': -16.322288513183594, 'loss_4': 0.4507136344909668, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 16:48:54,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:54,233 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:06<25:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:01,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020907580852508545, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.095, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.017565295100212097, 'eval_loss_2': 0.0033422857522964478, 'eval_loss_3': -18.084270477294922, 'eval_loss_4': 0.1684451699256897, 'epoch': 21.28}
{'loss': 0.0154, 'grad_norm': 5.454148769378662, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.01009073294699192, 'loss_2': 0.0052947998046875, 'loss_3': -16.328643798828125, 'loss_4': 0.09903836250305176, 'epoch': 21.28}
{'loss': 0.0096, 'grad_norm': 5.399014472961426, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.006586555391550064, 'loss_2': 0.0030460357666015625, 'loss_3': -16.26826286315918, 'loss_4': -0.1391790211200714, 'epoch': 21.29}
{'loss': 0.0051, 'grad_norm': 4.589078426361084, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.0030219557229429483, 'loss_2': 0.0020599365234375, 'loss_3': -16.189674377441406, 'loss_4': 0.25239288806915283, 'epoch': 21.3}
{'loss': 0.0136, 'grad_norm': 6.4419965744018555, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.010304851457476616, 'loss_2': 0.00330352783203125, 'loss_3': -16.400848388671875, 'loss_4': 0.2296561300754547, 'epoch': 21.3}
{'loss': 0.0077, 'grad_norm': 4.057053089141846, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0035717375576496124, 'loss_2': 0.00417327880859375, 'loss_3': -16.378238677978516, 'loss_4': 0.12916362285614014, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 16:49:01,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:01,556 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:14<25:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:08,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021715831011533737, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.681, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01846962794661522, 'eval_loss_2': 0.003246203064918518, 'eval_loss_3': -18.094894409179688, 'eval_loss_4': 0.23014603555202484, 'epoch': 21.31}
{'loss': 0.015, 'grad_norm': 5.876577854156494, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.009162037633359432, 'loss_2': 0.00583648681640625, 'loss_3': -16.337848663330078, 'loss_4': 0.3111761510372162, 'epoch': 21.31}
{'loss': 0.0124, 'grad_norm': 5.887939453125, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.007752598263323307, 'loss_2': 0.0046234130859375, 'loss_3': -16.265783309936523, 'loss_4': 0.45774373412132263, 'epoch': 21.32}
{'loss': 0.0077, 'grad_norm': 4.503125190734863, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.0034614750184118748, 'loss_2': 0.004241943359375, 'loss_3': -16.299163818359375, 'loss_4': 0.2029561549425125, 'epoch': 21.33}
{'loss': 0.0092, 'grad_norm': 4.485387802124023, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.003155894810333848, 'loss_2': 0.006011962890625, 'loss_3': -16.218198776245117, 'loss_4': 0.26285219192504883, 'epoch': 21.33}
{'loss': 0.0152, 'grad_norm': 5.149154186248779, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.0076280743815004826, 'loss_2': 0.007537841796875, 'loss_3': -16.200483322143555, 'loss_4': 0.2610969543457031, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 16:49:08,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:08,874 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:21<25:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:16,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02242298424243927, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.572, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.018818750977516174, 'eval_loss_2': 0.0036042332649230957, 'eval_loss_3': -18.091697692871094, 'eval_loss_4': 0.30714151263237, 'epoch': 21.34}
{'loss': 0.0217, 'grad_norm': 7.033077239990234, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.019785841926932335, 'loss_2': 0.0018701553344726562, 'loss_3': -16.28091049194336, 'loss_4': 0.2760167121887207, 'epoch': 21.34}
{'loss': 0.0197, 'grad_norm': 6.083503723144531, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.014461014419794083, 'loss_2': 0.00519561767578125, 'loss_3': -16.207435607910156, 'loss_4': 0.3039374351501465, 'epoch': 21.35}
{'loss': 0.0201, 'grad_norm': 9.542255401611328, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.018575705587863922, 'loss_2': 0.0015420913696289062, 'loss_3': -16.09747314453125, 'loss_4': 0.012588374316692352, 'epoch': 21.35}
{'loss': 0.0069, 'grad_norm': 4.871036529541016, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.003662722185254097, 'loss_2': 0.0032196044921875, 'loss_3': -16.257034301757812, 'loss_4': 0.22472254931926727, 'epoch': 21.36}
{'loss': 0.0068, 'grad_norm': 4.734439849853516, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.004150836728513241, 'loss_2': 0.002643585205078125, 'loss_3': -16.352645874023438, 'loss_4': 0.22468844056129456, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 16:49:16,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:16,199 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:28<25:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:23,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021954473108053207, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.565, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.0183865986764431, 'eval_loss_2': 0.0035678744316101074, 'eval_loss_3': -18.078571319580078, 'eval_loss_4': 0.3105661869049072, 'epoch': 21.37}
{'loss': 0.0152, 'grad_norm': 8.166903495788574, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.012939957901835442, 'loss_2': 0.00222015380859375, 'loss_3': -16.226032257080078, 'loss_4': 0.016169525682926178, 'epoch': 21.37}
{'loss': 0.004, 'grad_norm': 4.831091403961182, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.003085555275902152, 'loss_2': 0.0009565353393554688, 'loss_3': -16.096519470214844, 'loss_4': -0.3111039698123932, 'epoch': 21.38}
{'loss': 0.0097, 'grad_norm': 5.5890793800354, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.008220051415264606, 'loss_2': 0.001483917236328125, 'loss_3': -16.25829315185547, 'loss_4': 0.5106611251831055, 'epoch': 21.38}
{'loss': 0.0226, 'grad_norm': 10.670148849487305, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.022342197597026825, 'loss_2': 0.0002739429473876953, 'loss_3': -16.097963333129883, 'loss_4': 0.0566382110118866, 'epoch': 21.39}
{'loss': 0.0092, 'grad_norm': 4.6883368492126465, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.00770110497251153, 'loss_2': 0.0014801025390625, 'loss_3': -16.23499870300293, 'loss_4': -0.09186279773712158, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 16:49:23,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:23,520 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:36<25:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:30,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022774165496230125, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.554, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0182347372174263, 'eval_loss_2': 0.004539430141448975, 'eval_loss_3': -18.080272674560547, 'eval_loss_4': 0.27410954236984253, 'epoch': 21.4}
{'loss': 0.0135, 'grad_norm': 4.852233409881592, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.005995472427457571, 'loss_2': 0.00751495361328125, 'loss_3': -16.23141098022461, 'loss_4': 0.3524314761161804, 'epoch': 21.4}
{'loss': 0.0172, 'grad_norm': 4.597541332244873, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.006560272071510553, 'loss_2': 0.01064300537109375, 'loss_3': -16.2648868560791, 'loss_4': 0.2772982120513916, 'epoch': 21.41}
{'loss': 0.0286, 'grad_norm': 14.99767780303955, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.028169848024845123, 'loss_2': 0.00041103363037109375, 'loss_3': -16.233943939208984, 'loss_4': 0.10837174952030182, 'epoch': 21.41}
{'loss': 0.0222, 'grad_norm': 8.268335342407227, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.019240818917751312, 'loss_2': 0.002918243408203125, 'loss_3': -16.22616958618164, 'loss_4': 0.46988481283187866, 'epoch': 21.42}
{'loss': 0.0129, 'grad_norm': 7.055478572845459, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.011897479183971882, 'loss_2': 0.0010366439819335938, 'loss_3': -16.248003005981445, 'loss_4': 0.6923819780349731, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 16:49:30,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:30,850 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:30:43<25:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:38,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023853227496147156, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018644779920578003, 'eval_loss_2': 0.005208447575569153, 'eval_loss_3': -18.079259872436523, 'eval_loss_4': 0.24091500043869019, 'epoch': 21.42}
{'loss': 0.0056, 'grad_norm': 4.6129889488220215, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.0052453153766691685, 'loss_2': 0.00037860870361328125, 'loss_3': -16.337600708007812, 'loss_4': -0.021300725638866425, 'epoch': 21.43}
{'loss': 0.0102, 'grad_norm': 5.076481819152832, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.006554660852998495, 'loss_2': 0.00363922119140625, 'loss_3': -16.097246170043945, 'loss_4': 0.19323812425136566, 'epoch': 21.44}
{'loss': 0.0103, 'grad_norm': 4.55027961730957, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.0038245993200689554, 'loss_2': 0.006435394287109375, 'loss_3': -16.554412841796875, 'loss_4': -0.03316546976566315, 'epoch': 21.44}
{'loss': 0.0186, 'grad_norm': 8.50793743133545, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.01623716950416565, 'loss_2': 0.00234222412109375, 'loss_3': -16.300546646118164, 'loss_4': 0.17235106229782104, 'epoch': 21.45}
{'loss': 0.0138, 'grad_norm': 4.852963447570801, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.004272793419659138, 'loss_2': 0.0095062255859375, 'loss_3': -16.368854522705078, 'loss_4': 0.3885956108570099, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 16:49:38,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:38,187 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:30:50<25:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:45,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02285424992442131, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0180441252887249, 'eval_loss_2': 0.004810124635696411, 'eval_loss_3': -18.088390350341797, 'eval_loss_4': 0.17591018974781036, 'epoch': 21.45}
{'loss': 0.0176, 'grad_norm': 7.442530155181885, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.012070142664015293, 'loss_2': 0.005535125732421875, 'loss_3': -16.08409881591797, 'loss_4': 0.12055858224630356, 'epoch': 21.46}
{'loss': 0.0137, 'grad_norm': 7.4783101081848145, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.010035844519734383, 'loss_2': 0.00363922119140625, 'loss_3': -16.438501358032227, 'loss_4': -0.19665157794952393, 'epoch': 21.47}
{'loss': 0.0105, 'grad_norm': 4.609171390533447, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.006570839323103428, 'loss_2': 0.003955841064453125, 'loss_3': -16.25567626953125, 'loss_4': -0.20191234350204468, 'epoch': 21.47}
{'loss': 0.0126, 'grad_norm': 5.207664489746094, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.007997089065611362, 'loss_2': 0.00461578369140625, 'loss_3': -16.363479614257812, 'loss_4': -0.15385118126869202, 'epoch': 21.48}
{'loss': 0.0188, 'grad_norm': 4.790359973907471, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.008751392364501953, 'loss_2': 0.0100555419921875, 'loss_3': -16.336957931518555, 'loss_4': -0.17014703154563904, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 16:49:45,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:45,515 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:30:58<25:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:52,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020586377009749413, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.654, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.017117980867624283, 'eval_loss_2': 0.0034683942794799805, 'eval_loss_3': -18.104520797729492, 'eval_loss_4': 0.09186255931854248, 'epoch': 21.48}
{'loss': 0.0082, 'grad_norm': 4.405992031097412, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.005722140893340111, 'loss_2': 0.00251007080078125, 'loss_3': -16.263755798339844, 'loss_4': -0.12761157751083374, 'epoch': 21.49}
{'loss': 0.0158, 'grad_norm': 6.797738075256348, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.013444417156279087, 'loss_2': 0.002338409423828125, 'loss_3': -16.305429458618164, 'loss_4': 0.07118725031614304, 'epoch': 21.49}
{'loss': 0.0066, 'grad_norm': 4.21911096572876, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0045718420296907425, 'loss_2': 0.0020599365234375, 'loss_3': -16.291234970092773, 'loss_4': -0.10871194303035736, 'epoch': 21.5}
{'loss': 0.0214, 'grad_norm': 5.610576629638672, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.007904711179435253, 'loss_2': 0.01348114013671875, 'loss_3': -16.052173614501953, 'loss_4': -0.300798237323761, 'epoch': 21.51}
{'loss': 0.009, 'grad_norm': 5.890028476715088, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.007063671015202999, 'loss_2': 0.0019397735595703125, 'loss_3': -16.27511215209961, 'loss_4': -0.25377157330513, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 16:49:52,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:52,827 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:05<25:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:00,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01870330236852169, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.478, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01565111055970192, 'eval_loss_2': 0.0030521899461746216, 'eval_loss_3': -18.11963653564453, 'eval_loss_4': 0.010933324694633484, 'epoch': 21.51}
{'loss': 0.0267, 'grad_norm': 7.587082862854004, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.01640055701136589, 'loss_2': 0.0102691650390625, 'loss_3': -16.29766845703125, 'loss_4': 0.248866468667984, 'epoch': 21.52}
{'loss': 0.0102, 'grad_norm': 4.5916852951049805, 'learning_rate': 8.5e-06, 'loss_1': 0.004572249948978424, 'loss_2': 0.00562286376953125, 'loss_3': -16.305034637451172, 'loss_4': -0.308020681142807, 'epoch': 21.52}
{'loss': 0.0095, 'grad_norm': 5.3812479972839355, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.007313094567507505, 'loss_2': 0.002227783203125, 'loss_3': -16.23018455505371, 'loss_4': -0.03719726949930191, 'epoch': 21.53}
{'loss': 0.0088, 'grad_norm': 5.394693851470947, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.006737561896443367, 'loss_2': 0.00202178955078125, 'loss_3': -16.27117919921875, 'loss_4': -0.11829329282045364, 'epoch': 21.53}
{'loss': 0.0058, 'grad_norm': 4.601095676422119, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.00384288071654737, 'loss_2': 0.001995086669921875, 'loss_3': -16.0645751953125, 'loss_4': -0.03709845244884491, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 16:50:00,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:00,154 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:12<25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:07,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018657920882105827, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.51, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014919622801244259, 'eval_loss_2': 0.003738299012184143, 'eval_loss_3': -18.132137298583984, 'eval_loss_4': -0.018273241817951202, 'epoch': 21.54}
{'loss': 0.006, 'grad_norm': 4.678151607513428, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.005527299363166094, 'loss_2': 0.0004634857177734375, 'loss_3': -16.10407257080078, 'loss_4': -0.03975357115268707, 'epoch': 21.55}
{'loss': 0.0123, 'grad_norm': 4.869032859802246, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.005867577623575926, 'loss_2': 0.006420135498046875, 'loss_3': -16.348552703857422, 'loss_4': -0.015937350690364838, 'epoch': 21.55}
{'loss': 0.0073, 'grad_norm': 4.707204341888428, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.0034060096368193626, 'loss_2': 0.003925323486328125, 'loss_3': -16.340415954589844, 'loss_4': 0.005661971867084503, 'epoch': 21.56}
{'loss': 0.0105, 'grad_norm': 4.960975170135498, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.008932380937039852, 'loss_2': 0.001560211181640625, 'loss_3': -16.227312088012695, 'loss_4': -0.2295863926410675, 'epoch': 21.56}
{'loss': 0.0109, 'grad_norm': 5.493331432342529, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.009810126386582851, 'loss_2': 0.0010519027709960938, 'loss_3': -16.16297149658203, 'loss_4': 0.04843495786190033, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 16:50:07,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:07,484 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:20<24:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:50:14,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01930815353989601, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.294, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.015974581241607666, 'eval_loss_2': 0.0033335722982883453, 'eval_loss_3': -18.136760711669922, 'eval_loss_4': 0.0038119833916425705, 'epoch': 21.57}
{'loss': 0.0156, 'grad_norm': 5.796849727630615, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.007645480800420046, 'loss_2': 0.00798797607421875, 'loss_3': -15.983928680419922, 'loss_4': -0.14211776852607727, 'epoch': 21.58}
{'loss': 0.0186, 'grad_norm': 6.063711643218994, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.011735296808183193, 'loss_2': 0.0068817138671875, 'loss_3': -16.428428649902344, 'loss_4': -0.28982388973236084, 'epoch': 21.58}
{'loss': 0.0169, 'grad_norm': 10.39073371887207, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.016078433021903038, 'loss_2': 0.0008654594421386719, 'loss_3': -16.224445343017578, 'loss_4': 0.7694445848464966, 'epoch': 21.59}
{'loss': 0.0223, 'grad_norm': 12.289483070373535, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.01918531395494938, 'loss_2': 0.0031108856201171875, 'loss_3': -16.164791107177734, 'loss_4': 0.11437651515007019, 'epoch': 21.59}
{'loss': 0.0896, 'grad_norm': 14.755572319030762, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.08640407025814056, 'loss_2': 0.00316619873046875, 'loss_3': -16.278594970703125, 'loss_4': 0.24639248847961426, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 16:50:14,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:14,807 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:27<24:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:50:22,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019169677048921585, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.378, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.016504788771271706, 'eval_loss_2': 0.002664893865585327, 'eval_loss_3': -18.13042449951172, 'eval_loss_4': -0.023494288325309753, 'epoch': 21.6}
{'loss': 0.0192, 'grad_norm': 8.055946350097656, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.014816940762102604, 'loss_2': 0.004390716552734375, 'loss_3': -16.248231887817383, 'loss_4': -0.0884781926870346, 'epoch': 21.6}
{'loss': 0.0094, 'grad_norm': 4.95570182800293, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.006734583526849747, 'loss_2': 0.002651214599609375, 'loss_3': -16.409469604492188, 'loss_4': -0.0585988312959671, 'epoch': 21.61}
{'loss': 0.0094, 'grad_norm': 5.3924784660339355, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.007829288952052593, 'loss_2': 0.001590728759765625, 'loss_3': -16.021974563598633, 'loss_4': -0.21397249400615692, 'epoch': 21.62}
{'loss': 0.0204, 'grad_norm': 12.717220306396484, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.018811600282788277, 'loss_2': 0.0016155242919921875, 'loss_3': -16.216609954833984, 'loss_4': -0.6591006517410278, 'epoch': 21.62}
{'loss': 0.007, 'grad_norm': 4.988166332244873, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.005754326935857534, 'loss_2': 0.00119781494140625, 'loss_3': -16.25220489501953, 'loss_4': 0.21025869250297546, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 16:50:22,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:22,125 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:34<24:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:50:29,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020898152142763138, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.486, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01775183342397213, 'eval_loss_2': 0.0031463205814361572, 'eval_loss_3': -18.109519958496094, 'eval_loss_4': -0.050886619836091995, 'epoch': 21.63}
{'loss': 0.0085, 'grad_norm': 4.961671829223633, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.008417499251663685, 'loss_2': 0.00012159347534179688, 'loss_3': -16.061382293701172, 'loss_4': 0.2011306881904602, 'epoch': 21.63}
{'loss': 0.0203, 'grad_norm': 4.9824042320251465, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.005973382852971554, 'loss_2': 0.014373779296875, 'loss_3': -16.10460662841797, 'loss_4': -0.03375981003046036, 'epoch': 21.64}
{'loss': 0.022, 'grad_norm': 5.749904632568359, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.012447022832930088, 'loss_2': 0.009552001953125, 'loss_3': -16.122936248779297, 'loss_4': -0.30835509300231934, 'epoch': 21.65}
{'loss': 0.0098, 'grad_norm': 6.426494598388672, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.009640376083552837, 'loss_2': 0.00020897388458251953, 'loss_3': -16.246074676513672, 'loss_4': -0.01815890520811081, 'epoch': 21.65}
{'loss': 0.0136, 'grad_norm': 5.771218776702881, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.011684081517159939, 'loss_2': 0.0019130706787109375, 'loss_3': -16.248699188232422, 'loss_4': 0.11026963591575623, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 16:50:29,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:29,442 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:31:42<24:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:36,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02043634094297886, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.675, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.017097899690270424, 'eval_loss_2': 0.003338441252708435, 'eval_loss_3': -18.099157333374023, 'eval_loss_4': -0.0808844193816185, 'epoch': 21.66}
{'loss': 0.0217, 'grad_norm': 9.045392990112305, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.01892116293311119, 'loss_2': 0.002750396728515625, 'loss_3': -16.25564956665039, 'loss_4': 0.12686887383460999, 'epoch': 21.66}
{'loss': 0.0074, 'grad_norm': 5.605849742889404, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.007242914289236069, 'loss_2': 0.00013685226440429688, 'loss_3': -16.229846954345703, 'loss_4': 0.152604877948761, 'epoch': 21.67}
{'loss': 0.0055, 'grad_norm': 4.398004055023193, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.003737197257578373, 'loss_2': 0.001781463623046875, 'loss_3': -16.4862003326416, 'loss_4': -0.18309630453586578, 'epoch': 21.67}
{'loss': 0.0128, 'grad_norm': 5.8568115234375, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.007957243360579014, 'loss_2': 0.00484466552734375, 'loss_3': -16.431976318359375, 'loss_4': -0.03520101308822632, 'epoch': 21.68}
{'loss': 0.0121, 'grad_norm': 4.899349212646484, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.0054950956255197525, 'loss_2': 0.00656890869140625, 'loss_3': -16.030624389648438, 'loss_4': -0.228053480386734, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 16:50:36,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:36,767 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:31:49<24:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:44,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019015366211533546, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.439, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.016199462115764618, 'eval_loss_2': 0.0028159096837043762, 'eval_loss_3': -18.091264724731445, 'eval_loss_4': -0.12483461946249008, 'epoch': 21.69}
{'loss': 0.0098, 'grad_norm': 4.624608039855957, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.0043262904509902, 'loss_2': 0.00547027587890625, 'loss_3': -16.37493896484375, 'loss_4': -0.14154253900051117, 'epoch': 21.69}
{'loss': 0.0138, 'grad_norm': 5.431023120880127, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.008525531738996506, 'loss_2': 0.005245208740234375, 'loss_3': -16.279403686523438, 'loss_4': -0.26957184076309204, 'epoch': 21.7}
{'loss': 0.0098, 'grad_norm': 4.58046817779541, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.005929881241172552, 'loss_2': 0.003849029541015625, 'loss_3': -16.089292526245117, 'loss_4': -0.27053600549697876, 'epoch': 21.7}
{'loss': 0.0074, 'grad_norm': 5.019290447235107, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.0058568320237100124, 'loss_2': 0.00151824951171875, 'loss_3': -16.034591674804688, 'loss_4': -0.28632843494415283, 'epoch': 21.71}
{'loss': 0.0219, 'grad_norm': 8.17012882232666, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.01893451064825058, 'loss_2': 0.00293731689453125, 'loss_3': -15.976058959960938, 'loss_4': -0.13483181595802307, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 16:50:44,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:44,097 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:31:56<24:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:50:51,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01967027597129345, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.586, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01568060927093029, 'eval_loss_2': 0.003989666700363159, 'eval_loss_3': -18.103965759277344, 'eval_loss_4': -0.1769673228263855, 'epoch': 21.72}
{'loss': 0.0077, 'grad_norm': 4.974706172943115, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.006899918895214796, 'loss_2': 0.000823974609375, 'loss_3': -16.084136962890625, 'loss_4': -0.6237095594406128, 'epoch': 21.72}
{'loss': 0.0264, 'grad_norm': 8.065193176269531, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.016216997057199478, 'loss_2': 0.01013946533203125, 'loss_3': -16.045501708984375, 'loss_4': -0.39954906702041626, 'epoch': 21.73}
{'loss': 0.0129, 'grad_norm': 4.484178066253662, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.0050237346440553665, 'loss_2': 0.00789642333984375, 'loss_3': -16.19913101196289, 'loss_4': -8.00788402557373e-05, 'epoch': 21.73}
{'loss': 0.0094, 'grad_norm': 5.822343826293945, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.00771060585975647, 'loss_2': 0.0017375946044921875, 'loss_3': -16.20241355895996, 'loss_4': -0.5009039640426636, 'epoch': 21.74}
{'loss': 0.0077, 'grad_norm': 4.883706569671631, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.0044611981138587, 'loss_2': 0.00328826904296875, 'loss_3': -16.24740982055664, 'loss_4': -0.36186519265174866, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 16:50:51,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:51,420 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:04<24:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:58,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01854659616947174, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.098, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.015169796533882618, 'eval_loss_2': 0.003376796841621399, 'eval_loss_3': -18.111961364746094, 'eval_loss_4': -0.20521396398544312, 'epoch': 21.74}
{'loss': 0.0088, 'grad_norm': 5.602200508117676, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.008104940876364708, 'loss_2': 0.0006823539733886719, 'loss_3': -16.193557739257812, 'loss_4': -0.30694979429244995, 'epoch': 21.75}
{'loss': 0.0248, 'grad_norm': 18.256925582885742, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.023293431848287582, 'loss_2': 0.00147247314453125, 'loss_3': -16.397258758544922, 'loss_4': -0.288136750459671, 'epoch': 21.76}
{'loss': 0.0107, 'grad_norm': 4.694544315338135, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.00492329616099596, 'loss_2': 0.005802154541015625, 'loss_3': -16.231918334960938, 'loss_4': 0.061123326420784, 'epoch': 21.76}
{'loss': 0.0113, 'grad_norm': 5.151522636413574, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.007164660841226578, 'loss_2': 0.004085540771484375, 'loss_3': -16.320730209350586, 'loss_4': -0.6906486749649048, 'epoch': 21.77}
{'loss': 0.0118, 'grad_norm': 6.456864833831787, 'learning_rate': 8.25e-06, 'loss_1': 0.011768221855163574, 'loss_2': 6.61015510559082e-05, 'loss_3': -16.047840118408203, 'loss_4': -0.41450560092926025, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 16:50:58,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:58,754 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:11<24:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:06,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018609093502163887, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.423, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015350781381130219, 'eval_loss_2': 0.0032583102583885193, 'eval_loss_3': -18.102994918823242, 'eval_loss_4': -0.23049935698509216, 'epoch': 21.77}
{'loss': 0.0123, 'grad_norm': 4.385982990264893, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.00481231976300478, 'loss_2': 0.00751495361328125, 'loss_3': -16.37020492553711, 'loss_4': -0.5216600894927979, 'epoch': 21.78}
{'loss': 0.0077, 'grad_norm': 4.590786933898926, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.007048497442156076, 'loss_2': 0.0006422996520996094, 'loss_3': -16.265798568725586, 'loss_4': 0.15896877646446228, 'epoch': 21.78}
{'loss': 0.0114, 'grad_norm': 6.840926170349121, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.008978109806776047, 'loss_2': 0.0024242401123046875, 'loss_3': -16.29513168334961, 'loss_4': 0.027247488498687744, 'epoch': 21.79}
{'loss': 0.0162, 'grad_norm': 8.995367050170898, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.013294009491801262, 'loss_2': 0.002872467041015625, 'loss_3': -16.063692092895508, 'loss_4': 0.23478016257286072, 'epoch': 21.8}
{'loss': 0.0048, 'grad_norm': 4.704933166503906, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.003280903911218047, 'loss_2': 0.00152587890625, 'loss_3': -16.37600326538086, 'loss_4': -0.01875980943441391, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 16:51:06,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:06,078 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:18<24:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:13,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01890963688492775, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.388, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015608194284141064, 'eval_loss_2': 0.0033014416694641113, 'eval_loss_3': -18.08970832824707, 'eval_loss_4': -0.23286172747612, 'epoch': 21.8}
{'loss': 0.005, 'grad_norm': 4.413163661956787, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.00440778024494648, 'loss_2': 0.0005617141723632812, 'loss_3': -16.215967178344727, 'loss_4': -0.14893761277198792, 'epoch': 21.81}
{'loss': 0.0094, 'grad_norm': 5.242046356201172, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.0050750127993524075, 'loss_2': 0.004276275634765625, 'loss_3': -16.267593383789062, 'loss_4': -0.2855394184589386, 'epoch': 21.81}
{'loss': 0.0064, 'grad_norm': 4.923695087432861, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.005736559629440308, 'loss_2': 0.0006628036499023438, 'loss_3': -16.14702606201172, 'loss_4': -0.046559035778045654, 'epoch': 21.82}
{'loss': 0.0259, 'grad_norm': 12.425150871276855, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.01991649903357029, 'loss_2': 0.00598907470703125, 'loss_3': -16.156147003173828, 'loss_4': 0.10825707763433456, 'epoch': 21.83}
{'loss': 0.0116, 'grad_norm': 6.294111728668213, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.008202608674764633, 'loss_2': 0.0033550262451171875, 'loss_3': -16.169944763183594, 'loss_4': -0.33528751134872437, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 16:51:13,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:13,402 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:26<24:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:20,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019602395594120026, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.016425542533397675, 'eval_loss_2': 0.003176853060722351, 'eval_loss_3': -18.083824157714844, 'eval_loss_4': -0.1982879489660263, 'epoch': 21.83}
{'loss': 0.0114, 'grad_norm': 5.360079288482666, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.007267676759511232, 'loss_2': 0.00415802001953125, 'loss_3': -16.384769439697266, 'loss_4': 0.34191256761550903, 'epoch': 21.84}
{'loss': 0.0041, 'grad_norm': 4.813009262084961, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.0033517510164529085, 'loss_2': 0.0007781982421875, 'loss_3': -16.224567413330078, 'loss_4': -0.2004808783531189, 'epoch': 21.84}
{'loss': 0.0181, 'grad_norm': 7.671062469482422, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.015444683842360973, 'loss_2': 0.002620697021484375, 'loss_3': -16.281904220581055, 'loss_4': 0.17047271132469177, 'epoch': 21.85}
{'loss': 0.0149, 'grad_norm': 6.692642688751221, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.008354679681360722, 'loss_2': 0.006591796875, 'loss_3': -16.285844802856445, 'loss_4': -0.40160292387008667, 'epoch': 21.85}
{'loss': 0.0146, 'grad_norm': 4.661382675170898, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.0058743455447256565, 'loss_2': 0.0086822509765625, 'loss_3': -16.447214126586914, 'loss_4': -0.5865932703018188, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 16:51:20,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:20,722 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:33<24:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:28,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0201137512922287, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.645, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01698492467403412, 'eval_loss_2': 0.00312882661819458, 'eval_loss_3': -18.096969604492188, 'eval_loss_4': -0.1894320249557495, 'epoch': 21.86}
{'loss': 0.0343, 'grad_norm': 9.845831871032715, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.026662031188607216, 'loss_2': 0.0076751708984375, 'loss_3': -15.987634658813477, 'loss_4': -0.4746129512786865, 'epoch': 21.87}
{'loss': 0.0163, 'grad_norm': 5.757334232330322, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.009132045321166515, 'loss_2': 0.007205963134765625, 'loss_3': -16.161375045776367, 'loss_4': -0.13661926984786987, 'epoch': 21.87}
{'loss': 0.0067, 'grad_norm': 5.025139331817627, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.005196120589971542, 'loss_2': 0.0014867782592773438, 'loss_3': -16.067930221557617, 'loss_4': 0.26639124751091003, 'epoch': 21.88}
{'loss': 0.0308, 'grad_norm': 35.18098068237305, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.02796764299273491, 'loss_2': 0.002880096435546875, 'loss_3': -16.126590728759766, 'loss_4': -0.2721688151359558, 'epoch': 21.88}
{'loss': 0.0059, 'grad_norm': 4.694902420043945, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.005066804122179747, 'loss_2': 0.0008392333984375, 'loss_3': -16.225399017333984, 'loss_4': -0.4480208158493042, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 16:51:28,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:28,032 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:32:40<23:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:35,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0192258358001709, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.288, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01675543189048767, 'eval_loss_2': 0.0024704039096832275, 'eval_loss_3': -18.102508544921875, 'eval_loss_4': -0.18504369258880615, 'epoch': 21.89}
{'loss': 0.0103, 'grad_norm': 5.429845333099365, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.005928141996264458, 'loss_2': 0.00437164306640625, 'loss_3': -16.19451904296875, 'loss_4': -0.16556879878044128, 'epoch': 21.9}
{'loss': 0.0047, 'grad_norm': 3.933790683746338, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0029531740583479404, 'loss_2': 0.001728057861328125, 'loss_3': -16.23276138305664, 'loss_4': 0.07831995189189911, 'epoch': 21.9}
{'loss': 0.0065, 'grad_norm': 5.067462921142578, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.004287272226065397, 'loss_2': 0.002162933349609375, 'loss_3': -16.147964477539062, 'loss_4': -0.1147565022110939, 'epoch': 21.91}
{'loss': 0.0173, 'grad_norm': 5.090747356414795, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.007521987892687321, 'loss_2': 0.00974273681640625, 'loss_3': -16.107091903686523, 'loss_4': -0.12086854875087738, 'epoch': 21.91}
{'loss': 0.0049, 'grad_norm': 4.701286315917969, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.004817151464521885, 'loss_2': 8.082389831542969e-05, 'loss_3': -16.516454696655273, 'loss_4': -0.1673964411020279, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 16:51:35,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:35,359 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:32:48<23:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:42,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017988000065088272, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.506, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015902819111943245, 'eval_loss_2': 0.002085179090499878, 'eval_loss_3': -18.110015869140625, 'eval_loss_4': -0.17426803708076477, 'epoch': 21.92}
{'loss': 0.0224, 'grad_norm': 10.528447151184082, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.016723930835723877, 'loss_2': 0.00565338134765625, 'loss_3': -16.387535095214844, 'loss_4': -0.4996063709259033, 'epoch': 21.92}
{'loss': 0.0157, 'grad_norm': 8.32896900177002, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.014128741808235645, 'loss_2': 0.0016069412231445312, 'loss_3': -16.25259780883789, 'loss_4': -0.3530341386795044, 'epoch': 21.93}
{'loss': 0.0102, 'grad_norm': 5.29403018951416, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.006154988426715136, 'loss_2': 0.003997802734375, 'loss_3': -16.277835845947266, 'loss_4': -0.37256646156311035, 'epoch': 21.94}
{'loss': 0.012, 'grad_norm': 6.446643352508545, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.009580797515809536, 'loss_2': 0.00244903564453125, 'loss_3': -16.232372283935547, 'loss_4': -0.46492519974708557, 'epoch': 21.94}
{'loss': 0.0189, 'grad_norm': 9.360738754272461, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.015653563663363457, 'loss_2': 0.00324249267578125, 'loss_3': -16.173629760742188, 'loss_4': -0.3528326749801636, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 16:51:42,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:42,684 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:32:55<23:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:50,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018343526870012283, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.43, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015902454033493996, 'eval_loss_2': 0.0024410709738731384, 'eval_loss_3': -18.121639251708984, 'eval_loss_4': -0.16439613699913025, 'epoch': 21.95}
{'loss': 0.0069, 'grad_norm': 6.766754150390625, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.005880624055862427, 'loss_2': 0.001003265380859375, 'loss_3': -16.207595825195312, 'loss_4': -0.44612693786621094, 'epoch': 21.95}
{'loss': 0.007, 'grad_norm': 4.622618198394775, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.004432282410562038, 'loss_2': 0.002529144287109375, 'loss_3': -16.194564819335938, 'loss_4': -0.2475874274969101, 'epoch': 21.96}
{'loss': 0.0037, 'grad_norm': 5.114558696746826, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.0034952640999108553, 'loss_2': 0.000247955322265625, 'loss_3': -16.24441146850586, 'loss_4': -0.26538071036338806, 'epoch': 21.97}
{'loss': 0.0736, 'grad_norm': 10.597264289855957, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.07321078330278397, 'loss_2': 0.0003948211669921875, 'loss_3': -16.12217903137207, 'loss_4': -0.18421071767807007, 'epoch': 21.97}
{'loss': 0.0077, 'grad_norm': 5.1562371253967285, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.0051789069548249245, 'loss_2': 0.002513885498046875, 'loss_3': -16.202777862548828, 'loss_4': -0.44346803426742554, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 16:51:50,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:50,009 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:02<22:21,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 16:51:57,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019916681572794914, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.415, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.016302643343806267, 'eval_loss_2': 0.0036140382289886475, 'eval_loss_3': -18.104740142822266, 'eval_loss_4': -0.23584239184856415, 'epoch': 21.98}
{'loss': 0.0106, 'grad_norm': 5.120181560516357, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.007774454075843096, 'loss_2': 0.0028018951416015625, 'loss_3': -16.197586059570312, 'loss_4': -0.474170446395874, 'epoch': 21.98}
{'loss': 0.0061, 'grad_norm': 4.254401206970215, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.0031522007193416357, 'loss_2': 0.002925872802734375, 'loss_3': -16.36321258544922, 'loss_4': -0.28732678294181824, 'epoch': 21.99}
{'loss': 0.0071, 'grad_norm': 4.791001796722412, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.00424174452200532, 'loss_2': 0.0028972625732421875, 'loss_3': -16.226423263549805, 'loss_4': 0.0806761384010315, 'epoch': 21.99}
{'loss': 0.02, 'grad_norm': 6.014577388763428, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.0023799350019544363, 'loss_2': 0.01763916015625, 'loss_3': -16.401147842407227, 'loss_4': -0.44702965021133423, 'epoch': 22.0}
{'loss': 0.0119, 'grad_norm': 6.0663161277771, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.007358786650002003, 'loss_2': 0.004566192626953125, 'loss_3': -16.294143676757812, 'loss_4': -0.20088094472885132, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 16:51:57,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:57,024 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:09<23:22,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:52:04,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018456483259797096, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.695, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.01570882834494114, 'eval_loss_2': 0.002747654914855957, 'eval_loss_3': -18.12122917175293, 'eval_loss_4': -0.2734445035457611, 'epoch': 22.01}
{'loss': 0.0093, 'grad_norm': 5.7541680335998535, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.007242743391543627, 'loss_2': 0.0020904541015625, 'loss_3': -16.2851619720459, 'loss_4': -0.5726222991943359, 'epoch': 22.01}
{'loss': 0.009, 'grad_norm': 5.0052924156188965, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.005009561311453581, 'loss_2': 0.003997802734375, 'loss_3': -16.23178482055664, 'loss_4': -0.34348633885383606, 'epoch': 22.02}
{'loss': 0.0068, 'grad_norm': 5.2718281745910645, 'learning_rate': 8e-06, 'loss_1': 0.004329396411776543, 'loss_2': 0.00251007080078125, 'loss_3': -16.451858520507812, 'loss_4': -0.19350916147232056, 'epoch': 22.02}
{'loss': 0.0182, 'grad_norm': 8.521814346313477, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.017902102321386337, 'loss_2': 0.0003116130828857422, 'loss_3': -16.177249908447266, 'loss_4': -0.18411394953727722, 'epoch': 22.03}
{'loss': 0.0051, 'grad_norm': 4.924041748046875, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.004175289534032345, 'loss_2': 0.00093841552734375, 'loss_3': -16.38995933532715, 'loss_4': -0.5273622274398804, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 16:52:04,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:04,337 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:17<23:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:52:11,664 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017667248845100403, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.36, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015284860506653786, 'eval_loss_2': 0.0023823902010917664, 'eval_loss_3': -18.13344383239746, 'eval_loss_4': -0.2536381483078003, 'epoch': 22.03}
{'loss': 0.0128, 'grad_norm': 4.84783411026001, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.005825086031109095, 'loss_2': 0.00696563720703125, 'loss_3': -16.15106201171875, 'loss_4': -0.5196030735969543, 'epoch': 22.04}
{'loss': 0.009, 'grad_norm': 4.678318500518799, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.007527895737439394, 'loss_2': 0.001468658447265625, 'loss_3': -16.32171058654785, 'loss_4': -0.19830307364463806, 'epoch': 22.05}
{'loss': 0.0164, 'grad_norm': 6.215298652648926, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.009352054446935654, 'loss_2': 0.007022857666015625, 'loss_3': -16.424375534057617, 'loss_4': -0.04310113936662674, 'epoch': 22.05}
{'loss': 0.0104, 'grad_norm': 5.1927924156188965, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.0060258726589381695, 'loss_2': 0.00437164306640625, 'loss_3': -16.41264533996582, 'loss_4': 0.00858284905552864, 'epoch': 22.06}
{'loss': 0.012, 'grad_norm': 4.809017658233643, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.006006949581205845, 'loss_2': 0.006023406982421875, 'loss_3': -16.240890502929688, 'loss_4': -0.12262015044689178, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 16:52:11,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:11,664 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:24<23:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:52:18,983 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018290918320417404, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015988128259778023, 'eval_loss_2': 0.002302788197994232, 'eval_loss_3': -18.134986877441406, 'eval_loss_4': -0.16141831874847412, 'epoch': 22.06}
{'loss': 0.0049, 'grad_norm': 4.472670078277588, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.0042946599423885345, 'loss_2': 0.0006031990051269531, 'loss_3': -16.368879318237305, 'loss_4': -0.07381376624107361, 'epoch': 22.07}
{'loss': 0.0172, 'grad_norm': 5.2584228515625, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.010574640706181526, 'loss_2': 0.00664520263671875, 'loss_3': -16.20268440246582, 'loss_4': -0.040991947054862976, 'epoch': 22.08}
{'loss': 0.0135, 'grad_norm': 4.76997709274292, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.005341127514839172, 'loss_2': 0.00818634033203125, 'loss_3': -16.144210815429688, 'loss_4': 0.04630608856678009, 'epoch': 22.08}
{'loss': 0.0053, 'grad_norm': 4.404600143432617, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.004335233476012945, 'loss_2': 0.0009737014770507812, 'loss_3': -16.3670597076416, 'loss_4': -0.14239861071109772, 'epoch': 22.09}
{'loss': 0.0368, 'grad_norm': 10.3017578125, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.029264967888593674, 'loss_2': 0.00749969482421875, 'loss_3': -16.219505310058594, 'loss_4': -0.25585752725601196, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 16:52:18,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:18,984 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:31<23:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:52:26,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018568608909845352, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.505, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015753870829939842, 'eval_loss_2': 0.002814739942550659, 'eval_loss_3': -18.139022827148438, 'eval_loss_4': -0.12657693028450012, 'epoch': 22.09}
{'loss': 0.0066, 'grad_norm': 5.1063714027404785, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.005092587321996689, 'loss_2': 0.00147247314453125, 'loss_3': -16.31813621520996, 'loss_4': -0.2185056209564209, 'epoch': 22.1}
{'loss': 0.0058, 'grad_norm': 5.355916500091553, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.005533408373594284, 'loss_2': 0.0002510547637939453, 'loss_3': -16.55613136291504, 'loss_4': -0.16870082914829254, 'epoch': 22.1}
{'loss': 0.0087, 'grad_norm': 5.0444464683532715, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.006580098066478968, 'loss_2': 0.0021381378173828125, 'loss_3': -16.099376678466797, 'loss_4': -0.2845248281955719, 'epoch': 22.11}
{'loss': 0.0037, 'grad_norm': 4.42152738571167, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.0030491130892187357, 'loss_2': 0.0006122589111328125, 'loss_3': -16.179244995117188, 'loss_4': 0.0012553408741950989, 'epoch': 22.12}
{'loss': 0.0134, 'grad_norm': 6.793276309967041, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.013048519380390644, 'loss_2': 0.0003542900085449219, 'loss_3': -16.346065521240234, 'loss_4': -0.15911775827407837, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 16:52:26,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:26,303 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:39<23:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:52:33,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01805473119020462, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.516, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014896460808813572, 'eval_loss_2': 0.003158271312713623, 'eval_loss_3': -18.14402961730957, 'eval_loss_4': -0.11102084815502167, 'epoch': 22.12}
{'loss': 0.0114, 'grad_norm': 4.916738033294678, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.009142476134002209, 'loss_2': 0.002292633056640625, 'loss_3': -16.07248878479004, 'loss_4': -0.3234158754348755, 'epoch': 22.13}
{'loss': 0.0143, 'grad_norm': 5.905671119689941, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.009328648447990417, 'loss_2': 0.0049591064453125, 'loss_3': -16.293540954589844, 'loss_4': -0.28767073154449463, 'epoch': 22.13}
{'loss': 0.0077, 'grad_norm': 5.059488296508789, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.004247053060680628, 'loss_2': 0.00341033935546875, 'loss_3': -16.212526321411133, 'loss_4': -0.3727223873138428, 'epoch': 22.14}
{'loss': 0.0135, 'grad_norm': 4.820331573486328, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.0031329181510955095, 'loss_2': 0.010345458984375, 'loss_3': -16.261383056640625, 'loss_4': -0.2681223750114441, 'epoch': 22.15}
{'loss': 0.0645, 'grad_norm': 15.287755012512207, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.06306058168411255, 'loss_2': 0.001430511474609375, 'loss_3': -16.3096923828125, 'loss_4': 0.1482674777507782, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 16:52:33,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:33,625 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:33:46<23:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:52:40,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018022581934928894, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.599, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014547660946846008, 'eval_loss_2': 0.0034749209880828857, 'eval_loss_3': -18.15298843383789, 'eval_loss_4': -0.017399705946445465, 'epoch': 22.15}
{'loss': 0.0101, 'grad_norm': 4.559020042419434, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.006589642260223627, 'loss_2': 0.003505706787109375, 'loss_3': -16.217378616333008, 'loss_4': -0.29916754364967346, 'epoch': 22.16}
{'loss': 0.0127, 'grad_norm': 6.270158767700195, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.008143873885273933, 'loss_2': 0.00452423095703125, 'loss_3': -16.110471725463867, 'loss_4': 0.0753580778837204, 'epoch': 22.16}
{'loss': 0.0147, 'grad_norm': 5.6898274421691895, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.009130402468144894, 'loss_2': 0.0055389404296875, 'loss_3': -16.3241024017334, 'loss_4': 0.24211551249027252, 'epoch': 22.17}
{'loss': 0.0172, 'grad_norm': 5.663160800933838, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.011384974233806133, 'loss_2': 0.00577545166015625, 'loss_3': -16.214019775390625, 'loss_4': 0.16869376599788666, 'epoch': 22.17}
{'loss': 0.0146, 'grad_norm': 5.805173873901367, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.008843866176903248, 'loss_2': 0.005771636962890625, 'loss_3': -16.117084503173828, 'loss_4': 0.23503315448760986, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 16:52:40,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:40,946 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:33:53<23:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:48,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018431052565574646, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.54, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015299753285944462, 'eval_loss_2': 0.003131300210952759, 'eval_loss_3': -18.140060424804688, 'eval_loss_4': 0.020283468067646027, 'epoch': 22.18}
{'loss': 0.0132, 'grad_norm': 5.215266227722168, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.009065705351531506, 'loss_2': 0.004180908203125, 'loss_3': -16.09988021850586, 'loss_4': 0.13732457160949707, 'epoch': 22.19}
{'loss': 0.009, 'grad_norm': 5.059304237365723, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.008401293307542801, 'loss_2': 0.0005846023559570312, 'loss_3': -16.163917541503906, 'loss_4': 0.25597548484802246, 'epoch': 22.19}
{'loss': 0.005, 'grad_norm': 4.762950897216797, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.004959693644195795, 'loss_2': 6.854534149169922e-05, 'loss_3': -16.336265563964844, 'loss_4': -0.5061676502227783, 'epoch': 22.2}
{'loss': 0.0845, 'grad_norm': 18.587169647216797, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.08429604023694992, 'loss_2': 0.0001628398895263672, 'loss_3': -16.080276489257812, 'loss_4': 0.27490368485450745, 'epoch': 22.2}
{'loss': 0.0113, 'grad_norm': 5.042318344116211, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.004363211803138256, 'loss_2': 0.00688934326171875, 'loss_3': -16.206798553466797, 'loss_4': 0.05380059778690338, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 16:52:48,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:48,272 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:01<23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:55,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01721508428454399, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014366265386343002, 'eval_loss_2': 0.0028488188982009888, 'eval_loss_3': -18.12602996826172, 'eval_loss_4': 0.0057421401143074036, 'epoch': 22.21}
{'loss': 0.0146, 'grad_norm': 5.351780891418457, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.011650178581476212, 'loss_2': 0.002925872802734375, 'loss_3': -16.330516815185547, 'loss_4': 0.17880624532699585, 'epoch': 22.22}
{'loss': 0.006, 'grad_norm': 4.496052265167236, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.0054373834282159805, 'loss_2': 0.0005712509155273438, 'loss_3': -16.152427673339844, 'loss_4': 0.20388801395893097, 'epoch': 22.22}
{'loss': 0.0033, 'grad_norm': 4.423426151275635, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.0032207772601395845, 'loss_2': 8.165836334228516e-05, 'loss_3': -16.412246704101562, 'loss_4': 0.038407132029533386, 'epoch': 22.23}
{'loss': 0.0044, 'grad_norm': 5.020265579223633, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.0038695151451975107, 'loss_2': 0.0005245208740234375, 'loss_3': -16.211563110351562, 'loss_4': -0.09053772687911987, 'epoch': 22.23}
{'loss': 0.0114, 'grad_norm': 5.513268947601318, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.008351081050932407, 'loss_2': 0.003032684326171875, 'loss_3': -16.11980438232422, 'loss_4': -0.188536137342453, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 16:52:55,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:55,609 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:08<22:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:02,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018832558766007423, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.555, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015333929099142551, 'eval_loss_2': 0.0034986287355422974, 'eval_loss_3': -18.11736297607422, 'eval_loss_4': 0.011654425412416458, 'epoch': 22.24}
{'loss': 0.0105, 'grad_norm': 4.74784517288208, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.007311997469514608, 'loss_2': 0.0031795501708984375, 'loss_3': -16.253665924072266, 'loss_4': -0.10430946201086044, 'epoch': 22.24}
{'loss': 0.0118, 'grad_norm': 4.629302501678467, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.004803721327334642, 'loss_2': 0.00701141357421875, 'loss_3': -16.084945678710938, 'loss_4': -0.1359712928533554, 'epoch': 22.25}
{'loss': 0.0064, 'grad_norm': 4.615383625030518, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.0034238502848893404, 'loss_2': 0.0029430389404296875, 'loss_3': -16.205276489257812, 'loss_4': 0.01091642677783966, 'epoch': 22.26}
{'loss': 0.0122, 'grad_norm': 5.974829196929932, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.008571689017117023, 'loss_2': 0.0036411285400390625, 'loss_3': -16.080482482910156, 'loss_4': -0.4398867189884186, 'epoch': 22.26}
{'loss': 0.0092, 'grad_norm': 4.699564456939697, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.005752325523644686, 'loss_2': 0.003429412841796875, 'loss_3': -16.183670043945312, 'loss_4': -0.04686566814780235, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 16:53:02,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:02,931 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:15<23:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:53:10,455 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01951645128428936, 'eval_runtime': 3.9858, 'eval_samples_per_second': 256.915, 'eval_steps_per_second': 4.014, 'eval_loss_1': 0.015685854479670525, 'eval_loss_2': 0.0038305968046188354, 'eval_loss_3': -18.10828971862793, 'eval_loss_4': 0.0741712898015976, 'epoch': 22.27}
{'loss': 0.0088, 'grad_norm': 4.634166240692139, 'learning_rate': 7.75e-06, 'loss_1': 0.007511912379413843, 'loss_2': 0.0012960433959960938, 'loss_3': -16.231115341186523, 'loss_4': 0.01796089857816696, 'epoch': 22.27}
{'loss': 0.0075, 'grad_norm': 4.11033821105957, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.004984112456440926, 'loss_2': 0.0025177001953125, 'loss_3': -16.108028411865234, 'loss_4': 0.06907257437705994, 'epoch': 22.28}
{'loss': 0.0078, 'grad_norm': 6.072946071624756, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.005573358852416277, 'loss_2': 0.00225830078125, 'loss_3': -16.28811264038086, 'loss_4': 0.1993046998977661, 'epoch': 22.28}
{'loss': 0.0391, 'grad_norm': 17.75144386291504, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.03849098086357117, 'loss_2': 0.000637054443359375, 'loss_3': -16.056167602539062, 'loss_4': 0.1376025676727295, 'epoch': 22.29}
{'loss': 0.0052, 'grad_norm': 4.647120952606201, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.0031615644693374634, 'loss_2': 0.0020618438720703125, 'loss_3': -16.17308807373047, 'loss_4': 0.008703310042619705, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 16:53:10,455 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:10,456 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:23<22:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:17,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01922234334051609, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.311, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015234189108014107, 'eval_loss_2': 0.003988154232501984, 'eval_loss_3': -18.1143741607666, 'eval_loss_4': 0.17602984607219696, 'epoch': 22.3}
{'loss': 0.0067, 'grad_norm': 4.51056432723999, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.003780932864174247, 'loss_2': 0.0028972625732421875, 'loss_3': -16.285144805908203, 'loss_4': 0.014895923435688019, 'epoch': 22.3}
{'loss': 0.0075, 'grad_norm': 4.755086898803711, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.004151476547122002, 'loss_2': 0.0033855438232421875, 'loss_3': -16.416906356811523, 'loss_4': 0.24781844019889832, 'epoch': 22.31}
{'loss': 0.009, 'grad_norm': 4.955468654632568, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.003539642784744501, 'loss_2': 0.00550079345703125, 'loss_3': -16.055187225341797, 'loss_4': 0.0030584409832954407, 'epoch': 22.31}
{'loss': 0.0106, 'grad_norm': 6.225306987762451, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.008137085475027561, 'loss_2': 0.002429962158203125, 'loss_3': -16.146127700805664, 'loss_4': 0.13095064461231232, 'epoch': 22.32}
{'loss': 0.0292, 'grad_norm': 12.183756828308105, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.018827136605978012, 'loss_2': 0.01035308837890625, 'loss_3': -16.315017700195312, 'loss_4': 0.454183429479599, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 16:53:17,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:17,784 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:30<22:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:25,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019664354622364044, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015805313363671303, 'eval_loss_2': 0.0038590431213378906, 'eval_loss_3': -18.117273330688477, 'eval_loss_4': 0.27404850721359253, 'epoch': 22.33}
{'loss': 0.0121, 'grad_norm': 5.196456432342529, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.008563399314880371, 'loss_2': 0.003513336181640625, 'loss_3': -16.115018844604492, 'loss_4': -0.11379697173833847, 'epoch': 22.33}
{'loss': 0.0154, 'grad_norm': 5.151867866516113, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.004582665860652924, 'loss_2': 0.0108184814453125, 'loss_3': -16.238008499145508, 'loss_4': 0.18193520605564117, 'epoch': 22.34}
{'loss': 0.0103, 'grad_norm': 5.8319292068481445, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.007058871444314718, 'loss_2': 0.003192901611328125, 'loss_3': -16.276512145996094, 'loss_4': -0.22762298583984375, 'epoch': 22.34}
{'loss': 0.0172, 'grad_norm': 6.431026458740234, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.009655945934355259, 'loss_2': 0.0075225830078125, 'loss_3': -16.275794982910156, 'loss_4': 0.11577776074409485, 'epoch': 22.35}
{'loss': 0.0122, 'grad_norm': 5.861067771911621, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.01036452129483223, 'loss_2': 0.001811981201171875, 'loss_3': -16.475034713745117, 'loss_4': 0.33645275235176086, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 16:53:25,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:25,115 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:37<22:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:32,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01922411285340786, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.383, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015547758899629116, 'eval_loss_2': 0.0036763548851013184, 'eval_loss_3': -18.117088317871094, 'eval_loss_4': 0.31205642223358154, 'epoch': 22.35}
{'loss': 0.0146, 'grad_norm': 7.297608852386475, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.013767198659479618, 'loss_2': 0.0007829666137695312, 'loss_3': -16.140031814575195, 'loss_4': 0.3510422110557556, 'epoch': 22.36}
{'loss': 0.0065, 'grad_norm': 4.961334228515625, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.005236195400357246, 'loss_2': 0.001293182373046875, 'loss_3': -16.271751403808594, 'loss_4': 0.12843792140483856, 'epoch': 22.37}
{'loss': 0.018, 'grad_norm': 13.478717803955078, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.015548082068562508, 'loss_2': 0.00240325927734375, 'loss_3': -16.424619674682617, 'loss_4': 0.32709380984306335, 'epoch': 22.37}
{'loss': 0.0096, 'grad_norm': 5.353657245635986, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.005434815771877766, 'loss_2': 0.004119873046875, 'loss_3': -16.357101440429688, 'loss_4': 0.7921918630599976, 'epoch': 22.38}
{'loss': 0.01, 'grad_norm': 4.503822326660156, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.0038589525502175093, 'loss_2': 0.00611114501953125, 'loss_3': -16.285995483398438, 'loss_4': 0.46198928356170654, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 16:53:32,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:32,442 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:34:45<22:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:39,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019012248143553734, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.455, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015541529282927513, 'eval_loss_2': 0.0034707188606262207, 'eval_loss_3': -18.12003517150879, 'eval_loss_4': 0.3430139124393463, 'epoch': 22.38}
{'loss': 0.0055, 'grad_norm': 5.177733421325684, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.005192020442336798, 'loss_2': 0.0003476142883300781, 'loss_3': -16.328807830810547, 'loss_4': 0.6758289337158203, 'epoch': 22.39}
{'loss': 0.0104, 'grad_norm': 5.004862308502197, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.005551858805119991, 'loss_2': 0.00482177734375, 'loss_3': -16.067337036132812, 'loss_4': -0.11594785004854202, 'epoch': 22.4}
{'loss': 0.0106, 'grad_norm': 4.731868743896484, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.005819075275212526, 'loss_2': 0.004779815673828125, 'loss_3': -15.909571647644043, 'loss_4': 0.48207977414131165, 'epoch': 22.4}
{'loss': 0.0033, 'grad_norm': 4.863401889801025, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.003054545260965824, 'loss_2': 0.0002944469451904297, 'loss_3': -16.459318161010742, 'loss_4': 0.4244154095649719, 'epoch': 22.41}
{'loss': 0.009, 'grad_norm': 5.581405162811279, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.007782631553709507, 'loss_2': 0.001224517822265625, 'loss_3': -16.193262100219727, 'loss_4': 0.3433670401573181, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 16:53:39,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:39,773 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:34:52<22:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:53:47,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018518570810556412, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.394, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01477568969130516, 'eval_loss_2': 0.0037428811192512512, 'eval_loss_3': -18.11903953552246, 'eval_loss_4': 0.3486069440841675, 'epoch': 22.41}
{'loss': 0.016, 'grad_norm': 8.250550270080566, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.015203283168375492, 'loss_2': 0.0008053779602050781, 'loss_3': -16.209402084350586, 'loss_4': 0.33189475536346436, 'epoch': 22.42}
{'loss': 0.0128, 'grad_norm': 4.859472751617432, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.005512441508471966, 'loss_2': 0.00725555419921875, 'loss_3': -16.064781188964844, 'loss_4': 0.18787090480327606, 'epoch': 22.42}
{'loss': 0.009, 'grad_norm': 4.907167434692383, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.004645186010748148, 'loss_2': 0.00438690185546875, 'loss_3': -16.050893783569336, 'loss_4': 0.42229077219963074, 'epoch': 22.43}
{'loss': 0.009, 'grad_norm': 4.437731742858887, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.006558072753250599, 'loss_2': 0.002490997314453125, 'loss_3': -16.216978073120117, 'loss_4': 0.2959350645542145, 'epoch': 22.44}
{'loss': 0.0106, 'grad_norm': 4.799520492553711, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.008396448567509651, 'loss_2': 0.00217437744140625, 'loss_3': -16.190143585205078, 'loss_4': 0.36010634899139404, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 16:53:47,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:47,093 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:34:59<22:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:54,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017524994909763336, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.469, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014654913917183876, 'eval_loss_2': 0.0028700828552246094, 'eval_loss_3': -18.123550415039062, 'eval_loss_4': 0.3312378525733948, 'epoch': 22.44}
{'loss': 0.0115, 'grad_norm': 4.845974922180176, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0073165916837751865, 'loss_2': 0.0042266845703125, 'loss_3': -16.483272552490234, 'loss_4': 0.27292588353157043, 'epoch': 22.45}
{'loss': 0.0199, 'grad_norm': 8.648326873779297, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.019328320398926735, 'loss_2': 0.0006093978881835938, 'loss_3': -16.241744995117188, 'loss_4': 0.32788535952568054, 'epoch': 22.45}
{'loss': 0.0101, 'grad_norm': 4.601861953735352, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.004423011094331741, 'loss_2': 0.0057220458984375, 'loss_3': -16.28415870666504, 'loss_4': 0.38161927461624146, 'epoch': 22.46}
{'loss': 0.0156, 'grad_norm': 6.751396656036377, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.013449545949697495, 'loss_2': 0.0021228790283203125, 'loss_3': -16.243762969970703, 'loss_4': 0.550516664981842, 'epoch': 22.47}
{'loss': 0.0161, 'grad_norm': 5.265780925750732, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.008490689098834991, 'loss_2': 0.00762939453125, 'loss_3': -16.32220458984375, 'loss_4': 0.2518239915370941, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 16:53:54,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:54,416 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:07<22:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:54:01,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01801927015185356, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.015074117109179497, 'eval_loss_2': 0.002945154905319214, 'eval_loss_3': -18.135332107543945, 'eval_loss_4': 0.281497985124588, 'epoch': 22.47}
{'loss': 0.0088, 'grad_norm': 4.90035343170166, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.006967952474951744, 'loss_2': 0.0018777847290039062, 'loss_3': -16.49168586730957, 'loss_4': 0.42033931612968445, 'epoch': 22.48}
{'loss': 0.0098, 'grad_norm': 4.625180244445801, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.004060721956193447, 'loss_2': 0.0056915283203125, 'loss_3': -16.313499450683594, 'loss_4': -0.12082774937152863, 'epoch': 22.48}
{'loss': 0.01, 'grad_norm': 5.151052951812744, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.008078491315245628, 'loss_2': 0.0019159317016601562, 'loss_3': -16.11060905456543, 'loss_4': 0.33145672082901, 'epoch': 22.49}
{'loss': 0.011, 'grad_norm': 4.297003269195557, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.0040889643132686615, 'loss_2': 0.00693511962890625, 'loss_3': -16.241840362548828, 'loss_4': 0.37340396642684937, 'epoch': 22.49}
{'loss': 0.0089, 'grad_norm': 4.364323139190674, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.0056960745714604855, 'loss_2': 0.003185272216796875, 'loss_3': -16.262447357177734, 'loss_4': 0.15752960741519928, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 16:54:01,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:01,739 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:14<22:09,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:54:09,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018695702776312828, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01543300412595272, 'eval_loss_2': 0.0032626986503601074, 'eval_loss_3': -18.13640594482422, 'eval_loss_4': 0.18582004308700562, 'epoch': 22.5}
{'loss': 0.0145, 'grad_norm': 7.010988235473633, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.014240388758480549, 'loss_2': 0.0003056526184082031, 'loss_3': -16.034879684448242, 'loss_4': 0.4415932297706604, 'epoch': 22.51}
{'loss': 0.0098, 'grad_norm': 5.1336236000061035, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.005359494127333164, 'loss_2': 0.00441741943359375, 'loss_3': -16.291263580322266, 'loss_4': 0.007411077618598938, 'epoch': 22.51}
{'loss': 0.0086, 'grad_norm': 5.379405975341797, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.008220601826906204, 'loss_2': 0.000396728515625, 'loss_3': -16.217744827270508, 'loss_4': 0.6766420602798462, 'epoch': 22.52}
{'loss': 0.0307, 'grad_norm': 11.201042175292969, 'learning_rate': 7.5e-06, 'loss_1': 0.0298298429697752, 'loss_2': 0.0008769035339355469, 'loss_3': -16.381711959838867, 'loss_4': 0.22409850358963013, 'epoch': 22.52}
{'loss': 0.0087, 'grad_norm': 4.953225135803223, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.0062821609899401665, 'loss_2': 0.00238800048828125, 'loss_3': -16.171993255615234, 'loss_4': 0.09239150583744049, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 16:54:09,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:09,067 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:21<22:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:16,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018147872760891914, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.767, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.015221125446259975, 'eval_loss_2': 0.0029267482459545135, 'eval_loss_3': -18.121858596801758, 'eval_loss_4': 0.09218089282512665, 'epoch': 22.53}
{'loss': 0.0144, 'grad_norm': 6.98555326461792, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.013722152449190617, 'loss_2': 0.0006456375122070312, 'loss_3': -16.189048767089844, 'loss_4': -0.04576288163661957, 'epoch': 22.53}
{'loss': 0.0131, 'grad_norm': 7.988613128662109, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.012221022509038448, 'loss_2': 0.0008878707885742188, 'loss_3': -16.17827606201172, 'loss_4': -0.19019752740859985, 'epoch': 22.54}
{'loss': 0.0105, 'grad_norm': 6.303956985473633, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.008797155693173409, 'loss_2': 0.0017452239990234375, 'loss_3': -16.279834747314453, 'loss_4': 0.3154746890068054, 'epoch': 22.55}
{'loss': 0.0055, 'grad_norm': 4.543160438537598, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.004602180793881416, 'loss_2': 0.0009222030639648438, 'loss_3': -16.343994140625, 'loss_4': -0.1526510864496231, 'epoch': 22.55}
{'loss': 0.0127, 'grad_norm': 6.385158061981201, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.011191852390766144, 'loss_2': 0.0014591217041015625, 'loss_3': -16.216930389404297, 'loss_4': 0.22008489072322845, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 16:54:16,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:16,406 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:29<22:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:23,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018786948174238205, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.573, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.015770241618156433, 'eval_loss_2': 0.0030167102813720703, 'eval_loss_3': -18.116737365722656, 'eval_loss_4': 0.019601836800575256, 'epoch': 22.56}
{'loss': 0.01, 'grad_norm': 4.5224103927612305, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.0064949472434818745, 'loss_2': 0.0034961700439453125, 'loss_3': -16.20501708984375, 'loss_4': -0.17724142968654633, 'epoch': 22.56}
{'loss': 0.0065, 'grad_norm': 4.662962436676025, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.004237393382936716, 'loss_2': 0.002262115478515625, 'loss_3': -16.028789520263672, 'loss_4': -0.34255555272102356, 'epoch': 22.57}
{'loss': 0.0042, 'grad_norm': 4.428640842437744, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.0036743960808962584, 'loss_2': 0.0005269050598144531, 'loss_3': -16.338886260986328, 'loss_4': 0.3109673857688904, 'epoch': 22.58}
{'loss': 0.0038, 'grad_norm': 4.858967304229736, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.0032387268729507923, 'loss_2': 0.0005688667297363281, 'loss_3': -16.298372268676758, 'loss_4': -0.16462796926498413, 'epoch': 22.58}
{'loss': 0.0084, 'grad_norm': 4.805950164794922, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.004869746509939432, 'loss_2': 0.00348663330078125, 'loss_3': -16.229793548583984, 'loss_4': -0.12114085257053375, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 16:54:23,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:23,732 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:36<21:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:31,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01761545240879059, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.65, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.014903217554092407, 'eval_loss_2': 0.002712234854698181, 'eval_loss_3': -18.100746154785156, 'eval_loss_4': -0.052698150277137756, 'epoch': 22.59}
{'loss': 0.0172, 'grad_norm': 5.689415454864502, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.00742983166128397, 'loss_2': 0.0097503662109375, 'loss_3': -16.211650848388672, 'loss_4': 0.41051557660102844, 'epoch': 22.59}
{'loss': 0.0061, 'grad_norm': 4.772673606872559, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.003947234246879816, 'loss_2': 0.002147674560546875, 'loss_3': -16.202354431152344, 'loss_4': -0.020226597785949707, 'epoch': 22.6}
{'loss': 0.0076, 'grad_norm': 4.824275493621826, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.007353037130087614, 'loss_2': 0.0002865791320800781, 'loss_3': -16.220458984375, 'loss_4': 0.1116395965218544, 'epoch': 22.6}
{'loss': 0.013, 'grad_norm': 5.048416614532471, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.006095835939049721, 'loss_2': 0.006946563720703125, 'loss_3': -16.238828659057617, 'loss_4': 0.021444950252771378, 'epoch': 22.61}
{'loss': 0.0151, 'grad_norm': 6.440482139587402, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.013978960923850536, 'loss_2': 0.00112152099609375, 'loss_3': -16.1945858001709, 'loss_4': 0.0355008989572525, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 16:54:31,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:31,060 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:35:43<21:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:38,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017928611487150192, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.307, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014815281145274639, 'eval_loss_2': 0.0031133294105529785, 'eval_loss_3': -18.11235237121582, 'eval_loss_4': -0.07370242476463318, 'epoch': 22.62}
{'loss': 0.0102, 'grad_norm': 4.6530985832214355, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.005542175844311714, 'loss_2': 0.004680633544921875, 'loss_3': -16.140810012817383, 'loss_4': -0.12296229600906372, 'epoch': 22.62}
{'loss': 0.0147, 'grad_norm': 5.245594024658203, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.00791151449084282, 'loss_2': 0.0068206787109375, 'loss_3': -16.339176177978516, 'loss_4': -0.31871938705444336, 'epoch': 22.63}
{'loss': 0.0108, 'grad_norm': 5.173476219177246, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.00983609352260828, 'loss_2': 0.0009398460388183594, 'loss_3': -16.399267196655273, 'loss_4': 0.009081661701202393, 'epoch': 22.63}
{'loss': 0.0084, 'grad_norm': 4.4489617347717285, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.006748363375663757, 'loss_2': 0.0016050338745117188, 'loss_3': -16.27170181274414, 'loss_4': -0.18927150964736938, 'epoch': 22.64}
{'loss': 0.0072, 'grad_norm': 4.668766498565674, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.005532677285373211, 'loss_2': 0.0016965866088867188, 'loss_3': -16.315523147583008, 'loss_4': -0.20564088225364685, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 16:54:38,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:38,397 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:35:51<21:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:45,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019383274018764496, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.59, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.015838049352169037, 'eval_loss_2': 0.003545224666595459, 'eval_loss_3': -18.112672805786133, 'eval_loss_4': -0.06055871769785881, 'epoch': 22.65}
{'loss': 0.0096, 'grad_norm': 5.280787944793701, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.009393276646733284, 'loss_2': 0.0001766681671142578, 'loss_3': -16.27100372314453, 'loss_4': -0.3494694232940674, 'epoch': 22.65}
{'loss': 0.0089, 'grad_norm': 5.26580286026001, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.008555346168577671, 'loss_2': 0.0003190040588378906, 'loss_3': -16.168825149536133, 'loss_4': -0.23083510994911194, 'epoch': 22.66}
{'loss': 0.0097, 'grad_norm': 5.089470863342285, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.007192102260887623, 'loss_2': 0.0025177001953125, 'loss_3': -16.274314880371094, 'loss_4': -0.23682692646980286, 'epoch': 22.66}
{'loss': 0.0053, 'grad_norm': 5.318665504455566, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.004298441112041473, 'loss_2': 0.001026153564453125, 'loss_3': -16.335590362548828, 'loss_4': 0.1795717477798462, 'epoch': 22.67}
{'loss': 0.0067, 'grad_norm': 5.169730186462402, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.005351813044399023, 'loss_2': 0.0013256072998046875, 'loss_3': -16.06732749938965, 'loss_4': -0.09596893191337585, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 16:54:45,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:45,727 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:35:58<21:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:54:53,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019136402755975723, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.42, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015495393425226212, 'eval_loss_2': 0.0036410093307495117, 'eval_loss_3': -18.111486434936523, 'eval_loss_4': -0.06772401183843613, 'epoch': 22.67}
{'loss': 0.0136, 'grad_norm': 11.561970710754395, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.012341967783868313, 'loss_2': 0.0012569427490234375, 'loss_3': -16.20160484313965, 'loss_4': 0.2363802194595337, 'epoch': 22.68}
{'loss': 0.0483, 'grad_norm': 14.275346755981445, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.044400278478860855, 'loss_2': 0.00389862060546875, 'loss_3': -15.98620891571045, 'loss_4': 0.026591695845127106, 'epoch': 22.69}
{'loss': 0.0349, 'grad_norm': 11.482218742370605, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.025489872321486473, 'loss_2': 0.0093994140625, 'loss_3': -16.207677841186523, 'loss_4': 0.06889072060585022, 'epoch': 22.69}
{'loss': 0.0163, 'grad_norm': 6.105441093444824, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.013298332691192627, 'loss_2': 0.0029773712158203125, 'loss_3': -16.333660125732422, 'loss_4': -0.019274890422821045, 'epoch': 22.7}
{'loss': 0.0105, 'grad_norm': 4.6596879959106445, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.006446062121540308, 'loss_2': 0.00403594970703125, 'loss_3': -15.937074661254883, 'loss_4': 0.3924228549003601, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 16:54:53,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:53,049 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:05<21:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:00,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018575916066765785, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.431, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01553999911993742, 'eval_loss_2': 0.00303591787815094, 'eval_loss_3': -18.120561599731445, 'eval_loss_4': -0.057083822786808014, 'epoch': 22.7}
{'loss': 0.0094, 'grad_norm': 4.891102313995361, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.007915566675364971, 'loss_2': 0.0014448165893554688, 'loss_3': -16.292476654052734, 'loss_4': -0.3081008791923523, 'epoch': 22.71}
{'loss': 0.0206, 'grad_norm': 7.201080799102783, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.01423728372901678, 'loss_2': 0.00640106201171875, 'loss_3': -16.126373291015625, 'loss_4': -0.035496920347213745, 'epoch': 22.72}
{'loss': 0.016, 'grad_norm': 7.24199104309082, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.011778902262449265, 'loss_2': 0.00424957275390625, 'loss_3': -16.22540283203125, 'loss_4': 0.06576649099588394, 'epoch': 22.72}
{'loss': 0.0071, 'grad_norm': 5.176825046539307, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.006191643420606852, 'loss_2': 0.000957489013671875, 'loss_3': -16.141067504882812, 'loss_4': 0.05420897528529167, 'epoch': 22.73}
{'loss': 0.012, 'grad_norm': 4.311972141265869, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.004192111548036337, 'loss_2': 0.007762908935546875, 'loss_3': -16.36383056640625, 'loss_4': 0.10348014533519745, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 16:55:00,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:00,369 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:13<21:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:07,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019099168479442596, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.509, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.0165330171585083, 'eval_loss_2': 0.0025661513209342957, 'eval_loss_3': -18.1199951171875, 'eval_loss_4': -0.07495937496423721, 'epoch': 22.73}
{'loss': 0.0391, 'grad_norm': 18.96824836730957, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.038940127938985825, 'loss_2': 0.00012022256851196289, 'loss_3': -16.075275421142578, 'loss_4': -0.06313659995794296, 'epoch': 22.74}
{'loss': 0.0157, 'grad_norm': 5.227893352508545, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.009167730808258057, 'loss_2': 0.006561279296875, 'loss_3': -16.239288330078125, 'loss_4': 0.018699094653129578, 'epoch': 22.74}
{'loss': 0.0202, 'grad_norm': 5.088521480560303, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.009260766208171844, 'loss_2': 0.0109710693359375, 'loss_3': -16.171350479125977, 'loss_4': -0.2251276969909668, 'epoch': 22.75}
{'loss': 0.0105, 'grad_norm': 5.040523529052734, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.007473566569387913, 'loss_2': 0.0030059814453125, 'loss_3': -16.366634368896484, 'loss_4': 0.08501952886581421, 'epoch': 22.76}
{'loss': 0.0048, 'grad_norm': 5.000661849975586, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.003828298533335328, 'loss_2': 0.000942230224609375, 'loss_3': -16.163719177246094, 'loss_4': -0.010193254798650742, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 16:55:07,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:07,689 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:20<21:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:15,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020017413422465324, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.017045676708221436, 'eval_loss_2': 0.002971738576889038, 'eval_loss_3': -18.121875762939453, 'eval_loss_4': -0.12602588534355164, 'epoch': 22.76}
{'loss': 0.0112, 'grad_norm': 7.583651542663574, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.008844368159770966, 'loss_2': 0.00238037109375, 'loss_3': -16.322723388671875, 'loss_4': -0.45441141724586487, 'epoch': 22.77}
{'loss': 0.0153, 'grad_norm': 6.225082874298096, 'learning_rate': 7.25e-06, 'loss_1': 0.00937846302986145, 'loss_2': 0.0059356689453125, 'loss_3': -16.116230010986328, 'loss_4': 0.3629211187362671, 'epoch': 22.77}
{'loss': 0.0071, 'grad_norm': 4.802401542663574, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.0046590110287070274, 'loss_2': 0.0024566650390625, 'loss_3': -16.32147216796875, 'loss_4': 0.03889533132314682, 'epoch': 22.78}
{'loss': 0.0061, 'grad_norm': 4.86855936050415, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.004846127238124609, 'loss_2': 0.001270294189453125, 'loss_3': -16.32124900817871, 'loss_4': -0.2121410369873047, 'epoch': 22.78}
{'loss': 0.0117, 'grad_norm': 5.840597629547119, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.01098443940281868, 'loss_2': 0.0007457733154296875, 'loss_3': -16.347841262817383, 'loss_4': -0.21037507057189941, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 16:55:15,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:15,015 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:27<21:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:22,331 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020849814638495445, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.689, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.016968583688139915, 'eval_loss_2': 0.00388123095035553, 'eval_loss_3': -18.138891220092773, 'eval_loss_4': -0.1505325436592102, 'epoch': 22.79}
{'loss': 0.0518, 'grad_norm': 13.996254920959473, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.04630023241043091, 'loss_2': 0.0054931640625, 'loss_3': -16.55443572998047, 'loss_4': 0.5200681686401367, 'epoch': 22.8}
{'loss': 0.0202, 'grad_norm': 15.822649002075195, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.0156566072255373, 'loss_2': 0.0045318603515625, 'loss_3': -16.224193572998047, 'loss_4': -0.0379907488822937, 'epoch': 22.8}
{'loss': 0.0169, 'grad_norm': 5.397130489349365, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.0102747343480587, 'loss_2': 0.006626129150390625, 'loss_3': -16.331302642822266, 'loss_4': -0.23438608646392822, 'epoch': 22.81}
{'loss': 0.0066, 'grad_norm': 4.3178558349609375, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.004704312887042761, 'loss_2': 0.001888275146484375, 'loss_3': -16.351665496826172, 'loss_4': -0.16985267400741577, 'epoch': 22.81}
{'loss': 0.0071, 'grad_norm': 4.558342933654785, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.004287675488740206, 'loss_2': 0.00284576416015625, 'loss_3': -16.247222900390625, 'loss_4': -0.047149963676929474, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 16:55:22,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:22,331 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:35<21:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:29,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020270075649023056, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.496, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.017361605539917946, 'eval_loss_2': 0.002908468246459961, 'eval_loss_3': -18.150951385498047, 'eval_loss_4': -0.14165128767490387, 'epoch': 22.82}
{'loss': 0.0109, 'grad_norm': 5.316915512084961, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.009919737465679646, 'loss_2': 0.0009756088256835938, 'loss_3': -16.10970687866211, 'loss_4': 0.12304054945707321, 'epoch': 22.83}
{'loss': 0.0111, 'grad_norm': 5.364804744720459, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.007934914901852608, 'loss_2': 0.0031833648681640625, 'loss_3': -16.061025619506836, 'loss_4': -0.3896484375, 'epoch': 22.83}
{'loss': 0.0098, 'grad_norm': 4.750330924987793, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.005049747880548239, 'loss_2': 0.004726409912109375, 'loss_3': -16.315879821777344, 'loss_4': -0.055027712136507034, 'epoch': 22.84}
{'loss': 0.0059, 'grad_norm': 4.530081748962402, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.005604065954685211, 'loss_2': 0.0003123283386230469, 'loss_3': -16.298553466796875, 'loss_4': -0.006943196058273315, 'epoch': 22.84}
{'loss': 0.0038, 'grad_norm': 4.487231254577637, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.0031997922342270613, 'loss_2': 0.0005788803100585938, 'loss_3': -16.159364700317383, 'loss_4': -0.4034501314163208, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 16:55:29,652 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:29,652 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:36:42<21:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:36,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01952628418803215, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.206, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01717262528836727, 'eval_loss_2': 0.0023536570370197296, 'eval_loss_3': -18.156803131103516, 'eval_loss_4': -0.15441863238811493, 'epoch': 22.85}
{'loss': 0.0132, 'grad_norm': 6.234224319458008, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.008953699842095375, 'loss_2': 0.0042572021484375, 'loss_3': -16.128429412841797, 'loss_4': -0.34167560935020447, 'epoch': 22.85}
{'loss': 0.0113, 'grad_norm': 6.485386848449707, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.007747828494757414, 'loss_2': 0.003574371337890625, 'loss_3': -16.267269134521484, 'loss_4': -0.12152452766895294, 'epoch': 22.86}
{'loss': 0.0144, 'grad_norm': 5.330657482147217, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.008998390287160873, 'loss_2': 0.005405426025390625, 'loss_3': -16.318986892700195, 'loss_4': -0.26244640350341797, 'epoch': 22.87}
{'loss': 0.0147, 'grad_norm': 5.5911126136779785, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.012835497967898846, 'loss_2': 0.0018863677978515625, 'loss_3': -16.285091400146484, 'loss_4': -0.19162552058696747, 'epoch': 22.87}
{'loss': 0.0133, 'grad_norm': 5.358651161193848, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.008113887161016464, 'loss_2': 0.0052032470703125, 'loss_3': -16.024887084960938, 'loss_4': -0.24632646143436432, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 16:55:36,970 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:36,970 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:36:49<21:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:44,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01999841444194317, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016950054094195366, 'eval_loss_2': 0.0030483603477478027, 'eval_loss_3': -18.144874572753906, 'eval_loss_4': -0.17947161197662354, 'epoch': 22.88}
{'loss': 0.0106, 'grad_norm': 5.424106121063232, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.00733540765941143, 'loss_2': 0.0032520294189453125, 'loss_3': -16.347599029541016, 'loss_4': -0.4654347002506256, 'epoch': 22.88}
{'loss': 0.0069, 'grad_norm': 4.286013603210449, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.0066893817856907845, 'loss_2': 0.0002453327178955078, 'loss_3': -16.265003204345703, 'loss_4': -0.29191911220550537, 'epoch': 22.89}
{'loss': 0.0061, 'grad_norm': 5.254406452178955, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.005917723290622234, 'loss_2': 0.00016760826110839844, 'loss_3': -16.223388671875, 'loss_4': -0.3120812773704529, 'epoch': 22.9}
{'loss': 0.0196, 'grad_norm': 6.68513298034668, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.015307539142668247, 'loss_2': 0.004322052001953125, 'loss_3': -16.209314346313477, 'loss_4': -0.526042103767395, 'epoch': 22.9}
{'loss': 0.0062, 'grad_norm': 5.162927150726318, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.00502827949821949, 'loss_2': 0.0011434555053710938, 'loss_3': -16.33462142944336, 'loss_4': -0.3558959364891052, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 16:55:44,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:44,305 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:36:57<20:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:51,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021139532327651978, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.602, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.016912193968892097, 'eval_loss_2': 0.004227340221405029, 'eval_loss_3': -18.13414764404297, 'eval_loss_4': -0.2828720808029175, 'epoch': 22.91}
{'loss': 0.0159, 'grad_norm': 4.67738151550293, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.005415668711066246, 'loss_2': 0.010498046875, 'loss_3': -16.094745635986328, 'loss_4': -0.2909064292907715, 'epoch': 22.91}
{'loss': 0.0085, 'grad_norm': 5.321426868438721, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.006074223667383194, 'loss_2': 0.002384185791015625, 'loss_3': -16.245126724243164, 'loss_4': -0.35764920711517334, 'epoch': 22.92}
{'loss': 0.0094, 'grad_norm': 4.799050331115723, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.005944239906966686, 'loss_2': 0.003421783447265625, 'loss_3': -16.289167404174805, 'loss_4': -0.4216007888317108, 'epoch': 22.92}
{'loss': 0.0401, 'grad_norm': 19.182292938232422, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.03859690576791763, 'loss_2': 0.0014944076538085938, 'loss_3': -16.321063995361328, 'loss_4': -0.23776674270629883, 'epoch': 22.93}
{'loss': 0.0086, 'grad_norm': 5.284473896026611, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.007070537190884352, 'loss_2': 0.0014934539794921875, 'loss_3': -16.300947189331055, 'loss_4': -0.4082872271537781, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 16:55:51,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:51,626 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:04<20:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:58,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020913105458021164, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.593, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01662377640604973, 'eval_loss_2': 0.0042893290519714355, 'eval_loss_3': -18.124008178710938, 'eval_loss_4': -0.31444185972213745, 'epoch': 22.94}
{'loss': 0.0152, 'grad_norm': 5.592803001403809, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.00916050560772419, 'loss_2': 0.006011962890625, 'loss_3': -16.256925582885742, 'loss_4': 0.1807389259338379, 'epoch': 22.94}
{'loss': 0.007, 'grad_norm': 4.7237091064453125, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.0064243134111166, 'loss_2': 0.0005664825439453125, 'loss_3': -16.380460739135742, 'loss_4': -0.44642436504364014, 'epoch': 22.95}
{'loss': 0.0077, 'grad_norm': 4.648143291473389, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.006269238889217377, 'loss_2': 0.001468658447265625, 'loss_3': -16.2581787109375, 'loss_4': -0.35821524262428284, 'epoch': 22.95}
{'loss': 0.0094, 'grad_norm': 5.311034679412842, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.008232885040342808, 'loss_2': 0.0011196136474609375, 'loss_3': -16.233552932739258, 'loss_4': -0.5549265146255493, 'epoch': 22.96}
{'loss': 0.0078, 'grad_norm': 4.614112377166748, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.003459068015217781, 'loss_2': 0.0043182373046875, 'loss_3': -16.270437240600586, 'loss_4': -0.4165189266204834, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 16:55:58,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:58,949 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:11<20:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:56:06,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02091689594089985, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.354, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.017152654007077217, 'eval_loss_2': 0.003764241933822632, 'eval_loss_3': -18.12476348876953, 'eval_loss_4': -0.34334129095077515, 'epoch': 22.97}
{'loss': 0.0172, 'grad_norm': 5.804936408996582, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.009892585687339306, 'loss_2': 0.0073394775390625, 'loss_3': -16.33929443359375, 'loss_4': -0.2657836079597473, 'epoch': 22.97}
{'loss': 0.0091, 'grad_norm': 6.791071891784668, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.00843349564820528, 'loss_2': 0.0006365776062011719, 'loss_3': -16.391586303710938, 'loss_4': -0.6528268456459045, 'epoch': 22.98}
{'loss': 0.0132, 'grad_norm': 5.773714542388916, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.008072581142187119, 'loss_2': 0.005100250244140625, 'loss_3': -16.215164184570312, 'loss_4': -0.2199491709470749, 'epoch': 22.98}
{'loss': 0.0067, 'grad_norm': 5.8557353019714355, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.006452491972595453, 'loss_2': 0.00025153160095214844, 'loss_3': -16.242578506469727, 'loss_4': -0.4094619154930115, 'epoch': 22.99}
{'loss': 0.0081, 'grad_norm': 4.6725873947143555, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.004451636224985123, 'loss_2': 0.00360870361328125, 'loss_3': -16.07709503173828, 'loss_4': -0.5010395050048828, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 16:56:06,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:06,264 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:18<20:18,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:56:13,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022042173892259598, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01742592826485634, 'eval_loss_2': 0.004616245627403259, 'eval_loss_3': -18.120071411132812, 'eval_loss_4': -0.3639223575592041, 'epoch': 22.99}
{'loss': 0.0142, 'grad_norm': 6.783222198486328, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.004042629152536392, 'loss_2': 0.0101165771484375, 'loss_3': -16.04216957092285, 'loss_4': 0.015150533057749271, 'epoch': 23.0}
{'loss': 0.0096, 'grad_norm': 4.61246395111084, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.005120967980474234, 'loss_2': 0.00445556640625, 'loss_3': -16.568254470825195, 'loss_4': -0.38271796703338623, 'epoch': 23.01}
{'loss': 0.0181, 'grad_norm': 6.904066562652588, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.015497538261115551, 'loss_2': 0.00261688232421875, 'loss_3': -16.241003036499023, 'loss_4': -0.20829224586486816, 'epoch': 23.01}
{'loss': 0.0069, 'grad_norm': 4.4336371421813965, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.003600828815251589, 'loss_2': 0.003284454345703125, 'loss_3': -16.280630111694336, 'loss_4': -0.12930479645729065, 'epoch': 23.02}
{'loss': 0.0188, 'grad_norm': 7.789538383483887, 'learning_rate': 7e-06, 'loss_1': 0.012574765831232071, 'loss_2': 0.00618743896484375, 'loss_3': -16.180465698242188, 'loss_4': -0.004581235349178314, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 16:56:13,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:13,304 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:26<20:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:56:20,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02186962589621544, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.238, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016988413408398628, 'eval_loss_2': 0.004881210625171661, 'eval_loss_3': -18.11966323852539, 'eval_loss_4': -0.3523804843425751, 'epoch': 23.02}
{'loss': 0.0316, 'grad_norm': 5.73115348815918, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.02012181468307972, 'loss_2': 0.0114593505859375, 'loss_3': -16.130704879760742, 'loss_4': -0.4189039468765259, 'epoch': 23.03}
{'loss': 0.0263, 'grad_norm': 10.790824890136719, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.02179780974984169, 'loss_2': 0.00447845458984375, 'loss_3': -16.41472816467285, 'loss_4': -0.33846038579940796, 'epoch': 23.03}
{'loss': 0.007, 'grad_norm': 5.014213562011719, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.005242711398750544, 'loss_2': 0.0017557144165039062, 'loss_3': -16.34496307373047, 'loss_4': -0.32629382610321045, 'epoch': 23.04}
{'loss': 0.0067, 'grad_norm': 4.297348976135254, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.005186142399907112, 'loss_2': 0.0015392303466796875, 'loss_3': -16.18091583251953, 'loss_4': -0.46936842799186707, 'epoch': 23.05}
{'loss': 0.0046, 'grad_norm': 4.557635307312012, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.004028819501399994, 'loss_2': 0.0005736351013183594, 'loss_3': -16.27526092529297, 'loss_4': -0.48494580388069153, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 16:56:20,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:20,628 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:33<20:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:56:27,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02164151892066002, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.435, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01704169251024723, 'eval_loss_2': 0.004599828273057938, 'eval_loss_3': -18.123462677001953, 'eval_loss_4': -0.31267064809799194, 'epoch': 23.05}
{'loss': 0.0084, 'grad_norm': 4.560340881347656, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.0051900362595915794, 'loss_2': 0.0032444000244140625, 'loss_3': -16.140527725219727, 'loss_4': -0.7719689011573792, 'epoch': 23.06}
{'loss': 0.0102, 'grad_norm': 4.659670829772949, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.005535623989999294, 'loss_2': 0.00467681884765625, 'loss_3': -16.269393920898438, 'loss_4': -0.6164377331733704, 'epoch': 23.06}
{'loss': 0.0147, 'grad_norm': 6.359307765960693, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.009977688081562519, 'loss_2': 0.00470733642578125, 'loss_3': -16.17964744567871, 'loss_4': -0.5695531368255615, 'epoch': 23.07}
{'loss': 0.0113, 'grad_norm': 4.527930736541748, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.007182352244853973, 'loss_2': 0.00408935546875, 'loss_3': -16.087566375732422, 'loss_4': -0.07311715185642242, 'epoch': 23.08}
{'loss': 0.0074, 'grad_norm': 5.177846908569336, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.007007650099694729, 'loss_2': 0.00037789344787597656, 'loss_3': -16.01677894592285, 'loss_4': -0.49714183807373047, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 16:56:27,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:27,954 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:37:40<20:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:56:35,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021222412586212158, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.641, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.017702624201774597, 'eval_loss_2': 0.003519788384437561, 'eval_loss_3': -18.135812759399414, 'eval_loss_4': -0.2603505551815033, 'epoch': 23.08}
{'loss': 0.003, 'grad_norm': 4.46173095703125, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.0027296815533190966, 'loss_2': 0.0003085136413574219, 'loss_3': -16.358177185058594, 'loss_4': -0.3512992858886719, 'epoch': 23.09}
{'loss': 0.0134, 'grad_norm': 5.3292341232299805, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.008865391835570335, 'loss_2': 0.00452423095703125, 'loss_3': -16.33673858642578, 'loss_4': -0.22777751088142395, 'epoch': 23.09}
{'loss': 0.0127, 'grad_norm': 6.0842108726501465, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.012155884876847267, 'loss_2': 0.0005359649658203125, 'loss_3': -16.066635131835938, 'loss_4': -0.4302136301994324, 'epoch': 23.1}
{'loss': 0.0117, 'grad_norm': 4.697371006011963, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.005664575845003128, 'loss_2': 0.0059967041015625, 'loss_3': -16.30997657775879, 'loss_4': -0.1622658371925354, 'epoch': 23.1}
{'loss': 0.0095, 'grad_norm': 4.810727596282959, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.009403089061379433, 'loss_2': 0.00012421607971191406, 'loss_3': -16.09908676147461, 'loss_4': -0.46441560983657837, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 16:56:35,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:35,276 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:37:48<20:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:56:42,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022067684680223465, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.699, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.0178163293749094, 'eval_loss_2': 0.004251353442668915, 'eval_loss_3': -18.130495071411133, 'eval_loss_4': -0.17716732621192932, 'epoch': 23.11}
{'loss': 0.0125, 'grad_norm': 4.219846725463867, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.006689243949949741, 'loss_2': 0.005832672119140625, 'loss_3': -16.27374839782715, 'loss_4': -0.3374292254447937, 'epoch': 23.12}
{'loss': 0.0151, 'grad_norm': 5.422064304351807, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.00610117893666029, 'loss_2': 0.0090179443359375, 'loss_3': -16.267240524291992, 'loss_4': -0.27742332220077515, 'epoch': 23.12}
{'loss': 0.0084, 'grad_norm': 4.774456024169922, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.0069463723339140415, 'loss_2': 0.0014896392822265625, 'loss_3': -16.40523910522461, 'loss_4': -0.3627402186393738, 'epoch': 23.13}
{'loss': 0.0119, 'grad_norm': 5.618587493896484, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.00836348906159401, 'loss_2': 0.0035552978515625, 'loss_3': -16.187480926513672, 'loss_4': -0.45676562190055847, 'epoch': 23.13}
{'loss': 0.0767, 'grad_norm': 15.41008186340332, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.0758104994893074, 'loss_2': 0.0009241104125976562, 'loss_3': -16.109867095947266, 'loss_4': 0.0029697567224502563, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 16:56:42,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:42,590 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:37:55<20:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:49,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020809713751077652, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01714194007217884, 'eval_loss_2': 0.003667771816253662, 'eval_loss_3': -18.14518928527832, 'eval_loss_4': -0.16875319182872772, 'epoch': 23.14}
{'loss': 0.0079, 'grad_norm': 5.52323579788208, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.007756525184959173, 'loss_2': 0.00012612342834472656, 'loss_3': -16.20736312866211, 'loss_4': 0.17883352935314178, 'epoch': 23.15}
{'loss': 0.0071, 'grad_norm': 5.606202602386475, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.006676649674773216, 'loss_2': 0.0004601478576660156, 'loss_3': -16.246891021728516, 'loss_4': -0.16258537769317627, 'epoch': 23.15}
{'loss': 0.0066, 'grad_norm': 5.126567363739014, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.00647629052400589, 'loss_2': 9.572505950927734e-05, 'loss_3': -16.20432472229004, 'loss_4': 0.054607026278972626, 'epoch': 23.16}
{'loss': 0.0065, 'grad_norm': 4.592006683349609, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.004911897238343954, 'loss_2': 0.0015964508056640625, 'loss_3': -16.426023483276367, 'loss_4': -0.18843159079551697, 'epoch': 23.16}
{'loss': 0.0116, 'grad_norm': 5.094621181488037, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.011071417480707169, 'loss_2': 0.0005459785461425781, 'loss_3': -16.1849365234375, 'loss_4': -0.3839804530143738, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 16:56:49,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:49,916 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:02<20:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:57,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020576918497681618, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.952, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016873802989721298, 'eval_loss_2': 0.0037031173706054688, 'eval_loss_3': -18.137296676635742, 'eval_loss_4': -0.10923008620738983, 'epoch': 23.17}
{'loss': 0.0151, 'grad_norm': 6.843669891357422, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.01081414520740509, 'loss_2': 0.004268646240234375, 'loss_3': -16.188983917236328, 'loss_4': -0.400713711977005, 'epoch': 23.17}
{'loss': 0.0151, 'grad_norm': 5.141785621643066, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.010411564260721207, 'loss_2': 0.00469970703125, 'loss_3': -16.153833389282227, 'loss_4': -0.2817777991294861, 'epoch': 23.18}
{'loss': 0.013, 'grad_norm': 4.878870487213135, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.004532463848590851, 'loss_2': 0.008453369140625, 'loss_3': -16.340177536010742, 'loss_4': 0.0021803900599479675, 'epoch': 23.19}
{'loss': 0.0166, 'grad_norm': 4.875868320465088, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.0076078809797763824, 'loss_2': 0.0089569091796875, 'loss_3': -16.13894271850586, 'loss_4': -0.463573694229126, 'epoch': 23.19}
{'loss': 0.0139, 'grad_norm': 6.511839866638184, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.009217984974384308, 'loss_2': 0.004657745361328125, 'loss_3': -16.441852569580078, 'loss_4': 0.36820268630981445, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 16:56:57,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:57,243 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:09<20:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:04,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022126514464616776, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.425, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017878135666251183, 'eval_loss_2': 0.004248380661010742, 'eval_loss_3': -18.13414764404297, 'eval_loss_4': -0.04973266273736954, 'epoch': 23.2}
{'loss': 0.0117, 'grad_norm': 4.318639755249023, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.006223292555660009, 'loss_2': 0.005458831787109375, 'loss_3': -16.103544235229492, 'loss_4': -0.284845769405365, 'epoch': 23.2}
{'loss': 0.0058, 'grad_norm': 4.4217658042907715, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.0036272439174354076, 'loss_2': 0.0022220611572265625, 'loss_3': -16.293825149536133, 'loss_4': -0.23532383143901825, 'epoch': 23.21}
{'loss': 0.0098, 'grad_norm': 5.712687969207764, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.0075780488550662994, 'loss_2': 0.002269744873046875, 'loss_3': -16.405426025390625, 'loss_4': 0.4829466938972473, 'epoch': 23.22}
{'loss': 0.0112, 'grad_norm': 4.919485092163086, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.008331015706062317, 'loss_2': 0.002872467041015625, 'loss_3': -16.081785202026367, 'loss_4': -0.28919222950935364, 'epoch': 23.22}
{'loss': 0.0132, 'grad_norm': 6.47177791595459, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.0068079400807619095, 'loss_2': 0.00634765625, 'loss_3': -16.115848541259766, 'loss_4': 0.07691238820552826, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 16:57:04,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:04,577 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:17<20:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:11,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02123461849987507, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01777065172791481, 'eval_loss_2': 0.0034639686346054077, 'eval_loss_3': -18.124053955078125, 'eval_loss_4': -0.061926864087581635, 'epoch': 23.23}
{'loss': 0.0071, 'grad_norm': 4.53907585144043, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.006166656501591206, 'loss_2': 0.0009183883666992188, 'loss_3': -16.207565307617188, 'loss_4': -0.007944926619529724, 'epoch': 23.23}
{'loss': 0.0119, 'grad_norm': 4.797554016113281, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.004959566984325647, 'loss_2': 0.00693511962890625, 'loss_3': -16.32297134399414, 'loss_4': -0.10370688140392303, 'epoch': 23.24}
{'loss': 0.0094, 'grad_norm': 5.153547763824463, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.007253117393702269, 'loss_2': 0.00218963623046875, 'loss_3': -16.036272048950195, 'loss_4': -0.17726309597492218, 'epoch': 23.24}
{'loss': 0.0084, 'grad_norm': 5.114993095397949, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.007587418891489506, 'loss_2': 0.0008373260498046875, 'loss_3': -16.401657104492188, 'loss_4': -0.29927802085876465, 'epoch': 23.25}
{'loss': 0.0243, 'grad_norm': 7.4964470863342285, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.01212757732719183, 'loss_2': 0.01216888427734375, 'loss_3': -16.26140022277832, 'loss_4': -0.009342052042484283, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 16:57:11,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:11,915 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:24<19:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:19,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021728450432419777, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.488, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.018206285312771797, 'eval_loss_2': 0.0035221651196479797, 'eval_loss_3': -18.107017517089844, 'eval_loss_4': -0.11118346452713013, 'epoch': 23.26}
{'loss': 0.0099, 'grad_norm': 4.946874141693115, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.007313156966120005, 'loss_2': 0.00261688232421875, 'loss_3': -16.153400421142578, 'loss_4': -0.715385377407074, 'epoch': 23.26}
{'loss': 0.0122, 'grad_norm': 6.854698657989502, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.008695636875927448, 'loss_2': 0.0034637451171875, 'loss_3': -16.14781951904297, 'loss_4': -0.0718526542186737, 'epoch': 23.27}
{'loss': 0.0165, 'grad_norm': 6.154562950134277, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.011533220298588276, 'loss_2': 0.00499725341796875, 'loss_3': -16.224042892456055, 'loss_4': -0.20899948477745056, 'epoch': 23.27}
{'loss': 0.0112, 'grad_norm': 5.855137825012207, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.007894045673310757, 'loss_2': 0.003292083740234375, 'loss_3': -16.157304763793945, 'loss_4': -0.15342165529727936, 'epoch': 23.28}
{'loss': 0.0314, 'grad_norm': 9.014613151550293, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.022816302254796028, 'loss_2': 0.00862884521484375, 'loss_3': -16.278518676757812, 'loss_4': -0.5241217613220215, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 16:57:19,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:19,244 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:31<19:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:26,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022120434790849686, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.714, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.01878621056675911, 'eval_loss_2': 0.003334224224090576, 'eval_loss_3': -18.100265502929688, 'eval_loss_4': -0.1684066653251648, 'epoch': 23.28}
{'loss': 0.0063, 'grad_norm': 5.19926643371582, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.005760957486927509, 'loss_2': 0.0005507469177246094, 'loss_3': -16.18475914001465, 'loss_4': 0.14634476602077484, 'epoch': 23.29}
{'loss': 0.0196, 'grad_norm': 6.605429649353027, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.01522497646510601, 'loss_2': 0.00437164306640625, 'loss_3': -16.041095733642578, 'loss_4': -0.2672032117843628, 'epoch': 23.3}
{'loss': 0.0144, 'grad_norm': 4.291610240936279, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0051990835927426815, 'loss_2': 0.009185791015625, 'loss_3': -16.076908111572266, 'loss_4': -0.18558070063591003, 'epoch': 23.3}
{'loss': 0.0097, 'grad_norm': 4.841879844665527, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.0055822585709393024, 'loss_2': 0.004085540771484375, 'loss_3': -16.167510986328125, 'loss_4': -0.5081667900085449, 'epoch': 23.31}
{'loss': 0.0143, 'grad_norm': 7.140552520751953, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.010408314876258373, 'loss_2': 0.00390625, 'loss_3': -16.15835952758789, 'loss_4': -0.32457876205444336, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 16:57:26,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:26,565 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:39<19:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:57:33,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02162165567278862, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.23, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018963271751999855, 'eval_loss_2': 0.0026583820581436157, 'eval_loss_3': -18.08550262451172, 'eval_loss_4': -0.254741907119751, 'epoch': 23.31}
{'loss': 0.0079, 'grad_norm': 4.630688667297363, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.006427485030144453, 'loss_2': 0.001445770263671875, 'loss_3': -16.146480560302734, 'loss_4': -0.33121708035469055, 'epoch': 23.32}
{'loss': 0.0082, 'grad_norm': 4.388666152954102, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.006587179843336344, 'loss_2': 0.0016050338745117188, 'loss_3': -16.440467834472656, 'loss_4': -0.1367037296295166, 'epoch': 23.33}
{'loss': 0.0114, 'grad_norm': 6.236305236816406, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.009243909269571304, 'loss_2': 0.002147674560546875, 'loss_3': -16.278308868408203, 'loss_4': -0.32021865248680115, 'epoch': 23.33}
{'loss': 0.0097, 'grad_norm': 4.909716606140137, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.009271601215004921, 'loss_2': 0.0004591941833496094, 'loss_3': -16.38526153564453, 'loss_4': -0.18880343437194824, 'epoch': 23.34}
{'loss': 0.0179, 'grad_norm': 5.919700622558594, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.007840661332011223, 'loss_2': 0.01007843017578125, 'loss_3': -16.09872055053711, 'loss_4': -0.5581185817718506, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 16:57:33,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:33,886 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:38:46<19:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:41,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021625300869345665, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.574, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.018618043512105942, 'eval_loss_2': 0.003007255494594574, 'eval_loss_3': -18.0941104888916, 'eval_loss_4': -0.24518321454524994, 'epoch': 23.34}
{'loss': 0.0098, 'grad_norm': 4.806971549987793, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.003515866119414568, 'loss_2': 0.006267547607421875, 'loss_3': -16.310102462768555, 'loss_4': -0.2903370261192322, 'epoch': 23.35}
{'loss': 0.0157, 'grad_norm': 4.600892066955566, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.004541861824691296, 'loss_2': 0.01111602783203125, 'loss_3': -16.430877685546875, 'loss_4': -0.34326237440109253, 'epoch': 23.35}
{'loss': 0.0265, 'grad_norm': 5.950170040130615, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.019261658191680908, 'loss_2': 0.00720977783203125, 'loss_3': -16.402584075927734, 'loss_4': -0.43027830123901367, 'epoch': 23.36}
{'loss': 0.0071, 'grad_norm': 4.517567157745361, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.0063151465728878975, 'loss_2': 0.0007996559143066406, 'loss_3': -16.18058967590332, 'loss_4': -0.2770105004310608, 'epoch': 23.37}
{'loss': 0.0059, 'grad_norm': 4.449852466583252, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.005682898219674826, 'loss_2': 0.0001690387725830078, 'loss_3': -16.428165435791016, 'loss_4': -0.3473336398601532, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 16:57:41,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:41,213 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:38:53<19:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:57:48,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0217537060379982, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.484, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.018130861222743988, 'eval_loss_2': 0.0036228448152542114, 'eval_loss_3': -18.095232009887695, 'eval_loss_4': -0.19533436000347137, 'epoch': 23.37}
{'loss': 0.0075, 'grad_norm': 5.004173278808594, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.006054516416043043, 'loss_2': 0.0014829635620117188, 'loss_3': -16.29458236694336, 'loss_4': -0.3425058126449585, 'epoch': 23.38}
{'loss': 0.0086, 'grad_norm': 5.068350315093994, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.0069143748842179775, 'loss_2': 0.001708984375, 'loss_3': -16.22175407409668, 'loss_4': -0.06387101113796234, 'epoch': 23.38}
{'loss': 0.0091, 'grad_norm': 4.738576889038086, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.005103152710944414, 'loss_2': 0.00395965576171875, 'loss_3': -16.16826629638672, 'loss_4': -0.13369886577129364, 'epoch': 23.39}
{'loss': 0.0059, 'grad_norm': 4.941922187805176, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.004790795501321554, 'loss_2': 0.00115203857421875, 'loss_3': -16.06987953186035, 'loss_4': -0.7908015251159668, 'epoch': 23.4}
{'loss': 0.0093, 'grad_norm': 4.483922958374023, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.004331529140472412, 'loss_2': 0.00498199462890625, 'loss_3': -16.05617332458496, 'loss_4': -0.0195297971367836, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 16:57:48,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:48,532 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:01<19:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:55,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0235244482755661, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.565, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.018025772646069527, 'eval_loss_2': 0.005498677492141724, 'eval_loss_3': -18.089527130126953, 'eval_loss_4': -0.17741245031356812, 'epoch': 23.4}
{'loss': 0.0153, 'grad_norm': 5.1723856925964355, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.007225664332509041, 'loss_2': 0.008056640625, 'loss_3': -16.12613868713379, 'loss_4': -0.08139657974243164, 'epoch': 23.41}
{'loss': 0.0113, 'grad_norm': 4.871889114379883, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.007520269136875868, 'loss_2': 0.003742218017578125, 'loss_3': -16.238040924072266, 'loss_4': -0.10780373215675354, 'epoch': 23.41}
{'loss': 0.0094, 'grad_norm': 5.8659772872924805, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.007141194771975279, 'loss_2': 0.002307891845703125, 'loss_3': -16.02899932861328, 'loss_4': -0.43241673707962036, 'epoch': 23.42}
{'loss': 0.022, 'grad_norm': 4.391177654266357, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.007532957009971142, 'loss_2': 0.01445770263671875, 'loss_3': -16.29541778564453, 'loss_4': 0.035636067390441895, 'epoch': 23.42}
{'loss': 0.0117, 'grad_norm': 5.029045581817627, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.005942915566265583, 'loss_2': 0.0057830810546875, 'loss_3': -15.99612808227539, 'loss_4': -0.2413492351770401, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 16:57:55,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:55,855 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:08<19:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:58:03,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02409563586115837, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.496, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01792140118777752, 'eval_loss_2': 0.006174236536026001, 'eval_loss_3': -18.09275245666504, 'eval_loss_4': -0.23008078336715698, 'epoch': 23.43}
{'loss': 0.0215, 'grad_norm': 7.985282897949219, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.013040108606219292, 'loss_2': 0.00846099853515625, 'loss_3': -16.345897674560547, 'loss_4': -0.1806860864162445, 'epoch': 23.44}
{'loss': 0.0139, 'grad_norm': 4.98584508895874, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.00524225365370512, 'loss_2': 0.0086517333984375, 'loss_3': -16.25914192199707, 'loss_4': -0.5649430751800537, 'epoch': 23.44}
{'loss': 0.0074, 'grad_norm': 4.671894073486328, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.00419576233252883, 'loss_2': 0.003246307373046875, 'loss_3': -16.283288955688477, 'loss_4': -0.3615930676460266, 'epoch': 23.45}
{'loss': 0.0095, 'grad_norm': 4.989226818084717, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.005820185411721468, 'loss_2': 0.00371551513671875, 'loss_3': -16.213167190551758, 'loss_4': 0.5003281831741333, 'epoch': 23.45}
{'loss': 0.0134, 'grad_norm': 4.714393615722656, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.004365767352283001, 'loss_2': 0.0090179443359375, 'loss_3': -16.201391220092773, 'loss_4': -0.3710940182209015, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 16:58:03,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:03,173 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:15<19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:10,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021556466817855835, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.204, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016932087019085884, 'eval_loss_2': 0.0046243816614151, 'eval_loss_3': -18.080629348754883, 'eval_loss_4': -0.29299819469451904, 'epoch': 23.46}
{'loss': 0.0133, 'grad_norm': 4.6697773933410645, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.005030838306993246, 'loss_2': 0.00823211669921875, 'loss_3': -16.333715438842773, 'loss_4': -0.22547706961631775, 'epoch': 23.47}
{'loss': 0.0855, 'grad_norm': 11.373641967773438, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.07872284203767776, 'loss_2': 0.0067291259765625, 'loss_3': -16.278873443603516, 'loss_4': -0.17517226934432983, 'epoch': 23.47}
{'loss': 0.011, 'grad_norm': 5.119328022003174, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.007062280550599098, 'loss_2': 0.0038890838623046875, 'loss_3': -16.140975952148438, 'loss_4': -0.19690154492855072, 'epoch': 23.48}
{'loss': 0.0155, 'grad_norm': 7.348784446716309, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.014810927212238312, 'loss_2': 0.0006961822509765625, 'loss_3': -16.35565948486328, 'loss_4': -0.35318344831466675, 'epoch': 23.48}
{'loss': 0.0098, 'grad_norm': 6.050000190734863, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.008818223141133785, 'loss_2': 0.0009937286376953125, 'loss_3': -16.03104591369629, 'loss_4': -0.34460771083831787, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 16:58:10,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:10,500 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:23<19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:17,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020457599312067032, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.268, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.017175648361444473, 'eval_loss_2': 0.003281954675912857, 'eval_loss_3': -18.079914093017578, 'eval_loss_4': -0.3568035960197449, 'epoch': 23.49}
{'loss': 0.0092, 'grad_norm': 4.817416667938232, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.006861947942525148, 'loss_2': 0.0023174285888671875, 'loss_3': -16.263916015625, 'loss_4': -0.2883361876010895, 'epoch': 23.49}
{'loss': 0.0112, 'grad_norm': 5.431417942047119, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.0074605681002140045, 'loss_2': 0.0037021636962890625, 'loss_3': -16.021926879882812, 'loss_4': -0.25386327505111694, 'epoch': 23.5}
{'loss': 0.0098, 'grad_norm': 5.574286460876465, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.009138430468738079, 'loss_2': 0.0006990432739257812, 'loss_3': -16.194522857666016, 'loss_4': -0.438978374004364, 'epoch': 23.51}
{'loss': 0.0088, 'grad_norm': 5.506434917449951, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.0074326638132333755, 'loss_2': 0.00138092041015625, 'loss_3': -16.189687728881836, 'loss_4': -0.4643721580505371, 'epoch': 23.51}
{'loss': 0.0192, 'grad_norm': 7.37797737121582, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.015447481535375118, 'loss_2': 0.0037994384765625, 'loss_3': -16.36855697631836, 'loss_4': -0.5246897339820862, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 16:58:17,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:17,826 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:30<19:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:25,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02188080921769142, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.399, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017201969400048256, 'eval_loss_2': 0.004678837954998016, 'eval_loss_3': -18.074344635009766, 'eval_loss_4': -0.3775590658187866, 'epoch': 23.52}
{'loss': 0.011, 'grad_norm': 4.585330963134766, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.004594050347805023, 'loss_2': 0.006439208984375, 'loss_3': -16.201210021972656, 'loss_4': -0.3007085919380188, 'epoch': 23.52}
{'loss': 0.0114, 'grad_norm': 4.383721828460693, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.004354832228273153, 'loss_2': 0.00699615478515625, 'loss_3': -16.272289276123047, 'loss_4': -0.6004995703697205, 'epoch': 23.53}
{'loss': 0.0089, 'grad_norm': 4.401098251342773, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.004633914213627577, 'loss_2': 0.00426483154296875, 'loss_3': -16.40129852294922, 'loss_4': -0.6326619386672974, 'epoch': 23.53}
{'loss': 0.0212, 'grad_norm': 8.530719757080078, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.011600050143897533, 'loss_2': 0.00963592529296875, 'loss_3': -16.24108123779297, 'loss_4': -0.1431102603673935, 'epoch': 23.54}
{'loss': 0.0181, 'grad_norm': 7.611919403076172, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.009932946413755417, 'loss_2': 0.0081939697265625, 'loss_3': -16.12063980102539, 'loss_4': -0.2955777943134308, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 16:58:25,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:25,155 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:37<19:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:32,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022575344890356064, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.223, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018092263489961624, 'eval_loss_2': 0.00448308140039444, 'eval_loss_3': -18.072383880615234, 'eval_loss_4': -0.34613946080207825, 'epoch': 23.55}
{'loss': 0.015, 'grad_norm': 6.2462053298950195, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.01101475115865469, 'loss_2': 0.004001617431640625, 'loss_3': -16.274383544921875, 'loss_4': -0.5493628978729248, 'epoch': 23.55}
{'loss': 0.0169, 'grad_norm': 6.18727445602417, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.009636587463319302, 'loss_2': 0.0072174072265625, 'loss_3': -16.196090698242188, 'loss_4': 0.010821506381034851, 'epoch': 23.56}
{'loss': 0.0078, 'grad_norm': 4.533864974975586, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.0038405514787882566, 'loss_2': 0.00394439697265625, 'loss_3': -16.302165985107422, 'loss_4': 0.02136184647679329, 'epoch': 23.56}
{'loss': 0.0063, 'grad_norm': 4.64229154586792, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.0038323192857205868, 'loss_2': 0.002452850341796875, 'loss_3': -16.117454528808594, 'loss_4': -0.2557656466960907, 'epoch': 23.57}
{'loss': 0.0095, 'grad_norm': 4.426700115203857, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.007371058221906424, 'loss_2': 0.0021038055419921875, 'loss_3': -16.226924896240234, 'loss_4': -0.15108181536197662, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 16:58:32,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:32,488 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:39:45<19:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:39,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02103843353688717, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.151, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.017766710370779037, 'eval_loss_2': 0.003271721303462982, 'eval_loss_3': -18.052534103393555, 'eval_loss_4': -0.3102613091468811, 'epoch': 23.58}
{'loss': 0.0083, 'grad_norm': 4.811923980712891, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.004908921662718058, 'loss_2': 0.00342559814453125, 'loss_3': -16.04010009765625, 'loss_4': -0.6093250513076782, 'epoch': 23.58}
{'loss': 0.0097, 'grad_norm': 5.532059669494629, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.007862353697419167, 'loss_2': 0.0018367767333984375, 'loss_3': -16.281023025512695, 'loss_4': -0.46054762601852417, 'epoch': 23.59}
{'loss': 0.0102, 'grad_norm': 4.969286918640137, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.008253959938883781, 'loss_2': 0.0019817352294921875, 'loss_3': -16.13532257080078, 'loss_4': -0.12286379933357239, 'epoch': 23.59}
{'loss': 0.0113, 'grad_norm': 11.517068862915039, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.01101318746805191, 'loss_2': 0.0002753734588623047, 'loss_3': -16.067737579345703, 'loss_4': -0.3998982310295105, 'epoch': 23.6}
{'loss': 0.0125, 'grad_norm': 4.587387561798096, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.005500055383890867, 'loss_2': 0.0070343017578125, 'loss_3': -16.18383026123047, 'loss_4': -0.5125386714935303, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 16:58:39,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:39,820 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:39:52<18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:47,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021813511848449707, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018371259793639183, 'eval_loss_2': 0.0034422501921653748, 'eval_loss_3': -18.04628562927246, 'eval_loss_4': -0.3065051734447479, 'epoch': 23.6}
{'loss': 0.0147, 'grad_norm': 8.952315330505371, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.012230060994625092, 'loss_2': 0.00251007080078125, 'loss_3': -16.196622848510742, 'loss_4': -0.3325659930706024, 'epoch': 23.61}
{'loss': 0.0342, 'grad_norm': 8.073375701904297, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.02206597849726677, 'loss_2': 0.0121307373046875, 'loss_3': -16.154394149780273, 'loss_4': -0.5276486873626709, 'epoch': 23.62}
{'loss': 0.0142, 'grad_norm': 4.8972859382629395, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.007500846870243549, 'loss_2': 0.0066680908203125, 'loss_3': -15.99056625366211, 'loss_4': 0.3125295042991638, 'epoch': 23.62}
{'loss': 0.0082, 'grad_norm': 4.958768367767334, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.005051762796938419, 'loss_2': 0.0030994415283203125, 'loss_3': -16.220169067382812, 'loss_4': -0.5063869953155518, 'epoch': 23.63}
{'loss': 0.0096, 'grad_norm': 5.022894382476807, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.007049530744552612, 'loss_2': 0.0025043487548828125, 'loss_3': -16.191452026367188, 'loss_4': -0.06009999290108681, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 16:58:47,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:47,149 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:39:59<18:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:54,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021772896870970726, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.987, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.018320119008421898, 'eval_loss_2': 0.003452777862548828, 'eval_loss_3': -18.0434627532959, 'eval_loss_4': -0.31302401423454285, 'epoch': 23.63}
{'loss': 0.011, 'grad_norm': 5.14877462387085, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.008018583059310913, 'loss_2': 0.00301361083984375, 'loss_3': -16.276111602783203, 'loss_4': -0.6513911485671997, 'epoch': 23.64}
{'loss': 0.0038, 'grad_norm': 4.483333587646484, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.003720400622114539, 'loss_2': 8.189678192138672e-05, 'loss_3': -16.239215850830078, 'loss_4': -0.2406345158815384, 'epoch': 23.65}
{'loss': 0.0202, 'grad_norm': 8.591255187988281, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.01730370707809925, 'loss_2': 0.0028781890869140625, 'loss_3': -16.049142837524414, 'loss_4': -0.41353940963745117, 'epoch': 23.65}
{'loss': 0.0098, 'grad_norm': 4.8789496421813965, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.004925118759274483, 'loss_2': 0.00492095947265625, 'loss_3': -16.29541015625, 'loss_4': -0.2132035493850708, 'epoch': 23.66}
{'loss': 0.0069, 'grad_norm': 4.799826145172119, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.0042446451261639595, 'loss_2': 0.002674102783203125, 'loss_3': -16.171920776367188, 'loss_4': -0.41892945766448975, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 16:58:54,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:54,485 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:07<18:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:01,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02056979387998581, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.52, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.017607366666197777, 'eval_loss_2': 0.0029624290764331818, 'eval_loss_3': -18.04436492919922, 'eval_loss_4': -0.2873082160949707, 'epoch': 23.66}
{'loss': 0.0141, 'grad_norm': 5.1295623779296875, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.00740175973623991, 'loss_2': 0.006748199462890625, 'loss_3': -16.202510833740234, 'loss_4': -0.26433461904525757, 'epoch': 23.67}
{'loss': 0.0126, 'grad_norm': 6.787631988525391, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.010814090259373188, 'loss_2': 0.0017719268798828125, 'loss_3': -15.964800834655762, 'loss_4': 0.0582505539059639, 'epoch': 23.67}
{'loss': 0.0216, 'grad_norm': 9.082226753234863, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.012115015648305416, 'loss_2': 0.009490966796875, 'loss_3': -16.093448638916016, 'loss_4': -0.38054609298706055, 'epoch': 23.68}
{'loss': 0.0082, 'grad_norm': 4.611157417297363, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.005823180545121431, 'loss_2': 0.0023956298828125, 'loss_3': -16.077720642089844, 'loss_4': -0.1987929493188858, 'epoch': 23.69}
{'loss': 0.0098, 'grad_norm': 6.446809768676758, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.00867060013115406, 'loss_2': 0.0011653900146484375, 'loss_3': -16.137420654296875, 'loss_4': -0.3135468661785126, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 16:59:01,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:01,821 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:14<18:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:09,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020963095128536224, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.187, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.017334317788481712, 'eval_loss_2': 0.003628775477409363, 'eval_loss_3': -18.04217529296875, 'eval_loss_4': -0.31897082924842834, 'epoch': 23.69}
{'loss': 0.0077, 'grad_norm': 4.654983043670654, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.004556482192128897, 'loss_2': 0.0031280517578125, 'loss_3': -16.17333984375, 'loss_4': -0.15575802326202393, 'epoch': 23.7}
{'loss': 0.0055, 'grad_norm': 4.411281108856201, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.0040636323392391205, 'loss_2': 0.0014638900756835938, 'loss_3': -16.31792449951172, 'loss_4': -0.3463099002838135, 'epoch': 23.7}
{'loss': 0.0761, 'grad_norm': 11.93281078338623, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.07433436810970306, 'loss_2': 0.0017414093017578125, 'loss_3': -16.197551727294922, 'loss_4': -0.2750563621520996, 'epoch': 23.71}
{'loss': 0.0085, 'grad_norm': 4.548779487609863, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.0050416262820363045, 'loss_2': 0.00345611572265625, 'loss_3': -16.0827693939209, 'loss_4': -0.1402079463005066, 'epoch': 23.72}
{'loss': 0.0131, 'grad_norm': 5.006640434265137, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.006807625759392977, 'loss_2': 0.00627899169921875, 'loss_3': -16.122581481933594, 'loss_4': -0.11372971534729004, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 16:59:09,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:09,159 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:21<18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:16,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02042810618877411, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.189, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01648232713341713, 'eval_loss_2': 0.003945782780647278, 'eval_loss_3': -18.023387908935547, 'eval_loss_4': -0.3932468891143799, 'epoch': 23.72}
{'loss': 0.015, 'grad_norm': 10.954251289367676, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.01421350333839655, 'loss_2': 0.0007534027099609375, 'loss_3': -16.057178497314453, 'loss_4': -0.09002943336963654, 'epoch': 23.73}
{'loss': 0.0084, 'grad_norm': 4.937891006469727, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.0056619043461978436, 'loss_2': 0.0027370452880859375, 'loss_3': -16.047204971313477, 'loss_4': -0.5531018972396851, 'epoch': 23.73}
{'loss': 0.0244, 'grad_norm': 10.95942497253418, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.023692145943641663, 'loss_2': 0.0006780624389648438, 'loss_3': -16.199600219726562, 'loss_4': -0.34470653533935547, 'epoch': 23.74}
{'loss': 0.0204, 'grad_norm': 8.599071502685547, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.01805977337062359, 'loss_2': 0.00232696533203125, 'loss_3': -16.286340713500977, 'loss_4': -0.2537305951118469, 'epoch': 23.74}
{'loss': 0.0062, 'grad_norm': 4.5294294357299805, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.004262364469468594, 'loss_2': 0.00189971923828125, 'loss_3': -15.978675842285156, 'loss_4': -0.5725796222686768, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 16:59:16,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:16,493 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:29<18:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:23,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021254917606711388, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01784919761121273, 'eval_loss_2': 0.0034057199954986572, 'eval_loss_3': -18.004192352294922, 'eval_loss_4': -0.41441062092781067, 'epoch': 23.75}
{'loss': 0.0093, 'grad_norm': 4.158292770385742, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.004150928929448128, 'loss_2': 0.005115509033203125, 'loss_3': -16.25497817993164, 'loss_4': -0.5089961886405945, 'epoch': 23.76}
{'loss': 0.0135, 'grad_norm': 4.8941802978515625, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.007019456475973129, 'loss_2': 0.0064544677734375, 'loss_3': -16.079553604125977, 'loss_4': -0.7016815543174744, 'epoch': 23.76}
{'loss': 0.0091, 'grad_norm': 5.54778528213501, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.006608354859054089, 'loss_2': 0.002498626708984375, 'loss_3': -16.111835479736328, 'loss_4': -0.11975952237844467, 'epoch': 23.77}
{'loss': 0.0067, 'grad_norm': 5.019519805908203, 'learning_rate': 6.25e-06, 'loss_1': 0.004730689339339733, 'loss_2': 0.0019817352294921875, 'loss_3': -16.126811981201172, 'loss_4': -0.3913401961326599, 'epoch': 23.77}
{'loss': 0.0076, 'grad_norm': 4.916330337524414, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.0058520156890153885, 'loss_2': 0.00170135498046875, 'loss_3': -16.369550704956055, 'loss_4': -0.5269765853881836, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 16:59:23,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:23,828 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:36<18:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:31,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02268901653587818, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.055, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01859953999519348, 'eval_loss_2': 0.004089474678039551, 'eval_loss_3': -17.992572784423828, 'eval_loss_4': -0.4236656725406647, 'epoch': 23.78}
{'loss': 0.0163, 'grad_norm': 5.420729160308838, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.00874114315956831, 'loss_2': 0.007564544677734375, 'loss_3': -16.33648109436035, 'loss_4': -0.44605863094329834, 'epoch': 23.78}
{'loss': 0.0092, 'grad_norm': 5.025395393371582, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.0034630484879016876, 'loss_2': 0.0057373046875, 'loss_3': -16.05358123779297, 'loss_4': -0.47933661937713623, 'epoch': 23.79}
{'loss': 0.004, 'grad_norm': 4.311914443969727, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.003969206009060144, 'loss_2': 1.537799835205078e-05, 'loss_3': -16.040082931518555, 'loss_4': -0.6488550901412964, 'epoch': 23.8}
{'loss': 0.013, 'grad_norm': 5.262479305267334, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.008641411550343037, 'loss_2': 0.00433349609375, 'loss_3': -16.101228713989258, 'loss_4': -0.44457218050956726, 'epoch': 23.8}
{'loss': 0.0102, 'grad_norm': 4.7285332679748535, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.005789898801594973, 'loss_2': 0.00437164306640625, 'loss_3': -16.40289878845215, 'loss_4': -0.46348366141319275, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 16:59:31,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:31,160 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:40:43<18:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:38,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024956367909908295, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.187, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019813857972621918, 'eval_loss_2': 0.005142509937286377, 'eval_loss_3': -17.997634887695312, 'eval_loss_4': -0.43653982877731323, 'epoch': 23.81}
{'loss': 0.0086, 'grad_norm': 4.896435260772705, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.006166267674416304, 'loss_2': 0.002468109130859375, 'loss_3': -15.994635581970215, 'loss_4': -0.3844769597053528, 'epoch': 23.81}
{'loss': 0.0118, 'grad_norm': 4.51295280456543, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.0038504689000546932, 'loss_2': 0.007904052734375, 'loss_3': -16.173137664794922, 'loss_4': -0.7427345514297485, 'epoch': 23.82}
{'loss': 0.0093, 'grad_norm': 5.064001083374023, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.0022252104245126247, 'loss_2': 0.00705718994140625, 'loss_3': -16.286684036254883, 'loss_4': -0.3480048179626465, 'epoch': 23.83}
{'loss': 0.0149, 'grad_norm': 11.084967613220215, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.0103923249989748, 'loss_2': 0.00447845458984375, 'loss_3': -16.155845642089844, 'loss_4': -0.7958703637123108, 'epoch': 23.83}
{'loss': 0.0059, 'grad_norm': 4.6090168952941895, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.004626908805221319, 'loss_2': 0.0012788772583007812, 'loss_3': -16.388446807861328, 'loss_4': -0.2200126051902771, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 16:59:38,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:38,488 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:40:51<18:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:45,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025824803858995438, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.817, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021901380270719528, 'eval_loss_2': 0.003923423588275909, 'eval_loss_3': -17.98954200744629, 'eval_loss_4': -0.39591968059539795, 'epoch': 23.84}
{'loss': 0.0063, 'grad_norm': 4.373658180236816, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.004751972854137421, 'loss_2': 0.00157928466796875, 'loss_3': -16.258766174316406, 'loss_4': -0.3060448467731476, 'epoch': 23.84}
{'loss': 0.0096, 'grad_norm': 4.6761932373046875, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.00449706893414259, 'loss_2': 0.0051422119140625, 'loss_3': -16.20599365234375, 'loss_4': -0.5153830051422119, 'epoch': 23.85}
{'loss': 0.0124, 'grad_norm': 6.685473442077637, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.011328281834721565, 'loss_2': 0.0010976791381835938, 'loss_3': -15.819422721862793, 'loss_4': -0.4051916003227234, 'epoch': 23.85}
{'loss': 0.004, 'grad_norm': 4.475178241729736, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.00203390303067863, 'loss_2': 0.0019330978393554688, 'loss_3': -16.3143253326416, 'loss_4': -0.7544164061546326, 'epoch': 23.86}
{'loss': 0.0046, 'grad_norm': 4.387881278991699, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.0030380813404917717, 'loss_2': 0.001567840576171875, 'loss_3': -16.310495376586914, 'loss_4': -0.37732672691345215, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 16:59:45,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:45,824 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:40:58<18:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:53,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025302251800894737, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.437, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021651705726981163, 'eval_loss_2': 0.0036505460739135742, 'eval_loss_3': -17.99662208557129, 'eval_loss_4': -0.3407505452632904, 'epoch': 23.87}
{'loss': 0.0114, 'grad_norm': 5.064487934112549, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.006838423665612936, 'loss_2': 0.004596710205078125, 'loss_3': -16.2271671295166, 'loss_4': -0.8279850482940674, 'epoch': 23.87}
{'loss': 0.008, 'grad_norm': 5.31404447555542, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.004774181172251701, 'loss_2': 0.0032291412353515625, 'loss_3': -16.210445404052734, 'loss_4': -0.6573132872581482, 'epoch': 23.88}
{'loss': 0.0125, 'grad_norm': 5.184966087341309, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.00422689551487565, 'loss_2': 0.0082244873046875, 'loss_3': -16.009538650512695, 'loss_4': -0.384200781583786, 'epoch': 23.88}
{'loss': 0.009, 'grad_norm': 5.428769111633301, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.005509087350219488, 'loss_2': 0.003505706787109375, 'loss_3': -16.163238525390625, 'loss_4': -0.3001578748226166, 'epoch': 23.89}
{'loss': 0.0106, 'grad_norm': 6.044366359710693, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.007694982923567295, 'loss_2': 0.0029296875, 'loss_3': -16.275074005126953, 'loss_4': -0.21958038210868835, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 16:59:53,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:53,148 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:05<18:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:00,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024597415700554848, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.020470451563596725, 'eval_loss_2': 0.0041269659996032715, 'eval_loss_3': -17.997947692871094, 'eval_loss_4': -0.27064642310142517, 'epoch': 23.9}
{'loss': 0.0101, 'grad_norm': 5.099804878234863, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.006367315538227558, 'loss_2': 0.00376129150390625, 'loss_3': -16.293481826782227, 'loss_4': -0.01648406684398651, 'epoch': 23.9}
{'loss': 0.0218, 'grad_norm': 6.026101112365723, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.01039121299982071, 'loss_2': 0.0113983154296875, 'loss_3': -16.102569580078125, 'loss_4': -0.28443443775177, 'epoch': 23.91}
{'loss': 0.0087, 'grad_norm': 4.545896053314209, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.0030864498112350702, 'loss_2': 0.005611419677734375, 'loss_3': -16.155359268188477, 'loss_4': -0.6903249025344849, 'epoch': 23.91}
{'loss': 0.0137, 'grad_norm': 5.371036052703857, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.009835757315158844, 'loss_2': 0.0038604736328125, 'loss_3': -16.285308837890625, 'loss_4': -0.23281237483024597, 'epoch': 23.92}
{'loss': 0.0152, 'grad_norm': 6.811621189117432, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.013842867687344551, 'loss_2': 0.0014047622680664062, 'loss_3': -16.088336944580078, 'loss_4': -0.6058125495910645, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 17:00:00,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:00,477 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:13<17:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:07,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023676957935094833, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.020098324865102768, 'eval_loss_2': 0.0035786330699920654, 'eval_loss_3': -18.006364822387695, 'eval_loss_4': -0.18738329410552979, 'epoch': 23.92}
{'loss': 0.0142, 'grad_norm': 4.904723167419434, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.0035970809403806925, 'loss_2': 0.0106201171875, 'loss_3': -16.118568420410156, 'loss_4': -0.3473353087902069, 'epoch': 23.93}
{'loss': 0.014, 'grad_norm': 6.44140625, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.007991171441972256, 'loss_2': 0.006008148193359375, 'loss_3': -16.216367721557617, 'loss_4': -0.49922335147857666, 'epoch': 23.94}
{'loss': 0.0101, 'grad_norm': 4.895618915557861, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.00761771434918046, 'loss_2': 0.002490997314453125, 'loss_3': -15.995471000671387, 'loss_4': 0.1250363290309906, 'epoch': 23.94}
{'loss': 0.0124, 'grad_norm': 5.320489406585693, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.0077461963519454, 'loss_2': 0.00469207763671875, 'loss_3': -16.147607803344727, 'loss_4': 0.09694148600101471, 'epoch': 23.95}
{'loss': 0.0185, 'grad_norm': 5.060628890991211, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.008456672541797161, 'loss_2': 0.010040283203125, 'loss_3': -16.106035232543945, 'loss_4': -0.2528550922870636, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 17:00:07,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:07,810 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:20<17:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:15,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0230570025742054, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01974376104772091, 'eval_loss_2': 0.0033132433891296387, 'eval_loss_3': -18.01276397705078, 'eval_loss_4': -0.09194191545248032, 'epoch': 23.95}
{'loss': 0.0116, 'grad_norm': 9.178998947143555, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.011146043427288532, 'loss_2': 0.00041294097900390625, 'loss_3': -16.105070114135742, 'loss_4': 0.015676349401474, 'epoch': 23.96}
{'loss': 0.0098, 'grad_norm': 5.335053443908691, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.00956000480800867, 'loss_2': 0.00022482872009277344, 'loss_3': -16.074642181396484, 'loss_4': 0.1336853802204132, 'epoch': 23.97}
{'loss': 0.0105, 'grad_norm': 4.715874195098877, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.0044111404567956924, 'loss_2': 0.006103515625, 'loss_3': -16.02619743347168, 'loss_4': 0.00737057626247406, 'epoch': 23.97}
{'loss': 0.0097, 'grad_norm': 4.70033073425293, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.00676981033757329, 'loss_2': 0.0029735565185546875, 'loss_3': -16.275882720947266, 'loss_4': 0.07608647644519806, 'epoch': 23.98}
{'loss': 0.0101, 'grad_norm': 5.718472003936768, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.008236567489802837, 'loss_2': 0.0018711090087890625, 'loss_3': -16.19772720336914, 'loss_4': -0.27243709564208984, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 17:00:15,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:15,148 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:27<17:02,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 17:00:22,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023173365741968155, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.817, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019672123715281487, 'eval_loss_2': 0.0035012438893318176, 'eval_loss_3': -18.00762176513672, 'eval_loss_4': -0.030148379504680634, 'epoch': 23.98}
{'loss': 0.0065, 'grad_norm': 4.853099822998047, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.00581705616787076, 'loss_2': 0.0006465911865234375, 'loss_3': -16.179187774658203, 'loss_4': -0.0553973987698555, 'epoch': 23.99}
{'loss': 0.0112, 'grad_norm': 4.855301380157471, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.008256942965090275, 'loss_2': 0.0029926300048828125, 'loss_3': -16.20981216430664, 'loss_4': -0.13575372099876404, 'epoch': 23.99}
{'loss': 0.0037, 'grad_norm': 6.127866744995117, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.0013671590713784099, 'loss_2': 0.002349853515625, 'loss_3': -16.047550201416016, 'loss_4': -0.10036773234605789, 'epoch': 24.0}
{'loss': 0.0095, 'grad_norm': 6.109897613525391, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.009195132181048393, 'loss_2': 0.00027561187744140625, 'loss_3': -16.022005081176758, 'loss_4': -0.11099766194820404, 'epoch': 24.01}
{'loss': 0.0144, 'grad_norm': 5.811283588409424, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.008926810696721077, 'loss_2': 0.005496978759765625, 'loss_3': -16.224071502685547, 'loss_4': 0.10621453821659088, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 17:00:22,166 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:22,166 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:34<17:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:00:29,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022735927253961563, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.429, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.019425388425588608, 'eval_loss_2': 0.003310535103082657, 'eval_loss_3': -17.998579025268555, 'eval_loss_4': -0.002383248880505562, 'epoch': 24.01}
{'loss': 0.0107, 'grad_norm': 5.292550563812256, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.009555007331073284, 'loss_2': 0.0011091232299804688, 'loss_3': -15.883306503295898, 'loss_4': 0.1103479266166687, 'epoch': 24.02}
{'loss': 0.0077, 'grad_norm': 5.079188823699951, 'learning_rate': 6e-06, 'loss_1': 0.006778746843338013, 'loss_2': 0.0009102821350097656, 'loss_3': -16.085853576660156, 'loss_4': -0.13180428743362427, 'epoch': 24.02}
{'loss': 0.014, 'grad_norm': 10.401385307312012, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.012988605536520481, 'loss_2': 0.0010166168212890625, 'loss_3': -16.12640380859375, 'loss_4': -0.15366487205028534, 'epoch': 24.03}
{'loss': 0.0267, 'grad_norm': 13.56530475616455, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.019989123567938805, 'loss_2': 0.00670623779296875, 'loss_3': -16.00804901123047, 'loss_4': 0.003561820834875107, 'epoch': 24.03}
{'loss': 0.006, 'grad_norm': 4.799424648284912, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.004733562469482422, 'loss_2': 0.001239776611328125, 'loss_3': -16.119686126708984, 'loss_4': 0.27995985746383667, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 17:00:29,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:29,500 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:41:42<17:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:00:36,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023479336872696877, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.384, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.020076211541891098, 'eval_loss_2': 0.0034031271934509277, 'eval_loss_3': -18.00377655029297, 'eval_loss_4': -0.008071770891547203, 'epoch': 24.04}
{'loss': 0.0041, 'grad_norm': 4.550339698791504, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.0039054539520293474, 'loss_2': 0.00022649765014648438, 'loss_3': -16.211761474609375, 'loss_4': -0.20031306147575378, 'epoch': 24.05}
{'loss': 0.0317, 'grad_norm': 10.444381713867188, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.024474643170833588, 'loss_2': 0.007205963134765625, 'loss_3': -16.227481842041016, 'loss_4': 0.34441351890563965, 'epoch': 24.05}
{'loss': 0.0047, 'grad_norm': 4.604655742645264, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.003849801141768694, 'loss_2': 0.000835418701171875, 'loss_3': -16.027807235717773, 'loss_4': -0.0006741359829902649, 'epoch': 24.06}
{'loss': 0.0141, 'grad_norm': 6.11604118347168, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.009543590247631073, 'loss_2': 0.00458526611328125, 'loss_3': -16.02618408203125, 'loss_4': -0.6536237001419067, 'epoch': 24.06}
{'loss': 0.0167, 'grad_norm': 6.31046199798584, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.012737425975501537, 'loss_2': 0.00397491455078125, 'loss_3': -16.18825340270996, 'loss_4': -0.036389678716659546, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 17:00:36,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:36,826 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:41:49<17:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:00:44,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02526516281068325, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.401, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.020533716306090355, 'eval_loss_2': 0.0047314465045928955, 'eval_loss_3': -17.998310089111328, 'eval_loss_4': 0.0037647150456905365, 'epoch': 24.07}
{'loss': 0.0063, 'grad_norm': 5.3515214920043945, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.006212201900780201, 'loss_2': 9.232759475708008e-05, 'loss_3': -16.01725196838379, 'loss_4': 0.07397535443305969, 'epoch': 24.08}
{'loss': 0.0214, 'grad_norm': 5.372857093811035, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.007919476367533207, 'loss_2': 0.01351165771484375, 'loss_3': -16.07965660095215, 'loss_4': -0.42159712314605713, 'epoch': 24.08}
{'loss': 0.0085, 'grad_norm': 5.190025806427002, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.0075449212454259396, 'loss_2': 0.0009393692016601562, 'loss_3': -16.21085548400879, 'loss_4': -0.19430947303771973, 'epoch': 24.09}
{'loss': 0.0076, 'grad_norm': 4.335386276245117, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.0048613292165100574, 'loss_2': 0.002712249755859375, 'loss_3': -16.09731101989746, 'loss_4': 0.2516564428806305, 'epoch': 24.09}
{'loss': 0.008, 'grad_norm': 4.629425048828125, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.006888547446578741, 'loss_2': 0.0010995864868164062, 'loss_3': -16.040748596191406, 'loss_4': -0.0146237313747406, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 17:00:44,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:44,148 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:41:56<17:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:51,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025274822488427162, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.91, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.02052641473710537, 'eval_loss_2': 0.004748404026031494, 'eval_loss_3': -18.012405395507812, 'eval_loss_4': 0.005002528429031372, 'epoch': 24.1}
{'loss': 0.0123, 'grad_norm': 6.075303554534912, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.010388795286417007, 'loss_2': 0.0019073486328125, 'loss_3': -16.130538940429688, 'loss_4': -0.11592036485671997, 'epoch': 24.1}
{'loss': 0.0264, 'grad_norm': 13.392449378967285, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.025999024510383606, 'loss_2': 0.00043582916259765625, 'loss_3': -15.950408935546875, 'loss_4': -0.12361328303813934, 'epoch': 24.11}
{'loss': 0.0156, 'grad_norm': 6.2568159103393555, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.010106096975505352, 'loss_2': 0.00553131103515625, 'loss_3': -16.268217086791992, 'loss_4': 0.10292819887399673, 'epoch': 24.12}
{'loss': 0.0083, 'grad_norm': 4.7115373611450195, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.006429765839129686, 'loss_2': 0.0018949508666992188, 'loss_3': -16.157032012939453, 'loss_4': 0.25225886702537537, 'epoch': 24.12}
{'loss': 0.0263, 'grad_norm': 8.178476333618164, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.021256020292639732, 'loss_2': 0.0050506591796875, 'loss_3': -15.884544372558594, 'loss_4': -0.38406240940093994, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 17:00:51,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:51,481 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:04<17:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:58,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023186391219496727, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.315, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019419092684984207, 'eval_loss_2': 0.0037672966718673706, 'eval_loss_3': -18.01107406616211, 'eval_loss_4': 0.03404223173856735, 'epoch': 24.13}
{'loss': 0.0159, 'grad_norm': 4.916000843048096, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.006560215260833502, 'loss_2': 0.00934600830078125, 'loss_3': -16.155960083007812, 'loss_4': -0.08216595649719238, 'epoch': 24.13}
{'loss': 0.0108, 'grad_norm': 5.295418739318848, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.006376298610121012, 'loss_2': 0.0044708251953125, 'loss_3': -16.187297821044922, 'loss_4': -0.2538537383079529, 'epoch': 24.14}
{'loss': 0.0118, 'grad_norm': 6.408868312835693, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.009176701307296753, 'loss_2': 0.00260162353515625, 'loss_3': -16.065732955932617, 'loss_4': 0.10282252728939056, 'epoch': 24.15}
{'loss': 0.0069, 'grad_norm': 5.061050891876221, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.006750790867954493, 'loss_2': 0.00019598007202148438, 'loss_3': -16.146398544311523, 'loss_4': 0.11927840113639832, 'epoch': 24.15}
{'loss': 0.0047, 'grad_norm': 4.82108736038208, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.003879668889567256, 'loss_2': 0.0007801055908203125, 'loss_3': -16.01954460144043, 'loss_4': 0.08315467834472656, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 17:00:58,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:58,809 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:11<17:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:06,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02279544249176979, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01936805620789528, 'eval_loss_2': 0.0034273862838745117, 'eval_loss_3': -18.017215728759766, 'eval_loss_4': 0.08520490676164627, 'epoch': 24.16}
{'loss': 0.0087, 'grad_norm': 4.832993984222412, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.0033640130423009396, 'loss_2': 0.005367279052734375, 'loss_3': -16.21682357788086, 'loss_4': 0.2474088966846466, 'epoch': 24.16}
{'loss': 0.0081, 'grad_norm': 4.553232192993164, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.0037935490254312754, 'loss_2': 0.0043487548828125, 'loss_3': -16.32278823852539, 'loss_4': 0.49963831901550293, 'epoch': 24.17}
{'loss': 0.0064, 'grad_norm': 6.1894612312316895, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.006058056838810444, 'loss_2': 0.0003037452697753906, 'loss_3': -16.133861541748047, 'loss_4': 0.25468552112579346, 'epoch': 24.17}
{'loss': 0.0094, 'grad_norm': 5.9018473625183105, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.009138849563896656, 'loss_2': 0.000247955322265625, 'loss_3': -16.2448787689209, 'loss_4': -0.10091184079647064, 'epoch': 24.18}
{'loss': 0.0152, 'grad_norm': 6.763425350189209, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.012380821630358696, 'loss_2': 0.0028171539306640625, 'loss_3': -16.083877563476562, 'loss_4': 0.0091635063290596, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 17:01:06,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:06,145 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:18<17:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:13,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02354852855205536, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.379, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.019910646602511406, 'eval_loss_2': 0.0036378800868988037, 'eval_loss_3': -18.027381896972656, 'eval_loss_4': 0.06600244343280792, 'epoch': 24.19}
{'loss': 0.0081, 'grad_norm': 4.3552985191345215, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.0033717381302267313, 'loss_2': 0.00473785400390625, 'loss_3': -16.240690231323242, 'loss_4': 0.14645874500274658, 'epoch': 24.19}
{'loss': 0.0731, 'grad_norm': 13.69620132446289, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.06313104927539825, 'loss_2': 0.0099945068359375, 'loss_3': -16.200286865234375, 'loss_4': 0.2311042845249176, 'epoch': 24.2}
{'loss': 0.0118, 'grad_norm': 6.078481197357178, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.009080630727112293, 'loss_2': 0.0027179718017578125, 'loss_3': -15.917926788330078, 'loss_4': -0.08567452430725098, 'epoch': 24.2}
{'loss': 0.0063, 'grad_norm': 5.047885894775391, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.004287851974368095, 'loss_2': 0.0019683837890625, 'loss_3': -16.22439193725586, 'loss_4': 0.03443838655948639, 'epoch': 24.21}
{'loss': 0.0094, 'grad_norm': 6.0147833824157715, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.008178913965821266, 'loss_2': 0.0012493133544921875, 'loss_3': -16.266456604003906, 'loss_4': -0.23586289584636688, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 17:01:13,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:13,472 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:26<17:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:20,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023674018681049347, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.314, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019427482038736343, 'eval_loss_2': 0.004246532917022705, 'eval_loss_3': -18.049419403076172, 'eval_loss_4': -0.015564166009426117, 'epoch': 24.22}
{'loss': 0.0101, 'grad_norm': 4.724644660949707, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.003536534495651722, 'loss_2': 0.0065765380859375, 'loss_3': -16.272550582885742, 'loss_4': -0.20367631316184998, 'epoch': 24.22}
{'loss': 0.0092, 'grad_norm': 5.271821022033691, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.00675616879016161, 'loss_2': 0.002429962158203125, 'loss_3': -16.31676483154297, 'loss_4': 0.3983720541000366, 'epoch': 24.23}
{'loss': 0.0159, 'grad_norm': 4.370386600494385, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.005323602817952633, 'loss_2': 0.0105743408203125, 'loss_3': -16.165843963623047, 'loss_4': -0.010368231683969498, 'epoch': 24.23}
{'loss': 0.0063, 'grad_norm': 5.094202518463135, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.004994787275791168, 'loss_2': 0.0013523101806640625, 'loss_3': -16.105064392089844, 'loss_4': -0.16317200660705566, 'epoch': 24.24}
{'loss': 0.0223, 'grad_norm': 8.040923118591309, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.015847424045205116, 'loss_2': 0.006420135498046875, 'loss_3': -16.33896255493164, 'loss_4': 0.09299252182245255, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 17:01:20,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:20,800 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:33<17:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:28,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02276710793375969, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.893, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018781645223498344, 'eval_loss_2': 0.003985464572906494, 'eval_loss_3': -18.058252334594727, 'eval_loss_4': -0.05608873441815376, 'epoch': 24.24}
{'loss': 0.0047, 'grad_norm': 4.845946311950684, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.003626994090154767, 'loss_2': 0.0010633468627929688, 'loss_3': -16.223920822143555, 'loss_4': -0.3308134973049164, 'epoch': 24.25}
{'loss': 0.0088, 'grad_norm': 4.605496883392334, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.004722992889583111, 'loss_2': 0.004058837890625, 'loss_3': -16.230758666992188, 'loss_4': -0.034387849271297455, 'epoch': 24.26}
{'loss': 0.0074, 'grad_norm': 5.5118303298950195, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.0062402538023889065, 'loss_2': 0.0011663436889648438, 'loss_3': -16.197242736816406, 'loss_4': 0.009902626276016235, 'epoch': 24.26}
{'loss': 0.0067, 'grad_norm': 4.811676025390625, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.005193787626922131, 'loss_2': 0.00145721435546875, 'loss_3': -16.016294479370117, 'loss_4': -0.020745201036334038, 'epoch': 24.27}
{'loss': 0.0179, 'grad_norm': 11.507511138916016, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.0166311077773571, 'loss_2': 0.0012950897216796875, 'loss_3': -15.937752723693848, 'loss_4': -0.03820312023162842, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 17:01:28,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:28,133 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:42:40<16:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:35,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022773366421461105, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019314641132950783, 'eval_loss_2': 0.0034587234258651733, 'eval_loss_3': -18.06053924560547, 'eval_loss_4': -0.11826606094837189, 'epoch': 24.27}
{'loss': 0.0049, 'grad_norm': 4.741682529449463, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.0036556036211550236, 'loss_2': 0.001247406005859375, 'loss_3': -16.334712982177734, 'loss_4': -0.12496065348386765, 'epoch': 24.28}
{'loss': 0.0126, 'grad_norm': 5.6092915534973145, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.0097124595195055, 'loss_2': 0.00293731689453125, 'loss_3': -16.16073226928711, 'loss_4': -0.07773306220769882, 'epoch': 24.28}
{'loss': 0.0124, 'grad_norm': 6.632329940795898, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.007641582749783993, 'loss_2': 0.004734039306640625, 'loss_3': -16.199554443359375, 'loss_4': 0.019472546875476837, 'epoch': 24.29}
{'loss': 0.0233, 'grad_norm': 6.587186813354492, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.0162186361849308, 'loss_2': 0.007110595703125, 'loss_3': -16.28746795654297, 'loss_4': -0.06646326184272766, 'epoch': 24.3}
{'loss': 0.0088, 'grad_norm': 4.757577896118164, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.006628646049648523, 'loss_2': 0.0021820068359375, 'loss_3': -16.30225372314453, 'loss_4': 0.15093517303466797, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 17:01:35,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:35,467 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:42:48<16:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:01:42,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023363297805190086, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.179, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019678032025694847, 'eval_loss_2': 0.0036852657794952393, 'eval_loss_3': -18.051773071289062, 'eval_loss_4': -0.1500466763973236, 'epoch': 24.3}
{'loss': 0.0083, 'grad_norm': 5.395021438598633, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.005220672115683556, 'loss_2': 0.0031185150146484375, 'loss_3': -16.229522705078125, 'loss_4': -0.6124124526977539, 'epoch': 24.31}
{'loss': 0.0153, 'grad_norm': 5.3792405128479, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.009640648029744625, 'loss_2': 0.005657196044921875, 'loss_3': -16.32257080078125, 'loss_4': -0.25368428230285645, 'epoch': 24.31}
{'loss': 0.0151, 'grad_norm': 7.5777459144592285, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.010448435321450233, 'loss_2': 0.0046234130859375, 'loss_3': -16.282588958740234, 'loss_4': -0.24517644941806793, 'epoch': 24.32}
{'loss': 0.0122, 'grad_norm': 6.6978230476379395, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.010014870204031467, 'loss_2': 0.002227783203125, 'loss_3': -15.993782997131348, 'loss_4': -0.45293140411376953, 'epoch': 24.33}
{'loss': 0.0123, 'grad_norm': 5.520711421966553, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.007095288950949907, 'loss_2': 0.005207061767578125, 'loss_3': -16.05585289001465, 'loss_4': -0.36507561802864075, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 17:01:42,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:42,789 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:42:55<16:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:50,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023286348208785057, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.23, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019866323098540306, 'eval_loss_2': 0.003420025110244751, 'eval_loss_3': -18.052507400512695, 'eval_loss_4': -0.18827000260353088, 'epoch': 24.33}
{'loss': 0.0148, 'grad_norm': 6.909750938415527, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.008873364888131618, 'loss_2': 0.005954742431640625, 'loss_3': -16.354827880859375, 'loss_4': -0.1763191521167755, 'epoch': 24.34}
{'loss': 0.0079, 'grad_norm': 4.599655628204346, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.00586098525673151, 'loss_2': 0.00202178955078125, 'loss_3': -16.268726348876953, 'loss_4': -0.16066387295722961, 'epoch': 24.34}
{'loss': 0.0108, 'grad_norm': 5.448399066925049, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.008142898790538311, 'loss_2': 0.0026836395263671875, 'loss_3': -16.256223678588867, 'loss_4': -0.6916319131851196, 'epoch': 24.35}
{'loss': 0.0062, 'grad_norm': 4.47520637512207, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.0052305362187325954, 'loss_2': 0.0009202957153320312, 'loss_3': -16.029266357421875, 'loss_4': -0.270152747631073, 'epoch': 24.35}
{'loss': 0.0099, 'grad_norm': 5.148879051208496, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.008367130532860756, 'loss_2': 0.0015163421630859375, 'loss_3': -16.21330451965332, 'loss_4': 0.005972936749458313, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 17:01:50,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:50,117 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:02<16:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:01:57,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02344387397170067, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.395, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01987503096461296, 'eval_loss_2': 0.0035688430070877075, 'eval_loss_3': -18.045841217041016, 'eval_loss_4': -0.2534153461456299, 'epoch': 24.36}
{'loss': 0.0056, 'grad_norm': 5.228086471557617, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.004466159734874964, 'loss_2': 0.0011806488037109375, 'loss_3': -15.948351860046387, 'loss_4': -0.27880728244781494, 'epoch': 24.37}
{'loss': 0.0066, 'grad_norm': 5.415548801422119, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.00365926674567163, 'loss_2': 0.00298309326171875, 'loss_3': -16.27992820739746, 'loss_4': -0.26832830905914307, 'epoch': 24.37}
{'loss': 0.0758, 'grad_norm': 12.775390625, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.07255011051893234, 'loss_2': 0.003215789794921875, 'loss_3': -16.197418212890625, 'loss_4': -0.1791362315416336, 'epoch': 24.38}
{'loss': 0.0067, 'grad_norm': 5.448318958282471, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.0063301571644842625, 'loss_2': 0.0004124641418457031, 'loss_3': -16.19488525390625, 'loss_4': 0.16655100882053375, 'epoch': 24.38}
{'loss': 0.0059, 'grad_norm': 4.732605457305908, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.004403486382216215, 'loss_2': 0.001499176025390625, 'loss_3': -16.222023010253906, 'loss_4': -0.03408144414424896, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 17:01:57,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:57,440 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:10<17:02,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 17:02:04,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024170558899641037, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.06, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.019717808812856674, 'eval_loss_2': 0.004452750086784363, 'eval_loss_3': -18.050918579101562, 'eval_loss_4': -0.2710013687610626, 'epoch': 24.39}
{'loss': 0.0034, 'grad_norm': 4.503853797912598, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0030037984251976013, 'loss_2': 0.0004220008850097656, 'loss_3': -16.260799407958984, 'loss_4': -0.1900986135005951, 'epoch': 24.4}
{'loss': 0.0142, 'grad_norm': 4.892453193664551, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.006336630322039127, 'loss_2': 0.00791168212890625, 'loss_3': -16.10713005065918, 'loss_4': -0.2002427577972412, 'epoch': 24.4}
{'loss': 0.0054, 'grad_norm': 5.169172286987305, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.0048986999318003654, 'loss_2': 0.000507354736328125, 'loss_3': -16.23261260986328, 'loss_4': -0.5284615159034729, 'epoch': 24.41}
{'loss': 0.0144, 'grad_norm': 5.612379550933838, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.0067864833399653435, 'loss_2': 0.007568359375, 'loss_3': -16.276473999023438, 'loss_4': 0.021626800298690796, 'epoch': 24.41}
{'loss': 0.0123, 'grad_norm': 5.377204418182373, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.005531120579689741, 'loss_2': 0.006744384765625, 'loss_3': -16.213048934936523, 'loss_4': -0.2733224928379059, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 17:02:04,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:04,975 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:17<16:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:12,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02437286078929901, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.228, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019153987988829613, 'eval_loss_2': 0.005218870937824249, 'eval_loss_3': -18.062217712402344, 'eval_loss_4': -0.25195926427841187, 'epoch': 24.42}
{'loss': 0.0097, 'grad_norm': 4.591007709503174, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.005317396949976683, 'loss_2': 0.00437164306640625, 'loss_3': -16.240375518798828, 'loss_4': -0.03116689622402191, 'epoch': 24.42}
{'loss': 0.0176, 'grad_norm': 5.6490678787231445, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.00676649808883667, 'loss_2': 0.01080322265625, 'loss_3': -16.228702545166016, 'loss_4': -0.48908162117004395, 'epoch': 24.43}
{'loss': 0.0122, 'grad_norm': 4.707258701324463, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.005862402264028788, 'loss_2': 0.0063018798828125, 'loss_3': -16.197383880615234, 'loss_4': -0.347379595041275, 'epoch': 24.44}
{'loss': 0.0119, 'grad_norm': 5.101892948150635, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.006577325984835625, 'loss_2': 0.00530242919921875, 'loss_3': -16.066791534423828, 'loss_4': 0.13244906067848206, 'epoch': 24.44}
{'loss': 0.0124, 'grad_norm': 5.8359055519104, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.00939024519175291, 'loss_2': 0.003002166748046875, 'loss_3': -16.15807342529297, 'loss_4': 0.1055460199713707, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 17:02:12,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:12,303 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:25<16:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:19,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02302689664065838, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.342, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019484350457787514, 'eval_loss_2': 0.0035425499081611633, 'eval_loss_3': -18.060209274291992, 'eval_loss_4': -0.11519333720207214, 'epoch': 24.45}
{'loss': 0.0065, 'grad_norm': 4.509832859039307, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.0036237789317965508, 'loss_2': 0.002880096435546875, 'loss_3': -16.196882247924805, 'loss_4': 0.27833664417266846, 'epoch': 24.45}
{'loss': 0.0064, 'grad_norm': 4.820476055145264, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.0032983727287501097, 'loss_2': 0.003070831298828125, 'loss_3': -16.215688705444336, 'loss_4': -0.30691689252853394, 'epoch': 24.46}
{'loss': 0.0085, 'grad_norm': 5.1567463874816895, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.005539696663618088, 'loss_2': 0.002933502197265625, 'loss_3': -16.29657554626465, 'loss_4': -0.010375440120697021, 'epoch': 24.47}
{'loss': 0.0129, 'grad_norm': 7.430518627166748, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.010721434839069843, 'loss_2': 0.0022068023681640625, 'loss_3': -16.24140167236328, 'loss_4': 0.1177741065621376, 'epoch': 24.47}
{'loss': 0.0079, 'grad_norm': 5.267155647277832, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.007596314884722233, 'loss_2': 0.00029015541076660156, 'loss_3': -16.285093307495117, 'loss_4': -0.23006516695022583, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 17:02:19,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:19,631 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:32<16:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:26,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022521521896123886, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.198, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0198384840041399, 'eval_loss_2': 0.0026830360293388367, 'eval_loss_3': -18.059505462646484, 'eval_loss_4': -0.04983530566096306, 'epoch': 24.48}
{'loss': 0.0317, 'grad_norm': 9.658482551574707, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.02434898167848587, 'loss_2': 0.00737762451171875, 'loss_3': -16.25341796875, 'loss_4': 0.2042681872844696, 'epoch': 24.48}
{'loss': 0.018, 'grad_norm': 6.534379482269287, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.012669946067035198, 'loss_2': 0.005313873291015625, 'loss_3': -16.222766876220703, 'loss_4': 0.051934368908405304, 'epoch': 24.49}
{'loss': 0.008, 'grad_norm': 4.668087005615234, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.006835370324552059, 'loss_2': 0.0011844635009765625, 'loss_3': -16.30845069885254, 'loss_4': 0.10162261128425598, 'epoch': 24.49}
{'loss': 0.0071, 'grad_norm': 5.471141338348389, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.006797737441956997, 'loss_2': 0.00026416778564453125, 'loss_3': -16.048572540283203, 'loss_4': -0.30020207166671753, 'epoch': 24.5}
{'loss': 0.007, 'grad_norm': 5.028574466705322, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.00481751561164856, 'loss_2': 0.0021495819091796875, 'loss_3': -16.22450828552246, 'loss_4': -0.08175154030323029, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 17:02:26,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:26,965 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:43:39<16:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:34,293 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021932192146778107, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.366, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01951991394162178, 'eval_loss_2': 0.0024122782051563263, 'eval_loss_3': -18.05929183959961, 'eval_loss_4': -0.005162736400961876, 'epoch': 24.51}
{'loss': 0.0055, 'grad_norm': 4.373225212097168, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.004529161844402552, 'loss_2': 0.0010089874267578125, 'loss_3': -16.17394256591797, 'loss_4': -0.3786201477050781, 'epoch': 24.51}
{'loss': 0.0082, 'grad_norm': 6.802098274230957, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.007635642774403095, 'loss_2': 0.0005970001220703125, 'loss_3': -16.09520721435547, 'loss_4': -0.23601892590522766, 'epoch': 24.52}
{'loss': 0.02, 'grad_norm': 10.137693405151367, 'learning_rate': 5.5e-06, 'loss_1': 0.016635039821267128, 'loss_2': 0.003314971923828125, 'loss_3': -15.979167938232422, 'loss_4': 0.10880346596240997, 'epoch': 24.52}
{'loss': 0.0455, 'grad_norm': 18.632526397705078, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.03974441811442375, 'loss_2': 0.005725860595703125, 'loss_3': -16.257671356201172, 'loss_4': 0.08504519611597061, 'epoch': 24.53}
{'loss': 0.0118, 'grad_norm': 5.215806484222412, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.00730839604511857, 'loss_2': 0.004486083984375, 'loss_3': -16.28927230834961, 'loss_4': 0.2898673415184021, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 17:02:34,293 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:34,293 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:43:47<16:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:41,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021718062460422516, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.318, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019595658406615257, 'eval_loss_2': 0.0021224021911621094, 'eval_loss_3': -18.055747985839844, 'eval_loss_4': 0.056517407298088074, 'epoch': 24.53}
{'loss': 0.0121, 'grad_norm': 5.877962589263916, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.0075555481016635895, 'loss_2': 0.00457000732421875, 'loss_3': -16.175630569458008, 'loss_4': 0.02103065513074398, 'epoch': 24.54}
{'loss': 0.032, 'grad_norm': 14.420194625854492, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.02716665342450142, 'loss_2': 0.00484466552734375, 'loss_3': -16.037458419799805, 'loss_4': 0.20182237029075623, 'epoch': 24.55}
{'loss': 0.0213, 'grad_norm': 8.45406436920166, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.016299964860081673, 'loss_2': 0.00495147705078125, 'loss_3': -16.042827606201172, 'loss_4': 0.19169457256793976, 'epoch': 24.55}
{'loss': 0.0174, 'grad_norm': 6.903352737426758, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.013165551237761974, 'loss_2': 0.004276275634765625, 'loss_3': -16.175256729125977, 'loss_4': -0.47276657819747925, 'epoch': 24.56}
{'loss': 0.0092, 'grad_norm': 4.504654407501221, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.0032869004644453526, 'loss_2': 0.00595855712890625, 'loss_3': -16.232563018798828, 'loss_4': -0.06587524712085724, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 17:02:41,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:41,621 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:43:54<16:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:48,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0212443508207798, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.56, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.019104652106761932, 'eval_loss_2': 0.002139698714017868, 'eval_loss_3': -18.066654205322266, 'eval_loss_4': 0.12134015560150146, 'epoch': 24.56}
{'loss': 0.0044, 'grad_norm': 4.646627426147461, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.003306007944047451, 'loss_2': 0.0010471343994140625, 'loss_3': -16.17581558227539, 'loss_4': 0.15553821623325348, 'epoch': 24.57}
{'loss': 0.0067, 'grad_norm': 5.370373249053955, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.006681050173938274, 'loss_2': 5.221366882324219e-05, 'loss_3': -16.042613983154297, 'loss_4': -0.04163726419210434, 'epoch': 24.58}
{'loss': 0.0093, 'grad_norm': 4.484966278076172, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.0034729852341115475, 'loss_2': 0.005870819091796875, 'loss_3': -16.091487884521484, 'loss_4': -0.40807515382766724, 'epoch': 24.58}
{'loss': 0.0161, 'grad_norm': 5.171747207641602, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.011728160083293915, 'loss_2': 0.00440216064453125, 'loss_3': -15.92396068572998, 'loss_4': 0.3765607476234436, 'epoch': 24.59}
{'loss': 0.0095, 'grad_norm': 5.466464519500732, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.006341181695461273, 'loss_2': 0.0031585693359375, 'loss_3': -16.197956085205078, 'loss_4': 0.49889013171195984, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 17:02:48,943 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:48,943 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:01<15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:56,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02043483406305313, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.229, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.017785226926207542, 'eval_loss_2': 0.0026496052742004395, 'eval_loss_3': -18.088125228881836, 'eval_loss_4': 0.1586589515209198, 'epoch': 24.59}
{'loss': 0.0059, 'grad_norm': 4.884525299072266, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.005118752364069223, 'loss_2': 0.000789642333984375, 'loss_3': -16.243309020996094, 'loss_4': 0.12758830189704895, 'epoch': 24.6}
{'loss': 0.0053, 'grad_norm': 4.766968250274658, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.004695334937423468, 'loss_2': 0.0006518363952636719, 'loss_3': -16.116323471069336, 'loss_4': -0.004861358553171158, 'epoch': 24.6}
{'loss': 0.0422, 'grad_norm': 8.385565757751465, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.039488937705755234, 'loss_2': 0.0026721954345703125, 'loss_3': -16.11869239807129, 'loss_4': 0.30861005187034607, 'epoch': 24.61}
{'loss': 0.0146, 'grad_norm': 7.32076358795166, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.013990015722811222, 'loss_2': 0.0005693435668945312, 'loss_3': -16.093873977661133, 'loss_4': 0.29033657908439636, 'epoch': 24.62}
{'loss': 0.0093, 'grad_norm': 5.025242328643799, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.007144981995224953, 'loss_2': 0.0021953582763671875, 'loss_3': -16.226152420043945, 'loss_4': 0.06365706026554108, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 17:02:56,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:56,272 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:09<15:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:03,596 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0205110814422369, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.467, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0174462478607893, 'eval_loss_2': 0.0030648335814476013, 'eval_loss_3': -18.07356071472168, 'eval_loss_4': 0.15474097430706024, 'epoch': 24.62}
{'loss': 0.0317, 'grad_norm': 16.00678825378418, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.023040771484375, 'loss_2': 0.00865936279296875, 'loss_3': -16.01181983947754, 'loss_4': -0.0039230287075042725, 'epoch': 24.63}
{'loss': 0.014, 'grad_norm': 4.731557846069336, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.003686298383399844, 'loss_2': 0.0102691650390625, 'loss_3': -16.13109588623047, 'loss_4': 0.07204502820968628, 'epoch': 24.63}
{'loss': 0.0058, 'grad_norm': 4.613977909088135, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.002835658611729741, 'loss_2': 0.002948760986328125, 'loss_3': -15.997486114501953, 'loss_4': 0.6097959280014038, 'epoch': 24.64}
{'loss': 0.0763, 'grad_norm': 15.31807804107666, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.07026933878660202, 'loss_2': 0.0059967041015625, 'loss_3': -16.138946533203125, 'loss_4': 0.492186576128006, 'epoch': 24.65}
{'loss': 0.0108, 'grad_norm': 6.305383205413818, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.008574968203902245, 'loss_2': 0.00225830078125, 'loss_3': -16.08358383178711, 'loss_4': -0.057316724210977554, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 17:03:03,596 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:03,596 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:16<15:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:03:10,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019224077463150024, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.315, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016649432480335236, 'eval_loss_2': 0.002574644982814789, 'eval_loss_3': -18.068452835083008, 'eval_loss_4': 0.13634462654590607, 'epoch': 24.65}
{'loss': 0.0164, 'grad_norm': 12.829718589782715, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.015811724588274956, 'loss_2': 0.0005402565002441406, 'loss_3': -15.894021987915039, 'loss_4': -0.1713264435529709, 'epoch': 24.66}
{'loss': 0.0086, 'grad_norm': 4.460209846496582, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.003839634358882904, 'loss_2': 0.0047454833984375, 'loss_3': -16.12936019897461, 'loss_4': 0.037047576159238815, 'epoch': 24.66}
{'loss': 0.0118, 'grad_norm': 6.133187294006348, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.009089520201086998, 'loss_2': 0.00274658203125, 'loss_3': -15.907909393310547, 'loss_4': 0.5641341209411621, 'epoch': 24.67}
{'loss': 0.0049, 'grad_norm': 4.47020959854126, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.00455075828358531, 'loss_2': 0.0003352165222167969, 'loss_3': -16.210735321044922, 'loss_4': 0.3136264979839325, 'epoch': 24.67}
{'loss': 0.0063, 'grad_norm': 5.076101303100586, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.005926826503127813, 'loss_2': 0.0003771781921386719, 'loss_3': -16.17351722717285, 'loss_4': 0.1228502169251442, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 17:03:10,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:10,918 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:23<15:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:03:18,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019055699929594994, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.511, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.016597522422671318, 'eval_loss_2': 0.0024581775069236755, 'eval_loss_3': -18.060863494873047, 'eval_loss_4': 0.13804450631141663, 'epoch': 24.68}
{'loss': 0.0104, 'grad_norm': 4.923613548278809, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.003970390651375055, 'loss_2': 0.00640106201171875, 'loss_3': -16.090065002441406, 'loss_4': 0.21656382083892822, 'epoch': 24.69}
{'loss': 0.0104, 'grad_norm': 6.321259498596191, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.006382432300597429, 'loss_2': 0.00405120849609375, 'loss_3': -16.137104034423828, 'loss_4': -0.36638975143432617, 'epoch': 24.69}
{'loss': 0.0039, 'grad_norm': 4.657494068145752, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.00323230167850852, 'loss_2': 0.0006504058837890625, 'loss_3': -16.129751205444336, 'loss_4': 0.2841429114341736, 'epoch': 24.7}
{'loss': 0.0131, 'grad_norm': 5.120632171630859, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.005955195985734463, 'loss_2': 0.00719451904296875, 'loss_3': -16.135162353515625, 'loss_4': 0.10155026614665985, 'epoch': 24.7}
{'loss': 0.0102, 'grad_norm': 4.452415466308594, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.004864775575697422, 'loss_2': 0.005359649658203125, 'loss_3': -16.234718322753906, 'loss_4': 0.097316674888134, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 17:03:18,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:18,243 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:30<15:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:25,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01963043212890625, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.581, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01679399609565735, 'eval_loss_2': 0.0028364360332489014, 'eval_loss_3': -18.068944931030273, 'eval_loss_4': 0.169345423579216, 'epoch': 24.71}
{'loss': 0.0072, 'grad_norm': 4.488677501678467, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.00350540061481297, 'loss_2': 0.003688812255859375, 'loss_3': -16.073774337768555, 'loss_4': 0.11183404922485352, 'epoch': 24.72}
{'loss': 0.0065, 'grad_norm': 4.150079727172852, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.0043527716770768166, 'loss_2': 0.002193450927734375, 'loss_3': -16.337169647216797, 'loss_4': 0.3517056703567505, 'epoch': 24.72}
{'loss': 0.0075, 'grad_norm': 4.8979268074035645, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.00478966673836112, 'loss_2': 0.002696990966796875, 'loss_3': -16.002792358398438, 'loss_4': 0.16228051483631134, 'epoch': 24.73}
{'loss': 0.0098, 'grad_norm': 4.685514450073242, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.003960995934903622, 'loss_2': 0.00586700439453125, 'loss_3': -16.181976318359375, 'loss_4': 0.34439918398857117, 'epoch': 24.73}
{'loss': 0.0067, 'grad_norm': 5.026150703430176, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.004915304947644472, 'loss_2': 0.00180816650390625, 'loss_3': -16.182464599609375, 'loss_4': -0.08386477828025818, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 17:03:25,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:25,568 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:38<15:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:32,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019169356673955917, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.141, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016378022730350494, 'eval_loss_2': 0.0027913376688957214, 'eval_loss_3': -18.069568634033203, 'eval_loss_4': 0.22076478600502014, 'epoch': 24.74}
{'loss': 0.0122, 'grad_norm': 4.862903118133545, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.003804675070568919, 'loss_2': 0.0084075927734375, 'loss_3': -16.10677719116211, 'loss_4': 0.08465483039617538, 'epoch': 24.74}
{'loss': 0.0071, 'grad_norm': 4.834054946899414, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.0034954792354255915, 'loss_2': 0.003566741943359375, 'loss_3': -16.26624870300293, 'loss_4': -0.2533448040485382, 'epoch': 24.75}
{'loss': 0.0104, 'grad_norm': 4.578834056854248, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.005011700093746185, 'loss_2': 0.00536346435546875, 'loss_3': -16.09939956665039, 'loss_4': 0.2395690679550171, 'epoch': 24.76}
{'loss': 0.0053, 'grad_norm': 5.114635944366455, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.004147540777921677, 'loss_2': 0.0011243820190429688, 'loss_3': -16.043498992919922, 'loss_4': 0.061398789286613464, 'epoch': 24.76}
{'loss': 0.0223, 'grad_norm': 10.106233596801758, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.01346553210169077, 'loss_2': 0.0088043212890625, 'loss_3': -16.171669006347656, 'loss_4': 0.18440590798854828, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 17:03:32,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:32,893 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:44:45<15:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:40,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019622907042503357, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.923, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016846559941768646, 'eval_loss_2': 0.0027763471007347107, 'eval_loss_3': -18.07421875, 'eval_loss_4': 0.26229551434516907, 'epoch': 24.77}
{'loss': 0.0064, 'grad_norm': 5.053725719451904, 'learning_rate': 5.25e-06, 'loss_1': 0.005375952925533056, 'loss_2': 0.0010013580322265625, 'loss_3': -16.289569854736328, 'loss_4': 0.3371286988258362, 'epoch': 24.77}
{'loss': 0.0203, 'grad_norm': 9.195195198059082, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.020174195989966393, 'loss_2': 0.00010752677917480469, 'loss_3': -16.147062301635742, 'loss_4': 0.10153506696224213, 'epoch': 24.78}
{'loss': 0.0042, 'grad_norm': 4.257111072540283, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.0026312400586903095, 'loss_2': 0.0015993118286132812, 'loss_3': -16.31801986694336, 'loss_4': 0.2940177321434021, 'epoch': 24.78}
{'loss': 0.0076, 'grad_norm': 4.72510290145874, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.0055102198384702206, 'loss_2': 0.0020618438720703125, 'loss_3': -16.166118621826172, 'loss_4': 0.09041692316532135, 'epoch': 24.79}
{'loss': 0.0077, 'grad_norm': 4.942543029785156, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.007322878576815128, 'loss_2': 0.0003399848937988281, 'loss_3': -16.204715728759766, 'loss_4': 0.2260078489780426, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 17:03:40,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:40,225 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:44:52<15:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:47,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019939079880714417, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.03, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0168603602796793, 'eval_loss_2': 0.0030787214636802673, 'eval_loss_3': -18.069671630859375, 'eval_loss_4': 0.303806871175766, 'epoch': 24.8}
{'loss': 0.0228, 'grad_norm': 12.073131561279297, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.02008054591715336, 'loss_2': 0.002750396728515625, 'loss_3': -16.21664810180664, 'loss_4': 0.5618550181388855, 'epoch': 24.8}
{'loss': 0.0078, 'grad_norm': 4.850236415863037, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.004010012838989496, 'loss_2': 0.0038280487060546875, 'loss_3': -16.151803970336914, 'loss_4': 0.6041780710220337, 'epoch': 24.81}
{'loss': 0.0161, 'grad_norm': 9.572834014892578, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.011519105173647404, 'loss_2': 0.0045318603515625, 'loss_3': -16.344348907470703, 'loss_4': 0.8283721208572388, 'epoch': 24.81}
{'loss': 0.0204, 'grad_norm': 6.670022010803223, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.01477177906781435, 'loss_2': 0.005649566650390625, 'loss_3': -16.123428344726562, 'loss_4': 0.030956018716096878, 'epoch': 24.82}
{'loss': 0.0162, 'grad_norm': 4.5916666984558105, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.005344771314412355, 'loss_2': 0.0108642578125, 'loss_3': -16.078922271728516, 'loss_4': 0.1841667890548706, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 17:03:47,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:47,560 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:00<15:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:54,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02151491865515709, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.017834175378084183, 'eval_loss_2': 0.0036807432770729065, 'eval_loss_3': -18.062458038330078, 'eval_loss_4': 0.3214672803878784, 'epoch': 24.83}
{'loss': 0.0094, 'grad_norm': 4.234427452087402, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0034417358692735434, 'loss_2': 0.0059814453125, 'loss_3': -16.278968811035156, 'loss_4': 0.7791944742202759, 'epoch': 24.83}
{'loss': 0.0078, 'grad_norm': 4.635011196136475, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.0047577121295034885, 'loss_2': 0.003078460693359375, 'loss_3': -16.30283546447754, 'loss_4': 0.6566321849822998, 'epoch': 24.84}
{'loss': 0.0143, 'grad_norm': 5.927328586578369, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.013075252063572407, 'loss_2': 0.001224517822265625, 'loss_3': -16.01764488220215, 'loss_4': 0.14855533838272095, 'epoch': 24.84}
{'loss': 0.0103, 'grad_norm': 5.6121392250061035, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.007190885487943888, 'loss_2': 0.00307464599609375, 'loss_3': -16.10497283935547, 'loss_4': 0.42307808995246887, 'epoch': 24.85}
{'loss': 0.0092, 'grad_norm': 4.39495325088501, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.0068626124411821365, 'loss_2': 0.00235748291015625, 'loss_3': -16.159862518310547, 'loss_4': 0.3302447199821472, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 17:03:54,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:54,902 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:07<15:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:02,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021120324730873108, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017523080110549927, 'eval_loss_2': 0.003597244620323181, 'eval_loss_3': -18.064788818359375, 'eval_loss_4': 0.3439905643463135, 'epoch': 24.85}
{'loss': 0.0269, 'grad_norm': 11.657711029052734, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.021575329825282097, 'loss_2': 0.005290985107421875, 'loss_3': -16.207508087158203, 'loss_4': 0.36922651529312134, 'epoch': 24.86}
{'loss': 0.0101, 'grad_norm': 5.176011085510254, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.007873054593801498, 'loss_2': 0.002231597900390625, 'loss_3': -16.16098403930664, 'loss_4': 0.23347073793411255, 'epoch': 24.87}
{'loss': 0.0247, 'grad_norm': 10.688007354736328, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.015598388388752937, 'loss_2': 0.00911712646484375, 'loss_3': -16.136075973510742, 'loss_4': 0.5852648019790649, 'epoch': 24.87}
{'loss': 0.0056, 'grad_norm': 4.6056694984436035, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.004485808778554201, 'loss_2': 0.001132965087890625, 'loss_3': -16.200424194335938, 'loss_4': 0.28197968006134033, 'epoch': 24.88}
{'loss': 0.0084, 'grad_norm': 5.827085018157959, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.00793528463691473, 'loss_2': 0.00048232078552246094, 'loss_3': -15.973417282104492, 'loss_4': -0.0005454495549201965, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 17:04:02,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:02,238 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:14<15:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:09,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021210376173257828, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.385, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017548462375998497, 'eval_loss_2': 0.00366191565990448, 'eval_loss_3': -18.07396125793457, 'eval_loss_4': 0.3517594337463379, 'epoch': 24.88}
{'loss': 0.0052, 'grad_norm': 4.786836624145508, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.00344462669454515, 'loss_2': 0.0017175674438476562, 'loss_3': -16.05666732788086, 'loss_4': 0.39382898807525635, 'epoch': 24.89}
{'loss': 0.0068, 'grad_norm': 4.537492752075195, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.004215944092720747, 'loss_2': 0.0025348663330078125, 'loss_3': -16.106412887573242, 'loss_4': 0.20423713326454163, 'epoch': 24.9}
{'loss': 0.015, 'grad_norm': 5.4401140213012695, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.009940075688064098, 'loss_2': 0.005107879638671875, 'loss_3': -16.16326904296875, 'loss_4': -0.02336951345205307, 'epoch': 24.9}
{'loss': 0.007, 'grad_norm': 4.474742412567139, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.003690667450428009, 'loss_2': 0.003261566162109375, 'loss_3': -16.11635398864746, 'loss_4': 0.15072360634803772, 'epoch': 24.91}
{'loss': 0.0055, 'grad_norm': 4.5719451904296875, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.003900910494849086, 'loss_2': 0.0015783309936523438, 'loss_3': -16.331262588500977, 'loss_4': 0.510261058807373, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 17:04:09,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:09,581 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:22<15:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:16,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022042080760002136, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.456, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.018222259357571602, 'eval_loss_2': 0.0038198232650756836, 'eval_loss_3': -18.08089828491211, 'eval_loss_4': 0.34022238850593567, 'epoch': 24.91}
{'loss': 0.0096, 'grad_norm': 4.4228692054748535, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.004720807075500488, 'loss_2': 0.0049285888671875, 'loss_3': -16.191787719726562, 'loss_4': 0.29357844591140747, 'epoch': 24.92}
{'loss': 0.0069, 'grad_norm': 4.775729656219482, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.005841227248311043, 'loss_2': 0.00110626220703125, 'loss_3': -16.380170822143555, 'loss_4': 0.38201552629470825, 'epoch': 24.92}
{'loss': 0.0103, 'grad_norm': 5.321590900421143, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.007086567580699921, 'loss_2': 0.003204345703125, 'loss_3': -16.2044677734375, 'loss_4': 0.40723717212677, 'epoch': 24.93}
{'loss': 0.007, 'grad_norm': 4.511979103088379, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.002556010615080595, 'loss_2': 0.00440216064453125, 'loss_3': -16.151683807373047, 'loss_4': 0.006928004324436188, 'epoch': 24.94}
{'loss': 0.0123, 'grad_norm': 6.178681373596191, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.009605665691196918, 'loss_2': 0.00272369384765625, 'loss_3': -16.246564865112305, 'loss_4': 0.2809385061264038, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 17:04:16,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:16,911 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:29<14:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:24,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022561365738511086, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.507, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01902111992239952, 'eval_loss_2': 0.003540247678756714, 'eval_loss_3': -18.082805633544922, 'eval_loss_4': 0.31962719559669495, 'epoch': 24.94}
{'loss': 0.0063, 'grad_norm': 4.376168727874756, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.005313204601407051, 'loss_2': 0.0009899139404296875, 'loss_3': -16.196998596191406, 'loss_4': 0.32627707719802856, 'epoch': 24.95}
{'loss': 0.0128, 'grad_norm': 4.870617389678955, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.0051714712753891945, 'loss_2': 0.00760650634765625, 'loss_3': -15.935431480407715, 'loss_4': 0.3911241292953491, 'epoch': 24.95}
{'loss': 0.0073, 'grad_norm': 4.986106872558594, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.00612498726695776, 'loss_2': 0.0012159347534179688, 'loss_3': -15.99752140045166, 'loss_4': 0.038106709718704224, 'epoch': 24.96}
{'loss': 0.0049, 'grad_norm': 4.547930717468262, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.002795925596728921, 'loss_2': 0.002140045166015625, 'loss_3': -16.294918060302734, 'loss_4': 0.23238994181156158, 'epoch': 24.97}
{'loss': 0.0057, 'grad_norm': 4.705562114715576, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.0033435930963605642, 'loss_2': 0.002353668212890625, 'loss_3': -16.132108688354492, 'loss_4': 0.2717258036136627, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 17:04:24,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:24,231 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:36<13:20,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:04:31,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022254832088947296, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.189, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018540985882282257, 'eval_loss_2': 0.003713846206665039, 'eval_loss_3': -18.082826614379883, 'eval_loss_4': 0.2932458221912384, 'epoch': 24.97}
{'loss': 0.014, 'grad_norm': 5.660460472106934, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.00988570973277092, 'loss_2': 0.0040740966796875, 'loss_3': -16.11981773376465, 'loss_4': 0.08188743144273758, 'epoch': 24.98}
{'loss': 0.0056, 'grad_norm': 4.616589069366455, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.004746478050947189, 'loss_2': 0.0008959770202636719, 'loss_3': -16.211030960083008, 'loss_4': 0.36169126629829407, 'epoch': 24.98}
{'loss': 0.0032, 'grad_norm': 4.424158096313477, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.0028495732694864273, 'loss_2': 0.0003871917724609375, 'loss_3': -16.03719711303711, 'loss_4': 0.15819494426250458, 'epoch': 24.99}
{'loss': 0.0077, 'grad_norm': 5.200516700744629, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.006901815067976713, 'loss_2': 0.000762939453125, 'loss_3': -16.142074584960938, 'loss_4': 0.5715036392211914, 'epoch': 24.99}
{'loss': 0.0122, 'grad_norm': 5.838975429534912, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0037083651404827833, 'loss_2': 0.00852203369140625, 'loss_3': -16.1788330078125, 'loss_4': 0.20499595999717712, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 17:04:31,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:31,203 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:45:43<14:33,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 17:04:38,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021276118233799934, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.996, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01803678460419178, 'eval_loss_2': 0.0032393336296081543, 'eval_loss_3': -18.082754135131836, 'eval_loss_4': 0.23882539570331573, 'epoch': 25.0}
{'loss': 0.0102, 'grad_norm': 5.746957302093506, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.007560265716165304, 'loss_2': 0.0026187896728515625, 'loss_3': -16.057750701904297, 'loss_4': 0.08576974272727966, 'epoch': 25.01}
{'loss': 0.0048, 'grad_norm': 4.780679702758789, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.003668257500976324, 'loss_2': 0.001102447509765625, 'loss_3': -16.15097427368164, 'loss_4': 0.35824739933013916, 'epoch': 25.01}
{'loss': 0.009, 'grad_norm': 4.381803512573242, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.0038656634278595448, 'loss_2': 0.005157470703125, 'loss_3': -16.287708282470703, 'loss_4': 0.4774104654788971, 'epoch': 25.02}
{'loss': 0.0139, 'grad_norm': 5.9449591636657715, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.01037334930151701, 'loss_2': 0.0034961700439453125, 'loss_3': -16.039175033569336, 'loss_4': 0.3426307141780853, 'epoch': 25.02}
{'loss': 0.072, 'grad_norm': 15.682409286499023, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.07094687968492508, 'loss_2': 0.0010499954223632812, 'loss_3': -16.08523178100586, 'loss_4': 0.32281970977783203, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 17:04:38,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:38,576 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:45:51<14:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:04:45,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021867698058485985, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.642, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01858440786600113, 'eval_loss_2': 0.003283292055130005, 'eval_loss_3': -18.09148406982422, 'eval_loss_4': 0.2348065823316574, 'epoch': 25.03}
{'loss': 0.0211, 'grad_norm': 8.407647132873535, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.01619569957256317, 'loss_2': 0.0048828125, 'loss_3': -16.099443435668945, 'loss_4': 0.2776511311531067, 'epoch': 25.03}
{'loss': 0.0087, 'grad_norm': 5.818714618682861, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.008150912821292877, 'loss_2': 0.0005369186401367188, 'loss_3': -16.247356414794922, 'loss_4': 0.43622633814811707, 'epoch': 25.04}
{'loss': 0.0105, 'grad_norm': 5.675729751586914, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.006807052996009588, 'loss_2': 0.003696441650390625, 'loss_3': -16.139867782592773, 'loss_4': -0.006242319941520691, 'epoch': 25.05}
{'loss': 0.0105, 'grad_norm': 5.058819770812988, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.008279027417302132, 'loss_2': 0.0022144317626953125, 'loss_3': -16.09716033935547, 'loss_4': 0.08179648220539093, 'epoch': 25.05}
{'loss': 0.0106, 'grad_norm': 6.173486709594727, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.007541781757026911, 'loss_2': 0.0030517578125, 'loss_3': -16.205659866333008, 'loss_4': 0.38896387815475464, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 17:04:45,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:45,899 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:45:58<14:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:53,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02270684204995632, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.094, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.019363224506378174, 'eval_loss_2': 0.0033436156809329987, 'eval_loss_3': -18.088403701782227, 'eval_loss_4': 0.2476329356431961, 'epoch': 25.06}
{'loss': 0.0175, 'grad_norm': 7.301376819610596, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.01656176894903183, 'loss_2': 0.000957489013671875, 'loss_3': -16.238889694213867, 'loss_4': 0.054833970963954926, 'epoch': 25.06}
{'loss': 0.0079, 'grad_norm': 5.330078125, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.006932660471647978, 'loss_2': 0.0009469985961914062, 'loss_3': -16.034332275390625, 'loss_4': 0.3954848051071167, 'epoch': 25.07}
{'loss': 0.011, 'grad_norm': 4.899235248565674, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.004112641792744398, 'loss_2': 0.00687408447265625, 'loss_3': -16.212738037109375, 'loss_4': 0.2392149567604065, 'epoch': 25.08}
{'loss': 0.012, 'grad_norm': 5.563692092895508, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.006291136145591736, 'loss_2': 0.00574493408203125, 'loss_3': -15.931290626525879, 'loss_4': 0.2203686237335205, 'epoch': 25.08}
{'loss': 0.0148, 'grad_norm': 5.179356098175049, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.011368723586201668, 'loss_2': 0.003398895263671875, 'loss_3': -16.159042358398438, 'loss_4': 0.3656635284423828, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 17:04:53,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:53,229 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:05<14:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:00,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0231068916618824, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.404, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.019605208188295364, 'eval_loss_2': 0.003501683473587036, 'eval_loss_3': -18.088483810424805, 'eval_loss_4': 0.31662875413894653, 'epoch': 25.09}
{'loss': 0.0104, 'grad_norm': 4.516591548919678, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.005473105702549219, 'loss_2': 0.0049285888671875, 'loss_3': -16.39739227294922, 'loss_4': 0.19499604403972626, 'epoch': 25.09}
{'loss': 0.0074, 'grad_norm': 5.165008544921875, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.005286189261823893, 'loss_2': 0.0021514892578125, 'loss_3': -15.913311004638672, 'loss_4': 0.627223014831543, 'epoch': 25.1}
{'loss': 0.0056, 'grad_norm': 4.45159912109375, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.004521531984210014, 'loss_2': 0.0011234283447265625, 'loss_3': -16.384349822998047, 'loss_4': 0.39520275592803955, 'epoch': 25.1}
{'loss': 0.0073, 'grad_norm': 4.599315643310547, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.004452649038285017, 'loss_2': 0.002834320068359375, 'loss_3': -16.005970001220703, 'loss_4': 0.20798036456108093, 'epoch': 25.11}
{'loss': 0.0075, 'grad_norm': 4.19010591506958, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.005818491335958242, 'loss_2': 0.0017070770263671875, 'loss_3': -15.983565330505371, 'loss_4': 0.177016019821167, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 17:05:00,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:00,552 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:13<14:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:07,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022443154826760292, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.524, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.019221926108002663, 'eval_loss_2': 0.0032212287187576294, 'eval_loss_3': -18.07754135131836, 'eval_loss_4': 0.31140652298927307, 'epoch': 25.12}
{'loss': 0.0207, 'grad_norm': 8.206668853759766, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.015259805135428905, 'loss_2': 0.0054168701171875, 'loss_3': -16.227188110351562, 'loss_4': 0.4458644688129425, 'epoch': 25.12}
{'loss': 0.0061, 'grad_norm': 5.340027809143066, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.005444533657282591, 'loss_2': 0.0006513595581054688, 'loss_3': -16.305999755859375, 'loss_4': 0.0770452469587326, 'epoch': 25.13}
{'loss': 0.0111, 'grad_norm': 5.076720237731934, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.004329119808971882, 'loss_2': 0.00679779052734375, 'loss_3': -16.314054489135742, 'loss_4': 0.458134263753891, 'epoch': 25.13}
{'loss': 0.0092, 'grad_norm': 5.83779764175415, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.007273332215845585, 'loss_2': 0.0018939971923828125, 'loss_3': -16.171920776367188, 'loss_4': 0.4232970178127289, 'epoch': 25.14}
{'loss': 0.0113, 'grad_norm': 4.583980083465576, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.004962385632097721, 'loss_2': 0.00638580322265625, 'loss_3': -16.119983673095703, 'loss_4': 0.526972770690918, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 17:05:07,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:07,878 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:20<14:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:15,202 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02322549745440483, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.495, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.020069822669029236, 'eval_loss_2': 0.0031556785106658936, 'eval_loss_3': -18.072124481201172, 'eval_loss_4': 0.32141000032424927, 'epoch': 25.15}
{'loss': 0.0054, 'grad_norm': 4.611586093902588, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.005354260094463825, 'loss_2': 1.33514404296875e-05, 'loss_3': -16.25947380065918, 'loss_4': 0.5032543540000916, 'epoch': 25.15}
{'loss': 0.0031, 'grad_norm': 4.780904293060303, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.0028757876716554165, 'loss_2': 0.0002684593200683594, 'loss_3': -16.1984920501709, 'loss_4': 0.45925015211105347, 'epoch': 25.16}
{'loss': 0.0091, 'grad_norm': 5.270471572875977, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.004878494422882795, 'loss_2': 0.00426483154296875, 'loss_3': -16.120723724365234, 'loss_4': 0.1014241874217987, 'epoch': 25.16}
{'loss': 0.0083, 'grad_norm': 3.8693366050720215, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.0028474933933466673, 'loss_2': 0.0054779052734375, 'loss_3': -16.286075592041016, 'loss_4': 0.320016086101532, 'epoch': 25.17}
{'loss': 0.0054, 'grad_norm': 4.9642462730407715, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.005101979710161686, 'loss_2': 0.0002894401550292969, 'loss_3': -16.210174560546875, 'loss_4': 0.2124945968389511, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 17:05:15,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:15,203 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:27<14:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:22,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025180254131555557, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.154, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021701186895370483, 'eval_loss_2': 0.0034790635108947754, 'eval_loss_3': -18.071290969848633, 'eval_loss_4': 0.3298514485359192, 'epoch': 25.17}
{'loss': 0.0067, 'grad_norm': 4.795047760009766, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.004191733431071043, 'loss_2': 0.0024814605712890625, 'loss_3': -16.185483932495117, 'loss_4': 0.21250294148921967, 'epoch': 25.18}
{'loss': 0.0133, 'grad_norm': 6.205958843231201, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.011791830882430077, 'loss_2': 0.00146484375, 'loss_3': -15.852867126464844, 'loss_4': 0.5998112559318542, 'epoch': 25.19}
{'loss': 0.0094, 'grad_norm': 4.42142391204834, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.003603254444897175, 'loss_2': 0.00583648681640625, 'loss_3': -16.26300811767578, 'loss_4': 0.26052701473236084, 'epoch': 25.19}
{'loss': 0.0075, 'grad_norm': 4.664506912231445, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.006044055800884962, 'loss_2': 0.0014972686767578125, 'loss_3': -16.062227249145508, 'loss_4': 0.5650399923324585, 'epoch': 25.2}
{'loss': 0.015, 'grad_norm': 8.140995025634766, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.012261610478162766, 'loss_2': 0.002780914306640625, 'loss_3': -16.24557876586914, 'loss_4': 0.5006529092788696, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 17:05:22,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:22,531 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:35<14:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:29,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02659238688647747, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.115, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.022967888042330742, 'eval_loss_2': 0.0036244988441467285, 'eval_loss_3': -18.059345245361328, 'eval_loss_4': 0.33962583541870117, 'epoch': 25.2}
{'loss': 0.0228, 'grad_norm': 7.0300984382629395, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.014113688841462135, 'loss_2': 0.0086822509765625, 'loss_3': -15.911956787109375, 'loss_4': 0.25656330585479736, 'epoch': 25.21}
{'loss': 0.0059, 'grad_norm': 4.552688121795654, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.003699088469147682, 'loss_2': 0.00220489501953125, 'loss_3': -16.098007202148438, 'loss_4': 0.22677867114543915, 'epoch': 25.22}
{'loss': 0.0112, 'grad_norm': 5.854655742645264, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.008753305301070213, 'loss_2': 0.0023975372314453125, 'loss_3': -16.180601119995117, 'loss_4': -0.054554447531700134, 'epoch': 25.22}
{'loss': 0.0102, 'grad_norm': 5.211325168609619, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.005672110244631767, 'loss_2': 0.00457763671875, 'loss_3': -15.90572452545166, 'loss_4': 0.102086141705513, 'epoch': 25.23}
{'loss': 0.011, 'grad_norm': 4.9370503425598145, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.005525314714759588, 'loss_2': 0.00543212890625, 'loss_3': -16.22068977355957, 'loss_4': 0.6333678960800171, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 17:05:29,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:29,860 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:46:42<14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:37,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02734038606286049, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.585, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.023611310869455338, 'eval_loss_2': 0.0037290751934051514, 'eval_loss_3': -18.042322158813477, 'eval_loss_4': 0.3565457761287689, 'epoch': 25.23}
{'loss': 0.0083, 'grad_norm': 4.918640613555908, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.007118773180991411, 'loss_2': 0.0012063980102539062, 'loss_3': -16.21028709411621, 'loss_4': 0.322426438331604, 'epoch': 25.24}
{'loss': 0.0108, 'grad_norm': 7.667584419250488, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.007946966215968132, 'loss_2': 0.0028076171875, 'loss_3': -16.110944747924805, 'loss_4': 0.316583514213562, 'epoch': 25.24}
{'loss': 0.0063, 'grad_norm': 4.810911655426025, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.005668541416525841, 'loss_2': 0.0006723403930664062, 'loss_3': -16.121463775634766, 'loss_4': 0.193914994597435, 'epoch': 25.25}
{'loss': 0.0707, 'grad_norm': 16.320520401000977, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.06945885717868805, 'loss_2': 0.0012540817260742188, 'loss_3': -16.228851318359375, 'loss_4': 0.3104632496833801, 'epoch': 25.26}
{'loss': 0.0188, 'grad_norm': 6.733875751495361, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.013029973953962326, 'loss_2': 0.0057525634765625, 'loss_3': -16.047874450683594, 'loss_4': 0.7581601142883301, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 17:05:37,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:37,192 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:46:49<13:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:44,514 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027097130194306374, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.575, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.022916460409760475, 'eval_loss_2': 0.0041806697845458984, 'eval_loss_3': -18.036537170410156, 'eval_loss_4': 0.3629266917705536, 'epoch': 25.26}
{'loss': 0.0174, 'grad_norm': 8.781839370727539, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.01447974517941475, 'loss_2': 0.002941131591796875, 'loss_3': -16.342411041259766, 'loss_4': 0.5604226589202881, 'epoch': 25.27}
{'loss': 0.0243, 'grad_norm': 15.430334091186523, 'learning_rate': 4.75e-06, 'loss_1': 0.02229287475347519, 'loss_2': 0.00201416015625, 'loss_3': -16.271224975585938, 'loss_4': 0.02067755162715912, 'epoch': 25.27}
{'loss': 0.0088, 'grad_norm': 5.040958404541016, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.006727606523782015, 'loss_2': 0.00205230712890625, 'loss_3': -16.110597610473633, 'loss_4': 0.2728669345378876, 'epoch': 25.28}
{'loss': 0.0046, 'grad_norm': 4.519731521606445, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.004422445315867662, 'loss_2': 0.00019240379333496094, 'loss_3': -15.922501564025879, 'loss_4': 0.34293657541275024, 'epoch': 25.28}
{'loss': 0.049, 'grad_norm': 13.124831199645996, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.04715884476900101, 'loss_2': 0.001804351806640625, 'loss_3': -16.027111053466797, 'loss_4': 0.6181329488754272, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 17:05:44,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:44,514 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:46:57<13:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:51,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026883810758590698, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.412, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02247139997780323, 'eval_loss_2': 0.004412412643432617, 'eval_loss_3': -18.03856658935547, 'eval_loss_4': 0.39592957496643066, 'epoch': 25.29}
{'loss': 0.0085, 'grad_norm': 5.718539237976074, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.006772537715733051, 'loss_2': 0.0016803741455078125, 'loss_3': -16.04868507385254, 'loss_4': 0.5410866737365723, 'epoch': 25.3}
{'loss': 0.0054, 'grad_norm': 4.594034194946289, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.004471711814403534, 'loss_2': 0.0009093284606933594, 'loss_3': -16.28047752380371, 'loss_4': 0.18594464659690857, 'epoch': 25.3}
{'loss': 0.0085, 'grad_norm': 4.684653282165527, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.006953238509595394, 'loss_2': 0.0015840530395507812, 'loss_3': -15.990554809570312, 'loss_4': 0.41335946321487427, 'epoch': 25.31}
{'loss': 0.0374, 'grad_norm': 11.8978271484375, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.035237859934568405, 'loss_2': 0.00214385986328125, 'loss_3': -16.161670684814453, 'loss_4': 0.6993146538734436, 'epoch': 25.31}
{'loss': 0.0101, 'grad_norm': 4.9354143142700195, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.008405440486967564, 'loss_2': 0.0016889572143554688, 'loss_3': -16.16347885131836, 'loss_4': 0.36734312772750854, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 17:05:51,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:51,840 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:04<13:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:05:59,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026316890493035316, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.32, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.022178422659635544, 'eval_loss_2': 0.004138469696044922, 'eval_loss_3': -18.038061141967773, 'eval_loss_4': 0.40734541416168213, 'epoch': 25.32}
{'loss': 0.0062, 'grad_norm': 4.613280296325684, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.0029566201847046614, 'loss_2': 0.003208160400390625, 'loss_3': -16.21206283569336, 'loss_4': 0.3763619065284729, 'epoch': 25.33}
{'loss': 0.0169, 'grad_norm': 8.669881820678711, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.01414581760764122, 'loss_2': 0.002716064453125, 'loss_3': -16.093233108520508, 'loss_4': 0.3621792793273926, 'epoch': 25.33}
{'loss': 0.0091, 'grad_norm': 5.613670349121094, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.00445080641657114, 'loss_2': 0.00460052490234375, 'loss_3': -16.295316696166992, 'loss_4': 0.5672269463539124, 'epoch': 25.34}
{'loss': 0.0066, 'grad_norm': 4.545014381408691, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.004025132395327091, 'loss_2': 0.002567291259765625, 'loss_3': -16.136077880859375, 'loss_4': 0.23262611031532288, 'epoch': 25.34}
{'loss': 0.0106, 'grad_norm': 4.902567386627197, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.005682946182787418, 'loss_2': 0.0048980712890625, 'loss_3': -16.408462524414062, 'loss_4': 0.35858583450317383, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 17:05:59,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:59,165 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:11<13:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:06,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026697134599089622, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.347, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.022660650312900543, 'eval_loss_2': 0.0040364861488342285, 'eval_loss_3': -18.04033660888672, 'eval_loss_4': 0.4382005035877228, 'epoch': 25.35}
{'loss': 0.0079, 'grad_norm': 5.028066635131836, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.006374082528054714, 'loss_2': 0.0015048980712890625, 'loss_3': -15.991804122924805, 'loss_4': 0.2766791880130768, 'epoch': 25.35}
{'loss': 0.0132, 'grad_norm': 7.598084926605225, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.012853226624429226, 'loss_2': 0.000385284423828125, 'loss_3': -16.27448272705078, 'loss_4': 0.8363670110702515, 'epoch': 25.36}
{'loss': 0.0048, 'grad_norm': 4.616409778594971, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.004799642134457827, 'loss_2': 1.5497207641601562e-06, 'loss_3': -16.2276611328125, 'loss_4': 0.14396122097969055, 'epoch': 25.37}
{'loss': 0.0355, 'grad_norm': 12.938401222229004, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.032788168638944626, 'loss_2': 0.002716064453125, 'loss_3': -16.22319793701172, 'loss_4': 0.5031328797340393, 'epoch': 25.37}
{'loss': 0.0085, 'grad_norm': 5.689773082733154, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.005866013467311859, 'loss_2': 0.002643585205078125, 'loss_3': -15.870930671691895, 'loss_4': -0.06132178008556366, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 17:06:06,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:06,494 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:19<13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:13,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028378605842590332, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.668, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.023811224848031998, 'eval_loss_2': 0.004567384719848633, 'eval_loss_3': -18.04901123046875, 'eval_loss_4': 0.48642125725746155, 'epoch': 25.38}
{'loss': 0.01, 'grad_norm': 5.500822067260742, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.006714390590786934, 'loss_2': 0.0032939910888671875, 'loss_3': -16.254480361938477, 'loss_4': 0.1893528699874878, 'epoch': 25.38}
{'loss': 0.0124, 'grad_norm': 9.183401107788086, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.011153556406497955, 'loss_2': 0.001270294189453125, 'loss_3': -15.978509902954102, 'loss_4': 0.3742900490760803, 'epoch': 25.39}
{'loss': 0.0081, 'grad_norm': 5.9009318351745605, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.007989907637238503, 'loss_2': 9.047985076904297e-05, 'loss_3': -16.152807235717773, 'loss_4': 0.745863676071167, 'epoch': 25.4}
{'loss': 0.0103, 'grad_norm': 7.291503429412842, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.008670725859701633, 'loss_2': 0.0016689300537109375, 'loss_3': -16.07177734375, 'loss_4': 0.1573769599199295, 'epoch': 25.4}
{'loss': 0.0154, 'grad_norm': 4.660330772399902, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.0056978208012878895, 'loss_2': 0.0097503662109375, 'loss_3': -16.18036651611328, 'loss_4': 0.8420919179916382, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 17:06:13,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:13,815 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:26<13:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:21,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02893822267651558, 'eval_runtime': 3.7821, 'eval_samples_per_second': 270.752, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.024085989221930504, 'eval_loss_2': 0.004852235317230225, 'eval_loss_3': -18.044504165649414, 'eval_loss_4': 0.5089375972747803, 'epoch': 25.41}
{'loss': 0.0133, 'grad_norm': 5.6948394775390625, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.009256966412067413, 'loss_2': 0.00403594970703125, 'loss_3': -16.16904067993164, 'loss_4': 0.602745771408081, 'epoch': 25.41}
{'loss': 0.0118, 'grad_norm': 5.035461902618408, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.00433630496263504, 'loss_2': 0.00750732421875, 'loss_3': -16.143552780151367, 'loss_4': 0.4914647936820984, 'epoch': 25.42}
{'loss': 0.0086, 'grad_norm': 7.284584045410156, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.008513912558555603, 'loss_2': 9.363889694213867e-05, 'loss_3': -16.06366729736328, 'loss_4': 0.3430430591106415, 'epoch': 25.42}
{'loss': 0.011, 'grad_norm': 6.766366004943848, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.008746996521949768, 'loss_2': 0.00225067138671875, 'loss_3': -16.179277420043945, 'loss_4': 0.9277703762054443, 'epoch': 25.43}
{'loss': 0.0139, 'grad_norm': 5.347625732421875, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.007245357614010572, 'loss_2': 0.006683349609375, 'loss_3': -16.328170776367188, 'loss_4': 0.3423188328742981, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 17:06:21,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:21,139 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:33<13:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:28,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029420459643006325, 'eval_runtime': 3.7844, 'eval_samples_per_second': 270.586, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02465648576617241, 'eval_loss_2': 0.004763975739479065, 'eval_loss_3': -18.05400848388672, 'eval_loss_4': 0.5430768132209778, 'epoch': 25.44}
{'loss': 0.012, 'grad_norm': 7.318855285644531, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.011874842457473278, 'loss_2': 0.00010013580322265625, 'loss_3': -16.17951202392578, 'loss_4': 0.56307452917099, 'epoch': 25.44}
{'loss': 0.0407, 'grad_norm': 16.658201217651367, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.037584345787763596, 'loss_2': 0.0031337738037109375, 'loss_3': -16.151103973388672, 'loss_4': 0.744303822517395, 'epoch': 25.45}
{'loss': 0.0116, 'grad_norm': 5.232751369476318, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.010524007491767406, 'loss_2': 0.0011167526245117188, 'loss_3': -16.207231521606445, 'loss_4': 0.9343013763427734, 'epoch': 25.45}
{'loss': 0.0096, 'grad_norm': 5.332912445068359, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.0069623724557459354, 'loss_2': 0.002620697021484375, 'loss_3': -15.992952346801758, 'loss_4': 0.11703406274318695, 'epoch': 25.46}
{'loss': 0.0078, 'grad_norm': 4.896308422088623, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.006367764435708523, 'loss_2': 0.001384735107421875, 'loss_3': -16.19717788696289, 'loss_4': 0.3678011894226074, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 17:06:28,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:28,465 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:47:41<13:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:06:35,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029546206817030907, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.547, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.024740641936659813, 'eval_loss_2': 0.004805564880371094, 'eval_loss_3': -18.062824249267578, 'eval_loss_4': 0.5865846872329712, 'epoch': 25.47}
{'loss': 0.0038, 'grad_norm': 4.936902046203613, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.0028504773508757353, 'loss_2': 0.00099945068359375, 'loss_3': -16.03679084777832, 'loss_4': 0.5274173021316528, 'epoch': 25.47}
{'loss': 0.0053, 'grad_norm': 4.587730884552002, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.0039001849945634604, 'loss_2': 0.0013704299926757812, 'loss_3': -16.1695556640625, 'loss_4': 0.3821537494659424, 'epoch': 25.48}
{'loss': 0.0084, 'grad_norm': 5.619649410247803, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.007028472144156694, 'loss_2': 0.001377105712890625, 'loss_3': -16.308902740478516, 'loss_4': 0.5116812586784363, 'epoch': 25.48}
{'loss': 0.0096, 'grad_norm': 4.486570358276367, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.00513235991820693, 'loss_2': 0.00446319580078125, 'loss_3': -16.141754150390625, 'loss_4': 0.5764203071594238, 'epoch': 25.49}
{'loss': 0.0071, 'grad_norm': 5.001087665557861, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.006154461298137903, 'loss_2': 0.000934600830078125, 'loss_3': -16.138912200927734, 'loss_4': 0.8679039478302002, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 17:06:35,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:35,784 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:47:48<13:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:06:43,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029488161206245422, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.307, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.02534915693104267, 'eval_loss_2': 0.0041390061378479, 'eval_loss_3': -18.067142486572266, 'eval_loss_4': 0.6409657597541809, 'epoch': 25.49}
{'loss': 0.0144, 'grad_norm': 5.658012866973877, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.010313565842807293, 'loss_2': 0.0041351318359375, 'loss_3': -16.060951232910156, 'loss_4': 0.6264643669128418, 'epoch': 25.5}
{'loss': 0.0195, 'grad_norm': 9.533236503601074, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.017418010160326958, 'loss_2': 0.002117156982421875, 'loss_3': -16.072837829589844, 'loss_4': 0.5500727891921997, 'epoch': 25.51}
{'loss': 0.009, 'grad_norm': 4.420790195465088, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.00351666659116745, 'loss_2': 0.005435943603515625, 'loss_3': -16.202896118164062, 'loss_4': 0.39316827058792114, 'epoch': 25.51}
{'loss': 0.0062, 'grad_norm': 4.628360271453857, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.003977771382778883, 'loss_2': 0.002185821533203125, 'loss_3': -16.1044921875, 'loss_4': 0.4980769157409668, 'epoch': 25.52}
{'loss': 0.0056, 'grad_norm': 4.209841251373291, 'learning_rate': 4.5e-06, 'loss_1': 0.002636122517287731, 'loss_2': 0.0029754638671875, 'loss_3': -16.236209869384766, 'loss_4': 0.6228382587432861, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 17:06:43,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:43,109 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:47:55<13:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:50,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029419710859656334, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.898, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.025404062122106552, 'eval_loss_2': 0.004015650600194931, 'eval_loss_3': -18.057018280029297, 'eval_loss_4': 0.6497178673744202, 'epoch': 25.52}
{'loss': 0.037, 'grad_norm': 13.762822151184082, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.035210803151130676, 'loss_2': 0.001739501953125, 'loss_3': -16.196727752685547, 'loss_4': 0.9207379221916199, 'epoch': 25.53}
{'loss': 0.0104, 'grad_norm': 6.218871593475342, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.009041186422109604, 'loss_2': 0.0013561248779296875, 'loss_3': -16.002187728881836, 'loss_4': 0.6935051679611206, 'epoch': 25.53}
{'loss': 0.0179, 'grad_norm': 9.524394989013672, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.014515248127281666, 'loss_2': 0.003360748291015625, 'loss_3': -16.092296600341797, 'loss_4': 0.6838359832763672, 'epoch': 25.54}
{'loss': 0.005, 'grad_norm': 5.579830646514893, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.004447274375706911, 'loss_2': 0.0005922317504882812, 'loss_3': -16.33004379272461, 'loss_4': 0.6813744306564331, 'epoch': 25.55}
{'loss': 0.0086, 'grad_norm': 4.398904323577881, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.0052163563668727875, 'loss_2': 0.00334930419921875, 'loss_3': -15.986793518066406, 'loss_4': 0.4121816158294678, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 17:06:50,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:50,445 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:03<13:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:06:57,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030040515586733818, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.702, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.025692835450172424, 'eval_loss_2': 0.004347681999206543, 'eval_loss_3': -18.052776336669922, 'eval_loss_4': 0.6427381634712219, 'epoch': 25.55}
{'loss': 0.0115, 'grad_norm': 5.411480903625488, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.009133574552834034, 'loss_2': 0.0023174285888671875, 'loss_3': -16.15507698059082, 'loss_4': 0.8693296909332275, 'epoch': 25.56}
{'loss': 0.0034, 'grad_norm': 4.776358604431152, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.0029068661388009787, 'loss_2': 0.0004677772521972656, 'loss_3': -15.96987533569336, 'loss_4': 0.5308722853660583, 'epoch': 25.56}
{'loss': 0.0154, 'grad_norm': 6.351036548614502, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.011927977204322815, 'loss_2': 0.003437042236328125, 'loss_3': -16.292131423950195, 'loss_4': 0.30466076731681824, 'epoch': 25.57}
{'loss': 0.0065, 'grad_norm': 4.476709365844727, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.005343826021999121, 'loss_2': 0.0011501312255859375, 'loss_3': -16.09186553955078, 'loss_4': 0.5831989049911499, 'epoch': 25.58}
{'loss': 0.008, 'grad_norm': 4.368153095245361, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.0029455905314534903, 'loss_2': 0.00504302978515625, 'loss_3': -16.19990348815918, 'loss_4': 0.4528977572917938, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 17:06:57,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:57,767 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:10<13:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:05,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030462119728326797, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.634, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.02618584595620632, 'eval_loss_2': 0.004276275634765625, 'eval_loss_3': -18.047527313232422, 'eval_loss_4': 0.6444417834281921, 'epoch': 25.58}
{'loss': 0.0084, 'grad_norm': 6.528240203857422, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.007904581725597382, 'loss_2': 0.0005025863647460938, 'loss_3': -16.284595489501953, 'loss_4': 0.5432142019271851, 'epoch': 25.59}
{'loss': 0.0078, 'grad_norm': 4.703596591949463, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.006142338737845421, 'loss_2': 0.0016717910766601562, 'loss_3': -16.309127807617188, 'loss_4': 0.36837324500083923, 'epoch': 25.59}
{'loss': 0.0093, 'grad_norm': 5.582369804382324, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.006888367235660553, 'loss_2': 0.002391815185546875, 'loss_3': -15.989849090576172, 'loss_4': 0.5265390872955322, 'epoch': 25.6}
{'loss': 0.0084, 'grad_norm': 4.582406044006348, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.004479837603867054, 'loss_2': 0.003936767578125, 'loss_3': -16.039548873901367, 'loss_4': 0.7029435634613037, 'epoch': 25.6}
{'loss': 0.009, 'grad_norm': 5.522217750549316, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.006867533549666405, 'loss_2': 0.0021209716796875, 'loss_3': -16.168617248535156, 'loss_4': 0.7133299112319946, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 17:07:05,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:05,081 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:17<12:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:12,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029639821499586105, 'eval_runtime': 3.7819, 'eval_samples_per_second': 270.762, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.02572168968617916, 'eval_loss_2': 0.0039181336760520935, 'eval_loss_3': -18.061294555664062, 'eval_loss_4': 0.6506156921386719, 'epoch': 25.61}
{'loss': 0.0134, 'grad_norm': 5.07174825668335, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.00575683917850256, 'loss_2': 0.00760650634765625, 'loss_3': -16.12396240234375, 'loss_4': 0.6565530300140381, 'epoch': 25.62}
{'loss': 0.0077, 'grad_norm': 4.191649436950684, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.0036025159060955048, 'loss_2': 0.004085540771484375, 'loss_3': -16.222797393798828, 'loss_4': 0.8982678651809692, 'epoch': 25.62}
{'loss': 0.0071, 'grad_norm': 5.033269882202148, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.005804150365293026, 'loss_2': 0.0012950897216796875, 'loss_3': -16.06590461730957, 'loss_4': 0.6894286274909973, 'epoch': 25.63}
{'loss': 0.0072, 'grad_norm': 5.279398441314697, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.006382364314049482, 'loss_2': 0.000858306884765625, 'loss_3': -16.28740692138672, 'loss_4': 0.519481897354126, 'epoch': 25.63}
{'loss': 0.0161, 'grad_norm': 6.453062534332275, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.013696638867259026, 'loss_2': 0.00237274169921875, 'loss_3': -16.148704528808594, 'loss_4': 0.9427288770675659, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 17:07:12,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:12,404 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:25<12:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:19,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028586069121956825, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.591, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02437291108071804, 'eval_loss_2': 0.004213158041238785, 'eval_loss_3': -18.063447952270508, 'eval_loss_4': 0.6391857862472534, 'epoch': 25.64}
{'loss': 0.0092, 'grad_norm': 5.018679141998291, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.007417483255267143, 'loss_2': 0.0017642974853515625, 'loss_3': -15.989331245422363, 'loss_4': 0.6541929841041565, 'epoch': 25.65}
{'loss': 0.0147, 'grad_norm': 5.571855068206787, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.006799277849495411, 'loss_2': 0.0078582763671875, 'loss_3': -16.039213180541992, 'loss_4': 0.11667798459529877, 'epoch': 25.65}
{'loss': 0.018, 'grad_norm': 5.501741409301758, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.011382242664694786, 'loss_2': 0.00659942626953125, 'loss_3': -16.19843292236328, 'loss_4': 0.5896252393722534, 'epoch': 25.66}
{'loss': 0.0142, 'grad_norm': 9.57229232788086, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.012803400866687298, 'loss_2': 0.0014276504516601562, 'loss_3': -15.964985847473145, 'loss_4': 0.8530353307723999, 'epoch': 25.66}
{'loss': 0.0103, 'grad_norm': 5.201189041137695, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.0068551329895854, 'loss_2': 0.0034160614013671875, 'loss_3': -15.964052200317383, 'loss_4': 0.5527322292327881, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 17:07:19,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:19,724 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:32<12:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:27,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029343273490667343, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.075, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02477579191327095, 'eval_loss_2': 0.004567481577396393, 'eval_loss_3': -18.06219482421875, 'eval_loss_4': 0.6213885545730591, 'epoch': 25.67}
{'loss': 0.0086, 'grad_norm': 5.323611736297607, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.006427762098610401, 'loss_2': 0.0022144317626953125, 'loss_3': -16.010658264160156, 'loss_4': 0.869169294834137, 'epoch': 25.67}
{'loss': 0.0114, 'grad_norm': 6.7634596824646, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.00812217965722084, 'loss_2': 0.003276824951171875, 'loss_3': -15.948347091674805, 'loss_4': 0.7325359582901001, 'epoch': 25.68}
{'loss': 0.0102, 'grad_norm': 5.173937797546387, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.0067749968729913235, 'loss_2': 0.003452301025390625, 'loss_3': -16.04705047607422, 'loss_4': 0.27590882778167725, 'epoch': 25.69}
{'loss': 0.0225, 'grad_norm': 11.14608383178711, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.01447769533842802, 'loss_2': 0.00797271728515625, 'loss_3': -16.070404052734375, 'loss_4': 0.4800350069999695, 'epoch': 25.69}
{'loss': 0.0266, 'grad_norm': 15.010271072387695, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.022830702364444733, 'loss_2': 0.003818511962890625, 'loss_3': -16.295879364013672, 'loss_4': 0.5232123136520386, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 17:07:27,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:27,051 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:48:39<12:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:34,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029533684253692627, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.482, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.024489521980285645, 'eval_loss_2': 0.005044162273406982, 'eval_loss_3': -18.061870574951172, 'eval_loss_4': 0.6064645051956177, 'epoch': 25.7}
{'loss': 0.007, 'grad_norm': 4.441585540771484, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.0045523266308009624, 'loss_2': 0.00247955322265625, 'loss_3': -16.266178131103516, 'loss_4': 0.7121184468269348, 'epoch': 25.7}
{'loss': 0.0133, 'grad_norm': 5.472682952880859, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.005603944882750511, 'loss_2': 0.00771331787109375, 'loss_3': -16.019248962402344, 'loss_4': 0.7998894453048706, 'epoch': 25.71}
{'loss': 0.0068, 'grad_norm': 4.307121276855469, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.0022345276083797216, 'loss_2': 0.0045166015625, 'loss_3': -16.041126251220703, 'loss_4': 0.5676722526550293, 'epoch': 25.72}
{'loss': 0.0334, 'grad_norm': 17.838172912597656, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.032529350370168686, 'loss_2': 0.0008955001831054688, 'loss_3': -16.13813591003418, 'loss_4': 0.3352641761302948, 'epoch': 25.72}
{'loss': 0.0048, 'grad_norm': 4.934429168701172, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.0037400387227535248, 'loss_2': 0.0010356903076171875, 'loss_3': -16.185558319091797, 'loss_4': -0.05262451991438866, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 17:07:34,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:34,375 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:48:47<12:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:41,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029020044952630997, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.398, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.023884331807494164, 'eval_loss_2': 0.005135715007781982, 'eval_loss_3': -18.051204681396484, 'eval_loss_4': 0.569738507270813, 'epoch': 25.73}
{'loss': 0.0114, 'grad_norm': 6.51118278503418, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.007908175699412823, 'loss_2': 0.00347900390625, 'loss_3': -16.204208374023438, 'loss_4': 0.3854691982269287, 'epoch': 25.73}
{'loss': 0.0046, 'grad_norm': 4.514311790466309, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.00381289329379797, 'loss_2': 0.0008111000061035156, 'loss_3': -16.21673011779785, 'loss_4': 0.5407519936561584, 'epoch': 25.74}
{'loss': 0.0077, 'grad_norm': 5.454530715942383, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.006093927659094334, 'loss_2': 0.0016069412231445312, 'loss_3': -16.16681480407715, 'loss_4': 0.36185523867607117, 'epoch': 25.74}
{'loss': 0.0158, 'grad_norm': 5.726537227630615, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.009973018430173397, 'loss_2': 0.005802154541015625, 'loss_3': -16.19784927368164, 'loss_4': 0.5147563219070435, 'epoch': 25.75}
{'loss': 0.0105, 'grad_norm': 4.6993327140808105, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.004386882297694683, 'loss_2': 0.0061492919921875, 'loss_3': -16.246076583862305, 'loss_4': 0.2731170058250427, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 17:07:41,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:41,701 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:48:54<12:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:49,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02800251916050911, 'eval_runtime': 3.7816, 'eval_samples_per_second': 270.783, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.02327372319996357, 'eval_loss_2': 0.004728794097900391, 'eval_loss_3': -18.04683494567871, 'eval_loss_4': 0.51156085729599, 'epoch': 25.76}
{'loss': 0.0063, 'grad_norm': 4.798447132110596, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.003618163289502263, 'loss_2': 0.002696990966796875, 'loss_3': -16.139812469482422, 'loss_4': 0.5120804905891418, 'epoch': 25.76}
{'loss': 0.0101, 'grad_norm': 4.96204948425293, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.006974018644541502, 'loss_2': 0.003162384033203125, 'loss_3': -15.921537399291992, 'loss_4': 0.27698424458503723, 'epoch': 25.77}
{'loss': 0.0132, 'grad_norm': 5.097867488861084, 'learning_rate': 4.25e-06, 'loss_1': 0.008595181629061699, 'loss_2': 0.00464630126953125, 'loss_3': -16.097537994384766, 'loss_4': 0.5174294710159302, 'epoch': 25.77}
{'loss': 0.0118, 'grad_norm': 4.328938961029053, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.007608023006469011, 'loss_2': 0.00421905517578125, 'loss_3': -16.118732452392578, 'loss_4': 0.24738240242004395, 'epoch': 25.78}
{'loss': 0.0093, 'grad_norm': 6.170337200164795, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.00864465069025755, 'loss_2': 0.0006618499755859375, 'loss_3': -16.003393173217773, 'loss_4': -0.010661035776138306, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 17:07:49,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:49,022 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:01<12:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:56,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02823156677186489, 'eval_runtime': 3.7827, 'eval_samples_per_second': 270.708, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.02388877049088478, 'eval_loss_2': 0.004342794418334961, 'eval_loss_3': -18.050617218017578, 'eval_loss_4': 0.5086526870727539, 'epoch': 25.78}
{'loss': 0.0162, 'grad_norm': 5.4949631690979, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.007819506339728832, 'loss_2': 0.0083465576171875, 'loss_3': -16.102127075195312, 'loss_4': 0.4686868190765381, 'epoch': 25.79}
{'loss': 0.0243, 'grad_norm': 8.776939392089844, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.024165501818060875, 'loss_2': 0.00011324882507324219, 'loss_3': -16.056400299072266, 'loss_4': 0.40316471457481384, 'epoch': 25.8}
{'loss': 0.0076, 'grad_norm': 5.29695463180542, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.004475044552236795, 'loss_2': 0.00311279296875, 'loss_3': -16.125333786010742, 'loss_4': 0.14099271595478058, 'epoch': 25.8}
{'loss': 0.0102, 'grad_norm': 5.320931911468506, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.006930906791239977, 'loss_2': 0.00328826904296875, 'loss_3': -16.153419494628906, 'loss_4': 0.4324105978012085, 'epoch': 25.81}
{'loss': 0.0071, 'grad_norm': 4.6331634521484375, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.004164868500083685, 'loss_2': 0.00295257568359375, 'loss_3': -16.010473251342773, 'loss_4': 0.2181658297777176, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 17:07:56,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:56,342 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:09<12:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:03,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027933010831475258, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.315, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0236862413585186, 'eval_loss_2': 0.004246771335601807, 'eval_loss_3': -18.05179214477539, 'eval_loss_4': 0.5097337365150452, 'epoch': 25.81}
{'loss': 0.011, 'grad_norm': 4.8966064453125, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.007004962768405676, 'loss_2': 0.003986358642578125, 'loss_3': -16.149869918823242, 'loss_4': 0.3300487995147705, 'epoch': 25.82}
{'loss': 0.0134, 'grad_norm': 7.014138221740723, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.013363365083932877, 'loss_2': 1.3828277587890625e-05, 'loss_3': -16.02767562866211, 'loss_4': 0.4342495799064636, 'epoch': 25.83}
{'loss': 0.0186, 'grad_norm': 8.798110961914062, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.01556254643946886, 'loss_2': 0.003070831298828125, 'loss_3': -16.250701904296875, 'loss_4': 0.39297932386398315, 'epoch': 25.83}
{'loss': 0.0035, 'grad_norm': 4.200283527374268, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.0034050638787448406, 'loss_2': 6.020069122314453e-05, 'loss_3': -16.15908432006836, 'loss_4': 0.3851495385169983, 'epoch': 25.84}
{'loss': 0.008, 'grad_norm': 5.762947082519531, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.007222880609333515, 'loss_2': 0.0007562637329101562, 'loss_3': -15.900001525878906, 'loss_4': 0.4347667098045349, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 17:08:03,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:03,674 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:16<12:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:08:10,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027595780789852142, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.379, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02332710288465023, 'eval_loss_2': 0.004268679767847061, 'eval_loss_3': -18.05594825744629, 'eval_loss_4': 0.5076966881752014, 'epoch': 25.84}
{'loss': 0.0036, 'grad_norm': 4.320542335510254, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.003352927044034004, 'loss_2': 0.00020945072174072266, 'loss_3': -16.222593307495117, 'loss_4': 0.5544831156730652, 'epoch': 25.85}
{'loss': 0.0099, 'grad_norm': 5.572480201721191, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.007276574149727821, 'loss_2': 0.0026721954345703125, 'loss_3': -16.221328735351562, 'loss_4': 0.10547424107789993, 'epoch': 25.85}
{'loss': 0.0101, 'grad_norm': 4.844974517822266, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.004824201110750437, 'loss_2': 0.00527191162109375, 'loss_3': -16.188068389892578, 'loss_4': 0.33423423767089844, 'epoch': 25.86}
{'loss': 0.0043, 'grad_norm': 4.881049633026123, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.0033820082899183035, 'loss_2': 0.0009298324584960938, 'loss_3': -16.12236213684082, 'loss_4': 0.4610840976238251, 'epoch': 25.87}
{'loss': 0.0089, 'grad_norm': 4.699253082275391, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.0076733180321753025, 'loss_2': 0.001216888427734375, 'loss_3': -16.061973571777344, 'loss_4': 0.5987920165061951, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 17:08:10,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:10,995 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:23<12:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:18,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027655677869915962, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.515, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.023841246962547302, 'eval_loss_2': 0.0038144290447235107, 'eval_loss_3': -18.05059242248535, 'eval_loss_4': 0.5285537242889404, 'epoch': 25.87}
{'loss': 0.0133, 'grad_norm': 6.1732635498046875, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.009150613099336624, 'loss_2': 0.004161834716796875, 'loss_3': -16.11571502685547, 'loss_4': 0.5882172584533691, 'epoch': 25.88}
{'loss': 0.0073, 'grad_norm': 5.134777545928955, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.0064735072664916515, 'loss_2': 0.0008087158203125, 'loss_3': -16.078922271728516, 'loss_4': 0.5939733982086182, 'epoch': 25.88}
{'loss': 0.0126, 'grad_norm': 5.14699125289917, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.01016910932958126, 'loss_2': 0.002410888671875, 'loss_3': -16.01100730895996, 'loss_4': 0.40691983699798584, 'epoch': 25.89}
{'loss': 0.0071, 'grad_norm': 4.537943363189697, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.0033669155091047287, 'loss_2': 0.0037555694580078125, 'loss_3': -16.257217407226562, 'loss_4': 0.602123498916626, 'epoch': 25.9}
{'loss': 0.0107, 'grad_norm': 5.99796724319458, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.005542377475649118, 'loss_2': 0.00518798828125, 'loss_3': -16.1472225189209, 'loss_4': 0.7762388586997986, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 17:08:18,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:18,323 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:49:31<12:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:25,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028050165623426437, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.567, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02446843311190605, 'eval_loss_2': 0.0035817325115203857, 'eval_loss_3': -18.055707931518555, 'eval_loss_4': 0.5460501313209534, 'epoch': 25.9}
{'loss': 0.0092, 'grad_norm': 4.694304943084717, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.002848416566848755, 'loss_2': 0.0063018798828125, 'loss_3': -16.182941436767578, 'loss_4': 0.666135847568512, 'epoch': 25.91}
{'loss': 0.0048, 'grad_norm': 4.8731865882873535, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.004442545585334301, 'loss_2': 0.0003497600555419922, 'loss_3': -16.21619415283203, 'loss_4': 0.5412068367004395, 'epoch': 25.91}
{'loss': 0.0083, 'grad_norm': 4.881040573120117, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.00597831467166543, 'loss_2': 0.002349853515625, 'loss_3': -15.94282341003418, 'loss_4': 0.3149600028991699, 'epoch': 25.92}
{'loss': 0.0081, 'grad_norm': 5.813651084899902, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.006662470288574696, 'loss_2': 0.0014476776123046875, 'loss_3': -16.14118003845215, 'loss_4': 0.6371119618415833, 'epoch': 25.92}
{'loss': 0.0127, 'grad_norm': 5.782186508178711, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.009061108343303204, 'loss_2': 0.0036144256591796875, 'loss_3': -16.206363677978516, 'loss_4': 0.164357528090477, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 17:08:25,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:25,646 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:49:38<11:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:08:32,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027480196207761765, 'eval_runtime': 3.7806, 'eval_samples_per_second': 270.859, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.024131102487444878, 'eval_loss_2': 0.0033490918576717377, 'eval_loss_3': -18.047990798950195, 'eval_loss_4': 0.5521589517593384, 'epoch': 25.93}
{'loss': 0.0105, 'grad_norm': 6.026670932769775, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.008154358714818954, 'loss_2': 0.0023860931396484375, 'loss_3': -16.073986053466797, 'loss_4': 0.31383559107780457, 'epoch': 25.94}
{'loss': 0.0086, 'grad_norm': 4.581337928771973, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.003486075671389699, 'loss_2': 0.00508880615234375, 'loss_3': -16.14794921875, 'loss_4': 0.32313400506973267, 'epoch': 25.94}
{'loss': 0.0108, 'grad_norm': 4.348409652709961, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.004422077909111977, 'loss_2': 0.006374359130859375, 'loss_3': -16.39286994934082, 'loss_4': 0.5151797533035278, 'epoch': 25.95}
{'loss': 0.0114, 'grad_norm': 5.236088752746582, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.00531788868829608, 'loss_2': 0.0060577392578125, 'loss_3': -16.094627380371094, 'loss_4': 0.1276688575744629, 'epoch': 25.95}
{'loss': 0.0083, 'grad_norm': 5.588183879852295, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.006033736281096935, 'loss_2': 0.00231170654296875, 'loss_3': -16.05419158935547, 'loss_4': 0.3889877200126648, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 17:08:32,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:32,958 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:49:45<11:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:08:40,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026476051658391953, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.67, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.022978005930781364, 'eval_loss_2': 0.0034980475902557373, 'eval_loss_3': -18.04169273376465, 'eval_loss_4': 0.5359164476394653, 'epoch': 25.96}
{'loss': 0.0121, 'grad_norm': 5.737821102142334, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.0057288664393126965, 'loss_2': 0.0063323974609375, 'loss_3': -15.976594924926758, 'loss_4': 0.3772605061531067, 'epoch': 25.97}
{'loss': 0.006, 'grad_norm': 4.172659873962402, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.005089474376291037, 'loss_2': 0.0009307861328125, 'loss_3': -16.06940269470215, 'loss_4': 0.07818603515625, 'epoch': 25.97}
{'loss': 0.0084, 'grad_norm': 5.3487701416015625, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.005254248157143593, 'loss_2': 0.003143310546875, 'loss_3': -16.0538330078125, 'loss_4': 0.5871281623840332, 'epoch': 25.98}
{'loss': 0.0078, 'grad_norm': 5.333287715911865, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.007221915293484926, 'loss_2': 0.0006055831909179688, 'loss_3': -15.738877296447754, 'loss_4': 0.6188860535621643, 'epoch': 25.98}
{'loss': 0.0077, 'grad_norm': 4.1497483253479, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.0023052673786878586, 'loss_2': 0.005397796630859375, 'loss_3': -16.08989143371582, 'loss_4': 0.11212456226348877, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 17:08:40,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:40,277 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:49:52<11:28,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 17:08:47,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026027508080005646, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.431, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.022718699648976326, 'eval_loss_2': 0.003308810293674469, 'eval_loss_3': -18.042530059814453, 'eval_loss_4': 0.4805428981781006, 'epoch': 25.99}
{'loss': 0.005, 'grad_norm': 4.6184916496276855, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.0024765958078205585, 'loss_2': 0.0025177001953125, 'loss_3': -16.029190063476562, 'loss_4': 0.2602776288986206, 'epoch': 25.99}
{'loss': 0.0101, 'grad_norm': 10.171403884887695, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.009195440448820591, 'loss_2': 0.0009412765502929688, 'loss_3': -16.34617805480957, 'loss_4': 0.5426912307739258, 'epoch': 26.0}
{'loss': 0.0098, 'grad_norm': 5.675001621246338, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.008008880540728569, 'loss_2': 0.0017910003662109375, 'loss_3': -16.29470443725586, 'loss_4': 0.9402148127555847, 'epoch': 26.01}
{'loss': 0.0088, 'grad_norm': 5.249781131744385, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.007054902613162994, 'loss_2': 0.001750946044921875, 'loss_3': -16.20539093017578, 'loss_4': 0.5150085091590881, 'epoch': 26.01}
{'loss': 0.0822, 'grad_norm': 7.633876800537109, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.07850626111030579, 'loss_2': 0.00372314453125, 'loss_3': -16.1876277923584, 'loss_4': 0.5528267621994019, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 17:08:47,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:47,289 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:00<11:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:08:54,639 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02593345381319523, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02262013591825962, 'eval_loss_2': 0.003313317894935608, 'eval_loss_3': -18.037429809570312, 'eval_loss_4': 0.4716189503669739, 'epoch': 26.02}
{'loss': 0.0174, 'grad_norm': 7.819720268249512, 'learning_rate': 4e-06, 'loss_1': 0.011472029611468315, 'loss_2': 0.00592041015625, 'loss_3': -16.243736267089844, 'loss_4': 0.5606123805046082, 'epoch': 26.02}
{'loss': 0.0096, 'grad_norm': 4.856655120849609, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.005633227527141571, 'loss_2': 0.003940582275390625, 'loss_3': -16.12761688232422, 'loss_4': 0.5001519918441772, 'epoch': 26.03}
{'loss': 0.0053, 'grad_norm': 4.919856548309326, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.0021346912253648043, 'loss_2': 0.003124237060546875, 'loss_3': -16.155323028564453, 'loss_4': -0.021295800805091858, 'epoch': 26.03}
{'loss': 0.0084, 'grad_norm': 4.3945112228393555, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.004711104556918144, 'loss_2': 0.0036640167236328125, 'loss_3': -16.197330474853516, 'loss_4': 0.6757727265357971, 'epoch': 26.04}
{'loss': 0.0049, 'grad_norm': 4.358974456787109, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.003904311917722225, 'loss_2': 0.0009927749633789062, 'loss_3': -16.020771026611328, 'loss_4': -0.08266689628362656, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 17:08:54,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:54,640 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:07<11:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:09:01,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026123549789190292, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.502, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.022702384740114212, 'eval_loss_2': 0.0034211650490760803, 'eval_loss_3': -18.04099464416504, 'eval_loss_4': 0.43339958786964417, 'epoch': 26.05}
{'loss': 0.0268, 'grad_norm': 12.141365051269531, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.025746440514922142, 'loss_2': 0.00109100341796875, 'loss_3': -16.162208557128906, 'loss_4': -0.14390075206756592, 'epoch': 26.05}
{'loss': 0.0679, 'grad_norm': 14.845829010009766, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.06516652554273605, 'loss_2': 0.00273895263671875, 'loss_3': -16.350067138671875, 'loss_4': 0.9772076606750488, 'epoch': 26.06}
{'loss': 0.0041, 'grad_norm': 4.699596881866455, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.003596551949158311, 'loss_2': 0.0005488395690917969, 'loss_3': -16.27662467956543, 'loss_4': 0.44942253828048706, 'epoch': 26.06}
{'loss': 0.004, 'grad_norm': 4.9554877281188965, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.0033747132401913404, 'loss_2': 0.0006241798400878906, 'loss_3': -16.122909545898438, 'loss_4': 0.26604539155960083, 'epoch': 26.07}
{'loss': 0.0086, 'grad_norm': 4.6416473388671875, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.004422307014465332, 'loss_2': 0.00421905517578125, 'loss_3': -16.061656951904297, 'loss_4': 0.1354096233844757, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 17:09:01,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:01,959 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:14<11:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:09:09,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025558149442076683, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.556, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.02220153622329235, 'eval_loss_2': 0.0033566132187843323, 'eval_loss_3': -18.041423797607422, 'eval_loss_4': 0.4281504154205322, 'epoch': 26.08}
{'loss': 0.0076, 'grad_norm': 5.343647480010986, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.005873061250895262, 'loss_2': 0.0017766952514648438, 'loss_3': -16.178123474121094, 'loss_4': 0.1974238008260727, 'epoch': 26.08}
{'loss': 0.0121, 'grad_norm': 6.801948547363281, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.01086614653468132, 'loss_2': 0.0012187957763671875, 'loss_3': -16.10592269897461, 'loss_4': 0.36541709303855896, 'epoch': 26.09}
{'loss': 0.0107, 'grad_norm': 5.746709823608398, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.009118767455220222, 'loss_2': 0.001590728759765625, 'loss_3': -16.398460388183594, 'loss_4': 0.805808424949646, 'epoch': 26.09}
{'loss': 0.0116, 'grad_norm': 6.001933574676514, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.006711546331644058, 'loss_2': 0.004871368408203125, 'loss_3': -16.16828155517578, 'loss_4': 0.04424787312746048, 'epoch': 26.1}
{'loss': 0.0042, 'grad_norm': 4.194145679473877, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.0021395618095993996, 'loss_2': 0.002086639404296875, 'loss_3': -16.156076431274414, 'loss_4': 0.2576329708099365, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 17:09:09,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:09,283 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:22<11:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:16,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02488165907561779, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.674, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.021533489227294922, 'eval_loss_2': 0.0033481717109680176, 'eval_loss_3': -18.04043960571289, 'eval_loss_4': 0.4288584887981415, 'epoch': 26.1}
{'loss': 0.0028, 'grad_norm': 4.371615409851074, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.0025921817868947983, 'loss_2': 0.00018358230590820312, 'loss_3': -16.32919692993164, 'loss_4': 0.5330711603164673, 'epoch': 26.11}
{'loss': 0.0066, 'grad_norm': 4.218472480773926, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.0036334393080323935, 'loss_2': 0.00301361083984375, 'loss_3': -16.21927261352539, 'loss_4': 0.3004521429538727, 'epoch': 26.12}
{'loss': 0.0079, 'grad_norm': 4.432868003845215, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.002637632191181183, 'loss_2': 0.00527191162109375, 'loss_3': -16.24688720703125, 'loss_4': 0.6049153804779053, 'epoch': 26.12}
{'loss': 0.0051, 'grad_norm': 4.893527507781982, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.002471520332619548, 'loss_2': 0.0026493072509765625, 'loss_3': -16.089399337768555, 'loss_4': 0.21292629837989807, 'epoch': 26.13}
{'loss': 0.0086, 'grad_norm': 6.885733604431152, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.00845374446362257, 'loss_2': 0.00014901161193847656, 'loss_3': -16.286834716796875, 'loss_4': 0.294765442609787, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 17:09:16,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:16,609 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:29<11:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:23,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0255049467086792, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.44, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021307799965143204, 'eval_loss_2': 0.004197143018245697, 'eval_loss_3': -18.039875030517578, 'eval_loss_4': 0.4041643738746643, 'epoch': 26.13}
{'loss': 0.0119, 'grad_norm': 5.390598297119141, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.008693460375070572, 'loss_2': 0.003253936767578125, 'loss_3': -15.91025447845459, 'loss_4': 0.42920970916748047, 'epoch': 26.14}
{'loss': 0.0104, 'grad_norm': 5.213487148284912, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.00684709008783102, 'loss_2': 0.003520965576171875, 'loss_3': -16.20560073852539, 'loss_4': 0.38403037190437317, 'epoch': 26.15}
{'loss': 0.0103, 'grad_norm': 4.761380672454834, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.005665182135999203, 'loss_2': 0.00458526611328125, 'loss_3': -15.994023323059082, 'loss_4': 0.14445379376411438, 'epoch': 26.15}
{'loss': 0.0108, 'grad_norm': 4.9242048263549805, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.004966216627508402, 'loss_2': 0.005855560302734375, 'loss_3': -16.179405212402344, 'loss_4': 0.5684497952461243, 'epoch': 26.16}
{'loss': 0.0141, 'grad_norm': 4.554399013519287, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.004305915907025337, 'loss_2': 0.009796142578125, 'loss_3': -16.106443405151367, 'loss_4': 0.4999845623970032, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 17:09:23,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:23,938 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:50:36<11:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:31,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02643521875143051, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.372, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.021490059792995453, 'eval_loss_2': 0.004945158958435059, 'eval_loss_3': -18.029678344726562, 'eval_loss_4': 0.3779860734939575, 'epoch': 26.16}
{'loss': 0.0085, 'grad_norm': 4.945853233337402, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.0038296773564070463, 'loss_2': 0.004642486572265625, 'loss_3': -15.976478576660156, 'loss_4': -0.04215855151414871, 'epoch': 26.17}
{'loss': 0.023, 'grad_norm': 7.784071445465088, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.019709713757038116, 'loss_2': 0.003299713134765625, 'loss_3': -16.141427993774414, 'loss_4': -0.03733563423156738, 'epoch': 26.17}
{'loss': 0.0137, 'grad_norm': 9.08365535736084, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.011796843260526657, 'loss_2': 0.0019502639770507812, 'loss_3': -16.19290542602539, 'loss_4': 0.3655678629875183, 'epoch': 26.18}
{'loss': 0.0054, 'grad_norm': 4.841416358947754, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.0042652259580791, 'loss_2': 0.0011663436889648438, 'loss_3': -16.144123077392578, 'loss_4': 0.18890529870986938, 'epoch': 26.19}
{'loss': 0.0047, 'grad_norm': 4.668810844421387, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.003860319498926401, 'loss_2': 0.000827789306640625, 'loss_3': -16.24666404724121, 'loss_4': 0.053687311708927155, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 17:09:31,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:31,265 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:50:44<11:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:09:38,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025302723050117493, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.678, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.021124886348843575, 'eval_loss_2': 0.004177838563919067, 'eval_loss_3': -18.030967712402344, 'eval_loss_4': 0.3246380686759949, 'epoch': 26.19}
{'loss': 0.0111, 'grad_norm': 4.46707820892334, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.003777778474614024, 'loss_2': 0.007354736328125, 'loss_3': -16.037338256835938, 'loss_4': 0.28509998321533203, 'epoch': 26.2}
{'loss': 0.0073, 'grad_norm': 4.130120277404785, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.0029351250268518925, 'loss_2': 0.004390716552734375, 'loss_3': -16.271766662597656, 'loss_4': 0.07434900104999542, 'epoch': 26.2}
{'loss': 0.0082, 'grad_norm': 4.441263675689697, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.0038508796133100986, 'loss_2': 0.00439453125, 'loss_3': -16.15867042541504, 'loss_4': -0.20802491903305054, 'epoch': 26.21}
{'loss': 0.0122, 'grad_norm': 5.486446857452393, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.006205447018146515, 'loss_2': 0.005947113037109375, 'loss_3': -16.119810104370117, 'loss_4': 0.4625338315963745, 'epoch': 26.22}
{'loss': 0.0066, 'grad_norm': 4.4793524742126465, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.003914986737072468, 'loss_2': 0.0027313232421875, 'loss_3': -16.027938842773438, 'loss_4': 0.17172566056251526, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 17:09:38,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:38,584 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:50:51<11:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:09:45,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024928981438279152, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.388, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02169651724398136, 'eval_loss_2': 0.0032324641942977905, 'eval_loss_3': -18.04094886779785, 'eval_loss_4': 0.2789514660835266, 'epoch': 26.22}
{'loss': 0.0078, 'grad_norm': 4.674282073974609, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.004415234085172415, 'loss_2': 0.003421783447265625, 'loss_3': -15.945768356323242, 'loss_4': 0.6469599604606628, 'epoch': 26.23}
{'loss': 0.0061, 'grad_norm': 4.588059425354004, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.0038405382074415684, 'loss_2': 0.00226593017578125, 'loss_3': -16.01231575012207, 'loss_4': 0.3053799271583557, 'epoch': 26.23}
{'loss': 0.0118, 'grad_norm': 5.8738627433776855, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.009993568062782288, 'loss_2': 0.0018434524536132812, 'loss_3': -16.06157684326172, 'loss_4': 0.29106605052948, 'epoch': 26.24}
{'loss': 0.0063, 'grad_norm': 4.553431034088135, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.004657675977796316, 'loss_2': 0.001659393310546875, 'loss_3': -16.234970092773438, 'loss_4': 0.27097758650779724, 'epoch': 26.24}
{'loss': 0.0059, 'grad_norm': 4.539875507354736, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.0017753296997398138, 'loss_2': 0.00415802001953125, 'loss_3': -16.11498260498047, 'loss_4': 0.1768030822277069, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 17:09:45,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:45,909 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:50:58<11:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:09:53,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02516363002359867, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.576, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.021518558263778687, 'eval_loss_2': 0.003645069897174835, 'eval_loss_3': -18.035682678222656, 'eval_loss_4': 0.2459879070520401, 'epoch': 26.25}
{'loss': 0.0146, 'grad_norm': 7.1394572257995605, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.009719778783619404, 'loss_2': 0.004924774169921875, 'loss_3': -15.867449760437012, 'loss_4': -0.012374602258205414, 'epoch': 26.26}
{'loss': 0.0067, 'grad_norm': 4.263398170471191, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.004323848057538271, 'loss_2': 0.0023651123046875, 'loss_3': -16.304187774658203, 'loss_4': 0.12736493349075317, 'epoch': 26.26}
{'loss': 0.0143, 'grad_norm': 5.792778491973877, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.010285962373018265, 'loss_2': 0.004058837890625, 'loss_3': -16.094533920288086, 'loss_4': 0.241792693734169, 'epoch': 26.27}
{'loss': 0.0075, 'grad_norm': 5.80246114730835, 'learning_rate': 3.75e-06, 'loss_1': 0.005979485809803009, 'loss_2': 0.0015363693237304688, 'loss_3': -16.180522918701172, 'loss_4': -0.1882646232843399, 'epoch': 26.27}
{'loss': 0.0132, 'grad_norm': 4.604808330535889, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.00302383815869689, 'loss_2': 0.01013946533203125, 'loss_3': -16.180038452148438, 'loss_4': 0.011885229498147964, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 17:09:53,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:53,227 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:05<10:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:10:00,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025530319660902023, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.522, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.021335257217288017, 'eval_loss_2': 0.004195064306259155, 'eval_loss_3': -18.040687561035156, 'eval_loss_4': 0.2191709727048874, 'epoch': 26.28}
{'loss': 0.0126, 'grad_norm': 4.5312628746032715, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.006103078834712505, 'loss_2': 0.00646209716796875, 'loss_3': -16.191539764404297, 'loss_4': 0.003717578947544098, 'epoch': 26.28}
{'loss': 0.0063, 'grad_norm': 4.385985374450684, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.004371880553662777, 'loss_2': 0.0019359588623046875, 'loss_3': -16.024581909179688, 'loss_4': -0.15981373190879822, 'epoch': 26.29}
{'loss': 0.0776, 'grad_norm': 14.362792015075684, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.07542567700147629, 'loss_2': 0.00214385986328125, 'loss_3': -16.13119888305664, 'loss_4': 0.4677477478981018, 'epoch': 26.3}
{'loss': 0.0108, 'grad_norm': 4.750671863555908, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.003746821079403162, 'loss_2': 0.0070343017578125, 'loss_3': -15.996094703674316, 'loss_4': 0.11741312593221664, 'epoch': 26.3}
{'loss': 0.0104, 'grad_norm': 5.93646240234375, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.007637310773134232, 'loss_2': 0.0028018951416015625, 'loss_3': -16.02908706665039, 'loss_4': -0.020859017968177795, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 17:10:00,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:00,548 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:13<10:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:07,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026885585859417915, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.979, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02243049629032612, 'eval_loss_2': 0.004455089569091797, 'eval_loss_3': -18.0426082611084, 'eval_loss_4': 0.18535462021827698, 'epoch': 26.31}
{'loss': 0.0122, 'grad_norm': 4.6118669509887695, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.003019327064976096, 'loss_2': 0.00914764404296875, 'loss_3': -16.434505462646484, 'loss_4': 0.22740812599658966, 'epoch': 26.31}
{'loss': 0.0164, 'grad_norm': 6.389667987823486, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.00935388170182705, 'loss_2': 0.0070648193359375, 'loss_3': -16.084579467773438, 'loss_4': 0.1935824602842331, 'epoch': 26.32}
{'loss': 0.0078, 'grad_norm': 5.012596130371094, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.005306799430400133, 'loss_2': 0.002490997314453125, 'loss_3': -16.235902786254883, 'loss_4': 0.47837841510772705, 'epoch': 26.33}
{'loss': 0.01, 'grad_norm': 5.917755603790283, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.006478834897279739, 'loss_2': 0.003482818603515625, 'loss_3': -15.974940299987793, 'loss_4': -0.31041890382766724, 'epoch': 26.33}
{'loss': 0.0163, 'grad_norm': 6.20136022567749, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.013158129528164864, 'loss_2': 0.0031261444091796875, 'loss_3': -15.982131958007812, 'loss_4': -0.025777079164981842, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 17:10:07,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:07,884 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:20<10:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:15,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027023110538721085, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.568, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02278939262032509, 'eval_loss_2': 0.004233717918395996, 'eval_loss_3': -18.049962997436523, 'eval_loss_4': 0.17426398396492004, 'epoch': 26.34}
{'loss': 0.0072, 'grad_norm': 4.474146842956543, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.006067965645343065, 'loss_2': 0.0011014938354492188, 'loss_3': -16.086660385131836, 'loss_4': 0.41677194833755493, 'epoch': 26.34}
{'loss': 0.0081, 'grad_norm': 4.753908634185791, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.005127508193254471, 'loss_2': 0.0029392242431640625, 'loss_3': -16.182235717773438, 'loss_4': 0.1586742103099823, 'epoch': 26.35}
{'loss': 0.0125, 'grad_norm': 6.983829975128174, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.010272689163684845, 'loss_2': 0.00220489501953125, 'loss_3': -16.057830810546875, 'loss_4': 0.20208251476287842, 'epoch': 26.35}
{'loss': 0.0057, 'grad_norm': 4.9728803634643555, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.00379393738694489, 'loss_2': 0.00191497802734375, 'loss_3': -16.164474487304688, 'loss_4': 0.35828694701194763, 'epoch': 26.36}
{'loss': 0.0105, 'grad_norm': 5.694372653961182, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.0062584299594163895, 'loss_2': 0.00423431396484375, 'loss_3': -16.323856353759766, 'loss_4': -0.06146194785833359, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 17:10:15,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:15,207 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:27<10:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:22,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0277000293135643, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.53, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.02334844134747982, 'eval_loss_2': 0.004351586103439331, 'eval_loss_3': -18.046295166015625, 'eval_loss_4': 0.17134083807468414, 'epoch': 26.37}
{'loss': 0.0134, 'grad_norm': 7.470192909240723, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.010592092759907246, 'loss_2': 0.0028362274169921875, 'loss_3': -16.115772247314453, 'loss_4': 0.005195487290620804, 'epoch': 26.37}
{'loss': 0.0098, 'grad_norm': 5.733828067779541, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.008966540917754173, 'loss_2': 0.0008425712585449219, 'loss_3': -16.230199813842773, 'loss_4': 0.05092152953147888, 'epoch': 26.38}
{'loss': 0.0284, 'grad_norm': 16.112140655517578, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.027038181200623512, 'loss_2': 0.00140380859375, 'loss_3': -16.18482208251953, 'loss_4': -0.036205753684043884, 'epoch': 26.38}
{'loss': 0.0232, 'grad_norm': 18.347763061523438, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.0228740107268095, 'loss_2': 0.0002930164337158203, 'loss_3': -16.25530433654785, 'loss_4': 0.007031671702861786, 'epoch': 26.39}
{'loss': 0.0096, 'grad_norm': 4.618494510650635, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.0075637041591107845, 'loss_2': 0.0020198822021484375, 'loss_3': -16.120532989501953, 'loss_4': -0.06003902107477188, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 17:10:22,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:22,534 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:51:35<10:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:29,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026876788586378098, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.622, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.022320611402392387, 'eval_loss_2': 0.004556179046630859, 'eval_loss_3': -18.04689598083496, 'eval_loss_4': 0.19324083626270294, 'epoch': 26.4}
{'loss': 0.006, 'grad_norm': 4.843298435211182, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.0037815796677023172, 'loss_2': 0.002239227294921875, 'loss_3': -16.15371322631836, 'loss_4': 0.21940532326698303, 'epoch': 26.4}
{'loss': 0.0075, 'grad_norm': 6.851456642150879, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.006508810445666313, 'loss_2': 0.0009603500366210938, 'loss_3': -16.08229637145996, 'loss_4': 0.2204376757144928, 'epoch': 26.41}
{'loss': 0.016, 'grad_norm': 5.553370952606201, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.010398557409644127, 'loss_2': 0.005645751953125, 'loss_3': -16.252063751220703, 'loss_4': 0.385440468788147, 'epoch': 26.41}
{'loss': 0.0066, 'grad_norm': 4.859310626983643, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.004242417868226767, 'loss_2': 0.002307891845703125, 'loss_3': -16.065336227416992, 'loss_4': 0.10855920612812042, 'epoch': 26.42}
{'loss': 0.0091, 'grad_norm': 4.800784111022949, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.004038812126964331, 'loss_2': 0.005016326904296875, 'loss_3': -16.274799346923828, 'loss_4': 0.023518718779087067, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 17:10:29,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:29,863 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:51:42<10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:37,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026966486126184464, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.475, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.022485021501779556, 'eval_loss_2': 0.004481464624404907, 'eval_loss_3': -18.046728134155273, 'eval_loss_4': 0.19309595227241516, 'epoch': 26.42}
{'loss': 0.0145, 'grad_norm': 6.415757656097412, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.014082320034503937, 'loss_2': 0.0003879070281982422, 'loss_3': -16.002531051635742, 'loss_4': 0.07907825708389282, 'epoch': 26.43}
{'loss': 0.004, 'grad_norm': 4.549282550811768, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.0034243629779666662, 'loss_2': 0.0005550384521484375, 'loss_3': -16.124801635742188, 'loss_4': -0.1963910460472107, 'epoch': 26.44}
{'loss': 0.0122, 'grad_norm': 6.838842391967773, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.011587406508624554, 'loss_2': 0.000629425048828125, 'loss_3': -16.091842651367188, 'loss_4': 0.46685683727264404, 'epoch': 26.44}
{'loss': 0.0091, 'grad_norm': 5.638152599334717, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.006299705244600773, 'loss_2': 0.0027866363525390625, 'loss_3': -16.34428596496582, 'loss_4': 0.37625205516815186, 'epoch': 26.45}
{'loss': 0.0186, 'grad_norm': 8.680673599243164, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.014805909246206284, 'loss_2': 0.00376129150390625, 'loss_3': -16.123533248901367, 'loss_4': -0.3204442858695984, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 17:10:37,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:37,193 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:51:49<10:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:44,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027064651250839233, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.467, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.022868042811751366, 'eval_loss_2': 0.0041966065764427185, 'eval_loss_3': -18.048158645629883, 'eval_loss_4': 0.1731666624546051, 'epoch': 26.45}
{'loss': 0.0115, 'grad_norm': 6.3448944091796875, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.008466514758765697, 'loss_2': 0.003063201904296875, 'loss_3': -16.243377685546875, 'loss_4': 0.48114103078842163, 'epoch': 26.46}
{'loss': 0.0082, 'grad_norm': 4.649156093597412, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.004975736606866121, 'loss_2': 0.003246307373046875, 'loss_3': -15.998453140258789, 'loss_4': -0.17294162511825562, 'epoch': 26.47}
{'loss': 0.0052, 'grad_norm': 4.832727432250977, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.004206510726362467, 'loss_2': 0.001007080078125, 'loss_3': -16.054399490356445, 'loss_4': 0.21890880167484283, 'epoch': 26.47}
{'loss': 0.0072, 'grad_norm': 4.477068901062012, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.003069056896492839, 'loss_2': 0.004150390625, 'loss_3': -16.146156311035156, 'loss_4': -0.23376159369945526, 'epoch': 26.48}
{'loss': 0.008, 'grad_norm': 4.958326816558838, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.0046492028050124645, 'loss_2': 0.0033111572265625, 'loss_3': -16.14011001586914, 'loss_4': -0.13777315616607666, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 17:10:44,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:44,520 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:51:57<10:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:10:51,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027054963633418083, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.519, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.023304255679249763, 'eval_loss_2': 0.0037507079541683197, 'eval_loss_3': -18.052703857421875, 'eval_loss_4': 0.15693645179271698, 'epoch': 26.48}
{'loss': 0.0075, 'grad_norm': 4.82314920425415, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.005449327640235424, 'loss_2': 0.0020999908447265625, 'loss_3': -16.058015823364258, 'loss_4': 0.007902964949607849, 'epoch': 26.49}
{'loss': 0.0142, 'grad_norm': 5.029074668884277, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.007052089553326368, 'loss_2': 0.00714874267578125, 'loss_3': -16.181657791137695, 'loss_4': 0.48220112919807434, 'epoch': 26.49}
{'loss': 0.0061, 'grad_norm': 4.816722393035889, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.003519973950460553, 'loss_2': 0.00258636474609375, 'loss_3': -16.050003051757812, 'loss_4': -0.005503349006175995, 'epoch': 26.5}
{'loss': 0.0145, 'grad_norm': 6.164849281311035, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.008781490847468376, 'loss_2': 0.00572967529296875, 'loss_3': -16.24918556213379, 'loss_4': 0.2178037166595459, 'epoch': 26.51}
{'loss': 0.005, 'grad_norm': 4.676451683044434, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.004575960338115692, 'loss_2': 0.0004673004150390625, 'loss_3': -16.312044143676758, 'loss_4': 0.27676963806152344, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 17:10:51,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:51,834 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:04<10:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:10:59,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027496082708239555, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.634, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.023883378133177757, 'eval_loss_2': 0.003612704575061798, 'eval_loss_3': -18.04690933227539, 'eval_loss_4': 0.10984731465578079, 'epoch': 26.51}
{'loss': 0.004, 'grad_norm': 4.38468074798584, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.0030245252419263124, 'loss_2': 0.0009899139404296875, 'loss_3': -16.294139862060547, 'loss_4': -0.3039979636669159, 'epoch': 26.52}
{'loss': 0.0163, 'grad_norm': 9.885152816772461, 'learning_rate': 3.5e-06, 'loss_1': 0.013555601239204407, 'loss_2': 0.002777099609375, 'loss_3': -16.24587631225586, 'loss_4': 0.2435944825410843, 'epoch': 26.52}
{'loss': 0.0145, 'grad_norm': 5.6232757568359375, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.006097381003201008, 'loss_2': 0.0083770751953125, 'loss_3': -16.332189559936523, 'loss_4': 0.27022090554237366, 'epoch': 26.53}
{'loss': 0.0122, 'grad_norm': 5.465086936950684, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.007463489659130573, 'loss_2': 0.004688262939453125, 'loss_3': -16.058794021606445, 'loss_4': 0.5483100414276123, 'epoch': 26.53}
{'loss': 0.0121, 'grad_norm': 5.584087371826172, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.009885123930871487, 'loss_2': 0.002178192138671875, 'loss_3': -16.361398696899414, 'loss_4': -0.07855867594480515, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 17:10:59,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:59,155 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:12<10:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:11:06,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027990011498332024, 'eval_runtime': 3.9832, 'eval_samples_per_second': 257.078, 'eval_steps_per_second': 4.017, 'eval_loss_1': 0.023839980363845825, 'eval_loss_2': 0.004150032997131348, 'eval_loss_3': -18.04561424255371, 'eval_loss_4': 0.056157033890485764, 'epoch': 26.54}
{'loss': 0.0109, 'grad_norm': 4.514729022979736, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.002544939983636141, 'loss_2': 0.00832366943359375, 'loss_3': -15.995235443115234, 'loss_4': 0.05085048824548721, 'epoch': 26.55}
{'loss': 0.0123, 'grad_norm': 6.582544326782227, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.009948316030204296, 'loss_2': 0.0023365020751953125, 'loss_3': -16.242023468017578, 'loss_4': 0.15348589420318604, 'epoch': 26.55}
{'loss': 0.0082, 'grad_norm': 4.255282878875732, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.0050110709853470325, 'loss_2': 0.00321197509765625, 'loss_3': -16.302656173706055, 'loss_4': 0.22726312279701233, 'epoch': 26.56}
{'loss': 0.0035, 'grad_norm': 4.6120686531066895, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.002388620749115944, 'loss_2': 0.001148223876953125, 'loss_3': -16.136545181274414, 'loss_4': -0.032117538154125214, 'epoch': 26.56}
{'loss': 0.0073, 'grad_norm': 6.5009002685546875, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.005799469072371721, 'loss_2': 0.0015106201171875, 'loss_3': -16.293325424194336, 'loss_4': 0.1999412477016449, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 17:11:06,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:06,674 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:19<10:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:14,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028122570365667343, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.042, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.023731855675578117, 'eval_loss_2': 0.004390716552734375, 'eval_loss_3': -18.053955078125, 'eval_loss_4': 0.012682618573307991, 'epoch': 26.57}
{'loss': 0.0122, 'grad_norm': 6.641003131866455, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.010966327972710133, 'loss_2': 0.00119781494140625, 'loss_3': -16.0955867767334, 'loss_4': -0.1801910698413849, 'epoch': 26.58}
{'loss': 0.0324, 'grad_norm': 13.547595024108887, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.02541900798678398, 'loss_2': 0.00702667236328125, 'loss_3': -16.199613571166992, 'loss_4': 0.21531350910663605, 'epoch': 26.58}
{'loss': 0.0065, 'grad_norm': 4.65820837020874, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.0026590884663164616, 'loss_2': 0.0038242340087890625, 'loss_3': -16.099836349487305, 'loss_4': -0.36145517230033875, 'epoch': 26.59}
{'loss': 0.0144, 'grad_norm': 12.420053482055664, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.01405242644250393, 'loss_2': 0.0003314018249511719, 'loss_3': -16.170808792114258, 'loss_4': -0.23143784701824188, 'epoch': 26.59}
{'loss': 0.0111, 'grad_norm': 8.092430114746094, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.011050399392843246, 'loss_2': 5.429983139038086e-05, 'loss_3': -16.207530975341797, 'loss_4': -0.12243982404470444, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 17:11:14,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:14,002 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:26<10:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:11:21,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028578869998455048, 'eval_runtime': 3.7848, 'eval_samples_per_second': 270.557, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.02416590042412281, 'eval_loss_2': 0.0044129714369773865, 'eval_loss_3': -18.054689407348633, 'eval_loss_4': -0.013384995982050896, 'epoch': 26.6}
{'loss': 0.0086, 'grad_norm': 5.770410060882568, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.00703847361728549, 'loss_2': 0.001544952392578125, 'loss_3': -16.160879135131836, 'loss_4': -0.08176523447036743, 'epoch': 26.6}
{'loss': 0.0048, 'grad_norm': 4.94337272644043, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.003899849019944668, 'loss_2': 0.0009298324584960938, 'loss_3': -15.990678787231445, 'loss_4': -0.497121661901474, 'epoch': 26.61}
{'loss': 0.0073, 'grad_norm': 4.4555206298828125, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.004977219272404909, 'loss_2': 0.00228118896484375, 'loss_3': -16.222373962402344, 'loss_4': -0.16132661700248718, 'epoch': 26.62}
{'loss': 0.0119, 'grad_norm': 5.562324523925781, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.008607229217886925, 'loss_2': 0.003322601318359375, 'loss_3': -16.10455894470215, 'loss_4': -0.27369415760040283, 'epoch': 26.62}
{'loss': 0.0064, 'grad_norm': 4.62673807144165, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.0032941200770437717, 'loss_2': 0.003082275390625, 'loss_3': -16.031890869140625, 'loss_4': -0.3923218548297882, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 17:11:21,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:21,322 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:52:34<09:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:28,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029097996652126312, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.02503156289458275, 'eval_loss_2': 0.004066437482833862, 'eval_loss_3': -18.0584716796875, 'eval_loss_4': -0.03863678500056267, 'epoch': 26.63}
{'loss': 0.0057, 'grad_norm': 4.370937347412109, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.005084590055048466, 'loss_2': 0.0006093978881835938, 'loss_3': -16.113191604614258, 'loss_4': -0.2901269793510437, 'epoch': 26.63}
{'loss': 0.0158, 'grad_norm': 4.433010578155518, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.004904631525278091, 'loss_2': 0.0108489990234375, 'loss_3': -16.286508560180664, 'loss_4': -0.06943850219249725, 'epoch': 26.64}
{'loss': 0.0073, 'grad_norm': 4.385528087615967, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.00574732618406415, 'loss_2': 0.001598358154296875, 'loss_3': -15.991791725158691, 'loss_4': -0.4884793162345886, 'epoch': 26.65}
{'loss': 0.0054, 'grad_norm': 4.722586154937744, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.0033135246485471725, 'loss_2': 0.0020923614501953125, 'loss_3': -16.182750701904297, 'loss_4': -0.13021542131900787, 'epoch': 26.65}
{'loss': 0.0188, 'grad_norm': 9.44202995300293, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.016675550490617752, 'loss_2': 0.0021648406982421875, 'loss_3': -16.15502166748047, 'loss_4': -0.04232874512672424, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 17:11:28,656 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:28,656 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:52:41<09:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:35,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029837701469659805, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.525, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.025902006775140762, 'eval_loss_2': 0.003935694694519043, 'eval_loss_3': -18.055187225341797, 'eval_loss_4': -0.053167350590229034, 'epoch': 26.66}
{'loss': 0.0057, 'grad_norm': 4.954267978668213, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.003849331522360444, 'loss_2': 0.0018033981323242188, 'loss_3': -16.155790328979492, 'loss_4': -0.16793672740459442, 'epoch': 26.66}
{'loss': 0.0078, 'grad_norm': 4.821744918823242, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.004485053010284901, 'loss_2': 0.0033111572265625, 'loss_3': -16.214351654052734, 'loss_4': -0.25384950637817383, 'epoch': 26.67}
{'loss': 0.0033, 'grad_norm': 4.680851459503174, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.002747710794210434, 'loss_2': 0.000576019287109375, 'loss_3': -16.293657302856445, 'loss_4': -0.34741631150245667, 'epoch': 26.67}
{'loss': 0.0042, 'grad_norm': 4.29537296295166, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.002601560205221176, 'loss_2': 0.0016002655029296875, 'loss_3': -16.144184112548828, 'loss_4': -0.30770939588546753, 'epoch': 26.68}
{'loss': 0.0029, 'grad_norm': 5.093210220336914, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.002846467075869441, 'loss_2': 5.996227264404297e-05, 'loss_3': -16.238384246826172, 'loss_4': 0.2729336619377136, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 17:11:35,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:35,985 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:52:48<09:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:43,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029695168137550354, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.671, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.025252820923924446, 'eval_loss_2': 0.004442349076271057, 'eval_loss_3': -18.054744720458984, 'eval_loss_4': -0.10672949999570847, 'epoch': 26.69}
{'loss': 0.0041, 'grad_norm': 4.301924228668213, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.004071263130754232, 'loss_2': 5.125999450683594e-05, 'loss_3': -16.14351463317871, 'loss_4': -0.36227181553840637, 'epoch': 26.69}
{'loss': 0.012, 'grad_norm': 4.532784461975098, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0033881962299346924, 'loss_2': 0.00858306884765625, 'loss_3': -16.226848602294922, 'loss_4': -0.35111749172210693, 'epoch': 26.7}
{'loss': 0.015, 'grad_norm': 6.332825183868408, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.012381653301417828, 'loss_2': 0.00262451171875, 'loss_3': -16.19462776184082, 'loss_4': 0.19354228675365448, 'epoch': 26.7}
{'loss': 0.011, 'grad_norm': 5.525928974151611, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.009545763954520226, 'loss_2': 0.0014257431030273438, 'loss_3': -16.168598175048828, 'loss_4': -0.08822237700223923, 'epoch': 26.71}
{'loss': 0.0049, 'grad_norm': 4.70903205871582, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.0031810004729777575, 'loss_2': 0.0016918182373046875, 'loss_3': -16.356124877929688, 'loss_4': -0.12921957671642303, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 17:11:43,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:43,308 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:52:56<09:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:11:50,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03013443574309349, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.563, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02572961337864399, 'eval_loss_2': 0.004404820501804352, 'eval_loss_3': -18.0554141998291, 'eval_loss_4': -0.13455963134765625, 'epoch': 26.72}
{'loss': 0.0041, 'grad_norm': 4.5639824867248535, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.00393268559128046, 'loss_2': 0.00016200542449951172, 'loss_3': -16.085617065429688, 'loss_4': -0.2538117468357086, 'epoch': 26.72}
{'loss': 0.0066, 'grad_norm': 4.825173854827881, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.003111055586487055, 'loss_2': 0.0034427642822265625, 'loss_3': -16.312129974365234, 'loss_4': 0.0015778765082359314, 'epoch': 26.73}
{'loss': 0.0096, 'grad_norm': 5.314016819000244, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.00809429120272398, 'loss_2': 0.0015316009521484375, 'loss_3': -16.295228958129883, 'loss_4': 0.19586443901062012, 'epoch': 26.73}
{'loss': 0.0081, 'grad_norm': 4.608692646026611, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.002707116538658738, 'loss_2': 0.005420684814453125, 'loss_3': -16.355377197265625, 'loss_4': -0.21608403325080872, 'epoch': 26.74}
{'loss': 0.0112, 'grad_norm': 4.880212306976318, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.007170709315687418, 'loss_2': 0.004058837890625, 'loss_3': -16.372241973876953, 'loss_4': 0.16404320299625397, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 17:11:50,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:50,626 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:03<09:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:11:57,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029745297506451607, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.201, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.025576727464795113, 'eval_loss_2': 0.004168570041656494, 'eval_loss_3': -18.068483352661133, 'eval_loss_4': -0.17151302099227905, 'epoch': 26.74}
{'loss': 0.0079, 'grad_norm': 6.603302001953125, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.007819178514182568, 'loss_2': 0.00011849403381347656, 'loss_3': -16.039539337158203, 'loss_4': -0.373676598072052, 'epoch': 26.75}
{'loss': 0.0048, 'grad_norm': 4.351991653442383, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.0023303127381950617, 'loss_2': 0.0024547576904296875, 'loss_3': -16.22603988647461, 'loss_4': -0.16006691753864288, 'epoch': 26.76}
{'loss': 0.013, 'grad_norm': 4.861183166503906, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.004177870694547892, 'loss_2': 0.0087738037109375, 'loss_3': -16.093917846679688, 'loss_4': -0.4535273313522339, 'epoch': 26.76}
{'loss': 0.0075, 'grad_norm': 4.599466323852539, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.006833030842244625, 'loss_2': 0.0006947517395019531, 'loss_3': -16.04081153869629, 'loss_4': -0.05858972296118736, 'epoch': 26.77}
{'loss': 0.0104, 'grad_norm': 6.191549301147461, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.006167189683765173, 'loss_2': 0.004245758056640625, 'loss_3': -16.225570678710938, 'loss_4': -0.349381685256958, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 17:11:57,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:57,949 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:10<09:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:05,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02962074987590313, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.035, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.02549823932349682, 'eval_loss_2': 0.004122510552406311, 'eval_loss_3': -18.074344635009766, 'eval_loss_4': -0.20391631126403809, 'epoch': 26.77}
{'loss': 0.0075, 'grad_norm': 4.7000627517700195, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.00377518474124372, 'loss_2': 0.003692626953125, 'loss_3': -16.1685733795166, 'loss_4': -0.4780917465686798, 'epoch': 26.78}
{'loss': 0.0095, 'grad_norm': 4.375312805175781, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.0035241825971752405, 'loss_2': 0.0059356689453125, 'loss_3': -16.19734001159668, 'loss_4': -0.10879643261432648, 'epoch': 26.78}
{'loss': 0.0074, 'grad_norm': 5.772660732269287, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.007160102482885122, 'loss_2': 0.0002200603485107422, 'loss_3': -16.275146484375, 'loss_4': 0.22705501317977905, 'epoch': 26.79}
{'loss': 0.0088, 'grad_norm': 5.072181224822998, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.0033131621312350035, 'loss_2': 0.00543975830078125, 'loss_3': -16.456279754638672, 'loss_4': -0.5309150218963623, 'epoch': 26.8}
{'loss': 0.0136, 'grad_norm': 5.297718524932861, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.006682501174509525, 'loss_2': 0.00689697265625, 'loss_3': -16.067338943481445, 'loss_4': -0.2333018183708191, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 17:12:05,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:05,282 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:18<09:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:12,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029345359653234482, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.975, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.025129450485110283, 'eval_loss_2': 0.004215911030769348, 'eval_loss_3': -18.08057403564453, 'eval_loss_4': -0.23847103118896484, 'epoch': 26.8}
{'loss': 0.0088, 'grad_norm': 4.83358097076416, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.006038202438503504, 'loss_2': 0.002765655517578125, 'loss_3': -16.230144500732422, 'loss_4': -0.528766393661499, 'epoch': 26.81}
{'loss': 0.0154, 'grad_norm': 8.533086776733398, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.014874028973281384, 'loss_2': 0.00057220458984375, 'loss_3': -16.129180908203125, 'loss_4': -0.22127436101436615, 'epoch': 26.81}
{'loss': 0.0076, 'grad_norm': 5.349064826965332, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.004574306774884462, 'loss_2': 0.002986907958984375, 'loss_3': -15.902713775634766, 'loss_4': -0.6554361581802368, 'epoch': 26.82}
{'loss': 0.0156, 'grad_norm': 5.051560401916504, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.00804875697940588, 'loss_2': 0.00754547119140625, 'loss_3': -16.129276275634766, 'loss_4': -0.31376194953918457, 'epoch': 26.83}
{'loss': 0.0093, 'grad_norm': 4.766617298126221, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.004054161254316568, 'loss_2': 0.00524139404296875, 'loss_3': -16.030338287353516, 'loss_4': -0.5374993681907654, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 17:12:12,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:12,613 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:25<09:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:12:19,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02901400625705719, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.698, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.024842185899615288, 'eval_loss_2': 0.004171818494796753, 'eval_loss_3': -18.08721160888672, 'eval_loss_4': -0.22235459089279175, 'epoch': 26.83}
{'loss': 0.0086, 'grad_norm': 4.462756633758545, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.00449981028214097, 'loss_2': 0.004100799560546875, 'loss_3': -16.04509162902832, 'loss_4': -0.03872153162956238, 'epoch': 26.84}
{'loss': 0.0053, 'grad_norm': 4.625579357147217, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.0042716278694570065, 'loss_2': 0.0010128021240234375, 'loss_3': -16.20801544189453, 'loss_4': -0.06955159455537796, 'epoch': 26.84}
{'loss': 0.0192, 'grad_norm': 7.804900169372559, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.012025654315948486, 'loss_2': 0.007198333740234375, 'loss_3': -16.12130355834961, 'loss_4': -0.5895182490348816, 'epoch': 26.85}
{'loss': 0.009, 'grad_norm': 4.660482883453369, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.004036287311464548, 'loss_2': 0.00495147705078125, 'loss_3': -16.074752807617188, 'loss_4': -0.29058873653411865, 'epoch': 26.85}
{'loss': 0.0075, 'grad_norm': 4.694947242736816, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.00639287568628788, 'loss_2': 0.0010662078857421875, 'loss_3': -16.14990997314453, 'loss_4': -0.348090797662735, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 17:12:19,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:19,927 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:53:32<09:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:12:27,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028963087126612663, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.637, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.024997416883707047, 'eval_loss_2': 0.0039656683802604675, 'eval_loss_3': -18.096742630004883, 'eval_loss_4': -0.20688019692897797, 'epoch': 26.86}
{'loss': 0.0105, 'grad_norm': 4.736706733703613, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.002714108442887664, 'loss_2': 0.0078277587890625, 'loss_3': -16.23431968688965, 'loss_4': 0.06858993321657181, 'epoch': 26.87}
{'loss': 0.0094, 'grad_norm': 5.2914719581604, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.008662094362080097, 'loss_2': 0.0007715225219726562, 'loss_3': -16.19976806640625, 'loss_4': 0.2095119208097458, 'epoch': 26.87}
{'loss': 0.004, 'grad_norm': 4.65933084487915, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.003656083019450307, 'loss_2': 0.0003490447998046875, 'loss_3': -15.997949600219727, 'loss_4': -0.21443985402584076, 'epoch': 26.88}
{'loss': 0.007, 'grad_norm': 5.072380065917969, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.005196802783757448, 'loss_2': 0.001789093017578125, 'loss_3': -16.265090942382812, 'loss_4': -0.19299499690532684, 'epoch': 26.88}
{'loss': 0.0226, 'grad_norm': 9.901702880859375, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.019674645736813545, 'loss_2': 0.00293731689453125, 'loss_3': -16.151845932006836, 'loss_4': 0.05140664428472519, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 17:12:27,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:27,250 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:53:39<09:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:12:34,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028692521154880524, 'eval_runtime': 3.7823, 'eval_samples_per_second': 270.733, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.024818584322929382, 'eval_loss_2': 0.0038739368319511414, 'eval_loss_3': -18.10428810119629, 'eval_loss_4': -0.2079286426305771, 'epoch': 26.89}
{'loss': 0.004, 'grad_norm': 4.497623920440674, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.0033163714688271284, 'loss_2': 0.0007200241088867188, 'loss_3': -16.237276077270508, 'loss_4': -0.22005045413970947, 'epoch': 26.9}
{'loss': 0.0066, 'grad_norm': 6.143176555633545, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.006241201423108578, 'loss_2': 0.0003542900085449219, 'loss_3': -16.30760383605957, 'loss_4': -0.05188459903001785, 'epoch': 26.9}
{'loss': 0.0118, 'grad_norm': 8.286898612976074, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.009637915529310703, 'loss_2': 0.0021209716796875, 'loss_3': -16.31119728088379, 'loss_4': -0.39496564865112305, 'epoch': 26.91}
{'loss': 0.0125, 'grad_norm': 11.716830253601074, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.012407619506120682, 'loss_2': 0.0001380443572998047, 'loss_3': -16.185108184814453, 'loss_4': -0.2815916836261749, 'epoch': 26.91}
{'loss': 0.0108, 'grad_norm': 4.991333484649658, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.004698873497545719, 'loss_2': 0.0061492919921875, 'loss_3': -16.402711868286133, 'loss_4': -0.3830273747444153, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 17:12:34,564 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:34,564 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:53:47<09:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:41,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02807101607322693, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.024147463962435722, 'eval_loss_2': 0.003923550248146057, 'eval_loss_3': -18.09949493408203, 'eval_loss_4': -0.19640469551086426, 'epoch': 26.92}
{'loss': 0.0102, 'grad_norm': 4.680456638336182, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.003832540474832058, 'loss_2': 0.00640106201171875, 'loss_3': -15.998730659484863, 'loss_4': -0.20420491695404053, 'epoch': 26.92}
{'loss': 0.0109, 'grad_norm': 4.363111972808838, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.004024258349090815, 'loss_2': 0.00690460205078125, 'loss_3': -16.152324676513672, 'loss_4': -0.119992196559906, 'epoch': 26.93}
{'loss': 0.0076, 'grad_norm': 4.629724025726318, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.0032713792752474546, 'loss_2': 0.004364013671875, 'loss_3': -16.17751693725586, 'loss_4': -0.2846277356147766, 'epoch': 26.94}
{'loss': 0.0077, 'grad_norm': 4.925978183746338, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.004571879748255014, 'loss_2': 0.00313568115234375, 'loss_3': -16.214698791503906, 'loss_4': -0.29894185066223145, 'epoch': 26.94}
{'loss': 0.0129, 'grad_norm': 5.955210208892822, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.012628680095076561, 'loss_2': 0.00022983551025390625, 'loss_3': -16.132320404052734, 'loss_4': -0.2200750708580017, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 17:12:41,900 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:41,900 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:53:54<08:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:49,225 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027410345152020454, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.318, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.023401368409395218, 'eval_loss_2': 0.004008978605270386, 'eval_loss_3': -18.104812622070312, 'eval_loss_4': -0.20264193415641785, 'epoch': 26.95}
{'loss': 0.0091, 'grad_norm': 6.283973693847656, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.008974618278443813, 'loss_2': 0.0001571178436279297, 'loss_3': -16.03789710998535, 'loss_4': -0.32072913646698, 'epoch': 26.95}
{'loss': 0.0216, 'grad_norm': 10.440461158752441, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.01433604583144188, 'loss_2': 0.0072784423828125, 'loss_3': -16.2298583984375, 'loss_4': 0.23622995615005493, 'epoch': 26.96}
{'loss': 0.0112, 'grad_norm': 6.846663951873779, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.009219428524374962, 'loss_2': 0.0019512176513671875, 'loss_3': -16.256309509277344, 'loss_4': -0.27284181118011475, 'epoch': 26.97}
{'loss': 0.0121, 'grad_norm': 5.263956546783447, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.009196934290230274, 'loss_2': 0.0029354095458984375, 'loss_3': -16.308509826660156, 'loss_4': -0.272612988948822, 'epoch': 26.97}
{'loss': 0.0095, 'grad_norm': 4.760733604431152, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.005065750330686569, 'loss_2': 0.004413604736328125, 'loss_3': -16.000598907470703, 'loss_4': -0.45341363549232483, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 17:12:49,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:49,225 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:01<08:21,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 17:12:56,234 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02712143585085869, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.551, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.02328954078257084, 'eval_loss_2': 0.0038318969309329987, 'eval_loss_3': -18.099468231201172, 'eval_loss_4': -0.19249524176120758, 'epoch': 26.98}
{'loss': 0.0144, 'grad_norm': 6.28908109664917, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.007715790998190641, 'loss_2': 0.0066986083984375, 'loss_3': -16.349546432495117, 'loss_4': -0.6284117698669434, 'epoch': 26.98}
{'loss': 0.0098, 'grad_norm': 5.226291656494141, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.005999797955155373, 'loss_2': 0.0037670135498046875, 'loss_3': -16.218124389648438, 'loss_4': -0.374241441488266, 'epoch': 26.99}
{'loss': 0.0071, 'grad_norm': 4.821367263793945, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.004627469927072525, 'loss_2': 0.002468109130859375, 'loss_3': -16.25737953186035, 'loss_4': -0.41576069593429565, 'epoch': 26.99}
{'loss': 0.0071, 'grad_norm': 6.526860237121582, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.0017118179239332676, 'loss_2': 0.005405426025390625, 'loss_3': -16.269001007080078, 'loss_4': -0.3349962532520294, 'epoch': 27.0}
{'loss': 0.0046, 'grad_norm': 4.875846862792969, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.003979263827204704, 'loss_2': 0.0006089210510253906, 'loss_3': -16.116687774658203, 'loss_4': -0.32408204674720764, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 17:12:56,234 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:56,234 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:08<08:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:03,563 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027548473328351974, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.284, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.023558804765343666, 'eval_loss_2': 0.003989666700363159, 'eval_loss_3': -18.095186233520508, 'eval_loss_4': -0.17516012489795685, 'epoch': 27.01}
{'loss': 0.0114, 'grad_norm': 4.074050426483154, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.0038708059582859278, 'loss_2': 0.007518768310546875, 'loss_3': -16.146869659423828, 'loss_4': -0.11381123960018158, 'epoch': 27.01}
{'loss': 0.0109, 'grad_norm': 4.066197395324707, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.0030425002332776785, 'loss_2': 0.00787353515625, 'loss_3': -16.288990020751953, 'loss_4': -0.18491841852664948, 'epoch': 27.02}
{'loss': 0.0071, 'grad_norm': 4.206023693084717, 'learning_rate': 3e-06, 'loss_1': 0.005528656765818596, 'loss_2': 0.001605987548828125, 'loss_3': -16.38817024230957, 'loss_4': -0.05123376101255417, 'epoch': 27.02}
{'loss': 0.0192, 'grad_norm': 8.268858909606934, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.018135610967874527, 'loss_2': 0.00109100341796875, 'loss_3': -16.233413696289062, 'loss_4': -0.13119980692863464, 'epoch': 27.03}
{'loss': 0.0071, 'grad_norm': 5.19507360458374, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.005984605755656958, 'loss_2': 0.0010662078857421875, 'loss_3': -16.06492042541504, 'loss_4': -0.508876621723175, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 17:13:03,563 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:03,563 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:16<08:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:10,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027224456891417503, 'eval_runtime': 3.7839, 'eval_samples_per_second': 270.623, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.023516975343227386, 'eval_loss_2': 0.003707483410835266, 'eval_loss_3': -18.097900390625, 'eval_loss_4': -0.15429195761680603, 'epoch': 27.03}
{'loss': 0.0108, 'grad_norm': 5.772252559661865, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.007836828008294106, 'loss_2': 0.002994537353515625, 'loss_3': -16.236366271972656, 'loss_4': -0.25996291637420654, 'epoch': 27.04}
{'loss': 0.0116, 'grad_norm': 5.1674981117248535, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.006204023025929928, 'loss_2': 0.005401611328125, 'loss_3': -16.299121856689453, 'loss_4': -0.13701099157333374, 'epoch': 27.05}
{'loss': 0.0078, 'grad_norm': 5.560567855834961, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.0074086678214371204, 'loss_2': 0.00042438507080078125, 'loss_3': -16.354515075683594, 'loss_4': -0.4296245574951172, 'epoch': 27.05}
{'loss': 0.015, 'grad_norm': 4.502706050872803, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.007160005625337362, 'loss_2': 0.00782012939453125, 'loss_3': -16.227502822875977, 'loss_4': -0.42009514570236206, 'epoch': 27.06}
{'loss': 0.012, 'grad_norm': 5.47620964050293, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.008659261278808117, 'loss_2': 0.00337982177734375, 'loss_3': -16.30384063720703, 'loss_4': -0.2995099127292633, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 17:13:10,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:10,884 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:23<08:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:18,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028828270733356476, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.291, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0249832384288311, 'eval_loss_2': 0.003845028579235077, 'eval_loss_3': -18.093198776245117, 'eval_loss_4': -0.16614094376564026, 'epoch': 27.06}
{'loss': 0.0109, 'grad_norm': 5.2816643714904785, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.006643413100391626, 'loss_2': 0.00429534912109375, 'loss_3': -15.962754249572754, 'loss_4': -0.3854462206363678, 'epoch': 27.07}
{'loss': 0.0049, 'grad_norm': 4.616322994232178, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.0034772104118019342, 'loss_2': 0.0014581680297851562, 'loss_3': -16.118305206298828, 'loss_4': -0.36853623390197754, 'epoch': 27.08}
{'loss': 0.0028, 'grad_norm': 4.263798713684082, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.002722127130255103, 'loss_2': 0.00010502338409423828, 'loss_3': -16.151700973510742, 'loss_4': -0.3199020028114319, 'epoch': 27.08}
{'loss': 0.0057, 'grad_norm': 4.541845321655273, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.003559900913387537, 'loss_2': 0.00209808349609375, 'loss_3': -16.019207000732422, 'loss_4': -0.5457620620727539, 'epoch': 27.09}
{'loss': 0.0094, 'grad_norm': 6.209383487701416, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.006016803439706564, 'loss_2': 0.003383636474609375, 'loss_3': -16.0511474609375, 'loss_4': -0.47363904118537903, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 17:13:18,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:18,207 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:54:30<08:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:25,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029527662321925163, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.567, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.02507525123655796, 'eval_loss_2': 0.004452407360076904, 'eval_loss_3': -18.099609375, 'eval_loss_4': -0.1661224663257599, 'epoch': 27.09}
{'loss': 0.0049, 'grad_norm': 4.9158220291137695, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.003577573224902153, 'loss_2': 0.001312255859375, 'loss_3': -16.33352279663086, 'loss_4': -0.12851478159427643, 'epoch': 27.1}
{'loss': 0.0096, 'grad_norm': 5.385884761810303, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.007311570458114147, 'loss_2': 0.0023059844970703125, 'loss_3': -16.290912628173828, 'loss_4': 0.11685707420110703, 'epoch': 27.1}
{'loss': 0.0086, 'grad_norm': 5.493031024932861, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.007236340548843145, 'loss_2': 0.0013790130615234375, 'loss_3': -16.22011947631836, 'loss_4': -0.22926582396030426, 'epoch': 27.11}
{'loss': 0.0026, 'grad_norm': 4.334611415863037, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.0025263018906116486, 'loss_2': 0.00010883808135986328, 'loss_3': -16.024539947509766, 'loss_4': -0.21259494125843048, 'epoch': 27.12}
{'loss': 0.0155, 'grad_norm': 6.9568657875061035, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.013903360813856125, 'loss_2': 0.00162506103515625, 'loss_3': -16.288562774658203, 'loss_4': -0.5539838671684265, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 17:13:25,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:25,522 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:54:38<08:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:32,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029214154928922653, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.157, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.025006866082549095, 'eval_loss_2': 0.004207290709018707, 'eval_loss_3': -18.098960876464844, 'eval_loss_4': -0.1690073013305664, 'epoch': 27.12}
{'loss': 0.0106, 'grad_norm': 5.54524040222168, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.009407108649611473, 'loss_2': 0.0011615753173828125, 'loss_3': -16.075603485107422, 'loss_4': -0.2230277806520462, 'epoch': 27.13}
{'loss': 0.0088, 'grad_norm': 5.135483741760254, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.007281897123903036, 'loss_2': 0.001506805419921875, 'loss_3': -16.30235481262207, 'loss_4': -0.45046308636665344, 'epoch': 27.13}
{'loss': 0.0043, 'grad_norm': 4.5832319259643555, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.003386239055544138, 'loss_2': 0.0009450912475585938, 'loss_3': -16.24292755126953, 'loss_4': -0.6572616696357727, 'epoch': 27.14}
{'loss': 0.0093, 'grad_norm': 4.794002532958984, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.003502379171550274, 'loss_2': 0.00576019287109375, 'loss_3': -16.26993179321289, 'loss_4': -0.08253642916679382, 'epoch': 27.15}
{'loss': 0.0103, 'grad_norm': 8.445545196533203, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.008106228895485401, 'loss_2': 0.0022220611572265625, 'loss_3': -16.155418395996094, 'loss_4': -0.4663281738758087, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 17:13:32,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:32,844 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:54:45<08:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:40,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02912776730954647, 'eval_runtime': 3.782, 'eval_samples_per_second': 270.758, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.025121605023741722, 'eval_loss_2': 0.0040061622858047485, 'eval_loss_3': -18.102622985839844, 'eval_loss_4': -0.17979303002357483, 'epoch': 27.15}
{'loss': 0.0116, 'grad_norm': 4.970817565917969, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.00973825715482235, 'loss_2': 0.0018768310546875, 'loss_3': -16.158592224121094, 'loss_4': -0.10753917694091797, 'epoch': 27.16}
{'loss': 0.0052, 'grad_norm': 4.176393032073975, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.005182400345802307, 'loss_2': 4.792213439941406e-05, 'loss_3': -16.169395446777344, 'loss_4': -0.49241188168525696, 'epoch': 27.16}
{'loss': 0.0222, 'grad_norm': 21.463268280029297, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.018850145861506462, 'loss_2': 0.003322601318359375, 'loss_3': -16.39361572265625, 'loss_4': 0.30084264278411865, 'epoch': 27.17}
{'loss': 0.0069, 'grad_norm': 4.32824182510376, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.004025180358439684, 'loss_2': 0.002899169921875, 'loss_3': -16.378292083740234, 'loss_4': -0.25603240728378296, 'epoch': 27.17}
{'loss': 0.0048, 'grad_norm': 4.8625993728637695, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.004300194792449474, 'loss_2': 0.0005445480346679688, 'loss_3': -16.062267303466797, 'loss_4': -0.25595489144325256, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 17:13:40,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:40,159 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:54:52<08:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:13:47,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02927381359040737, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.352, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.02527853660285473, 'eval_loss_2': 0.003995280712842941, 'eval_loss_3': -18.096479415893555, 'eval_loss_4': -0.1998753845691681, 'epoch': 27.18}
{'loss': 0.008, 'grad_norm': 4.620881080627441, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.004558348562568426, 'loss_2': 0.003429412841796875, 'loss_3': -16.140575408935547, 'loss_4': 0.2817533314228058, 'epoch': 27.19}
{'loss': 0.0096, 'grad_norm': 4.539126873016357, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.005193197168409824, 'loss_2': 0.00441741943359375, 'loss_3': -16.205291748046875, 'loss_4': -0.2844046354293823, 'epoch': 27.19}
{'loss': 0.0068, 'grad_norm': 4.182372570037842, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.0039756037294864655, 'loss_2': 0.002872467041015625, 'loss_3': -16.459129333496094, 'loss_4': -0.05906309932470322, 'epoch': 27.2}
{'loss': 0.0069, 'grad_norm': 4.558235168457031, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.0053117177449166775, 'loss_2': 0.00160980224609375, 'loss_3': -16.15834617614746, 'loss_4': -0.5753744840621948, 'epoch': 27.2}
{'loss': 0.0079, 'grad_norm': 4.837634563446045, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.003598206676542759, 'loss_2': 0.00428009033203125, 'loss_3': -16.135631561279297, 'loss_4': -0.25645455718040466, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 17:13:47,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:47,480 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:00<08:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:54,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02924150601029396, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.508, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.025140706449747086, 'eval_loss_2': 0.004100799560546875, 'eval_loss_3': -18.10127067565918, 'eval_loss_4': -0.2249544858932495, 'epoch': 27.21}
{'loss': 0.0103, 'grad_norm': 5.527082443237305, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.008042920380830765, 'loss_2': 0.00228118896484375, 'loss_3': -16.302566528320312, 'loss_4': -0.45339441299438477, 'epoch': 27.22}
{'loss': 0.0042, 'grad_norm': 4.361667633056641, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.004112446215003729, 'loss_2': 4.1604042053222656e-05, 'loss_3': -16.229259490966797, 'loss_4': -0.4472559094429016, 'epoch': 27.22}
{'loss': 0.0054, 'grad_norm': 4.873660087585449, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.004183788318186998, 'loss_2': 0.0012426376342773438, 'loss_3': -16.286083221435547, 'loss_4': -0.3546592593193054, 'epoch': 27.23}
{'loss': 0.0064, 'grad_norm': 5.007723331451416, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.0038635681848973036, 'loss_2': 0.002567291259765625, 'loss_3': -16.161792755126953, 'loss_4': -0.5570765137672424, 'epoch': 27.23}
{'loss': 0.016, 'grad_norm': 5.507292747497559, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.00781529676169157, 'loss_2': 0.008148193359375, 'loss_3': -16.315715789794922, 'loss_4': -0.26035240292549133, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 17:13:54,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:54,802 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:07<08:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:02,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028815995901823044, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.02476172335445881, 'eval_loss_2': 0.004054270684719086, 'eval_loss_3': -18.110790252685547, 'eval_loss_4': -0.250095009803772, 'epoch': 27.24}
{'loss': 0.0122, 'grad_norm': 5.0217180252075195, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.0030478998087346554, 'loss_2': 0.00916290283203125, 'loss_3': -16.225515365600586, 'loss_4': -0.03998183459043503, 'epoch': 27.24}
{'loss': 0.0194, 'grad_norm': 10.551963806152344, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.015512987039983273, 'loss_2': 0.003849029541015625, 'loss_3': -16.24302864074707, 'loss_4': -0.3988613486289978, 'epoch': 27.25}
{'loss': 0.0162, 'grad_norm': 7.2866129875183105, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.011901378631591797, 'loss_2': 0.004337310791015625, 'loss_3': -16.17665672302246, 'loss_4': -0.31332552433013916, 'epoch': 27.26}
{'loss': 0.0101, 'grad_norm': 4.9868974685668945, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.007234408985823393, 'loss_2': 0.002849578857421875, 'loss_3': -16.32571792602539, 'loss_4': -0.6577936410903931, 'epoch': 27.26}
{'loss': 0.0034, 'grad_norm': 4.559648036956787, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.0031686224974691868, 'loss_2': 0.00027179718017578125, 'loss_3': -16.2399845123291, 'loss_4': -0.479492723941803, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 17:14:02,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:02,130 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:14<08:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:09,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02857576310634613, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.65, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.024385524913668633, 'eval_loss_2': 0.004190236330032349, 'eval_loss_3': -18.115680694580078, 'eval_loss_4': -0.2775365114212036, 'epoch': 27.27}
{'loss': 0.0063, 'grad_norm': 4.772425651550293, 'learning_rate': 2.75e-06, 'loss_1': 0.004701359663158655, 'loss_2': 0.00164794921875, 'loss_3': -15.985176086425781, 'loss_4': -0.7590334415435791, 'epoch': 27.27}
{'loss': 0.018, 'grad_norm': 7.182766437530518, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.011067701503634453, 'loss_2': 0.00698089599609375, 'loss_3': -16.322805404663086, 'loss_4': -0.4958896040916443, 'epoch': 27.28}
{'loss': 0.0059, 'grad_norm': 4.78816556930542, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.003252220107242465, 'loss_2': 0.002685546875, 'loss_3': -16.007993698120117, 'loss_4': -0.481220543384552, 'epoch': 27.28}
{'loss': 0.0162, 'grad_norm': 7.555854797363281, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.013734082691371441, 'loss_2': 0.002452850341796875, 'loss_3': -16.036745071411133, 'loss_4': -0.5277414917945862, 'epoch': 27.29}
{'loss': 0.0196, 'grad_norm': 8.076581001281738, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.014167437329888344, 'loss_2': 0.0054473876953125, 'loss_3': -16.17339515686035, 'loss_4': -0.040039438754320145, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 17:14:09,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:09,443 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:22<07:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:16,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027729982510209084, 'eval_runtime': 3.7815, 'eval_samples_per_second': 270.793, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.023533737286925316, 'eval_loss_2': 0.004196241497993469, 'eval_loss_3': -18.126968383789062, 'eval_loss_4': -0.28477904200553894, 'epoch': 27.3}
{'loss': 0.0061, 'grad_norm': 3.974475145339966, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.002890222240239382, 'loss_2': 0.00321197509765625, 'loss_3': -16.39950180053711, 'loss_4': -0.08530165255069733, 'epoch': 27.3}
{'loss': 0.0806, 'grad_norm': 12.109454154968262, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.07611509412527084, 'loss_2': 0.0045318603515625, 'loss_3': -16.106800079345703, 'loss_4': -0.2572496831417084, 'epoch': 27.31}
{'loss': 0.0079, 'grad_norm': 4.834053993225098, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.00693932082504034, 'loss_2': 0.0009260177612304688, 'loss_3': -16.067739486694336, 'loss_4': -0.6361361145973206, 'epoch': 27.31}
{'loss': 0.0222, 'grad_norm': 10.558280944824219, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.021721815690398216, 'loss_2': 0.0004353523254394531, 'loss_3': -16.2742862701416, 'loss_4': -0.16034744679927826, 'epoch': 27.32}
{'loss': 0.0089, 'grad_norm': 4.716533184051514, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.00662705022841692, 'loss_2': 0.0022525787353515625, 'loss_3': -16.241548538208008, 'loss_4': -0.5095540285110474, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 17:14:16,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:16,760 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:55:29<07:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:24,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027272887527942657, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.574, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.023129131644964218, 'eval_loss_2': 0.004143755882978439, 'eval_loss_3': -18.124631881713867, 'eval_loss_4': -0.2956577241420746, 'epoch': 27.33}
{'loss': 0.0117, 'grad_norm': 4.315073013305664, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.004516109358519316, 'loss_2': 0.007160186767578125, 'loss_3': -16.12928009033203, 'loss_4': -0.4490986466407776, 'epoch': 27.33}
{'loss': 0.0037, 'grad_norm': 4.6788105964660645, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.003061595605686307, 'loss_2': 0.0006113052368164062, 'loss_3': -16.223976135253906, 'loss_4': -0.8459498286247253, 'epoch': 27.34}
{'loss': 0.0206, 'grad_norm': 9.067532539367676, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.018234314396977425, 'loss_2': 0.00238037109375, 'loss_3': -16.171215057373047, 'loss_4': -0.39682310819625854, 'epoch': 27.34}
{'loss': 0.0153, 'grad_norm': 4.515161991119385, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.0047574592754244804, 'loss_2': 0.0105743408203125, 'loss_3': -16.311878204345703, 'loss_4': -0.3995821177959442, 'epoch': 27.35}
{'loss': 0.0092, 'grad_norm': 5.358497142791748, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.007368981372565031, 'loss_2': 0.0018062591552734375, 'loss_3': -16.11344337463379, 'loss_4': -0.15175338089466095, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 17:14:24,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:24,082 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:55:36<07:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:31,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027778932824730873, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.226, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.023689476773142815, 'eval_loss_2': 0.004089459776878357, 'eval_loss_3': -18.121458053588867, 'eval_loss_4': -0.29801714420318604, 'epoch': 27.35}
{'loss': 0.006, 'grad_norm': 4.427231788635254, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.0023458844516426325, 'loss_2': 0.0036754608154296875, 'loss_3': -16.23177719116211, 'loss_4': -0.5947045087814331, 'epoch': 27.36}
{'loss': 0.0145, 'grad_norm': 6.347683906555176, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.01132122054696083, 'loss_2': 0.003192901611328125, 'loss_3': -16.172481536865234, 'loss_4': -0.49512961506843567, 'epoch': 27.37}
{'loss': 0.0085, 'grad_norm': 4.097371578216553, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.004072233103215694, 'loss_2': 0.00443267822265625, 'loss_3': -16.148530960083008, 'loss_4': -0.565147340297699, 'epoch': 27.37}
{'loss': 0.0079, 'grad_norm': 4.690984725952148, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.0028830429073423147, 'loss_2': 0.00498199462890625, 'loss_3': -16.307445526123047, 'loss_4': -0.28074944019317627, 'epoch': 27.38}
{'loss': 0.0088, 'grad_norm': 4.802591323852539, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.004353235010057688, 'loss_2': 0.004428863525390625, 'loss_3': -16.18451690673828, 'loss_4': -0.51419597864151, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 17:14:31,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:31,407 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:55:44<07:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:38,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026962194591760635, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.52, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.023109767585992813, 'eval_loss_2': 0.0038524270057678223, 'eval_loss_3': -18.123987197875977, 'eval_loss_4': -0.28969675302505493, 'epoch': 27.38}
{'loss': 0.01, 'grad_norm': 5.34402322769165, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.006746765226125717, 'loss_2': 0.003299713134765625, 'loss_3': -16.180553436279297, 'loss_4': -0.4787798523902893, 'epoch': 27.39}
{'loss': 0.0083, 'grad_norm': 5.281206130981445, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.005661045201122761, 'loss_2': 0.002643585205078125, 'loss_3': -16.300724029541016, 'loss_4': -0.664352297782898, 'epoch': 27.4}
{'loss': 0.0835, 'grad_norm': 17.549072265625, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.08125600963830948, 'loss_2': 0.00225830078125, 'loss_3': -16.167688369750977, 'loss_4': -0.21965372562408447, 'epoch': 27.4}
{'loss': 0.024, 'grad_norm': 14.096875190734863, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.023007694631814957, 'loss_2': 0.0010309219360351562, 'loss_3': -16.137187957763672, 'loss_4': -0.5087593197822571, 'epoch': 27.41}
{'loss': 0.011, 'grad_norm': 6.577831745147705, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.010286104865372181, 'loss_2': 0.0006685256958007812, 'loss_3': -16.15312385559082, 'loss_4': -0.61961430311203, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 17:14:38,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:38,729 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:55:51<07:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:46,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02646220102906227, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.656, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.022844107821583748, 'eval_loss_2': 0.003618091344833374, 'eval_loss_3': -18.122440338134766, 'eval_loss_4': -0.30830520391464233, 'epoch': 27.41}
{'loss': 0.005, 'grad_norm': 5.2023725509643555, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.003944362048059702, 'loss_2': 0.0010919570922851562, 'loss_3': -16.06395721435547, 'loss_4': -0.16727904975414276, 'epoch': 27.42}
{'loss': 0.0083, 'grad_norm': 5.479094505310059, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.007181251421570778, 'loss_2': 0.001079559326171875, 'loss_3': -16.248586654663086, 'loss_4': -0.29288893938064575, 'epoch': 27.42}
{'loss': 0.01, 'grad_norm': 4.533894062042236, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.009065133519470692, 'loss_2': 0.000934600830078125, 'loss_3': -16.272289276123047, 'loss_4': -0.37156444787979126, 'epoch': 27.43}
{'loss': 0.0134, 'grad_norm': 8.44810676574707, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.012574086897075176, 'loss_2': 0.0007762908935546875, 'loss_3': -16.26902198791504, 'loss_4': -0.34971851110458374, 'epoch': 27.44}
{'loss': 0.0163, 'grad_norm': 7.445956707000732, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.013258230872452259, 'loss_2': 0.00308990478515625, 'loss_3': -16.06149673461914, 'loss_4': -0.28328025341033936, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 17:14:46,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:46,041 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:55:58<07:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:14:53,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026450008153915405, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.54, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.022796526551246643, 'eval_loss_2': 0.003653481602668762, 'eval_loss_3': -18.127737045288086, 'eval_loss_4': -0.33414432406425476, 'epoch': 27.44}
{'loss': 0.0121, 'grad_norm': 5.26400089263916, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.0056266775354743, 'loss_2': 0.00650787353515625, 'loss_3': -16.09053611755371, 'loss_4': -0.18012918531894684, 'epoch': 27.45}
{'loss': 0.0132, 'grad_norm': 4.703646659851074, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.00608384283259511, 'loss_2': 0.007080078125, 'loss_3': -16.257568359375, 'loss_4': -0.7204492092132568, 'epoch': 27.45}
{'loss': 0.0193, 'grad_norm': 5.98325252532959, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.013035605661571026, 'loss_2': 0.00627899169921875, 'loss_3': -16.213199615478516, 'loss_4': -0.6691371202468872, 'epoch': 27.46}
{'loss': 0.0157, 'grad_norm': 5.1979451179504395, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.008443293161690235, 'loss_2': 0.00725555419921875, 'loss_3': -16.06472396850586, 'loss_4': -0.3672349750995636, 'epoch': 27.47}
{'loss': 0.0072, 'grad_norm': 5.68344259262085, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.005563853774219751, 'loss_2': 0.001617431640625, 'loss_3': -16.231571197509766, 'loss_4': -0.7301653623580933, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 17:14:53,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:53,359 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:06<07:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:15:00,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026000870391726494, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.533, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.022547300904989243, 'eval_loss_2': 0.003453567624092102, 'eval_loss_3': -18.1336669921875, 'eval_loss_4': -0.3561205267906189, 'epoch': 27.47}
{'loss': 0.0088, 'grad_norm': 4.781487941741943, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.006233291234821081, 'loss_2': 0.002544403076171875, 'loss_3': -15.960015296936035, 'loss_4': -0.7155486345291138, 'epoch': 27.48}
{'loss': 0.005, 'grad_norm': 5.645366191864014, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.004995156545192003, 'loss_2': 3.600120544433594e-05, 'loss_3': -16.197101593017578, 'loss_4': -0.5367366075515747, 'epoch': 27.48}
{'loss': 0.0038, 'grad_norm': 4.207747459411621, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.0034843310713768005, 'loss_2': 0.0003268718719482422, 'loss_3': -16.305143356323242, 'loss_4': -0.45791664719581604, 'epoch': 27.49}
{'loss': 0.0112, 'grad_norm': 4.757760047912598, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.004338266793638468, 'loss_2': 0.00684356689453125, 'loss_3': -16.359411239624023, 'loss_4': -0.06188644468784332, 'epoch': 27.49}
{'loss': 0.0078, 'grad_norm': 4.480536460876465, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.003003898775205016, 'loss_2': 0.004791259765625, 'loss_3': -16.253952026367188, 'loss_4': -0.010192066431045532, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 17:15:00,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:00,676 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:13<07:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:07,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02622600831091404, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.713, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.02265828289091587, 'eval_loss_2': 0.003567725419998169, 'eval_loss_3': -18.13326072692871, 'eval_loss_4': -0.3540949523448944, 'epoch': 27.5}
{'loss': 0.0195, 'grad_norm': 6.581418991088867, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.007473310921341181, 'loss_2': 0.0120391845703125, 'loss_3': -16.20352554321289, 'loss_4': -0.4311341643333435, 'epoch': 27.51}
{'loss': 0.0084, 'grad_norm': 4.995494365692139, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.006784514524042606, 'loss_2': 0.0015773773193359375, 'loss_3': -16.106624603271484, 'loss_4': -0.2050352692604065, 'epoch': 27.51}
{'loss': 0.0094, 'grad_norm': 4.600558757781982, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.004523625131696463, 'loss_2': 0.0048675537109375, 'loss_3': -16.232728958129883, 'loss_4': -0.3716992139816284, 'epoch': 27.52}
{'loss': 0.0095, 'grad_norm': 4.606426239013672, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.004431770183146, 'loss_2': 0.00506591796875, 'loss_3': -16.202327728271484, 'loss_4': -0.4147372245788574, 'epoch': 27.52}
{'loss': 0.004, 'grad_norm': 4.613134860992432, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.003683760529384017, 'loss_2': 0.0003437995910644531, 'loss_3': -16.367755889892578, 'loss_4': -0.5327160358428955, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 17:15:07,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:07,997 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:20<07:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:15,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026906048879027367, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.674, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.023048510774970055, 'eval_loss_2': 0.003857538104057312, 'eval_loss_3': -18.13597297668457, 'eval_loss_4': -0.3490248918533325, 'epoch': 27.53}
{'loss': 0.0061, 'grad_norm': 4.659031867980957, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.004480887204408646, 'loss_2': 0.0016489028930664062, 'loss_3': -16.19475746154785, 'loss_4': -0.7085137367248535, 'epoch': 27.53}
{'loss': 0.0094, 'grad_norm': 4.7832560539245605, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.0054195295087993145, 'loss_2': 0.004016876220703125, 'loss_3': -16.226810455322266, 'loss_4': -0.646634042263031, 'epoch': 27.54}
{'loss': 0.0231, 'grad_norm': 15.809030532836914, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.020900525152683258, 'loss_2': 0.0021820068359375, 'loss_3': -16.120418548583984, 'loss_4': -0.13945753872394562, 'epoch': 27.55}
{'loss': 0.0064, 'grad_norm': 4.616877555847168, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.004954935051500797, 'loss_2': 0.0014410018920898438, 'loss_3': -16.178936004638672, 'loss_4': -0.16360825300216675, 'epoch': 27.55}
{'loss': 0.0124, 'grad_norm': 5.044804573059082, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.0048040482215583324, 'loss_2': 0.00760650634765625, 'loss_3': -16.30462074279785, 'loss_4': -0.3321925401687622, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 17:15:15,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:15,326 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:28<07:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:22,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02728991024196148, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.184, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.023078450933098793, 'eval_loss_2': 0.004211455583572388, 'eval_loss_3': -18.128889083862305, 'eval_loss_4': -0.3739702105522156, 'epoch': 27.56}
{'loss': 0.0049, 'grad_norm': 5.8021087646484375, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.004812612198293209, 'loss_2': 0.00012731552124023438, 'loss_3': -16.18189239501953, 'loss_4': -0.6224282383918762, 'epoch': 27.56}
{'loss': 0.0089, 'grad_norm': 4.587764263153076, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.004762210417538881, 'loss_2': 0.00415802001953125, 'loss_3': -16.140043258666992, 'loss_4': -0.40264707803726196, 'epoch': 27.57}
{'loss': 0.0103, 'grad_norm': 5.019550323486328, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.006166487000882626, 'loss_2': 0.004180908203125, 'loss_3': -16.23436164855957, 'loss_4': -0.0988241508603096, 'epoch': 27.58}
{'loss': 0.0086, 'grad_norm': 5.032412052154541, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.006220105104148388, 'loss_2': 0.002414703369140625, 'loss_3': -16.10560417175293, 'loss_4': -0.3758789300918579, 'epoch': 27.58}
{'loss': 0.0078, 'grad_norm': 4.264014720916748, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.002564174821600318, 'loss_2': 0.005279541015625, 'loss_3': -16.255592346191406, 'loss_4': -0.7368524074554443, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 17:15:22,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:22,658 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:56:35<07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:29,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026791419833898544, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.132, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.022714074701070786, 'eval_loss_2': 0.004077345132827759, 'eval_loss_3': -18.12986946105957, 'eval_loss_4': -0.3677115738391876, 'epoch': 27.59}
{'loss': 0.0092, 'grad_norm': 4.171876430511475, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.002792083192616701, 'loss_2': 0.00644683837890625, 'loss_3': -16.27421760559082, 'loss_4': -0.2946251630783081, 'epoch': 27.59}
{'loss': 0.0099, 'grad_norm': 5.512880802154541, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.009688783437013626, 'loss_2': 0.0002536773681640625, 'loss_3': -16.29564094543457, 'loss_4': -0.5988184213638306, 'epoch': 27.6}
{'loss': 0.0092, 'grad_norm': 6.0607099533081055, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.005780974868685007, 'loss_2': 0.0033721923828125, 'loss_3': -16.244998931884766, 'loss_4': -0.6658191680908203, 'epoch': 27.6}
{'loss': 0.0081, 'grad_norm': 5.794825553894043, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.007504699751734734, 'loss_2': 0.0006275177001953125, 'loss_3': -16.017105102539062, 'loss_4': -0.3263095021247864, 'epoch': 27.61}
{'loss': 0.0057, 'grad_norm': 4.022616863250732, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.0036474871449172497, 'loss_2': 0.0020847320556640625, 'loss_3': -15.946800231933594, 'loss_4': -0.8457511067390442, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 17:15:29,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:29,995 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:56:42<06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:37,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026483623310923576, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.136, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.022442307323217392, 'eval_loss_2': 0.004041314125061035, 'eval_loss_3': -18.127534866333008, 'eval_loss_4': -0.364679217338562, 'epoch': 27.62}
{'loss': 0.0086, 'grad_norm': 4.613342761993408, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.00381922023370862, 'loss_2': 0.0047454833984375, 'loss_3': -15.98611068725586, 'loss_4': -0.29330649971961975, 'epoch': 27.62}
{'loss': 0.0091, 'grad_norm': 4.150634288787842, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0033521063160151243, 'loss_2': 0.005741119384765625, 'loss_3': -16.26327896118164, 'loss_4': -0.3951183557510376, 'epoch': 27.63}
{'loss': 0.0056, 'grad_norm': 4.679834365844727, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.0046381875872612, 'loss_2': 0.0009584426879882812, 'loss_3': -16.150100708007812, 'loss_4': -0.24200919270515442, 'epoch': 27.63}
{'loss': 0.0141, 'grad_norm': 6.065241813659668, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.008891523815691471, 'loss_2': 0.00518035888671875, 'loss_3': -16.055763244628906, 'loss_4': -0.7853648066520691, 'epoch': 27.64}
{'loss': 0.0031, 'grad_norm': 4.598090648651123, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.0025518436450511217, 'loss_2': 0.000499725341796875, 'loss_3': -16.241880416870117, 'loss_4': -0.4269446134567261, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 17:15:37,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:37,326 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:56:50<06:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:44,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02701914869248867, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.022887444123625755, 'eval_loss_2': 0.004131704568862915, 'eval_loss_3': -18.123981475830078, 'eval_loss_4': -0.38218992948532104, 'epoch': 27.65}
{'loss': 0.0036, 'grad_norm': 4.442068576812744, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.0027599448803812265, 'loss_2': 0.0008392333984375, 'loss_3': -16.22835922241211, 'loss_4': -0.39897647500038147, 'epoch': 27.65}
{'loss': 0.0094, 'grad_norm': 4.814112186431885, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.005373619496822357, 'loss_2': 0.0039825439453125, 'loss_3': -16.268863677978516, 'loss_4': -0.12492242455482483, 'epoch': 27.66}
{'loss': 0.0126, 'grad_norm': 5.917685031890869, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.00683300057426095, 'loss_2': 0.0057525634765625, 'loss_3': -16.32984733581543, 'loss_4': -0.7772654891014099, 'epoch': 27.66}
{'loss': 0.0072, 'grad_norm': 4.740799903869629, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.004383178893476725, 'loss_2': 0.002834320068359375, 'loss_3': -16.132003784179688, 'loss_4': -0.4768279194831848, 'epoch': 27.67}
{'loss': 0.0102, 'grad_norm': 5.280466556549072, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.00648942356929183, 'loss_2': 0.003681182861328125, 'loss_3': -16.404743194580078, 'loss_4': -0.04403373599052429, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 17:15:44,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:44,662 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:56:57<06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:52,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02680959179997444, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.894, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.022600583732128143, 'eval_loss_2': 0.004209004342556, 'eval_loss_3': -18.12104606628418, 'eval_loss_4': -0.39212316274642944, 'epoch': 27.67}
{'loss': 0.0055, 'grad_norm': 4.499935150146484, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.002776860957965255, 'loss_2': 0.0027313232421875, 'loss_3': -16.343894958496094, 'loss_4': 0.15713120996952057, 'epoch': 27.68}
{'loss': 0.0159, 'grad_norm': 6.702399730682373, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.01319839432835579, 'loss_2': 0.0027370452880859375, 'loss_3': -15.969907760620117, 'loss_4': -0.14510396122932434, 'epoch': 27.69}
{'loss': 0.0082, 'grad_norm': 5.012554168701172, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.007637910079210997, 'loss_2': 0.0005550384521484375, 'loss_3': -16.213272094726562, 'loss_4': -0.687760591506958, 'epoch': 27.69}
{'loss': 0.011, 'grad_norm': 6.16592264175415, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.007262613158673048, 'loss_2': 0.00372314453125, 'loss_3': -16.14431381225586, 'loss_4': -0.6551403999328613, 'epoch': 27.7}
{'loss': 0.0076, 'grad_norm': 5.325211048126221, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.0059504262171685696, 'loss_2': 0.001605987548828125, 'loss_3': -16.24543571472168, 'loss_4': -0.43053606152534485, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 17:15:52,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:52,010 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:04<06:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:59,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027449296787381172, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.309, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.022930730134248734, 'eval_loss_2': 0.004518568515777588, 'eval_loss_3': -18.1175479888916, 'eval_loss_4': -0.3760080635547638, 'epoch': 27.7}
{'loss': 0.0062, 'grad_norm': 5.2799177169799805, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.005943348631262779, 'loss_2': 0.0002675056457519531, 'loss_3': -16.27102279663086, 'loss_4': -0.8039902448654175, 'epoch': 27.71}
{'loss': 0.0069, 'grad_norm': 6.145779609680176, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.006909278687089682, 'loss_2': 2.002716064453125e-05, 'loss_3': -16.304285049438477, 'loss_4': -0.204315185546875, 'epoch': 27.72}
{'loss': 0.0108, 'grad_norm': 7.229222297668457, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.00551624596118927, 'loss_2': 0.00531768798828125, 'loss_3': -16.219221115112305, 'loss_4': -0.09435474872589111, 'epoch': 27.72}
{'loss': 0.0039, 'grad_norm': 4.35723876953125, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0030832625925540924, 'loss_2': 0.00086212158203125, 'loss_3': -16.293861389160156, 'loss_4': -0.6356630325317383, 'epoch': 27.73}
{'loss': 0.0102, 'grad_norm': 5.886002540588379, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.008659769780933857, 'loss_2': 0.001499176025390625, 'loss_3': -16.234676361083984, 'loss_4': -0.6632866859436035, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 17:15:59,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:59,339 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:12<06:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:06,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027628952637314796, 'eval_runtime': 3.7797, 'eval_samples_per_second': 270.92, 'eval_steps_per_second': 4.233, 'eval_loss_1': 0.022921141237020493, 'eval_loss_2': 0.004707813262939453, 'eval_loss_3': -18.116104125976562, 'eval_loss_4': -0.3464603126049042, 'epoch': 27.73}
{'loss': 0.0107, 'grad_norm': 5.068431377410889, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.0091369254514575, 'loss_2': 0.00160980224609375, 'loss_3': -16.13294792175293, 'loss_4': -0.26041078567504883, 'epoch': 27.74}
{'loss': 0.0142, 'grad_norm': 4.8911614418029785, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.005327833350747824, 'loss_2': 0.00882720947265625, 'loss_3': -16.139680862426758, 'loss_4': 0.21837517619132996, 'epoch': 27.74}
{'loss': 0.0085, 'grad_norm': 4.786257743835449, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.005180818028748035, 'loss_2': 0.003307342529296875, 'loss_3': -16.140562057495117, 'loss_4': -0.7540947794914246, 'epoch': 27.75}
{'loss': 0.0051, 'grad_norm': 4.8232316970825195, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.004219818394631147, 'loss_2': 0.0008497238159179688, 'loss_3': -16.26913833618164, 'loss_4': -0.20421460270881653, 'epoch': 27.76}
{'loss': 0.0085, 'grad_norm': 4.904794692993164, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.005477805621922016, 'loss_2': 0.003032684326171875, 'loss_3': -16.179155349731445, 'loss_4': 0.0013641268014907837, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 17:16:06,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:06,653 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:19<06:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:13,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027389202266931534, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.571, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.022904101759195328, 'eval_loss_2': 0.004485100507736206, 'eval_loss_3': -18.114177703857422, 'eval_loss_4': -0.34520888328552246, 'epoch': 27.76}
{'loss': 0.0057, 'grad_norm': 4.986327648162842, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.0033183014020323753, 'loss_2': 0.00235748291015625, 'loss_3': -16.230484008789062, 'loss_4': -0.6824682950973511, 'epoch': 27.77}
{'loss': 0.0098, 'grad_norm': 4.734172344207764, 'learning_rate': 2.25e-06, 'loss_1': 0.0034005006309598684, 'loss_2': 0.00643157958984375, 'loss_3': -16.189210891723633, 'loss_4': 0.030853256583213806, 'epoch': 27.77}
{'loss': 0.0107, 'grad_norm': 7.388626575469971, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.009213900193572044, 'loss_2': 0.001453399658203125, 'loss_3': -16.295135498046875, 'loss_4': -0.4092036485671997, 'epoch': 27.78}
{'loss': 0.0055, 'grad_norm': 5.091305732727051, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.005288269370794296, 'loss_2': 0.000171661376953125, 'loss_3': -16.207040786743164, 'loss_4': -0.5542384386062622, 'epoch': 27.78}
{'loss': 0.0034, 'grad_norm': 4.8085761070251465, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.0033893005456775427, 'loss_2': 5.4836273193359375e-05, 'loss_3': -16.34198760986328, 'loss_4': -0.44076624512672424, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 17:16:13,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:13,976 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:26<06:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:21,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026521693915128708, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.538, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.022140540182590485, 'eval_loss_2': 0.004381150007247925, 'eval_loss_3': -18.11254119873047, 'eval_loss_4': -0.37203019857406616, 'epoch': 27.79}
{'loss': 0.0034, 'grad_norm': 5.01179313659668, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.0032221225555986166, 'loss_2': 0.00016927719116210938, 'loss_3': -16.299144744873047, 'loss_4': 0.08990046381950378, 'epoch': 27.8}
{'loss': 0.0084, 'grad_norm': 4.698835372924805, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.004966330248862505, 'loss_2': 0.003482818603515625, 'loss_3': -16.199974060058594, 'loss_4': -0.3777976632118225, 'epoch': 27.8}
{'loss': 0.019, 'grad_norm': 7.815310955047607, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.013936329632997513, 'loss_2': 0.00508880615234375, 'loss_3': -16.158954620361328, 'loss_4': -0.47521862387657166, 'epoch': 27.81}
{'loss': 0.0036, 'grad_norm': 4.67522668838501, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.0024152975529432297, 'loss_2': 0.0012054443359375, 'loss_3': -16.268468856811523, 'loss_4': -0.35121583938598633, 'epoch': 27.81}
{'loss': 0.006, 'grad_norm': 5.354066848754883, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.004600001499056816, 'loss_2': 0.0014390945434570312, 'loss_3': -16.19017219543457, 'loss_4': -0.39296138286590576, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 17:16:21,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:21,295 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:57:34<06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:28,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026110224425792694, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.02184545248746872, 'eval_loss_2': 0.004264771938323975, 'eval_loss_3': -18.112590789794922, 'eval_loss_4': -0.4082397222518921, 'epoch': 27.82}
{'loss': 0.0069, 'grad_norm': 4.309226989746094, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.0036853074561804533, 'loss_2': 0.00319671630859375, 'loss_3': -16.314943313598633, 'loss_4': -0.530588686466217, 'epoch': 27.83}
{'loss': 0.0068, 'grad_norm': 4.529698848724365, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.005372127052396536, 'loss_2': 0.001430511474609375, 'loss_3': -16.304779052734375, 'loss_4': -0.22659075260162354, 'epoch': 27.83}
{'loss': 0.0158, 'grad_norm': 6.708119869232178, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.01311968732625246, 'loss_2': 0.00266265869140625, 'loss_3': -16.193761825561523, 'loss_4': -0.24320338666439056, 'epoch': 27.84}
{'loss': 0.0176, 'grad_norm': 5.180590629577637, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.007114981766790152, 'loss_2': 0.01047515869140625, 'loss_3': -16.17074203491211, 'loss_4': -0.36975425481796265, 'epoch': 27.84}
{'loss': 0.0074, 'grad_norm': 4.608665943145752, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.005529643967747688, 'loss_2': 0.001827239990234375, 'loss_3': -16.198257446289062, 'loss_4': -0.17197401821613312, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 17:16:28,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:28,628 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:57:41<06:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:35,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025693677365779877, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.578, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.021656250581145287, 'eval_loss_2': 0.004037424921989441, 'eval_loss_3': -18.11187171936035, 'eval_loss_4': -0.4107496440410614, 'epoch': 27.85}
{'loss': 0.0105, 'grad_norm': 4.82678747177124, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.005752527620643377, 'loss_2': 0.004791259765625, 'loss_3': -16.18895721435547, 'loss_4': -0.5992669463157654, 'epoch': 27.85}
{'loss': 0.0056, 'grad_norm': 4.39107084274292, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.0038422737270593643, 'loss_2': 0.0017261505126953125, 'loss_3': -16.040754318237305, 'loss_4': -0.5806678533554077, 'epoch': 27.86}
{'loss': 0.0113, 'grad_norm': 4.495816707611084, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.00374847324565053, 'loss_2': 0.00756072998046875, 'loss_3': -16.406558990478516, 'loss_4': -0.7216647863388062, 'epoch': 27.87}
{'loss': 0.0106, 'grad_norm': 4.943667888641357, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.004696506541222334, 'loss_2': 0.005859375, 'loss_3': -16.350879669189453, 'loss_4': -0.40175411105155945, 'epoch': 27.87}
{'loss': 0.0132, 'grad_norm': 4.567995548248291, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.005656419321894646, 'loss_2': 0.00749969482421875, 'loss_3': -16.28653335571289, 'loss_4': -0.42118939757347107, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 17:16:35,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:35,942 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:57:48<06:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:43,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026119960471987724, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.026, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.02218220941722393, 'eval_loss_2': 0.003937751054763794, 'eval_loss_3': -18.11018180847168, 'eval_loss_4': -0.4033108353614807, 'epoch': 27.88}
{'loss': 0.0113, 'grad_norm': 5.433314323425293, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.008731775917112827, 'loss_2': 0.00254058837890625, 'loss_3': -16.12872314453125, 'loss_4': -0.599655270576477, 'epoch': 27.88}
{'loss': 0.0098, 'grad_norm': 4.698347568511963, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.003082653973251581, 'loss_2': 0.0067291259765625, 'loss_3': -16.187049865722656, 'loss_4': -0.33234643936157227, 'epoch': 27.89}
{'loss': 0.008, 'grad_norm': 4.496476173400879, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.006352597381919622, 'loss_2': 0.0016345977783203125, 'loss_3': -16.29255485534668, 'loss_4': -0.4634137749671936, 'epoch': 27.9}
{'loss': 0.0106, 'grad_norm': 5.8339972496032715, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.007338964380323887, 'loss_2': 0.003276824951171875, 'loss_3': -16.19485092163086, 'loss_4': -0.4803994596004486, 'epoch': 27.9}
{'loss': 0.0075, 'grad_norm': 4.8813042640686035, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.004379008896648884, 'loss_2': 0.00316619873046875, 'loss_3': -16.292495727539062, 'loss_4': -0.3609614074230194, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 17:16:43,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:43,267 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:57:56<06:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:50,596 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025634823366999626, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.021730490028858185, 'eval_loss_2': 0.0039043352007865906, 'eval_loss_3': -18.107234954833984, 'eval_loss_4': -0.3839092254638672, 'epoch': 27.91}
{'loss': 0.0099, 'grad_norm': 4.956904411315918, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.004621565341949463, 'loss_2': 0.0053253173828125, 'loss_3': -16.171220779418945, 'loss_4': -0.8200567960739136, 'epoch': 27.91}
{'loss': 0.0098, 'grad_norm': 5.861496448516846, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.007558317389339209, 'loss_2': 0.0022125244140625, 'loss_3': -16.410213470458984, 'loss_4': -0.2722269594669342, 'epoch': 27.92}
{'loss': 0.0123, 'grad_norm': 6.225344657897949, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.008690652437508106, 'loss_2': 0.003597259521484375, 'loss_3': -16.22170639038086, 'loss_4': -0.5372855067253113, 'epoch': 27.92}
{'loss': 0.0714, 'grad_norm': 12.042139053344727, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.06869494169950485, 'loss_2': 0.002666473388671875, 'loss_3': -16.29860496520996, 'loss_4': -0.06919778138399124, 'epoch': 27.93}
{'loss': 0.0092, 'grad_norm': 4.865162372589111, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.006865302100777626, 'loss_2': 0.002292633056640625, 'loss_3': -16.263412475585938, 'loss_4': -0.6796492338180542, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 17:16:50,596 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:50,596 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:03<06:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:57,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02532973140478134, 'eval_runtime': 3.782, 'eval_samples_per_second': 270.756, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.0213149506598711, 'eval_loss_2': 0.004014782607555389, 'eval_loss_3': -18.1141357421875, 'eval_loss_4': -0.3827565908432007, 'epoch': 27.94}
{'loss': 0.0054, 'grad_norm': 4.84920072555542, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.002164598787203431, 'loss_2': 0.0031948089599609375, 'loss_3': -16.245227813720703, 'loss_4': -0.6160801649093628, 'epoch': 27.94}
{'loss': 0.012, 'grad_norm': 4.963872909545898, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.007038723677396774, 'loss_2': 0.004913330078125, 'loss_3': -16.273862838745117, 'loss_4': -0.5965431928634644, 'epoch': 27.95}
{'loss': 0.0085, 'grad_norm': 7.409395217895508, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.008029318414628506, 'loss_2': 0.00042247772216796875, 'loss_3': -16.19639778137207, 'loss_4': -0.013117700815200806, 'epoch': 27.95}
{'loss': 0.0113, 'grad_norm': 5.306788444519043, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.005449775606393814, 'loss_2': 0.00583648681640625, 'loss_3': -16.3848876953125, 'loss_4': -0.578683078289032, 'epoch': 27.96}
{'loss': 0.013, 'grad_norm': 4.707334041595459, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.0033412359189242125, 'loss_2': 0.00968170166015625, 'loss_3': -16.207746505737305, 'loss_4': -0.3304387331008911, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 17:16:57,921 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:57,921 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:10<05:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:17:05,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025569742545485497, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.625, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.021321900188922882, 'eval_loss_2': 0.004247844219207764, 'eval_loss_3': -18.114717483520508, 'eval_loss_4': -0.3835824131965637, 'epoch': 27.97}
{'loss': 0.0093, 'grad_norm': 4.508673191070557, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.005177320446819067, 'loss_2': 0.00412750244140625, 'loss_3': -16.399765014648438, 'loss_4': -0.4794960618019104, 'epoch': 27.97}
{'loss': 0.0104, 'grad_norm': 4.769354820251465, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.004855507519096136, 'loss_2': 0.00559234619140625, 'loss_3': -15.933053970336914, 'loss_4': -0.5502344965934753, 'epoch': 27.98}
{'loss': 0.0115, 'grad_norm': 4.934562683105469, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.00540019990876317, 'loss_2': 0.006114959716796875, 'loss_3': -16.257192611694336, 'loss_4': -1.0936685800552368, 'epoch': 27.98}
{'loss': 0.0116, 'grad_norm': 4.7945475578308105, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.006586405914276838, 'loss_2': 0.00504302978515625, 'loss_3': -16.219242095947266, 'loss_4': -0.5303529500961304, 'epoch': 27.99}
{'loss': 0.006, 'grad_norm': 5.352671146392822, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.005930297076702118, 'loss_2': 6.777048110961914e-05, 'loss_3': -16.14154815673828, 'loss_4': -0.6177059412002563, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 17:17:05,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:05,222 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:17<05:44,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 17:17:12,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02510260045528412, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.124, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021041007712483406, 'eval_loss_2': 0.004061594605445862, 'eval_loss_3': -18.117141723632812, 'eval_loss_4': -0.39211875200271606, 'epoch': 27.99}
{'loss': 0.0107, 'grad_norm': 6.058102130889893, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.002521405229344964, 'loss_2': 0.0081939697265625, 'loss_3': -16.175384521484375, 'loss_4': -0.6814385652542114, 'epoch': 28.0}
{'loss': 0.014, 'grad_norm': 7.500836372375488, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.012519779615104198, 'loss_2': 0.0014972686767578125, 'loss_3': -16.20882797241211, 'loss_4': -0.45926356315612793, 'epoch': 28.01}
{'loss': 0.0042, 'grad_norm': 4.4434990882873535, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.0032617549877613783, 'loss_2': 0.0009183883666992188, 'loss_3': -16.43461036682129, 'loss_4': -0.16129794716835022, 'epoch': 28.01}
{'loss': 0.0078, 'grad_norm': 4.653163433074951, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.0038445645477622747, 'loss_2': 0.00390625, 'loss_3': -16.228073120117188, 'loss_4': -0.48740246891975403, 'epoch': 28.02}
{'loss': 0.0136, 'grad_norm': 8.323049545288086, 'learning_rate': 2e-06, 'loss_1': 0.012789949774742126, 'loss_2': 0.0008168220520019531, 'loss_3': -16.232755661010742, 'loss_4': -0.2811223864555359, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 17:17:12,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:12,251 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:25<05:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:17:19,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02485307678580284, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.148, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021002452820539474, 'eval_loss_2': 0.0038506239652633667, 'eval_loss_3': -18.117942810058594, 'eval_loss_4': -0.3754991888999939, 'epoch': 28.02}
{'loss': 0.0062, 'grad_norm': 5.085562229156494, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.0027692208532243967, 'loss_2': 0.0033855438232421875, 'loss_3': -16.09982681274414, 'loss_4': -0.3990694582462311, 'epoch': 28.03}
{'loss': 0.0071, 'grad_norm': 4.4038214683532715, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.00222194567322731, 'loss_2': 0.00487518310546875, 'loss_3': -16.316967010498047, 'loss_4': -0.3361431956291199, 'epoch': 28.03}
{'loss': 0.0084, 'grad_norm': 4.672926902770996, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.004779443610459566, 'loss_2': 0.003627777099609375, 'loss_3': -16.13507652282715, 'loss_4': -0.1333112120628357, 'epoch': 28.04}
{'loss': 0.0093, 'grad_norm': 4.821325778961182, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.004350814502686262, 'loss_2': 0.00490570068359375, 'loss_3': -16.16831398010254, 'loss_4': -0.5411744117736816, 'epoch': 28.05}
{'loss': 0.0051, 'grad_norm': 4.564399719238281, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.0030973090324550867, 'loss_2': 0.0019702911376953125, 'loss_3': -16.339393615722656, 'loss_4': -0.3685515820980072, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 17:17:19,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:19,584 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:58:32<05:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:17:26,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02460828796029091, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.415, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02079821564257145, 'eval_loss_2': 0.0038100741803646088, 'eval_loss_3': -18.118560791015625, 'eval_loss_4': -0.3528882563114166, 'epoch': 28.05}
{'loss': 0.0091, 'grad_norm': 5.1777191162109375, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.004952696617692709, 'loss_2': 0.00412750244140625, 'loss_3': -16.212125778198242, 'loss_4': -0.36889851093292236, 'epoch': 28.06}
{'loss': 0.0032, 'grad_norm': 4.497278690338135, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.0024928695056587458, 'loss_2': 0.0007419586181640625, 'loss_3': -16.197229385375977, 'loss_4': -0.44774365425109863, 'epoch': 28.06}
{'loss': 0.0166, 'grad_norm': 5.442036151885986, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.008940978907048702, 'loss_2': 0.00765228271484375, 'loss_3': -16.250804901123047, 'loss_4': -0.48028814792633057, 'epoch': 28.07}
{'loss': 0.0088, 'grad_norm': 4.613321304321289, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.006274149753153324, 'loss_2': 0.00255584716796875, 'loss_3': -16.15306854248047, 'loss_4': -0.2053374946117401, 'epoch': 28.08}
{'loss': 0.0124, 'grad_norm': 4.455146312713623, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0017471483442932367, 'loss_2': 0.0106048583984375, 'loss_3': -16.323318481445312, 'loss_4': -0.17748530209064484, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 17:17:26,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:26,909 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:58:39<05:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:34,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024864349514245987, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.699, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.020965684205293655, 'eval_loss_2': 0.0038986653089523315, 'eval_loss_3': -18.11832046508789, 'eval_loss_4': -0.3402186334133148, 'epoch': 28.08}
{'loss': 0.009, 'grad_norm': 6.703160762786865, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.007261141203343868, 'loss_2': 0.0017251968383789062, 'loss_3': -16.339576721191406, 'loss_4': -0.07540598511695862, 'epoch': 28.09}
{'loss': 0.0129, 'grad_norm': 5.733714580535889, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.007374889682978392, 'loss_2': 0.0054779052734375, 'loss_3': -16.36998748779297, 'loss_4': -0.24395537376403809, 'epoch': 28.09}
{'loss': 0.0048, 'grad_norm': 4.47247314453125, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0021904532331973314, 'loss_2': 0.0026531219482421875, 'loss_3': -16.228561401367188, 'loss_4': -0.21681082248687744, 'epoch': 28.1}
{'loss': 0.0061, 'grad_norm': 5.110713958740234, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.004528478253632784, 'loss_2': 0.0015888214111328125, 'loss_3': -16.355323791503906, 'loss_4': -0.47875311970710754, 'epoch': 28.1}
{'loss': 0.0096, 'grad_norm': 5.041759490966797, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.005771796219050884, 'loss_2': 0.0037937164306640625, 'loss_3': -16.07649040222168, 'loss_4': -0.7373027801513672, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 17:17:34,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:34,232 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:58:46<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:41,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02548353374004364, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.684, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.02173764258623123, 'eval_loss_2': 0.0037458911538124084, 'eval_loss_3': -18.118534088134766, 'eval_loss_4': -0.3417055010795593, 'epoch': 28.11}
{'loss': 0.0041, 'grad_norm': 4.391542911529541, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.003265493316575885, 'loss_2': 0.0008559226989746094, 'loss_3': -16.347688674926758, 'loss_4': -0.39549973607063293, 'epoch': 28.12}
{'loss': 0.0079, 'grad_norm': 4.515769958496094, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.004000063054263592, 'loss_2': 0.00394439697265625, 'loss_3': -16.205698013305664, 'loss_4': -0.4721902310848236, 'epoch': 28.12}
{'loss': 0.0117, 'grad_norm': 6.419332504272461, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0069984206929802895, 'loss_2': 0.004730224609375, 'loss_3': -16.31563949584961, 'loss_4': -0.6392073631286621, 'epoch': 28.13}
{'loss': 0.037, 'grad_norm': 23.292465209960938, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.03453252837061882, 'loss_2': 0.002429962158203125, 'loss_3': -16.45018768310547, 'loss_4': -0.4785234332084656, 'epoch': 28.13}
{'loss': 0.0128, 'grad_norm': 6.07387638092041, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.007727400399744511, 'loss_2': 0.00511932373046875, 'loss_3': -16.19663429260254, 'loss_4': -0.08544550836086273, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 17:17:41,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:41,550 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:58:54<05:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:17:48,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02561679109930992, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.449, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021851932629942894, 'eval_loss_2': 0.0037648603320121765, 'eval_loss_3': -18.114240646362305, 'eval_loss_4': -0.35854047536849976, 'epoch': 28.14}
{'loss': 0.0066, 'grad_norm': 4.362315654754639, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.004752783570438623, 'loss_2': 0.0018482208251953125, 'loss_3': -16.284809112548828, 'loss_4': -0.36512863636016846, 'epoch': 28.15}
{'loss': 0.0114, 'grad_norm': 5.170745849609375, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.00668345857411623, 'loss_2': 0.00473785400390625, 'loss_3': -16.25994110107422, 'loss_4': -0.5532218217849731, 'epoch': 28.15}
{'loss': 0.0107, 'grad_norm': 5.1574273109436035, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.00511288782581687, 'loss_2': 0.005626678466796875, 'loss_3': -16.23706817626953, 'loss_4': -0.3769260346889496, 'epoch': 28.16}
{'loss': 0.0734, 'grad_norm': 6.8680877685546875, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.07182647287845612, 'loss_2': 0.0016164779663085938, 'loss_3': -16.17923355102539, 'loss_4': 0.24453556537628174, 'epoch': 28.16}
{'loss': 0.0056, 'grad_norm': 4.404542922973633, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.003589340252801776, 'loss_2': 0.00202178955078125, 'loss_3': -16.12795639038086, 'loss_4': -0.2830663323402405, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 17:17:48,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:48,868 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:01<05:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:17:56,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025841977447271347, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.527, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.021942678838968277, 'eval_loss_2': 0.00389929860830307, 'eval_loss_3': -18.113712310791016, 'eval_loss_4': -0.3655194640159607, 'epoch': 28.17}
{'loss': 0.012, 'grad_norm': 4.7640604972839355, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.004942455794662237, 'loss_2': 0.007083892822265625, 'loss_3': -16.20724105834961, 'loss_4': -0.5873369574546814, 'epoch': 28.17}
{'loss': 0.0128, 'grad_norm': 4.836225986480713, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.011964264325797558, 'loss_2': 0.0008268356323242188, 'loss_3': -16.330780029296875, 'loss_4': -0.4561951458454132, 'epoch': 28.18}
{'loss': 0.0168, 'grad_norm': 10.661229133605957, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.012738966383039951, 'loss_2': 0.004039764404296875, 'loss_3': -16.055923461914062, 'loss_4': -0.426933616399765, 'epoch': 28.19}
{'loss': 0.0067, 'grad_norm': 5.0411200523376465, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.0031205022241920233, 'loss_2': 0.003551483154296875, 'loss_3': -16.196949005126953, 'loss_4': -0.6580670475959778, 'epoch': 28.19}
{'loss': 0.0126, 'grad_norm': 5.004456996917725, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.006335754878818989, 'loss_2': 0.006252288818359375, 'loss_3': -16.35300064086914, 'loss_4': -0.5673710703849792, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 17:17:56,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:56,186 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:08<05:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:18:03,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026196323335170746, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.955, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02212616242468357, 'eval_loss_2': 0.004070162773132324, 'eval_loss_3': -18.116840362548828, 'eval_loss_4': -0.3433472812175751, 'epoch': 28.2}
{'loss': 0.0104, 'grad_norm': 7.927241325378418, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.01022712979465723, 'loss_2': 0.0001556873321533203, 'loss_3': -16.333393096923828, 'loss_4': -0.5742903351783752, 'epoch': 28.2}
{'loss': 0.0063, 'grad_norm': 4.596363067626953, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.003863709280267358, 'loss_2': 0.0024738311767578125, 'loss_3': -16.243282318115234, 'loss_4': -0.5162152647972107, 'epoch': 28.21}
{'loss': 0.0144, 'grad_norm': 8.274157524108887, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.00724166352301836, 'loss_2': 0.0071868896484375, 'loss_3': -16.156156539916992, 'loss_4': -0.38701918721199036, 'epoch': 28.22}
{'loss': 0.0054, 'grad_norm': 5.4678874015808105, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.003941771108657122, 'loss_2': 0.001438140869140625, 'loss_3': -16.267051696777344, 'loss_4': -0.18512141704559326, 'epoch': 28.22}
{'loss': 0.0054, 'grad_norm': 4.823512554168701, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.004084927495568991, 'loss_2': 0.0013065338134765625, 'loss_3': -16.127248764038086, 'loss_4': -0.42524394392967224, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 17:18:03,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:03,513 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:16<05:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:10,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025822976604104042, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.679, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.021701375022530556, 'eval_loss_2': 0.004121601581573486, 'eval_loss_3': -18.11404037475586, 'eval_loss_4': -0.3108130395412445, 'epoch': 28.23}
{'loss': 0.01, 'grad_norm': 4.69079065322876, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.0036680835764855146, 'loss_2': 0.006305694580078125, 'loss_3': -16.23418617248535, 'loss_4': -0.6318587064743042, 'epoch': 28.23}
{'loss': 0.0051, 'grad_norm': 4.688545227050781, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.0036364959087222815, 'loss_2': 0.00147247314453125, 'loss_3': -16.265911102294922, 'loss_4': -0.48246195912361145, 'epoch': 28.24}
{'loss': 0.0174, 'grad_norm': 6.574082374572754, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.011581853032112122, 'loss_2': 0.005847930908203125, 'loss_3': -16.175479888916016, 'loss_4': -0.40319186449050903, 'epoch': 28.24}
{'loss': 0.0051, 'grad_norm': 4.516055107116699, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.0030487861949950457, 'loss_2': 0.0020046234130859375, 'loss_3': -16.36777114868164, 'loss_4': -0.46399185061454773, 'epoch': 28.25}
{'loss': 0.0074, 'grad_norm': 5.123983860015869, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.00551520986482501, 'loss_2': 0.0018711090087890625, 'loss_3': -16.217844009399414, 'loss_4': -0.04059624299407005, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 17:18:10,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:10,841 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:23<05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:18,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02599199116230011, 'eval_runtime': 3.7819, 'eval_samples_per_second': 270.761, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.02171356976032257, 'eval_loss_2': 0.004278421401977539, 'eval_loss_3': -18.112417221069336, 'eval_loss_4': -0.28647950291633606, 'epoch': 28.26}
{'loss': 0.0826, 'grad_norm': 18.00160789489746, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.07655371725559235, 'loss_2': 0.006011962890625, 'loss_3': -16.158828735351562, 'loss_4': -0.1527966856956482, 'epoch': 28.26}
{'loss': 0.0035, 'grad_norm': 4.267600059509277, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.0018967022188007832, 'loss_2': 0.0016498565673828125, 'loss_3': -16.347640991210938, 'loss_4': -0.3123731017112732, 'epoch': 28.27}
{'loss': 0.012, 'grad_norm': 4.85230016708374, 'learning_rate': 1.75e-06, 'loss_1': 0.005793733987957239, 'loss_2': 0.00620269775390625, 'loss_3': -16.190269470214844, 'loss_4': -0.31300145387649536, 'epoch': 28.27}
{'loss': 0.0037, 'grad_norm': 4.429344177246094, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.0034883986227214336, 'loss_2': 0.0002453327178955078, 'loss_3': -16.166038513183594, 'loss_4': -0.5934352874755859, 'epoch': 28.28}
{'loss': 0.0073, 'grad_norm': 4.920773506164551, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.006122836843132973, 'loss_2': 0.001148223876953125, 'loss_3': -16.253524780273438, 'loss_4': -0.6170334219932556, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 17:18:18,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:18,162 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [1:59:30<05:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:18:25,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025793902575969696, 'eval_runtime': 3.7822, 'eval_samples_per_second': 270.742, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.021369926631450653, 'eval_loss_2': 0.004423975944519043, 'eval_loss_3': -18.105762481689453, 'eval_loss_4': -0.27641668915748596, 'epoch': 28.28}
{'loss': 0.0092, 'grad_norm': 5.5645599365234375, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.006253709085285664, 'loss_2': 0.002960205078125, 'loss_3': -16.17328453063965, 'loss_4': -0.3177281618118286, 'epoch': 28.29}
{'loss': 0.0127, 'grad_norm': 5.602996349334717, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.007600617129355669, 'loss_2': 0.005084991455078125, 'loss_3': -16.241748809814453, 'loss_4': -0.13918912410736084, 'epoch': 28.3}
{'loss': 0.0037, 'grad_norm': 4.5647687911987305, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0036052651703357697, 'loss_2': 6.562471389770508e-05, 'loss_3': -16.391944885253906, 'loss_4': -0.08583357185125351, 'epoch': 28.3}
{'loss': 0.0094, 'grad_norm': 5.008354663848877, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.00641821650788188, 'loss_2': 0.00295257568359375, 'loss_3': -16.215068817138672, 'loss_4': -0.3522900938987732, 'epoch': 28.31}
{'loss': 0.0093, 'grad_norm': 4.877425670623779, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.004714342299848795, 'loss_2': 0.004611968994140625, 'loss_3': -16.205841064453125, 'loss_4': -0.5931827425956726, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 17:18:25,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:25,482 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [1:59:38<04:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:18:32,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02560962177813053, 'eval_runtime': 3.7831, 'eval_samples_per_second': 270.68, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.021236544474959373, 'eval_loss_2': 0.004373073577880859, 'eval_loss_3': -18.107921600341797, 'eval_loss_4': -0.2682346701622009, 'epoch': 28.31}
{'loss': 0.007, 'grad_norm': 4.462222576141357, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.002535475417971611, 'loss_2': 0.004467010498046875, 'loss_3': -16.262182235717773, 'loss_4': -0.7257540225982666, 'epoch': 28.32}
{'loss': 0.1433, 'grad_norm': 22.86888313293457, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.14195053279399872, 'loss_2': 0.0013141632080078125, 'loss_3': -15.962787628173828, 'loss_4': -0.41470032930374146, 'epoch': 28.33}
{'loss': 0.0034, 'grad_norm': 4.3462300300598145, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.0030368498992174864, 'loss_2': 0.0003437995910644531, 'loss_3': -16.282394409179688, 'loss_4': -0.5734401941299438, 'epoch': 28.33}
{'loss': 0.0091, 'grad_norm': 4.507964611053467, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.005286748055368662, 'loss_2': 0.0037841796875, 'loss_3': -16.226829528808594, 'loss_4': -0.45024538040161133, 'epoch': 28.34}
{'loss': 0.0126, 'grad_norm': 4.789101600646973, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.004346346948295832, 'loss_2': 0.00823211669921875, 'loss_3': -16.12139892578125, 'loss_4': -0.4093444347381592, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 17:18:32,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:32,797 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [1:59:45<04:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:40,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02529597282409668, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.671, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.02103191614151001, 'eval_loss_2': 0.00426405668258667, 'eval_loss_3': -18.108366012573242, 'eval_loss_4': -0.25455236434936523, 'epoch': 28.34}
{'loss': 0.0066, 'grad_norm': 5.415692329406738, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.005493840202689171, 'loss_2': 0.001132965087890625, 'loss_3': -16.087949752807617, 'loss_4': 0.1460859477519989, 'epoch': 28.35}
{'loss': 0.0122, 'grad_norm': 5.0871758460998535, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.004255021922290325, 'loss_2': 0.00798797607421875, 'loss_3': -16.268413543701172, 'loss_4': -0.23592358827590942, 'epoch': 28.35}
{'loss': 0.0061, 'grad_norm': 5.27345085144043, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.005296988412737846, 'loss_2': 0.0007963180541992188, 'loss_3': -16.240507125854492, 'loss_4': -0.25183385610580444, 'epoch': 28.36}
{'loss': 0.0063, 'grad_norm': 4.586316108703613, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.0033748040441423655, 'loss_2': 0.0028896331787109375, 'loss_3': -16.165706634521484, 'loss_4': -0.1325182467699051, 'epoch': 28.37}
{'loss': 0.005, 'grad_norm': 4.237412929534912, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.003790265414863825, 'loss_2': 0.001186370849609375, 'loss_3': -16.298261642456055, 'loss_4': -0.5821033716201782, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 17:18:40,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:40,123 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [1:59:52<04:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:47,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02493170276284218, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.627, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.020864641293883324, 'eval_loss_2': 0.004067063331604004, 'eval_loss_3': -18.105621337890625, 'eval_loss_4': -0.23653505742549896, 'epoch': 28.37}
{'loss': 0.0026, 'grad_norm': 4.505621433258057, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.002393629401922226, 'loss_2': 0.00022542476654052734, 'loss_3': -16.440643310546875, 'loss_4': -0.382055401802063, 'epoch': 28.38}
{'loss': 0.0042, 'grad_norm': 4.756003379821777, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0021951564121991396, 'loss_2': 0.002025604248046875, 'loss_3': -16.43154525756836, 'loss_4': -0.27133217453956604, 'epoch': 28.38}
{'loss': 0.0097, 'grad_norm': 5.961418151855469, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.0059815882705152035, 'loss_2': 0.003688812255859375, 'loss_3': -16.109216690063477, 'loss_4': -0.3213129937648773, 'epoch': 28.39}
{'loss': 0.0041, 'grad_norm': 4.826869964599609, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.002817462431266904, 'loss_2': 0.0013217926025390625, 'loss_3': -16.267261505126953, 'loss_4': -0.2215258777141571, 'epoch': 28.4}
{'loss': 0.0068, 'grad_norm': 4.206012725830078, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.003417955245822668, 'loss_2': 0.0033931732177734375, 'loss_3': -16.092979431152344, 'loss_4': -0.25274425745010376, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 17:18:47,447 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:47,447 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:00<04:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:54,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024685580283403397, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.671, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.02067001536488533, 'eval_loss_2': 0.004015564918518066, 'eval_loss_3': -18.104076385498047, 'eval_loss_4': -0.22334857285022736, 'epoch': 28.4}
{'loss': 0.0112, 'grad_norm': 4.392081260681152, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.004164813552051783, 'loss_2': 0.007022857666015625, 'loss_3': -16.054931640625, 'loss_4': -0.4593260884284973, 'epoch': 28.41}
{'loss': 0.0084, 'grad_norm': 5.225368499755859, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.004817934241145849, 'loss_2': 0.003543853759765625, 'loss_3': -16.344890594482422, 'loss_4': -0.18475206196308136, 'epoch': 28.41}
{'loss': 0.0107, 'grad_norm': 6.14380407333374, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.00853264331817627, 'loss_2': 0.00214385986328125, 'loss_3': -16.17647933959961, 'loss_4': -0.047559306025505066, 'epoch': 28.42}
{'loss': 0.0107, 'grad_norm': 5.424284934997559, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.007501192390918732, 'loss_2': 0.003238677978515625, 'loss_3': -16.272024154663086, 'loss_4': -0.8409449458122253, 'epoch': 28.42}
{'loss': 0.0152, 'grad_norm': 5.31494140625, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.007345620077103376, 'loss_2': 0.00788116455078125, 'loss_3': -16.229747772216797, 'loss_4': -0.29611867666244507, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 17:18:54,773 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:54,773 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:07<04:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:19:02,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024314388632774353, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.711, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.020441193133592606, 'eval_loss_2': 0.003873199224472046, 'eval_loss_3': -18.106769561767578, 'eval_loss_4': -0.20584413409233093, 'epoch': 28.43}
{'loss': 0.0152, 'grad_norm': 5.947357177734375, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.009942841716110706, 'loss_2': 0.0052337646484375, 'loss_3': -16.31545639038086, 'loss_4': 0.27323147654533386, 'epoch': 28.44}
{'loss': 0.0049, 'grad_norm': 4.099619388580322, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.002216214779764414, 'loss_2': 0.00267791748046875, 'loss_3': -16.22663116455078, 'loss_4': -0.3258521556854248, 'epoch': 28.44}
{'loss': 0.0084, 'grad_norm': 4.427305221557617, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.005097589455544949, 'loss_2': 0.003314971923828125, 'loss_3': -16.04315948486328, 'loss_4': -0.2874230742454529, 'epoch': 28.45}
{'loss': 0.0077, 'grad_norm': 4.784598350524902, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.0042131333611905575, 'loss_2': 0.0035114288330078125, 'loss_3': -16.054750442504883, 'loss_4': -0.2771589159965515, 'epoch': 28.45}
{'loss': 0.0097, 'grad_norm': 4.689271926879883, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.005721411667764187, 'loss_2': 0.003936767578125, 'loss_3': -16.208152770996094, 'loss_4': -0.4043795168399811, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 17:19:02,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:02,093 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:14<04:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:19:09,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0239354707300663, 'eval_runtime': 3.7812, 'eval_samples_per_second': 270.814, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.020224427804350853, 'eval_loss_2': 0.0037110447883605957, 'eval_loss_3': -18.107545852661133, 'eval_loss_4': -0.1917273998260498, 'epoch': 28.46}
{'loss': 0.0021, 'grad_norm': 4.6050238609313965, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.0019261152483522892, 'loss_2': 0.0001881122589111328, 'loss_3': -16.309690475463867, 'loss_4': -0.4602372646331787, 'epoch': 28.47}
{'loss': 0.0134, 'grad_norm': 5.976611614227295, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.009324301965534687, 'loss_2': 0.00406646728515625, 'loss_3': -16.221826553344727, 'loss_4': -0.5957562327384949, 'epoch': 28.47}
{'loss': 0.0097, 'grad_norm': 5.308620452880859, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.006077961530536413, 'loss_2': 0.00363922119140625, 'loss_3': -16.08490753173828, 'loss_4': -0.5914171934127808, 'epoch': 28.48}
{'loss': 0.0066, 'grad_norm': 5.2484893798828125, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.004286675248295069, 'loss_2': 0.0023250579833984375, 'loss_3': -16.131797790527344, 'loss_4': -0.3055341839790344, 'epoch': 28.48}
{'loss': 0.0129, 'grad_norm': 5.69435453414917, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.01010865904390812, 'loss_2': 0.0027618408203125, 'loss_3': -16.40906524658203, 'loss_4': -0.19147813320159912, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 17:19:09,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:09,408 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:22<04:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:19:16,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0238043162971735, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.327, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.020178474485874176, 'eval_loss_2': 0.003625839948654175, 'eval_loss_3': -18.107851028442383, 'eval_loss_4': -0.18314366042613983, 'epoch': 28.49}
{'loss': 0.0146, 'grad_norm': 7.29985237121582, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.011649388819932938, 'loss_2': 0.002941131591796875, 'loss_3': -16.191375732421875, 'loss_4': -0.1455717384815216, 'epoch': 28.49}
{'loss': 0.0143, 'grad_norm': 4.79337739944458, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.00453958148136735, 'loss_2': 0.0097503662109375, 'loss_3': -16.260927200317383, 'loss_4': -0.5462151169776917, 'epoch': 28.5}
{'loss': 0.0026, 'grad_norm': 4.710484504699707, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.002173080574721098, 'loss_2': 0.0004134178161621094, 'loss_3': -16.2177734375, 'loss_4': -0.1903868466615677, 'epoch': 28.51}
{'loss': 0.0112, 'grad_norm': 6.375372886657715, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.011002321727573872, 'loss_2': 0.0001556873321533203, 'loss_3': -16.04825782775879, 'loss_4': -0.39381173253059387, 'epoch': 28.51}
{'loss': 0.0036, 'grad_norm': 4.577836036682129, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.003145819064229727, 'loss_2': 0.000499725341796875, 'loss_3': -16.314937591552734, 'loss_4': -0.41267645359039307, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 17:19:16,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:16,729 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:00:29<04:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:24,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024060862138867378, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.288, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.020457657054066658, 'eval_loss_2': 0.00360320508480072, 'eval_loss_3': -18.109661102294922, 'eval_loss_4': -0.17859557271003723, 'epoch': 28.52}
{'loss': 0.0052, 'grad_norm': 4.387022018432617, 'learning_rate': 1.5e-06, 'loss_1': 0.002815773943439126, 'loss_2': 0.002407073974609375, 'loss_3': -16.144561767578125, 'loss_4': -0.3704227805137634, 'epoch': 28.52}
{'loss': 0.0067, 'grad_norm': 4.582290172576904, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.00438727717846632, 'loss_2': 0.002346038818359375, 'loss_3': -16.330766677856445, 'loss_4': -0.37565404176712036, 'epoch': 28.53}
{'loss': 0.0052, 'grad_norm': 4.497687816619873, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.0046176486648619175, 'loss_2': 0.0006237030029296875, 'loss_3': -16.197328567504883, 'loss_4': -0.39012449979782104, 'epoch': 28.53}
{'loss': 0.0144, 'grad_norm': 7.17861795425415, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.014023493975400925, 'loss_2': 0.00032711029052734375, 'loss_3': -16.168800354003906, 'loss_4': -0.21015696227550507, 'epoch': 28.54}
{'loss': 0.0084, 'grad_norm': 4.732834339141846, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.006227103993296623, 'loss_2': 0.00220489501953125, 'loss_3': -16.141921997070312, 'loss_4': -0.00963485985994339, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 17:19:24,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:24,058 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:00:36<04:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:19:31,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02393389120697975, 'eval_runtime': 3.7832, 'eval_samples_per_second': 270.673, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.020370379090309143, 'eval_loss_2': 0.0035635121166706085, 'eval_loss_3': -18.104782104492188, 'eval_loss_4': -0.183616504073143, 'epoch': 28.55}
{'loss': 0.0028, 'grad_norm': 4.431199550628662, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.0026422706432640553, 'loss_2': 0.0001327991485595703, 'loss_3': -16.175827026367188, 'loss_4': -0.015327095985412598, 'epoch': 28.55}
{'loss': 0.0118, 'grad_norm': 4.514700889587402, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0034093300346285105, 'loss_2': 0.00841522216796875, 'loss_3': -16.244007110595703, 'loss_4': -0.5582063794136047, 'epoch': 28.56}
{'loss': 0.0078, 'grad_norm': 5.32259464263916, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.00641398411244154, 'loss_2': 0.001338958740234375, 'loss_3': -16.102901458740234, 'loss_4': -0.2511039674282074, 'epoch': 28.56}
{'loss': 0.0118, 'grad_norm': 5.107819080352783, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.005474728066474199, 'loss_2': 0.00637054443359375, 'loss_3': -16.18801498413086, 'loss_4': -0.47335588932037354, 'epoch': 28.57}
{'loss': 0.0134, 'grad_norm': 5.248028755187988, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.0060126204043626785, 'loss_2': 0.007434844970703125, 'loss_3': -16.30727767944336, 'loss_4': -0.3049430847167969, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 17:19:31,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:31,374 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:00:44<04:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:19:38,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023940574377775192, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.647, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.020377108827233315, 'eval_loss_2': 0.0035634636878967285, 'eval_loss_3': -18.100345611572266, 'eval_loss_4': -0.19442453980445862, 'epoch': 28.58}
{'loss': 0.0064, 'grad_norm': 4.8896684646606445, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.004063770640641451, 'loss_2': 0.0023441314697265625, 'loss_3': -16.219146728515625, 'loss_4': -0.1026512086391449, 'epoch': 28.58}
{'loss': 0.0055, 'grad_norm': 4.547646999359131, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.003152538323774934, 'loss_2': 0.0023326873779296875, 'loss_3': -16.064882278442383, 'loss_4': -0.20704257488250732, 'epoch': 28.59}
{'loss': 0.0058, 'grad_norm': 5.027480125427246, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.005557807628065348, 'loss_2': 0.00019788742065429688, 'loss_3': -16.205013275146484, 'loss_4': -0.11537288129329681, 'epoch': 28.59}
{'loss': 0.0107, 'grad_norm': 6.8640875816345215, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.010206044651567936, 'loss_2': 0.0005025863647460938, 'loss_3': -16.140625, 'loss_4': -0.6553266644477844, 'epoch': 28.6}
{'loss': 0.0113, 'grad_norm': 5.208254814147949, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.006099458783864975, 'loss_2': 0.0052490234375, 'loss_3': -16.19189453125, 'loss_4': -0.3602079153060913, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 17:19:38,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:38,693 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:00:51<04:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:46,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024068839848041534, 'eval_runtime': 3.7803, 'eval_samples_per_second': 270.875, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.020472906529903412, 'eval_loss_2': 0.0035959333181381226, 'eval_loss_3': -18.096765518188477, 'eval_loss_4': -0.19972899556159973, 'epoch': 28.6}
{'loss': 0.0036, 'grad_norm': 4.629743576049805, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0028460172470659018, 'loss_2': 0.0007524490356445312, 'loss_3': -16.437870025634766, 'loss_4': -0.3132409453392029, 'epoch': 28.61}
{'loss': 0.0067, 'grad_norm': 4.9128618240356445, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.00572399515658617, 'loss_2': 0.0009946823120117188, 'loss_3': -16.185382843017578, 'loss_4': -0.3955383598804474, 'epoch': 28.62}
{'loss': 0.0093, 'grad_norm': 4.060030460357666, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.006090129259973764, 'loss_2': 0.00316619873046875, 'loss_3': -16.355939865112305, 'loss_4': 0.03020884096622467, 'epoch': 28.62}
{'loss': 0.0115, 'grad_norm': 4.354105472564697, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.003715137718245387, 'loss_2': 0.00780487060546875, 'loss_3': -16.189655303955078, 'loss_4': -0.337438702583313, 'epoch': 28.63}
{'loss': 0.0111, 'grad_norm': 4.369773864746094, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.00470008235424757, 'loss_2': 0.006397247314453125, 'loss_3': -16.3096923828125, 'loss_4': -0.09707902371883392, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 17:19:46,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:46,017 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:00:58<03:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:53,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024372875690460205, 'eval_runtime': 3.7827, 'eval_samples_per_second': 270.71, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.02074730210006237, 'eval_loss_2': 0.0036255717277526855, 'eval_loss_3': -18.08968162536621, 'eval_loss_4': -0.20029163360595703, 'epoch': 28.63}
{'loss': 0.0058, 'grad_norm': 5.016573905944824, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.003508918220177293, 'loss_2': 0.002277374267578125, 'loss_3': -16.220577239990234, 'loss_4': -0.1959758847951889, 'epoch': 28.64}
{'loss': 0.016, 'grad_norm': 5.5732741355896, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.009297078475356102, 'loss_2': 0.00673675537109375, 'loss_3': -16.11412811279297, 'loss_4': 0.10746236145496368, 'epoch': 28.65}
{'loss': 0.0037, 'grad_norm': 4.499780178070068, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.003314052941277623, 'loss_2': 0.00035572052001953125, 'loss_3': -16.27189826965332, 'loss_4': -0.6823115944862366, 'epoch': 28.65}
{'loss': 0.0076, 'grad_norm': 6.861228942871094, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.005320596508681774, 'loss_2': 0.002315521240234375, 'loss_3': -16.29416275024414, 'loss_4': -0.4242362976074219, 'epoch': 28.66}
{'loss': 0.0043, 'grad_norm': 4.4571685791015625, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.0021561712492257357, 'loss_2': 0.002170562744140625, 'loss_3': -16.234153747558594, 'loss_4': -0.31147295236587524, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 17:19:53,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:53,340 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:06<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:00,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02479482814669609, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.112, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.021255087107419968, 'eval_loss_2': 0.003539741039276123, 'eval_loss_3': -18.091554641723633, 'eval_loss_4': -0.20147347450256348, 'epoch': 28.66}
{'loss': 0.0166, 'grad_norm': 11.788028717041016, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.01448313519358635, 'loss_2': 0.002147674560546875, 'loss_3': -16.375335693359375, 'loss_4': 0.08718433976173401, 'epoch': 28.67}
{'loss': 0.0055, 'grad_norm': 5.160592555999756, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.005437058862298727, 'loss_2': 4.374980926513672e-05, 'loss_3': -16.185935974121094, 'loss_4': -0.33978793025016785, 'epoch': 28.67}
{'loss': 0.0137, 'grad_norm': 5.669039249420166, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.007203695364296436, 'loss_2': 0.006465911865234375, 'loss_3': -16.176708221435547, 'loss_4': 0.22167369723320007, 'epoch': 28.68}
{'loss': 0.0045, 'grad_norm': 4.289065837860107, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.003956635016947985, 'loss_2': 0.0005483627319335938, 'loss_3': -16.19008445739746, 'loss_4': -0.3275644779205322, 'epoch': 28.69}
{'loss': 0.0123, 'grad_norm': 4.467793941497803, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.005546079482883215, 'loss_2': 0.006717681884765625, 'loss_3': -16.127965927124023, 'loss_4': -0.6350401639938354, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 17:20:00,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:00,675 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:13<03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:08,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024809159338474274, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.474, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021277710795402527, 'eval_loss_2': 0.003531448543071747, 'eval_loss_3': -18.093690872192383, 'eval_loss_4': -0.20732517540454865, 'epoch': 28.69}
{'loss': 0.0071, 'grad_norm': 4.51880407333374, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.003520111320540309, 'loss_2': 0.00362396240234375, 'loss_3': -16.332096099853516, 'loss_4': -0.4428177773952484, 'epoch': 28.7}
{'loss': 0.0081, 'grad_norm': 4.5504560470581055, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.004935980308800936, 'loss_2': 0.003192901611328125, 'loss_3': -16.21746826171875, 'loss_4': -0.3344174325466156, 'epoch': 28.7}
{'loss': 0.0114, 'grad_norm': 5.389519214630127, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.009231770411133766, 'loss_2': 0.002216339111328125, 'loss_3': -16.18720245361328, 'loss_4': -0.25751644372940063, 'epoch': 28.71}
{'loss': 0.0054, 'grad_norm': 4.688226222991943, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.003511020913720131, 'loss_2': 0.00186920166015625, 'loss_3': -16.131797790527344, 'loss_4': -0.4093691408634186, 'epoch': 28.72}
{'loss': 0.0042, 'grad_norm': 4.372070789337158, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.001618843525648117, 'loss_2': 0.0026302337646484375, 'loss_3': -16.137939453125, 'loss_4': -0.5199993848800659, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 17:20:08,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:08,003 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:20<03:45,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:20:15,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02461421675980091, 'eval_runtime': 3.9997, 'eval_samples_per_second': 256.02, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.021049080416560173, 'eval_loss_2': 0.0035651326179504395, 'eval_loss_3': -18.093814849853516, 'eval_loss_4': -0.21616439521312714, 'epoch': 28.72}
{'loss': 0.0109, 'grad_norm': 4.72960901260376, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.00579987233504653, 'loss_2': 0.005130767822265625, 'loss_3': -16.275794982910156, 'loss_4': -0.32804226875305176, 'epoch': 28.73}
{'loss': 0.008, 'grad_norm': 4.069102764129639, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.0024136414285749197, 'loss_2': 0.00562286376953125, 'loss_3': -16.211090087890625, 'loss_4': 0.04522864520549774, 'epoch': 28.73}
{'loss': 0.006, 'grad_norm': 4.906447410583496, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.004753440152853727, 'loss_2': 0.0012063980102539062, 'loss_3': -16.28990936279297, 'loss_4': -0.3093467056751251, 'epoch': 28.74}
{'loss': 0.0047, 'grad_norm': 4.261826992034912, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.002737918170168996, 'loss_2': 0.0019588470458984375, 'loss_3': -16.130578994750977, 'loss_4': -0.24447393417358398, 'epoch': 28.74}
{'loss': 0.014, 'grad_norm': 5.115060806274414, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.005428800825029612, 'loss_2': 0.00859832763671875, 'loss_3': -16.24472427368164, 'loss_4': -0.34930068254470825, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 17:20:15,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:15,538 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:01:28<03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:22,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024608131498098373, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.028, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020967166870832443, 'eval_loss_2': 0.00364096462726593, 'eval_loss_3': -18.099327087402344, 'eval_loss_4': -0.21835073828697205, 'epoch': 28.75}
{'loss': 0.0077, 'grad_norm': 4.605666637420654, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.0024267833214253187, 'loss_2': 0.00524139404296875, 'loss_3': -16.402530670166016, 'loss_4': -0.30037635564804077, 'epoch': 28.76}
{'loss': 0.0072, 'grad_norm': 4.70211935043335, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0051916432566940784, 'loss_2': 0.002048492431640625, 'loss_3': -16.188129425048828, 'loss_4': -0.2761451005935669, 'epoch': 28.76}
{'loss': 0.0078, 'grad_norm': 5.194271087646484, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.005381621420383453, 'loss_2': 0.0024356842041015625, 'loss_3': -16.267364501953125, 'loss_4': -0.21211083233356476, 'epoch': 28.77}
{'loss': 0.0076, 'grad_norm': 4.247066020965576, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.003777707228437066, 'loss_2': 0.0038661956787109375, 'loss_3': -16.261398315429688, 'loss_4': 0.010406836867332458, 'epoch': 28.77}
{'loss': 0.008, 'grad_norm': 5.971531867980957, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.007296365685760975, 'loss_2': 0.0007476806640625, 'loss_3': -16.39735984802246, 'loss_4': 0.03368285298347473, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 17:20:22,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:22,869 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:01:35<03:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:20:30,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0246751569211483, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.49, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021075885742902756, 'eval_loss_2': 0.0035992711782455444, 'eval_loss_3': -18.098573684692383, 'eval_loss_4': -0.22327736020088196, 'epoch': 28.78}
{'loss': 0.0118, 'grad_norm': 5.715965270996094, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.008302968926727772, 'loss_2': 0.003528594970703125, 'loss_3': -16.33305549621582, 'loss_4': -0.24423502385616302, 'epoch': 28.78}
{'loss': 0.0273, 'grad_norm': 8.706138610839844, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.02114214561879635, 'loss_2': 0.006122589111328125, 'loss_3': -16.121225357055664, 'loss_4': -0.34239399433135986, 'epoch': 28.79}
{'loss': 0.0029, 'grad_norm': 4.922252178192139, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.002740035532042384, 'loss_2': 0.0001304149627685547, 'loss_3': -16.287609100341797, 'loss_4': -0.5035818219184875, 'epoch': 28.8}
{'loss': 0.0054, 'grad_norm': 4.343656063079834, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.004601398948580027, 'loss_2': 0.0008268356323242188, 'loss_3': -16.111255645751953, 'loss_4': -0.556825578212738, 'epoch': 28.8}
{'loss': 0.0136, 'grad_norm': 5.729158401489258, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.008084011264145374, 'loss_2': 0.00550079345703125, 'loss_3': -16.223480224609375, 'loss_4': -0.09540063887834549, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 17:20:30,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:30,188 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:01:42<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:37,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024643536657094955, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.214, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.021093977615237236, 'eval_loss_2': 0.00354955717921257, 'eval_loss_3': -18.095003128051758, 'eval_loss_4': -0.23994490504264832, 'epoch': 28.81}
{'loss': 0.0133, 'grad_norm': 6.989386081695557, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.01054022554308176, 'loss_2': 0.0027675628662109375, 'loss_3': -16.153860092163086, 'loss_4': -0.39901188015937805, 'epoch': 28.81}
{'loss': 0.0114, 'grad_norm': 7.846869945526123, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.009453603997826576, 'loss_2': 0.001983642578125, 'loss_3': -15.944520950317383, 'loss_4': -0.5692629814147949, 'epoch': 28.82}
{'loss': 0.0052, 'grad_norm': 4.403283596038818, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.0033867117017507553, 'loss_2': 0.001766204833984375, 'loss_3': -16.206403732299805, 'loss_4': -0.5044259428977966, 'epoch': 28.83}
{'loss': 0.0062, 'grad_norm': 4.845214366912842, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.00461876206099987, 'loss_2': 0.001613616943359375, 'loss_3': -16.43780517578125, 'loss_4': -0.4416658878326416, 'epoch': 28.83}
{'loss': 0.0078, 'grad_norm': 4.831777572631836, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.004305077716708183, 'loss_2': 0.00345611572265625, 'loss_3': -16.509084701538086, 'loss_4': -0.2523694932460785, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 17:20:37,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:37,529 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:01:50<03:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:44,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024644147604703903, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.267, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.02108425833284855, 'eval_loss_2': 0.003559887409210205, 'eval_loss_3': -18.09542465209961, 'eval_loss_4': -0.23749765753746033, 'epoch': 28.84}
{'loss': 0.0059, 'grad_norm': 4.340373992919922, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.003084408352151513, 'loss_2': 0.002826690673828125, 'loss_3': -16.106632232666016, 'loss_4': -0.4212566018104553, 'epoch': 28.84}
{'loss': 0.0103, 'grad_norm': 4.9012956619262695, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.006702684797346592, 'loss_2': 0.003574371337890625, 'loss_3': -16.270652770996094, 'loss_4': -0.3025304079055786, 'epoch': 28.85}
{'loss': 0.0092, 'grad_norm': 4.96800422668457, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.006975455675274134, 'loss_2': 0.0022125244140625, 'loss_3': -16.297039031982422, 'loss_4': -0.6413382291793823, 'epoch': 28.85}
{'loss': 0.0111, 'grad_norm': 5.947330474853516, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.006844769697636366, 'loss_2': 0.004283905029296875, 'loss_3': -16.30961799621582, 'loss_4': -0.38957199454307556, 'epoch': 28.86}
{'loss': 0.0106, 'grad_norm': 5.883707523345947, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.00863222312182188, 'loss_2': 0.001995086669921875, 'loss_3': -16.176868438720703, 'loss_4': -0.5862922668457031, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 17:20:44,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:44,854 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:01:57<03:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:52,176 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02439689077436924, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.442, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.020954841747879982, 'eval_loss_2': 0.003442049026489258, 'eval_loss_3': -18.0961971282959, 'eval_loss_4': -0.23309966921806335, 'epoch': 28.87}
{'loss': 0.0057, 'grad_norm': 5.606623649597168, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.004939693957567215, 'loss_2': 0.000762939453125, 'loss_3': -16.303674697875977, 'loss_4': -0.5749058723449707, 'epoch': 28.87}
{'loss': 0.0074, 'grad_norm': 4.667083263397217, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.0042466698214411736, 'loss_2': 0.0031528472900390625, 'loss_3': -16.362686157226562, 'loss_4': -0.11506523191928864, 'epoch': 28.88}
{'loss': 0.0024, 'grad_norm': 4.640342712402344, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.0020593099761754274, 'loss_2': 0.00033402442932128906, 'loss_3': -16.17858123779297, 'loss_4': 0.003680385649204254, 'epoch': 28.88}
{'loss': 0.0108, 'grad_norm': 4.989804744720459, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.003973614890128374, 'loss_2': 0.006855010986328125, 'loss_3': -16.353588104248047, 'loss_4': -0.5556609630584717, 'epoch': 28.89}
{'loss': 0.0103, 'grad_norm': 5.58528995513916, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.006360094994306564, 'loss_2': 0.0039215087890625, 'loss_3': -16.134153366088867, 'loss_4': -0.4139838218688965, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 17:20:52,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:52,176 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:04<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:59,503 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02443181537091732, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.429, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.020963378250598907, 'eval_loss_2': 0.003468438982963562, 'eval_loss_3': -18.09824562072754, 'eval_loss_4': -0.224339559674263, 'epoch': 28.9}
{'loss': 0.0131, 'grad_norm': 5.612532615661621, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.006345576606690884, 'loss_2': 0.0067596435546875, 'loss_3': -16.266342163085938, 'loss_4': 0.08935150504112244, 'epoch': 28.9}
{'loss': 0.0136, 'grad_norm': 5.514289855957031, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.009747613221406937, 'loss_2': 0.0038852691650390625, 'loss_3': -16.125137329101562, 'loss_4': -0.11994782090187073, 'epoch': 28.91}
{'loss': 0.0115, 'grad_norm': 6.770232200622559, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.0061051067896187305, 'loss_2': 0.005443572998046875, 'loss_3': -16.084714889526367, 'loss_4': -0.23303848505020142, 'epoch': 28.91}
{'loss': 0.0063, 'grad_norm': 4.3499979972839355, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.002505006268620491, 'loss_2': 0.003841400146484375, 'loss_3': -16.30555534362793, 'loss_4': -0.33314964175224304, 'epoch': 28.92}
{'loss': 0.0054, 'grad_norm': 4.808874607086182, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.004223031457513571, 'loss_2': 0.0012187957763671875, 'loss_3': -16.104700088500977, 'loss_4': -0.4066425561904907, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 17:20:59,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:59,504 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:12<03:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:21:06,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024658452719449997, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.424, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.021080145612359047, 'eval_loss_2': 0.0035783052444458008, 'eval_loss_3': -18.09952735900879, 'eval_loss_4': -0.21516172587871552, 'epoch': 28.92}
{'loss': 0.0104, 'grad_norm': 5.162429332733154, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.006018692161887884, 'loss_2': 0.004367828369140625, 'loss_3': -16.07356834411621, 'loss_4': 0.030759505927562714, 'epoch': 28.93}
{'loss': 0.0083, 'grad_norm': 4.348957538604736, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.0038775817956775427, 'loss_2': 0.004421234130859375, 'loss_3': -16.134197235107422, 'loss_4': -0.27386239171028137, 'epoch': 28.94}
{'loss': 0.0059, 'grad_norm': 4.3301239013671875, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.004389023873955011, 'loss_2': 0.00148773193359375, 'loss_3': -16.198917388916016, 'loss_4': -0.4602643847465515, 'epoch': 28.94}
{'loss': 0.0097, 'grad_norm': 4.273652076721191, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.004150602966547012, 'loss_2': 0.005512237548828125, 'loss_3': -16.24828338623047, 'loss_4': -0.15876972675323486, 'epoch': 28.95}
{'loss': 0.0076, 'grad_norm': 4.99732780456543, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.005406646057963371, 'loss_2': 0.002166748046875, 'loss_3': -16.295881271362305, 'loss_4': -0.5561190843582153, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 17:21:06,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:06,825 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:19<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:14,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02472424879670143, 'eval_runtime': 3.7815, 'eval_samples_per_second': 270.794, 'eval_steps_per_second': 4.231, 'eval_loss_1': 0.02106667123734951, 'eval_loss_2': 0.0036575794219970703, 'eval_loss_3': -18.094928741455078, 'eval_loss_4': -0.20748820900917053, 'epoch': 28.95}
{'loss': 0.0075, 'grad_norm': 5.226850509643555, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.004928264766931534, 'loss_2': 0.0025577545166015625, 'loss_3': -16.204557418823242, 'loss_4': -0.16628476977348328, 'epoch': 28.96}
{'loss': 0.0086, 'grad_norm': 4.63870096206665, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.00614212267100811, 'loss_2': 0.00244903564453125, 'loss_3': -16.273216247558594, 'loss_4': -0.38348472118377686, 'epoch': 28.97}
{'loss': 0.0074, 'grad_norm': 4.196903228759766, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0031900762114673853, 'loss_2': 0.0042266845703125, 'loss_3': -16.271621704101562, 'loss_4': -0.21448731422424316, 'epoch': 28.97}
{'loss': 0.0031, 'grad_norm': 4.39542293548584, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0024426360614597797, 'loss_2': 0.0006608963012695312, 'loss_3': -16.32282257080078, 'loss_4': -0.5233318209648132, 'epoch': 28.98}
{'loss': 0.0043, 'grad_norm': 4.2741475105285645, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0036424940917640924, 'loss_2': 0.0006723403930664062, 'loss_3': -16.296478271484375, 'loss_4': -0.6454237699508667, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 17:21:14,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:14,144 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:26<02:48,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 17:21:21,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02452024444937706, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.020941877737641335, 'eval_loss_2': 0.003578364849090576, 'eval_loss_3': -18.093534469604492, 'eval_loss_4': -0.20772632956504822, 'epoch': 28.98}
{'loss': 0.0087, 'grad_norm': 4.763458251953125, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.004479649476706982, 'loss_2': 0.0042572021484375, 'loss_3': -16.212554931640625, 'loss_4': -0.21503561735153198, 'epoch': 28.99}
{'loss': 0.0092, 'grad_norm': 5.018247127532959, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.00427275849506259, 'loss_2': 0.004932403564453125, 'loss_3': -16.370906829833984, 'loss_4': -0.6185087561607361, 'epoch': 28.99}
{'loss': 0.0082, 'grad_norm': 7.785595893859863, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.005630733445286751, 'loss_2': 0.002605438232421875, 'loss_3': -16.035472869873047, 'loss_4': -0.02609076537191868, 'epoch': 29.0}
{'loss': 0.0091, 'grad_norm': 4.728343963623047, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.00465988228097558, 'loss_2': 0.00444793701171875, 'loss_3': -16.16041374206543, 'loss_4': -0.3811401128768921, 'epoch': 29.01}
{'loss': 0.0133, 'grad_norm': 6.5550217628479, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.009995942004024982, 'loss_2': 0.0032711029052734375, 'loss_3': -16.378496170043945, 'loss_4': -0.43316903710365295, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 17:21:21,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:21,155 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:02:33<02:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:21:28,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024486536160111427, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.412, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02089902199804783, 'eval_loss_2': 0.0035875141620635986, 'eval_loss_3': -18.092723846435547, 'eval_loss_4': -0.21012340486049652, 'epoch': 29.01}
{'loss': 0.0138, 'grad_norm': 5.311154365539551, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.007300005294382572, 'loss_2': 0.0065155029296875, 'loss_3': -16.288307189941406, 'loss_4': -0.24151253700256348, 'epoch': 29.02}
{'loss': 0.0081, 'grad_norm': 4.5350141525268555, 'learning_rate': 1e-06, 'loss_1': 0.003947695251554251, 'loss_2': 0.004119873046875, 'loss_3': -16.174423217773438, 'loss_4': -0.15571841597557068, 'epoch': 29.02}
{'loss': 0.0032, 'grad_norm': 4.250856399536133, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.0027861488051712513, 'loss_2': 0.0003669261932373047, 'loss_3': -16.319507598876953, 'loss_4': -0.2747216522693634, 'epoch': 29.03}
{'loss': 0.0103, 'grad_norm': 5.431118488311768, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.007355656940490007, 'loss_2': 0.002910614013671875, 'loss_3': -16.289152145385742, 'loss_4': -0.4313555061817169, 'epoch': 29.03}
{'loss': 0.0068, 'grad_norm': 5.249428749084473, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.004569276235997677, 'loss_2': 0.002277374267578125, 'loss_3': -16.49956512451172, 'loss_4': -0.43995511531829834, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 17:21:28,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:28,484 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:02:41<02:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:21:35,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024283520877361298, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.118, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.020726613700389862, 'eval_loss_2': 0.0035569071769714355, 'eval_loss_3': -18.090599060058594, 'eval_loss_4': -0.2198486477136612, 'epoch': 29.04}
{'loss': 0.0076, 'grad_norm': 4.676218032836914, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.007400232367217541, 'loss_2': 0.0002455711364746094, 'loss_3': -16.025754928588867, 'loss_4': -0.028649792075157166, 'epoch': 29.05}
{'loss': 0.0071, 'grad_norm': 4.59063196182251, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.004083998501300812, 'loss_2': 0.0030193328857421875, 'loss_3': -16.0636043548584, 'loss_4': -0.5130444169044495, 'epoch': 29.05}
{'loss': 0.0105, 'grad_norm': 6.891604423522949, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.010108944028615952, 'loss_2': 0.00037384033203125, 'loss_3': -16.16455078125, 'loss_4': -0.1481708586215973, 'epoch': 29.06}
{'loss': 0.0111, 'grad_norm': 4.997304916381836, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.008126930333673954, 'loss_2': 0.002948760986328125, 'loss_3': -16.09778594970703, 'loss_4': 0.026361092925071716, 'epoch': 29.06}
{'loss': 0.0054, 'grad_norm': 4.774355411529541, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.002255172934383154, 'loss_2': 0.003131866455078125, 'loss_3': -16.4282169342041, 'loss_4': -0.5419356822967529, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 17:21:35,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:35,814 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:02:48<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:43,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02405686490237713, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.167, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.020614221692085266, 'eval_loss_2': 0.0034426450729370117, 'eval_loss_3': -18.090646743774414, 'eval_loss_4': -0.2301628589630127, 'epoch': 29.07}
{'loss': 0.0135, 'grad_norm': 5.990446090698242, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.0076732272282242775, 'loss_2': 0.005779266357421875, 'loss_3': -16.114032745361328, 'loss_4': -0.4917258024215698, 'epoch': 29.08}
{'loss': 0.0091, 'grad_norm': 4.838161945343018, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.004129915498197079, 'loss_2': 0.00492095947265625, 'loss_3': -16.354759216308594, 'loss_4': -0.10947389155626297, 'epoch': 29.08}
{'loss': 0.0074, 'grad_norm': 4.519989967346191, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.0022758443374186754, 'loss_2': 0.0051727294921875, 'loss_3': -16.242473602294922, 'loss_4': -0.0584469735622406, 'epoch': 29.09}
{'loss': 0.0612, 'grad_norm': 13.142791748046875, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.06024077534675598, 'loss_2': 0.00098419189453125, 'loss_3': -16.16777229309082, 'loss_4': 0.16338090598583221, 'epoch': 29.09}
{'loss': 0.0057, 'grad_norm': 4.746102333068848, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.002641193335875869, 'loss_2': 0.00310516357421875, 'loss_3': -16.345407485961914, 'loss_4': -0.0633181780576706, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 17:21:43,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:43,145 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:02:55<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:50,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02405262365937233, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.306, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.020650748163461685, 'eval_loss_2': 0.0034018754959106445, 'eval_loss_3': -18.092918395996094, 'eval_loss_4': -0.2407224029302597, 'epoch': 29.1}
{'loss': 0.011, 'grad_norm': 5.5355987548828125, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.0065115285106003284, 'loss_2': 0.00444793701171875, 'loss_3': -16.240131378173828, 'loss_4': -0.045339107513427734, 'epoch': 29.1}
{'loss': 0.0189, 'grad_norm': 11.64990234375, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.013261941261589527, 'loss_2': 0.00568389892578125, 'loss_3': -16.028772354125977, 'loss_4': -0.25264477729797363, 'epoch': 29.11}
{'loss': 0.0138, 'grad_norm': 6.523487567901611, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.012412706390023232, 'loss_2': 0.0013790130615234375, 'loss_3': -16.23719024658203, 'loss_4': -0.5431652069091797, 'epoch': 29.12}
{'loss': 0.0044, 'grad_norm': 4.253483295440674, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.002299117622897029, 'loss_2': 0.0021343231201171875, 'loss_3': -16.376903533935547, 'loss_4': -0.044317543506622314, 'epoch': 29.12}
{'loss': 0.0101, 'grad_norm': 5.601231575012207, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.006250504404306412, 'loss_2': 0.003818511962890625, 'loss_3': -16.149946212768555, 'loss_4': -0.5131009817123413, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 17:21:50,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:50,473 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:03<02:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:21:57,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024004412814974785, 'eval_runtime': 3.7826, 'eval_samples_per_second': 270.711, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.0206576120108366, 'eval_loss_2': 0.0033468008041381836, 'eval_loss_3': -18.093786239624023, 'eval_loss_4': -0.25502076745033264, 'epoch': 29.13}
{'loss': 0.0069, 'grad_norm': 5.067660808563232, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.006564939394593239, 'loss_2': 0.0003218650817871094, 'loss_3': -16.110687255859375, 'loss_4': -0.13808420300483704, 'epoch': 29.13}
{'loss': 0.0034, 'grad_norm': 4.35248327255249, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.0031151946168392897, 'loss_2': 0.00025725364685058594, 'loss_3': -16.100311279296875, 'loss_4': -0.4701472520828247, 'epoch': 29.14}
{'loss': 0.0078, 'grad_norm': 4.482370853424072, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.0036907608155161142, 'loss_2': 0.004116058349609375, 'loss_3': -16.21070671081543, 'loss_4': -0.5368812084197998, 'epoch': 29.15}
{'loss': 0.015, 'grad_norm': 4.595938205718994, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.004988504573702812, 'loss_2': 0.010009765625, 'loss_3': -16.376089096069336, 'loss_4': -0.22847247123718262, 'epoch': 29.15}
{'loss': 0.005, 'grad_norm': 4.742638111114502, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0031256184447556734, 'loss_2': 0.001888275146484375, 'loss_3': -16.29850196838379, 'loss_4': -0.3938998281955719, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 17:21:57,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:57,793 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:10<02:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:05,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024077825248241425, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.273, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.020735016092658043, 'eval_loss_2': 0.0033428072929382324, 'eval_loss_3': -18.095651626586914, 'eval_loss_4': -0.265565425157547, 'epoch': 29.16}
{'loss': 0.0188, 'grad_norm': 10.60255241394043, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.013350140303373337, 'loss_2': 0.0054931640625, 'loss_3': -16.13109588623047, 'loss_4': -0.19106803834438324, 'epoch': 29.16}
{'loss': 0.0138, 'grad_norm': 9.553936958312988, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.013261561281979084, 'loss_2': 0.0005283355712890625, 'loss_3': -16.234355926513672, 'loss_4': -0.6061118245124817, 'epoch': 29.17}
{'loss': 0.005, 'grad_norm': 5.851447582244873, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.0049704285338521, 'loss_2': 2.968311309814453e-05, 'loss_3': -16.21314811706543, 'loss_4': -0.381888210773468, 'epoch': 29.17}
{'loss': 0.0087, 'grad_norm': 5.6061811447143555, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.008581873960793018, 'loss_2': 0.000156402587890625, 'loss_3': -16.34881591796875, 'loss_4': -0.26564139127731323, 'epoch': 29.18}
{'loss': 0.0083, 'grad_norm': 4.778232574462891, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.004663976840674877, 'loss_2': 0.00359344482421875, 'loss_3': -16.083087921142578, 'loss_4': -0.2857189178466797, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 17:22:05,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:05,117 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:17<02:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:12,441 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024188891053199768, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.64, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.02079339139163494, 'eval_loss_2': 0.0033954977989196777, 'eval_loss_3': -18.094221115112305, 'eval_loss_4': -0.2757624387741089, 'epoch': 29.19}
{'loss': 0.014, 'grad_norm': 5.250192642211914, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.007545255124568939, 'loss_2': 0.006488800048828125, 'loss_3': -16.31397819519043, 'loss_4': -0.06578879058361053, 'epoch': 29.19}
{'loss': 0.0082, 'grad_norm': 4.495057106018066, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0017311585834249854, 'loss_2': 0.0064697265625, 'loss_3': -16.131380081176758, 'loss_4': 0.05242341011762619, 'epoch': 29.2}
{'loss': 0.015, 'grad_norm': 5.373498439788818, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.007230146322399378, 'loss_2': 0.0077667236328125, 'loss_3': -16.142715454101562, 'loss_4': -0.6323822736740112, 'epoch': 29.2}
{'loss': 0.0078, 'grad_norm': 4.646538257598877, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.005764325615018606, 'loss_2': 0.0020351409912109375, 'loss_3': -16.27699089050293, 'loss_4': -0.16321516036987305, 'epoch': 29.21}
{'loss': 0.011, 'grad_norm': 4.873117923736572, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.005109866615384817, 'loss_2': 0.0058746337890625, 'loss_3': -16.385555267333984, 'loss_4': -0.10389840602874756, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 17:22:12,441 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:12,441 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:25<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:19,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024564377963542938, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.51, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.021067971363663673, 'eval_loss_2': 0.003496408462524414, 'eval_loss_3': -18.090015411376953, 'eval_loss_4': -0.28070390224456787, 'epoch': 29.22}
{'loss': 0.005, 'grad_norm': 5.036954402923584, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0043131024576723576, 'loss_2': 0.0006799697875976562, 'loss_3': -16.291969299316406, 'loss_4': 0.07360348105430603, 'epoch': 29.22}
{'loss': 0.0112, 'grad_norm': 6.558337688446045, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.005776804406195879, 'loss_2': 0.005401611328125, 'loss_3': -16.059009552001953, 'loss_4': -0.5849469900131226, 'epoch': 29.23}
{'loss': 0.0086, 'grad_norm': 4.4369425773620605, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.004328734707087278, 'loss_2': 0.0042266845703125, 'loss_3': -16.45836067199707, 'loss_4': -0.04706543684005737, 'epoch': 29.23}
{'loss': 0.0102, 'grad_norm': 4.54733943939209, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.0034322089049965143, 'loss_2': 0.00678253173828125, 'loss_3': -16.083690643310547, 'loss_4': -0.34772807359695435, 'epoch': 29.24}
{'loss': 0.0064, 'grad_norm': 4.6195387840271, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.005029674153774977, 'loss_2': 0.0013294219970703125, 'loss_3': -16.218875885009766, 'loss_4': -0.6950546503067017, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 17:22:19,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:19,764 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:03:32<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:27,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024831611663103104, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.537, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.021273629739880562, 'eval_loss_2': 0.0035579800605773926, 'eval_loss_3': -18.08907699584961, 'eval_loss_4': -0.2840144634246826, 'epoch': 29.24}
{'loss': 0.0139, 'grad_norm': 6.0905070304870605, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.008872004225850105, 'loss_2': 0.005031585693359375, 'loss_3': -16.295297622680664, 'loss_4': -0.6415393352508545, 'epoch': 29.25}
{'loss': 0.0058, 'grad_norm': 5.136035919189453, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.005590400658547878, 'loss_2': 0.00019288063049316406, 'loss_3': -16.425945281982422, 'loss_4': -0.6232320070266724, 'epoch': 29.26}
{'loss': 0.0641, 'grad_norm': 17.215856552124023, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.06380351632833481, 'loss_2': 0.00028061866760253906, 'loss_3': -16.419219970703125, 'loss_4': -0.0034758448600769043, 'epoch': 29.26}
{'loss': 0.0079, 'grad_norm': 4.848948955535889, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.007101057097315788, 'loss_2': 0.00084686279296875, 'loss_3': -16.265621185302734, 'loss_4': -0.2448491007089615, 'epoch': 29.27}
{'loss': 0.0094, 'grad_norm': 4.607858180999756, 'learning_rate': 7.5e-07, 'loss_1': 0.003998144995421171, 'loss_2': 0.00537872314453125, 'loss_3': -16.409744262695312, 'loss_4': -0.7782295346260071, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 17:22:27,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:27,088 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:03:39<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:34,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02499120496213436, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.443, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.021376600489020348, 'eval_loss_2': 0.0036146044731140137, 'eval_loss_3': -18.08765411376953, 'eval_loss_4': -0.28996309638023376, 'epoch': 29.27}
{'loss': 0.0067, 'grad_norm': 4.71470832824707, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.004452133551239967, 'loss_2': 0.002292633056640625, 'loss_3': -16.3946533203125, 'loss_4': 0.06039813905954361, 'epoch': 29.28}
{'loss': 0.0047, 'grad_norm': 4.18186092376709, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0036701299250125885, 'loss_2': 0.00099945068359375, 'loss_3': -16.254554748535156, 'loss_4': -0.6008250713348389, 'epoch': 29.28}
{'loss': 0.0043, 'grad_norm': 4.99372673034668, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.002671343507245183, 'loss_2': 0.0016546249389648438, 'loss_3': -16.247344970703125, 'loss_4': 0.11597490310668945, 'epoch': 29.29}
{'loss': 0.0074, 'grad_norm': 5.355004787445068, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.005611009430140257, 'loss_2': 0.0018062591552734375, 'loss_3': -16.11188507080078, 'loss_4': -0.4076707661151886, 'epoch': 29.3}
{'loss': 0.0056, 'grad_norm': 4.721944808959961, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.004935922101140022, 'loss_2': 0.0006818771362304688, 'loss_3': -16.1621150970459, 'loss_4': -0.6922493577003479, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 17:22:34,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:34,414 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:03:47<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:41,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025019485503435135, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.396, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02141525223851204, 'eval_loss_2': 0.0036042332649230957, 'eval_loss_3': -18.086811065673828, 'eval_loss_4': -0.297493577003479, 'epoch': 29.3}
{'loss': 0.0095, 'grad_norm': 6.703088760375977, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.005798584781587124, 'loss_2': 0.003665924072265625, 'loss_3': -16.268491744995117, 'loss_4': -0.43525201082229614, 'epoch': 29.31}
{'loss': 0.0052, 'grad_norm': 4.950230121612549, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.0036385301500558853, 'loss_2': 0.0015287399291992188, 'loss_3': -16.268939971923828, 'loss_4': -0.674263596534729, 'epoch': 29.31}
{'loss': 0.0071, 'grad_norm': 5.920186519622803, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.006919622886925936, 'loss_2': 0.00020205974578857422, 'loss_3': -16.12957000732422, 'loss_4': -0.26909714937210083, 'epoch': 29.32}
{'loss': 0.0071, 'grad_norm': 4.5109052658081055, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.0034619919024407864, 'loss_2': 0.0035915374755859375, 'loss_3': -16.132720947265625, 'loss_4': -0.4909785985946655, 'epoch': 29.33}
{'loss': 0.01, 'grad_norm': 5.584780693054199, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.007173354271799326, 'loss_2': 0.002803802490234375, 'loss_3': -16.38648223876953, 'loss_4': -0.14167585968971252, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 17:22:41,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:41,743 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:03:54<01:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:49,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0250970758497715, 'eval_runtime': 3.7811, 'eval_samples_per_second': 270.823, 'eval_steps_per_second': 4.232, 'eval_loss_1': 0.02152338996529579, 'eval_loss_2': 0.003573685884475708, 'eval_loss_3': -18.086721420288086, 'eval_loss_4': -0.2953440845012665, 'epoch': 29.33}
{'loss': 0.0109, 'grad_norm': 5.547974586486816, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.005098581779748201, 'loss_2': 0.00576019287109375, 'loss_3': -16.32022476196289, 'loss_4': -0.5103803277015686, 'epoch': 29.34}
{'loss': 0.0087, 'grad_norm': 6.677299499511719, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.007148025557398796, 'loss_2': 0.0015277862548828125, 'loss_3': -16.288251876831055, 'loss_4': -0.40358656644821167, 'epoch': 29.34}
{'loss': 0.0099, 'grad_norm': 4.984791278839111, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.006770823150873184, 'loss_2': 0.003170013427734375, 'loss_3': -16.144338607788086, 'loss_4': -0.3437640368938446, 'epoch': 29.35}
{'loss': 0.006, 'grad_norm': 4.4213032722473145, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.00299538834951818, 'loss_2': 0.002979278564453125, 'loss_3': -16.24066162109375, 'loss_4': -0.3716779947280884, 'epoch': 29.35}
{'loss': 0.0073, 'grad_norm': 5.451058387756348, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.005179218482226133, 'loss_2': 0.002079010009765625, 'loss_3': -16.135272979736328, 'loss_4': -0.16939133405685425, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 17:22:49,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:49,066 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:01<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:56,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02504180558025837, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.129, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021511774510145187, 'eval_loss_2': 0.003530029207468033, 'eval_loss_3': -18.087495803833008, 'eval_loss_4': -0.291824609041214, 'epoch': 29.36}
{'loss': 0.0079, 'grad_norm': 6.992112159729004, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.006576333660632372, 'loss_2': 0.0013685226440429688, 'loss_3': -16.054794311523438, 'loss_4': -0.4324871301651001, 'epoch': 29.37}
{'loss': 0.0065, 'grad_norm': 4.095663070678711, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0022053634747862816, 'loss_2': 0.004261016845703125, 'loss_3': -16.378442764282227, 'loss_4': -0.2500323951244354, 'epoch': 29.37}
{'loss': 0.0117, 'grad_norm': 7.9193854331970215, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.011191889643669128, 'loss_2': 0.0005235671997070312, 'loss_3': -16.430137634277344, 'loss_4': -0.2845045328140259, 'epoch': 29.38}
{'loss': 0.0067, 'grad_norm': 4.571835517883301, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.004858838859945536, 'loss_2': 0.0018291473388671875, 'loss_3': -16.354774475097656, 'loss_4': -0.1507953256368637, 'epoch': 29.38}
{'loss': 0.0061, 'grad_norm': 4.622040271759033, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.0043801357969641685, 'loss_2': 0.001735687255859375, 'loss_3': -16.097545623779297, 'loss_4': -0.2737067937850952, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 17:22:56,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:56,397 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:09<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:03,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025010615587234497, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.958, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02151183784008026, 'eval_loss_2': 0.003498777747154236, 'eval_loss_3': -18.08708953857422, 'eval_loss_4': -0.2942386269569397, 'epoch': 29.39}
{'loss': 0.0107, 'grad_norm': 5.301450252532959, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0055810753256082535, 'loss_2': 0.005123138427734375, 'loss_3': -16.161434173583984, 'loss_4': -0.5793758630752563, 'epoch': 29.4}
{'loss': 0.0056, 'grad_norm': 5.075026988983154, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.004767580423504114, 'loss_2': 0.000823974609375, 'loss_3': -16.33643341064453, 'loss_4': -0.21437111496925354, 'epoch': 29.4}
{'loss': 0.0166, 'grad_norm': 5.194319725036621, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.006894454825669527, 'loss_2': 0.00974273681640625, 'loss_3': -16.332963943481445, 'loss_4': -0.23531657457351685, 'epoch': 29.41}
{'loss': 0.0116, 'grad_norm': 5.974259853363037, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.008271095342934132, 'loss_2': 0.0033130645751953125, 'loss_3': -16.075193405151367, 'loss_4': -0.7162191867828369, 'epoch': 29.41}
{'loss': 0.003, 'grad_norm': 4.591274738311768, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.00255199265666306, 'loss_2': 0.0004119873046875, 'loss_3': -16.313785552978516, 'loss_4': -0.5063467025756836, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 17:23:03,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:03,726 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:16<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:11,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02496185153722763, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.973, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.021490631625056267, 'eval_loss_2': 0.0034712255001068115, 'eval_loss_3': -18.085674285888672, 'eval_loss_4': -0.2980421781539917, 'epoch': 29.42}
{'loss': 0.003, 'grad_norm': 4.323642730712891, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.00198001810349524, 'loss_2': 0.0010595321655273438, 'loss_3': -16.446077346801758, 'loss_4': -0.3560631573200226, 'epoch': 29.42}
{'loss': 0.0049, 'grad_norm': 4.67204475402832, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.0026840344071388245, 'loss_2': 0.0021686553955078125, 'loss_3': -16.144948959350586, 'loss_4': -0.881852388381958, 'epoch': 29.43}
{'loss': 0.0087, 'grad_norm': 4.479109287261963, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.004221187438815832, 'loss_2': 0.00447845458984375, 'loss_3': -16.228252410888672, 'loss_4': -0.36211198568344116, 'epoch': 29.44}
{'loss': 0.009, 'grad_norm': 5.137425422668457, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.005541570018976927, 'loss_2': 0.0034503936767578125, 'loss_3': -16.02285385131836, 'loss_4': -0.6190511584281921, 'epoch': 29.44}
{'loss': 0.0062, 'grad_norm': 5.284153938293457, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.005781253334134817, 'loss_2': 0.0004277229309082031, 'loss_3': -16.25302505493164, 'loss_4': -0.19755598902702332, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 17:23:11,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:11,059 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:23<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:18,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024881336838006973, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021455800160765648, 'eval_loss_2': 0.0034255385398864746, 'eval_loss_3': -18.084640502929688, 'eval_loss_4': -0.30073410272598267, 'epoch': 29.45}
{'loss': 0.0155, 'grad_norm': 5.014136791229248, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0056724706664681435, 'loss_2': 0.0097808837890625, 'loss_3': -16.33914566040039, 'loss_4': -0.35512977838516235, 'epoch': 29.45}
{'loss': 0.0106, 'grad_norm': 5.206768035888672, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.003101094625890255, 'loss_2': 0.0075225830078125, 'loss_3': -16.257343292236328, 'loss_4': -0.47281748056411743, 'epoch': 29.46}
{'loss': 0.0063, 'grad_norm': 4.374243259429932, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.0028413136024028063, 'loss_2': 0.0034332275390625, 'loss_3': -16.20684051513672, 'loss_4': -0.6331075429916382, 'epoch': 29.47}
{'loss': 0.0045, 'grad_norm': 4.865781307220459, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.0040090507827699184, 'loss_2': 0.0004839897155761719, 'loss_3': -16.289411544799805, 'loss_4': -0.42497366666793823, 'epoch': 29.47}
{'loss': 0.0104, 'grad_norm': 4.977051258087158, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.003503626212477684, 'loss_2': 0.0069427490234375, 'loss_3': -16.29053497314453, 'loss_4': -0.4235532283782959, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 17:23:18,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:18,395 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:04:31<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:25,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024851633235812187, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.823, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021451545879244804, 'eval_loss_2': 0.003400087356567383, 'eval_loss_3': -18.08403205871582, 'eval_loss_4': -0.3000466227531433, 'epoch': 29.48}
{'loss': 0.0083, 'grad_norm': 5.834754943847656, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.00503300316631794, 'loss_2': 0.003265380859375, 'loss_3': -16.24605941772461, 'loss_4': -0.4367586374282837, 'epoch': 29.48}
{'loss': 0.0073, 'grad_norm': 4.58389139175415, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.004394139163196087, 'loss_2': 0.0028972625732421875, 'loss_3': -16.501585006713867, 'loss_4': -0.5019997358322144, 'epoch': 29.49}
{'loss': 0.014, 'grad_norm': 8.094239234924316, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.013877063989639282, 'loss_2': 0.00011169910430908203, 'loss_3': -16.209890365600586, 'loss_4': -0.3986210525035858, 'epoch': 29.49}
{'loss': 0.0094, 'grad_norm': 6.9461350440979, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.007051941007375717, 'loss_2': 0.002338409423828125, 'loss_3': -16.229333877563477, 'loss_4': -0.5760241746902466, 'epoch': 29.5}
{'loss': 0.0074, 'grad_norm': 5.94523811340332, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.006893213838338852, 'loss_2': 0.0004706382751464844, 'loss_3': -16.237743377685547, 'loss_4': -0.3549811542034149, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 17:23:25,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:25,734 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:04:38<01:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:33,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024869583547115326, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.021506063640117645, 'eval_loss_2': 0.0033635199069976807, 'eval_loss_3': -18.083984375, 'eval_loss_4': -0.29839077591896057, 'epoch': 29.51}
{'loss': 0.0074, 'grad_norm': 4.497969627380371, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.0027482688892632723, 'loss_2': 0.004611968994140625, 'loss_3': -16.176513671875, 'loss_4': -0.5152108669281006, 'epoch': 29.51}
{'loss': 0.0039, 'grad_norm': 4.328785419464111, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0032140249386429787, 'loss_2': 0.0006947517395019531, 'loss_3': -16.399293899536133, 'loss_4': -0.4434453248977661, 'epoch': 29.52}
{'loss': 0.0064, 'grad_norm': 4.442239761352539, 'learning_rate': 5e-07, 'loss_1': 0.00420354912057519, 'loss_2': 0.0022373199462890625, 'loss_3': -16.213428497314453, 'loss_4': -0.5328289866447449, 'epoch': 29.52}
{'loss': 0.0062, 'grad_norm': 4.975874423980713, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.004300807602703571, 'loss_2': 0.00189208984375, 'loss_3': -16.130197525024414, 'loss_4': -0.021863088011741638, 'epoch': 29.53}
{'loss': 0.0074, 'grad_norm': 4.432522773742676, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0021104298066347837, 'loss_2': 0.00528717041015625, 'loss_3': -16.211017608642578, 'loss_4': -0.15769869089126587, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 17:23:33,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:33,075 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:04:45<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:40,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024844838306307793, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.823, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.021511323750019073, 'eval_loss_2': 0.00333351269364357, 'eval_loss_3': -18.085063934326172, 'eval_loss_4': -0.2959480881690979, 'epoch': 29.53}
{'loss': 0.0026, 'grad_norm': 4.450158596038818, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.0023427666164934635, 'loss_2': 0.0002989768981933594, 'loss_3': -16.40693473815918, 'loss_4': -0.5624889731407166, 'epoch': 29.54}
{'loss': 0.009, 'grad_norm': 4.718748569488525, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.004787156358361244, 'loss_2': 0.004253387451171875, 'loss_3': -16.15446662902832, 'loss_4': -0.44220489263534546, 'epoch': 29.55}
{'loss': 0.0055, 'grad_norm': 4.379245758056641, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.0044496129266917706, 'loss_2': 0.0010547637939453125, 'loss_3': -16.19620132446289, 'loss_4': -0.4783485531806946, 'epoch': 29.55}
{'loss': 0.0042, 'grad_norm': 5.079645156860352, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0025906749069690704, 'loss_2': 0.0015697479248046875, 'loss_3': -16.2208194732666, 'loss_4': -0.6516884565353394, 'epoch': 29.56}
{'loss': 0.0078, 'grad_norm': 5.431191921234131, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.006340227089822292, 'loss_2': 0.00141143798828125, 'loss_3': -16.344097137451172, 'loss_4': -0.5990273952484131, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 17:23:40,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:40,409 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:04:53<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:47,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024913771077990532, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021537525579333305, 'eval_loss_2': 0.0033762454986572266, 'eval_loss_3': -18.084936141967773, 'eval_loss_4': -0.28963595628738403, 'epoch': 29.56}
{'loss': 0.0074, 'grad_norm': 4.684676647186279, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.002300356514751911, 'loss_2': 0.00507354736328125, 'loss_3': -16.40167999267578, 'loss_4': -0.15800850093364716, 'epoch': 29.57}
{'loss': 0.0069, 'grad_norm': 4.790008068084717, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.0038904864341020584, 'loss_2': 0.0029811859130859375, 'loss_3': -16.06705665588379, 'loss_4': -0.7183973789215088, 'epoch': 29.58}
{'loss': 0.0112, 'grad_norm': 5.968430042266846, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.007418192457407713, 'loss_2': 0.0037841796875, 'loss_3': -16.151077270507812, 'loss_4': -0.2257903516292572, 'epoch': 29.58}
{'loss': 0.0103, 'grad_norm': 4.834367752075195, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.007544750347733498, 'loss_2': 0.002788543701171875, 'loss_3': -16.183544158935547, 'loss_4': -0.3513581454753876, 'epoch': 29.59}
{'loss': 0.0045, 'grad_norm': 4.381955146789551, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.0030078436248004436, 'loss_2': 0.0014476776123046875, 'loss_3': -16.204967498779297, 'loss_4': -0.6382021903991699, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 17:23:47,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:47,739 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:00<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:55,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025151101872324944, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.026, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.021734418347477913, 'eval_loss_2': 0.003416687250137329, 'eval_loss_3': -18.085329055786133, 'eval_loss_4': -0.28477853536605835, 'epoch': 29.59}
{'loss': 0.0061, 'grad_norm': 4.449934005737305, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.003093548584729433, 'loss_2': 0.00302886962890625, 'loss_3': -16.22344207763672, 'loss_4': -0.10000650584697723, 'epoch': 29.6}
{'loss': 0.0047, 'grad_norm': 3.9403061866760254, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.0028528987895697355, 'loss_2': 0.0018939971923828125, 'loss_3': -16.30658721923828, 'loss_4': -0.17139510810375214, 'epoch': 29.6}
{'loss': 0.0047, 'grad_norm': 4.791016101837158, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.004076861776411533, 'loss_2': 0.0006132125854492188, 'loss_3': -16.244155883789062, 'loss_4': -0.21872299909591675, 'epoch': 29.61}
{'loss': 0.0099, 'grad_norm': 5.063055992126465, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.004771412815898657, 'loss_2': 0.005084991455078125, 'loss_3': -16.267230987548828, 'loss_4': -0.459486186504364, 'epoch': 29.62}
{'loss': 0.0132, 'grad_norm': 9.922656059265137, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.011884491890668869, 'loss_2': 0.0013637542724609375, 'loss_3': -16.20624542236328, 'loss_4': -0.3741619884967804, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 17:23:55,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:55,069 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:07<01:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:24:02,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025241311639547348, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.659, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021812167018651962, 'eval_loss_2': 0.0034291446208953857, 'eval_loss_3': -18.08597183227539, 'eval_loss_4': -0.2842055559158325, 'epoch': 29.62}
{'loss': 0.0083, 'grad_norm': 4.682799339294434, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.004019137471914291, 'loss_2': 0.004306793212890625, 'loss_3': -16.286727905273438, 'loss_4': -0.5888570547103882, 'epoch': 29.63}
{'loss': 0.0025, 'grad_norm': 4.2992987632751465, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.001929015968926251, 'loss_2': 0.0005702972412109375, 'loss_3': -16.285463333129883, 'loss_4': -0.294623464345932, 'epoch': 29.63}
{'loss': 0.0101, 'grad_norm': 5.282313823699951, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.005977659020572901, 'loss_2': 0.004138946533203125, 'loss_3': -16.235504150390625, 'loss_4': -0.7180852890014648, 'epoch': 29.64}
{'loss': 0.0091, 'grad_norm': 5.495297431945801, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.007233491167426109, 'loss_2': 0.001888275146484375, 'loss_3': -16.17306137084961, 'loss_4': 0.045415520668029785, 'epoch': 29.65}
{'loss': 0.0176, 'grad_norm': 7.717649936676025, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.016330305486917496, 'loss_2': 0.001308441162109375, 'loss_3': -16.105979919433594, 'loss_4': -0.7219266891479492, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 17:24:02,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:02,395 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:15<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:09,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025207923725247383, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.902, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021834272891283035, 'eval_loss_2': 0.003373652696609497, 'eval_loss_3': -18.0870304107666, 'eval_loss_4': -0.28683820366859436, 'epoch': 29.65}
{'loss': 0.0092, 'grad_norm': 7.044966697692871, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.007568747736513615, 'loss_2': 0.0015850067138671875, 'loss_3': -16.24744415283203, 'loss_4': -0.3420214056968689, 'epoch': 29.66}
{'loss': 0.0048, 'grad_norm': 4.762607097625732, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.004758714698255062, 'loss_2': 8.153915405273438e-05, 'loss_3': -16.31155014038086, 'loss_4': -0.3774186968803406, 'epoch': 29.66}
{'loss': 0.0045, 'grad_norm': 4.669778347015381, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.004337428603321314, 'loss_2': 0.00018918514251708984, 'loss_3': -16.000717163085938, 'loss_4': -0.5882095694541931, 'epoch': 29.67}
{'loss': 0.0106, 'grad_norm': 6.005645751953125, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.009390901774168015, 'loss_2': 0.001190185546875, 'loss_3': -16.165870666503906, 'loss_4': -0.07766498625278473, 'epoch': 29.67}
{'loss': 0.0143, 'grad_norm': 9.122343063354492, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.011004166677594185, 'loss_2': 0.003265380859375, 'loss_3': -16.124530792236328, 'loss_4': -0.1709035038948059, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 17:24:09,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:09,732 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:22<00:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:17,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02524350956082344, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.021885039284825325, 'eval_loss_2': 0.0033584684133529663, 'eval_loss_3': -18.087417602539062, 'eval_loss_4': -0.2884085178375244, 'epoch': 29.68}
{'loss': 0.006, 'grad_norm': 4.961285591125488, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.0051124668680131435, 'loss_2': 0.0008473396301269531, 'loss_3': -16.175870895385742, 'loss_4': -0.16629059612751007, 'epoch': 29.69}
{'loss': 0.0103, 'grad_norm': 4.446426868438721, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.004510404076427221, 'loss_2': 0.00583648681640625, 'loss_3': -16.31616973876953, 'loss_4': -0.7863439917564392, 'epoch': 29.69}
{'loss': 0.0173, 'grad_norm': 6.908346652984619, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.01081894151866436, 'loss_2': 0.00653076171875, 'loss_3': -16.217960357666016, 'loss_4': -0.46012407541275024, 'epoch': 29.7}
{'loss': 0.0027, 'grad_norm': 4.653611660003662, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.0024944781325757504, 'loss_2': 0.0001933574676513672, 'loss_3': -16.1818790435791, 'loss_4': -0.17576906085014343, 'epoch': 29.7}
{'loss': 0.0156, 'grad_norm': 12.983195304870605, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.015418187715113163, 'loss_2': 0.0001633167266845703, 'loss_3': -16.26276397705078, 'loss_4': -0.2603289484977722, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 17:24:17,091 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:17,091 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:05:29<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:24,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02508486434817314, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021782221272587776, 'eval_loss_2': 0.003302648663520813, 'eval_loss_3': -18.087308883666992, 'eval_loss_4': -0.28873246908187866, 'epoch': 29.71}
{'loss': 0.0062, 'grad_norm': 4.915286064147949, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.005295426584780216, 'loss_2': 0.0008716583251953125, 'loss_3': -16.118833541870117, 'loss_4': -0.7923527956008911, 'epoch': 29.72}
{'loss': 0.0055, 'grad_norm': 5.352217197418213, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.00461460929363966, 'loss_2': 0.000934600830078125, 'loss_3': -16.250244140625, 'loss_4': -0.42125019431114197, 'epoch': 29.72}
{'loss': 0.0104, 'grad_norm': 5.140219688415527, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.007222816348075867, 'loss_2': 0.003131866455078125, 'loss_3': -16.18394660949707, 'loss_4': -0.6377365589141846, 'epoch': 29.73}
{'loss': 0.0117, 'grad_norm': 7.3867692947387695, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.01147694606333971, 'loss_2': 0.0002206563949584961, 'loss_3': -16.11808204650879, 'loss_4': -0.4282078146934509, 'epoch': 29.73}
{'loss': 0.0084, 'grad_norm': 4.659564971923828, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.005991989281028509, 'loss_2': 0.002429962158203125, 'loss_3': -16.232492446899414, 'loss_4': -0.13574129343032837, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 17:24:24,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:24,435 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:05:37<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:31,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02508479915559292, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.671, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02177833579480648, 'eval_loss_2': 0.003306463360786438, 'eval_loss_3': -18.087913513183594, 'eval_loss_4': -0.28756290674209595, 'epoch': 29.74}
{'loss': 0.0071, 'grad_norm': 4.876822471618652, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.00542293768376112, 'loss_2': 0.001651763916015625, 'loss_3': -16.204917907714844, 'loss_4': -0.4184599220752716, 'epoch': 29.74}
{'loss': 0.0037, 'grad_norm': 4.671389102935791, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.0029258255381137133, 'loss_2': 0.0007753372192382812, 'loss_3': -16.394390106201172, 'loss_4': -0.4794766306877136, 'epoch': 29.75}
{'loss': 0.0072, 'grad_norm': 4.913390636444092, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.004731466062366962, 'loss_2': 0.002452850341796875, 'loss_3': -16.331281661987305, 'loss_4': -0.21311764419078827, 'epoch': 29.76}
{'loss': 0.004, 'grad_norm': 4.494444370269775, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.002409339416772127, 'loss_2': 0.0015735626220703125, 'loss_3': -16.078479766845703, 'loss_4': -0.07242335379123688, 'epoch': 29.76}
{'loss': 0.0118, 'grad_norm': 5.471643924713135, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.00746440002694726, 'loss_2': 0.0043182373046875, 'loss_3': -16.352018356323242, 'loss_4': -0.6853702068328857, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 17:24:31,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:31,776 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:05:44<00:36,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:24:39,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025113817304372787, 'eval_runtime': 3.8343, 'eval_samples_per_second': 267.064, 'eval_steps_per_second': 4.173, 'eval_loss_1': 0.021777473390102386, 'eval_loss_2': 0.003336343914270401, 'eval_loss_3': -18.08782196044922, 'eval_loss_4': -0.28881528973579407, 'epoch': 29.77}
{'loss': 0.0112, 'grad_norm': 4.479289531707764, 'learning_rate': 2.5e-07, 'loss_1': 0.002800168702378869, 'loss_2': 0.008392333984375, 'loss_3': -16.00006103515625, 'loss_4': -0.1821281909942627, 'epoch': 29.77}
{'loss': 0.0822, 'grad_norm': 7.2119340896606445, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.07963869720697403, 'loss_2': 0.002582550048828125, 'loss_3': -16.359596252441406, 'loss_4': -0.19102811813354492, 'epoch': 29.78}
{'loss': 0.0046, 'grad_norm': 4.444276332855225, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.004003237001597881, 'loss_2': 0.0005841255187988281, 'loss_3': -16.148052215576172, 'loss_4': -0.4292405843734741, 'epoch': 29.78}
{'loss': 0.0126, 'grad_norm': 9.50322437286377, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.008439771831035614, 'loss_2': 0.0041351318359375, 'loss_3': -16.442298889160156, 'loss_4': -1.023430347442627, 'epoch': 29.79}
{'loss': 0.0133, 'grad_norm': 5.32368803024292, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.004909791983664036, 'loss_2': 0.008392333984375, 'loss_3': -16.228378295898438, 'loss_4': -0.21758463978767395, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 17:24:39,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:39,175 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:05:52<00:31,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:24:46,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025080084800720215, 'eval_runtime': 3.9662, 'eval_samples_per_second': 258.181, 'eval_steps_per_second': 4.034, 'eval_loss_1': 0.021749379113316536, 'eval_loss_2': 0.003330707550048828, 'eval_loss_3': -18.08763885498047, 'eval_loss_4': -0.2880200445652008, 'epoch': 29.8}
{'loss': 0.004, 'grad_norm': 4.781230449676514, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.003441095585003495, 'loss_2': 0.0005621910095214844, 'loss_3': -16.298154830932617, 'loss_4': -0.4342453181743622, 'epoch': 29.8}
{'loss': 0.0084, 'grad_norm': 4.705321311950684, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.003774261800572276, 'loss_2': 0.00464630126953125, 'loss_3': -16.507038116455078, 'loss_4': -0.19060832262039185, 'epoch': 29.81}
{'loss': 0.008, 'grad_norm': 4.633264064788818, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.003172737779095769, 'loss_2': 0.004848480224609375, 'loss_3': -16.169780731201172, 'loss_4': -0.592206597328186, 'epoch': 29.81}
{'loss': 0.0136, 'grad_norm': 4.996845245361328, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0058942255564033985, 'loss_2': 0.007686614990234375, 'loss_3': -16.237926483154297, 'loss_4': -0.3265027403831482, 'epoch': 29.82}
{'loss': 0.013, 'grad_norm': 9.918665885925293, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.012074463069438934, 'loss_2': 0.0008993148803710938, 'loss_3': -16.217660903930664, 'loss_4': -0.24701783061027527, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 17:24:46,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:46,725 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:05:59<00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:54,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02515113353729248, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.021807624027132988, 'eval_loss_2': 0.0033435076475143433, 'eval_loss_3': -18.086959838867188, 'eval_loss_4': -0.28831201791763306, 'epoch': 29.83}
{'loss': 0.0157, 'grad_norm': 5.314903736114502, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.006028716918081045, 'loss_2': 0.00970458984375, 'loss_3': -16.139148712158203, 'loss_4': -0.43778717517852783, 'epoch': 29.83}
{'loss': 0.0081, 'grad_norm': 4.383145809173584, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.00413905642926693, 'loss_2': 0.00396728515625, 'loss_3': -16.338483810424805, 'loss_4': -0.2265569269657135, 'epoch': 29.84}
{'loss': 0.0048, 'grad_norm': 4.069016456604004, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.0025105306413024664, 'loss_2': 0.0022411346435546875, 'loss_3': -16.465988159179688, 'loss_4': -0.3635541796684265, 'epoch': 29.84}
{'loss': 0.0078, 'grad_norm': 5.1660919189453125, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.004590109456330538, 'loss_2': 0.003170013427734375, 'loss_3': -16.417146682739258, 'loss_4': -0.2739711105823517, 'epoch': 29.85}
{'loss': 0.0069, 'grad_norm': 4.709242343902588, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.0028663098346441984, 'loss_2': 0.00399017333984375, 'loss_3': -16.327350616455078, 'loss_4': -0.42356711626052856, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 17:24:54,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:54,068 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:06<00:20,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:25:01,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02511667087674141, 'eval_runtime': 3.857, 'eval_samples_per_second': 265.489, 'eval_steps_per_second': 4.148, 'eval_loss_1': 0.02178042009472847, 'eval_loss_2': 0.0033362507820129395, 'eval_loss_3': -18.08636474609375, 'eval_loss_4': -0.289190411567688, 'epoch': 29.85}
{'loss': 0.0111, 'grad_norm': 5.751707077026367, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.008168119005858898, 'loss_2': 0.0028820037841796875, 'loss_3': -16.401016235351562, 'loss_4': -0.37040001153945923, 'epoch': 29.86}
{'loss': 0.0159, 'grad_norm': 10.251914024353027, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.015857143327593803, 'loss_2': 6.568431854248047e-05, 'loss_3': -16.00442123413086, 'loss_4': -0.5397148728370667, 'epoch': 29.87}
{'loss': 0.0128, 'grad_norm': 4.553577423095703, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.004721558652818203, 'loss_2': 0.00803375244140625, 'loss_3': -16.245162963867188, 'loss_4': -0.5639177560806274, 'epoch': 29.87}
{'loss': 0.0051, 'grad_norm': 4.554443359375, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.0032906015403568745, 'loss_2': 0.0018014907836914062, 'loss_3': -16.17755889892578, 'loss_4': -0.2344275712966919, 'epoch': 29.88}
{'loss': 0.016, 'grad_norm': 5.555739879608154, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.00806463323533535, 'loss_2': 0.00795745849609375, 'loss_3': -16.27383804321289, 'loss_4': 0.05022421479225159, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 17:25:01,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:01,507 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:14<00:15,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:25:08,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025135409086942673, 'eval_runtime': 3.9184, 'eval_samples_per_second': 261.329, 'eval_steps_per_second': 4.083, 'eval_loss_1': 0.0217951200902462, 'eval_loss_2': 0.003340288996696472, 'eval_loss_3': -18.086599349975586, 'eval_loss_4': -0.28836169838905334, 'epoch': 29.88}
{'loss': 0.0145, 'grad_norm': 5.192467212677002, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.0066304863430559635, 'loss_2': 0.00788116455078125, 'loss_3': -16.096799850463867, 'loss_4': -0.3938668668270111, 'epoch': 29.89}
{'loss': 0.0096, 'grad_norm': 5.421349048614502, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.008390402421355247, 'loss_2': 0.0012226104736328125, 'loss_3': -16.239151000976562, 'loss_4': -0.6117779016494751, 'epoch': 29.9}
{'loss': 0.0101, 'grad_norm': 5.879050254821777, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.009472547098994255, 'loss_2': 0.0006570816040039062, 'loss_3': -16.34852409362793, 'loss_4': -0.5664165019989014, 'epoch': 29.9}
{'loss': 0.0043, 'grad_norm': 4.424275875091553, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.00386127270758152, 'loss_2': 0.0004229545593261719, 'loss_3': -16.316024780273438, 'loss_4': -0.3456776440143585, 'epoch': 29.91}
{'loss': 0.0063, 'grad_norm': 4.838491439819336, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.004307599272578955, 'loss_2': 0.0020294189453125, 'loss_3': -16.073450088500977, 'loss_4': -0.9179782271385193, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 17:25:08,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:08,962 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:21<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:25:16,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025142285972833633, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.896, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.021820036694407463, 'eval_loss_2': 0.0033222511410713196, 'eval_loss_3': -18.086572647094727, 'eval_loss_4': -0.2880517840385437, 'epoch': 29.91}
{'loss': 0.0101, 'grad_norm': 4.807915687561035, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.004568730015307665, 'loss_2': 0.00554656982421875, 'loss_3': -16.094820022583008, 'loss_4': -0.13352850079536438, 'epoch': 29.92}
{'loss': 0.0036, 'grad_norm': 4.768971920013428, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.003010527929291129, 'loss_2': 0.0005998611450195312, 'loss_3': -16.21318244934082, 'loss_4': -0.5806316137313843, 'epoch': 29.92}
{'loss': 0.0106, 'grad_norm': 6.613972187042236, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.0074018994346261024, 'loss_2': 0.00318145751953125, 'loss_3': -16.220191955566406, 'loss_4': -0.8880631923675537, 'epoch': 29.93}
{'loss': 0.0145, 'grad_norm': 5.499560832977295, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.008359470404684544, 'loss_2': 0.006160736083984375, 'loss_3': -16.133333206176758, 'loss_4': -0.23027467727661133, 'epoch': 29.94}
{'loss': 0.0134, 'grad_norm': 6.849626541137695, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.006919684819877148, 'loss_2': 0.00644683837890625, 'loss_3': -16.266939163208008, 'loss_4': -0.003169149160385132, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 17:25:16,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:16,298 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:06:29<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:25:23,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02513904869556427, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.329, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.021800341084599495, 'eval_loss_2': 0.0033387094736099243, 'eval_loss_3': -18.086782455444336, 'eval_loss_4': -0.28823208808898926, 'epoch': 29.94}
{'loss': 0.0042, 'grad_norm': 4.862905979156494, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.0038988450542092323, 'loss_2': 0.00027370452880859375, 'loss_3': -16.121021270751953, 'loss_4': -0.6844934225082397, 'epoch': 29.95}
{'loss': 0.008, 'grad_norm': 6.093113422393799, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.006094412412494421, 'loss_2': 0.0019321441650390625, 'loss_3': -16.173851013183594, 'loss_4': -0.4942660331726074, 'epoch': 29.95}
{'loss': 0.0093, 'grad_norm': 5.743506908416748, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.00676299910992384, 'loss_2': 0.0025348663330078125, 'loss_3': -16.09986686706543, 'loss_4': -0.3568127751350403, 'epoch': 29.96}
{'loss': 0.0064, 'grad_norm': 4.313797950744629, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0025635508354753256, 'loss_2': 0.0038604736328125, 'loss_3': -16.349029541015625, 'loss_4': -0.22691205143928528, 'epoch': 29.97}
{'loss': 0.0101, 'grad_norm': 5.474117279052734, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.00724591501057148, 'loss_2': 0.002872467041015625, 'loss_3': -16.30746841430664, 'loss_4': -0.3703716993331909, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 17:25:23,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:23,645 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:36<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:25:30,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025137921795248985, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02178233675658703, 'eval_loss_2': 0.003355585038661957, 'eval_loss_3': -18.086963653564453, 'eval_loss_4': -0.28888675570487976, 'epoch': 29.97}
{'loss': 0.0089, 'grad_norm': 4.697710990905762, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.005856807343661785, 'loss_2': 0.003063201904296875, 'loss_3': -16.197967529296875, 'loss_4': -0.7195092439651489, 'epoch': 29.98}
{'loss': 0.0081, 'grad_norm': 5.729432582855225, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.008002622053027153, 'loss_2': 0.00012958049774169922, 'loss_3': -16.154449462890625, 'loss_4': -0.07435604929924011, 'epoch': 29.98}
{'loss': 0.0069, 'grad_norm': 4.776740074157715, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.004709658678621054, 'loss_2': 0.002223968505859375, 'loss_3': -16.193185806274414, 'loss_4': -0.434554785490036, 'epoch': 29.99}
{'loss': 0.022, 'grad_norm': 7.374753475189209, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.019901487976312637, 'loss_2': 0.0021228790283203125, 'loss_3': -16.029075622558594, 'loss_4': -0.32054561376571655, 'epoch': 29.99}
{'loss': 0.002, 'grad_norm': 6.085115432739258, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.001710425829514861, 'loss_2': 0.0003199577331542969, 'loss_3': -16.307327270507812, 'loss_4': -0.47435563802719116, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 17:25:30,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:30,632 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:39<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 17:25:34,435 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.025159664452075958, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.021809427067637444, 'eval_loss_2': 0.0033502355217933655, 'eval_loss_3': -18.087181091308594, 'eval_loss_4': -0.28996846079826355, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 17:25:34,435 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/checkpoint-1605 (score: 0.01274043694138527).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:39<00:00,  1.47s/it]
{'train_runtime': 7600.9384, 'train_samples_per_second': 43.329, 'train_steps_per_second': 0.679, 'train_loss': 0.04303540970517373, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 17:25:34,512 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64
[INFO|configuration_utils.py:420] 2025-01-21 17:25:34,514 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 17:25:34,969 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 17:25:34,971 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 17:25:34,971 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg64/special_tokens_map.json
01/21/2025 17:25:35 - INFO - __main__ -   ***** Train results *****
01/21/2025 17:25:35 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:25:35 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 17:25:35 - INFO - __main__ -     train_loss = 0.04303540970517373
01/21/2025 17:25:35 - INFO - __main__ -     train_runtime = 7600.9384
01/21/2025 17:25:35 - INFO - __main__ -     train_samples_per_second = 43.329
01/21/2025 17:25:35 - INFO - __main__ -     train_steps_per_second = 0.679
01/21/2025 17:25:35 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 17:25:35,190 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 17:25:35,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:25:35,191 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.56it/s]
01/21/2025 17:25:38 - INFO - __main__ -   ***** Eval results *****
01/21/2025 17:25:38 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:25:38 - INFO - __main__ -     eval_loss = 0.01274043694138527
01/21/2025 17:25:38 - INFO - __main__ -     eval_loss_1 = 0.009303619153797626
01/21/2025 17:25:38 - INFO - __main__ -     eval_loss_2 = 0.0034368187189102173
01/21/2025 17:25:38 - INFO - __main__ -     eval_loss_3 = -18.148771286010742
01/21/2025 17:25:38 - INFO - __main__ -     eval_loss_4 = 1.270930290222168
01/21/2025 17:25:38 - INFO - __main__ -     eval_runtime = 3.7871
01/21/2025 17:25:38 - INFO - __main__ -     eval_samples_per_second = 270.395
01/21/2025 17:25:38 - INFO - __main__ -     eval_steps_per_second = 4.225
